<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>elsevier</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij">AIJ - 21</h2>
<ul>
<li><details>
<summary>
(2025). Minimax off-policy evaluation and learning with subgaussian and differentiable importance weighting. <em>AIJ</em>, <em>348</em>, 104419. (<a href='https://doi.org/10.1016/j.artint.2025.104419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the statistical properties of the off-policy estimation problem, i.e., estimating expectations under a target policy using samples collected from a different policy. We begin by presenting a novel minimax concentration lower bound that highlights the fundamental limits of off-policy estimation. We then analyze two well-known importance weighting (IW) techniques: vanilla IW and self-normalized importance weighting (SN). For both methods, we derive concentration and anti-concentration results, showing that their concentration rates are provably suboptimal compared to our lower bound. Observing that this undesired behavior arises from the heavy-tailed nature of the IW and SN estimators, we propose a new class of parametric estimators based on a transformation using the power mean (PM), which is no longer heavy-tailed. We study the theoretical properties of the PM estimator in terms of bias and variance. We show that, with suitable (possibly data-driven) tuning of its parameters, the PM estimator satisfies two key properties under certain conditions: ( i ) it achieves a subgaussian concentration rate that matches our lower bound and ( ii ) it maintains differentiability with respect to the target policy. Finally, we validate our approach through numerical simulations on both synthetic datasets and contextual bandits, comparing it against standard off-policy evaluation and learning baselines. 1},
  archive      = {J_AIJ},
  author       = {Alberto Maria Metelli and Alessio Russo and Marcello Restelli},
  doi          = {10.1016/j.artint.2025.104419},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104419},
  shortjournal = {Artif. Intell.},
  title        = {Minimax off-policy evaluation and learning with subgaussian and differentiable importance weighting},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the disjunctive rational closure of a conditional knowledge base. <em>AIJ</em>, <em>348</em>, 104418. (<a href='https://doi.org/10.1016/j.artint.2025.104418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most widely investigated decision problems in symbolic AI is that of which conditional sentences of the form “if α , then normally β ” should follow from a knowledge base containing this type of statements. Probably, the most notable approach to this problem is the rational closure construction put forward by Lehmann and Magidor in the'90s, which has been adapted to logical languages of various expressive powers since then. At the core of rational closure is the Rational Monotonicity property, which allows one to retain existing (defeasible) conclusions whenever new information cannot be negated by existing conclusions. As it turns out, Rational Monotonicity is not universally accepted, with many researchers advocating the investigation of weaker versions thereof leading to a larger class of consequence relations. A case in point is that of the Disjunctive Rationality property, which states that if one may draw a (defeasible) conclusion from a disjunction of premises, then one should be able to draw this conclusion from at least one of the premises taken alone. While there are convincing arguments that the rational closure forms the ‘simplest’ rational consequence relation extending a given set of conditionals, the question of what the simplest disjunctive consequence relation in this setting is has not been explored in depth. In this article, we do precisely that by motivating and proposing a concrete construction of the disjunctive rational closure of a conditional knowledge base, of which the properties and consequences of its adoption we also investigate in detail. (Previous versions of this work have been selected for presentation at the 18th International Workshop on Nonmonotonic Reasoning (NMR 2020) [1] and at the 35th AAAI Conference on Artificial Intelligence (AAAI 2021) [2] . The present submission extends and elaborates on both papers.)},
  archive      = {J_AIJ},
  author       = {Richard Booth and Ivan Varzinczak},
  doi          = {10.1016/j.artint.2025.104418},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104418},
  shortjournal = {Artif. Intell.},
  title        = {On the disjunctive rational closure of a conditional knowledge base},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking visual prompt learning as masked visual token modeling. <em>AIJ</em>, <em>348</em>, 104417. (<a href='https://doi.org/10.1016/j.artint.2025.104417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt learning has achieved great success in efficiently exploiting large-scale pre-trained models in natural language processing (NLP). It reformulates the downstream tasks as the generative pre-training ones to achieve consistency, thus improving the performance stably. However, when transferring it to the vision area, current visual prompt learning methods are almost designed on discriminative pre-trained models, and there is also a lack of careful design to unify the forms of pre-training and downstream tasks. To explore prompt learning on the generative pre-trained visual model, as well as keeping the task consistency, we propose Visual Prompt learning as masked visual Token Modeling (VPTM) to transform the downstream visual classification task into the pre-trained masked visual token prediction task. In addition, we develop the prototypical verbalizer for mapping the predicted visual token with implicit semantics to explicit downstream labels. To our best knowledge, VPTM is the first visual prompt method on the generative pre-trained visual model, which achieves consistency between pre-training and downstream visual classification by task reformulation. Experiments show that VPTM outperforms other visual prompt methods and achieves excellent efficiency. Moreover, the task consistency of VPTM contributes to the robustness against prompt location, prompt length and prototype dimension, and could be deployed uniformly.},
  archive      = {J_AIJ},
  author       = {Ning Liao and Bowen Shi and Xiaopeng Zhang and Min Cao and Junchi Yan and Qi Tian},
  doi          = {10.1016/j.artint.2025.104417},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104417},
  shortjournal = {Artif. Intell.},
  title        = {Rethinking visual prompt learning as masked visual token modeling},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Planning for temporally extended goals in pure-past linear temporal logic. <em>AIJ</em>, <em>348</em>, 104409. (<a href='https://doi.org/10.1016/j.artint.2025.104409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study planning for temporally extended goals expressed in Pure-Past Linear Temporal Logic ( ppltl ) in the context of deterministic (i.e., classical) and fully observable nondeterministic (FOND) domains. ppltl is the variant of Linear-time Temporal Logic on finite traces ( ltl f ) that refers to the past rather than the future. Although ppltl is as expressive as ltl f , we show that it is computationally much more effective for planning. In particular, we show that checking the validity of a plan for a ppltl formula is Markovian. This is achieved by introducing a linear number of additional propositional variables that capture the validity of the entire formula in a modular fashion. The solution encoding introduces only a linear number of new fluents proportional to the size of the ppltl goal and does not require any additional spurious action. We implement our solution technique in a system called Plan4Past , which can be used alongside state-of-the-art classical and FOND planners. Our empirical analysis demonstrates the practical effectiveness of Plan4Past in both classical and FOND problems, showing that the resulting planner performs overall better than other planning approaches for ltl f goals.},
  archive      = {J_AIJ},
  author       = {Luigi Bonassi and Giuseppe De Giacomo and Marco Favorito and Francesco Fuggitti and Alfonso Emilio Gerevini and Enrico Scala},
  doi          = {10.1016/j.artint.2025.104409},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104409},
  shortjournal = {Artif. Intell.},
  title        = {Planning for temporally extended goals in pure-past linear temporal logic},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incentives for responsiveness, instrumental control and impact. <em>AIJ</em>, <em>348</em>, 104408. (<a href='https://doi.org/10.1016/j.artint.2025.104408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce three concepts that describe an agent's incentives: response incentives indicate which variables in the environment, such as sensitive demographic information, affect the decision under the optimal policy. Instrumental control incentives indicate whether an agent's policy is chosen to manipulate part of its environment, such as the preferences or instructions of a user. Impact incentives indicate which variables an agent will affect, intentionally or otherwise. For each concept, we establish sound and complete graphical criteria, and discuss general classes of techniques that may be used to produce incentives for safe and fair agent behaviour. Finally, we outline how these notions may be generalised to multi-decision settings. This journal paper extends our conference publication “Agent Incentives: A Causal Perspective”: the material on response incentives and instrumental control incentives is updated, while the work on impact incentives and multi-decision settings is entirely new.},
  archive      = {J_AIJ},
  author       = {Ryan Carey and Eric Langlois and Chris van Merwijk and Shane Legg and Tom Everitt},
  doi          = {10.1016/j.artint.2025.104408},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104408},
  shortjournal = {Artif. Intell.},
  title        = {Incentives for responsiveness, instrumental control and impact},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abstracting situation calculus action theories. <em>AIJ</em>, <em>348</em>, 104407. (<a href='https://doi.org/10.1016/j.artint.2025.104407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a general framework for agent abstraction based on the situation calculus and the ConGolog agent programming language. We assume that we have a high-level specification and a low-level specification of the agent, both represented as basic action theories. A refinement mapping specifies how each high-level action is implemented by a low-level ConGolog program and how each high-level fluent can be translated into a low-level formula. We define a notion of sound abstraction between such action theories in terms of the existence of a suitable bisimulation between their respective models. Sound abstractions have many useful properties that ensure that we can reason about the agent's actions (e.g., executability, projection, and planning) at the abstract level, and refine and concretely execute them at the low level. We also characterize the notion of complete abstraction where all actions (including exogenous ones) that the high level thinks can happen can in fact occur at the low level. To facilitate verifying that one has a sound/complete abstraction relative to a mapping, we provide a set of necessary and sufficient conditions. Finally, we identify a set of basic action theory constraints that ensure that for any low-level action sequence, there is a unique high-level action sequence that it refines. This allows us to track/monitor what the low-level agent is doing and describe it in abstract terms (i.e., provide high-level explanations, for instance, to a client or manager).},
  archive      = {J_AIJ},
  author       = {Bita Banihashemi and Giuseppe De Giacomo and Yves Lespérance},
  doi          = {10.1016/j.artint.2025.104407},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104407},
  shortjournal = {Artif. Intell.},
  title        = {Abstracting situation calculus action theories},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards optimal subsidy bounds for envy-freeable allocations. <em>AIJ</em>, <em>348</em>, 104406. (<a href='https://doi.org/10.1016/j.artint.2025.104406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fair division of indivisible items with subsidies among n agents, where the absolute marginal valuation of each item is at most one. Under monotone nondecreasing valuations (where each item is a good), Brustle et al. [9] demonstrated that a maximum subsidy of 2 ( n − 1 ) and a total subsidy of 2 ( n − 1 ) 2 are sufficient to guarantee the existence of an envy-freeable allocation. In this paper, we improve upon these bounds, even in a wider model. Namely, we show that, given an EF1 allocation, we can compute in polynomial time an envy-free allocation with a subsidy of at most n − 1 per agent and a total subsidy of at most n ( n − 1 ) / 2 . Moreover, when the valuations are monotone nondecreasing, we provide a polynomial-time algorithm that computes an envy-free allocation with a subsidy of at most n − 1.5 per agent and a total subsidy of at most ( n 2 − n − 1 ) / 2 .},
  archive      = {J_AIJ},
  author       = {Yasushi Kawase and Kazuhisa Makino and Hanna Sumita and Akihisa Tamura and Makoto Yokoo},
  doi          = {10.1016/j.artint.2025.104406},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104406},
  shortjournal = {Artif. Intell.},
  title        = {Towards optimal subsidy bounds for envy-freeable allocations},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local-MIP: Efficient local search for mixed integer programming. <em>AIJ</em>, <em>348</em>, 104405. (<a href='https://doi.org/10.1016/j.artint.2025.104405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed Integer Programming (MIP) is a fundamental model in operations research with broad industrial applications. Local search is a powerful methodology for solving complex optimization problems; however, the development of local search algorithms for MIP still needs exploration. In this work, we propose Local-MIP , an efficient local search algorithm tailored for MIP that integrates novel operators and employs a two-mode architecture to adaptively apply operators based on the current solution's feasibility. For the feasible mode, we propose the lift move operator and a corresponding lift process to improve the objective value while maintaining feasibility. For the infeasible mode, we propose the breakthrough move and mixed tight move operators to respectively optimize the objective function and satisfy constraints. To apply operators intelligently, we develop a dynamic weighting scheme that balances the priorities of the objective function and constraints. Furthermore, we propose a two-level scoring function structure that hierarchically selects operations, guiding the search toward high-quality feasible solutions. Experiments are conducted on public benchmarks to compare Local-MIP with state-of-the-art MIP solvers in finding high-quality solutions. The results show that Local-MIP significantly outperforms CPLEX , HiGHS , SCIP , and Feasibility Jump while remaining competitive with the commercial solver Gurobi on challenging problems within short time limits. Moreover, Local-MIP establishes 10 new records on MIPLIB open instances.},
  archive      = {J_AIJ},
  author       = {Peng Lin and Shaowei Cai and Mengchuan Zou and Jinkun Lin},
  doi          = {10.1016/j.artint.2025.104405},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104405},
  shortjournal = {Artif. Intell.},
  title        = {Local-MIP: Efficient local search for mixed integer programming},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Centralized training with hybrid execution in multi-agent reinforcement learning via predictive observation imputation. <em>AIJ</em>, <em>348</em>, 104404. (<a href='https://doi.org/10.1016/j.artint.2025.104404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study hybrid execution in multi-agent reinforcement learning (MARL), a paradigm where agents aim to complete cooperative tasks with arbitrary communication levels at execution time by taking advantage of information-sharing among the agents. Under hybrid execution, the communication level can range from a setting in which no communication is allowed between agents (fully decentralized), to a setting featuring full communication (fully centralized), but the agents do not know beforehand which communication level they will encounter at execution time. We contribute MARO, an approach that makes use of an auto-regressive predictive model, trained in a centralized manner, to estimate missing agents' observations at execution time. We evaluate MARO on standard scenarios and extensions of previous benchmarks tailored to emphasize the impact of partial observability in MARL. Experimental results show that our method consistently outperforms relevant baselines, allowing agents to act with faulty communication while successfully exploiting shared information.},
  archive      = {J_AIJ},
  author       = {Pedro P. Santos and Diogo S. Carvalho and Miguel Vasco and Alberto Sardinha and Pedro A. Santos and Ana Paiva and Francisco S. Melo},
  doi          = {10.1016/j.artint.2025.104404},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104404},
  shortjournal = {Artif. Intell.},
  title        = {Centralized training with hybrid execution in multi-agent reinforcement learning via predictive observation imputation},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algebras of actions in an agent's representations of the world. <em>AIJ</em>, <em>348</em>, 104403. (<a href='https://doi.org/10.1016/j.artint.2025.104403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning efficient representations allows robust processing of data, data that can then be generalised across different tasks and domains, and it is thus paramount in various areas of Artificial Intelligence, including computer vision, natural language processing and reinforcement learning, among others. Within the context of reinforcement learning, we propose in this paper a mathematical framework to learn representations by extracting the algebra of the transformations of worlds from the perspective of an agent. As a starting point, we use our framework to reproduce representations from the symmetry-based disentangled representation learning (SBDRL) formalism proposed by [1] and prove that, although useful, they are restricted to transformations that respond to the properties of algebraic groups. We then generalise two important results of SBDRL –the equivariance condition and the disentangling definition– from only working with group-based symmetry representations to working with representations capturing the transformation properties of worlds for any algebra, using examples common in reinforcement learning and generated by an algorithm that computes their corresponding Cayley tables. Finally, we combine our generalised equivariance condition and our generalised disentangling definition to show that disentangled sub-algebras can each have their own individual equivariance conditions, which can be treated independently, using category theory. In so doing, our framework offers a rich formal tool to represent different types of symmetry transformations in reinforcement learning, extending the scope of previous proposals and providing Artificial Intelligence developers with a sound foundation to implement efficient applications.},
  archive      = {J_AIJ},
  author       = {Alexander Dean and Eduardo Alonso and Esther Mondragón},
  doi          = {10.1016/j.artint.2025.104403},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104403},
  shortjournal = {Artif. Intell.},
  title        = {Algebras of actions in an agent's representations of the world},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cooperativity in controlled query evaluation over ontologies. <em>AIJ</em>, <em>348</em>, 104402. (<a href='https://doi.org/10.1016/j.artint.2025.104402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlled Query Evaluation (CQE) is a methodology designed to maintain confidentiality by either rejecting specific queries or adjusting responses to safeguard sensitive information. In this investigation, our focus centers on CQE within Description Logic ontologies, aiming to ensure that queries are answered truthfully as long as possible before resorting to deceptive responses, a cooperativity property which is called the “longest honeymoon”. Our work introduces new semantics for CQE, denoted as MC-CQE, which enjoys the longest honeymoon property and outperforms previous methodologies in terms of cooperativity. We study the complexity of query answering in this new framework for ontologies expressed in the Description Logic DL-Lite R . Specifically, we establish data complexity results under different maximally cooperative semantics and for different classes of queries. Our results identify both tractable and intractable cases. In particular, we show that the evaluation of Boolean unions of conjunctive queries is the same under all the above semantics and its data complexity is in . This result makes query answering amenable to SQL query rewriting. However, this favorable property does not extend to open queries, even with a restricted query language limited to conjunctions of atoms. While, in general, answering open queries in the MC-CQE framework is intractable, we identify a sub-family of semantics under which answering full conjunctive queries is tractable.},
  archive      = {J_AIJ},
  author       = {Piero Bonatti and Gianluca Cima and Domenico Lembo and Francesco Magliocca and Lorenzo Marconi and Riccardo Rosati and Luigi Sauro and Domenico Fabio Savo},
  doi          = {10.1016/j.artint.2025.104402},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104402},
  shortjournal = {Artif. Intell.},
  title        = {Enhancing cooperativity in controlled query evaluation over ontologies},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BATED: Learning fair representation for pre-trained language models via biased teacher-guided disentanglement. <em>AIJ</em>, <em>348</em>, 104401. (<a href='https://doi.org/10.1016/j.artint.2025.104401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Pre-trained Language Models (PLMs) and their widespread deployment in various real-world applications, social biases of PLMs have attracted increasing attention, especially the fairness of downstream tasks, which potentially affects the development and stability of society. Among existing debiasing methods, intrinsic debiasing methods are not necessarily effective when applied to downstream tasks, and the downstream fine-tuning process may introduce new biases or catastrophic forgetting. Most extrinsic debiasing methods rely on sensitive attribute words as prior knowledge to supervise debiasing training. However, it is difficult to collect sensitive attribute information of real data due to privacy and regulation. Moreover, limited sensitive attribute words may lead to inadequate debiasing training. To this end, this paper proposes a debiasing method to learn fair representation for PLMs via B i A sed TE acher-guided D isentanglement (called BATED ). Specific to downstream tasks, BATED performs debiasing training under the guidance of a biased teacher model rather than relying on sensitive attribute information of the training data. First, we leverage causal contrastive learning to train a task-agnostic general biased teacher model. We then employ Variational Auto-Encoder (VAE) to disentangle the PLM-encoded representation into the fair representation and the biased representation. The Biased representation is further decoupled via biased teacher-guided disentanglement, while the fair representation learn downstream tasks. Therefore, BATED guarantees the performance of downstream tasks while improving the fairness. Experimental results on seven PLMs testing three downstream tasks demonstrate that BATED outperforms the state-of-the-art overall in terms of fairness and performance on downstream tasks.},
  archive      = {J_AIJ},
  author       = {Yingji Li and Mengnan Du and Rui Song and Mu Liu and Ying Wang},
  doi          = {10.1016/j.artint.2025.104401},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104401},
  shortjournal = {Artif. Intell.},
  title        = {BATED: Learning fair representation for pre-trained language models via biased teacher-guided disentanglement},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On preference learning based on sequential bayesian optimization with pairwise comparison. <em>AIJ</em>, <em>348</em>, 104400. (<a href='https://doi.org/10.1016/j.artint.2025.104400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User preference learning is generally a hard problem. Individual preferences are typically unknown even to users themselves, while the space of choices is infinite. Here we study user preference learning from information-theoretic perspective. We model preference learning as a system with two interacting sub-systems, one representing a user with his/her preferences and another one representing an agent that has to learn these preferences. The user with his/her behavior is modeled by a parametric preference function. To efficiently learn the preferences and reduce search space quickly, we propose the agent that interacts with the user to collect the most informative data for learning. The agent presents two proposals to the user for evaluation, and the user rates them based on his/her preference function. We show that the optimum agent strategy for data collection and preference learning is a result of maximin optimization of the normalized weighted Kullback-Leibler (KL) divergence between true and agent-assigned predictive user response distributions. The resulting value of the KL-divergence, which we also call of a remaining system uncertainty (RSU), provides an efficient performance metric in the absence of the ground truth. This metric characterizes how well the agent can predict user and, thus, the quality of the underlying learned user (preference) model. Our proposed agent comprises sequential mechanisms for user model inference and proposal generation. To infer the user model (preference function), Bayesian approximate inference is used in the agent. The data collection strategy is to generate proposals, responses to which help resolving uncertainty associated with prediction of the user responses the most. The efficiency of our approach is validated by numerical simulations. Also a real-life example of preference learning application is provided.},
  archive      = {J_AIJ},
  author       = {Tanya Ignatenko and Kirill Kondrashov and Marco Cox and Bert de Vries},
  doi          = {10.1016/j.artint.2025.104400},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104400},
  shortjournal = {Artif. Intell.},
  title        = {On preference learning based on sequential bayesian optimization with pairwise comparison},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Choosing abstraction levels for model-based software debugging: A theoretical and empirical analysis for spreadsheet programs. <em>AIJ</em>, <em>348</em>, 104399. (<a href='https://doi.org/10.1016/j.artint.2025.104399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based diagnosis is a generally applicable, principled approach to the systematic debugging of a wide range of system types such as circuits, knowledge bases, physical devices, or software. Based on a formal description of the system, it enables precise and deterministic reasoning about potential faults responsible for observed misbehavior. In software, such a formal system description can often even be extracted from the buggy program fully automatically. As logical reasoning is central to diagnosis, the performance of model-based debuggers is largely influenced by reasoning efficiency, which in turn depends on the complexity and expressivity of the system description. Since highly detailed models capturing exact semantics often exceed the capabilities of current reasoning tools, researchers have proposed more abstract representations. In this work, we thoroughly analyze system modeling techniques with a focus on fault localization in spreadsheets—one of the most widely used end-user programming paradigms. Specifically, we present three constraint model types characterizing spreadsheets at different abstraction levels, show how to extract them automatically from faulty spreadsheets, and provide theoretical and empirical investigations of the impact of abstraction on both diagnostic output and computational performance. Our main conclusions are that (i) for the model types, there is a trade-off between the conciseness of generated fault candidates and computation time, (ii) the exact model is often impractical, and (iii) a new model based on qualitative reasoning yields the same solutions as the exact one in up to more than half the cases while being orders of magnitude faster. Due to their ability to restrict the solution space in a sound way, the explored model-based techniques, rather than being used as standalone approaches, are expected to realize their full potential in combination with iterative sequential diagnosis or indeterministic but more performant statistical debugging methods.},
  archive      = {J_AIJ},
  author       = {Patrick Rodler and Birgit Hofer and Dietmar Jannach and Iulia Nica and Franz Wotawa},
  doi          = {10.1016/j.artint.2025.104399},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104399},
  shortjournal = {Artif. Intell.},
  title        = {Choosing abstraction levels for model-based software debugging: A theoretical and empirical analysis for spreadsheet programs},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Argus: Programming with communication protocols in a belief-desire-intention architecture. <em>AIJ</em>, <em>348</em>, 104398. (<a href='https://doi.org/10.1016/j.artint.2025.104398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protocols model multiagent systems (MAS) by capturing the communications between its agents. Belief-Desire-Intention (BDI) architectures provide an attractive way for organizing an agent in terms of cognitive concepts. Current BDI approaches, however, lack adequate support for engineering protocol-based agents. We describe Argus, an approach that melds recent advances in flexible, declarative communication protocols with BDI architectures. For concreteness, we adopt Jason as an exemplar of the BDI paradigm and show how to support protocol-based reasoning in it. Specifically, Argus contributes (1) a novel architecture and formal operational semantics combining protocols and BDI; (2) a code generation-based programming model that guides the implementation of agents; and (3) integrity checking for incoming and outgoing messages that help ensure that the agents are well-behaved. The Argus conceptual architecture builds quite naturally on top of Jason. Thus, Argus enables building more flexible multiagent systems while using a BDI architecture than is currently possible.},
  archive      = {J_AIJ},
  author       = {Samuel H. Christie V and Munindar P. Singh and Amit K. Chopra},
  doi          = {10.1016/j.artint.2025.104398},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104398},
  shortjournal = {Artif. Intell.},
  title        = {Argus: Programming with communication protocols in a belief-desire-intention architecture},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social behavior as a key to learning-based multi-agent pathfinding dilemmas. <em>AIJ</em>, <em>348</em>, 104397. (<a href='https://doi.org/10.1016/j.artint.2025.104397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-agent Path Finding (MAPF) problem involves finding collision-free paths for a team of agents in a known, static environment, with important applications in warehouse automation, logistics, or last-mile delivery. To meet the needs of these large-scale applications, current learning-based methods often deploy the same fully trained, decentralized network to all agents to improve scalability. However, such parameter sharing typically results in homogeneous behaviors among agents, which may prevent agents from breaking ties around symmetric conflict (e.g., bottlenecks) and might lead to live-/deadlocks. In this paper, we propose SYLPH, a novel learning-based MAPF framework aimed to mitigate the adverse effects of homogeneity by allowing agents to learn and dynamically select different social behaviors (akin to individual, dynamic roles), without affecting the scalability offered by parameter sharing. Specifically, SYLPH offers a novel hierarchical mechanism by introducing Social Value Orientation (SVO) as a temporally extended latent variable that plays a central role in both policy generation and reward assignment. To support this hierarchical decision-making process, we introduce Social-aware Multi-Policy PPO (SMP3O), a reinforcement learning method that ensures stable and effective training through a mechanism for the cross-utilization of advantages. Moreover, we design an SVO-based learning tie-breaking algorithm, allowing agents to proactively avoid collisions, rather than relying solely on post-processing techniques. As a result of this hierarchical decision-making and exchange of social preferences, SYLPH endows agents with the ability to reason about the MAPF task through more latent spaces and nuanced contexts, leading to varied responses that can help break ties around symmetric conflicts. Our comparative experiments show that SYLPH achieves state-of-the-art performance, surpassing other learning-based MAPF planners in random, room-like, and maze-like maps, while our ablation studies demonstrate the advantages of each component in SYLPH. We finally experimentally validate our trained policies on hardware in three types of maps, showing how SYLPH allows agents to find high-quality paths under real-life conditions. Our code and videos are available at: marmotlab.github.io/mapf_sylph .},
  archive      = {J_AIJ},
  author       = {Chengyang He and Tanishq Duhan and Parth Tulsyan and Patrick Kim and Guillaume Sartoretti},
  doi          = {10.1016/j.artint.2025.104397},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104397},
  shortjournal = {Artif. Intell.},
  title        = {Social behavior as a key to learning-based multi-agent pathfinding dilemmas},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MATE: Masked optimal transport with dynamic selection for partial label graph learning. <em>AIJ</em>, <em>348</em>, 104396. (<a href='https://doi.org/10.1016/j.artint.2025.104396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of partial label graph learning, in which every graph is associated with a set of candidate labels. Previous methods for weakly supervised graph classification often provide pseudo-labels for graph samples that could be overconfident and biased towards the dominant classes, thus resulting in substantial error accumulation. In this paper, we introduce a new framework named M asked Optim a l T ransport with Dynamic S e lection (MATE) for partial label graph learning, which improves the quality of graph assignments from the perspectives of class balancing and uncertainty mining. In particular, our MATE masks probabilities out of candidate sets and then adopts optimal transport to optimize the assignments without class biases. This design is based on the assumption that the true label distribution is class-balanced or nearly balanced, which is common in various training datasets and real-world scenarios. To further reduce potential noise, we propose a novel scoring metric termed partial energy discrepancy (PED) to evaluate the uncertainty of assignments, and then introduce a dynamic selection strategy that modifies the sample-specific thresholds via momentum updating. Finally, these samples are divided into three levels, i.e., confident, less-confident, and unconfident and each group is trained separately in our collaborative optimization framework. Extensive experiments on various benchmarks demonstrate the superiority of our MATE compared to various state-of-the-art baselines.},
  archive      = {J_AIJ},
  author       = {Yiyang Gu and Binqi Chen and Zihao Chen and Ziyue Qiao and Xiao Luo and Junyu Luo and Zhiping Xiao and Wei Ju and Ming Zhang},
  doi          = {10.1016/j.artint.2025.104396},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104396},
  shortjournal = {Artif. Intell.},
  title        = {MATE: Masked optimal transport with dynamic selection for partial label graph learning},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpreting capsule networks for image classification by routing path visualization. <em>AIJ</em>, <em>348</em>, 104395. (<a href='https://doi.org/10.1016/j.artint.2025.104395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks are popular for computer vision as they often give state-of-the-art performance, but are difficult to interpret because of their complexity. This black box modeling is especially troubling when the application concerns human well-being such as in medical image analysis or autonomous driving. In this work, we propose a technique called routing path visualization for capsule networks, which reveals how much of each region in an image is routed to each capsule. In turn, this technique can be used to interpret the entity that a given capsule detects, and speculate how the network makes a prediction. We demonstrate our new visualization technique on several real world datasets. Experimental results suggest that routing path visualization can precisely localize the predicted class from an image, even though the capsule networks are trained using just images and their respective class labels, without additional information defining the location of the class in the image.},
  archive      = {J_AIJ},
  author       = {Amanjot Bhullar and Michael Czomko and R. Ayesha Ali and Douglas L. Welch},
  doi          = {10.1016/j.artint.2025.104395},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104395},
  shortjournal = {Artif. Intell.},
  title        = {Interpreting capsule networks for image classification by routing path visualization},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relaxed core stability in hedonic games. <em>AIJ</em>, <em>348</em>, 104394. (<a href='https://doi.org/10.1016/j.artint.2025.104394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core is a well-known and fundamental notion of stability in games intended to model coalition formation such as hedonic games: an outcome is core stable if there exists no blocking coalition , i.e., no set of agents that may profit by forming a coalition together. The fact that the cardinality of a blocking coalition, i.e., the number of deviating agents that have to coordinate themselves, can be arbitrarily high, and the fact that agents may benefit only by a tiny amount from their deviation, while they could incur in a higher cost for deviating, suggest that the core is not able to suitably model practical scenarios in large and highly distributed multi-agent systems. For this reason, we consider relaxed core stable outcomes where the notion of permissible deviations is modified along two orthogonal directions: the former takes into account the size q of the deviating coalition, and the latter the amount of utility gain, in terms of a multiplicative factor k , for each member of the deviating coalition. These changes result in two different notions of stability, namely, the q-size core and k-improvement core . We consider fractional hedonic games, that is a well-known subclass of hedonic games for which core stable outcomes are not guaranteed to exist and it is computationally hard to decide non-emptiness of the core; we investigate these relaxed concepts of stability with respect to their existence, computability and performance in terms of price of anarchy and price of stability, by providing in many cases tight or almost tight bounds. Interestingly, the considered relaxed notions of core also possess the appealing property of recovering, in some notable cases, the convergence, the existence and the possibility of computing stable solutions in polynomial time.},
  archive      = {J_AIJ},
  author       = {Angelo Fanelli and Gianpiero Monaco and Luca Moscardelli},
  doi          = {10.1016/j.artint.2025.104394},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104394},
  shortjournal = {Artif. Intell.},
  title        = {Relaxed core stability in hedonic games},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provably efficient information-directed sampling algorithms for multi-agent reinforcement learning. <em>AIJ</em>, <em>348</em>, 104392. (<a href='https://doi.org/10.1016/j.artint.2025.104392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work designs and analyzes a novel set of algorithms for multi-agent reinforcement learning (MARL) based on the principle of information-directed sampling (IDS). These algorithms draw inspiration from foundational concepts in information theory, and are proven to be sample efficient in MARL settings such as two-player zero-sum Markov games (MGs) and multi-player general-sum MGs. For episodic two-player zero-sum MGs, we present three sample-efficient algorithms for learning Nash equilibrium. The basic algorithm, referred to as MAIDS , employs an asymmetric learning structure where the max-player first solves a minimax optimization problem based on the joint information ratio of the joint policy, and the min-player then minimizes the marginal information ratio with the max-player's policy fixed. Theoretical analyses show that it achieves a Bayesian regret of O ˜ ( K ) for K episodes. To reduce the computational load of MAIDS , we develop an improved algorithm called Reg-MAIDS , which has the same Bayesian regret bound while enjoying less computational complexity. Moreover, by leveraging the flexibility of IDS principle in choosing the learning target, we propose two methods for constructing compressed environments based on rate-distortion theory, upon which we develop an algorithm Compressed-MAIDS wherein the learning target is a compressed environment. Finally, we extend Reg-MAIDS to multi-player general-sum MGs and prove that it can learn either the Nash equilibrium or coarse correlated equilibrium in a sample-efficient manner.},
  archive      = {J_AIJ},
  author       = {Qiaosheng Zhang and Chenjia Bai and Shuyue Hu and Zhen Wang and Xuelong Li},
  doi          = {10.1016/j.artint.2025.104392},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104392},
  shortjournal = {Artif. Intell.},
  title        = {Provably efficient information-directed sampling algorithms for multi-agent reinforcement learning},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the design of truthful mechanisms for the capacitated facility location problem with two and more facilities. <em>AIJ</em>, <em>348</em>, 104390. (<a href='https://doi.org/10.1016/j.artint.2025.104390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we explore the Mechanism Design aspects of the m -Capacitated Facility Location Problem ( m -CFLP) on a line, focusing on two frameworks. In the first framework, the number of facilities is arbitrary, all facilities share the same capacity, and the number of agents matches the total capacity of the facilities. In the second framework, we need to locate two facilities, each with a capacity equal to at least half the number of agents. For both frameworks, we propose truthful mechanisms with bounded approximation ratios in terms of Social Cost (SC) and Maximum Cost (MC). When m > 2 , our results stand in contrast to the impossibility results known for the classical m -Facility Location Problem, where capacity constraints are absent. Moreover, all the proposed mechanisms are optimal with respect to MC and either optimal or near-optimal with respect to the SC among anonymous mechanisms. We then establish lower bounds on the approximation ratios that any truthful and deterministic mechanism achieves with respect to SC and MC for both frameworks. Lastly, we run several numerical experiments to empirically evaluate the performances of our mechanisms with respect to the SC or the MC. Our empirical analysis shows that our proposed mechanisms outperform all previously proposed mechanisms applicable in this setting.},
  archive      = {J_AIJ},
  author       = {Gennaro Auricchio and Zihe Wang and Jie Zhang},
  doi          = {10.1016/j.artint.2025.104390},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104390},
  shortjournal = {Artif. Intell.},
  title        = {On the design of truthful mechanisms for the capacitated facility location problem with two and more facilities},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="amc">AMC - 8</h2>
<ul>
<li><details>
<summary>
(2026). Integrating emotion and expectation improves cooperation. <em>AMC</em>, <em>511</em>, 129736. (<a href='https://doi.org/10.1016/j.amc.2025.129736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperation is a key issue attracting widespread attention across various fields. Emotions and expectations jointly participate in the decision-making process, and are key factors influencing the evolution of cooperation. Therefore, this paper proposes a game evolution model that considers the dual influences of emotions and expectations. In the model, a player’s initial strategy depends on their emotions. Subsequently, expectations influence the decision-making process, altering the player’s initial strategy to the current strategy. Specifically, high expectations lead players to maintain their initial strategy, whereas low expectations prompt them to change strategies. Furthermore, the paper analyzes the evolution of cooperation in the prisoner’s dilemma and the influence of expectations. Simulation results show that under high betrayal temptation, players with loneliness and defection would change their initial strategy to cooperation due to low expectations, while those players who initially gather with cooperation strategies maintain the cooperation strategies due to higher expectations, ultimately increasing the cooperation fraction and payoff of the population. Therefore, expectations effectively enhance the cooperation level and payoff of the population. When the scale of individuals changing their strategies based on expectations (ICSE) is large, the effect of expectations on enhancing cooperation and payoff is more pronounced. Frequent consideration of anticipated initial strategy changes also yields the same effect. Additionally, mechanisms of the influence of emotion on payoff, direct emotion interaction and the influence of strategy on emotion collectively contribute to enhancing the significantly evolutionary advantage of friendly emotions and cooperation strategies. This paper contributes to a deeper understanding of the role of expectations in the evolution of emotions and cooperation, laying the groundwork for enhancing social cooperation through expectation management.},
  archive      = {J_AMC},
  author       = {Wen Lu and Shu Liang},
  doi          = {10.1016/j.amc.2025.129736},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129736},
  shortjournal = {Appl. Math. Comput.},
  title        = {Integrating emotion and expectation improves cooperation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On sketch-and-project methods for solving tensor equations. <em>AMC</em>, <em>511</em>, 129735. (<a href='https://doi.org/10.1016/j.amc.2025.129735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a regular sketch-and-project method for solving linear tensor equations based on the t-product and present its equivalent Fourier domain version, along with several special cases corresponding to existing classical matrix equation methods. Furthermore, we extend this framework via a hierarchical approach to solve generalized Sylvester tensor equations. All the methods are proved to converge linearly in expectation. Finally, numerical experiments demonstrate the efficiency and effectiveness of the proposed approach.},
  archive      = {J_AMC},
  author       = {Ling Tang and Yanjun Zhang and Hanyu Li},
  doi          = {10.1016/j.amc.2025.129735},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129735},
  shortjournal = {Appl. Math. Comput.},
  title        = {On sketch-and-project methods for solving tensor equations},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sampling patterns for zernike-like bases in non-standard geometries. <em>AMC</em>, <em>511</em>, 129727. (<a href='https://doi.org/10.1016/j.amc.2025.129727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zernike polynomials are widely used in optics and ophthalmology due to their direct connection to classical optical aberrations. While orthogonal on the unit disk, their application to discrete data or non-circular domains–such as ellipses, annuli, and hexagons–presents challenges in terms of numerical stability and accuracy. In this work, we extend Zernike-like orthogonal functions to these non-standard geometries using diffeomorphic mappings and construct sampling patterns that preserve favorable numerical conditioning. We provide theoretical bounds for the condition numbers of the resulting collocation matrices and validate them through extensive numerical experiments. As a practical application, we demonstrate accurate wavefront interpolation and reconstruction in segmented mirror telescopes composed of hexagonal facets. Our results show that appropriately transferred sampling configurations, especially Optimal Concentric Sampling and Lebesgue points , allow stable high-order interpolation and effective wavefront modeling in complex optical systems. Moreover, the Optimal Concentric Samplings can be computed with an explicit expression, which is a significant advantage in practice.},
  archive      = {J_AMC},
  author       = {S. Díaz-Elbal and A. Martínez-Finkelshtein and D. Ramos-López},
  doi          = {10.1016/j.amc.2025.129727},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129727},
  shortjournal = {Appl. Math. Comput.},
  title        = {Sampling patterns for zernike-like bases in non-standard geometries},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal information spreading strategy for containing epidemic spreading on higher-order multiplex networks. <em>AMC</em>, <em>511</em>, 129725. (<a href='https://doi.org/10.1016/j.amc.2025.129725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When an epidemic spreads through a population, related information also spreads concurrently, prompting individuals to adopt protective behaviours (e.g., washing hands). Collective behaviour has been shown to play a critical role in shaping the dynamics of epidemic spreading, and higher-order networks offer a natural framework to describe such group interactions in social contact networks. Yet, the interplay between epidemic and information dynamics on higher-order structures is not fully understood, further limiting our understanding of the optimal information spreading strategy for containing epidemic spreading.In this study, we first construct a higher-order multiplex network framework based on simplicial complexes. Then, a coevolutionary spreading model is proposed, integrating epidemic spreading and information spreading on simplicial complexes. The epidemic spreads through both lower-order (pairwise) and higher-order (group) interactions, while information spreads through lower-order interactions in a degree-preferential manner. Using an extended Microscopic Markov Chain Approach, we analytically derive the dynamical equations of the system and compute the basic reproduction number using the next-generation matrix method. Finally, we conduct extensive numerical simulations of the spreading process across various parameter regimes. Our results demonstrate the role of higher-order infections in promoting epidemics. Although information spreading generally suppresses the spread of most epidemics, it can paradoxically enhance the spread of certain epidemics with a very low spreading capacity. Increases in the recovery probabilities of both the disease and the information can weaken the promoting effect of higher-order infection and enhance the suppressive effect of the information. For certain epidemics with weak spreading capabilities but strong recovery capabilities, the spread of information can completely suppress the outbreak of the disease, while the enhancement of higher-order infections can promote the outbreak of these diseases. By analysing the effects of different information spreading strategies on epidemic spreading, we find that the optimal strategy for containing the epidemic is to allow information to spread without degree preference.},
  archive      = {J_AMC},
  author       = {Jiayi Song and Wenjie Li and Yunzhu Xiao and Ling Chen and Chun Yang and Li Qi and Wei Wang},
  doi          = {10.1016/j.amc.2025.129725},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129725},
  shortjournal = {Appl. Math. Comput.},
  title        = {Optimal information spreading strategy for containing epidemic spreading on higher-order multiplex networks},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the fairness and cooperation among free-riders. <em>AMC</em>, <em>511</em>, 129724. (<a href='https://doi.org/10.1016/j.amc.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the free-rider problem in peer-to-peer (P2P) systems, where agents enjoy the group effort without contributing their share. We introduce the Free-Rider Game (FRG), a non-cooperative game incorporating a fairness-aware profit allocation rule based on the Robin Hood index. We show that FRG admits strong structural properties. First, making a non-zero contribution is a dominant strategy for any player. Second, a player contributes positively whenever at least one other player does so. Third, FRG admits a unique Nash equilibrium in which each player contributes the fullest, eliminating free riding. Fourth, equilibrium outcomes are proportionally fair, ensuring balanced allocation across agents. Finally, FRG guarantees full participation by embedding fairness directly into the payoff structure, differentiating it from classical public goods games, which often yield zero or partial contributions.},
  archive      = {J_AMC},
  author       = {Avadh Kishor},
  doi          = {10.1016/j.amc.2025.129724},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129724},
  shortjournal = {Appl. Math. Comput.},
  title        = {On the fairness and cooperation among free-riders},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Equilibrium analysis of edge-heterogeneous binary network games. <em>AMC</em>, <em>511</em>, 129723. (<a href='https://doi.org/10.1016/j.amc.2025.129723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies on the equilibrium of binary network games have primarily focused on scenarios characterized by agent heterogeneity, where agents exhibit unique attributes but their interactions with different neighbors remain uniform. In this paper, we investigate the edge-heterogeneous binary network game, a more general framework that incorporates heterogeneity into agent interactions. We establish two sufficient equilibrium conditions under asynchronous best-response dynamics from different perspectives. The first condition requires underlying symmetry in interactions between neighboring agents, integrating and generalizing three classical convergence situations in binary network games. The second condition focuses on network balance, positing that equilibrium is achievable if the coordination value network of a game is structurally balanced. Additionally, for games meeting this condition, we develop a method to predict the final state based on initial state information. These results reveal factors that steer edge-heterogeneous binary network games towards equilibrium, providing valuable insights for controlling such highly nonlinear systems. Lastly, we extend the analysis to higher-order network games and propose an equilibrium condition for edge-heterogeneous 2-order network games.},
  archive      = {J_AMC},
  author       = {Jiawen Wang and Yangyang Luan and Xiaoqun Wu},
  doi          = {10.1016/j.amc.2025.129723},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129723},
  shortjournal = {Appl. Math. Comput.},
  title        = {Equilibrium analysis of edge-heterogeneous binary network games},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Theory and numerics of subspace approximation of eigenvalue problems. <em>AMC</em>, <em>511</em>, 129722. (<a href='https://doi.org/10.1016/j.amc.2025.129722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale eigenvalue problems arise in various fields of science and engineering and demand computationally efficient solutions. In this study, we investigate the subspace approximation for parametric linear eigenvalue problems, aiming to mitigate the computational burden associated with high-fidelity systems. We provide general error estimates under non-simple eigenvalue conditions, establishing some theoretical foundations for understanding the convergence behavior of subspace approximations. Numerical examples, including problems with one-dimensional to three-dimensional spatial domain and one-dimensional to two-dimensional parameter domain, are presented to demonstrate the efficacy of reduced basis method in handling parametric variations in boundary conditions and coefficient fields to achieve significant computational savings while maintaining high accuracy, making them promising tools for practical applications in large-scale eigenvalue computations.},
  archive      = {J_AMC},
  author       = {Siu Wun Cheung and Youngsoo Choi and Seung Whan Chung and Jean-Luc Fattebert and Coleman Kendrick and Daniel Osei-Kuffuor},
  doi          = {10.1016/j.amc.2025.129722},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129722},
  shortjournal = {Appl. Math. Comput.},
  title        = {Theory and numerics of subspace approximation of eigenvalue problems},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Numerical approximation for a stochastic time-fractional cable equation. <em>AMC</em>, <em>511</em>, 129709. (<a href='https://doi.org/10.1016/j.amc.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient numerical method is proposed to address a stochastic time-fractional cable equation driven by fractionally integrated additive noise. Under the reasonable assumptions, we rigorously establish for the first time, the existence, uniqueness, and regularity of the mild solution for this equation. For spatial discretization, a semi-discrete scheme is constructed employing the Galerkin FEM, and the optimal spatial error estimate is derived based on the semigroup approach. In temporal discretization, a piecewise constant function is introduced to approximate the noise, leading to the formulation of a regularized stochastic time-fractional cable equation. A detailed proof of the temporal error estimates is provided via the semigroup approach. Numerical experiments demonstrate that the temporal convergence order attains O ( τ 1 / 2 ) for initial data of either smooth or non-smooth type. The order is independent of the parameters α 1 ∈ ( 0 , 1 ) , α 2 ∈ ( 0 , 1 ) , and β ∈ ( 0 , 1 ) in the equation. These results perfectly align with the theoretical predictions.},
  archive      = {J_AMC},
  author       = {Qimin Li and Yubin Yan and Leijie Qiao and Yu Zhang},
  doi          = {10.1016/j.amc.2025.129709},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129709},
  shortjournal = {Appl. Math. Comput.},
  title        = {Numerical approximation for a stochastic time-fractional cable equation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="artmed">ARTMED - 9</h2>
<ul>
<li><details>
<summary>
(2025). The interpretable deep learning framework and validation for seizure detection in pediatric electroencephalography: An improved accuracy and performance analysis. <em>ARTMED</em>, <em>170</em>, 103276. (<a href='https://doi.org/10.1016/j.artmed.2025.103276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an interpretable deep learning framework and compares the two novel models. A fully convolutional network with squeeze-and-excitation modules (SE-FCN) is designed to enhance spatial sensitivity and retain temporal resolution. In addition, a transformer-based model (TransNet) is developed to capture temporal and channel-wise dependencies via self-attention. These two models output channel saliency weights to the EEG electrode space and generate heatmaps for inferring potential epileptogenic zones. Deep learning primarily adopts convolutional neural networks (CNNs) or sequence generation networks (SGNs) and faces the limitations. For instance, CNN-based models often lack hierarchical modeling and fail to quantify channel-wise contributions, hindering spatial localization. SGN-based models struggle to capture complex spatiotemporal dependencies and typically lack adaptive attention tailored to electroencephalography (EEG) characters. Epileptic seizure detection is vital for effective clinical intervention and existing methods operated as black boxes, limiting clinical interpretability. This study evaluates the models on the CHB-MIT pediatric EEG dataset using a subject-independent cross-validation protocol. SE-FCN achieves an AUC of 0.89 and accuracy of 86.7 %, while TransNet achieves an AUC of 0.92 and accuracy of 86.4 %. Saliency maps from both models demonstrate high consistency and enable categorization of 22 patients into five groups based on inferred seizure origins.},
  archive      = {J_ARTMED},
  author       = {Yu Zhou and Yuxin Gao and Qiang Li and Ruiheng Wu and Aiping Yang and Ming-Lang Tseng},
  doi          = {10.1016/j.artmed.2025.103276},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103276},
  shortjournal = {Artif. Intell. Med.},
  title        = {The interpretable deep learning framework and validation for seizure detection in pediatric electroencephalography: An improved accuracy and performance analysis},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding the cortical responses to mechanical wrist perturbations: A two-step shared structure NARX method. <em>ARTMED</em>, <em>170</em>, 103273. (<a href='https://doi.org/10.1016/j.artmed.2025.103273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared structure nonlinear autoregressive with exogenous input (NARX) model is a promising tool for exploring cortical responses mechanism to external stimuli, essential for advancing our understanding of brain function and developing methods for direct brain information encoding. In this paper, we proposed a two-step method to overcome limitations in existing method, which neglect data relationships and rely on a greedy search for regression terms, leading to less accurate models. In our approach, data from multiple trials are concatenated, and then the orthogonal forward regression (OFR) algorithm identifies model terms in first step, enhancing inter-trial connections and establishing a preliminary model for each subject. Shared model terms across subjects are then used to construct a general target model. Next, non-shared regression terms that best represent population-level information are identified, using adaptive multi-population genetic algorithms, and use to enhance the target models' descriptive power. Simulations results show significant competitiveness in terms of accuracy as compared to other state-of-the-art methods. When applied to real electroencephalography signals under mechanical disturbance, structural and parameter analysis revealed consistent neural response patterns across subjects, with subject-specific responses likely stemming from muscle feedback. Frequency response analysis further suggests that the brain may generate motor inhibition signals based on sensory inputs to maintain a pre-disturbance resting state. These findings provide valuable insights into cortical response mechanisms and have potential implications for future brain information encoding research.},
  archive      = {J_ARTMED},
  author       = {Nan Zheng and Yurong Li and Wuxiang Shi and Jiyu Tan},
  doi          = {10.1016/j.artmed.2025.103273},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103273},
  shortjournal = {Artif. Intell. Med.},
  title        = {Decoding the cortical responses to mechanical wrist perturbations: A two-step shared structure NARX method},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven dynamic grouping for adaptive clinical trials: Rethinking randomization in precision medicine. <em>ARTMED</em>, <em>170</em>, 103272. (<a href='https://doi.org/10.1016/j.artmed.2025.103272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating artificial intelligence into biomedical human subjects research is transforming traditional experimental paradigms. This perspective introduces the concept of “dynamic grouping,” wherein artificial intelligence (AI) systems continuously reassign participants across experimental conditions based on real-time biomarker data and clinical response patterns. Unlike traditional biomedical research designs that rely on fixed treatment and control groups, dynamic grouping allows participant assignments to evolve throughout the study. We examine the ethical implications, methodological challenges, and research opportunities associated with this paradigm, particularly in clinical trials, precision medicine, and digital therapeutics. To support this analysis, we present three computational simulations that quantify its impact: (i) a heterogeneity simulation demonstrating how patient variability affects the advantage of dynamic grouping, (ii) a statistical power analysis showing potential sample size reductions in adaptive designs, and (iii) a clinical outcome distribution analysis highlighting how dynamic grouping reduces negative treatment outcomes and optimizes patient responses. Our findings suggest that dynamic grouping can improve treatment effectiveness, enhance resource allocation, and increase statistical efficiency, although it also raises new challenges for causal inference, informed consent, and regulatory oversight. As AI continues to reshape medical research, adapting ethical and methodological frameworks will be essential for its responsible implementation.},
  archive      = {J_ARTMED},
  author       = {Madhur Mangalam},
  doi          = {10.1016/j.artmed.2025.103272},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103272},
  shortjournal = {Artif. Intell. Med.},
  title        = {AI-driven dynamic grouping for adaptive clinical trials: Rethinking randomization in precision medicine},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining multi-electrode and multi-wave electroencephalogram based time-interval temporal patterns for improved classification capabilities and explainability. <em>ARTMED</em>, <em>170</em>, 103269. (<a href='https://doi.org/10.1016/j.artmed.2025.103269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interface (BCI) systems, and particularly electroencephalogram (EEG) based BCI systems, have become more widely used in recent years and are utilized in various applications and domains ranging from medicine and marketing to games and entertainment. While different algorithms have been used to analyze EEG data and enable its classification, existing algorithms have two main drawbacks; both their classification and explainability capabilities are limited. Lacking in explainability, they cannot indicate which electrodes and waves led to a classification decision or explain how areas and frequencies of the brain's activity correlate to a specific task. In this study, we propose a novel extension for the time-interval temporal patterns mining algorithms aimed at enhancing the data mining process by enabling a richer set of patterns to be learned from the EEG data, thereby contributing to improved classification and explainability capabilities. The extended algorithm is designed to capture and leverage the unique nature of EEG data by decomposing it into different brain waves and modeling the relations among them and between different electrodes. Our evaluation of the proposed extended algorithm on multiple learning tasks and three EEG datasets demonstrated the extended algorithm's ability to mine richer patterns that improve the classification performance by 4–11 % based on the Area-Under the receiver operating characteristic Curve (AUC) metric, compared to the original version of the algorithm. Moreover, the algorithm was shown to shed light on the areas and frequencies of the brain's activity that are correlated with specific tasks.},
  archive      = {J_ARTMED},
  author       = {Ofir Landau and Nir Nissim},
  doi          = {10.1016/j.artmed.2025.103269},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103269},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mining multi-electrode and multi-wave electroencephalogram based time-interval temporal patterns for improved classification capabilities and explainability},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical multimodal foundation models in clinical diagnosis and treatment: Applications, challenges, and future directions. <em>ARTMED</em>, <em>170</em>, 103265. (<a href='https://doi.org/10.1016/j.artmed.2025.103265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning have significantly revolutionized the field of clinical diagnosis and treatment, offering novel approaches to improve diagnostic precision and treatment efficacy across diverse clinical domains, thus driving the pursuit of precision medicine. The growing availability of multi-organ and multimodal datasets has accelerated the development of large-scale Medical Multimodal Foundation Models (MMFMs). These models, known for their strong generalization capabilities and rich representational power, are increasingly being adapted to address a wide range of clinical tasks, from early diagnosis to personalized treatment strategies. This review offers a comprehensive analysis of recent developments in MMFMs, focusing on three key aspects: datasets, model architectures, and clinical applications. We also explore the challenges and opportunities in optimizing multimodal representations and discuss how these advancements are shaping the future of healthcare by enabling improved patient outcomes and more efficient clinical workflows.},
  archive      = {J_ARTMED},
  author       = {Kai Sun and Siyan Xue and Fuchun Sun and Haoran Sun and Yu Luo and Ling Wang and Siyuan Wang and Na Guo and Lei Liu and Tian Zhao and Xinzhou Wang and Lei Yang and Shuo Jin and Jun Yan and Jiahong Dong},
  doi          = {10.1016/j.artmed.2025.103265},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103265},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical multimodal foundation models in clinical diagnosis and treatment: Applications, challenges, and future directions},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end solution for out-of-hospital emergency medical dispatch triage based on multimodal and continual deep learning. <em>ARTMED</em>, <em>170</em>, 103264. (<a href='https://doi.org/10.1016/j.artmed.2025.103264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study was to build a multimodal, multitask predictive model—named E2eDeepEMC 2 —to improve out-of-hospital emergency incident severity assessments while coping with shifts in data distributions over time. We drew on 2 054 694 independent incidents recorded by the Valencian emergency medical dispatch service between 2009 and 2019 (excluding 2013), combining demographic, temporal, clinical and free-text inputs. To handle temporal drift, our model integrates continual learning strategies and comprises three encoder modules (for context, clinical data and text), whose outputs are merged to predict the life-threatening level, admissible response delay and emergency system jurisdiction. Compared with the Valencian Region’s existing in-house triage protocol, E2eDeepEMC 2 achieved absolute F1-score gains of 18.46% for life-threatening level, 25.96% for response delay and 3.63% for jurisdiction. Compared to non-continual learning baselines, it also outperformed them by 3.04%, 9.66% and 0.58%, respectively. Deployment of E2eDeepEMC 2 is currently underway in the Valencian Region, underscoring its practical impact on real-world emergency dispatch decision-making.},
  archive      = {J_ARTMED},
  author       = {Pablo Ferri and Carlos Sáez and Antonio Félix-De Castro and Purificación Sánchez-Cuesta and Juan M. García-Gómez},
  doi          = {10.1016/j.artmed.2025.103264},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103264},
  shortjournal = {Artif. Intell. Med.},
  title        = {An end-to-end solution for out-of-hospital emergency medical dispatch triage based on multimodal and continual deep learning},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRA-PT: Low-rank adapting UNETR for hippocampus segmentation using principal tensor singular values and vectors. <em>ARTMED</em>, <em>170</em>, 103254. (<a href='https://doi.org/10.1016/j.artmed.2025.103254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hippocampus is an important brain structure involved in various psychiatric disorders, and its automatic and accurate segmentation is vital for studying these diseases. Recently, deep learning-based methods have made significant progress in hippocampus segmentation. However, training deep neural network models requires substantial computational resources, time, and a large amount of labeled training data, which is frequently scarce in medical image segmentation. To address these issues, we propose LoRA-PT, a novel parameter-efficient fine-tuning (PEFT) method that transfers the pre-trained UNETR model from the BraTS2021 dataset to the hippocampus segmentation task. Specifically, LoRA-PT divides the parameter matrix of the transformer structure into three distinct sizes, yielding three third-order tensors. These tensors are decomposed using tensor singular value decomposition to generate low-rank tensors consisting of the principal singular values and vectors, with the remaining singular values and vectors forming the residual tensor. During fine-tuning, only the low-rank tensors (i.e., the principal tensor singular values and vectors) are updated, while the residual tensors remain unchanged. We validated the proposed method on three public hippocampus datasets, and the experimental results show that LoRA-PT outperformed state-of-the-art PEFT methods in segmentation accuracy while significantly reducing the number of parameter updates. Our source code is available at https://github.com/WangangCheng/LoRA-PT/tree/LoRA-PT .},
  archive      = {J_ARTMED},
  author       = {Guanghua He and Wangang Cheng and Hancan Zhu and Gaohang Yu},
  doi          = {10.1016/j.artmed.2025.103254},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103254},
  shortjournal = {Artif. Intell. Med.},
  title        = {LoRA-PT: Low-rank adapting UNETR for hippocampus segmentation using principal tensor singular values and vectors},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMSupcon: An image fusion-based multi-modal supervised contrastive method for brain tumor diagnosis. <em>ARTMED</em>, <em>170</em>, 103253. (<a href='https://doi.org/10.1016/j.artmed.2025.103253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of brain tumors is pivotal for effective treatment, with MRI serving as a commonly used non-invasive diagnostic modality in clinical practices. Fundamentally, brain tumor diagnosis is a type of pattern recognition task that requires the integration of information from multi-modal MRI images. However, existing fusion strategies are hindered by the scarcity of multi-modal imaging samples. In this paper, we propose a new training paradigm tailored for the scenario of multi-modal imaging in brain tumor diagnosis, called multi-modal supervised contrastive learning method (MMSupcon). This method significantly enhances diagnostic accuracy through two key components: multi-modal medical image fusion and multi-modal supervised contrastive loss. First, the fusion component integrates complementary imaging modalities to generate information-rich samples. Second, by introducing fused samples to guide original samples in learning feature consistency or inconsistency among classes, our loss component effectively preserves the integrity of cross-modal information while maintaining the distinctiveness of individual modalities. Finally, MMSupcon is validated on a real-world brain tumor dataset collected from Beijing Tiantan Hospital, achieving state-of-the-art performance. Furthermore, additional experiments on two public BraTS glioma classification datasets also demonstrate our substantial performance improvements. The source code is released at https://github.com/hywang02/MMSupcon .},
  archive      = {J_ARTMED},
  author       = {Haoyu Wang and Jing Zhang and Siying Wu and Haoran Wei and Xun Chen and Yunwei Ou and Xiaoyan Sun},
  doi          = {10.1016/j.artmed.2025.103253},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103253},
  shortjournal = {Artif. Intell. Med.},
  title        = {MMSupcon: An image fusion-based multi-modal supervised contrastive method for brain tumor diagnosis},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathway information on methylation analysis using deep neural network (PROMINENT): An interpretable deep learning method with pathway prior for phenotype prediction using gene-level DNA methylation. <em>ARTMED</em>, <em>170</em>, 103236. (<a href='https://doi.org/10.1016/j.artmed.2025.103236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background DNA methylation is a key epigenetic marker that influences gene expression and phenotype regulation, and is affected by both genetic and environmental factors. Traditional linear regression methods such as elastic nets have been employed to assess the cumulative effects of multiple DNA methylation markers on phenotypes. However, these methods often fail to capture the complex nonlinear nature of the data. Recent deep learning approaches, such as MethylNet, have improved the prediction accuracy but lack interpretability and efficiency. Findings To address these limitations, we introduced P athway Info r mati o n on M ethylat i on Analysis using a Deep Ne ural N e t work (PROMINENT), a novel interpretable deep learning method that integrates gene-level DNA methylation data with biological pathway information for phenotype prediction. PROMINENT enhances interpretability and prediction accuracy by incorporating gene- and pathway-level priors from databases such as Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG). It employs SHapley Additive exPlanations (SHAP) to prioritize significant genes and pathways. Evaluated across various datasets, childhood asthma, idiopathic pulmonary fibrosis (IPF), and first-episode psychosis (FEP)—PROMINENT consistently outperformed existing methods in terms of prediction accuracy and computational efficiency. PROMINENT also identified crucial genes and pathways involved in disease mechanisms. Conclusions PROMINENT represents a significant advancement in leveraging DNA methylation data for phenotype prediction, offering both high accuracy and interpretability within reasonable computational time. This method holds promise for elucidating the epigenetic underpinnings of complex diseases and enhancing the utility of DNA methylation data in biomedical research.},
  archive      = {J_ARTMED},
  author       = {Soyeon Kim and Laizhi Zhang and Yidi Qin and Rebecca I. Caldino Bohn and Hyun Jung Park},
  doi          = {10.1016/j.artmed.2025.103236},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103236},
  shortjournal = {Artif. Intell. Med.},
  title        = {Pathway information on methylation analysis using deep neural network (PROMINENT): An interpretable deep learning method with pathway prior for phenotype prediction using gene-level DNA methylation},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="asoc">ASOC - 32</h2>
<ul>
<li><details>
<summary>
(2025). Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets. <em>ASOC</em>, <em>185</em>, 113969. (<a href='https://doi.org/10.1016/j.asoc.2025.113969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors segmentation in Magnetic Resonance Imaging (MRI) images poses significant challenges owing to the uncertain location and size of the tumors, the difficulty in describing their boundaries, and the fuzzy demarcation of diseased tissues. Although U-Net and its recent variants have emerged as leading models for semantic segmentation in medical imaging, they still face structural limitations. These limitations cause the erosion of detail information during downsampling and poor performance in segmenting small lesions when handling targets of varying sizes, indicating a lack of detail handling capability. To counteract these issues, we designed a segmentation model that enhances detail features using frequency information. To reduce the loss of feature information during downsampling, we developed a downsampling module based on lifting wavelets. By lifting wavelets to group and integrate features according to frequency from high to low, we reduce feature resolution while enhancing information transmission and minimizing feature information loss. In our designed multi-frequency directional filtering edge feature extraction module, we extract low-frequency and high-frequency features and construct a dual-channel multi-directional filtering combination. This combination extracts directional information from low-frequency and high-frequency features separately, increasing the multi-angle directional information of the features and enriching the detailed information such as direction and position within the features. On the BraTS2018, BraTS2020, and BraTS2024 brain tumor datasets, our model demonstrated optimal results compared to 14 other advanced models. The average Dice Similarity Coefficients are 78.48 %, 79.80 %, and 74.35 %, while the 95th percentile Hausdorff Distances are 5.75, 6.60, and 7.72. Our code link is https://github.com/Eric-H8/BraTS_Seg_Model .},
  archive      = {J_ASOC},
  author       = {Xin Hua and Zhijiang Du and Hongjian Yu and Zibo Li and Qiaohui Lu and Hui Zhao},
  doi          = {10.1016/j.asoc.2025.113969},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework. <em>ASOC</em>, <em>185</em>, 113942. (<a href='https://doi.org/10.1016/j.asoc.2025.113942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal additive manufacturing (AM) has revolutionized industries such as aerospace and automotive manufacturing due to its ability to rapidly prototype complex structures. Laser Directed Energy Deposition (L-DED) is a key AM technique, offering high deposition rates and superior mechanical properties. However, the inherent complexity and high cost of L-DED equipment demand reliable maintenance management to minimize downtime. Traditional maintenance approaches struggle to keep pace with escalating production demands and to cope with growing equipment complexity. To address this, we propose a dual-driven intelligent maintenance system for L-DED, integrating Digital Twins (DT) and Large Language Models (LLMs). The system features a comprehensive DT framework that synchronizes the virtual entity with the physical one in real time, it also incorporates an intelligent maintenance Q&A assistant powered by Retrieval-Augmented Generation (RAG), leveraging L-DED maintenance knowledge bases to provide accurate operational support. Additionally, we propose a Directed Acyclic Graphs (DAG)-based framework to assess LLMs’ ability to guide users through complete fault diagnosis. Our work aims to enhance the reliability and efficiency of L-DED maintenance through advanced digital technologies, ultimately improving productivity and reducing downtime in additive manufacturing.},
  archive      = {J_ASOC},
  author       = {Jian Tang and Shitong Peng and Jianan Guo and Danya Song and Dongna Gao and Weiwei Liu and Fengtao Wang},
  doi          = {10.1016/j.asoc.2025.113942},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113942},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model. <em>ASOC</em>, <em>185</em>, 113941. (<a href='https://doi.org/10.1016/j.asoc.2025.113941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large model technology exemplified by large language models has been applied in the field of industrial fault diagnosis. However, existing large models are optimized for specific equipment types and have yet to fully exploit the potential of time-series monitoring data to enable widespread application across diverse mechanical equipment in various industrial scenarios. To address this challenge, a fault diagnosis large model (UniTS-FD) is designed based on unified time series model (UniTS). First, a multi-scale feature fusion backbone network is developed based on UniTS backbone to capture general mechanical fault features. Second, the fault classification head integrates the Pearson correlation coefficient to assess the similarity of class information within linear space for enabling adaptive classification. Third, P-LoRA fine-tuning approach incorporating LoRA and prompt technology is proposed to fine-tune the fault classification head, which enhances the generalization ability of the UniTS-FD model for fault diagnosis tasks of various mechanical equipment. Finally, the UniTS-FD model is pre-trained on 11 fault datasets and fine-tuning experiments were conducted on four different fault datasets to achieve cross-machine fault diagnosis. Experimental results demonstrate the effectiveness of the UniTS-FD in fault diagnosis tasks.},
  archive      = {J_ASOC},
  author       = {Zhiwei Zhang and Chengbin Wei and Weimin Zhang and Long Wen},
  doi          = {10.1016/j.asoc.2025.113941},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113941},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling. <em>ASOC</em>, <em>185</em>, 113920. (<a href='https://doi.org/10.1016/j.asoc.2025.113920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agentic workflows, powered by Industrial Large Models (ILMs), represent a significant development emphasizing collaboration between humans and intelligent systems. This paper presents a structured perspective on the role of agentic workflows for smart design and manufacturing, grounded in integrating ILMs. We define an agentic workflow as a labeled Activity-on-Vertex (AOV) graph, where each node represents a functionally closed subtask and is executed by an ILM-based agent, a human operator, or an automated system. This formalism supports analyzable, modular, and hybrid execution, offering a foundation for modeling complex, mixed-initiative processes in manufacturing environments. To support real-world deployment, we introduce a set of reusable agentic workflow patterns that describe how ILM agents perceive, plan, and act in coordination with other components. Besides, a proof-of-concept case study illustrates the practical application of the human-in-the-loop framework through the agentic generation of CAD models. The study covers task decomposition, workflow implementation, and benchmarking, providing evidence for the feasibility of agentic workflows. Building upon these findings, this work contributes to advancing the development and application of agentic workflows in smart manufacturing contexts.},
  archive      = {J_ASOC},
  author       = {Keyou Zheng and Yuanwei Zhong and Xuyang Su and Jiewu Leng and Qiang Liu and Xin Chen},
  doi          = {10.1016/j.asoc.2025.113920},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility. <em>ASOC</em>, <em>185</em>, 113917. (<a href='https://doi.org/10.1016/j.asoc.2025.113917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of metropolitan populations causes transportation network congestion, which increases fuel usage, travel time, and environmental damage. Traditional traffic management systems (TMS) seldom handle these issues in real time. Recently developed Large Language Models (LLMs), especially those using Reinforcement Learning (RL), may enhance urban transportation systems. Traffic management technology's real-time flexibility and shifting congestion patterns provide improved potential. Traditional approaches cannot estimate traffic flow or adapt to urban settings. A strong AI-driven method is needed to improve urban mobility and traffic flow. This paper introduces the LLM-RL Traffic Optimization Framework (LLM-RL-TOF). LLMs analyze real-time traffic data and give predictive insights in this context. Due to these new insights, the RL algorithm can improve traffic flow in real time and reduce congestion via dynamic traffic management. IoT sensors and urban traffic cameras capture real-time traffic data, including traffic volume and incidents. This data helps the LLM estimate bottlenecks, accidents, and traffic congestion. An RL agent uses LLM outputs to adjust traffic signal timing and suggest alternate routes. With real-time alternatives, traffic flow and urban mobility may be optimized. The junction throughput rate rose 17.5 %, the queue length accumulation index fell 22.3 %, and the average vehicle delay fell 18.6 %. The decrease in average vehicle delay enabled all these gains.},
  archive      = {J_ASOC},
  author       = {Arvind R. Singh and Muhammad Wasim Abbas Ashraf and Rajkumar Singh Rathore and Bin Li and M.S. Sujatha},
  doi          = {10.1016/j.asoc.2025.113917},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113917},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind turbine blades defect detection based on global and local attention with multi-feature fusion. <em>ASOC</em>, <em>185</em>, 113914. (<a href='https://doi.org/10.1016/j.asoc.2025.113914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbine blades are prone to small-scale defects—such as cracks, corrosion, and contamination—during long-term operation. Accurate detection of these defects is essential for ensuring the safety and efficiency of wind power systems. However, small-object detection remains challenging due to limited feature representation and weak discriminative cues. To address this, an enhanced YOLOX-s-based framework called Global-Frequency Dual-aware YOLOX (GFD-YOLOX) is proposed. GFD-YOLOX introduces three main improvements. First, the Path Aggregation Feature Pyramid Network (PAFPN) in the neck is replaced with Dual-Frequency Fused Bidirectional Feature Pyramid Network (DFF-BiFPN) to strengthen multi-scale contextual representation. Second, the backbone bottleneck is redesigned with a lightweight structure, improving computational efficiency and convergence speed. Third, a Hierarchical Frequency-Adaptive Fusion (HFAF) module is integrated to enhance cross-scale feature interaction by combining fine-grained and global information. On the self-constructed WTBlade-Defect dataset (3570 annotated images, five defect types: corrosion, hide-craze, surface-eye, thunderstrike, dirt), GFD-YOLOX achieves mAP@0.5 and mAP@0.5:0.95 scores of 94.5 % and 68.9 %, respectively, with 44.3 FPS inference—improving by 13.6 % and 14.4 % over state-of-the-art models. On the public dataset of Ashley Foster et al., it achieves 94.8 % and 69.3 %, with gains of 10.4 % and 10.9 %. These results demonstrate that GFD-YOLOX delivers substantial accuracy gains while maintaining real-time speed and strong cross-dataset generalization, indicating high potential for deployment in operational wind turbine inspection systems.},
  archive      = {J_ASOC},
  author       = {Dandan Liu and Mingjie Liu},
  doi          = {10.1016/j.asoc.2025.113914},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113914},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind turbine blades defect detection based on global and local attention with multi-feature fusion},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction. <em>ASOC</em>, <em>185</em>, 113910. (<a href='https://doi.org/10.1016/j.asoc.2025.113910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable wind speed prediction is critical for stabilizing wind power integration. However, current methods are limited by accuracy and stability issues, hindering their large-scale application in wind farms. To overcome these problems, this study innovatively proposes an IMFSformer-CNN model integrating three core components. First, the spatio-temporal and multi-factor feature extraction technology comprehensively captures the spatio-temporal patterns and complex dependencies of wind speed dynamics, incorporating multiple factors such as meteorological variables and spatial correlation. Second, the multi-feature sparse attention mechanism reduces computational complexity by combining sparse attention with multi-feature attention, enhancing representation ability and scalability for precise interval value prediction. Finally, the enhanced interval spatio-temporal prediction fusion model combines the global dependency modeling capabilities of the improved Transformer architecture with the local receptive field advantages of CNN. This hybrid design facilitates the simultaneous capture of both macro-scale atmospheric patterns and micro-scale wind speed fluctuations. The model achieved prediction interval coverage probabilities of 0.921 and 0.899, and coverage width criteria of 1.493 and 3.776, outperforming other models on both datasets. This significantly enhances accuracy and practical value for wind farm cluster forecasting, supporting more reliable and efficient wind energy integration into power grids.},
  archive      = {J_ASOC},
  author       = {Weiyi Jiang and Jujie Wang and Xuecheng He},
  doi          = {10.1016/j.asoc.2025.113910},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction. <em>ASOC</em>, <em>185</em>, 113909. (<a href='https://doi.org/10.1016/j.asoc.2025.113909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction has significant application value in many fields. However, existing methods often fail to fully capture the spatial relationships between joints and the temporal flow of information when modeling complex spatiotemporal dependencies. Additionally, these methods are prone to overfitting dominant features while neglecting other important aspects, and struggle with perceiving contour features effectively. To address these issues, this study introduces a novel encoder-decoder framework. The encoder generates a dual-layer adaptive adjacency matrix using a distance partition strategy to parameterize joint relationships, while incorporating a gating mechanism to control the temporal flow of information. The decoder then employs separate spatiotemporal attention modules to decode temporal and spatial features independently. These features are subsequently reconstructed through a spatiotemporal fusion strategy, effectively decoupling and modeling complex spatiotemporal dependencies. To address the issue of overfitting to dominant features, we introduce a denoising reconstruction strategy that allows the model to learn richer combinations of spatiotemporal features under multiple constraints. Furthermore, a multi-granularity information adaptive fusion module is incorporated to achieve adaptive fusion of both local and contour features. Experimental results across several benchmark datasets demonstrate that our method significantly outperforms the state-of-the-art approaches, showcasing its effectiveness in human motion prediction tasks.},
  archive      = {J_ASOC},
  author       = {Yong Li and Linfeng Zhu and Haofei Xie and Xinchang Yi},
  doi          = {10.1016/j.asoc.2025.113909},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113909},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model. <em>ASOC</em>, <em>185</em>, 113897. (<a href='https://doi.org/10.1016/j.asoc.2025.113897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, extreme events caused by global climate change have intensified the phenomenon of saltwater intrusion (SWI) in estuaries. The nonlinear and non-stationary characteristics of estuarine SWI have led to an exponential decline in the timeliness of traditional regression prediction models, making it difficult to meet the operational needs of SWI forecasting. To address this, this study proposed a technical framework for SWI risk level forecasting based on temporal clustering, with its core innovation lying in algorithmic improvements for accurately characterizing complex disaster systems. The key challenges in forecasting SWI risk levels involved capturing the dynamic nonlinear relationships between multidimensional disaster factors (such as runoff, tide level, and wind) and SWI severity, as well as enhancing feature discriminability in label-limited scenarios. Accordingly, this study optimized algorithms through dual-path supervised and unsupervised learning: In the supervised learning framework, LightGBM, RF, XGBoost, and Extra trees were introduced as base learners into the Deep Forest (DF) model. The complementary feature-space partitioning of diverse learners was leveraged to improve the model’s ability to distinguish risk -level boundaries, achieving an average performance gain of 7.8 %. In the unsupervised learning framework, discriminative regularization was incorporated into the Extreme Learning Machine-Autoencoder (ELM-AE) model. By forcing features of samples from the same class to cluster toward the class center, the model’s feature separability for rare events (e.g., severe SWI) was enhanced, leading to an average performance improvement of 11 %. Finally, the optimal model was used to extract dynamic evolution patterns between multidimensional disaster factors and SWI risk levels, with interpretability analysis conducted for real-world forecasting. Notably, upstream flow sequences exhibited high distinguishability between no-SWI and severe-SWI, while mild and moderate SWI showed similar flow patterns, with tidal sequences being the primary differentiator. The algorithmic advancements not only enhanced the accuracy and efficiency of SWI forecasting but also provided a generalizable framework for risk classification in nonlinear hydrological systems.},
  archive      = {J_ASOC},
  author       = {Qingqing Tian and Hongyu Yang and Yu Tian and Peiyao Weng},
  doi          = {10.1016/j.asoc.2025.113897},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113897},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with mirror-task for multimodal sentiment analysis. <em>ASOC</em>, <em>185</em>, 113896. (<a href='https://doi.org/10.1016/j.asoc.2025.113896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning (MTL) in Multimodal Sentiment Analysis (MSA) involves implementing various parameter-sharing strategies among tasks. Currently, MSA primarily focuses on hard parameter-sharing mechanisms based on encoder sharing, while soft parameter-sharing is often neglected. To explore a reasonable combination of soft and hard mechanisms in MSA and optimize multimodal representations, along with multimodal contrastive learning, we propose D 3 MSA. It consists of D ouble network (primaryNet and MirrorNet), D ouble parameter-sharing strategies and D ouble contrastive learning modes for multimodal sentiment analysis. D 3 MSA utilizes hard-sharing to consolidate correlations between positive samples of intra-sample contrastive learning. In soft-sharing, we propose a pre-trained MirrorNet (MN) that generates negative samples by the learned inverse distributions. This optimizes the feature space of negative samples. MN interacts with the MSA task through soft-sharing during inter-sample contrastive learning. Experimental results demonstrate that our proposed method can achieve advanced performance on the CMU-MOSI and CMU-MOSEI datasets with lightweight training that requires only a small number of parameters.},
  archive      = {J_ASOC},
  author       = {Hang Shi and Lianmin Zhou and Yuanyuan Pu and Zhengpeng Zhao and Jinjing Gu and Dan Xu},
  doi          = {10.1016/j.asoc.2025.113896},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113896},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning with mirror-task for multimodal sentiment analysis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems. <em>ASOC</em>, <em>185</em>, 113895. (<a href='https://doi.org/10.1016/j.asoc.2025.113895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multimodal multiobjective problems (CMMOPs) have multiple equivalent constrained Pareto optimal sets in the decision space corresponding to the identical constrained Pareto front in the objective space. The key to solving CMMOPs is how to balance feasibility, convergence, and diversity of solutions in both the decision and objective spaces. In view of this, this paper proposes a Nearest-Best neighbors optimization algorithm with constraint-based fitness (NBNOA) to solve CMMOPs. First, a constraint-based fitness assignment scheme is designed to assign specific fitness values to individuals in the population. Then, the Nearest-better-neighbor clustering method is adopted to identify the nearest-better neighbor and best neighbor of each individual according to the specific fitness values. On this basis, a Nearest-Best neighbors guided strategy is developed to guide the search direction of individuals, striking a better balance between exploration and exploitation capabilities. Moreover, a CDP-density elite selection mechanism is constructed to obtain feasible Pareto optimal solutions with higher precision and better diversity. Extensive experiments on two CMMOPs test suites demonstrated that the proposed NBNOA significantly outperforms nine state-of-the-art algorithms. Notably, NBNOA ranks first among all ten algorithms and achieves the best values for 23 out of 31 benchmark functions regarding the reciprocal of Pareto sets proximity and inverted generational distance. Furthermore, NBNOA is applied to a real-world CMMOP, verifying its effective practical application capability. Additionally, NBNOA is tested on two high-dimensional constrained multiobjective optimization problems test suites, further proving its competitive performance in solving complex problems.},
  archive      = {J_ASOC},
  author       = {Xuming Han and Ting Zhou and Limin Wang and Yali Chu},
  doi          = {10.1016/j.asoc.2025.113895},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113895},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency decomposition and patch modeling framework for time-series forecasting. <em>ASOC</em>, <em>185</em>, 113890. (<a href='https://doi.org/10.1016/j.asoc.2025.113890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is widely applied across diverse fields, including finance, transportation, and energy, and has made significant contributions in these areas. However, in real-world applications, time series data can be complex and dynamic. Current methodologies still encounter several challenges in managing high-dimensional data, extracting intricate features, and making long-term forecasts. In this study, we propose a Frequency Decomposition and Patch Modeling Framework (FPF). Our FPF consists of the Frequency Domain Decomposition Block (FDB) and the Dual Patch Modeling Block (DPMB). DPMB consists of Patch Enhancement Block and Patch Mixing Block. First, FDB transforms the input sequence to the frequency domain through the Fast Fourier Transform and designs frequency masks to decompose the data into high-frequency and low-frequency components, to extract fast-changing patterns and trend information respectively. Subsequently, DPMB divides the components into patches, where the high-frequency components are modeled by MLP-based Patch Enhancement Block to capture local features, and the low-frequency components are modeled by Transformer-based Patch Mixing Block to capture global dependencies and cross-patch correlations. We conducted comprehensive experiments using seven real-world time series forecasting datasets, including ETT, Traffic, Electricity, and Weather. The findings indicate that this method demonstrates superior performance in the field of time series forecasting.},
  archive      = {J_ASOC},
  author       = {Denghui Xu and Hua Wang and Fan Zhang},
  doi          = {10.1016/j.asoc.2025.113890},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113890},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Frequency decomposition and patch modeling framework for time-series forecasting},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering algorithm based on boundary elimination and backbone construction. <em>ASOC</em>, <em>185</em>, 113880. (<a href='https://doi.org/10.1016/j.asoc.2025.113880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) is an effective clustering algorithm, but it still has some problems and faces some challenges. For instance, it cannot identify the variable density datasets, the assignment strategy is easy to produce domino phenomenon, and the clustering results of DPC and its improved algorithms are easily affected by the intersection points between clusters. To solve these problems, in this paper, we propose a novel density peak clustering algorithm based on boundary elimination and backbone construction, called BEBC-DPC. A new local density is defined based on the natural neighbor search, and the boundary degree is defined by the position relationship between each point and its neighbors, which accurately describes the local distribution information of the point. The boundary points of clusters are eliminated by fusing the density and the boundary degree, which reduces the influence of the intersection points on the cluster division. In addition, the cluster backbone construction method based on representative points and representative sets is proposed. The density relationship among non-boundary points is used to form representative sets, and the similarity between representative sets is used to construct the cluster backbones, which can effectively describe the overall distribution structure characteristics of the clusters. Moreover, the adjacency degree of each boundary point is defined by using the neighbor information and distance information, and the boundary points are gradually assigned to the most appropriate cluster backbone based on it to complete the clustering. Finally, sufficient experiments are performed on synthetic, UCI and image datasets, and the proposed BEBC-DPC is compared with DPC and its improved algorithms. Experimental results show the effectiveness of the proposed BEBC-DPC on various types of datasets.},
  archive      = {J_ASOC},
  author       = {Zhizhong Zhao and Sugen Chen and Cong Hu},
  doi          = {10.1016/j.asoc.2025.113880},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Density peak clustering algorithm based on boundary elimination and backbone construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable type 2 fuzzy Min–Max neural networks for pattern classification. <em>ASOC</em>, <em>185</em>, 113875. (<a href='https://doi.org/10.1016/j.asoc.2025.113875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fuzzy Min–Max (FMM) algorithm is a powerful classification method capable of handling non-linear class boundaries and making both hard and soft decisions while learning from online data. However, it faces significant challenges, including sensitivity to the expansion coefficient, information loss during the contraction stage, and the overlap problem. To address these limitations, we propose a Reliable Type-2 Fuzzy Min–Max (RT2FMM) algorithm, which incorporates type-2 fuzzy logic to consider hyperbox uncertainty and effectively resolve the overlap problem. By assigning distinct certainties to overlapping regions, RT2FMM eliminates the need for the contraction stage and the overlap test. Additionally, we introduce weighted factors for hyperboxes, which enhances the reliability of membership values and models their mutual effects. Our comprehensive experimental evaluation across twenty datasets demonstrates that RT2FMM significantly outperforms existing FMM-based models in terms of robustness and accuracy. The Friedman test further confirms the superior performance of RT2FMM compared to commonly used classifiers, highlighting its potential as a robust solution for complex classification tasks.},
  archive      = {J_ASOC},
  author       = {Ali Nik-Khorasani and Mohammad-R. Akbarzadeh-T.},
  doi          = {10.1016/j.asoc.2025.113875},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113875},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reliable type 2 fuzzy Min–Max neural networks for pattern classification},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fortifying vision models: A comprehensive survey of defences against adversarial examples. <em>ASOC</em>, <em>185</em>, 113874. (<a href='https://doi.org/10.1016/j.asoc.2025.113874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and Machine learning (ML) have seen many advancements in the past two decades. It has led to the creation of several techniques, including Deep Neural Networks (DNN), Convolution Neural Networks (CNN), Autoencoders, Generative Adversarial Networks (GAN) and Diffusion models. These techniques have been applied to various real-world applications, such as self-driving cars, medical diagnosis and voice assistants. Despite these advancements, a carefully crafted input can fool the ML model. Such attacks are known as adversarial examples. It is a serious threat to safety critical systems. This survey provides a comprehensive review of defences against adversarial examples by tracing their evolution from early empirical methods to more principled, theoretically grounded approaches. We systematically categorise defences based on their underlying mechanisms. In addition to surveying state-of-the-art techniques, we spotlight emerging trends such as generative defences and diffusion-based purification. Finally, we identify persistent vulnerabilities and outline promising directions for future research towards building truly resilient vision models. This work aims to equip researchers and practitioners with a deep understanding of current defences and inspire innovation in adversarial robustness for the next generation of vision applications.},
  archive      = {J_ASOC},
  author       = {Siddheshwar Kumar and Shashank Srivastava and Shashwati Banerjea},
  doi          = {10.1016/j.asoc.2025.113874},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113874},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fortifying vision models: A comprehensive survey of defences against adversarial examples},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform. <em>ASOC</em>, <em>185</em>, 113873. (<a href='https://doi.org/10.1016/j.asoc.2025.113873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative image detection faces persistent challenges in terms of generalization and interpretability, limiting its reliability in complex scenarios. To address these issues, we propose AOT-PixelNet, a lightweight and interpretable detection framework that integrates an Adaptive Orthogonal Transform (AOT) module with a streamlined 1 × 1 convolution-based PixelNet architecture. The AOT module leverages diverse orthogonal transforms, such as FFT and DCT, to extract informative frequency-domain features, thereby enhancing sensitivity to medium- and high-frequency artifacts. Meanwhile, PixelNet minimizes parameter count (only 0.98 million) while effectively capturing cross-channel inconsistencies and mitigating overfitting. Experimental evaluations on multiple unseen GAN and diffusion-based datasets demonstrate that AOT-PixelNet achieves superior performance with minimal computational cost. Specifically, it outperforms the NPR method by 0.6% and 11.76% on the ForenSynths and GenImage datasets, respectively, validating the framework’s robustness, effectiveness, and interpretability.},
  archive      = {J_ASOC},
  author       = {Dengtai Tan and Deyi Yang and Boao Tan and Chengyu Niu and Yang Yang and Shichao Li},
  doi          = {10.1016/j.asoc.2025.113873},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113873},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud. <em>ASOC</em>, <em>185</em>, 113872. (<a href='https://doi.org/10.1016/j.asoc.2025.113872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud facilitates the user to complete their work utilizing the cost strategy of pay-as-you-go, which is based on the consumed Virtual Machine (VM) hours. Thus, the scheduler must offer the highest throughput to attain efficient allocation of resources in the cloud paradigm. Cloud services are dependent on characteristics such as fault tolerance, security, scalability, and availability. Hence, an effective scheduler is necessary to arrange the scheduling tasks and adjust the server loads. Typically, a load-balancing task focuses on detecting the overloaded and under-loaded nodes and adjusting the load between them. When considering the significant role of fault-tolerance in load-balancing algorithms, it seems to suffer from poor organization and a lack of in-depth experiments in this sector. This paper proposes a new task for the load-balancing operation. Initially, task scheduling is performed where the fault tolerance and the priority-aided scheduling approach are adopted. Furthermore, resource optimization is carried out in the scheduling task using Randomly Improved Electric Fish Optimization (RIEFO). To validate the load balancing operation, several multi-objective functions such as resource utilization, delay, time, makespan, active servers, throughput, success rate, fault tolerance rate, and energy consumption are derived. Moreover, because of the system’s dynamic environment, the status of the server varies simultaneously. The server status prediction is significant in allocating the tasks to the server or the VM resources. Thus, the Attention-based Cascaded Residual Bidirectional Long Short-Term Memory (ACRes-BiLSTM) is employed to predict the server status before performing the resource allocation. Finally, the tasks are scheduled effectively using the predicted server status. The performance is estimated using numerous performance metrics.},
  archive      = {J_ASOC},
  author       = {Gudivada Lokesh and Kasarapu Ramani and K.K. Baseer},
  doi          = {10.1016/j.asoc.2025.113872},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113872},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +. <em>ASOC</em>, <em>185</em>, 113871. (<a href='https://doi.org/10.1016/j.asoc.2025.113871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape leaf diseases, such as black rot, powdery mildew, and downy mildew, pose a significant threat to global viticulture, leading to substantial yield losses and reduced fruit quality. Early and accurate identification of these diseases is essential for precision agriculture and sustainable crop management. This study presents a comprehensive comparison of traditional and deep learning-based image segmentation methods for detecting grape leaf lesions. A series of classical segmentation techniques, including Mean Shift, Fuzzy C-Means (FCM), Normalized Cut, K-Means, and Fuzzy K-Means (FKM), were evaluated alongside an advanced DeepLabv3 + model. The baseline DeepLabv3 + architecture was further enhanced by integrating a ResNeSt-50 backbone with various attention mechanisms, including Squeeze-and-Excitation (SE) Block, Convolutional Block Attention Module (CBAM), Bottleneck Attention Module (BAM), Self-Attention, and Dual Attention Network (DANet). Among all models, DeepLabv3 + with ResNeSt-50 and CBAM achieved the highest performance, attaining 98.2 % accuracy, 97.1 % precision, 96.7 % recall, 96.6 % mean Intersection over Union (mIoU), and a 96.8 % Dice Score. The results demonstrate that attention-augmented deep networks significantly outperform classical methods, especially in handling complex lesion structures under diverse environmental conditions. While traditional algorithms remain useful in resource-constrained scenarios, deep learning models, particularly those enhanced with spatial and channel-wise attention, offer greater accuracy and robustness, making them ideal for integration into intelligent agricultural platforms such as drones, mobile scanners, and automated disease monitoring systems. Future work will focus on incorporating temporal and multimodal data, expanding dataset diversity, and optimizing lightweight models for real-time deployment on edge devices.},
  archive      = {J_ASOC},
  author       = {Kittipol Wisaeng},
  doi          = {10.1016/j.asoc.2025.113871},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113871},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger. <em>ASOC</em>, <em>185</em>, 113870. (<a href='https://doi.org/10.1016/j.asoc.2025.113870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Teaching-Learning-Based optimization (TLBO) algorithm, which includes teacher phase and learner phase, is a widely used method for global optimization. However, TLBO will experience premature convergence and get stuck in local optimum when faced with complex optimization challenges. Especially when tackling complex problems in practical engineering applications, which involves multiple variables and numerous constraints. To address this issue, a new variant termed Stochastic Proportional–Differential TLBO (SPD-TLBO) has been developed. The SPD phase allows students to learn not only from the current population but also from previous stochastic errors and their generation differences using adaptive random operators. By incorporating an SPD operator into the original TLBO framework, the algorithm’s search diversity is enhanced, reducing the likelihood of premature convergence to local optimum. The experimental results conducted at the IEEE Conference on Evolutionary Computation 2014 (CEC 2014) indicated that the proposed SPD-TLBO algorithm achieved an effective balance between exploration and exploitation capabilities. Specifically, the SPD-TLBO algorithm achieves the highest ranking in 21 out of 30 cases (70%) for 30-dimensional problems and 18 out of 30 cases (60%) for 50-dimensional problems. Statistical tests and convergence analyses show that the SPD-TLBO algorithm outperforms other algorithms in solving global optimization problems. Additionally, when applied to engineering optimization problems, the SPD-TLBO algorithm shows significant advantages over other algorithms. Therefore, the SPD-TLBO algorithm is further applied to optimize the structure of a wafer transfer finger in semiconductor manufacturing.},
  archive      = {J_ASOC},
  author       = {Jinfeng Sun and Yunlang Xu and Haibo Zhou},
  doi          = {10.1016/j.asoc.2025.113870},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113870},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network. <em>ASOC</em>, <em>185</em>, 113867. (<a href='https://doi.org/10.1016/j.asoc.2025.113867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus Disease 2019 (COVID-19) is an infectious illness that affects both humans and animals. Individuals infected with COVID-19 are prone to lung complications during the recovery phase . Radiography and Computed Tomography (CT) are the most commonly used methods for diagnosing lung-related diseases. The primary aim of this paper is to assess the impact of COVID-19 on patients’ lungs, heart, and blood sugar levels using a deep learning-based approach. Initially, data related to the heart, blood sugar levels, and lungs of COVID-19-infected individuals are collected. From this dataset, three types of features are extracted. Deep features are obtained using Iterated Dilated Convolutional Neural Networks (IDCNN). From these deep features, which are obtained from the IDCNN, the optimal weighted features are derived by implementing the Hybrid Dolphin Pod Cuttlefish Optimization (HDPCO) algorithm. Subsequently, the HDPCO algorithm is also employed for optimal feature extraction. In addition, dimensionality reduction is performed using Principal Component Analysis (PCA). These three sets of features from the IDCNN, HDPCO, and PCA, are then fused into a single feature set . This fused feature set is fed into a hybrid classifier composed of a Deep Temporal Convolutional Network (DTCN) and an Attention-based Long Short-Term Memory (ALSTM) network . The classifier parameters are optimized using the HDPCO algorithm. The output from the hybrid classifier provides the final prediction result. Experimental results demonstrate that the proposed COVID-19 impact prediction model significantly outperforms existing models in terms of prediction accuracy and efficiency.},
  archive      = {J_ASOC},
  author       = {Sadanandam Kalvala and B. Baranidharan},
  doi          = {10.1016/j.asoc.2025.113867},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113867},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware. <em>ASOC</em>, <em>185</em>, 113866. (<a href='https://doi.org/10.1016/j.asoc.2025.113866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing offers the potential to enhance computational efficiency beyond classical methods, but practical implementation remains challenging due to the limitations of Noisy Intermediate-Scale Quantum (NISQ) hardware, namely, restricted qubit counts, limited connectivity, and the presence of noise and decoherence. This study presents a novel approach to edge detection by leveraging a recently developed Quantum Fuzzy Inference Engine, implemented on a NISQ device. We introduce an optimized quantum circuit for its implementation, reducing qubit requirements and gate depth to improve execution on NISQ hardware. To overcome constraints related to large-scale image processing, a hybrid quantum–classical lookup table approach is employed. Edge detection performance is evaluated on the Berkeley Segmentation Data Set and Benchmarks 500 dataset under different conditions, including classical execution, ideal quantum simulation, noisy quantum simulation, and NISQ hardware calculation. Results demonstrate that the quantum fuzzy logic-based edge detection achieves outcomes comparable to classical methods by using fewer operations, marking a step toward practical quantum-enhanced image processing.},
  archive      = {J_ASOC},
  author       = {G. Nunziata and S. Crisci and G. De Gregorio and R. Schiattarella and G. Acampora and L. Coraggio and N. Itaco},
  doi          = {10.1016/j.asoc.2025.113866},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113866},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompted complex context generation guided fine-grained ship recognition. <em>ASOC</em>, <em>185</em>, 113856. (<a href='https://doi.org/10.1016/j.asoc.2025.113856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained ship recognition in complex marine environments is challenged by background interference, high inter-class similarity, and limited labeled data. Existing methods often rely on inefficient cascades or holistic feature extraction, which limits both accuracy and efficiency. To address these issues, we propose a Prompted Complex Context Generation Guided Fine-Grained Ship Recognition framework, consisting of two core modules. The Cross-Attention Context Generation Module utilizes a diffusion model to generate diverse background images from prompts, maintaining target consistency and enriching the training data to mitigate data scarcity. It also employs a cross-attention map to highlight target-relevant regions, guiding the Attention Map Guided Fusion Module. The Attention Map Guided Fusion Module adopts a dual-branch transformer architecture: one branch extracts global features from background-enhanced images, and the other captures local features through attention-guided cropping of target-specific regions. By integrating both global and local features, our method effectively identifies key target characteristics. Experimental results demonstrate that our approach achieves 97.04% accuracy on the publicly available MAR-ships dataset and 84.57% accuracy on the challenging GCS dataset, outperforming state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Runtian Wang and Kejun Wu and Renjie Qiao and Chunsheng Yang and Chengtao Cai},
  doi          = {10.1016/j.asoc.2025.113856},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113856},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prompted complex context generation guided fine-grained ship recognition},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy. <em>ASOC</em>, <em>185</em>, 113851. (<a href='https://doi.org/10.1016/j.asoc.2025.113851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing decision tree algorithms often use a single-layer measure to process data, which cannot fully consider the complex interactions and dependencies between different granularity levels. In addition, decision tree algorithms inevitably face the issue of multi-value preference, which may lead to the selection of unreasonable attributes in the process of partition, thereby affecting the performance of the algorithms. Therefore, this paper proposes an improved decision tree algorithm, called Ze-VNDT, which combines variable precision rough sets with Zentropy. First, to avoid the information loss caused by data discretization, this paper introduces variable precision neighborhood rough sets for data processing. Second, by analyzing the granularity level structure within the variable precision neighborhood rough set model, knowledge uncertainty is analyzed from three granularity levels: decision classes, approximate relations, and similarity classes. We describe the uncertain knowledge from the overall to the internal using the idea of going from coarse to fine, and design a Zentropy to measure uncertainty. To address the issue of multi-value preference, an adaptive weighted Zentropy uncertainty measure is designed based on the definition of uncertainty measure based on Zentropy. Third, when constructing the improved decision tree algorithm, the optimal attributes are selected based on the designed uncertainty measure. Finally, numerical experiments on 18 UCI datasets validated the effectiveness and rationality of the proposed algorithm. The experimental results showed that, compared to traditional algorithms and the latest improved algorithms, the proposed algorithm achieved an average accuracy of 94.79%, an average precision of 85.77%, an average recall rate of 84.68%, and an F1-score of 84.97% across the 18 datasets. It ranked first in all five evaluation metrics, demonstrating higher stability and accuracy.},
  archive      = {J_ASOC},
  author       = {Hui Dong and Caihui Liu and Xiying Chen and Duoqian Miao},
  doi          = {10.1016/j.asoc.2025.113851},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113851},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skin lesion classification with mini-batch sampling and deep metric learning. <em>ASOC</em>, <em>185</em>, 113850. (<a href='https://doi.org/10.1016/j.asoc.2025.113850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin lesion image classification based on deep learning has recently garnered significant attention. However, directly applying methods that perform well in general computer vision tasks to skin lesion image classification is not ideal, as skin lesion image datasets possess intrinsic characteristics, such as class imbalance, intra-class variability, and inter-class similarity. To tackle these challenges simultaneously, we propose a novel unified learning framework, named mBSML, which integrates mini-batch sampling and deep metric learning. In this framework, mini-batch sampling re-samples data in real-time during each iteration of learning, while a new loss function combines mini-batch distance metric-based loss with cross-entropy loss. Through the alternating training procedure on both imbalanced training data and balanced re-sampling data, mBSML effectively learns from global distribution information and local similarity information, not only from the original dataset but also from the minority classes. Extensive experiments conducted on two publicly available datasets demonstrate the effectiveness of mBSML for skin lesion image classification.},
  archive      = {J_ASOC},
  author       = {Shengdan Hu and Zhifei Zhang and Li Ying and Guangming Lang},
  doi          = {10.1016/j.asoc.2025.113850},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113850},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Skin lesion classification with mini-batch sampling and deep metric learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes. <em>ASOC</em>, <em>185</em>, 113849. (<a href='https://doi.org/10.1016/j.asoc.2025.113849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in airport surface scenes is crucial for enhancing safety. However, the coexistence of objects with significant scale disparities within the same region complicates feature representation, limiting existing models’ ability to capture fine-grained details, especially for small objects. To address this challenge, we propose AOD-YOLO, an Airport Object Detection (AOD) model incorporating a Self-Modulating Multi-Scale Feature Aggregation Mechanism. This model introduces two key innovations: (1) Enhanced Context Modeling: By leveraging large-kernel convolution, frequency-domain modulation, and statistical feature analysis, our approach effectively adjusts feature contributions across different object scales, improving contextual understanding in complex scenes; (2) Optimized Small Object Representation: A dynamic gradient gain allocation strategy refines small-object features, enhancing detection accuracy and overall feature presentation. AOD-YOLO consistently improves performance across model scales. On our self-constructed Airport dataset and the public VisDrone-DET2019 dataset, it achieves mean Average Precision (mAP 0.5 ) of 87.9% and 44.9%, respectively—outperforming state-of-the-art models like YOLOv11 and Gold-YOLO by substantial margins. Additionally, through optimized network module placement, AOD-YOLO achieves 112 FPS, striking a balance between computational efficiency and accuracy, making it well-suited for real-time airport object detection.},
  archive      = {J_ASOC},
  author       = {Yingqing Wang and Weili Zeng and Ziyu Zhao and Baogeng Li and Zhibin Quan},
  doi          = {10.1016/j.asoc.2025.113849},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113849},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient mathematical-based optimization method to optimize multi-hydropower operating rules. <em>ASOC</em>, <em>185</em>, 113846. (<a href='https://doi.org/10.1016/j.asoc.2025.113846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing hydropower multi-reservoir systems requires both effective operating rules and efficient optimization techniques. The main contribution of this paper is offering a unique approach that elegantly combines two important parts: creating an efficient optimization method and developing hydropower operating rules. In this regard, a nonlinear rule curve (NLRC) and a linear rule curve (LRC), are tailored for the coordination of a hydropower multi-reservoir system (HMRS) in Iran. To optimize operating rules, the study fabricates a novel algorithm termed the multi-operator weighted mean of vectors (MINFO). The algorithm combines a powerful global search strategy (GSS) that thoroughly searches the solution space with an efficient local search (LS), striking a balance between solution diversity and convergence speed. To fine-tune this balance, an adaptive parameter-tuning strategy is applied. Furthermore, the active-set sequential quadratic programming (ASQP) serves as a localized escaping operator to enhance the algorithm's convergence speed. The effectiveness of the proposed MINFO algorithm is first evaluated through a nonlinear five-reservoir problem. The findings indicate that the MINFO algorithm outperforms a set of 14 distinct optimization methods. Subsequently, the MINFO algorithm is applied to identify optimal NLRC and LRC for a six-reservoir hydropower system. The results underscore the superiority of optimized NLRC, yielding a potential power augmentation of up to 17 % in comparison to the LRC approach. In summation, this study constitutes a seminal contribution by cultivating an efficient rule curve framework for the management of HMRSs.},
  archive      = {J_ASOC},
  author       = {Shuguang Li and Iman Ahmadianfar and Aitazaz A. Farooque and Zaher Mundher Yaseen},
  doi          = {10.1016/j.asoc.2025.113846},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113846},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient mathematical-based optimization method to optimize multi-hydropower operating rules},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach. <em>ASOC</em>, <em>185</em>, 113837. (<a href='https://doi.org/10.1016/j.asoc.2025.113837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting debris and monitoring marine life in sea aquaculture face challenges due to limited visibility and the presence of diverse. Underwater object detection by Autonomous Unmanned Vehicle(AUV) is inherently more challenging than land due to light attenuation and water turbidity, especially for small and dense objects in murky images, where extracting high-quality features is hindered. In this paper, we present an efficient approach for real-time underwater object detection through improvements in image enhancement, data augmentation, and feature aggregation. Initially, U-Shape Transformer is applied to enhance the original images. For data augmentation, it is observable that while Mosaic data augmentation enhances complex images but fails to improve small-object detection due generation of less number of images with small objects. To address this limitation, we propose Underwater-Mosaic (U-Mosaic), a modified Mosaic data augmentation technique designed to enhance small-object detection. Additionally, it was noted that existing YOLOv4 struggles with detecting small and densely populated objects in underwater images as unable to get sufficient features for small objects due to downsampling, image quality and also found difficulty in selecting anchor box size. Therefore, we propose a model called Advanced YOLOv4, tailored for underwater object detection. The proposed Advanced YOLOv4 aims to improve object detection efficiency by altering the neck and prediction layers of YOLOv4. Moreover, we introduce an additional spatial pyramid pooling layer to aggregate features and reduce feature dimensions thereby improving object detection rates. Also, the proposed work concentrates on very large object detection and for this purpose used downsampling during the detection of large objects. The proposed approach is validated through two distinct application areas: (i) detecting and locating debris (ii) detecting fish from underwater images. For validation, the Trash ICRA19 dataset is used for debris detection, while the Brackish dataset is employed for fish detection. UIQM and UCIQE, image enhancement assessment metrics are used to measure quality of enhanced images and found more than 20% better result for both the datasets. The proposed real-time underwater object detection model outperformed single-stage object detectors like YOLOv3, YOLOv4, YOLOv5, YOLOv7, and KPE-YOLOv5 by 5% in terms of mean Average Precision(mAP). Also proposed work compared with two-stage detector RCNN and found 8% better mAP than RCNN.},
  archive      = {J_ASOC},
  author       = {Pratima Sarkar and Sourav De and Prasenjit Dey and Sandeep Gurung},
  doi          = {10.1016/j.asoc.2025.113837},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113837},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniCon: Unified image-guiding generation with noise consistency. <em>ASOC</em>, <em>185</em>, 113832. (<a href='https://doi.org/10.1016/j.asoc.2025.113832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have demonstrated remarkable capabilities in image-to-image tasks. However, existing methods typically focus either on structural (e.g., layout, content) or stylistic guidance, with few approaches effectively excel at both. On the other hand, many methods require time-consuming fine-tuning or high inference latency, making interactive generation applications challenging to realize. To address these issues, we propose a two-stage framework referred as UniCon ( Uni fied Image-guiding Generation with Noise Con sistency). To improve time efficiency, we follow the paradigm of inversion-based image manipulation and introduce a novel method called Noise Consistency Inversion . Leveraging the nature of Consistency Models, this inversion process is highly efficient, requiring only a single neural function evaluation (NFE) in the inversion process. To achieve high consistency and finer control, we introduce a unified attention-based guidance mechanism that supports structural, stylistic, or joint reference inputs, without any additional fine-tuning. Experiments with structure- and style-specific methods show that our approach performs competitively or better in each individual aspect. In comparison of style transfer tasks that demand both structure and style, our method outperforms state-of-the-art baselines, confirming the effectiveness of our union control strategy. And overall, our approach also achieves the best efficiency in terms of runtime performance.},
  archive      = {J_ASOC},
  author       = {Yuanjun Liao and Yuning Gong and Yanci Zhang},
  doi          = {10.1016/j.asoc.2025.113832},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113832},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UniCon: Unified image-guiding generation with noise consistency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment. <em>ASOC</em>, <em>185</em>, 113830. (<a href='https://doi.org/10.1016/j.asoc.2025.113830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Turkish textile and apparel sector plays a crucial role in the national economy through employment, exports, and investment. The financial performance of companies is a key determinant of their sustainability and competitiveness, especially in global markets. The Turkish textile and apparel sector is one of the essential industries in terms of macro-economic indicators such as net foreign exchange inflow, employment and investment. This sector is also one of the critical actors in world trade. A robust performance evaluation model is essential for stakeholders such as investors, creditors, and managers. However, the assessment of firms is a very critical decision involving uncertainty due to various conflicting criteria based on judgements. In this study, an integrated multi-criteria decision-making (MCDM) model including interval type-2 fuzzy hierarchy process (IT2FAHP) and Compromise Ranking of Alternatives from Distance to Ideal Solution (CRADIS) approaches are proposed to assess the financial performance of Turkish textile and clothing firms that are traded in Borsa İstanbul (BİST) in the period from 2006 to 2020. In line with the determined purpose, the arithmetic average of the determined financial ratios during the analysis period covering 15 years is computed to obtain long-term performance indicators. The importance weights of the selected financial criteria for the performance evaluation model are identified by employing the IT2FAHP approach. Then, the firms are ranked according to their financial performances with the CRADIS method. In addition, the results from the sensitivity analysis validate the proposed approach and prove that it is practical. Moreover, practical and managerial implications are discussed based on the results. The results offer valuable insights for strategic decision-making and can support efforts to enhance financial stability in the textile and apparel sector. According to the results, "LUKSK" had the highest long-term financial performance among the 11 companies discussed. This company is followed by BOSSA, YATAS, and ATEKS companies. The alternatives confirm the robustness of the proposed model in maintaining its place in the ranking in 190 scenarios. In addition, the comparative analysis confirms the consistency of the proposed ranking framework.},
  archive      = {J_ASOC},
  author       = {Ömer Faruk Görçün and Mohsin Shabir and Ahmet Çalık and Özcan Işık},
  doi          = {10.1016/j.asoc.2025.113830},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113830},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks. <em>ASOC</em>, <em>185</em>, 113829. (<a href='https://doi.org/10.1016/j.asoc.2025.113829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty analysis of wind speed forecasting using the Lower Upper Bound Estimation (LUBE) represents an advanced interval prediction method that does not require assumptions about data distribution. Previous studies, however, have exclusively focused on univariate prediction models, neglecting the information from other variables, and have not fully exploited the prediction errors in their loss function during training. To address these issues, an interpretable dual-output multivariate wind speed interval prediction scheme (IMWSIPS) that utilizes a hyper-heuristic optimization algorithm and a deep neural network is proposed, along with a novel loss function for training. The system initially takes multiple inputs such as historical wind speed and other influencing factors including wind direction, density, temperature, and pressure into a deep neural network. The actual wind speeds are then scaled up and down by factors of 1 + θ 1 (0 <θ 1 <1) and 1 + θ 2 (-1 <θ 2 <0), respectively, to produce two outputs from the network. On this basis, an optimization problem to minimize interval width under a given coverage probability is formulated and solved using the developed hyper-heuristic algorithm, yielding optimal values for θ 1 and θ 2 and the prediction intervals for sub-models. Subsequently, the advantages of five deep neural network models are leveraged to construct an ensemble model, with weights optimized by the hyper-heuristic algorithm to derive the final prediction intervals. Ultimately, the system's interpretability is analyzed at both variable and sub-model levels. Experimental and discussion results demonstrate that the introduction of IMWSIPS not only signifies enhancements in forecasting performance but also implies improvements in wind energy utilization efficiency and reductions in operational costs for power systems.},
  archive      = {J_ASOC},
  author       = {Mengzheng Lv and Jianzhou Wang and Shuai Wang and Yang Zhao and Jialu Gao and Yuansheng Qian},
  doi          = {10.1016/j.asoc.2025.113829},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113829},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction. <em>ASOC</em>, <em>185</em>, 113776. (<a href='https://doi.org/10.1016/j.asoc.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material properties are illustrated by numerical data and semantic factors. In general, existing methods typically adopt machine learning (ML) algorithms to regress numerical properties or transfer other pre-trained knowledge graphs (KGs) to the material, due to the limitations of small-sample datasets. However, integrating semantic and numerical information from multi-modal data which across diverse experimental conditions remains a significant challenge in materials science. In this paper, a numerical reasoning method for material KGs (NR-KG) 1 was proposed, which constructs a cross-modal KG using semantic nodes and numerical proxy nodes. Both types of information by projecting KG into a canonical KG were captured and a graph neural network to predict material properties was utilized. In process, a novel projection prediction loss is proposed to extract semantic features from numerical information. NR-KG facilitates end-to-end processing of cross-modal data, mining relationships and cross-modal information in small-sample datasets, and fully utilizes effective experimental data to enhance the accuracy of material prediction. We propose two new high-entropy alloys (HEA) property datasets with semantic descriptions. NR-KG outperforms state-of-the-art (SOTA) methods on two material datasets, with MSE values of 3520 and 2.210, and achieving relative improvements of 25.9% and 16.1%, respectively, over the second-best methods, KANO and PCHMLP (semantic). It also achieves RMSE values of 0.584 and 0.521 on the FreeSolv and ESOL public molecular datasets, surpassing SOTA methods by 48.8% and 22.2% over KANO, highlighting its potential application and generalizability.},
  archive      = {J_ASOC},
  author       = {Guangxuan Song and Dongmei Fu and Zhongwei Qiu and Zijiang Yang and Jiaxin Dai and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.asoc.2025.113776},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113776},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing. <em>ASOC</em>, <em>185</em>, 113697. (<a href='https://doi.org/10.1016/j.asoc.2025.113697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading in volatile markets, such as cryptocurrencies, requires portfolio models that can swiftly adapt to regime shifts while controlling risk. We propose a novel approach that frames portfolio management as a dynamic strategy-selection problem. Instead of directly predicting asset weights, our agent selects from a pool of expert strategies based on recent market trends. We introduce a Transformer-based Variational Autoencoder (VAE) to extract disentangled trend representations, and a trend-aware actor–critic model to perform expert selection. Experiments demonstrate that this modular, strategy-level control mechanism outperforms existing methods in risk-sensitive crypto portfolio management.},
  archive      = {J_ASOC},
  author       = {Ahmad Asadi and Reza Safabakhsh},
  doi          = {10.1016/j.asoc.2025.113697},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113697},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="autom">AUTOM - 33</h2>
<ul>
<li><details>
<summary>
(2026). Sector stabilization criterion of a novel nonlinear flexible marine riser coupled system. <em>AUTOM</em>, <em>183</em>, 112618. (<a href='https://doi.org/10.1016/j.automatica.2025.112618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes a sector stabilization criterion for a nonlinear flexible marine riser system that incorporates lateral and transverse coupling vibrations, derived from Hamilton’s principle. This criterion, grounded in the sector-bounded condition, encompasses a wide range of linear and nonlinear feedback control laws applied to the transverse and lateral directions at the top boundary of the flexible marine riser, respectively. In the analysis, the nonlinear semigroup theory is utilized to establish the well-posedness of the resulting closed-loop coupled system. Notably, the solution demonstrates continuous dependence on the initial conditions. Furthermore, the exponential stability of the closed-loop coupled system is achieved by employing a generalized Gronwall-type integral inequality and the integral multiplier method, which involves the innovative development of an energy-like functional. To demonstrate the effectiveness of the proposed controls, numerical simulations utilizing the finite element method are presented.},
  archive      = {J_AUTOM},
  author       = {Yi Cheng and Xin Wang and Yuhu Wu and Bao-Zhu Guo},
  doi          = {10.1016/j.automatica.2025.112618},
  journal      = {Automatica},
  month        = {1},
  pages        = {112618},
  shortjournal = {Automatica},
  title        = {Sector stabilization criterion of a novel nonlinear flexible marine riser coupled system},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven unknown-input observers. <em>AUTOM</em>, <em>183</em>, 112614. (<a href='https://doi.org/10.1016/j.automatica.2025.112614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown inputs related to, e.g., sensor aging, modeling errors, or device bias, represent a major concern in wireless sensor networks, as they degrade the state estimation performance. To improve the performance, unknown-input observers (UIOs) have been proposed. Most of the results available to design UIOs are based on explicit system models, which can be difficult or impossible to obtain in real-world applications. Data-driven techniques, on the other hand, have become a viable alternative for the design and analysis of unknown systems using only data. In this context, a novel data-driven distributed unknown-input observer (D-DUIO) for unknown continuous-time linear time-invariant (LTI) systems is developed, which requires solely some data collected offline, without any prior knowledge of the system matrices. In the paper, first, a model-based approach to the design of a DUIO is presented. A sufficient condition for the existence of such a DUIO is recalled, and a new one is proposed, that is prone to a data-driven adaptation. Moving to a data-driven approach, it is shown that under suitable assumptions on the input/output/state data collected from the continuous-time system, it is possible to both claim the existence of a D-DUIO and to derive its matrices in terms of the matrices of pre-collected data. Finally, the efficacy of the D-DUIO is illustrated by means of numerical examples.},
  archive      = {J_AUTOM},
  author       = {Yuzhou Wei and Giorgia Disarò and Wenjie Liu and Jian Sun and Maria Elena Valcher and Gang Wang},
  doi          = {10.1016/j.automatica.2025.112614},
  journal      = {Automatica},
  month        = {1},
  pages        = {112614},
  shortjournal = {Automatica},
  title        = {Distributed data-driven unknown-input observers},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robustness of supervisory controllers subject to measurement disturbances. <em>AUTOM</em>, <em>183</em>, 112613. (<a href='https://doi.org/10.1016/j.automatica.2025.112613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the supervisory control problem for a class of uncertain nonlinearly parameterized systems in the presence of measurement disturbance. Based on the well-established estimator-based supervisory control structure, a robustification of supervisory controller dealing with measurement disturbance is developed taking advantage of the monitoring signals redesign, such that the plant state asymptotically converges to a given set-point or its neighborhood, subject to the vanishing or the persistent measurement disturbance, respectively. Moreover, a constructive design of the multi-estimator using measurement feedback is proposed for the supervisory control of a class of uncertain nonlinearly parameterized systems in the strict-feedback form. A numerical simulation based on an uncertain mass–spring system is given to show the efficacy of our proposed algorithm, in which we use an event-trigger to be a measurement disturbance generator.},
  archive      = {J_AUTOM},
  author       = {Yutian Wang and Qingkai Meng and Yi Jiang},
  doi          = {10.1016/j.automatica.2025.112613},
  journal      = {Automatica},
  month        = {1},
  pages        = {112613},
  shortjournal = {Automatica},
  title        = {Robustness of supervisory controllers subject to measurement disturbances},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive fault-tolerant control of nonlinear systems: A self-regulating spatiotemporal performance approach. <em>AUTOM</em>, <em>183</em>, 112602. (<a href='https://doi.org/10.1016/j.automatica.2025.112602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of performance constraints of uncertain nonlinear systems with actuator faults. Particularly, by developing the boundary threshold triggering strategy, the performance boundaries would be updated adaptively once the distance between the tracking error and the performance boundaries is smaller than the given threshold. Moreover, compared with the existing works, the transient behaviors are improved, and the limitation imposed on the initial conditions is removed attributed to the construction of novel performance functions and error transformation. Then, an adaptive fault-tolerant control scheme with self-regulating spatiotemporal performance is designed for a class of nonlinear systems with non-parametric uncertainties. It is shown that both the boundedness of the closed-loop signals and the satisfactory performance constraints are guaranteed in the presence of unpredictable actuator failure. The effectiveness of the proposed method is verified by theoretical analysis and numerical simulation.},
  archive      = {J_AUTOM},
  author       = {Zeqiang Li and Jason J.R. Liu and Yongduan Song},
  doi          = {10.1016/j.automatica.2025.112602},
  journal      = {Automatica},
  month        = {1},
  pages        = {112602},
  shortjournal = {Automatica},
  title        = {Adaptive fault-tolerant control of nonlinear systems: A self-regulating spatiotemporal performance approach},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed nash equilibrium seeking with a dynamic set of players. <em>AUTOM</em>, <em>183</em>, 112598. (<a href='https://doi.org/10.1016/j.automatica.2025.112598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formulates a new distributed Nash equilibrium seeking problem with a dynamic set of players in which players are allowed to join and leave the network in a free manner during the decision-making process. To accommodate the dynamic joining and leaving behaviors of the players, a status estimation mechanism, which is capable of estimating in a finite time whether the players are active or inactive, is introduced. Based on the status estimation mechanism, a gradient play based algorithm is developed for distributed Nash equilibrium seeking in the dynamic environment. It is shown that under strongly connected communication graphs, players’ actions are convergent to a small neighborhood of the new Nash equilibrium linearly every time the player set changes. Moreover, the convergence accuracy and convergence rate can be adjusted by suitably tuning the step-size. To cover more general communication scenarios, strongly connected graphs are further relaxed to be B-jointly connected graphs, under which the convergence properties of the proposed algorithm are analytically studied. Furthermore, the upper bound of the average tracking error is quantified to evaluate the dynamic performance of the proposed algorithm. In the last, a simulation study on energy consumption games is given to verify the effectiveness of the proposed algorithm.},
  archive      = {J_AUTOM},
  author       = {Yuxuan Liu and Maojiao Ye and Lei Ding and Lihua Xie and Qing-Long Han},
  doi          = {10.1016/j.automatica.2025.112598},
  journal      = {Automatica},
  month        = {1},
  pages        = {112598},
  shortjournal = {Automatica},
  title        = {Distributed nash equilibrium seeking with a dynamic set of players},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Constrained finite-time and fixed-time stabilization for linear systems: Adaptive implicit lyapunov function-based control. <em>AUTOM</em>, <em>183</em>, 112597. (<a href='https://doi.org/10.1016/j.automatica.2025.112597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, finite-time and fixed-time stabilization problems are investigated for single-input single-output (SISO) linear system under the control input constraint. The achievement of finite-time or fixed-time convergence rates is facilitated through the utilization of adaptive implicit Lyapunov function (ILF)-based control. For ease of practical implementation, the dynamics of Approximated-ILF (AILF) guarantees the precise estimation of ILF, while the stability of AILF-based control holds established. Furthermore, from both performance and input-constrained safety considerations, the anti-windup (AW) AILF endows the system with tolerance to saturation and maintains the non-asymptotic convergence properties. Numerical simulations support the obtained theoretical results and verify their effectiveness.},
  archive      = {J_AUTOM},
  author       = {Peng Wang and Mou Chen and Shuzhi Sam Ge and Xiaobing Zhang},
  doi          = {10.1016/j.automatica.2025.112597},
  journal      = {Automatica},
  month        = {1},
  pages        = {112597},
  shortjournal = {Automatica},
  title        = {Constrained finite-time and fixed-time stabilization for linear systems: Adaptive implicit lyapunov function-based control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Input-to-state stability of self-triggered impulsive control systems. <em>AUTOM</em>, <em>183</em>, 112596. (<a href='https://doi.org/10.1016/j.automatica.2025.112596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the local input-to-state stability ( LISS ) of nonlinear systems under the self-triggered impulsive control ( STIC ) method. A novel LISS -type comparison principle is proposed, by which the LISS property of addressed system can be derived by the LISS property of its comparison system. On the basis of it, some Lyapunov-based sufficient conditions for non-Zeno behavior and LISS of nonlinear systems are provided in the framework of STIC . Moreover, the designed self-triggering mechanism ( STM ) is in the form of an explicit relationship with simple structure and east implementation. Finally, two numerical examples are given to illustrate the effectiveness of the proposed results.},
  archive      = {J_AUTOM},
  author       = {Xiaodi Li and Mingzhu Wang},
  doi          = {10.1016/j.automatica.2025.112596},
  journal      = {Automatica},
  month        = {1},
  pages        = {112596},
  shortjournal = {Automatica},
  title        = {Input-to-state stability of self-triggered impulsive control systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-model-hybrid-driven near-optimal operational control of two-time-scale industrial systems with unknown operational model. <em>AUTOM</em>, <em>183</em>, 112594. (<a href='https://doi.org/10.1016/j.automatica.2025.112594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the optimal operational control (OOC) problem of two-time-scale (TTS) industrial systems with unknown operation model. Based on the singular perturbation theory (SPT), the OOC problem of TTS industrial systems is decomposed into an optimal regulation problem in fast time-scale and an optimal set-point tracking problem in slow time-scale. Then, by convex duality, the obtained optimization problems are equivalently transformed into convex optimization (CO) problems, and a data-model-hybrid-driven composite controller is designed. The design method of this composite controller avoids the potential numerical stiffness problems, and does not need complete system dynamics information while ensuring the steady-state output tracking error converges to zero. Finally, an example of mixed separation thickening process (MSTP) of hematite beneficiation is given to show the effectiveness of the proposed scheme.},
  archive      = {J_AUTOM},
  author       = {Yao Xu and Linna Zhou and Jianguo Zhao and Lei Ma and Chunyu Yang},
  doi          = {10.1016/j.automatica.2025.112594},
  journal      = {Automatica},
  month        = {1},
  pages        = {112594},
  shortjournal = {Automatica},
  title        = {Data-model-hybrid-driven near-optimal operational control of two-time-scale industrial systems with unknown operational model},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reducing real-time complexity via sub-control lyapunov functions: From theory to experiments. <em>AUTOM</em>, <em>183</em>, 112592. (<a href='https://doi.org/10.1016/j.automatica.2025.112592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The techniques to design control Lyapunov functions (CLF), along with a proper stabilizing feedback, possibly in the presence of constraints, often provide control laws that are too complex for proper implementation online, especially when an optimization problem is involved. In this work, we show how to acquire an alternative, computationally attractive feedback. Given a nominal CLF and a nominal state feedback, we say that a different positive definite function is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative is negative-definite and bounded above by the Lyapunov derivative of the nominal function with the nominal control. It turns out that if we consider a family of basis functions, then an SCLF can be computed by linear programming, with an infinite number of constraints. The idea is that although the offline computational burden to achieve the new controller and solve the linear program is considerable, the online computational burden is drastically reduced. Comprehensive simulations and experiments on drone control are conducted to demonstrate the effectiveness of the study.},
  archive      = {J_AUTOM},
  author       = {Huu-Thinh Do and Franco Blanchini and Stefano Miani and Ionela Prodan},
  doi          = {10.1016/j.automatica.2025.112592},
  journal      = {Automatica},
  month        = {1},
  pages        = {112592},
  shortjournal = {Automatica},
  title        = {Reducing real-time complexity via sub-control lyapunov functions: From theory to experiments},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adversarial dynamic games for markov jump systems: A policy iteration Q-learning method. <em>AUTOM</em>, <em>183</em>, 112591. (<a href='https://doi.org/10.1016/j.automatica.2025.112591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reinforcement Q-learning approach for solving adversarial dynamic games in Markov jump systems. The H ∞ control problem is first formulated as a two-player zero-sum dynamic game, where the control policy and the disturbance policy act as adversarial players. To derive the Nash equilibrium control strategies for such games, a set of coupled algebraic Riccati equations is established, with the disturbance attenuation level properly prescribed. On this basis, two novel data-driven parallel Q-learning algorithms are proposed. The advantages of the proposed method are threefold: (i) it does not require precise knowledge of the system dynamics; (ii) it learns the optimal disturbance attenuation level; (iii) it yields Nash equilibrium control strategies. Finally, two simulation examples validate the effectiveness of the proposed method.},
  archive      = {J_AUTOM},
  author       = {Hao Shen and Jiacheng Wu and Jing Wang and Zhengguang Wu},
  doi          = {10.1016/j.automatica.2025.112591},
  journal      = {Automatica},
  month        = {1},
  pages        = {112591},
  shortjournal = {Automatica},
  title        = {Adversarial dynamic games for markov jump systems: A policy iteration Q-learning method},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). H2/H∞ state and output feedback control with sparse actuation. <em>AUTOM</em>, <em>183</em>, 112581. (<a href='https://doi.org/10.1016/j.automatica.2025.112581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present novel convex optimization formulations for designing full-state and output-feedback controllers with sparse actuation that achieve user-specified H 2 and H ∞ performance criteria. The sparsity is induced through the ℓ 1 -minimization over channel-wise H 2 norms from disturbances to the individual actuator signals, while simultaneously constraining H 2 or H ∞ norm from disturbances to the output variables The proposed approach is applied to a structural dynamics problem, demonstrating the advantages of simultaneous optimization of the control law and the actuation architecture in realizing an efficient closed-loop system, as well as highlighting the trade-offs between maximum allowable actuator magnitudes and the controller sparsity.},
  archive      = {J_AUTOM},
  author       = {Vedang M. Deshpande and Raktim Bhattacharya},
  doi          = {10.1016/j.automatica.2025.112581},
  journal      = {Automatica},
  month        = {1},
  pages        = {112581},
  shortjournal = {Automatica},
  title        = {H2/H∞ state and output feedback control with sparse actuation},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive dynamic event–triggered distributed optimal coordination of heterogeneous uncertain nonlinear multiagent systems. <em>AUTOM</em>, <em>183</em>, 112580. (<a href='https://doi.org/10.1016/j.automatica.2025.112580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed optimal coordination problem for a class of heterogeneous uncertain nonlinear multiagent systems. Instead of relying on the analytical forms of gradient functions, we use the measured gradient values depending on agents’ real-time outputs and propose a novel adaptive distributed control scheme. This scheme integrates event-triggered optimal coordinators, high-order filters, and tracking controllers. To handle the interaction between optimal coordinators and filters, we incorporate a new compensation term into the updating law for the coupling weight of each edge. Moreover, we design a novel adaptive distributed dynamic event-triggering mechanism that ensures that the inter-event times of each agent are lower bounded by a positive constant. Asymptotic convergence of agents’ outputs to the optimal point is proved by constructing a composite Lyapunov function. The proposed control scheme does not depend on global topology information. A numerical example is given to demonstrate the effectiveness of the proposed control scheme.},
  archive      = {J_AUTOM},
  author       = {Tianyu Liu and Lu Liu},
  doi          = {10.1016/j.automatica.2025.112580},
  journal      = {Automatica},
  month        = {1},
  pages        = {112580},
  shortjournal = {Automatica},
  title        = {Adaptive dynamic event–triggered distributed optimal coordination of heterogeneous uncertain nonlinear multiagent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accelerated primal–dual methods for strongly convex objective functions in continuous and discrete time. <em>AUTOM</em>, <em>183</em>, 112579. (<a href='https://doi.org/10.1016/j.automatica.2025.112579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a “second-order primal” + “first-order dual” continuous-time dynamic for linearly constrained optimization problems, where the objective function is μ -strongly convex. We consider a constant damping 2 μ for the second-order ordinary differential equation in the primal variable, following Nesterov’s acceleration for strongly convex optimization. A positive constant scaling is applied to the primal variable, while a positive increasing scaling function is applied to the dual variable. We prove that the proposed dynamic achieves a fast convergence rate for both the objective residual and the feasibility violation, with the decay rate potentially reaching O ( e − μ t ) . Additionally, we show that the dynamic is robust under small perturbations. By discretizing the proposed continuous-time dynamic, we develop an accelerated linearized augmented Lagrangian method for strongly convex composite optimization with linear constraints, where the objective function has a nonsmooth + smooth composite structure. The proposed algorithm achieves a fast convergence rate that matches the one of the continuous-time dynamic. We also consider an inexact version of the proposed algorithm, which can be viewed as a discrete version of the perturbed continuous-time dynamic. Numerical results are provided to verify the practical performances.},
  archive      = {J_AUTOM},
  author       = {Xin He and Dong He and Ya-Ping Fang},
  doi          = {10.1016/j.automatica.2025.112579},
  journal      = {Automatica},
  month        = {1},
  pages        = {112579},
  shortjournal = {Automatica},
  title        = {Accelerated primal–dual methods for strongly convex objective functions in continuous and discrete time},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical supervisory control of networked and cyber-attacked discrete-event systems. <em>AUTOM</em>, <em>183</em>, 112578. (<a href='https://doi.org/10.1016/j.automatica.2025.112578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In standard supervisory control of discrete-event systems, partial (incomplete) observations are given by deterministic functions such as natural projections, which erase unobservable events, or masks, which can represent indistinguishable events, where two or more different events yield the same observation. However, communication channels in modern technological systems are not always reliable and can be attacked by malicious external agents. In that case, the plant observations obtained by the supervisor may not be deterministic, e.g., due to delays and losses, or external attacks. This paper considers a unified supervisory control framework with set-valued (nondeterministic) observations and proposes a simplified version of nondeterministic observability, together with a generalized normality. It shows how the results of hierarchical control can be extended to the networked and cyber-attacked discrete-event systems at the same time.},
  archive      = {J_AUTOM},
  author       = {Shaowen Miao and Jan Komenda and Feng Lin},
  doi          = {10.1016/j.automatica.2025.112578},
  journal      = {Automatica},
  month        = {1},
  pages        = {112578},
  shortjournal = {Automatica},
  title        = {Hierarchical supervisory control of networked and cyber-attacked discrete-event systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the design of linear time varying model predictive control for trajectory stabilization. <em>AUTOM</em>, <em>183</em>, 112577. (<a href='https://doi.org/10.1016/j.automatica.2025.112577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilizing a reference trajectory of a nonlinear system is a recurrent, non-trivial task in control engineering. A common approach is to linearize the dynamics along the trajectory, thus deriving a linear-time-varying (LTV) model, and to design a model predictive controller (MPC), which results to be computationally efficient, since only convex programs need to be solved in real time, while retaining constraint handling capabilities. Building on recent developments in gain-scheduling control design, where linearization errors and tracking error bounds are considered, a new approach to derive such LTV-MPC controllers is presented. The method addresses the systematic derivation of a suitable terminal cost. The resulting MPC law is tube-based, exploiting the co-designed auxiliary gain-scheduled controller. Computational and implementation aspects are discussed as well, and the resulting hierarchical method is demonstrated both in simulation and in experiments with a small drone with fast dynamics and limited embedded computational capacity.},
  archive      = {J_AUTOM},
  author       = {Nicolas Kessler and Lorenzo Fagiano},
  doi          = {10.1016/j.automatica.2025.112577},
  journal      = {Automatica},
  month        = {1},
  pages        = {112577},
  shortjournal = {Automatica},
  title        = {On the design of linear time varying model predictive control for trajectory stabilization},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intersection-based architectures for decentralized diagnosis of discrete event systems. <em>AUTOM</em>, <em>183</em>, 112576. (<a href='https://doi.org/10.1016/j.automatica.2025.112576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two intersection-based architectures, named the normal-state-estimator-intersection-based architecture (N-SEI architecture) and the failure-state-estimator-intersection-based architecture (F-SEI architecture), are examined for decentralized diagnosis of discrete event systems. For each of these architectures, the corresponding notion of codiagnosability is defined. These defined notions of codiagnosability are incomparable with inference diagnosability for the inference-based architecture. In addition, codiagnosability for the N-SEI architecture is weaker than the existing notion of intersection-based codiagnosability, while codiagnosability for the F-SEI architecture is incomparable with it. For each of the N-SEI and F-SEI architectures, a method for verifying the corresponding notion of codiagnosability is developed.},
  archive      = {J_AUTOM},
  author       = {Shigemasa Takai and Takashi Yamamoto},
  doi          = {10.1016/j.automatica.2025.112576},
  journal      = {Automatica},
  month        = {1},
  pages        = {112576},
  shortjournal = {Automatica},
  title        = {Intersection-based architectures for decentralized diagnosis of discrete event systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed stochastic constrained optimization with constant step-sizes via saddle-point dynamics. <em>AUTOM</em>, <em>183</em>, 112575. (<a href='https://doi.org/10.1016/j.automatica.2025.112575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers distributed stochastic optimization problems over a multi-agent network, where each agent collaboratively minimizes the sum of individual expectation-valued cost functions subject to nonidentical set constraints. We first recast the distributed constrained optimization as a constrained saddle-point problem. Subsequently, two distributed stochastic algorithms via optimistic gradient descent ascent (SOGDA) and extragradient (SEG) methods are developed with constant step sizes, in which the variable sample-size technique is incorporated to reduce the variance of the sampled gradients. We present the explicit selection criteria of the constant step size, under which the developed algorithms achieve almost sure convergence to an optimal solution. Moreover, the convergence rate is O ( 1 / k ) for merely convex cost functions, which matches the optimal rate of its deterministic counterpart. Finally, a numerical example is provided to reflect the theoretical findings.},
  archive      = {J_AUTOM},
  author       = {Yi Huang and Shisheng Cui and Xianlin Zeng and Ziyang Meng},
  doi          = {10.1016/j.automatica.2025.112575},
  journal      = {Automatica},
  month        = {1},
  pages        = {112575},
  shortjournal = {Automatica},
  title        = {Distributed stochastic constrained optimization with constant step-sizes via saddle-point dynamics},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A characterization method of terminal ingredients for nonlinear MPC using value-based reinforcement learning. <em>AUTOM</em>, <em>183</em>, 112574. (<a href='https://doi.org/10.1016/j.automatica.2025.112574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability of nonlinear model predictive control (MPC) relies significantly on stabilizing factors such as the terminal region and cost. A larger terminal region not only expands the region of attraction for the closed-loop system but also contributes to reducing online computation costs. However, existing methods in the literature often impose limitations on the degrees of freedom available for characterizing terminal ingredients. This limitation arises from the reliance on either a predetermined linear local controller or a preset control Lyapunov function. This paper introduces an innovative approach to terminal ingredient characterization leveraging value-based reinforcement learning (RL). This method provides ample degrees of freedom for expanding the terminal region. To achieve this, a deep neural network is employed to learn the parametric state value function, serving as the terminal cost for MPC. The local controller adopts a one-step MPC instead of a predetermined linear or nonlinear feedback controller. Subsequently, a terminal set sequence is constructed iteratively through the one-step set expansion. The proposed approach’s effectiveness is validated through simulations.},
  archive      = {J_AUTOM},
  author       = {Jinghan Cui and Jinwu Gao and Xiangjie Liu and Yuqi Liu and Shuyou Yu},
  doi          = {10.1016/j.automatica.2025.112574},
  journal      = {Automatica},
  month        = {1},
  pages        = {112574},
  shortjournal = {Automatica},
  title        = {A characterization method of terminal ingredients for nonlinear MPC using value-based reinforcement learning},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Aperiodic-sampled neural network controllers with closed-loop stability verifications. <em>AUTOM</em>, <em>183</em>, 112573. (<a href='https://doi.org/10.1016/j.automatica.2025.112573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we synthesize two aperiodic-sampled deep neural network (DNN) control schemes, based on the closed-loop tracking stability guarantees. By means of the integral quadratic constraint coping with the input–output behavior of system uncertainties/nonlinearities and the convex relaxations of nonlinear DNN activations leveraging their local sector-bounded attributes, we establish conditions to design the event- and self-triggered logics and to compute the ellipsoidal inner approximations of region of attraction, respectively. Finally, we perform a numerical example of an inverted pendulum to illustrate the effectiveness of the proposed aperiodic-sampled DNN control schemes.},
  archive      = {J_AUTOM},
  author       = {Renjie Ma and Zhijian Hu and Rongni Yang and Ligang Wu},
  doi          = {10.1016/j.automatica.2025.112573},
  journal      = {Automatica},
  month        = {1},
  pages        = {112573},
  shortjournal = {Automatica},
  title        = {Aperiodic-sampled neural network controllers with closed-loop stability verifications},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backstepping for partial differential equations: A survey. <em>AUTOM</em>, <em>183</em>, 112572. (<a href='https://doi.org/10.1016/j.automatica.2025.112572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems modeled by partial differential equations (PDEs) are at least as ubiquitous as those by nature finite-dimensional and modeled by ordinary differential equations (ODEs). And yet, systematic and readily usable methodologies, for such a significant portion of real systems, have been historically scarce. Around the year 2000, the backstepping approach to PDE control began to offer not only a less abstract alternative to PDE control techniques replicating optimal and spectrum assignment techniques of the 1960s, but also enabled the methodologies of adaptive and nonlinear control, matured in the 1980s and 1990s, to be extended from ODEs to PDEs, allowing feedback synthesis for systems that are uncertain, nonlinear, and infinite-dimensional. The PDE backstepping literature has since grown to hundreds of papers and nearly a dozen books. This survey aims to facilitate the entry into this thriving area of overwhelming size and topical diversity. Designs of controllers and observers, for parabolic, hyperbolic, and other classes of PDEs, in one or more dimensions, with nonlinear, adaptive, sampled-data, and event-triggered extensions, are covered in the survey. The lifeblood of control are technology and physics. The survey places a particular emphasis on applications that have motivated the development of the theory and which have benefited from the theory and designs: flows, flexible structures, materials, thermal and chemically reacting dynamics, energy (from oil drilling to batteries and magnetic confinement fusion), and vehicles.},
  archive      = {J_AUTOM},
  author       = {Rafael Vazquez and Jean Auriol and Federico Bribiesca-Argomedo and Miroslav Krstic},
  doi          = {10.1016/j.automatica.2025.112572},
  journal      = {Automatica},
  month        = {1},
  pages        = {112572},
  shortjournal = {Automatica},
  title        = {Backstepping for partial differential equations: A survey},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Maximum principle for partial information non-zero sum stochastic differential games with mixed delays. <em>AUTOM</em>, <em>183</em>, 112570. (<a href='https://doi.org/10.1016/j.automatica.2025.112570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with one kind of partial information non-zero sum stochastic differential game with mixed delays. Both the state and control processes contain delays, where the former contains moving-average delay, discrete delay and noisy memory. We establish a necessary as well as two sufficient stochastic maximum principles for the game. As one of the main features of this research, a new kind of sufficient maximum principle is given, where the diffusion term can be controlled with non-convex control domains, and no second-order adjoint equation is needed. The theoretical results are applied to study two examples where the adjoint processes can be derived by two approaches and then the equilibrium points are obtained. This research generalizes those of stochastic optimal control problems.},
  archive      = {J_AUTOM},
  author       = {Pan Chen and Feng Zhang},
  doi          = {10.1016/j.automatica.2025.112570},
  journal      = {Automatica},
  month        = {1},
  pages        = {112570},
  shortjournal = {Automatica},
  title        = {Maximum principle for partial information non-zero sum stochastic differential games with mixed delays},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State estimation for lithium-ion batteries based on electrolyte–electrode PDE observers. <em>AUTOM</em>, <em>183</em>, 112568. (<a href='https://doi.org/10.1016/j.automatica.2025.112568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate information about the states of an electrochemical battery model facilitates a deeper understanding of battery behavior and enables performance enhancement. This paper first proposes backstepping Partial Differential Equation (PDE) observers for lithium concentration in the electrolyte phase within the negative electrode, positive electrode, and separator. Reverse sensitivity analysis is conducted to identify the most suitable measurable parameter for obtaining the electrolyte lithium concentration at the boundaries, which is used in the design of the electrolyte-phase observer. Subsequently, enhanced observers for the solid-phase lithium concentration in the negative and positive electrodes are developed. The proposed solid-phase observer enables more accurate State-of-Charge (SoC) estimation by leveraging the closed-loop electrolyte-phase observer. Simulations of the reverse sensitivity analysis and state observers are performed on a commercial cylindrical lithium iron phosphate ( LiFePO 4 ) cell to validate the effectiveness of the proposed approach.},
  archive      = {J_AUTOM},
  author       = {Sara Sepasiahooyi and Shu-Xia Tang},
  doi          = {10.1016/j.automatica.2025.112568},
  journal      = {Automatica},
  month        = {1},
  pages        = {112568},
  shortjournal = {Automatica},
  title        = {State estimation for lithium-ion batteries based on electrolyte–electrode PDE observers},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interval-constraint multiagent systems: Global attractivity and structural stability of equilibria. <em>AUTOM</em>, <em>183</em>, 112566. (<a href='https://doi.org/10.1016/j.automatica.2025.112566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the dynamic behavior of an interval-constraint multiagent system. Each agent has a constraint interval that limits its potential consensus values, achieved by encoding a nonsmooth piecewise function into the agent. In addition, the underlying graphs considered are strongly connected. First, a dichotomy of equilibria is identified: either a unique non-consensus equilibrium point or multiple consensus points, depending on whether the intersection of the constraint intervals is empty or not. Then, the set of equilibria is proven to be a global attractor. Structural stability of such a system is also proven based on real-analysis methods, showing that the equilibria have continuous dependence on changes of the constraint intervals. Three running examples are used to illustrate the proposed results.},
  archive      = {J_AUTOM},
  author       = {Fengqiu Liu and Kuize Zhang and Yuhu Wu and Xiaoping Xue},
  doi          = {10.1016/j.automatica.2025.112566},
  journal      = {Automatica},
  month        = {1},
  pages        = {112566},
  shortjournal = {Automatica},
  title        = {Interval-constraint multiagent systems: Global attractivity and structural stability of equilibria},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Closed-loop data-enabled predictive control and its equivalence with closed-loop subspace predictive control. <em>AUTOM</em>, <em>183</em>, 112556. (<a href='https://doi.org/10.1016/j.automatica.2025.112556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factors like growing data availability and increasing system complexity have sparked interest in data-driven predictive control (DDPC) methods like Data-enabled Predictive Control (DeePC). However, closed-loop identification bias arises in the presence of noise, which reduces the effectiveness of obtained control policies. In this paper we propose Closed-loop Data-enabled Predictive Control (CL-DeePC), a framework that unifies different approaches to address this challenge. To this end, CL-DeePC incorporates instrumental variables (IVs) to synthesize and sequentially apply consistent single or multi-step-ahead predictors. Furthermore, a computationally efficient CL-DeePC implementation is developed that reveals an equivalence with Closed-loop Subspace Predictive Control (CL-SPC). Time marching simulations of DeePC and CL-DeePC are conducted using Hankel matrices of past data that are updated at every time step to induce potentially troublesome closed-loop correlations between inputs and noise. Compared to DeePC, CL-DeePC simulations demonstrate superior reference tracking, with a sensitivity study finding a 48% lower susceptibility to noise-induced reference tracking performance degradation.},
  archive      = {J_AUTOM},
  author       = {Rogier Dinkla and Tom Oomen and Sebastiaan Paul Mulders and Jan-Willem van Wingerden},
  doi          = {10.1016/j.automatica.2025.112556},
  journal      = {Automatica},
  month        = {1},
  pages        = {112556},
  shortjournal = {Automatica},
  title        = {Closed-loop data-enabled predictive control and its equivalence with closed-loop subspace predictive control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated online learning for gaussian process regression. <em>AUTOM</em>, <em>183</em>, 112554. (<a href='https://doi.org/10.1016/j.automatica.2025.112554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Byzantine-resilient federated online learning for Gaussian process regression (GPR). We develop a Byzantine-resilient federated GPR algorithm that allows a cloud and a group of agents to collaboratively learn a latent function and improve the learning performances where some agents exhibit Byzantine failures, i.e., arbitrary and potentially adversarial behavior. Each agent-based local GPR sends potentially compromised local predictions to the cloud, and the cloud-based aggregated GPR computes a global model by a Byzantine-resilient product of experts aggregation rule. Then the cloud broadcasts the current global model to all the agents. Agent-based fused GPR refines local predictions by fusing the received global model with that of the agent-based local GPR. Moreover, we quantify the learning accuracy improvements of the agent-based fused GPR over the agent-based local GPR. Experiments on a toy example and two medium-scale real-world datasets are conducted to demonstrate the performances of the proposed algorithm.},
  archive      = {J_AUTOM},
  author       = {Xu Zhang and Zhenyuan Yuan and Minghui Zhu},
  doi          = {10.1016/j.automatica.2025.112554},
  journal      = {Automatica},
  month        = {1},
  pages        = {112554},
  shortjournal = {Automatica},
  title        = {Byzantine-resilient federated online learning for gaussian process regression},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Observer-based asymptotic active fault diagnosis: Separate and joint design of observer gain and input. <em>AUTOM</em>, <em>183</em>, 112548. (<a href='https://doi.org/10.1016/j.automatica.2025.112548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes observer gain and input design methods for observer-based asymptotic active fault diagnosis, which are based on a newly-defined notion named the excluding degree of the origin from a zonotope. Using the excluding degree, a quantitative specification is obtained to characterize the performance of set-based robust fault diagnosis. Furthermore, a separate gain design method and a joint gain and input design method are proposed, respectively. This is the first work to achieve a joint observer gain and input design for set-based active fault diagnosis. Compared with the existing methods that design gains and input separately, the proposed joint gain and input design method has advantages to exploit the fault diagnosis potential of observer-based schemes. Finally, several examples are used to illustrate the effectiveness of the proposed methods.},
  archive      = {J_AUTOM},
  author       = {Feng Xu and Yiming Wan and Ye Wang and Vicenç Puig},
  doi          = {10.1016/j.automatica.2025.112548},
  journal      = {Automatica},
  month        = {1},
  pages        = {112548},
  shortjournal = {Automatica},
  title        = {Observer-based asymptotic active fault diagnosis: Separate and joint design of observer gain and input},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Controller synthesis from noisy-input noisy-output data. <em>AUTOM</em>, <em>183</em>, 112545. (<a href='https://doi.org/10.1016/j.automatica.2025.112545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of synthesizing a dynamic output-feedback controller for a linear system, using solely input–output data corrupted by measurement noise. To handle input–output data, an auxiliary representation of the original system is utilized. By exploiting the structure of the auxiliary system, we design a controller that robustly stabilizes all possible systems consistent with data. Notably, we also provide a novel solution to extend the results to generic multi-input multi-output systems. The findings are illustrated by numerical examples.},
  archive      = {J_AUTOM},
  author       = {Lidong Li and Andrea Bisoffi and Claudio De Persis and Nima Monshizadeh},
  doi          = {10.1016/j.automatica.2025.112545},
  journal      = {Automatica},
  month        = {1},
  pages        = {112545},
  shortjournal = {Automatica},
  title        = {Controller synthesis from noisy-input noisy-output data},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accuracy bounds for the simulation of a class of continuous-time nonlinear models. <em>AUTOM</em>, <em>183</em>, 112543. (<a href='https://doi.org/10.1016/j.automatica.2025.112543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world dynamic systems evolve in the continuous-time world, while their models are simulated in the digital world using discrete-time numerical simulation algorithms. Such simulation is essential for a variety of system and control problems such as system identification and performance analysis of (control) systems. Ideally, the simulated model response should be identical to the system response. However, this is typically not the case in practice, even when the effects of unmodelled dynamics and parametric uncertainty are excluded. Even in that scenario, a mismatch exists between the response of the system and the model due to the interface between the physical world and the digital computer, unknown disturbances, and simulation inaccuracies. For the class of continuous-time, nonlinear Lur’e-type systems, this paper analyses the mismatch between the steady-state system response and the steady-state model response computed using the so-called mixed time–frequency algorithm. Firstly, a bound on the mismatch between the steady-state system response and the computed steady-state model response based on continuous-time signals is derived. Secondly, a bound for the same mismatch is derived for a sampled version of the signals. The bounds are further decomposed into several components, each given an interpretation that can be used to reduce the bounds on the mismatch. In a numerical case study, we show that reducing the bounds also reduces the actual mismatch.},
  archive      = {J_AUTOM},
  author       = {Fahim Shakib and Johan Schoukens and Alexander Yu. Pogromsky and Alexey Pavlov and Nathan van de Wouw},
  doi          = {10.1016/j.automatica.2025.112543},
  journal      = {Automatica},
  month        = {1},
  pages        = {112543},
  shortjournal = {Automatica},
  title        = {Accuracy bounds for the simulation of a class of continuous-time nonlinear models},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revisiting lossless convexification: Theoretical guarantees for discrete-time optimal control problems. <em>AUTOM</em>, <em>183</em>, 112537. (<a href='https://doi.org/10.1016/j.automatica.2025.112537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lossless Convexification (LCvx) is a modeling approach that transforms a class of nonconvex optimal control problems, where nonconvexity primarily arises from control constraints, into convex problems through convex relaxations. These convex problems can be solved using polynomial-time numerical methods after discretization, which converts the original infinite-dimensional problem into a finite-dimensional one. However, existing LCvx theory is limited to continuous-time optimal control problems, as the equivalence between the relaxed convex problem and the original nonconvex problem holds only in continuous-time. This paper extends LCvx theory to discrete-time optimal control problems by classifying them into normal and long-horizon cases. For normal cases, after an arbitrarily small perturbation to the system dynamics (recursive equality constraints), applying the existing LCvx method to discrete-time problems results in optimal controls that meet the original nonconvex constraints at all but no more than n x − 1 temporal grid points, where n x is the state dimension. For long-horizon cases, the existing LCvx method fails, but we resolve this issue by integrating it with a bisection search, leveraging the continuity of the value function from the relaxed convex problem to achieve similar results as in normal cases. This paper strengthens the theoretical foundation of LCvx, extending the applicability of LCvx theory to discrete-time optimal control problems.},
  archive      = {J_AUTOM},
  author       = {Dayou Luo and Kazuya Echigo and Behçet Açıkmeşe},
  doi          = {10.1016/j.automatica.2025.112537},
  journal      = {Automatica},
  month        = {1},
  pages        = {112537},
  shortjournal = {Automatica},
  title        = {Revisiting lossless convexification: Theoretical guarantees for discrete-time optimal control problems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated cubic regularized newton learning with sparsification-amplified differential privacy. <em>AUTOM</em>, <em>183</em>, 112531. (<a href='https://doi.org/10.1016/j.automatica.2025.112531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the cubic-regularized Newton method within a federated learning framework while addressing two major concerns: privacy leakage and communication bottlenecks. We propose the Differentially Private Federated Cubic Regularized Newton (DP-FCRN) algorithm, which leverages second-order techniques to achieve lower iteration complexity than first-order methods. We incorporate noise perturbation during local computations to ensure privacy. Furthermore, we employ sparsification in uplink transmission, which not only reduces the communication costs but also amplifies the privacy guarantee. Specifically, this approach reduces the necessary noise intensity without compromising privacy protection. We analyze the convergence properties of our algorithm and establish the privacy guarantee. Finally, we validate the effectiveness of the proposed algorithm through experiments on a benchmark dataset.},
  archive      = {J_AUTOM},
  author       = {Wei Huo and Changxin Liu and Kemi Ding and Karl Henrik Johansson and Ling Shi},
  doi          = {10.1016/j.automatica.2025.112531},
  journal      = {Automatica},
  month        = {1},
  pages        = {112531},
  shortjournal = {Automatica},
  title        = {Federated cubic regularized newton learning with sparsification-amplified differential privacy},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A consensus kalman filter on l2 spaces. <em>AUTOM</em>, <em>183</em>, 112530. (<a href='https://doi.org/10.1016/j.automatica.2025.112530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the estimation problem of infinite dimensional discrete-time stochastic linear systems with finite dimensional measurements on sensor networks modeled by connected undirected graphs. The framework encompasses discretized PDEs with sampled measurements. A new scheme of distributed consensus on measurements is extended to systems evolving in L 2 spaces in order to limit the information exchange to finite-dimensional vectors. We show that, in analogy to the finite-dimensional case, at each node the variance of the estimation error tends to the one of the centralized Kalman filter for systems is L 2 when the number of consensus steps increases.},
  archive      = {J_AUTOM},
  author       = {Stefano Battilotti and Alessandro Borri and Filippo Cacace and Massimiliano d’Angelo and Alfredo Germani},
  doi          = {10.1016/j.automatica.2025.112530},
  journal      = {Automatica},
  month        = {1},
  pages        = {112530},
  shortjournal = {Automatica},
  title        = {A consensus kalman filter on l2 spaces},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning for safe time-critical verification using reachability analysis. <em>AUTOM</em>, <em>183</em>, 112528. (<a href='https://doi.org/10.1016/j.automatica.2025.112528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a safe time-critical control problem using reachability analysis and design a reinforcement learning-based mechanism for learning online and in fixed-time the solution to the safe time-critical control problem. Safety is ensured by determining a set of states for which there exists an admissible control law generating a system trajectory that does not reach a set of forbidden states at a user-prescribed time instant. Specifically, we cast our safe time-critical problem as a Mayer optimal feedback control problem whose solution satisfies the Hamilton–Jacobi–Bellman (HJB) equation and characterizes the set of safe states. Since the HJB equation is generally difficult to solve, we develop an online critic-only reinforcement learning-based algorithm for simultaneously learning the solution to the HJB equation and the safe set in a fixed time. In particular, we introduce a non-Lipschitz experience replay-based learning law utilizing recorded and current data for updating the critic weights to learn the value function and the safe set. The non-Lipschitz property of the dynamics gives rise to fixed-time convergence, whereas the experience replay-based approach eliminates the need to satisfy the persistence of excitation condition provided that a recorded data set is sufficiently rich. Simulation results illustrate the efficacy of the proposed approach to the problem of fixed-wing unmanned aerial vehicle collision avoidance.},
  archive      = {J_AUTOM},
  author       = {Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis and Wassim M. Haddad},
  doi          = {10.1016/j.automatica.2025.112528},
  journal      = {Automatica},
  month        = {1},
  pages        = {112528},
  shortjournal = {Automatica},
  title        = {Fixed-time learning for safe time-critical verification using reachability analysis},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Orchestrating on-board sensors for global hybrid robust stabilization of unicycles. <em>AUTOM</em>, <em>183</em>, 112502. (<a href='https://doi.org/10.1016/j.automatica.2025.112502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider mobile robots described through unicycle dynamics equipped with on-board range sensors and cameras, one facing forward and one facing backward, providing measurements of the distance and misalignment to a target. We propose a hybrid control law combining the two on-board measurements and discuss stability results for the closed-loop expressed in the on-board camera-based coordinates, using Lyapunov-based arguments. We prove robustness of the stability properties to uncertainties affecting the sensors and external perturbations acting on the robot. The results are illustrated via simulations.},
  archive      = {J_AUTOM},
  author       = {Riccardo Ballaben and Alessandro Astolfi and Philipp Braun and Luca Zaccarian},
  doi          = {10.1016/j.automatica.2025.112502},
  journal      = {Automatica},
  month        = {1},
  pages        = {112502},
  shortjournal = {Automatica},
  title        = {Orchestrating on-board sensors for global hybrid robust stabilization of unicycles},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cma">CMA - 7</h2>
<ul>
<li><details>
<summary>
(2025). An averaged l1 ADI compact difference scheme for the three-dimensional time-fractional mobile/immobile transport equation with weakly singular solutions. <em>CMA</em>, <em>200</em>, 102-116. (<a href='https://doi.org/10.1016/j.camwa.2025.09.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a three-dimensional (3D) time-fractional mobile/immobile (MIM) transport equation, which incorporates the Caputo time-fractional derivative of order α ∈ ( 0 , 1 ) , is taken into consideration. The space derivatives are discretized using the compact finite difference approximation, and the Caputo time-fractional derivative is estimated by employing the averaged L1 formula. Combining with corresponding alternating direction implicit (ADI) algorithms, the overall computational cost is reduced significantly. Using the discrete energy analysis methodology, we demonstrate that the suggested method possesses temporal second-order convergence and spatial fourth-order convergence under the regularity assumption. Numerical experiments demonstrate that ADI techniques is effective in computing 3D problems.},
  archive      = {J_CMA},
  author       = {Kai Liu and Haixiang Zhang and Xuehua Yang},
  doi          = {10.1016/j.camwa.2025.09.019},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {102-116},
  shortjournal = {Comput. Meth. Appl.},
  title        = {An averaged l1 ADI compact difference scheme for the three-dimensional time-fractional mobile/immobile transport equation with weakly singular solutions},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pricing american options with exogenous and endogenous transaction costs. <em>CMA</em>, <em>200</em>, 85-101. (<a href='https://doi.org/10.1016/j.camwa.2025.09.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an American option pricing problem with liquidity risks and transaction fees. As endogenous transaction costs, liquidity risks of the underlying asset are modeled by a mean-reverting process. Transaction fees are exogenous transaction costs and are assumed to be proportional to the trading amount, with the long-run liquidity level depending on the proportional transaction costs rate. Two nonlinear partial differential equations are established to characterize the option values for the holder and the writer, respectively. To illustrate the impact of these transaction costs on option prices and optimal exercise prices, we apply the alternating direction implicit method to solve the linear complementarity problem numerically. Finally, we conduct model calibration from market data via maximum likelihood estimation, and find that our model incorporating liquidity risks outperforms the Leland model significantly.},
  archive      = {J_CMA},
  author       = {Dong Yan and Xin-Jie Huang and Guiyuan Ma and Xin-Jiang He},
  doi          = {10.1016/j.camwa.2025.09.008},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {85-101},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Pricing american options with exogenous and endogenous transaction costs},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A space-time discontinuous petrov-galerkin finite element formulation for a modified schrödinger equation for laser pulse propagation in waveguides. <em>CMA</em>, <em>200</em>, 67-84. (<a href='https://doi.org/10.1016/j.camwa.2025.09.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a modified nonlinear Schrödinger equation for modeling pulse propagation in optical waveguides. The proposed model bifurcates into a system of elliptic and hyperbolic equations depending on waveguide parameters. The proposed model leads to a stable first-order system of equations, distinguishing itself from the canonical nonlinear Schrödinger equation. We have employed the space-time discontinuous Petrov-Galerkin finite element method to discretize the first-order system of equations. We present a stability analysis for both the elliptic and hyperbolic systems of equations and demonstrate the stability of the proposed model through several numerical examples on space-time meshes.},
  archive      = {J_CMA},
  author       = {A. Chakraborty and J. Muñoz-Matute and L. Demkowicz and J. Grosek},
  doi          = {10.1016/j.camwa.2025.09.004},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {67-84},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A space-time discontinuous petrov-galerkin finite element formulation for a modified schrödinger equation for laser pulse propagation in waveguides},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence analysis of an energy-stable linearized virtual element method for the strongly damped klein-gordon equation. <em>CMA</em>, <em>200</em>, 49-66. (<a href='https://doi.org/10.1016/j.camwa.2025.09.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and analyze an efficient, linearized, fully discrete scheme for the nonlinear, strongly damped Klein-Gordon equation on polygonal meshes. The numerical scheme uses a conforming virtual element method for spatial discretization and a modified leapfrog (central finite difference) scheme for time discretization, with the nonlinear term | u | p − 1 u is treated semi-implicitly. We first prove that the proposed scheme is energy dissipative in the sense of discrete energy, and then the stability of the numerical solution in the H 1 -norm is established using mathematical induction, which plays an important role in handling the nonlinear term. By applying the boundedness of the numerical solution and the Sobolev embedding inequality, we derive the optimal H 1 error estimate of order O ( h k + τ 2 ) without imposing any ratio restrictions between the time step τ and the mesh size h . Additionally, we remark that the leapfrog virtual element scheme can be applied to some more complex nonlinear damped wave equations. Finally, some numerical examples are provided to confirm the theoretical results.},
  archive      = {J_CMA},
  author       = {Zhixin Liu and Minghui Song and Yuhang Zhang},
  doi          = {10.1016/j.camwa.2025.09.002},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {49-66},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Convergence analysis of an energy-stable linearized virtual element method for the strongly damped klein-gordon equation},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A posteriori error estimate of the discontinuous galerkin method with lagrange multiplier for elliptic problems. <em>CMA</em>, <em>200</em>, 38-48. (<a href='https://doi.org/10.1016/j.camwa.2025.09.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to derive and analyze an a posteriori error estimator for the solution of the discontinuous Galerkin method with Lagrange multiplier (DGLM) for the elliptic problems with nonhomogeneous Dirichlet boundary condition u = g for g in H 1 / 2 ( ∂ Ω ) . A general version of the DGLM method is derived. Strong stability of the solution of the DGLM method is proved. Edgewise iterative scheme for the general DGLM method is described.},
  archive      = {J_CMA},
  author       = {Mi-Young Kim},
  doi          = {10.1016/j.camwa.2025.09.005},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {38-48},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A posteriori error estimate of the discontinuous galerkin method with lagrange multiplier for elliptic problems},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability and convergence analysis of mixed finite element approximations for a biot-brinkman model. <em>CMA</em>, <em>200</em>, 22-37. (<a href='https://doi.org/10.1016/j.camwa.2025.09.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many multiphysics processes of fluid-solid interaction within a porous medium can be described by the Biot-Brinkman model to account for the effects of viscosity in fluid flow. By introducing the auxiliary variables, we can transform the original problem into two generalized Stokes equations. The generalized Stokes equations incorporate a built-in mechanism to circumvent the Poisson locking for the continuous Galerkin method. Subsequently, we establish an energy law and provide a priori estimates for the reformulated problem. Well-posedness is demonstrated using the standard Galerkin method in conjunction with a compactness argument. After that, we develop stable mixed finite element algorithms for the reformulated problem. Influenced by Lamé constant λ , we design three finite element pairs for the proposed algorithms and present the corresponding error estimates. Numerical tests are conducted to validate the theoretical results.},
  archive      = {J_CMA},
  author       = {Wenlong He and Jiwei Zhang},
  doi          = {10.1016/j.camwa.2025.09.006},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {22-37},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Stability and convergence analysis of mixed finite element approximations for a biot-brinkman model},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed neural network for option pricing weather derivatives model. <em>CMA</em>, <em>200</em>, 1-21. (<a href='https://doi.org/10.1016/j.camwa.2025.09.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weather derivatives are financial tools that use a weather index as the underlying asset to provide protection against non-catastrophic weather events. In this article, we propose a physics-informed neural network (PINN) approach for pricing weather derivatives associated with two standard processes: the Ornstein-Uhlenbeck process and the Ornstein-Uhlenbeck process with jump-diffusions. PINNs are a scientific machine learning method specifically designed to address problems related to partial differential equations (PDEs). To apply the PINN technique for jump-diffusion, we convert the partial integro-differential equation into a PDE using integral discretization. We randomly select training data points within the domain and utilize the transformed PDE along with the initial and boundary conditions to construct the loss function. For the neurons in the hidden layer, we employ the hyperbolic tangent function (tanh) as the activation function. The weights of the network connection are optimized using the L-BFGS algorithm. We will conduct numerical experiments to evaluate the efficiency of the proposed technique. Additionally, we compare our method with conventional numerical approaches to show that our technique serves as an effective alternative to existing pricing methods for weather derivatives. Finally, we will examine a real-world case study where the model's parameters are determined using precipitation data.},
  archive      = {J_CMA},
  author       = {Saurabh Bansal and Pradanya Boro and Srinivasan Natesan},
  doi          = {10.1016/j.camwa.2025.09.001},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {1-21},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Physics-informed neural network for option pricing weather derivatives model},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cmame">CMAME - 48</h2>
<ul>
<li><details>
<summary>
(2025). Structural transient dynamic topology optimization based on autoencoder-enhanced generative adversarial network and elitist guidance evolutionary algorithm. <em>CMAME</em>, <em>447</em>, 118417. (<a href='https://doi.org/10.1016/j.cma.2025.118417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural transient dynamic optimization faces significant challenges stemming from material nonlinearities and geometric nonlinearities induced by large deformations. These nonlinear phenomena severely complicate gradient-based sensitivity analysis, while conventional non-gradient optimization approaches face limitations including prohibitive computational demands, suboptimal solution quality, and compromised robustness. To overcome these challenges, we present an integrated computational framework synergistically combining an autoencoder-enhanced generative adversarial network with an elitist guidance evolutionary algorithm for nonlinear dynamic optimization. The developed multi-fidelity surrogate modeling architecture achieves dual enhancement in computational efficiency and solution diversity, while the elitism-preserving mechanism in elitist guidance evolutionary algorithm ensures superior convergence characteristics. Furthermore, we introduce a self-supervised criterion noise rate metric for quantitatively evaluating structural performance under transient loads. Results demonstrate that the proposed method improves structural clarity and diversity by 18.56 and 21.55 times compared to conventional methods. Case studies with both cantilever and fixed-end beams across dynamic loading regimes confirm the method’s generalizability. This framework is easily transferable to other engineering fields, offering new insights for solving transient nonlinear problems.},
  archive      = {J_CMAME},
  author       = {Haojie Ma and Xiao Kang and Yixing Huang and Shengyu Duan and Ying Li and Daining Fang},
  doi          = {10.1016/j.cma.2025.118417},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118417},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Structural transient dynamic topology optimization based on autoencoder-enhanced generative adversarial network and elitist guidance evolutionary algorithm},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GALDS: A graph-autoencoder-based latent dynamics surrogate model to predict neurite material transport. <em>CMAME</em>, <em>447</em>, 118409. (<a href='https://doi.org/10.1016/j.cma.2025.118409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurons exhibit intricate geometries within their neurite networks, which play a crucial role in processes such as signaling and nutrient transport. Accurate simulation of material transport in the networks is essential for understanding these biological phenomena but poses significant computational challenges because of the complex tree-like structures involved. Traditional approaches are time-intensive and resource-demanding, yet the inherent properties of neuron trees, which consists primarily of pipes with steady-state parabolic velocity profiles and bifurcations, provide opportunities for computational optimization. To address these challenges, we propose a Graph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which is specifically designed to streamline the simulation of material transport in neural trees. GALDS employs a graph autoencoder to encode latent representations of the network’s geometry, velocity fields, and concentration profiles. These latent space representations are then assembled into a global graph, which is subsequently used to predict system dynamics in the latent space via a trained graph latent space system dynamic model, inspired by the Neural Ordinary Differential Equations (Neural ODEs) concept. The integration of an autoencoder allows for the use of smaller graph neural network models with reduced training data requirements. Furthermore, the Neural ODE component effectively mitigates the issue of error accumulation commonly encountered in recurrent neural networks. The effectiveness of the GALDS model is demonstrated through results on eight unseen geometries and four abnormal transport examples, where our approach achieves mean relative error of 3 % with maximum relative error < 8 % and demonstrates a 10-fold speed improvement compared to previous surrogate model approaches.},
  archive      = {J_CMAME},
  author       = {Tsung Yeh Hsieh and Yongjie Jessica Zhang},
  doi          = {10.1016/j.cma.2025.118409},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118409},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {GALDS: A graph-autoencoder-based latent dynamics surrogate model to predict neurite material transport},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral-element SBPML for 3D infinite transient wave problems. <em>CMAME</em>, <em>447</em>, 118407. (<a href='https://doi.org/10.1016/j.cma.2025.118407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops a novel spectral-element scaled boundary perfectly matched layer (SBPML) coupled the spectral elements method (SEM) to simulate wave problems in 3D unbounded domains. The SBPML can accommodate boundary of general shapes and consider the planar physical interfaces and surfaces that extend infinitely. Furthermore, it supports direct coupling with 3D spectral elements of any orders in interior domain, leading to significantly higher computation accuracy. The spectral-element SBPML can flexibly and adaptively adjust the elements orders within the SBPML domain according to those used in the finite domain. Moreover, by generalizing the flexibility matrix, this method can model 3D transversely isotropic (TI) unbounded media, thereby enhancing its applicability to realistic geological scenarios. Firstly, quadrilateral spectral element shape functions are introduced in the circumferential direction of scaled boundary coordinates, which is compatible with 3D spectral elements of any orders of the finite domain. Subsequently, a complex coordinate stretching function is introduced along the radial direction, transforming the unbounded domain into a complex-valued space that defines the SBPML domain. This SBPML formulation employs a 2nd-order mixed unsplit-field displacement-stress form via spatial discretization of the SBPML domain. This mixed element is formulated by using shape functions of an n -th order spectral element for the displacement field and an ( n -1)-th order element for the auxiliary stress field. This method allows for the use of different interpolation orders along the radial and circumferential directions in SBPML, achieving an optimal balance between numerical accuracy and computational efficiency. Ultimately, the accuracy, convergence, and robustness of the proposed approach are validated by three wave propagation problems and two seismic response analyses of complex sites.},
  archive      = {J_CMAME},
  author       = {Junru Zhang and Mi Zhao and Guoliang Zhang and Junqi Zhang and Xiuli Du},
  doi          = {10.1016/j.cma.2025.118407},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118407},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Spectral-element SBPML for 3D infinite transient wave problems},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A polytopal discontinuous galerkin method for the pseudo-stress formulation of the unsteady stokes problem. <em>CMAME</em>, <em>447</em>, 118404. (<a href='https://doi.org/10.1016/j.cma.2025.118404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to construct and analyze a discontinuous Galerkin method on polytopal grids (PolydG) to solve the pseudo-stress formulation of the unsteady Stokes problem. The pseudo-stress variable is introduced due to the growing interest in non-Newtonian flows and coupled interface problems, where stress assumes a fundamental role. The space-time discretization of the problem is achieved by combining the PolydG approach with the implicit θ -method time integration scheme. For both the semi- and fully-discrete problems we present a detailed stability analysis. Moreover, we derive convergence estimates for the fully discrete space-time discretization. A set of verification tests is presented to verify the theoretical estimates and the application of the method to cases of engineering interest.},
  archive      = {J_CMAME},
  author       = {Paola F. Antonietti and Michele Botti and Alessandra Cancrini and Ilario Mazzieri},
  doi          = {10.1016/j.cma.2025.118404},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118404},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A polytopal discontinuous galerkin method for the pseudo-stress formulation of the unsteady stokes problem},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anant-net: Breaking the curse of dimensionality with scalable and interpretable neural surrogate for high-dimensional PDEs. <em>CMAME</em>, <em>447</em>, 118403. (<a href='https://doi.org/10.1016/j.cma.2025.118403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional partial differential equations (PDEs) arise in diverse scientific and engineering applications but remain computationally intractable due to the curse of dimensionality. Traditional numerical methods struggle with the exponential growth in computational complexity, particularly on hypercubic domains, where the number of required collocation points increases rapidly with dimensionality. Here, we introduce Anant-Net , an efficient neural surrogate that overcomes this challenge, enabling the solution of PDEs in high dimensions. Unlike hyperspheres, where the internal volume diminishes as dimensionality increases, hypercubes retain or expand their volume (for unit or larger length), making high-dimensional computations significantly more demanding. Anant-Net efficiently incorporates high-dimensional boundary conditions and minimizes the PDE residual at high-dimensional collocation points. To enhance interpretability, we integrate Kolmogorov-Arnold networks into the Anant-Net architecture. We benchmark Anant-Net’s performance on several linear and nonlinear high-dimensional equations, including the Poisson, Sine-Gordon, and Allen-Cahn equations, as well as transient heat equations, demonstrating high accuracy and robustness across randomly sampled test points from high-dimensional spaces. Importantly, Anant-Net achieves these results with remarkable efficiency, solving 300-dimensional problems on a single GPU within a few hours. We also compare Anant-Net’s results for accuracy and runtime with other state-of-the-art methods. Our findings establish Anant-Net as an accurate, interpretable, and scalable framework for efficiently solving high-dimensional PDEs. The Anant-Net code is available at https://github.com/ParamIntelligence/Anant-Net .},
  archive      = {J_CMAME},
  author       = {Sidharth S. Menon and Ameya D. Jagtap},
  doi          = {10.1016/j.cma.2025.118403},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118403},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Anant-net: Breaking the curse of dimensionality with scalable and interpretable neural surrogate for high-dimensional PDEs},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rigorous error analysis of ETDRK4P-SAV scheme for the allen-cahn equation. <em>CMAME</em>, <em>447</em>, 118398. (<a href='https://doi.org/10.1016/j.cma.2025.118398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel numerical method for the Allen-Cahn (AC) equation. By combining the dimension-splitting technique with the fourth-order exponential time-differencing Runge-Kutta(ETDRK)-scalar auxiliary variable (SAV) extrapolation method, we construct a fourth-order accurate ETDRK4P-SAV scheme with energy decay property. In terms of spatial discretization, a fourth-order central difference combined with dimension-splitting technique is employed; for temporal discretization, a fourth-order ETDRK-SAV extrapolation method based on the Padé approximation is utilized. From a theoretical perspective, we rigorously prove that the fully discrete scheme preserves the maximum principle, energy decay property and unique solvability, while also establishing the optimal error estimation theory. Numerical experimental results show that this scheme not only has good convergence but also maintains the discrete energy dissipation property, verifying its effectiveness and reliability in solving the AC equation.},
  archive      = {J_CMAME},
  author       = {Xiaoyan Li and Xinlong Feng and Lingzhi Qian},
  doi          = {10.1016/j.cma.2025.118398},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118398},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Rigorous error analysis of ETDRK4P-SAV scheme for the allen-cahn equation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition-free variational quantum linear solver: Application in computational mechanics. <em>CMAME</em>, <em>447</em>, 118396. (<a href='https://doi.org/10.1016/j.cma.2025.118396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving a linear system of equations is a fundamental task in computational mechanics. The recently proposed variational quantum linear solver (VQLS) offers potential acceleration for this task by using quantum computing. However, its application faces a critical bottleneck: the costly requirement to decompose the coefficient matrix into a linear combination of unitary matrices. In this work, we propose a decomposition-free variational quantum linear solver (DF-VQLS) that eliminates this requirement, enabling direct application without matrix decomposition. The key innovation lies in proposing two vectorization techniques, which map the cost functions of VQLS to the inner product of vectors. Specifically, the vectorization techniques reshape the matrix into a vector, and only manipulations on the vector are needed to compute the cost functions, thereby eliminating matrix decomposition entirely. The convergence and accuracy of the proposed method are validated through numerical examples on a quantum simulator. Three application examples in computational mechanics, including bar, truss, and two-dimensional continuum problems, are also presented to show the potential feasibility.},
  archive      = {J_CMAME},
  author       = {Yongchun Xu and Heng Hu},
  doi          = {10.1016/j.cma.2025.118396},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118396},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Decomposition-free variational quantum linear solver: Application in computational mechanics},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-order time-marching schemes for incompressible flow in particle methods. <em>CMAME</em>, <em>447</em>, 118395. (<a href='https://doi.org/10.1016/j.cma.2025.118395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents novel high-order time-marching schemes for simulating incompressible flow in particle methods. The proposed schemes are based on a newly developed formulation that describes the time evolution of computational variables along particle trajectories, resulting in a new form of the pressure Poisson equation. This formulation enables the direct application of existing forward-advancing time integration schemes, such as explicit Runge–Kutta methods, to achieve high-order temporal accuracy. Furthermore, the proposed schemes are generalized for arbitrary particle movement, enabling the efficient incorporation of particle shifting without requiring additional particle movement or variable corrections. By applying Runge–Kutta methods, this study presents four single- or multistage schemes referred to as RK1–RK4, corresponding to the number of stages. The validity of the proposed schemes is rigorously evaluated through numerical investigations involving four test cases and three types of particle movement (Lagrangian, Eulerian, and quasi-Lagrangian). The results reveal that the proposed RK2, RK3, and RK4 schemes achieve second-, third-, and fourth-order temporal convergence, respectively, and exhibit substantially higher accuracy than conventional first-order schemes, leading to improved volume and energy conservation. In addition, the proposed schemes demonstrate high computational efficiency, indicating their practical value for the numerical analysis of incompressible flow.},
  archive      = {J_CMAME},
  author       = {Takuya Matsunaga},
  doi          = {10.1016/j.cma.2025.118395},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118395},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {High-order time-marching schemes for incompressible flow in particle methods},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantized local reduced-order modeling in time (ql-ROM). <em>CMAME</em>, <em>447</em>, 118393. (<a href='https://doi.org/10.1016/j.cma.2025.118393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporally chaotic systems, such as the solutions of some nonlinear partial differential equations, are dynamical systems that evolve toward a lower dimensional manifold. This manifold has an intricate geometry with heterogeneous density, which makes the design of a single (global) nonlinear reduced-order model (ROM) challenging. In this paper, we turn this around. Instead of modeling the manifold with one single model, we partition the manifold into clusters within which the dynamics are locally modeled. This results in a quantized local reduced-order model (ql-ROM), which consists of (i) quantizing the manifold via unsupervised clustering; (ii) constructing intrusive ROMs for each cluster; and (iii) connecting the switching of local models with a change of basis and assignment functions. We test the method on two nonlinear partial differential equations, i.e., the Kuramoto-Sivashinsky and 2D Navier-Stokes equations (Kolmogorov flow), across bursting, chaotic, quasiperiodic, and turbulent regimes. The local models are built via Galerkin projection onto the local principal directions, which are centered on the cluster centroids. The dynamics are modeled by switching the local ROMs based on the cluster proximity. The proposed ql-ROM framework has three advantages over global ROMs (g-ROMs): (i) numerical stability, (ii) improved short-term prediction accuracy in time, and (iii) accurate prediction of long-term statistics, such as energy spectra and probability distributions. The computational overhead is minimal with respect to g-ROMs. The proposed framework retains the interpretability and simplicity of intrusive projection-based ROMs, whilst overcoming their limitations in modeling complex, high-dimensional, nonlinear dynamics.},
  archive      = {J_CMAME},
  author       = {Antonio Colanera and Luca Magri},
  doi          = {10.1016/j.cma.2025.118393},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118393},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Quantized local reduced-order modeling in time (ql-ROM)},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Isogeometric analysis for non-newtonian viscoplastic fluids: Challenges for non-smooth solutions. <em>CMAME</em>, <em>447</em>, 118386. (<a href='https://doi.org/10.1016/j.cma.2025.118386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores the application of high-order Isogeometric Analysis (IGA) to the numerical simulation of non-Newtonian viscoplastic fluids, particularly in the presence of yield surfaces and non-smooth solutions. While IGA has demonstrated superior accuracy in smooth problems due to its high-continuity basis functions, its performance in cases with sharp transitions, such as viscoplastic flows with localized singularities, presents unique challenges. To address this, we develop a stabilized isogeometric framework for viscoplastic Stokes flow using the Variational Multiscale (VMS) method, ensuring numerical stability and preventing spurious pressure oscillations in equal-order discretizations. Additionally, we integrate an embedded boundary approach based on the Shifted Boundary Method (SBM) to efficiently handle complex geometries without the need for body-fitted meshes. The effectiveness of this high-order stabilized IGA framework is assessed through numerical benchmarks. The results confirm that high-order B-Spline bases achieve optimal convergence in smooth regions, while their performance near yield surfaces is affected by localized oscillations due to the inherent continuity of the basis functions. Furthermore, we demonstrate that the SBM-IGA formulation successfully enforces boundary conditions in embedded domains while preserving high-order accuracy. These findings provide valuable insights into the role of basis smoothness, stabilization techniques, and embedded formulations in non-Newtonian flow simulations, offering a foundation for future advancements in isogeometric methods for complex fluids.},
  archive      = {J_CMAME},
  author       = {Nicolò Antonelli and Andrea Gorgi and Rubén Zorrilla and Riccardo Rossi},
  doi          = {10.1016/j.cma.2025.118386},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118386},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Isogeometric analysis for non-newtonian viscoplastic fluids: Challenges for non-smooth solutions},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-fidelity modelling of floor-borne vibrations in axisymmetric MRI magnets using hp-finite element method. <em>CMAME</em>, <em>447</em>, 118385. (<a href='https://doi.org/10.1016/j.cma.2025.118385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic Resonance Imaging (MRI) relies on the stability of highly uniform fields from superconducting main coils and spatially varying fields from AC-driven gradient coils. Both types of coils are thermally separated, as the main coils are cryogenically cooled within a cryostat whilst gradient coils operate at room temperature. Externally generated floor-borne vibrations (FBV) can induce relative motion between radiation shields and coils, generating eddy currents in the shields. These in turn produce parasitic magnetic fields that compromise field homogeneity and degrade image quality. This paper presents a high-fidelity computational framework for simulating the magneto-mechanical effects of FBV in axisymmetric MRI scanners to inform the manufacturing design workflow. The approach introduces three key advancements: first , a nonlinear, fully coupled magneto-mechanical formulation solved using h p -Finite Element Methods ( h p -FEM) in the open-source NGSolve framework, with a focus on optimal interpolation order p and time step size; second , explicit mechanical modelling of both main and gradient coils, moving beyond idealised Biot-Savart type current sources; and third , the use of realistic axisymmetric geometries with structural connectivity between coils and radiation shields in order to inform preliminary designs in Industry. A comprehensive series of numerical results is presented in order to validate the method against some benchmarked scenarios and highlight its potential for guiding vibration mitigation and improving MRI image fidelity.},
  archive      = {J_CMAME},
  author       = {Yashwanth Sooriyakanthan and Antonio J. Gil and Paul D. Ledger and Michael J. Mallett},
  doi          = {10.1016/j.cma.2025.118385},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118385},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {High-fidelity modelling of floor-borne vibrations in axisymmetric MRI magnets using hp-finite element method},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite deformation analysis of flexoelectric shells. <em>CMAME</em>, <em>447</em>, 118384. (<a href='https://doi.org/10.1016/j.cma.2025.118384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a nonlinear shell model for the coupled mechanical and electrical analysis of thin flexoelectric polymers is developed. In addition to the classical terms, contributions from the second gradient of deformation, electro-mechanical coupling and flexoelectricity are incorporated into the free energy density of these materials. Furthermore, starting from a variational framework, a nonlinear finite element formulation in the material setting is developed to provide numerical solutions for various problems. By neglecting the electrical and flexoelectric effects, the present formulation can reflect the deformation of purely mechanical gradient shells. Conversely, by disregarding the gradient and flexoelectric effects, the present formulation is greatly capable of modeling the deformation of electro-active shells. The midsurface displacement and director difference vectors are interpolated using C 1 shape functions, while C 0 -continuous interpolation functions are used for the thickness stretching and voltage parameters. Several numerical examples are solved to evaluate performance and robustness of the proposed formulation. The results show that the present formulation yields excellent agreement with those available in the literature. Moreover, the proposed formulation effectively captures the flexoelectric response of both initially flat and initially curved thin structures experiencing finite deformations.},
  archive      = {J_CMAME},
  author       = {Farzam Dadgar-Rad and Shahab Sahraee and Mokarram Hossain and Stefan Hartmann},
  doi          = {10.1016/j.cma.2025.118384},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118384},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Finite deformation analysis of flexoelectric shells},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symplectic hamiltonian hybridizable discontinuous galerkin methods for linearized shallow water equations. <em>CMAME</em>, <em>447</em>, 118383. (<a href='https://doi.org/10.1016/j.cma.2025.118383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the numerical approximation of the linearized shallow water equations using hybridizable discontinuous Galerkin (HDG) methods, leveraging the Hamiltonian structure of the evolution system. First, we propose an equivalent formulation of the equations by introducing an auxiliary variable. Then, we discretize the space variables using HDG methods, resulting in a semi-discrete scheme that preserves a discrete version of the Hamiltonian structure. The use of an alternative formulation with the auxiliary variable is crucial for developing the HDG scheme that preserves this Hamiltonian structure. The resulting system is subsequently discretized in time using symplectic integrators, ensuring the energy conservation of the fully discrete scheme. We present numerical experiments that demonstrate optimal convergence rates for all variables and showcase the conservation of total energy, as well as the evolution of other physical quantities.},
  archive      = {J_CMAME},
  author       = {Cristhian Núñez and Manuel A. Sánchez},
  doi          = {10.1016/j.cma.2025.118383},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118383},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Symplectic hamiltonian hybridizable discontinuous galerkin methods for linearized shallow water equations},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear model reduction using spectral proper orthogonal decomposition. <em>CMAME</em>, <em>447</em>, 118382. (<a href='https://doi.org/10.1016/j.cma.2025.118382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most model reduction methods reduce the state dimension and then temporally evolve a set of coefficients that encode the state in the reduced representation. In this paper, we instead employ an efficient representation of the entire trajectory of the state over some time interval of interest and then solve for the static coefficients that encode the trajectory on the interval. We use spectral proper orthogonal decomposition (SPOD) modes, which are provably optimal for representing long trajectories and substantially outperform any representation of the trajectory in a purely spatial basis (e.g., POD). We develop a method to solve for the SPOD coefficients that encode the trajectories for forced linear dynamical systems given the forcing and initial condition, thereby obtaining the accurate prediction of the dynamics afforded by the SPOD representation of the trajectory. The method, which we refer to as spectral solution operator projection (SSOP), is derived by projecting the general time-domain solution for a linear time-invariant system onto the SPOD modes. We demonstrate the new method using two examples: a linearized Ginzburg-Landau equation and an advection-diffusion problem. In both cases, the error of the proposed method is orders of magnitude lower than that of POD-Galerkin projection and balanced truncation. The method is also fast, with CPU time comparable to or lower than both benchmarks in our examples. Finally, we describe a data-free space-time method that is a derivative of the proposed method and show that it is also more accurate than balanced truncation in most cases.},
  archive      = {J_CMAME},
  author       = {Peter Frame and Cong Lin and Oliver T. Schmidt and Aaron Towne},
  doi          = {10.1016/j.cma.2025.118382},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118382},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Linear model reduction using spectral proper orthogonal decomposition},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A phase-field cohesive fracture model free from the length scale constraints. <em>CMAME</em>, <em>447</em>, 118374. (<a href='https://doi.org/10.1016/j.cma.2025.118374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In conventional phase-field cohesive fracture methods, an upper bound on the phase-field length scale parameter is typically imposed to ensure the convexity of the energy degradation function. However, this constraint can result in substantial computational costs when analyzing large-scale structures, geological fractures, or fractures in high-strength materials. To overcome this limitation, this work introduces a novel field variable that guarantees the convexity of the energy degradation function is always satisfied, thereby eliminating the physical constraint on the phase-field length scale parameter. Based on this innovation, a new class of phase-field cohesive fracture models is formulated using a variational approach, and the intrinsic relationship between the characteristic function and the cohesive law is established through the one-dimensional analytical solution. Both implicit and explicit dynamic algorithms are developed for the numerical implementation of the model. The effectiveness and robustness of the proposed approach are demonstrated through simulations of several typical fracture problems. The results indicate that the model can efficiently and accurately address large-scale fracture and high-strength material failure analyses, while maintaining insensitivity to the phase-field length scale parameter in both static and dynamic cases. These findings highlight the model’s potential for broad application in the computational analysis of complex fracture phenomena.},
  archive      = {J_CMAME},
  author       = {Lu Hai and Ye Feng},
  doi          = {10.1016/j.cma.2025.118374},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118374},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A phase-field cohesive fracture model free from the length scale constraints},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Full-scale topology optimization for dynamic responses of functionally graded porous infill designs using nitsche-type multi-patch isogeometric analysis. <em>CMAME</em>, <em>447</em>, 118365. (<a href='https://doi.org/10.1016/j.cma.2025.118365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Porous structures, with their outstanding mechanical properties, play a crucial role in engineering applications and are an important consideration in material distribution optimization for structural dynamic performance. Recently, Isogeometric Analysis (IGA) has gained significant interest due to precise geometric representation, high-order continuity, and flexible topology evolution capabilities. Hence, this study proposes a novel infill design approach through a periodic constraint strategy in multiple Non-Uniform Rational B-Splines (NURBS) patches for two dynamic topology optimization problems, namely eigenfrequency maximization and dynamic compliance minimization. By coupling multiple NURBS patches in a conforming mesh, the complexity of the structural design domain is effectively enhanced. The Nitsche-type dynamic formulation is introduced within the IGA framework, and the theoretical analysis of the stabilization condition is performed. Furthermore, the periodic constraint strategy is imposed onto NURBS patches within the specified parameter direction, which controls the sensitivity update values of the objective function across these patches to generate a gradient porous structure. The global topology is described by the Density Distribution Function (DDF) to achieve full-scale topology optimization. The Multi-frequency Quasi-Static Ritz Vector (MQSRV) method is used to reduce the computational cost associated with dynamic problems. The mathematical models for the dynamic compliance minimization and the eigenfrequency maximization are established, where the sensitivity analysis is derived in detail. Finally, the optimized results produced by the work are fully applicable to complex structural design domains and exhibit well-defined boundaries and smooth gradient distributions. Several numerical examples are presented to demonstrate the effectiveness of the proposed multi-patch isogeometric topology optimization infill design method.},
  archive      = {J_CMAME},
  author       = {Zhen Yang and Liang Gao and Haibin Tang and Jie Gao},
  doi          = {10.1016/j.cma.2025.118365},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118365},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Full-scale topology optimization for dynamic responses of functionally graded porous infill designs using nitsche-type multi-patch isogeometric analysis},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel meshfree superconvergent gradient smoothing stabilized collocation method (GSSCM) for large deformation problems: A concise discretized form. <em>CMAME</em>, <em>447</em>, 118364. (<a href='https://doi.org/10.1016/j.cma.2025.118364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The strong form Direct Collocation Method (DCM) with Reproducing Kernel (RK) shape function is hindered in its development due to its computational complexity and low efficiency in derivative calculations. Furthermore, the nonlinear large deformation governing equations in strong form, which involve intricate derivative terms, introduce additional challenges for discretization and iterative solutions. This paper proposes a novel efficient and superconvergent Gradient Smoothing Stabilized Collocation Method (GSSCM) using RK shape function. Based upon the divergence theorem, the proposed method converts traditional subdomain integration in the Stabilized Collocation Method (SCM) into subdomain boundary integration by gradient smoothing, which reduces the order of derivatives and simplifies the discretized terms of governing equations. This allows RK shape function with low-order basis functions like the linear basis functions, and enhances computational efficiency. GSSCM ensures exact integration using low-order Gaussian quadrature and improves solution stability. Both conforming and non-conforming smoothing domain are constructed for the gradient smooth. The incremental Newton-Raphson iteration approach is employed to solve the nonlinear discrete equations. Numerical results demonstrate that the proposed approach achieves superconvergent rates when odd RK basis functions are used. The GSSCM can also outperform traditional DCM, SCM and Superconvergent Gradient Smoothing Meshfree Collocation (SGSMC) method with gradient smoothing of shape function in terms of computational efficiency under the same accuracy. Moreover, GSSCM-II with conforming integration subdomains generally outmatches GSSCM-I and SCM with non-conforming subdomains in accuracy, efficiency and stability. The advantages of GSSCMs hold significant promise for nonlinear solid mechanics and engineering applications.},
  archive      = {J_CMAME},
  author       = {Zhiyuan Xue and Lihua Wang and Yan Li and Magd Abdel Wahab},
  doi          = {10.1016/j.cma.2025.118364},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118364},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A novel meshfree superconvergent gradient smoothing stabilized collocation method (GSSCM) for large deformation problems: A concise discretized form},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-motivated geometric method for overheating prevention in topology optimization for additive manufacturing. <em>CMAME</em>, <em>447</em>, 118363. (<a href='https://doi.org/10.1016/j.cma.2025.118363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designs generated by topology optimization are often geometrically too complex for conventional manufacturing techniques. While additive manufacturing holds promise for producing such complex designs, several manufacturability constraints must be addressed, including overhang and overheating. Unlike the well-studied overhang constraints, which can be described geometrically, overheating lacks a straightforward and reliable geometric characterization and therefore requires thermal process simulations to identify regions prone to it. However, these simulations are computationally expensive and thus unsuitable for topology optimization, which involves numerous design evaluations. This paper proposes a computationally efficient alternative for detecting zones prone to overheating. The key idea is to estimate local thermal conductivity—and thereby potential overheating—by analyzing the local material distribution. This geometric approach provides a physically motivated approximation of thermal behavior. The method is then integrated into topology optimization, resulting in optimized structures that exhibit clear heat conduction paths to the baseplate. Comparisons with high-fidelity thermal simulations demonstrate the effectiveness and efficiency of the proposed method in mitigating overheating in topology optimization.},
  archive      = {J_CMAME},
  author       = {Manabendra Nath Das and Rajit Ranjan and Kai Wu and Jun Wu and Can Ayas},
  doi          = {10.1016/j.cma.2025.118363},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118363},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A physics-motivated geometric method for overheating prevention in topology optimization for additive manufacturing},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual element methods for HJB equations with cordes coefficients. <em>CMAME</em>, <em>447</em>, 118362. (<a href='https://doi.org/10.1016/j.cma.2025.118362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and analyze both conforming and nonconforming virtual element methods (VEMs) for the fully nonlinear second-order elliptic Hamilton-Jacobi-Bellman (HJB) equations with Cordes coefficients. By incorporating stabilization terms, we establish the well-posedness of the proposed methods, thus avoiding the need to construct a discrete Miranda-Talenti estimate. We derive the optimal error estimate in the discrete H 2 norm for both numerical formulations. Furthermore, a semismooth Newton’s method is employed to linearize the discrete problems. Several numerical experiments using the lowest-order VEMs are provided to demonstrate the efficacy of the proposed methods and to validate our theoretical results.},
  archive      = {J_CMAME},
  author       = {Ying Cai and Hailong Guo and Zhimin Zhang},
  doi          = {10.1016/j.cma.2025.118362},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118362},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Virtual element methods for HJB equations with cordes coefficients},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provably third-order energy stable adaptive algorithm for modeling square pattern in phase field crystal. <em>CMAME</em>, <em>447</em>, 118361. (<a href='https://doi.org/10.1016/j.cma.2025.118361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Square pattern emerges widely in crystallography, ranging from soft matters to thermal convection in fluid dynamics. The square phase field crystal equation models such pattern formation on atomic length and diffusive time scales. The governing equation, derived from a conserved gradient flow of a free energy, involves sixth-order spatial derivatives and Laplacian-gradient type nonlinear term, which result in severe stability restriction on the time stepsizes and difficulty in theoretical analysis. In this paper, we propose a novel unconditionally energy stable, third-order adaptive BDF scheme. The convex-splitting and a multistep stabilization are leveraged to maintain energy stable with arbitrary time stepsizes, and the adaptive time-stepping control based on evolution rate is applied to efficiently obtain high-resolution results. We strictly prove optimal error estimate in the variable-step setting under a mild step ratio constraint by enhancing the discrete kernel framework proposed recently. Numerical tests in 2D/3D demonstrate the square pattern evolution in crystallization process from random or supercooled liquid initial states over a long time. The adaptive algorithm reduces computation time by 95 % while capturing details of phases, confirming the effectiveness of our method. This is the first systematic work on adaptive high-order structure-preserving method for square phase field crystal.},
  archive      = {J_CMAME},
  author       = {Ren-jun Qi and Xuan Zhao},
  doi          = {10.1016/j.cma.2025.118361},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118361},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Provably third-order energy stable adaptive algorithm for modeling square pattern in phase field crystal},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust-weighted hybrid nonlinear regression for reliability based topology optimization with multi-source uncertainties. <em>CMAME</em>, <em>447</em>, 118360. (<a href='https://doi.org/10.1016/j.cma.2025.118360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational burden in topology optimization (TO) under probabilistic constraints is a major challenge for both topology optimization and reliability analysis methods. The machine learning method can be applied for controlling the computational burden of inverse TO method for approximating the optimal volume fraction (Vf) which is related to max/min a probabilistic constraint. In this current work a hybrid nonlinear modelling training method is proposed by using the exponential nonlinear function and improved harmony search optimization for approximating the optimal Vf applied in reliability-based TO (RBTO) problems. For improving the accuracy predictions of nonlinear model a weighted training scheme is proposed given based on absolute bi-linear loss function applied as robust learning format. The applied weights given from near optimal constraints computed by Vf and loss function is determined based on two absolute function with different slop as 1 and 0.1. The proposed learning approach for nonlinear function is compared with the results of TO-based bisection under multi-source uncertainties for both accuracy and computational burden through four engineering problems. Results indicated that the proposed robust-weighted hybrid learning method computed by hybrid nonlinear regression and harmony search optimization is strongly improved the computational burden for evaluating the optimal Vf in TO and RBTO problems compared to TO and RBTO using bisection while it is more accurate as the nonlinear regression.},
  archive      = {J_CMAME},
  author       = {Shiyuan Yang and Debiao Meng and Mahmoud Alfouneh and Behrooz Keshtegar and Shun-Peng Zhu},
  doi          = {10.1016/j.cma.2025.118360},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118360},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A robust-weighted hybrid nonlinear regression for reliability based topology optimization with multi-source uncertainties},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermodynamically consistent coupled chemo-thermo-mechanical model of interfaces in overmolded thermoplastic parts. <em>CMAME</em>, <em>447</em>, 118359. (<a href='https://doi.org/10.1016/j.cma.2025.118359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving reliable bonding between dissimilar semicrystalline polymers in overmolded components remains a critical challenge in advanced manufacturing, with significant implications for structural integrity, process efficiency, and material design. This work introduces a transformational, thermodynamically consistent multiphysics framework that, for the first time, captures the full coupling between heat conduction, crystallization, deformation, and nanoscale polymer diffusion during the cooling stage of the overmolding process. The framework rigorously links manufacturing conditions to the mechanical performance of the final product by integrating process-induced residual stresses, interfacial crystallinity, and polymer interpenetration into a cohesive zone model whose fracture properties evolve dynamically. Unlike existing approaches, which rely on phenomenological models or decoupled analyses, our formulation provides predictive capability grounded in continuum thermodynamics and validated by experimental observations. This enables not only the detection of manufacturing-induced interfacial defects but also virtual process optimization through simulation. The resulting model serves as a digital twin for overmolded thermoplastics, offering a powerful new tool for engineering high-performance composite parts in automotive, aerospace, and biomedical applications.},
  archive      = {J_CMAME},
  author       = {Junhe Cui and Tiansheng Liu and Michele Valsecchi and Martin Giersberg and Hakan Çelik and Jaan-Willem Simon and Sanat Kumar and Jan Petersen and Jacob Fish},
  doi          = {10.1016/j.cma.2025.118359},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118359},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Thermodynamically consistent coupled chemo-thermo-mechanical model of interfaces in overmolded thermoplastic parts},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). History-aware neural operator: Robust data-driven constitutive modeling of path-dependent materials. <em>CMAME</em>, <em>447</em>, 118358. (<a href='https://doi.org/10.1016/j.cma.2025.118358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an end-to-end learning framework for data-driven modeling of path-dependent inelastic materials using neural operators. The novel framework is built on the premise that the irreversible evolution of material responses, governed by hidden dynamics, can be inferred from observable data. We develop the History-Aware Neural Operator (HANO), an autoregressive model that predicts path-dependent material responses from short segments of recent strain-stress history without relying on hidden state variables, thereby overcoming the self-consistency issues commonly encountered in recurrent neural network (RNN)-based models. Built on a Fourier-based neural operator backbone, HANO enables discretization-invariant learning. To further enhance its ability to capture both global loading patterns and critical local path dependencies, we embed a hierarchical self-attention mechanism that facilitates multiscale feature extraction. Beyond ensuring self-consistency, HANO mitigates sensitivity to initial hidden states, a commonly overlooked issue that can lead to instability in recurrent models when applied to generalized loading paths. By modeling stress-strain evolution as a continuous operator rather than relying on fixed input-output mappings, HANO naturally accommodates varying path discretizations and exhibits robust performance under complex conditions, including irregular sampling, multi-cycle loading, noisy data, and pre-stressed states. We evaluate HANO on two benchmark problems: elastoplasticity with hardening and progressive anisotropic damage in brittle solids. Results show that HANO consistently outperforms baseline models in predictive accuracy, generalization, and robustness. With its demonstrated capabilities and discretization-invariant design, HANO provides an effective and flexible data-driven surrogate for simulating a broad class of inelastic materials.},
  archive      = {J_CMAME},
  author       = {Binyao Guo and Zihan Lin and QiZhi He},
  doi          = {10.1016/j.cma.2025.118358},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118358},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {History-aware neural operator: Robust data-driven constitutive modeling of path-dependent materials},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed-depth physics-informed neural network with nested activation mechanism in solving partial differential equations. <em>CMAME</em>, <em>447</em>, 118356. (<a href='https://doi.org/10.1016/j.cma.2025.118356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have become promising tools for solving complex partial differential equations (PDEs), but traditional PINNs suffered from slow convergence, vanishing gradients, and poor handling of local physical features. This paper proposes a mixed-depth physics-informed neural network ( md -PINN) for solving the complex PDEs, aiming to improve the efficiency of network structure and activation function. The contributions are two aspects: (1) the md -PINN includes the various mixed-depth blocks, each of which contains parallel connected deep sub-network and shallow sub-network. The deep sub-network captures complex physical features, ensuring a comprehensive understanding of the system; while the shallow sub-network focuses on the basic physical features, facilitating the stable training; (2) the md -PINN introduces a new nest-tanh (.) activation functions with nested mechanism in shallow sub-networks to enable efficient extraction of complex features using fewer hidden layers, reducing reliance on deep networks. By incorporating mixed-depth structures, md -PINN enables more efficient information sharing across different layer, leading to faster convergence and improved training efficiency. Theoretical analysis demonstrates that md -PINN avoids suboptimal convergence with appropriate initialization. The proposed approach is validated across multiple PDEs, including heat transfer scenarios with complex boundaries, bi-material solid mechanical problems, Allen-Cahn equation, fluid dynamics, and the higher order Kuramoto-Sivashinsky equation. Results show that md -PINN exhibits the superior capabilities in approximating and capturing intricate system features. These findings underscore the computational efficiency and potential of md -PINN in tackling real-world and complex problems.},
  archive      = {J_CMAME},
  author       = {Tianhao Wang and Guirong Liu and Eric Li and Xu Xu},
  doi          = {10.1016/j.cma.2025.118356},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118356},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Mixed-depth physics-informed neural network with nested activation mechanism in solving partial differential equations},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertain constitutive model for metals in the presence of inherent defects. <em>CMAME</em>, <em>447</em>, 118355. (<a href='https://doi.org/10.1016/j.cma.2025.118355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constitutive model of metals is one of the most important elements in solid mechanics, as the mechanical behavior at different spatial scales is uncertain, and the constitutive model is inevitably subject to uncertainty of defects. The complexity of metal microstructure, coupled with the high cost of numerical simulation, poses a challenge in establishing the correlation between macro and micro uncertainties in metals. This article proposes a new uncertain constitutive model for hexagonal close packing (HCP) polycrystal, integrating Point defect and dislocation into micro-uncertainty analysis and developing a multiscale framework for calculating the uncertain constitutive model of metal. Building on density functional theory and microcrystalline plasticity theory, interval forms are employed as variables for micro-uncertainty, allowing for accurate quantification of uncertainties in parameters such as initial dislocation density. By constructing a surrogate model for cross-scale uncertainty propagation, the performance envelope of metals can be determined. The framework is then applied to engineering case study of α-phase pure titanium to calculate system responses.},
  archive      = {J_CMAME},
  author       = {Jiazheng Zhu and Xiaojun Wang and Yanru Mu},
  doi          = {10.1016/j.cma.2025.118355},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118355},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Uncertain constitutive model for metals in the presence of inherent defects},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System reliability-based design optimization of structures using non-probabilistic ellipsoidal convex model. <em>CMAME</em>, <em>447</em>, 118354. (<a href='https://doi.org/10.1016/j.cma.2025.118354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a system non-probabilistic reliability-based design optimization (SNRBDO) framework for engineering structural systems. In view of the limitations of traditional probabilistic methods due to insufficient uncertainty information, the ellipsoidal convex model is used to quantify the uncertainty while considering the parameter correlation. The non-probabilistic credible set uncertainty method is employed to quantify the ellipsoidal uncertainty domain of uncertain parameters. A system non-probabilistic reliability index, defined as the volume ratio of safe regions to uncertainty domains, is introduced to evaluate structural safety under multiple failure modes. To enhance computational efficiency, Kriging surrogate model is utilized to replace the finite element analysis during optimization, and a localized sampling strategy is developed to refine accuracy near critical design points. The method is validated through a mathematical example and two engineering applications. The results demonstrate significant improvements in computational efficiency and design precision compared to conventional methods.},
  archive      = {J_CMAME},
  author       = {Zirui Liu and Jinglei Gong and Yongxiang Mu and Xiaojun Wang},
  doi          = {10.1016/j.cma.2025.118354},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118354},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {System reliability-based design optimization of structures using non-probabilistic ellipsoidal convex model},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully GPU-accelerated, matrix-free immersed boundary method for complex fiber-reinforced hyperelastic cardiac models. <em>CMAME</em>, <em>447</em>, 118353. (<a href='https://doi.org/10.1016/j.cma.2025.118353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The immersed boundary (IB) method has become a leading approach in cardiac fluid-structure interaction (FSI) modeling due to its ability to handle large deformations and complex geometries without requiring mesh regeneration. However, the use of nonlinear, fiber-reinforced hyperelastic materials for modeling soft cardiac tissues introduces challenges in computational efficiency, particularly due to the additional projection steps required for stability in the IB framework. These steps often involve sparse matrix storage and computation, which can degrade GPU performance. In this work, we present a fully GPU-accelerated, matrix-free IB method for FSI in anatomically realistic cardiac models, which novelly integrates established components into a unified, GPU-optimized system. By employing nodal coupling, our method eliminates the need for projection operations in the finite element space. Additionally, we solve the Navier-Stokes equations using Chorin’s projection method combined with a matrix-free geometric multigrid solver, ensuring the entire FSI algorithm remains matrix-free and highly compatible with GPU acceleration. Our implementation features several GPU-specific optimizations, including the use of constant memory to store values of nodal basis functions and their derivatives at quadrature points, and texture memory to efficiently implement the semi-Lagrangian discretization of convection terms. These innovations maximize GPU utilization while preserving the complex mechanical behavior of soft cardiac tissue. Benchmark tests demonstrate that our GPU-accelerated solver achieves a 50 × − 100 × speedup compared to a 20-core CPU implementation, with comparable accuracy. Critically, this performance enables clinically viable cardiac valve FSI simulations to be completed within a few hours on a single consumer-grade GPU-an achievement that was previously infeasible using traditional CPU-based frameworks.},
  archive      = {J_CMAME},
  author       = {Pengfei Ma and Li Cai and Xuan Wang and Hao Gao},
  doi          = {10.1016/j.cma.2025.118353},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118353},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Fully GPU-accelerated, matrix-free immersed boundary method for complex fiber-reinforced hyperelastic cardiac models},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid flux-preserving finite element for coupled flow deformation: Linear formulation. <em>CMAME</em>, <em>447</em>, 118351. (<a href='https://doi.org/10.1016/j.cma.2025.118351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate modeling of coupled solid-fluid systems in porous media poses intrinsic computational challenges due to the nonlinear interaction between kinematic fields and fluid transport. Although a wide spectrum of finite element formulations is documented in the literature, the majority are based on principles in which solid displacement and fluid pressure fields are treated as primary unknowns, leading to a saddle point problem, thus requiring the satisfaction of the inf-sup condition to ensure the well-posedness and stability of the mixed formulation. Furthermore, in critical scenarios, such as low permeability or small time steps, numerical instabilities, including pressure oscillations, may still occur, requiring the implementation of stabilization techniques or the adoption of high-resolution discretizations to maintain solution accuracy. The present contribution proposes a novel hybrid flux-preserving finite element formulation, designed to preserve mass flux consistency within each element, by adopting an alternative set of primary variables. An original hybrid variational principle is established, wherein the solid deformation and the mass flux fields are adopted as primary unknowns, while the fluid potential acts as a Lagrange multiplier to enforce weak continuity of mass flow across inter-element boundaries, thus avoiding the necessity of globally conforming function spaces. The resulting hybrid element is implemented within the open-source software FEAP. Its performance is assessed through classical benchmark problems in poroelasticity. In particular, the accurate resolution of the fluid pressure field highlights the advantages of the proposed formulation over classical displacement-pressure elements and shows the potential of the proposed method.},
  archive      = {J_CMAME},
  author       = {Simona Lo Franco and Michele Terzano and Guido Borino and Gerhard A. Holzapfel and Francesco Parrinello},
  doi          = {10.1016/j.cma.2025.118351},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118351},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A hybrid flux-preserving finite element for coupled flow deformation: Linear formulation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Peridynamic correspondence model for nearly-incompressible finite elasticity. <em>CMAME</em>, <em>447</em>, 118350. (<a href='https://doi.org/10.1016/j.cma.2025.118350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a correspondence model for use with peridynamic states in the context of nearly incompressible finite elasticity. An isochoric/volumetric decomposition is adopted, enabling the derivation of the peridynamic force state from a purely spherical, pointwise non-local deformation gradient and a deviatoric, bond-level non-local deformation gradient. This approach leads to a stable one-field, state-based peridynamic formulation that is free from zero-energy modes and capable of accurately capturing the mechanical behavior of elastic materials under large deformations, including those with low or negligible compressibility, typical of unfilled elastomers and isotropic soft biological tissues. Notably, the proposed correspondence model, based on a selective bond-associated deformation gradient, avoids the artificial stiffening commonly observed in standard displacement-based formulations near the incompressible limit. Moreover, its performance is shown to be independent of the specific compressibility ratio assumed in the hyperelastic constitutive law. The model has been successfully validated using classical polynomial strain energy functions through a series of illustrative examples involving both homogeneous and inhomogeneous finite deformations in isotropic hyperelastic solids.},
  archive      = {J_CMAME},
  author       = {Francesco Scabbia and Vito Diana and Francesca Fantoni and Mirco Zaccariotto and Ugo Galvanetto},
  doi          = {10.1016/j.cma.2025.118350},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118350},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Peridynamic correspondence model for nearly-incompressible finite elasticity},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S-PINN: Stabilized physics-informed neural networks for alleviating barriers between multi-level co-optimization. <em>CMAME</em>, <em>447</em>, 118348. (<a href='https://doi.org/10.1016/j.cma.2025.118348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have rapidly evolved since their robust capabilities of integrating physical laws into data-driven models. However, the multi-level co-optimization mechanism hidden in the collocation-type loss function in PINNs leads to conflicts between data and physical equations, as well as conflicts among pointwise residuals, which results in poor stability and conservation. In this paper, a stabilized physics-informed neural network (S-PINN) framework is proposed to alleviate these limitations. First, S-PINN incorporates local domains around collocation points for evaluating residuals of conserved quantities. These domains can be flexibly established by creating a square centered on the collocation point of the original PINN, without constructing any mesh with topological relations. During online training, S-PINN mitigates conflicts in the multi-level co-optimization by minimizing a novel loss function based on the cumulative residuals of conserved quantities in all subdomains, significantly enhancing conservation. Finally, the novel approach is applied to predict the dynamic characteristics of incompressible fluid problems, with benchmarks including the pressure Poisson equation of fluid, Burgers' equation, heat diffusion equation, and the Navier-Stokes equations. Results demonstrate notable advancements in both the conservation and accuracy of the S-PINN. While traditional PINN lays a solid foundation for model interpretability and integration of physical laws, the newly proposed S-PINN exhibits improved performances in multiples aspects compared to PINN. These improvements promote extensive applicability in solving partial differential equations integrated with observational data, which is crucial for the application of complex dynamic systems.},
  archive      = {J_CMAME},
  author       = {Tengmao Yang and Zhihao Qian and Nianzhi Hang and Moubin Liu},
  doi          = {10.1016/j.cma.2025.118348},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118348},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {S-PINN: Stabilized physics-informed neural networks for alleviating barriers between multi-level co-optimization},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model order reduction of hæmodynamics by space–time reduced basis and reduced fluid–structure interaction. <em>CMAME</em>, <em>447</em>, 118347. (<a href='https://doi.org/10.1016/j.cma.2025.118347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we apply the space–time Galerkin reduced basis (ST–GRB) method to a reduced fluid–structure interaction model, for the numerical simulation of hæmodynamics in arteries. In essence, ST–GRB extends the classical reduced basis (RB) method, exploiting a data–driven low–dimensional linear encoding of the temporal dynamics to further cut the computational costs. The current investigation brings forth two key enhancements, compared to previous works on the topic. On the one side, we model blood flow through the Navier–Stokes equations, hence accounting for convection. In this regard, we implement a hyper–reduction scheme, based on approximate space–time reduced affine decompositions, to deal with nonlinearities effectively. On the other side, we move beyond the constraint of modelling blood vessels as rigid structures, acknowledging the importance of elasticity for the accurate simulation of complex blood flow patterns. To limit computational complexity, we adopt the Coupled Momentum model, incorporating the effect of wall compliance in the fluid’s equations through a generalized Robin boundary condition. In particular, we propose an efficient strategy for handling the spatio–temporal projection of the structural displacement, which ultimately configures as a by–product. The performances of ST–GRB are assessed in three different numerical experiments. The results confirm that the proposed approach can outperform the classical RB method, yielding precise approximations of high–fidelity solutions at more convenient costs. However, the computational gains of ST–GRB vanish if the number of retained temporal modes is too large, which occurs either when complex dynamics arise or if very precise solutions are sought.},
  archive      = {J_CMAME},
  author       = {Riccardo Tenderini and Simone Deparis},
  doi          = {10.1016/j.cma.2025.118347},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118347},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Model order reduction of hæmodynamics by space–time reduced basis and reduced fluid–structure interaction},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharp-PINNs: Staggered hard-constrained physics-informed neural networks for phase field modelling of corrosion. <em>CMAME</em>, <em>447</em>, 118346. (<a href='https://doi.org/10.1016/j.cma.2025.118346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks have shown significant potential in solving partial differential equations (PDEs) across diverse scientific fields. However, their performance often deteriorates when addressing PDEs with intricate and strongly coupled solutions. In this work, we present a novel Sharp-PINN framework to tackle complex phase field corrosion problems. Instead of minimizing all governing PDE residuals simultaneously, the Sharp-PINNs introduce a staggered training scheme that alternately minimizes the residuals of Allen-Cahn and Cahn-Hilliard equations, which govern the corrosion system. To further enhance its efficiency and accuracy, we design an advanced neural network architecture that integrates random Fourier features as coordinate embeddings, employs a modified multi-layer perceptron as the primary backbone, and enforces hard constraints in the output layer. This framework is benchmarked through simulations of corrosion problems with multiple pits, where the staggered training scheme and network architecture significantly improve both the efficiency and accuracy of PINNs. Moreover, in three-dimensional cases, our approach is 5–10 times faster than traditional finite element methods while maintaining competitive accuracy, demonstrating its potential for real-world engineering applications in corrosion prediction.},
  archive      = {J_CMAME},
  author       = {Nanxi Chen and Chuanjie Cui and Rujin Ma and Airong Chen and Sifan Wang},
  doi          = {10.1016/j.cma.2025.118346},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118346},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Sharp-PINNs: Staggered hard-constrained physics-informed neural networks for phase field modelling of corrosion},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature preserving data assimilation via feature alignment. <em>CMAME</em>, <em>447</em>, 118345. (<a href='https://doi.org/10.1016/j.cma.2025.118345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data assimilation combines information from physical observations and numerical simulation results to obtain better estimates of the state and parameters of a physical system. A wide class of physical systems of interest have solutions that exhibit the formation of structures, called features, that have to be accurately captured by the assimilation framework. For example, fluids can develop features such as shock waves and contact discontinuities that need to be tracked and preserved during data assimilation. State-of-the-art data assimilation techniques are agnostic of such features. Current ensemble-based methods construct state estimates by taking linear combinations of multiple ensemble states; repeated averaging tends to smear the features over multiple assimilation cycles, leading to nonphysical state estimates. A novel feature-preserving data assimilation methodology that combines sequence alignment with the ensemble transform particle filter is proposed to overcome this limitation of existing assimilation algorithms. Specifically, optimal transport of particles is performed along feature-aligned characteristics. The strength of the proposed feature-preserving filtering approach is demonstrated on multiple test problems described by the compressible Euler equations.},
  archive      = {J_CMAME},
  author       = {Amit~N. Subrahmanya and Adrian Sandu},
  doi          = {10.1016/j.cma.2025.118345},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118345},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Feature preserving data assimilation via feature alignment},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A meshfree immersed variational multiscale method for perfectly bonded interfaces. <em>CMAME</em>, <em>447</em>, 118344. (<a href='https://doi.org/10.1016/j.cma.2025.118344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composites are ubiquitous in many engineering applications, and computing stresses near material interfaces is crucial for predicting and understanding meso- and micro-structural failure in these materials. While many notable approaches to this problem are available, stable interfacial tractions are still difficult to achieve in numerical simulations. This work presents a simplified immersed variational multiscale (SIVMS) method for interfaces that achieves stable, convergent results for the normal traction. The convergence behavior in both the bulk domain fields and interfacial tractions is investigated for SIVMS and is compared to conventional methods such as the Lagrange multiplier method and Nitsche’s method. The difficulty in selecting appropriate values of parameters for Nitsche’s method is highlighted. In contrast, SIVMS provides stabilization that emanates naturally from the assumed fine-scale basis functions. The proposed SIVMS method is free from ad-hoc parameters and provides good accuracy and stability in interfacial tractions. Several benchmark test cases are presented to show the effectiveness and confirm the range of applicability of the proposed method.},
  archive      = {J_CMAME},
  author       = {Andrew B. Groeneveld and Michael C. Hillman and Pinlei Chen},
  doi          = {10.1016/j.cma.2025.118344},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118344},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A meshfree immersed variational multiscale method for perfectly bonded interfaces},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A velocity-vorticity-pressure formulation for the steady Navier–Stokes–Brinkman–Forchheimer problem. <em>CMAME</em>, <em>447</em>, 118343. (<a href='https://doi.org/10.1016/j.cma.2025.118343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flow of incompressible fluid in highly permeable porous media in vorticity - velocity - Bernoulli pressure form leads to a double saddle-point problem in the Navier–Stokes–Brinkman–Forchheimer equations. The paper establishes, for small sources, the existence of solutions on the continuous and discrete level of lowest-order piecewise divergence-free Crouzeix–Raviart finite elements. The vorticity employs a vector version of the pressure space with normal and tangential velocity jump penalisation terms. A simple Raviart–Thomas interpolant leads to pressure-robust a priori error estimates. An explicit residual-based a posteriori error estimate allows for efficient and reliable a posteriori error control. The efficiency for the Forchheimer nonlinearity requires a novel discrete inequality of independent interest. The implementation is based upon a light-weight forest-of-trees data structure handled by a highly parallel set of adaptive mesh refining algorithms. Numerical simulations reveal robustness of the a posteriori error estimates and improved convergence rates by adaptive mesh-refining.},
  archive      = {J_CMAME},
  author       = {Santiago Badia and Carsten Carstensen and Alberto F. Martín and Ricardo Ruiz-Baier and Segundo Villa-Fuentes},
  doi          = {10.1016/j.cma.2025.118343},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118343},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A velocity-vorticity-pressure formulation for the steady Navier–Stokes–Brinkman–Forchheimer problem},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A locking free multiscale method for linear elasticity in stress-displacement formulation with high contrast coefficients. <em>CMAME</em>, <em>447</em>, 118342. (<a href='https://doi.org/10.1016/j.cma.2025.118342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving strongly symmetric stress approximations for linear elasticity problems in high-contrast media poses a significant computational challenge. Conventional methods often struggle with prohibitively high computational costs due to excessive degrees of freedom, limiting their practical applicability. To overcome this challenge, we introduce an efficient multiscale model reduction method and a computationally inexpensive coarse-grid simulation technique for linear elasticity equations in highly heterogeneous, high-contrast media. We first utilize a stable stress-displacement mixed finite element method to discretize the linear elasticity problem and then present the construction of multiscale basis functions for the displacement and the stress. The mixed formulation offers several advantages such as direct stress computation without post-processing, local momentum conservation (ensuring physical consistency), and robustness against locking effects, even for nearly incompressible materials. Theoretical analysis confirms that our method is inf-sup stable and locking-free, with first-order convergence relative to the coarse mesh size. Notably, the convergence remains independent of contrast ratios as enlarging oversampling regions. Numerical experiments validate the method’s effectiveness, demonstrating its superior performance even under extreme contrast conditions.},
  archive      = {J_CMAME},
  author       = {Eric T. Chung and Changqing Ye and Xiang Zhong},
  doi          = {10.1016/j.cma.2025.118342},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118342},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A locking free multiscale method for linear elasticity in stress-displacement formulation with high contrast coefficients},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical hierarchical bayesian modeling framework for model updating and uncertainty propagation utilizing frequency response function data. <em>CMAME</em>, <em>447</em>, 118341. (<a href='https://doi.org/10.1016/j.cma.2025.118341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model updating using frequency response functions (FRFs) provides critical advantages in structural dynamics. However, existing probabilistic approaches struggle to balance computational efficiency with comprehensive uncertainty quantification. To this end, this paper introduces an analytical hierarchical Bayesian modeling (HBM) framework that overcomes these limitations through utilization of complex-valued FRF data and variational inference. In particular, the proposed approach incorporates a complex Gaussian likelihood formulation directly into the HBM framework for the FRF experimental data, which allows for a more appropriate and physically consistent treatment of FRF data, particularly when both magnitude and phase information (real and imaginary parts) are essential. Additionally, the proposed approach enables the analytical HBM solution under the complex likelihood setting, improving both the accuracy of parameter estimation and the efficiency of the computation. The framework further propagates the parameter uncertainty to the response predictions and reliability assessment. Numerical and experimental validations on a simply supported beam demonstrate the effectiveness of the proposed approach. Results indicate that the proposed framework provides a reasonable uncertainty estimate of the model parameters as well as the response predictions. Reliability computations on the numerical example also suggest that the proposed framework provides conservative and reliable failure probability estimates, compared to the classical Bayesian modeling which often leads to unsafe engineering decisions.},
  archive      = {J_CMAME},
  author       = {Xinyu Jia and Weinan Hou and Shi-Ze Cao and Wang-Ji Yan and Costas Papadimitriou},
  doi          = {10.1016/j.cma.2025.118341},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118341},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Analytical hierarchical bayesian modeling framework for model updating and uncertainty propagation utilizing frequency response function data},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework of bond-associated peridynamic material correspondence models: Formulation and evaluation. <em>CMAME</em>, <em>447</em>, 118340. (<a href='https://doi.org/10.1016/j.cma.2025.118340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional peridynamic material correspondence formulation is known to suffer from issue of material instability or existence of zero-energy modes. This issue arises from the non-unique mapping between the nonlocal deformation gradient and the resulting bond force density state. Among many stabilization techniques proposed to handle this issue, a number of bond-associated models that employ bond-level deformation gradients have emerged as more effective approaches. Although initially developed from different theoretical perspectives, many of these models share underlying structural similarities. This paper aims to unify these differing approaches and introduce a generalized framework for all bond-associated peridynamic material correspondence models. On the basis of formulations proposed in the literature, a unified expression for the bond-associated deformation gradient is developed. Assuming energy equivalence with the local continuum mechanics theory, the unified bond force density state is derived using the Fréchet derivative. In addition, some properties of the bond-associated models, including linear momentum balance, angular momentum balance, and objectivity, are thoroughly examined. To assess and compare the performance of bond-associated models, a series of numerical studies are carried out, including bond mapping analysis, elastic deformation prediction, and elastic wave propagation modeling. It is found that in wave propagation modeling the use of non-constant spherical influence functions, even though this is common in peridynamic models, can lead to phase shift phenomena in certain bond-associated models. Overall, this work provides a comprehensive and unified treatment of bond-associated peridynamic material correspondence models, and it is intended to serve as a valuable reference for further development and application of bond-associated material correspondence formulations in peridynamics.},
  archive      = {J_CMAME},
  author       = {Xuan Hu and Hailong Chen and Shaofan Li},
  doi          = {10.1016/j.cma.2025.118340},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118340},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A unified framework of bond-associated peridynamic material correspondence models: Formulation and evaluation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative high-order weakly compressible smoothed particle hydrodynamics model for viscous fluid flows. <em>CMAME</em>, <em>447</em>, 118339. (<a href='https://doi.org/10.1016/j.cma.2025.118339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoothed particle hydrodynamics (SPH) is an efficient and robust particle-based method for large deformation problems such as strongly nonlinear free interface flow and structural damage due to its meshless characteristics. However, achieving consistent high-order accuracy remains a fundamental challenge under irregular particle distributions, which often leads to significant accuracy degradation in conventional SPH interpolation schemes. To address this issue, we propose a novel iterative high-order SPH framework to systematically improve the accuracy of gradient and Laplacian operators through multiple layers of Taylor expansions. An adaptive iteration strategy is introduced at each expansion layer, resulting in a recursive correction that utilizes high-order derivatives to improve low-order estimates, thereby improving consistency and robustness for inhomogeneous particle fields. To maintain accuracy near domain boundaries, a new high-order ghost particle extrapolation scheme is developed to ensure consistency of spatial derivatives. The proposed framework is validated on a series of typical incompressible viscous flow benchmarks, including Taylor-Green vortex, Lamb-Osing vortex, inviscid shear layer, Burggraf flow, and Lid driven flow. Results show that the proposed approach achieves up to fourth-order convergence even with irregular particle arrangements and improves simulation accuracy by two orders of magnitude compared to the conventional SPH formulation. By avoiding the use of high-order kernel functions and large matrix systems, this method provides a scalable approach for high-fidelity particle-based simulations.},
  archive      = {J_CMAME},
  author       = {Guixun Zhu and Siming Zheng and Yaru Ren and Yuzhu Pearl Li},
  doi          = {10.1016/j.cma.2025.118339},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118339},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Iterative high-order weakly compressible smoothed particle hydrodynamics model for viscous fluid flows},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-energy physics-informed multi-material topology optimization method within the phase-field framework. <em>CMAME</em>, <em>447</em>, 118338. (<a href='https://doi.org/10.1016/j.cma.2025.118338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a dual-energy physics-informed multi-material topology optimization method within the phase-field framework. The method employs a dual-network collaborative architecture, utilizing two fully connected networks incorporating Fourier transformations to approximate the displacement field and the multiphase field, respectively. This approach enables a fully physics-driven optimization process throughout the entire workflow. The displacement field is approximated via the deep energy method, using the principle of minimum potential energy as the driving mechanism. Within the phase-field framework, an energy functional is constructed that incorporates the classical Ginzburg-Landau free energy, elastic strain energy and volume fraction constraints. This functional serves as the loss function that couples the displacement and phase fields, promoting the balancing of mechanical performance, interface thickness, material volume fractions, and phase repulsion during network training. Thus it achieves a deep integration of multi-material physical information. The pretraining strategy effectively reduces convergence time and enhances optimization performance. Automatic differentiation replaces traditional sensitivity analysis, enhancing computational efficiency, while appropriate control of sampling points balances training cost and accuracy. Several numerical experiments validate the effectiveness of the proposed method.},
  archive      = {J_CMAME},
  author       = {Sijing Lai and Jiachen Feng and Zhixian Lv and Junseok Kim and Yibao Li},
  doi          = {10.1016/j.cma.2025.118338},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118338},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A dual-energy physics-informed multi-material topology optimization method within the phase-field framework},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Midplane based 3D single pass unbiased segment-to-segment contact interaction using penalty method. <em>CMAME</em>, <em>447</em>, 118335. (<a href='https://doi.org/10.1016/j.cma.2025.118335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a contact interaction methodology for an unbiased treatment of contacting surfaces without assigning surfaces as master and slave. Contact tractions between interacting discrete segments are evaluated with respect to a midplane in a single pass, inherently maintaining traction equilibrium. These tractions are based on the penalisation of true interpenetration between opposite surfaces, and the procedure of their integral for discrete contacting segments is described. A detailed examination of the possible geometric configurations of interacting 3D segments is provided to support visual understanding and better traction evaluation accuracy. The accuracy and robustness of the proposed method are validated against the analytical solutions of the contact patch test and Hertzian contact, demonstrating the capability to reproduce contact between flat and curved surfaces. The method passes the contact patch test with the uniform transmission of contact pressure matching the accuracy levels of finite elements. It converges towards the analytical solution with appropriate mesh refinement and a suitably high penalty factor in Hertzian contact. Dynamic problems involving elastic and inelastic collisions between two bars, as well as oblique collisions of cylinders, are also presented. The ability of the algorithm to resolve contacts between flat and curved surfaces in nonconformal meshes for both static and dynamic cases with high accuracy demonstrates its versatility for general contact problems, including self-contact.},
  archive      = {J_CMAME},
  author       = {Indrajeet Sahu and Nik Petrinic},
  doi          = {10.1016/j.cma.2025.118335},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118335},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Midplane based 3D single pass unbiased segment-to-segment contact interaction using penalty method},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistent pressure formulation of the stokes problem and approximation thereof. <em>CMAME</em>, <em>447</em>, 118333. (<a href='https://doi.org/10.1016/j.cma.2025.118333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A non-conforming approximation of a non standard formulation of the generalized Stokes problem is proposed using continuous finite elements. The stability, convergence, and scalability properties of the method are numerically tested. Four key features of the method are as follows: (i) It is observed to converge optimally with pairs of equal order; (ii) The resulting algebraic system is simple to precondition; (iii) The formulation is pressure-robust for equal pairs; (iv) The formulation is particularly well adapted for the approximation of the time-dependent incompressible Navier-Stokes equations.},
  archive      = {J_CMAME},
  author       = {Melvin Creff and Jean-Luc Guermond},
  doi          = {10.1016/j.cma.2025.118333},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118333},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Consistent pressure formulation of the stokes problem and approximation thereof},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving long-term autoregressive spatiotemporal predictions: A proof of concept with fluid dynamics. <em>CMAME</em>, <em>447</em>, 118332. (<a href='https://doi.org/10.1016/j.cma.2025.118332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven approaches have emerged as a powerful alternative to traditional numerical methods for forecasting physical systems, offering fast inference and reduced computational costs. However, for complex systems and those without prior knowledge, the accuracy of long-term predictions frequently deteriorates due to error accumulation. Existing solutions often adopt an autoregressive approach that unrolls multiple time steps during each training iteration; although effective for long-term forecasting, this method requires storing entire unrolling sequences in GPU memory, leading to high resource demands. Moreover, optimizing for long-term accuracy in autoregressive frameworks can compromise short-term performance. To address these challenges, we introduce the Stochastic PushForward (SPF) training framework in this paper. SPF preserves the one-step-ahead training paradigm while still enabling multi-step-ahead learning. It dynamically constructs a supplementary dataset from the model’s predictions and uses this dataset in combination with the original training data. By drawing inputs from both the ground truth and model-generated predictions through a stochastic acquisition strategy, SPF naturally balances short- and long-term predictive performance and further reduces overfitting and improves generalization. Furthermore, the training process is executed in a one-step-ahead manner, with multi-step-ahead predictions precomputed between epochs-thus eliminating the need to retain entire unrolling sequences in memory, thus keeping memory usage stable. We demonstrate the effectiveness of SPF on the Burgers’ equation and the Shallow Water benchmark. Experimental results demonstrated that SPF delivers superior long-term accuracy compared to autoregressive approaches while reducing memory consumption. This positions SPF as a promising solution for resource-constrained environments and complex physical simulations.},
  archive      = {J_CMAME},
  author       = {Hao Zhou and Sibo Cheng},
  doi          = {10.1016/j.cma.2025.118332},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118332},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Improving long-term autoregressive spatiotemporal predictions: A proof of concept with fluid dynamics},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A curvilinear surface ALE formulation for self-evolving navier-stokes manifolds – Stabilized finite element formulation. <em>CMAME</em>, <em>447</em>, 118331. (<a href='https://doi.org/10.1016/j.cma.2025.118331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a stabilized finite element formulation of the arbitrary Lagrangian-Eulerian (ALE) surface theory for Navier-Stokes flow on self-evolving manifolds developed in Sauer [1]. The formulation is physically frame-invariant, applicable to large deformations, and relevant to fluidic surfaces such as soap films, capillary menisci and lipid membranes, which are complex and inherently unstable physical systems. It is applied here to area-incompressible surface flows using a stabilized pressure-velocity (or surface tension-velocity) formulation based on quadratic finite elements and implicit time integration. The unknown ALE mesh motion is determined by membrane elasticity such that the in-plane mesh motion is stabilized without affecting the physical behavior of the system. The resulting three-field system is monolithically coupled, and fully linearized within the Newton-Rhapson solution method. The new formulation is demonstrated on several challenging examples including shear flow on self-evolving surfaces and inflating soap bubbles with partial inflow on evolving boundaries. Optimal convergence rates are obtained in all cases. Particularly advantageous are C 1 -continuous surface discretizations, for example based on NURBS.},
  archive      = {J_CMAME},
  author       = {Roger A. Sauer},
  doi          = {10.1016/j.cma.2025.118331},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118331},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A curvilinear surface ALE formulation for self-evolving navier-stokes manifolds – Stabilized finite element formulation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive physics-informed system modeling with control for nonlinear structural system estimation. <em>CMAME</em>, <em>447</em>, 118330. (<a href='https://doi.org/10.1016/j.cma.2025.118330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately capturing the nonlinear dynamic behavior of structures remains a significant challenge in mechanics and engineering. Traditional physics-based models and data-driven approaches often struggle to simultaneously ensure model interpretability, noise robustness, and estimation optimality. To address this issue, this paper proposes an Adaptive Physics-Informed System Modeling with Control (APSMC) framework. By integrating Kalman filter-based state estimation with physics-constrained proximal gradient optimization, the framework adaptively updates time-varying state-space model parameters while processing real-time input–output data under white noise disturbances. Theoretically, this process is equivalent to real-time tracking of the Jacobian matrix of a nonlinear dynamical system. Within this framework, we leverage the theoretical foundation of stochastic subspace identification to demonstrate that, as observational data accumulates, the APSMC algorithm yields state-space model estimates that converge to the theoretically optimal solution. The effectiveness of the proposed framework is validated through numerical simulations of a Duffing oscillator and the seismic response of a frame structure, as well as experimental tests on a scaled bridge model and real wind turbine health monitoring data. Experimental results show that, under noisy conditions, APSMC successfully predicts 19 consecutive 10-second time series using only a single initial 10-second segment for model updating, achieving a minimum normalized mean square error (NMSE) of 0.398 %. Furthermore, APSMC achieves the best performance among classical time-domain algorithms on measured wind turbine acceleration data. These findings demonstrate that the APSMC framework not only offers superior online identification and denoising performance but also provides a reliable foundation for downstream applications such as structural health monitoring, real-time control, adaptive filtering, and system identification. An open-source Python implementation is available on GitHub .},
  archive      = {J_CMAME},
  author       = {Biqi Chen and Chenyu Zhang and Jun Zhang and Ying Wang},
  doi          = {10.1016/j.cma.2025.118330},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118330},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Adaptive physics-informed system modeling with control for nonlinear structural system estimation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-augmented GraphGPS framework for the reconstruction of 3D riemann problems from sparse data. <em>CMAME</em>, <em>447</em>, 118328. (<a href='https://doi.org/10.1016/j.cma.2025.118328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In compressible fluid flow, reconstructing shocks, discontinuities, rarefactions, and their interactions from sparse measurements is an important inverse problem with practical applications. Moreover, physics-informed machine learning has recently become an increasingly popular approach for performing reconstructions tasks. In this work we explore a machine learning recipe, known as GraphGPS, for reconstructing canonical compressible flows known as 3D Riemann problems from sparse observations, in a physics-informed manner. The GraphGPS framework combines the benefits of positional encodings, local message-passing of graphs, and global contextual awareness, and we explore the latter two components through an ablation study. Furthermore, we modify the aggregation step of message-passing such that it is aware of shocks and discontinuities, resulting in sharper reconstructions of these features. Additionally, we modify message-passing such that information flows strictly from known nodes only, which results in computational savings, better training convergence, and no degradation of reconstruction accuracy. We also show that the GraphGPS framework outperforms numerous machine learning and classical benchmarks.},
  archive      = {J_CMAME},
  author       = {Rami Cassia and Rich Kerswell},
  doi          = {10.1016/j.cma.2025.118328},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118328},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A physics-augmented GraphGPS framework for the reconstruction of 3D riemann problems from sparse data},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A low-level teamwork hybrid model based swarm intelligent algorithm for engineering design optimization. <em>CMAME</em>, <em>447</em>, 118317. (<a href='https://doi.org/10.1016/j.cma.2025.118317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a multi-algorithm hybrid strategy, named WIFN, to mitigate the poor performance of the naked mole-rat algorithm (NMRA). The proposed WIFN algorithm employs the best exploration and exploitation properties of existing algorithms, viz. weighted mean of vectors (INFO), whale optimization algorithm (WOA) and fission fusion optimization (FuFiO). These algorithms are integrated into the worker phase of the NMRA. A new stagnation phase is introduced in WIFN to minimize the effect of local optima stagnation. To add self-adaptivity, five new mutation/inertia weight strategies are added to the parameters of WIFN. To assess its performance, four data sets are used: classical benchmarks, CEC 2014, CEC 2017 and CEC 2019. An experimental study is carried out using i) five constrained engineering design problems and ii) 15 real-world constrained problems from the CEC 2020 benchmark dataset to analyze the applicability of WIFN for computationally expensive problems. In addition, WIFN is applied to multilevel image thresholding with type-II fuzzy sets. It is tested using a real image set that features different histogram distributions for three different threshold numbers. Experimental results suggest that WIFN perform significantly better than the existing state-of-the-art algorithms in terms of quality metrics, viz. mean squared error (MSE), peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM). Wilcoxon’s ranksum and the Friedman test establish the superiority of WIFN statistically.},
  archive      = {J_CMAME},
  author       = {Amanjot Kaur Lamba and Rohit Salgotra and Nitin Mittal},
  doi          = {10.1016/j.cma.2025.118317},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118317},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A low-level teamwork hybrid model based swarm intelligent algorithm for engineering design optimization},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stage constitutive modeling framework based on finite strain data-driven identification and physics-augmented neural networks. <em>CMAME</em>, <em>447</em>, 118289. (<a href='https://doi.org/10.1016/j.cma.2025.118289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, we present a novel consistent dual-stage approach for the automated generation of hyperelastic constitutive models which only requires experimentally measurable data. As a proof of concept, the present work relies on synthetic data generated through virtual experiments. To generate input data for our approach, an experiment with full-field measurement has to be conducted to gather testing force and corresponding displacement field of the sample. Then, in the first step of the dual-stage framework, a new finite strain Data-Driven Identification (DDI) formulation is applied. This method enables to identify tuples consisting of stresses and strains by only prescribing the applied boundary conditions and the measured displacement field. In the second step, the data set is used to calibrate a Physics-Augmented Neural Network (PANN), which fulfills all common conditions of hyperelasticity by construction and is very flexible at the same time. We demonstrate the applicability of our approach by several descriptive examples. Two-dimensional synthetic data are exemplarily generated in virtual experiments by using a reference constitutive model. The calibrated PANN is then applied in 3D Finite Element simulations. In addition, a real experiment including noisy data is mimicked.},
  archive      = {J_CMAME},
  author       = {Lennart Linden and Karl A. Kalina and Jörg Brummund and Brain Riemer and Markus Kästner},
  doi          = {10.1016/j.cma.2025.118289},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118289},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A dual-stage constitutive modeling framework based on finite strain data-driven identification and physics-augmented neural networks},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="comcom">COMCOM - 40</h2>
<ul>
<li><details>
<summary>
(2025). A scalable blockchain framework for IoT based on restaking and incentive mechanisms. <em>COMCOM</em>, <em>242</em>, 108317. (<a href='https://doi.org/10.1016/j.comcom.2025.108317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a scalable blockchain framework based on sidechain solution for the Internet of Things (IoT). Considering the low-trust models of existing sidechains, we present a restaking-based trust aggregation method for Proof of Stake (PoS). By allowing mainchain validators to duplicate their stake on the sidechain network, we enhance the cryptoeconomics security of the sidechain while reducing costs. Given the potential conflicts between risks and rewards of trust aggregation, and the challenges posed by the heterogeneity of IoT devices for quantitative analysis, we propose an incentive analysis framework based on contract. By analyzing the optimal strategies of different risk-preference validators, design differentiated contracts to promote incentive-compatible outcomes. Additionally, we account for the uncertainty in the distribution of sidechain validators and discuss optimal configurations under various conditions. To address potential collusion attacks, we introduce a quantifiable exemption mechanism to limit the security risks. Finally, numerical simulations verify the feasibility and effectiveness of our proposed method.},
  archive      = {J_COMCOM},
  author       = {Fang Ye and Zitao Zhou and Yifan Wang and Yibing Li},
  doi          = {10.1016/j.comcom.2025.108317},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108317},
  shortjournal = {Comput. Commun.},
  title        = {A scalable blockchain framework for IoT based on restaking and incentive mechanisms},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proactive retention-aware online video caching scheme in mobile edge computing. <em>COMCOM</em>, <em>242</em>, 108313. (<a href='https://doi.org/10.1016/j.comcom.2025.108313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current massive video requests have caused severe network congestion. To reduce transmission latency and improve user Quality of Experience (QoE), caching infrastructures are deployed closer to the edge. Nowadays, most caching systems tend to cache content with a high programming voltage to ensure a long retention time, which leads to significant cache damage. However, as new videos emerge every second, the rapidly changing popularity makes long retention time wasteful in terms of caching resource. Moreover, with the rise of emerging video formats (such as virtual reality content), the diverse requirements for transmission latency across various video categories make balancing user QoE more challenging. To tackle these challenges, we propose a joint optimization framework that balances user QoE and operational costs through video category recognition and adaptive retention time selection. First, we model user QoE as transmission latency cost and further formulate the optimization problem as a Markov Decision Process (MDP) to minimize the system cost. To solve the proposed problem, we design a two-step Double Deep Q-Network (DDQN)-based scheme. The scheme first determines the optimal retention time through unifying the process of action selection and state-value evaluation. Secondly, it makes replacement decisions according to the computed caching value of each content. By validating on three datasets, the experiments show that the proposed scheme outperforms the baseline algorithms in both cache hit rate and system cost.},
  archive      = {J_COMCOM},
  author       = {Guangzhou Liu and Zhen Qian and Guanghui Li},
  doi          = {10.1016/j.comcom.2025.108313},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108313},
  shortjournal = {Comput. Commun.},
  title        = {Proactive retention-aware online video caching scheme in mobile edge computing},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trust-defined network: A panoramic P2P framework for distributed ledger systems. <em>COMCOM</em>, <em>242</em>, 108311. (<a href='https://doi.org/10.1016/j.comcom.2025.108311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has revolutionized distributed ledger systems by offering superior security and transparency compared to traditional centralized systems. Despite its advantages, current blockchain systems face significant challenges such as network congestion, communication errors, and scalability issues, largely due to the limitations of blockchain peer-to-peer (P2P) protocols. These problems hinder the performance, reliability, and widespread adoption of blockchain technology. In this paper, we propose a Trust-Defined Network (TDN) framework designed to solve these challenges by reflecting the physical network information to the blockchain. This approach enables the precise diagnosis of existing blockchain P2P protocol limitations and facilitates the objective verification of new improvement measures. Our proposed framework supports various blockchain network environments, particularly Ethereum-based networks, and ensures enhanced network stability and performance. Through extensive simulations and real-world case studies in IoT-enabled blockchain applications, we demonstrate that TDN significantly reduces network congestion, improves transaction finality, and enhances the reliability of blockchain communication channels. These findings highlight the framework’s potential to optimize blockchain infrastructure, making it more robust for large-scale deployment and real-world applications.},
  archive      = {J_COMCOM},
  author       = {Taehoon Yoo and Kiseok Kim and Hwangnam Kim},
  doi          = {10.1016/j.comcom.2025.108311},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108311},
  shortjournal = {Comput. Commun.},
  title        = {Trust-defined network: A panoramic P2P framework for distributed ledger systems},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-reinforcement learning driven model architecture and algorithm optimization in intelligent driving task offloading. <em>COMCOM</em>, <em>242</em>, 108310. (<a href='https://doi.org/10.1016/j.comcom.2025.108310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of rapid development of intelligent driving technology, the amount of data generated by vehicles increases dramatically, while the bottleneck of storage and computation capacity of in-vehicle devices becomes more and more prominent, and task offloading becomes the key to improve the performance of intelligent driving systems. In this context, this paper proposes the MRL-ADTO algorithm, which innovatively applies meta-reinforcement learning (MRL) to the field of intelligent driving task offloading, optimizes the directed acyclic graph (DAG) synthesis logic and the task priority ranking algorithm, designs a neural network model based on the sequence to sequence (Seq2Seq) structure, and introduces the mechanism of multi-head attention at the same time. The experimental results show that MRL-ADTO can significantly reduce the task execution delay in multiple scenarios compared with the existing algorithms, and has obvious advantages in terms of training efficiency and convergence performance, providing an efficient and reliable solution for smart driving task offloading.},
  archive      = {J_COMCOM},
  author       = {Peiying Zhang and Jiamin Liu and Zhiyuan Ren and Lizhuang Tan and Neeraj Kumar and Konstantin Igorevich Kostromitin},
  doi          = {10.1016/j.comcom.2025.108310},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108310},
  shortjournal = {Comput. Commun.},
  title        = {Meta-reinforcement learning driven model architecture and algorithm optimization in intelligent driving task offloading},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed learning-based context-aware SFC deployment in the artificial intelligence of things. <em>COMCOM</em>, <em>242</em>, 108309. (<a href='https://doi.org/10.1016/j.comcom.2025.108309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet of Things (IoT) and Artificial Intelligence (AI) technologies, the Artificial Intelligence of Things (AIoT) has become a key driving force for realizing intelligent and automated applications. The deployment of Service Function Chains (SFCs) is crucial in dynamic AIoT environments, where efficiently and flexibly deploying SFCs to meet real-time application demands is a research focus. However, existing SFC deployment methods often face challenges such as dynamic variations and uncertainty in contextual information, resource allocation inefficiencies, and limited adaptability to changing network conditions. To address these issues, we propose a learning-based context-aware dynamic SFC deployment method tailored for AIoT environments. Specifically, we introduce an attention-based contextual feature extraction method to capture dynamic changes (e.g., link latency variations) and prioritize key contextual information, improving the rate of served requests by 17.90% (69.60% vs. 59.03% for MADDPG) and enhancing the flexibility of SFC deployment decisions. Additionally, to address resource allocation bottlenecks and adaptability challenges in SFC deployment, we propose a distributed learning-based context-aware approach that uses collaborative learning and periodic updates (every 200 ms) to adjust SFC deployment strategies in response to topology changes and load variations and optimize system performance. Extensive experimental results demonstrate the efficacy of the proposed algorithm. Numerical results demonstrate that our algorithm reduces SFC deployment latency by 8% (46 ms vs. 50 ms for MADDPG), achieves 98.3% computational resource utilization, processes 211 Mbit/s service data volume, and improves adaptability to network changes, as validated in simulations.},
  archive      = {J_COMCOM},
  author       = {Wenlin Cheng and Xingwei Wang and Fuliang Li and Bo Yi and Qiang He and Chuangchuang Zhang and Chengxi Gao and Min Huang},
  doi          = {10.1016/j.comcom.2025.108309},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108309},
  shortjournal = {Comput. Commun.},
  title        = {Distributed learning-based context-aware SFC deployment in the artificial intelligence of things},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-feature fusion approach for physical layer authentication in LEO satellites. <em>COMCOM</em>, <em>242</em>, 108308. (<a href='https://doi.org/10.1016/j.comcom.2025.108308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial information networks (SINs) have emerged as a means to enhance the expanse and dependability of communication and data transmission services. SINs rely on satellite systems to provide these services, among which low earth orbit (LEO) satellites are widely concerned because of their advantages of low orbital altitude, small network transmission delay, small path loss, and high signal strength. However, due to the frequent switching of communication links between LEO satellites and the ground, the authentication mechanism of the ground users to the satellites is vulnerable to spoofing attacks, and the traditional upper layer authentication method based on encryption usually requires a lot of overhead and delay. In this case, the lightweight physical layer authentication (PLA) mechanism utilizes the inherent distinctiveness and unpredictable nature of channel physical properties, serving as a vital application in SINs for ensuring authentication. Therefore, our work introduces a PLA method incorporating multi-feature integration, aimed at delivering effective identity verification tailored for LEO satellites. The approach employs doppler frequency shift (DS), angles of arrival (AOAs), and received power (RP) features, fusing an support vector machine (SVM) classifier, to distinguish between legal and illegal satellites in different simulation scenarios. The satellite toolkit (STK) is used to collect data from the actual orbit of satellites and assess the efficacy of the scheme. The findings indicate that the scheme offers enhanced authentication capabilities.},
  archive      = {J_COMCOM},
  author       = {Rongjun Yan and Fan Jia},
  doi          = {10.1016/j.comcom.2025.108308},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108308},
  shortjournal = {Comput. Commun.},
  title        = {A multi-feature fusion approach for physical layer authentication in LEO satellites},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating blockchain with IoT: Evaluating the feasibility of lightweight bitcoin wallets on resource-constrained devices. <em>COMCOM</em>, <em>242</em>, 108300. (<a href='https://doi.org/10.1016/j.comcom.2025.108300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of blockchain technology with IoT architectures holds immense potential for advancing application design and enhancing security properties. However, the resource constraints typically present in IoT devices pose a challenge. This paper explores the feasibility of running a lightweight Bitcoin wallet on IoT devices and identifies the minimum requirements for their successful operation. A review of the literature is used to identify existing integration architectures and derive the wallet needs. The study evaluates performance metrics such as execution time, memory usage, network data transmission, and power consumption to determine the feasibility of deploying these architectures.},
  archive      = {J_COMCOM},
  author       = {Mohsen Rahmanikivi and Cristina Pérez-Solà and Víctor Garcia-Font},
  doi          = {10.1016/j.comcom.2025.108300},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108300},
  shortjournal = {Comput. Commun.},
  title        = {Integrating blockchain with IoT: Evaluating the feasibility of lightweight bitcoin wallets on resource-constrained devices},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source-rate planning in self-powered wireless multi-hop D2D settings under stochasticity: A scenario-based iterative optimization approach. <em>COMCOM</em>, <em>242</em>, 108299. (<a href='https://doi.org/10.1016/j.comcom.2025.108299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop Device-to-Device (D2D) communications are emerging as the foundation for numerous compelling 6G applications, enabling seamless information flow between distributed nodes. In the context of such uncertain wireless multi-hop D2D settings, jointly optimizing source data rates, routing, and transmission power decisions is both an essential task and a highly complex problem, particularly due to uncertainties introduced by the wireless channel states and the energy harvesting processes on the nodes. In the current literature, this problem is mostly tackled in a future agnostic sense, and/or using specific distributions to model the uncertainties. In contrast, in this paper, we compute a future energy and resource allocation plan of the network’s operation, using scenario-based optimization techniques to account for stochasticities. Scenarios can model generic distributions of uncertain quantities in a tractable manner. The formulated problem is inherently non-convex and to solve it, we propose CoNetPlan-E, a heuristic iterative method that at each iteration solves appropriately parameterized convex approximations of the original problem. We prove that CoNetPlan-E converges under realistic assumptions, while ensuring that the obtained solution at convergence is feasible for the original non-convex problem. Numerical evaluations showcase the effectiveness of the proposed method compared to existing baseline solutions, while considering three levels of increasing network topology complexity. Importantly, CoNetPlan-E is superior with respect to scalability and runtime while leading to close-to-optimal solutions as these are determined by the standard non-convex solver Ipopt.},
  archive      = {J_COMCOM},
  author       = {Georgia Stavropoulou and Eleni Stai and Maria Diamanti and Symeon Papavassiliou},
  doi          = {10.1016/j.comcom.2025.108299},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108299},
  shortjournal = {Comput. Commun.},
  title        = {Source-rate planning in self-powered wireless multi-hop D2D settings under stochasticity: A scenario-based iterative optimization approach},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed denial of service attack analysis and mitigation for MQTTv5 shared subscription. <em>COMCOM</em>, <em>242</em>, 108298. (<a href='https://doi.org/10.1016/j.comcom.2025.108298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sixth-generation (6G) networks will feature Massive IoT (M-IoT) deployments with a huge number of interconnected devices, enabling fast and reliable IoT applications. To address scalability and enhance message delivery, MQTTv5 introduces the shared subscription mechanism. However, the increased interconnectivity amplifies security vulnerabilities, posing significant risks with potentially severe consequences. In light of these challenges, this work aims to conduct a security-focused analysis of the shared subscription feature. Our study highlights the potential extent of damage from such an attack, which can potentially lead to indefinite starvation among legacy subscribers, and proposes a countermeasure to mitigate its impact. Additionally, to provide comprehensive security to the proposed mitigation mechanism, we design an Authenticated Encryption with Associated Data (AEAD)-based protection to counteract external malicious entities as well as an attacker detection mechanism based on a trust-based approach combined with the z-score statistical method to protect the proposed mitigation against internal attackers. These countermeasures are designed to accommodate the lightweight nature of MQTT and are characterized by a low protocol footprint while effectively mitigating the impact of the attack. Through an extensive experimental campaign, we tested this solution under real IoT traffic patterns to demonstrate its effectiveness and capability to restore the performance of the MQTT system targeted by the discovered attack.},
  archive      = {J_COMCOM},
  author       = {Graziano Rizzo and Mattia Giovanni Spina and Floriano De Rango},
  doi          = {10.1016/j.comcom.2025.108298},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108298},
  shortjournal = {Comput. Commun.},
  title        = {Distributed denial of service attack analysis and mitigation for MQTTv5 shared subscription},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applying reinforcement learning in slotted LoRaWAN: From concept to implementation. <em>COMCOM</em>, <em>242</em>, 108297. (<a href='https://doi.org/10.1016/j.comcom.2025.108297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Low Power Wide Area Networks (LPWANs) are increasingly adopted for Internet of Things (IoT) applications, they face significant challenges related to interference and scalability, which can lead to high collision rates and reduced network throughput. This paper presents a novel approach to enhancing the performance of LoRaWAN, one of the dominant LPWAN protocols, by leveraging Reinforcement Learning (RL). The proposed solution introduces a synchronization framework designed to operate under LoRaWAN principles, coupled with a low-cost, on-device RL mechanism that autonomously mitigates collisions. Through extensive simulations and real-world experiments, the effectiveness of the RL approach is demonstrated, showing an over 30% improvement in terms of packet delivery ratio (PDR) compared to traditional multiple access methods such as Pure-Aloha, Slotted-Aloha, and Carrier Sense Multiple Access (CSMA). Additionally, open-source implementations for both simulation and experimental validation are provided, ensuring reproducibility and facilitating further research in this domain.},
  archive      = {J_COMCOM},
  author       = {Dimitrios Zorbas and Sultan Kasenov and Kamila Salimzhanova and Dias Gaziz and Timur Ismailov and Batyrkhan Baimukhanov},
  doi          = {10.1016/j.comcom.2025.108297},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108297},
  shortjournal = {Comput. Commun.},
  title        = {Applying reinforcement learning in slotted LoRaWAN: From concept to implementation},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on grouping strategy for NOMA downlink based on pointer network. <em>COMCOM</em>, <em>242</em>, 108296. (<a href='https://doi.org/10.1016/j.comcom.2025.108296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of Non-Orthogonal Multiple Access (NOMA) technology in 5G and beyond communication systems, how to effectively group users to optimize power allocation has become a key challenge. This paper proposes a user grouping method based on a Pointer Network, which efficiently extracts user location information through embedding layers, encoder–decoder structures, and attention mechanisms, achieving the goal of precise grouping decisions and power optimization. The embedding layer maps users’ two-dimensional coordinates into a high-dimensional space, enhancing the model’s spatial awareness. The encoder–decoder structure, combined with Long Short-Term Memory (LSTM) networks and attention mechanisms, captures the spatiotemporal dependencies between users and dynamically selects the optimal path during the grouping process. Experimental results show that when users are located 300 meters from the base station, the recognition accuracy of a 4-user grouping reaches 94.85%, and that of a 6-user grouping reaches 89.3%. The method also demonstrates strong robustness under multipath fading channels and low signal-to-noise ratio conditions. Compared to random grouping methods, the proposed grouping strategy exhibits better adaptability and scalability in complex communication environments, significantly reducing power consumption, and providing new technical support for resource allocation and energy management in NOMA systems.},
  archive      = {J_COMCOM},
  author       = {Lingfeng Wu and Rui Zhu and Yarong Chen and Peng Chu and Juan Tian and Jiuxiao Cao},
  doi          = {10.1016/j.comcom.2025.108296},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108296},
  shortjournal = {Comput. Commun.},
  title        = {Research on grouping strategy for NOMA downlink based on pointer network},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private networks: Evolution, ecosystem, use cases, architecture, spectrum, and deployment challenges. <em>COMCOM</em>, <em>242</em>, 108295. (<a href='https://doi.org/10.1016/j.comcom.2025.108295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private networks have reshaped enterprise communications by providing unmatched control, security, and tailored solutions for various industries. This paper presents an in-depth survey of private networks, covering their evolution, current landscape, and future outlook. Key topics include the use cases, architecture, spectrum management, and deployment strategies. The study examines the transition from private 4G/LTE to private 5G networks, fueled by demands for higher data throughput and ultra-low latency across sectors. It highlights the advantages of private 5G over public mobile networks (MNOs) and Wi-Fi, with a special focus on spectrum sharing as a means to optimize frequency use. Additionally, the paper reviews global spectrum allocations for private 5G, providing an overview of regulatory frameworks and available frequency bands across countries. It also explores future prospects, including private 6G networks and emerging spectrum technologies. Key challenges such as high deployment costs, interoperability issues, and security concerns are discussed alongside potential solutions. Through this comprehensive analysis, the paper aims to provide valuable insights for researchers, practitioners, and policymakers in the field of private networks.},
  archive      = {J_COMCOM},
  author       = {Onur Sahin and Vanlin Sathya and Mehmet Yavuz},
  doi          = {10.1016/j.comcom.2025.108295},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108295},
  shortjournal = {Comput. Commun.},
  title        = {Private networks: Evolution, ecosystem, use cases, architecture, spectrum, and deployment challenges},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simplifying distributed application deployment at the edge through software-defined overlay networks. <em>COMCOM</em>, <em>242</em>, 108294. (<a href='https://doi.org/10.1016/j.comcom.2025.108294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for low latency, bandwidth efficiency, and privacy has driven the deployment of distributed applications to the network edge. However, edge environments introduce concrete challenges such as limited infrastructure control, constrained connectivity due to NAT or firewalls, and the heterogeneity of devices and network conditions. This paper introduces a software-defined overlay networking (SDON) middleware that addresses these issues by simplifying the development and deployment of edge applications through centralized control and dynamic overlay management. SDON allows applications to define high-level requirements, such as node and link characteristics and the network topology. These requirements are translated into device-specific configurations and enforced across suitable edge devices. We implemented our SDON middleware as a fully functional software and evaluated it in two edge computing use cases: i) routing for video streaming across middleboxed edge devices and ii) computation offloading on heterogeneous edge devices. Our results show that deployments via SDON, with centrally enforced optimizations, improve application performance by reducing mean streaming latency by 20 % and computation times by 22 %.},
  archive      = {J_COMCOM},
  author       = {Heiko Bornholdt and Kevin Röbert and Stefan Schulte and Janick Edinger and Mathias Fischer},
  doi          = {10.1016/j.comcom.2025.108294},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108294},
  shortjournal = {Comput. Commun.},
  title        = {Simplifying distributed application deployment at the edge through software-defined overlay networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving satellite network efficiency with terminal traffic prediction and SQP-SRA algorithm. <em>COMCOM</em>, <em>242</em>, 108293. (<a href='https://doi.org/10.1016/j.comcom.2025.108293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the low resource utilization in satellite networks caused by heterogeneous regional traffic demands, this paper proposes a resource allocation strategy for LEO satellite internet based on terminal traffic prediction. An improved LSTM-GRU hybrid model is developed using real-world datasets to forecast ground traffic, accounting for periodic patterns and weather effects. A leaseable EOSN differentiated transmission framework is designed to enable targeted resource allocation and inter-satellite leasing, enhancing network coverage. To optimize data transmission ratios, user bandwidth, and service pricing, we introduce a sequential quadratic programming-based satellite resource allocation (SQP-SRA) algorithm that balances latency and energy consumption. Compared with LSTM, GRU, Transformer, and wavelet neural networks, the proposed model reduces traffic prediction error by approximately 26%. Simulation results demonstrate that, relative to the DDTOA, FCFS, and TOMRA algorithms, the proposed strategy improves user benefits by approximately 60% and enhances satellite service provider revenues by approximately 80%.},
  archive      = {J_COMCOM},
  author       = {Liangang Qi and Enqiang Wang and Tianfang Xu and Yuan Zhu and Yun Zhao},
  doi          = {10.1016/j.comcom.2025.108293},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108293},
  shortjournal = {Comput. Commun.},
  title        = {Improving satellite network efficiency with terminal traffic prediction and SQP-SRA algorithm},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved AVB-aware scheduling of time-triggered traffic in time-sensitive networks. <em>COMCOM</em>, <em>242</em>, 108292. (<a href='https://doi.org/10.1016/j.comcom.2025.108292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-Sensitive Networking (TSN) provides deterministic services for diverse traffic types within a unified network. Among them, time-triggered (TT) traffic requires stringent timing guarantees, typically achieved through precise scheduling using Gate Control Lists (GCLs) in Time-Aware Shapers (TASs). However, most existing studies primarily focus on TT scheduling, often overlooking its impact on Audio Video Bridging (AVB) traffic, which demands worst-case delay (WCD) guarantees. This paper proposes an improved AVB-aware scheduling approach for TT traffic that enhances AVB performance without compromising TT schedulability. A rigorous network calculus analysis identifies two critical factors influencing WCD of AVB traffic: the maximum TT window length and the minimum relative offset between adjacent TT windows. Building on these insights, we develop a lightweight objective function for TT flow scheduling, enabling efficient evaluation of the impact on AVB traffic. This objective function is embedded into a Greedy Randomized Adaptive Search Procedure (GRASP)-based scheduling framework, further enhanced by a flow sorting strategy and a flexible local search mechanism that prioritizes high-impact TT flows and adaptively escapes local optima. Simulation results demonstrate that the proposed method significantly improves AVB performance and reduces runtime overhead, while consistently maintaining full TT schedulability across diverse TSN scenarios.},
  archive      = {J_COMCOM},
  author       = {Meng Wang and Yiqin Lu},
  doi          = {10.1016/j.comcom.2025.108292},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108292},
  shortjournal = {Comput. Commun.},
  title        = {An improved AVB-aware scheduling of time-triggered traffic in time-sensitive networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing vertical handover of energy efficient sleep mode schemes in heterogeneous networks. <em>COMCOM</em>, <em>242</em>, 108291. (<a href='https://doi.org/10.1016/j.comcom.2025.108291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous networks (HetNets) are a promising solution for the growing traffic demands of 5G. However, the continuous construction of small base stations (SBSs) increases the number of vertical handovers, which is closely related to a decrease in quality of service (QoS) due to the challenges in handover management. Therefore, many studies calculate the vertical handover rate using simulation-based or numerical methods. The sleep mode schemes, which dynamically put some SBSs into sleep mode, aim to address the concerns of excessive power consumption and also reduce the number of vertical handovers. Sleep modes are cost-effective and have become one of the popular methods for reducing energy consumption in HetNets. However, there is currently no model to analyze the number of vertical handovers when sleep modes are applied, making it difficult for internet service providers (ISPs) to estimate the impact of vertical handovers. In this paper, we analyze the number of vertical handovers in sleep mode schemes for heterogeneous networks and calculate the energy savings of three different schemes. The average errors of our proposed mathematical equations are less than 5%.},
  archive      = {J_COMCOM},
  author       = {Ting-Yu Lin and Hao-Zhong Zheng and Chun-Hao Yang and Fang-Yi Lee and Chia-Heng Tu and Meng-Hsun Tsai},
  doi          = {10.1016/j.comcom.2025.108291},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108291},
  shortjournal = {Comput. Commun.},
  title        = {Analyzing vertical handover of energy efficient sleep mode schemes in heterogeneous networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network traffic classification through high-order L-moments and multi-objective optimization. <em>COMCOM</em>, <em>242</em>, 108290. (<a href='https://doi.org/10.1016/j.comcom.2025.108290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of encrypted and dynamic network traffic poses significant challenges to traditional traffic analysis methods, underscoring the need for robust and scalable solutions. Statistical approaches like L-moments have demonstrated exceptional potential in characterizing traffic flows, offering reduced sensitivity to outliers and the ability to capture higher-order distributional properties with minimal data. Building on previous work by the authors, this study introduces significant enhancements to the L-moment-based methodology for flow analysis and classification, specifically addressing limitations in feature selection and sample size requirements, aspects crucial for achieving deployable configurations in high-performance network environments. Key contributions include the integration of the fifth-order L-moment ratio ( τ 5 ) for enriched traffic representation and a multi-objective optimization framework based on a multi-objective evolutionary algorithm that balances competing goals: minimizing flow features selected for flow classification, reducing sample sizes for L-moment estimation, and maximizing classification quality. The enhanced methodology was applied to the CIC-DDoS2019 dataset, previously used in the authors’ earlier work, enabling direct comparison. Results show a reduction in sample size requirements from 200 to as few as 10, while simultaneously improving classification accuracy and selecting minimal features. These findings demonstrate the scalability and effectiveness of the proposed framework, designed for resource-constrained environments in Next-Generation Networks (NGNs), and make it publicly available for reproducibility and future research.},
  archive      = {J_COMCOM},
  author       = {Jesús Galeano-Brajones and Mihaela I. Chidean and Francisco Luna and Jesús Calle-Cancho and Javier Carmona-Murillo},
  doi          = {10.1016/j.comcom.2025.108290},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108290},
  shortjournal = {Comput. Commun.},
  title        = {Network traffic classification through high-order L-moments and multi-objective optimization},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A blockchain solution for decentralized training in machine learning for IoT. <em>COMCOM</em>, <em>242</em>, 108289. (<a href='https://doi.org/10.1016/j.comcom.2025.108289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of Internet of Things (IoT) devices and applications has led to an increased demand for advanced analytics and machine learning techniques capable of handling the challenges associated with data privacy, security, and scalability. Federated learning (FL) and blockchain technologies have emerged as promising approaches to address these challenges by enabling decentralized, secure, and privacy-preserving model training on distributed data sources. In this paper, we present a novel IoT solution that combines the incremental learning vector quantization algorithm (XuILVQ) with Ethereum blockchain technology to facilitate secure and efficient data sharing, model training, and prototype storage in a distributed environment. Our proposed architecture addresses the shortcomings of existing blockchain-based FL solutions by reducing computational and communication overheads while maintaining data privacy and security. We assess the performance of our system through a series of experiments, showing its potential to enhance the accuracy and efficiency of machine learning tasks in IoT settings.},
  archive      = {J_COMCOM},
  author       = {Carlos Beis-Penedo and Francisco Troncoso-Pastoriza and Rebeca P. Díaz-Redondo and Ana Fernández-Vilas and Manuel Fernández-Veiga and Martín González Soto},
  doi          = {10.1016/j.comcom.2025.108289},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108289},
  shortjournal = {Comput. Commun.},
  title        = {A blockchain solution for decentralized training in machine learning for IoT},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FLoV2T: A fine-grained malicious traffic classification method based on federated learning for AIoT. <em>COMCOM</em>, <em>242</em>, 108288. (<a href='https://doi.org/10.1016/j.comcom.2025.108288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Artificial Intelligence of Things (AIoT), the network security risks associated with AIoT have surged, making precise fine-grained malicious traffic classification (MTC) technology essential, but the reliance on large datasets raises privacy concerns. Federated Learning (FL) offers a privacy-preserving alternative, but existing FL-based solutions still suffer from suboptimal classification accuracy, limited terminal resources, and the non-independent and identically distributed (non-IID) IoT data that hinder effective global model aggregation. To address these issues, this paper introduces FLoV2T — a FL-based fine-grained MTC method for AIoT. To improve classification performance, we first employ a pretrained Vision Transformer (ViT) to extract discriminative features by visualizing raw network traffic as images, thereby tackling the problem of inadequate feature representation. To alleviate the burden of resource constraints and high communication costs, we then implement a local parameter fine-tuning mechanism based on Low-Rank Adaptation (LoRA), significantly reducing the parameter for model learning and communication at the edge. Furthermore, to counteract the model bias towards clients’ non-IID data on model aggregation, we design a regularized parameter aggregation strategy to enhance global model robustness. Experimental results show that FLoV2T achieves an average accuracy of 97.26% and an F1 score of 96.99%, surpassing the baseline by 10.94% and 11.47%. Moreover, LoRA reduces parameter count by approximately 64 times while maintaining high classification performance, and under non-IID conditions, overall performance reaches an average accuracy of 96.17% and an average F1 score of 95.81%, underscoring FLoV2T’s potential in future AIoT communication networks.},
  archive      = {J_COMCOM},
  author       = {Fanyi Zeng and Chen Xu and Dapeng Man and Junhui Jiang and Wu Yang},
  doi          = {10.1016/j.comcom.2025.108288},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108288},
  shortjournal = {Comput. Commun.},
  title        = {FLoV2T: A fine-grained malicious traffic classification method based on federated learning for AIoT},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ILoRa: Interleaving-driven neural network for rate adaptation in LoRa communications. <em>COMCOM</em>, <em>242</em>, 108287. (<a href='https://doi.org/10.1016/j.comcom.2025.108287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rate adaptation in LoRa communications is crucial for improving the channel throughput by adjusting the data rate according to varying channel conditions. Existing methods typically operate at the packet or symbol level, which limits their ability to achieve fine-grained rate adaptation. In this paper, we propose ILoRa, an Interleaving-driven partial transmission method that automatically adjusts transmission rates according to real-time channel conditions. To be specific, we first introduce intra-symbol interleaving that leverages a progressive inorder traversal method to determine the transmission order within a symbol. Then inter-symbol interleaving is applied to coordinate the order across symbols. To manage the interleaving-induced partial transmission and improve communication performance under noisy conditions, we employ a multi-task convolutional recurrent neural network (MT-CRNN). This network leverages advanced data augmentation methods to further enhance channel robustness: time-spectral augmentation to mitigate information loss and synthetic noisy data to simulate various channel conditions. Extensive experimental results demonstrate that ILoRa significantly enhance transmission efficiency while maintaining reliable performance even in challenging environments.},
  archive      = {J_COMCOM},
  author       = {Xiaoke Qi and Haiyang Li and Dian Zhang and Lu Wang},
  doi          = {10.1016/j.comcom.2025.108287},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108287},
  shortjournal = {Comput. Commun.},
  title        = {ILoRa: Interleaving-driven neural network for rate adaptation in LoRa communications},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning based interference optimization for coordinated beamforming in ultra-dense wi-fi networks. <em>COMCOM</em>, <em>242</em>, 108286. (<a href='https://doi.org/10.1016/j.comcom.2025.108286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next-generation Wi-Fi networks are expected to have an ultra-dense deployment of access points (APs), thus, interference from overlapping basic service sets (OBSSs) poses challenges for interference management. Wi-Fi 8 aims at mitigating such interference using multi-access point coordination (MAPC). One of the MAPC variants is coordinated beamforming (Co-BF), where neighboring APs direct their signals towards specific users. Besides beam steering, APs can also perform null steering, which is more complex but can bring greater performance gains. In this paper, we present a centralized approach named intelligent null steering by reinforcement learning (IntelliNull), designed to reduce interference from neighboring transmitters by coordinated nulling while maximizing the signal quality at each station. We show that training the beam and null steering mechanism with a deep deterministic policy gradient (DDPG), it is possible to steer beams toward associated stations while intelligently nulling the most destructive interference from OBSS rather than nulling random interference directions. This method enhances communication between the AP and neighboring stations by reducing channel access contention, enabling transmissions at full power, and reducing worst-case latency. The proposed IntelliNull agent continuously adapts to changes in the network environment, including node mobility using channel state information (CSI) collected in real-time. We also compare our IntelliNull, which is based on beamforming plus nulling, with the baseline which is based on beamforming only. Our results demonstrate that IntelliNull outperforms the baseline by effectively mitigating interference, leading to higher throughput and better signal-to-interference-plus-noise ratio (SINR), especially in dense deployment scenarios where beamforming alone fails to sufficiently suppress OBSS interference.},
  archive      = {J_COMCOM},
  author       = {Jamshid Bacha and Anatolij Zubow and Szymon Szott and Katarzyna Kosek-Szott and Falko Dressler},
  doi          = {10.1016/j.comcom.2025.108286},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108286},
  shortjournal = {Comput. Commun.},
  title        = {Deep reinforcement learning based interference optimization for coordinated beamforming in ultra-dense wi-fi networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient security service function chaining based on federated learning in edge networks. <em>COMCOM</em>, <em>242</em>, 108285. (<a href='https://doi.org/10.1016/j.comcom.2025.108285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating demand for network services has prompted the evolution of Service Function Chaining (SFC) within 6G networks to deliver sophisticated, customized services while ensuring robust cybersecurity. This paper introduces an efficient and secure framework for SFC in Mobile Edge Computing (MEC) environments, termed the Federated Learning-based SFC (FL-SFC), which integrates SFC, MEC, and Federated Learning (FL) to enhance service policy decision-making and safeguard user privacy. The FL-SFC framework enables dynamic updating of service policies and optimizes communication efficiency. We propose an anomaly detection model, CNN-GRU, which combines Convolutional Neural Networks (CNNs) and Gated Recurrent Units (GRUs) to significantly improve anomaly detection performance at the network edge. Additionally, to address the high communication costs associated with service policy models, we have designed a model compression mechanism leveraging sparsification and quantization techniques, which substantially reduces communication overhead during model training. Simulation experiments demonstrated the superiority of the FL-SFC framework and the CNN-GRU model in detection performance over existing methods. Results indicate that our model excels in accuracy, precision, recall, and F1-score while significantly reducing the number of communication bits, thereby validating the effectiveness of our approach.},
  archive      = {J_COMCOM},
  author       = {Yunjian Jia and Jian Yu and Liang Liang and Fang Fang and Wanli Wen},
  doi          = {10.1016/j.comcom.2025.108285},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108285},
  shortjournal = {Comput. Commun.},
  title        = {Efficient security service function chaining based on federated learning in edge networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correctness of flow migration across network function instances. <em>COMCOM</em>, <em>242</em>, 108284. (<a href='https://doi.org/10.1016/j.comcom.2025.108284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Functions (NFs) improve the safety and efficiency of networks. Flows traversing NFs may need to be migrated from a source NF instance (sNF) to a destination NF instance (dNF) to balance load, conserve energy, etc. When NFs are stateful, the information stored on an sNF per flow must be migrated to the corresponding dNF before the flow is migrated, to avoid problems of consistency. Our main contribution is to examine what it means to correctly migrate flows from a stateful NF instance. We define the property of Weak-O, where only the state information required for packets to be correctly forwarded from an sNF is migrated first to the corresponding dNF, while the remaining states are eventually migrated. Weak-O can be preserved without buffering or dropping packets, unlike existing algorithms. We propose an algorithm that preserves Weak-O and prove its correctness. Even though this may cause packet re-ordering, we experimentally demonstrate that the goodputs with and without migration are comparable when the old and new paths have the same delays and bandwidths. This is also true when the new path has larger bandwidth or at most 5 times longer delays. Thus flow migration without buffering is practical, contrary to what was thought before. We also prove that no criterion stronger than Weak-O can be preserved in a flow migration system that requires no buffering or dropping of packets and eventually synchronizes its states.},
  archive      = {J_COMCOM},
  author       = {Ranjan Patowary and Gautam Barua and Radhika Sukapuram},
  doi          = {10.1016/j.comcom.2025.108284},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108284},
  shortjournal = {Comput. Commun.},
  title        = {Correctness of flow migration across network function instances},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDR: Stackelberg-based deep reinforcement learning for multi-skill spatiotemporal task allocation in AIoT systems. <em>COMCOM</em>, <em>242</em>, 108283. (<a href='https://doi.org/10.1016/j.comcom.2025.108283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In AIoT-based multi-skill environments, task allocation is a complex process that involves multiple constraints and worker acceptance rates. However, existing studies often overlook worker acceptance rates and fail to properly balance the interests of both workers and requesters. To address this, we propose SDR, a system based on a dual Dueling DQN model in deep reinforcement learning, designed to maximize the long-term utility of all participants while considering user acceptance rates and demand constraints. SDR introduces targeted enhancements in state, action, and reward design to balance acceptance rates with spatiotemporal and skill constraints, optimizing both immediate and long-term task allocation performance. To resolve conflicts of interest, we integrate Pareto optimization into the Q-value computation and action selection. For scenarios where interests align, we adopt Stackelberg game theory to refine the reward mechanism. Extensive simulations on both synthetic and real-world datasets validate the effectiveness of our approach in improving task allocation and pricing strategies.},
  archive      = {J_COMCOM},
  author       = {Yu Li and Fengya Yin and Yihao Zheng and Wenjian Xu and Jung Yoon Kim and Zhe Peng},
  doi          = {10.1016/j.comcom.2025.108283},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108283},
  shortjournal = {Comput. Commun.},
  title        = {SDR: Stackelberg-based deep reinforcement learning for multi-skill spatiotemporal task allocation in AIoT systems},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proactive handover for task offloading in UAVs. <em>COMCOM</em>, <em>242</em>, 108282. (<a href='https://doi.org/10.1016/j.comcom.2025.108282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) are usually deployed alongside Internet of Things (IoT) devices in smart city applications, particularly for critical tasks such as disaster management that require continuous service. UAVs often handle resource-intensive and sensitive tasks through offloading, but unexpected task interruptions due to UAV dropouts can generate safety risks and increase costs. Although existing approaches in the literature have already addressed proactive handovers to mitigate such disruptions, their primary focus is on communication issues arising from UAV movement and are unable to handle offloading related issues. In this paper, we include in our model, in addition to communication, factors such as energy, computation requirements, and dynamic environmental conditions (e.g., wind speed and incentive), pushing toward a comprehensive solution for UAV task offloading and resource allocation. In fact, we formulate our problematic as a Markov game, which we solve using a Multi Agent Deep Q Network (MADQN). In our experiments, we assessed our approach using a federated learning scenario to illustrate its effectiveness in a realistic distributed application setting against several baselines from the state of the art. Results showed that our approach outperforms its peers in terms of system utility, and tradeoff between cost and dropout rates, leading to an improved handover management of computational and energy resources in UAV-IoT based systems. In fact, it reduces the dropout rate by approximately 45% compared to the second-best baseline, leading to a 2% improvement in model accuracy and a 50% reduction in deployment costs.},
  archive      = {J_COMCOM},
  author       = {Mohammed Riyadh Abdmeziem and Amina Ahmed Nacer and Soumeya Demil},
  doi          = {10.1016/j.comcom.2025.108282},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108282},
  shortjournal = {Comput. Commun.},
  title        = {Proactive handover for task offloading in UAVs},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance model and system optimization of an energy-saving strategy based on adaptive service rate tuning in cloud data centers with micro-burst traffic. <em>COMCOM</em>, <em>242</em>, 108281. (<a href='https://doi.org/10.1016/j.comcom.2025.108281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing competition in cloud market, reducing operating costs and improving Quality of Service (QoS) are two of the key issues that cloud vendors need to consider. In order to reduce the power consumption while mitigating the negative impact of micro-burst traffic in Cloud Data Centers (CDCs) on performance, and make cloud vendors more competitive, we design an Energy-saving Strategy based on Sleep and Adaptive Service-rate Tuning (ES-SAST) in this paper. We model the arrivals of the cloud task requests as an environment-dependent R -phase Markov Arrival Process (MAP ( R ) ), and we establish a multi-server synchronous multi-vacation queue with adaptive service rate tuning. We construct a four-dimensional Markov chain to analyze the queue, and we calculate some measures to evaluate the energy efficiency and QoS in the steady state. Then we develop an objective function composed of three performance measures. Finally, we propose an Improved Fire Hawk Optimizer (IFHO) with multi-strategy integration, and IFHO jointly optimizes two system parameters. An empirical study shows that IFHO chooses a lower system expected cost, where the power consumption of the system falls by 3%, the latency of tasks decreases by 19%, and the loss rate of the system reduces by 37%, on average.},
  archive      = {J_COMCOM},
  author       = {Xuena Yan and Shunfu Jin},
  doi          = {10.1016/j.comcom.2025.108281},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108281},
  shortjournal = {Comput. Commun.},
  title        = {Performance model and system optimization of an energy-saving strategy based on adaptive service rate tuning in cloud data centers with micro-burst traffic},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming data limitations in internet traffic forecasting: LSTM models with transfer learning and wavelet augmentation. <em>COMCOM</em>, <em>242</em>, 108280. (<a href='https://doi.org/10.1016/j.comcom.2025.108280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate internet traffic prediction in smaller ISP networks is challenged by limited data availability. This paper explores this issue using transfer learning and data augmentation techniques with two LSTM-based models, LSTMSeq2Seq and LSTMSeq2SeqAtn, initially trained on a comprehensive dataset provided by Juniper Networks, Inc. and subsequently applied to smaller datasets. The datasets represent real internet traffic telemetry, offering insights into diverse traffic patterns across different network domains. Our study found that although both models performed well in single-step predictions, multi-step forecasting was more challenging, especially regarding long-term accuracy. Empirical results demonstrated that LSTMSeq2Seq outperformed LSTMSeq2SeqAtn on smaller datasets, with improvements in forecasting accuracy by up to 36.70% in MAE and 27.66% in WAPE after applying data augmentation using Discrete Wavelet Transform. The LSTMSeq2Seq model achieved an accuracy improvement from 83% to 88% for 6-step forecasts, 82% to 88% for 9-step forecasts, and 81% to 87% for 12-step forecasts, whereas LSTMSeq2SeqAtn exhibited a more stable short-term performance but higher variability in longer forecasts. Additionally, the mean absolute percentage error (MAPE) of multi-step predictions increased over longer horizons, with LSTMSeq2Seq reaching 6.74% at 12 steps and LSTMSeq2SeqAtn at 6.77%, highlighting the challenge of long-term forecasting. Variability analysis showed that while the attention mechanism in LSTMSeq2SeqAtn improved short-term prediction consistency, it also increased uncertainty in longer forecasts, as seen in the interquartile range (IQR) rising from 0.578 at 6 steps to 1.237 at 9 steps. Outlier analysis further confirmed that LSTMSeq2Seq exhibited more stable improvements, whereas LSTMSeq2SeqAtn showed increased dispersion in forecast accuracy. These findings underscore the importance of transfer learning and data augmentation in enhancing forecasting accuracy, particularly for smaller ISP networks with limited data availability. Furthermore, our analysis highlights the trade-offs between model complexity, short-term consistency, and long-term stability in internet traffic prediction.},
  archive      = {J_COMCOM},
  author       = {Sajal Saha and Anwar Haque and Greg Sidebottom},
  doi          = {10.1016/j.comcom.2025.108280},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108280},
  shortjournal = {Comput. Commun.},
  title        = {Overcoming data limitations in internet traffic forecasting: LSTM models with transfer learning and wavelet augmentation},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring traffic pattern variability in vehicular federated learning. <em>COMCOM</em>, <em>242</em>, 108279. (<a href='https://doi.org/10.1016/j.comcom.2025.108279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of software-defined vehicles has brought machine learning into the vehicular domain. To support these data-driven applications, techniques to incentivize users to share their vehicle data are crucial. Federated learning trains machine learning models in a distributed manner, leveraging client data without compromising its privacy. Nonetheless, in vehicular networks, the dynamic behavior of nodes affects client availability and the global model’s performance. Accordingly, this paper evaluates federated learning (FL) in a realistic vehicular network topology, accounting for real vehicle traffic in two Brazilian urban areas. The network simulation covers 3 . 7 km 2 with 1290 vehicles per hour and road speeds, based on real data. Our paper provides a comprehensive analysis of the impact that different traffic behaviors can yield during the training phase of a federated learning model. We observe that there is a performance decay in urban areas with longer vehicle permanence. Interestingly, longer vehicle participation in FL training leads to a biased final model with reduced generalization. We propose a novel approach to verify vehicle variability over time, by using the Dice-Sørensen coefficient to compare the set of clients participating in different rounds of training. By maintaining the vehicle variability over the rounds we can reduce the effect of the bias on the model, and – with a 47% reduction of the communication overhead – achieve faster learning, higher convergence in the first 15 rounds, and an equivalent final accuracy. Additionally, we extend our analysis by conducting simulations under more extreme traffic scenarios across multiple datasets, using a MobileNetV3. The results confirm that sustaining high vehicle variability – in scenarios with a brief participation of vehicles in the training – yields comparable model performance while saving up to 83.5 GB in communication costs.},
  archive      = {J_COMCOM},
  author       = {Giuliano Fittipaldi and Rodrigo S. Couto and Luís H.M.K. Costa},
  doi          = {10.1016/j.comcom.2025.108279},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108279},
  shortjournal = {Comput. Commun.},
  title        = {Exploring traffic pattern variability in vehicular federated learning},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Delay analysis of BFT consensus: Case study of narwhal and bullshark protocols. <em>COMCOM</em>, <em>242</em>, 108278. (<a href='https://doi.org/10.1016/j.comcom.2025.108278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acknowledging the critical influence of consensus delays on blockchain performance, this paper presents an analytical and simulation-based exploration of delay characteristics in Byzantine Fault Tolerant (BFT) consensus mechanisms. Our focus is on SUI, a blockchain system that employs a Directed Acyclic Graph (DAG) structure to support parallel transaction execution. SUI relies on two integrated protocols: Narwhal, a mempool protocol responsible for efficient block dissemination and DAG construction; and Bullshark, which organizes DAG vertices to produce a consistent total order of transactions without incurring additional communication overhead. While our previous work modeled Narwhal’s delay characteristics under various message propagation distributions, this study shifts attention to Bullshark—the protocol responsible for reaching consensus. We propose a probabilistic analytical model that estimates the number of rounds required to reach consensus. In this model, each validator’s decision is treated as a Bernoulli trial, and we apply the binomial distribution to determine the probability of reaching quorum. This framework enables us to analyze the expected delay of the protocol. To validate our model, we implemented both Narwhal and Bullshark and conducted extensive simulations. The simulation results show strong agreement with our analytical predictions, confirming the accuracy of our model. For instance, under a Gaussian delay model with mean μ = 1 ms and standard deviation σ = 0 . 25 ms—values representative of short-range wireless communication in real-world IoT or LAN settings [1] —we predict an average round duration of approximately 3.26 ms. Furthermore, based on our binomial-based model of block commitment, the expected number of rounds to reach consensus is approximately 1 when f = 10 , indicating that blocks typically commit in a single round with high probability. To the best of our knowledge, this is the first study to model Bullshark’s consensus process using Bernoulli trials and binomial distributions. Our contributions offer a novel framework for evaluating its efficiency and provide insights that can guide future optimization and scalability efforts for DAG-based BFT protocols.},
  archive      = {J_COMCOM},
  author       = {Khouloud Hwerbi and Ichrak Amdouni and Cédric Adjih and Leila Azouz Saidane and Anis Laouiti},
  doi          = {10.1016/j.comcom.2025.108278},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108278},
  shortjournal = {Comput. Commun.},
  title        = {Delay analysis of BFT consensus: Case study of narwhal and bullshark protocols},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic split federated learning for resource-constrained IoT systems. <em>COMCOM</em>, <em>242</em>, 108275. (<a href='https://doi.org/10.1016/j.comcom.2025.108275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient resource utilization in Internet of Things (IoT) systems is challenging due to device limitations. These limitations restrict on-device machine learning (ML) model training, leading to longer processing times and inefficient metadata analysis. Additionally, conventional centralized data collection poses privacy concerns, as raw data has to leave the device to the server for processing. Combining Federated Learning (FL) and Split Learning (SL) offers a promising solution by enabling effective machine learning on resource-constrained devices while preserving user privacy. However, the dynamic nature of IoT resources and device heterogeneity can complicate the application of these solutions, as some IoT devices cannot complete the training task on time. To address these concerns, we have developed a Dynamic Split Federated Learning (DSFL) architecture that dynamically adjusts to the real-time resource availability of individual clients. Combining real-time split-point selection with a Genetic Algorithm (GA) for client selection, tailored to heterogeneous, resource-constrained IoT devices. DSFL ensures optimal utilization of resources and efficient training across heterogeneous IoT devices and servers. Our architecture detects each IoT device’s training capabilities by identifying the number of layers it can train. Moreover, an effective Genetic Algorithm (GA) process strategically selects the clients required to complete the split federated learning round. Cooperatively, the clients and servers train their parts of the model, aggregate them, and then combine the results before moving to the next round. Our proposed architecture enables collaborative model training across devices while preserving data privacy by combining FL’s parallelism with SL’s dynamic modeling. We evaluated our architecture on sensory and image-based datasets, showing improved accuracy and reduced overhead compared to baseline methods.},
  archive      = {J_COMCOM},
  author       = {Mohamad Wazzeh and Ahmad Hammoud and Azzam Mourad and Hadi Otrok and Chamseddine Talhi and Zbigniew Dziong and Chang-Dong Wang and Mohsen Guizani},
  doi          = {10.1016/j.comcom.2025.108275},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108275},
  shortjournal = {Comput. Commun.},
  title        = {Dynamic split federated learning for resource-constrained IoT systems},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical layer security in FAS-aided wireless powered NOMA systems. <em>COMCOM</em>, <em>242</em>, 108274. (<a href='https://doi.org/10.1016/j.comcom.2025.108274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of communication technologies and the emergence of sixth-generation (6G) networks have introduced unprecedented opportunities for ultra-reliable, low-latency, and energy-efficient communication. Integrating technologies like non-orthogonal multiple access (NOMA) and wireless powered communication networks (WPCNs) brings new challenges. These include energy constraints and increased security vulnerabilities. Traditional antenna systems and orthogonal multiple access schemes struggle to meet the increasing demands for performance and security in such environments. To address this gap, this paper investigates the impact of emerging fluid antenna systems (FAS) on the performance of physical layer security (PLS) in WPCNs. Specifically, we consider a scenario in which a transmitter, powered by a power beacon via an energy link, transmits confidential messages to legitimate FAS-aided users over information links while an external eavesdropper attempts to decode the transmitted signals. Additionally, users leverage the NOMA scheme, where the far user may also act as an internal eavesdropper. For the proposed model, we first derive the distributions of the equivalent channels at each node and subsequently obtain compact expressions for the secrecy outage probability (SOP) and average secrecy capacity (ASC), using the Gaussian quadrature methods. Our results reveal that incorporating the FAS for NOMA users, instead of the TAS, enhances the performance of the proposed secure WPCN.},
  archive      = {J_COMCOM},
  author       = {Farshad Rostami Ghadi and Masoud Kaveh and Kai-Kit Wong and Diego Martín and Riku Jäntti and Zheng Yan},
  doi          = {10.1016/j.comcom.2025.108274},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108274},
  shortjournal = {Comput. Commun.},
  title        = {Physical layer security in FAS-aided wireless powered NOMA systems},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A slot-based energy storage decision-making approach for optimal off-grid telecommunication operator. <em>COMCOM</em>, <em>242</em>, 108273. (<a href='https://doi.org/10.1016/j.comcom.2025.108273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a slot-based energy storage approach for decision-making in the context of an Off-Grid telecommunication operator. We consider network systems powered by solar panels, where harvest energy is stored in a battery that can also be sold when fully charged. To reflect real-world conditions, we account for non-stationary energy arrivals and service demands that depend on the time of day, as well as the failure states of PV panel. The network operator we model faces two conflicting objectives: maintaining the operation of its infrastructure and selling (or supplying to other networks) surplus energy from fully charged batteries. To address these challenges, we developed a slot-based Markov Decision Process (MDP) model that incorporates positive rewards for energy sales, as well as penalties for energy loss and battery depletion. This slot-based MDP follows a specific structure we have previously proven to be efficient in terms of computational performance and accuracy. From this model, we derive the optimal policy that balances these conflicting objectives and maximizes the average reward function. Additionally, we present results comparing different cities and months, which the operator can consider when deploying its infrastructure to maximize rewards based on location-specific energy availability and seasonal variations. Experimental results show that our proposed algorithm outperforms classical methods in large-scale scenarios. While Relative Value Iteration algorithm remains competitive on smaller instances, its convergence time increases significantly under strict precision requirements (e.g., ϵ < 1 0 − 10 ). In contrast, our method maintains both speed and robustness, solving MDPs with up to 2 × 1 0 5 states and 100 actions in under one hour, whereas standard approaches exceed 1 0 4 seconds.},
  archive      = {J_COMCOM},
  author       = {Youssef Ait El Mahjoub and Jean-Michel Fourneau},
  doi          = {10.1016/j.comcom.2025.108273},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108273},
  shortjournal = {Comput. Commun.},
  title        = {A slot-based energy storage decision-making approach for optimal off-grid telecommunication operator},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight secret-sharing-based defense against model poisoning attacks in privacy-preserving federated learning. <em>COMCOM</em>, <em>242</em>, 108272. (<a href='https://doi.org/10.1016/j.comcom.2025.108272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Artificial Intelligence of Things (AIoT) converges with Privacy-Preserving Federated Learning (PPFL), the challenge of defending against model poisoning attacks emerges as increasingly critical. Due to PPFL’s cryptographic protocols for protecting gradient exchanges, detecting poisoning attacks becomes challenging. Traditional defense mechanisms rely on plaintext gradient analysis and thus cannot be directly applied to encrypted gradients. Although homomorphic encryption-based defense schemes enable secure computations on encrypted data, their substantial computational overhead makes them impractical for resource-constrained Internet of Things (IoT) deployments. To address these challenges, we propose a Secret-Sharing-based Defense Framework (SSDF), a lightweight scheme that enables efficient similarity calculations on encrypted gradients under secure aggregation protocols. Our scheme facilitates robust aggregation of encrypted parameters in resource-constrained edge computing environments while protecting the privacy of local model updates. Extensive experiments on four datasets demonstrate that our proposed scheme provides robust defense capabilities against poisoning attacks for both Independent and Identically Distributed (IID) and non-IID data.},
  archive      = {J_COMCOM},
  author       = {Hengheng Xiong and Jiguang Lv and Dapeng Man and Yukun Zhu and Tao Liu and Huanran Wang and Chen Xu and Wu Yang},
  doi          = {10.1016/j.comcom.2025.108272},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108272},
  shortjournal = {Comput. Commun.},
  title        = {A lightweight secret-sharing-based defense against model poisoning attacks in privacy-preserving federated learning},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A homomorphic MAC-based verifiable secure aggregation for federated learning in cloud–edge AIoT. <em>COMCOM</em>, <em>242</em>, 108271. (<a href='https://doi.org/10.1016/j.comcom.2025.108271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud–edge collaborative Artificial Intelligence of Things (AIoT) architecture addresses challenges in managing vast data storage, intelligent information processing, device interconnectivity within the Internet of Things. For its security risks and data privacy, federated learning emerges as a promising solution for ensuring data privacy in AIoT. However, susceptibility to malicious attacks during data transmission poses a significant challenge and a semi-trusted server may deviate from the specified protocol leading to inaccurate aggregation parameters returned to clients. Our proposed solution introduces a federated learning integrity verification scheme based on homomorphic Message Authentication Code (MAC) within a cloud–edge collaborative AIoT architecture. Homomorphic MAC ensures secure aggregation and integrity verification, even when distinct clients possess different keys, emphasizing integrity verification by edge node, contributes to reduced client computing costs. Further verifying of the aggregated parameters by users prevents untrusted transmission from edge node. Leveraging data integrity verification proves effective in mitigating challenges associated with parameter security, especially in scenarios involving inaccurate aggregation of local model parameters within federated learning. Our solution is free bilinear pairing, resulting in a significant reduction in computational overhead. We evaluate accuracy on the MNIST dataset through comparison with the FedAVG plaintext scheme, showing that our approach ensures parameter integrity while maintaining model performance, numerical simulations also confirm its efficiency.},
  archive      = {J_COMCOM},
  author       = {Shufen Niu and Weiying Kong and Lihua Chen and Xusheng Zhou and Ning Wang},
  doi          = {10.1016/j.comcom.2025.108271},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108271},
  shortjournal = {Comput. Commun.},
  title        = {A homomorphic MAC-based verifiable secure aggregation for federated learning in cloud–edge AIoT},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance of UAV-assisted C-V2X communications with 3D antenna beam-width fluctuations. <em>COMCOM</em>, <em>242</em>, 108267. (<a href='https://doi.org/10.1016/j.comcom.2025.108267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The antenna’s three-dimensional (3D) beam-width orientation is crucial in assessing the effectiveness of vehicular communications. This paper investigates the influence of variations of millimeter waveband antenna 3D beam-width on the performance of un-crewed aerial vehicle (UAV)-assisted cellular vehicle-to-everything (C-V2X) communications. The cellular base-stations are represented using a two-dimensional Poisson point process (PPP), while vehicular nodes (V-Ns) are represented using a Poisson line process, and UAVs are represented using a 3D PPP. The typical transmitting V-N can connect with the nearest V-N in direct mode transmission or with the (macro base-station) MBS, line-of-sight (LOS) UAV, or non-LOS (NLOS) UAV in shared mode transmission. The efficiency of the system is measured by using the antenna’s 3D beam-width relative to coverage and spectrum efficiency. To that aim, analytical equations for the association and coverage probability of vehicular-to-vehicular, vehicular-to-MBS, vehicular-to-LOS UAV, and vehicular-to-NLOS UAV connections are obtained in the setting of variation in beam-width. The efficiency is also measured in terms of V-Ns, MBS, and UAVs. The findings revealed that our system, considering millimeter waveband-based UAV-assisted C-V2X network leveraging the benefits of MBSs and UAVs, performs better than the conventional V2X network. The findings reveal that the efficiency of the UAV-assisted C-V2X networks is affected by the variable 3D beam-width, hence, it needs to be thoroughly specified. Furthermore, the network’s performance degrades when the UAV’s beam-width variations grow.},
  archive      = {J_COMCOM},
  author       = {Mohammad Arif and Wooseong Kim and Asif Mehmood},
  doi          = {10.1016/j.comcom.2025.108267},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108267},
  shortjournal = {Comput. Commun.},
  title        = {Performance of UAV-assisted C-V2X communications with 3D antenna beam-width fluctuations},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ACSFL: An adaptive client selection-based federated learning with personalized differential privacy for heterogeneous AIoT environments. <em>COMCOM</em>, <em>242</em>, 108264. (<a href='https://doi.org/10.1016/j.comcom.2025.108264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the rapid development of Artificial Intelligence (AI) and the Internet of Things (IoT), the Artificial Intelligence of Things (AIoT) is increasingly applied in smart environments. Federated Learning (FL) meets the need for intelligent data processing in these environments by providing powerful training capabilities while preserving privacy. However, AIoT environments pose new challenges for FL, particularly due to the heterogeneity of edge devices, which vary in hardware, software, network conditions, and data distribution. These factors degrade model performance and hinder convergence. Additionally, communication overhead and data privacy risks are also critical concerns. Although Differential Privacy (DP) can offer protection, they often apply uniform privacy levels, overlooking the diversity of AIoT devices. On the other hand, while current client-selection approaches partially address the heterogeneity of AIoT devices, they also tend to ignore the impact of the noising mechanisms. In this paper, we propose ACSFL, an adaptive client selection-based FL framework that integrates personalized local DP. By a novel, dynamic evaluation metric of node heterogeneity, privacy budget, and contribution, ACSFL can jointly optimize model performance, privacy preservation, and communication efficiency. We further propose a personalized local differential privacy mechanism in ACSFL, to filter and allocate each client’s budget per round, substantially enhancing privacy preservation and yielding significant accuracy gains under identical overall privacy constraints. All the above assertions are also well supported by theoretical and experimental demonstration. Specifically, our experiments show that ACSFL improves model convergence and generalization by 14% on average, achieves comparable model accuracy with 20% fewer clients, reduces communication overhead by over 25%, and saves about 26% of the privacy budget compared to other client selection methods.},
  archive      = {J_COMCOM},
  author       = {Zhousheng Wang and Junjie Chen and Hua Dai and Jian Xu and Geng Yang and Hao Zhou},
  doi          = {10.1016/j.comcom.2025.108264},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108264},
  shortjournal = {Comput. Commun.},
  title        = {ACSFL: An adaptive client selection-based federated learning with personalized differential privacy for heterogeneous AIoT environments},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient blockchain synchronization mechanism over NDN based on directed interest forwarding. <em>COMCOM</em>, <em>242</em>, 108258. (<a href='https://doi.org/10.1016/j.comcom.2025.108258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology, as a decentralized technology, has been applied across various industries due to its immutability and information security features. With the increasing adoption of blockchain technology, network scale and transaction volumes have increased rapidly. The growing data transmission demands have exposed network performance issues in blockchain systems, creating a bottleneck for further improvements. While Named Data Networking (NDN) offers strong support for blockchain networks, some existing designs lack efficient synchronization methods, resulting in redundancies and limiting the full potential of NDN in blockchain networks. To address this issue, this paper proposes a directed Interest forwarding-based synchronization mechanism for NDN-based blockchain networks. In this mechanism, we design a Block Synchronous Forward Table (BSFT) to record the synchronization status of upstream and downstream nodes. Through the structure of this table, nodes can obtain information about other nodes in the network via six specifically designed NDN Interests. During synchronization, nodes dynamically select the appropriate peers to send data request Interest based on the actual network state and synchronization status, thereby reducing the large number of redundant Interest packets and corresponding response Data packets caused by Interest broadcasts. Experimental results demonstrate that our proposed synchronization mechanism can effectively reduce network traffic, lowering traffic by about 30% or more compared to traditional IP-based blockchain and other NDN-based blockchain solutions. This also accelerates the synchronization of Data packets across the entire network, thereby enhancing the overall performance of blockchain networks.},
  archive      = {J_COMCOM},
  author       = {Dehao Zhang and Jiapeng Xiu and Zhengqiu Yang and Huixin Liu and Shaoyong Guo},
  doi          = {10.1016/j.comcom.2025.108258},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108258},
  shortjournal = {Comput. Commun.},
  title        = {Efficient blockchain synchronization mechanism over NDN based on directed interest forwarding},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing mobility prediction in 5G for enhanced C-V2X applications: A multidisciplinary research survey. <em>COMCOM</em>, <em>242</em>, 108254. (<a href='https://doi.org/10.1016/j.comcom.2025.108254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of 5G New Radio technologies, autonomous vehicles are evolving from isolated units into components of a larger, interconnected system. This transformation is enabled by robust Vehicle-to-Everything (V2X) communications, facilitating applications such as high-definition sensor data sharing and collision avoidance within the Cellular-V2X (C-V2X) framework. Nationwide, ultra-reliable, low-latency coverage is crucial for these applications, necessitating a smart, flexible network to manage mobility uncertainties effectively. To achieve this, mobility prediction will play a pivotal role by preparing the network for anticipated traffic patterns and optimizing its radio and computational resources, thereby enhancing overall efficiency. This survey provides a comprehensive review and analysis of current and emerging mobility prediction methodologies essential for enhancing these networks. We explore these methodologies along with the standards and requirements set by key organizations like the 3rd Generation Partnership Project (3GPP) and industry leaders such as the 5G Automotive Association (5GAA). By reviewing state-of-the-art mobility prediction techniques, this survey critically analyzes their role in forecasting key network performance indicators (KPIs), enabling proactive resource allocation, robust edge-computing strategies, and slice orchestration, all crucial for optimizing 5G performance and ensuring ultra-reliable, low-latency C-V2X communications.},
  archive      = {J_COMCOM},
  author       = {Mario Bou Abboud and Maroua Drissi and Oumaya Baala and Sylvain Allio},
  doi          = {10.1016/j.comcom.2025.108254},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108254},
  shortjournal = {Comput. Commun.},
  title        = {Optimizing mobility prediction in 5G for enhanced C-V2X applications: A multidisciplinary research survey},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing bandwidth allocation in mmWave/sub-THz cellular networks using maximum flow algorithms. <em>COMCOM</em>, <em>242</em>, 108221. (<a href='https://doi.org/10.1016/j.comcom.2025.108221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploitation of millimeter wave (mmWave) and sub-Terahertz (sub-THz) bands is expected to be one of the main pillars for the development of future cellular networks due to the high available bandwidth they provide. The existence of Line-of-Sight (LOS) link between a user equipment (UE) and an access point (AP) is a prerequisite for connection establishment in these networks, as the wireless links in these bands are very sensitive to blockage effects. This can be achieved by densifying APs within a network area. An arising challenge is the efficient exploitation of the available bandwidth of a given network. In this paper, the maximization of the number of served UEs in modern mmWave and sub-THz cellular networks is investigated and achieved by deploying a Maximum Flow Algorithm for UE-AP association (MFUA) to optimize bandwidth allocation, assuming that every AP will have a finite and predefined amount of bandwidth which they can share among UEs. MFUA determines the maximum flow between two given nodes of a graph corresponding to a specific network, where the capacity of its edges is known. An extensive simulation campaign was carried out revealing that the use of MFUA utilizes bandwidth more effectively compared to the reference method and improves the system performance, leading to the maximization of number of served UEs. The examined test cases include static and time-evolving scenarios.},
  archive      = {J_COMCOM},
  author       = {Kyriakos N. Manganaris and Panagiotis Promponas and Aris Tsolis and Fotis I. Lazarakis and Kostas P. Peppas},
  doi          = {10.1016/j.comcom.2025.108221},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108221},
  shortjournal = {Comput. Commun.},
  title        = {Optimizing bandwidth allocation in mmWave/sub-THz cellular networks using maximum flow algorithms},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accountable privacy-enhanced multi-authority attribute-based authentication scheme for cloud services. <em>COMCOM</em>, <em>242</em>, 108205. (<a href='https://doi.org/10.1016/j.comcom.2025.108205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current attribute-based authentication (ABA) schemes have three major drawbacks: first, the single attribute authority (AA) becomes the system bottleneck, i.e., if the AA is corrupted, the entire system will stop working; second, user privacy is not completely secured; and third, malicious users may exploit their anonymity. To overcome these defects, we improved a previously established privacy-preserving decentralized ciphertext policy attribute-based encryption (PPD-CP-ABE) scheme, obtaining a PPD-CP-ABE with verifiable outsourced decryption (PPD-CP-ABE-VOD). This improved scheme uses outsourced decryption, secure two-party computation protocol, and zero-knowledge proofs. We transformed the PPD-CP-ABE-VOD scheme into a new privacy-enhanced multi-authority ABA scheme using an identity tracing mechanism based on linear encryption. This new scheme has the following advantages over similar schemes. First, it introduces multiple AAs and does not require users to trust AA fully. Second, it protects users’ attributes, global identifiers, and access behavior, thus strengthening user privacy protection. Finally, it balances user privacy protection and user accountability. Theoretical and experimental analyses have shown that the new scheme is comparable to recently proposed ABA systems in terms of performance in the key generation and authentication phases, despite appending multiple security properties.},
  archive      = {J_COMCOM},
  author       = {Xin Liu and Hao Wang and Bo Zhang and Bin Zhang},
  doi          = {10.1016/j.comcom.2025.108205},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108205},
  shortjournal = {Comput. Commun.},
  title        = {Accountable privacy-enhanced multi-authority attribute-based authentication scheme for cloud services},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cor">COR - 21</h2>
<ul>
<li><details>
<summary>
(2026). Optimizing high-tech product take-back schemes in a closed-loop supply chain. <em>COR</em>, <em>185</em>, 107282. (<a href='https://doi.org/10.1016/j.cor.2025.107282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent product development is a solution to the shortened product lifecycles in the consumer electronics industry. It enables companies to maintain competitiveness and strengthen their market share. However, environmental concerns bring reverse logistics practices into focus. A take-back policy is a strategic reverse logistics activity known to foster market share; however, it poses various challenges and uncertainties. Considering uncertain demand, we introduced an innovative adoption model with two distinct take-back policies, trade-in and credit, to address challenges in multi-generation production planning. Inspired by real-world practices of companies like Apple and Samsung, our model first examines how trade-in programs drive repeat purchases and enhance market share, with credit-based programs to attract new customers. It then captures changes in demand, production planning, recovery decisions, and internal competition among multiple product generations. Distinct from previous conclusions, this study explores how producers can strategically manage demand for new generations to slow diffusion, thereby increasing refurbishment and recycling volumes over time. Our findings highlight the pivotal role of adaptive pricing strategies and production scalability in maximizing profitability and promoting sustainability in competitive high-tech industries.},
  archive      = {J_COR},
  author       = {Fatemeh Keshavarz-Ghorbani and Mohamad Y. Jaber and Seyed Hamid Reza Pasandideh},
  doi          = {10.1016/j.cor.2025.107282},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107282},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing high-tech product take-back schemes in a closed-loop supply chain},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Q-learning-based hyper-heuristic algorithm for open dimension irregular packing problems. <em>COR</em>, <em>185</em>, 107279. (<a href='https://doi.org/10.1016/j.cor.2025.107279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic methods provide a computationally efficient framework for addressing two-dimensional irregular packing problems, particularly in resource-constrained industrial settings. As a typical combinatorial optimization problem, irregular packing exhibits exponential growth in computational complexity with increasing workpiece counts, while the solution space dynamically reconfigures due to geometric variability among workpieces. Although heuristic algorithms can generate feasible layouts within acceptable timeframes, their reliance on fixed search rule limits adaptability to diverse scenarios, necessitating more flexible approaches. In this paper, a hyper-heuristic algorithm based on Q-Learning is proposed to solve open dimension packing problems, including one-open and two-open dimension problems. Q-Learning is adopted as the high-level strategy for its ability to optimize low-level heuristic selection through reward-driven experience accumulation. The method incorporates a mixed encoding method for solution representation, four specialized low-level heuristic operators, a linear population decline mechanism, and an elite preservation strategy to balance exploration–exploitation. The Q-Learning controller dynamically selects operators by updating the Q-table based on Bellman’s equation. The proposed algorithm is compared to some advanced algorithms in general datasets. The results show that our method has better performance and applicability.},
  archive      = {J_COR},
  author       = {Yongchun Wang and Qingjin Peng and Zhen Wang and Shuiquan Huang and Zhengkai Xu and Chuanzhen Huang and Baosu Guo},
  doi          = {10.1016/j.cor.2025.107279},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107279},
  shortjournal = {Comput. Oper. Res.},
  title        = {Q-learning-based hyper-heuristic algorithm for open dimension irregular packing problems},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A note on battery swapping policies in the electric vehicle routing problem with time windows and battery swapping vehicles. <em>COR</em>, <em>185</em>, 107277. (<a href='https://doi.org/10.1016/j.cor.2025.107277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Çatay and Sadati [An improved matheuristic for solving the electric vehicle routing problem with time windows and synchronized mobile charging/battery swapping. Computers & Operations Research 159, 106310, 2023] explores a variant of the Electric Vehicle Routing Problem with Time Windows that incorporates mobile chargers for recharging electric vehicles (EVs) at selected locations while serving customers. The authors propose a matheuristic method to address this problem and its special case, where EV batteries are swapped in constant time instead of being recharged over variable durations. While comparing their results with those in the literature, the authors overlook a critical assumption regarding the swapping policy, potentially causing confusion in interpreting the findings. This note addresses the issue, clarifies the overlooked assumption, and updates the results that do not align with the actual scenario in the literature. Furthermore, it introduces two new battery swapping policies and presents an extensive computational study to offer new insights on synchronized mobile battery swapping.},
  archive      = {J_COR},
  author       = {Bülent Çatay and İhsan Sadati},
  doi          = {10.1016/j.cor.2025.107277},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107277},
  shortjournal = {Comput. Oper. Res.},
  title        = {A note on battery swapping policies in the electric vehicle routing problem with time windows and battery swapping vehicles},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive K-means and reinforcement learning (RL) algorithm to effective vaccine distribution. <em>COR</em>, <em>185</em>, 107275. (<a href='https://doi.org/10.1016/j.cor.2025.107275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new adaptive reinforcement learning (RL) approach, integrated with a K-means clustering algorithm and guided by simulated annealing, to address the capacitated vehicle routing for vaccine distribution (CVRVD) problem. This integrated method provides an efficient and scalable solution for optimizing vaccine distribution logistics. By incorporating cost factors related to travel distance, inventory levels, and penalty terms – while adhering to delivery time windows – our approach improves both operational efficiency and vaccine allocation effectiveness. Experimental results demonstrate that our K-means supported RL algorithm significantly outperforms traditional solvers in tackling this NP-hard problem, particularly in large-scale scenarios. Specifically, our approach can efficiently solve CVRVD instances with up to 1,000 facilities—scenarios that are computationally intractable for exact methods. We demonstrate the effectiveness of the adaptive K-means supported RL algorithm using data from New Jersey, USA, where facility-level vaccination data were available through the state’s Immunization Information System. Beyond vaccine distribution, our method has broad applicability in logistics and transportation, enabling more efficient and cost-effective allocation of critical resources such as vaccines and medical supplies.},
  archive      = {J_COR},
  author       = {Elson Cibaku and İ. Esra Büyüktahtakın},
  doi          = {10.1016/j.cor.2025.107275},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107275},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive K-means and reinforcement learning (RL) algorithm to effective vaccine distribution},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A Q-learning-based evolutionary algorithm for solving the low-carbon multi-objective flexible job shop scheduling problem. <em>COR</em>, <em>185</em>, 107266. (<a href='https://doi.org/10.1016/j.cor.2025.107266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, how to reduce energy consumption at the manufacturing system level in the low-carbon multi-objective flexible job shop scheduling problem (LCM-FJSP) has received significant attention. In this research, a model with the maximum completion time, total machine workload and total carbon emissions is built. Moreover, a Q-learning-based adaptive weight-adjusted decomposition evolutionary algorithm (QMOEA/D-AWA) is proposed. In the QMOEA/D-AWA, an initialization strategy with four heuristic initial rules for obtaining high-quality population, a variable neighborhood search strategy with four problem-specific local search methods for enhancing exploration and a Q-learning-based parameter adaptive strategy for automatically determining the number of neighborhood solutions are designed. To validate the effectiveness of the proposed QMOEA/D-AWA, it is compared with five state-of-the-art algorithms on 15 instances. In the statistical analysis, the QMOEA/D-AWA obtains the overwhelming metric results in 10 instances. In the visual analysis, the completion time is reduced by 3.74%, the total workload is reduced by 3.94%, and the carbon emissions are reduced by 5.94%.},
  archive      = {J_COR},
  author       = {Zhixue Wang and Maowei He and Hanning Chen and Yabao Hu and Yelin Xia},
  doi          = {10.1016/j.cor.2025.107266},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107266},
  shortjournal = {Comput. Oper. Res.},
  title        = {A Q-learning-based evolutionary algorithm for solving the low-carbon multi-objective flexible job shop scheduling problem},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A benders-branch-and-cut methodology for global cargo vessel traffic prediction given declining arctic sea ice and changing risks. <em>COR</em>, <em>185</em>, 107265. (<a href='https://doi.org/10.1016/j.cor.2025.107265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global warming has led to declining sea-ice in the Arctic Ocean, making it easier for ice-class vessels to navigate Arctic waters for greater portions of the year. As sailing conditions in these waters improve over coming decades, these passageways are expected to open for larger portions of the year and to become increasingly viable options for unsupported transit and even open-water vessels. This paper proposes a Benders-branch-and-cut methodology for estimating changes in global maritime cargo flow patterns under future climate scenarios with declining Arctic sea ice. The model accounts for changing incident risk along Arctic passageways and corresponding ice-class vessel and icebreaker escort requirements, lower speeds, increased insurance premiums, higher accident probabilities, and constraints on path-based maximum risk exposure. The resulting mixed-integer program involves path-based, continuous decision variables. The solution technique is applied on a model of the global maritime container network including 80 ports, 76 routes, 426 links and 4,303 legs associated with the world’s largest carrier alliance. Embedded acceleration techniques and a label-correcting algorithm that employs specialized fathoming rules for a non-additive, constrained path subproblem enable solution at this global scale. The outcome is an estimate of seasonal future global maritime trade flows along key global routes and through ports predicted under six climate-related scenarios. Results illustrate that the developed model can provide support to companies, nations and regions as they prepare for a changing global landscape and climate.},
  archive      = {J_COR},
  author       = {Wenjie Li and Elise Miller-Hooks},
  doi          = {10.1016/j.cor.2025.107265},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107265},
  shortjournal = {Comput. Oper. Res.},
  title        = {A benders-branch-and-cut methodology for global cargo vessel traffic prediction given declining arctic sea ice and changing risks},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning approach for dynamic job-shop scheduling problem considering time variable and new job arrivals. <em>COR</em>, <em>185</em>, 107263. (<a href='https://doi.org/10.1016/j.cor.2025.107263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the complexity of the production process due to increased demand for customization has greatly increased the difficulty of dynamic job-shop scheduling problem (DJSP). This paper proposes a deep reinforcement learning (DRL) approach to tackle the DJSP based on proximal policy optimization (PPO) algorithm. A novel state representation method that expresses state features as multi-channel images is proposed to simplify the state characterization process. Various heuristic-based priority dispatching rules (PDRs)are used to construct action space. By converting scheduling instances into images and leveraging the spatial pyramid pooling fast (SPPF) module for feature extraction, this model can handle scheduling instances of varying scales and map size-independent processing information matrix to fixed action space. Additionally, a dense reward based on a predefined scheduling region is developed to offer detailed guidance to the agent, enabling more precise and comprehensive policy assessment. Static tests are conducted on well-known benchmarks, and the experimental results indicate that our scheduling model surpasses the performance of the three latest DRL approaches on average. Compared with PDR methods, dynamic experiments demonstrate that the proposed DRL model excels in adaptability and robustness when new tasks arrive and the processing time fluctuates with uncertainty.},
  archive      = {J_COR},
  author       = {Haoyang Yu and Wenbin Gu and Na Tang and Zhenyang Guo},
  doi          = {10.1016/j.cor.2025.107263},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107263},
  shortjournal = {Comput. Oper. Res.},
  title        = {A deep reinforcement learning approach for dynamic job-shop scheduling problem considering time variable and new job arrivals},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient resource utilization and scheduling strategy for in-service aircraft maintenance and operations. <em>COR</em>, <em>185</em>, 107262. (<a href='https://doi.org/10.1016/j.cor.2025.107262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal scheduling of maintenance activities requires the solution of combinatorial optimization problems that need to be efficiently modeled and solved with optimization techniques. Maintenance scheduling and operations-associated problems in the aviation industry can efficiently enhance competitiveness. In the maintenance and scheduling problem, aircrafts need to undergo tasks for both line (A check) and base (C check) maintenance at various hangers at MRO (Maintenance, Repair and Operations) based on resource availability (both human and material). The determination of the optimal maintenance plan, in terms of allocating the resources to the aircraft, and resource movement from one aircraft to another based on availability and licensed skills in the presence of multiple tasks and capacity constraints so as to obtain maximum utilization of resources at maintenance site and minimize the turnaround time is a complex combinatorial optimization problem. To the best of our knowledge, this work is the first CP (Constraint Programming) based mathematical solution that jointly integrates zone, task precedence, technician-pool sharing, and multi-shift continuity for large-scale aircraft maintenance scheduling. In this article, we proposed an efficient optimization strategy that overcomes many of the drawbacks of the formulation/strategies available in literature and helps in determining efficient execution of maintenance work packages. The proposed strategy is generic, encompassing multi-aircraft, multi-skill and multi-shift scheduling capabilities and is validated on two real scenario business case studies, one each for line maintenance (A check) tasks and base maintenance (C check) tasks, as well as six large-scale synthetic scenarios with up to 20,000 tasks, demonstrating feasibility and scalable performance. The proposed strategy is demonstrated on MRO scheduling and it shows an improvement of up to 30.68% in the turn-around time by incorporating the proposed optimization strategy.},
  archive      = {J_COR},
  author       = {Sandeep Singh Chauhan and Likhith Maadhav and Abhijit Dake and Gauthier Brillaud},
  doi          = {10.1016/j.cor.2025.107262},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107262},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient resource utilization and scheduling strategy for in-service aircraft maintenance and operations},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven optimization approach for the integrated train scheduling and maintenance planning in high-speed railways. <em>COR</em>, <em>185</em>, 107261. (<a href='https://doi.org/10.1016/j.cor.2025.107261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In railway systems, preventive maintenance plans are essential for ensuring the safety of train operations. However, these tasks are often subject to various disturbances (e.g., bad weather), leading to unpredictable deviations between planned and actual maintenance durations, which can further disrupt train schedules. Unlike most studies that assume constant maintenance durations, this paper introduces a data-driven, two-stage distributionally robust optimization (DRO) model for jointly optimizing train scheduling and maintenance planning. In the first stage, we determine the initial train schedule and maintenance plan. In the second stage, we allow for slight adjustments to train departure and arrival times at each station to accommodate disturbances affecting maintenance tasks. Our objective is to minimize both the expected travel time of trains and the deviation from the planned schedule under worst-case scenarios for maintenance disturbances. To capture the uncertainty of maintenance disturbances, we construct an ambiguity set using historical data and the Wasserstein metric. We show that the proposed two-stage DRO model, formulated over the Wasserstein ambiguity set, can be reformulated into an efficiently solvable equivalent form. Finally, we apply our model to a real-world case study of the Beijing–Guangzhou high-speed railway and compare it with traditional stochastic programming methods, including sample average approximation and robust optimization. The results highlight the efficiency of our approach and provide valuable insights for railway management.},
  archive      = {J_COR},
  author       = {Hangyu Ji and Chuntian Zhang and Jiateng Yin and Lixing Yang},
  doi          = {10.1016/j.cor.2025.107261},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107261},
  shortjournal = {Comput. Oper. Res.},
  title        = {A data-driven optimization approach for the integrated train scheduling and maintenance planning in high-speed railways},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ROBIST: Robust optimization by iterative scenario sampling and statistical testing. <em>COR</em>, <em>185</em>, 107260. (<a href='https://doi.org/10.1016/j.cor.2025.107260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose ROBIST , a simple, yet effective, data-driven algorithm for optimization under parametric uncertainty. The algorithm first generates solutions in an iterative manner by sampling and optimizing over a relatively small set of scenarios. Then, using statistical testing, the robustness of the solutions is evaluated, which can be done with a much larger set of scenarios. ROBIST offers a number of practical advantages over existing methods as it is: (i) easy to implement, (ii) able to deal with a wide range of problems and (iii) capable of providing sharp probability guarantees that are easily computable and independent of the dimensions of the problem. Numerical experiments demonstrate the effectiveness of ROBIST in comparison to alternative methods.},
  archive      = {J_COR},
  author       = {Justin Starreveld and Guanyu Jin and Dick den Hertog and Roger J.A. Laeven},
  doi          = {10.1016/j.cor.2025.107260},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107260},
  shortjournal = {Comput. Oper. Res.},
  title        = {ROBIST: Robust optimization by iterative scenario sampling and statistical testing},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A branch-and-price algorithm for energy aware task scheduling of constellations of nanosatellites. <em>COR</em>, <em>185</em>, 107259. (<a href='https://doi.org/10.1016/j.cor.2025.107259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-price algorithm for solving the Optimal Network Task Scheduling (ONTS) problem in satellite constellations. The algorithm efficiently manages both constellation tasks that can be performed by any satellite and satellite-specific tasks that must be executed by designated satellites, while considering critical energy constraints. We formulate the problem as a Mixed-Integer Linear Programming (MILP) model and develop a Dantzig–Wolfe decomposition that handles battery management constraints for the satellites at the master level, while addressing constellation-wide coordination requirements in the subproblems. A novel dynamic programming algorithm is proposed to solve the pricing subproblem for constellation tasks, augmented with dual stabilization techniques to improve convergence. Comprehensive computational experiments on realistic instances derived from nanosatellite operations demonstrate the effectiveness of the algorithm. Results show that our structured formulation significantly outperforms a naive approach, particularly for large instances, while effectively balancing workload distribution and energy management across the constellation. This work provides a practical framework for optimizing task scheduling in modern satellite constellations, with direct applications in Earth observation, telecommunications, and scientific missions.},
  archive      = {J_COR},
  author       = {Pedro Marcolin Antunes and Laio Oriel Seman and Eduardo Camponogara},
  doi          = {10.1016/j.cor.2025.107259},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107259},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-price algorithm for energy aware task scheduling of constellations of nanosatellites},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid memetic metaheuristic for medical staff assignment in major public health emergencies. <em>COR</em>, <em>185</em>, 107256. (<a href='https://doi.org/10.1016/j.cor.2025.107256'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During major public health emergencies, effective assignment of medical staff is crucial for saving lives and controlling the spread of epidemics. This work focuses on the assignment of doctors and nurses to hospitals to form treatment groups that carry out patient treatment tasks. We consider the practical constraints of skill types of medical staff and the severity of patients’ conditions and propose a mixed integer programming model with the objective of maximizing demand satisfaction and personnel skill matching. To solve this problem, we introduce a hybrid memetic search algorithm that combines a specialized crossover operator for generating promising offspring solutions and a variable neighborhood search procedure to improve their quality. Computational results demonstrate that our algorithm outperforms the general mixed integer programming solver GUROBI . The key components of the proposed algorithm are experimentally analyzed and managerial insights are derived.},
  archive      = {J_COR},
  author       = {Yang Wang and He Zheng and Zequn Wei and Christophe Wilbaut and Saïd Hanafi},
  doi          = {10.1016/j.cor.2025.107256},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107256},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid memetic metaheuristic for medical staff assignment in major public health emergencies},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-guided iterated local search for the minmax multiple traveling salesman problem. <em>COR</em>, <em>185</em>, 107255. (<a href='https://doi.org/10.1016/j.cor.2025.107255'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minmax multiple traveling salesman problem involves minimizing the costs of a longest tour among a set of tours. The problem is of great practical interest because it can be used to formulate several real-life applications. To solve this computationally challenging problem, we propose a learning-driven iterated local search approach that combines an effective local search procedure to find high-quality local optimal solutions and a multi-armed bandit algorithm to select removal and insertion operators to escape local optimal traps. Extensive experiments on 77 commonly used benchmark instances show that the algorithm achieves excellent results in terms of solution quality and running time. In particular, it achieves 32 new best results (improved upper bounds) and matches the best-known results for 35 other instances. Additional experiments shed light on the understanding of the algorithm’s constituent elements. Multi-armed bandit selection can be used advantageously in other multi-operator local search algorithms.},
  archive      = {J_COR},
  author       = {Pengfei He and Jin-Kao Hao and Jinhui Xia},
  doi          = {10.1016/j.cor.2025.107255},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107255},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning-guided iterated local search for the minmax multiple traveling salesman problem},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Grouping strategies on two-phase methods for bi-objective combinatorial optimization. <em>COR</em>, <em>185</em>, 107254. (<a href='https://doi.org/10.1016/j.cor.2025.107254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-phase methods are commonly used to solve bi-objective combinatorial optimization problems. In the first phase, all extreme supported nondominated points are generated through a dichotomic search. This phase also allows the identification of search zones that may contain other nondominated points. The second phase focuses on exploring these search zones to locate the remaining points, which typically accounts for most of the computational cost. Ranking algorithms are frequently employed to explore each zone individually, but this approach leads to redundancies, causing multiple visits to the same solutions. To mitigate these redundancies, we propose several strategies that group adjacent zones, allowing a single run of the ranking algorithm for the entire group. Additionally, we explore an implicit grouping approach based on a new concept of coverage. Our experiments on the Bi-Objective Spanning Tree Problem demonstrate the beneficial impact of these grouping strategies when combined with coverage.},
  archive      = {J_COR},
  author       = {Felipe O. Mota and Luís Paquete and Daniel Vanderpooten},
  doi          = {10.1016/j.cor.2025.107254},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107254},
  shortjournal = {Comput. Oper. Res.},
  title        = {Grouping strategies on two-phase methods for bi-objective combinatorial optimization},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Drone-aided mobile blood collection problem: A rolling-horizon-based matheuristic. <em>COR</em>, <em>185</em>, 107253. (<a href='https://doi.org/10.1016/j.cor.2025.107253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the drone-aided mobile blood collection problem, which integrates mobile blood donation vehicles with drones to improve operations related to the blood collection in urban areas. Each vehicle, carrying multiple drones, travels to several collection sites to conduct blood collection operations within a working day. Drones fly between vehicles to pick up collected blood bags and deliver them to the blood center. This collaborative framework enhances the performances of the collection system and ensures the freshness of collected blood upon arrival to the blood center. We develop a novel mixed-integer linear programming model to optimally synchronize the routes and collection schedules of mobile units and drones to ensure the timely delivery of collected blood to the blood center. We also develop a rolling-horizon-based matheuristic to solve large-scale instances of the problem. This algorithm combines a rolling horizon approach, which divides the problem into manageable subproblems solved sequentially, with a local branching technique that enhances solutions by exploring promising neighborhoods. To evaluate the algorithm’s performance, we conduct a comprehensive computational study. Our results show that the proposed algorithm not only finds better solutions than those obtained by Gurobi but also outperforms other matheuristics, including the rolling horizon, relax-and-fix, and fix-and-optimize algorithms. Finally, we demonstrate the real-life applicability of the problem through a case study in Quebec City, Canada.},
  archive      = {J_COR},
  author       = {Amirhossein Abbaszadeh and Hossein Hashemi Doulabi},
  doi          = {10.1016/j.cor.2025.107253},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107253},
  shortjournal = {Comput. Oper. Res.},
  title        = {Drone-aided mobile blood collection problem: A rolling-horizon-based matheuristic},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fair and efficient multi-agent routing for cooperative and autonomous agricultural fleets with implements. <em>COR</em>, <em>185</em>, 107252. (<a href='https://doi.org/10.1016/j.cor.2025.107252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing use of autonomous tractor fleets with detachable implements presents complex logistical challenges in agriculture. Current systems often rely on simple heuristics and avoid implement swapping, limiting efficiency. A central challenge is to dynamically coordinate vehicle routing and implement exchanges to enable efficient, low-intervention task execution. Due to high costs, such fleets are owned mainly by large enterprises or cooperatives, where fair task allocation and profit sharing are critical. Addressing both coordination and fairness, in this paper, we introduce the Agricultural Fleet Vehicle Routing Problem with Implements (AFVRPI). We propose a distributed model derived from a centralized formulation also presented in this paper. This model is embedded within a Distributed Multi-Agent System Architecture (DIMASA), where autonomous vehicle agents manage routing and implement use under limited fuel autonomy, while implement agents ensure compatibility and sufficient capacity to meet task demands. Our solution applies systematic egalitarian social welfare optimization to iteratively maximize the profit of the worst-off vehicle, balancing fairness with system efficiency. To enhance scalability, we use column generation in the distributed model, achieving solution quality comparable to the centralized model while significantly reducing computing time. Simulation results on new benchmark instances demonstrate that our distributed multi-agent AFVRPI approach is scalable, efficient, and fair.},
  archive      = {J_COR},
  author       = {Aitor López-Sánchez and Marin Lujak and Frédéric Semet and Holger Billhardt},
  doi          = {10.1016/j.cor.2025.107252},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107252},
  shortjournal = {Comput. Oper. Res.},
  title        = {Fair and efficient multi-agent routing for cooperative and autonomous agricultural fleets with implements},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flexible scheduling of customized bus for green mega-events: A distributionally robust optimization approach. <em>COR</em>, <em>185</em>, 107249. (<a href='https://doi.org/10.1016/j.cor.2025.107249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mega-events such as the Olympics and the World Championships face significant challenges in evacuating large numbers of attendees after the events conclude, which consume substantial transportation resources. Under the global pressure to reduce carbon emissions, energy conservation and emission reduction are increasingly becoming top priorities. This paper focuses on the efficient scheduling of customized buses (CB) after green mega-events, incorporating skip-stop operations and coordinated bus services to minimize energy consumption, fixed and transportation costs, and facilitate the evacuation of attendees, while accounting for practical constraints such as the availability of customized buses, vehicle capacity, time windows, and flow balance. A distributionally robust optimization (DRO) model is developed, using a novel ambiguity set to model uncertain demand via parametric interval-valued fuzzy variables. To ensure computational tractability, the model is reformulated as an integer linear programming model. To address the computational challenges of large-scale instances, an improved variable neighborhood search heuristic is designed by incorporating the reinforcement learning techniques, including the KL-UCB algorithm and a sliding window mechanism. Extensive numerical experiments are conducted to verify the performance of the proposed heuristic. Computational results demonstrate that the proposed DRO model effectively handles uncertainty, offering robust and adaptable solutions. Compared to existing heuristics, the proposed heuristic improves performance by 6.51% on average, and incorporating reinforcement learning into VNS enhances computational efficiency by 4.88% on average. A real-life case study further validates the model, demonstrating that the skip-stop strategy significantly reduces vehicle travel time and enhances overall operational efficiency.},
  archive      = {J_COR},
  author       = {Xiaojie An and Xiang Li and Bowen Zhang},
  doi          = {10.1016/j.cor.2025.107249},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107249},
  shortjournal = {Comput. Oper. Res.},
  title        = {Flexible scheduling of customized bus for green mega-events: A distributionally robust optimization approach},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal planning of power distribution networks with fault-tolerant configuration. <em>COR</em>, <em>185</em>, 107248. (<a href='https://doi.org/10.1016/j.cor.2025.107248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power Distribution networks are essential infrastructures that should be designed by satisfying two conflicting requests: cost minimization and reliability. While traditional network planning aimed at radial configurations, which are more similar to the typical working configuration of a network but are not fault-tolerant, modern techniques seek for meshed configurations, since these architectures are more fault-tolerant. Due to the complexity of the problem and the large size of nowadays instances, most of the techniques used for planning are based on heuristic approaches. Thus, they are usually unable to guarantee optimality and not even able to provide an assessment of the distance from the optimal solution. In this work, we address the challenge of planning a fault tolerant network through an exact approach, by introducing innovative Mixed-Integer Linear Programming models designed for the planning of meshed distribution networks with loop-feeder or open-loop topology. Differently from other techniques, our approach simplifies the formulation by avoiding the need for fault scenarios, significantly reducing the computational burden of the optimization problem. The outcomes of our approach are the generation of optimal meshed network, which effectively balance cost and reliability of the electric distribution system. Comprehensive studies on realistic test instances show the advantages of the proposed formulations.},
  archive      = {J_COR},
  author       = {Renato Bruni and Alberto Geri and Marco Maccioni and Ludovico Nati},
  doi          = {10.1016/j.cor.2025.107248},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107248},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal planning of power distribution networks with fault-tolerant configuration},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Centrality measures and opinion dynamics in two-layer networks with replica nodes. <em>COR</em>, <em>185</em>, 107245. (<a href='https://doi.org/10.1016/j.cor.2025.107245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two fast and accurate algorithms to approximate game-theoretic centrality measures and examine connection between centrality measures, network properties, and key performance indicators (consensus time and winning rate) of opinion dynamic processes on such networks. As an example, we consider a Zachary’s karate club as a social network and extend it by adding the second (internal) layer of communication. The internal layer represents the network where individuals can share their real opinions with the close friends. The structures of the external and internal layers may be different. The significant positive correlation between internal graph density and consensus time, and significant negative correlation between centrality of authoritative nodes and consensus time are found. The proposed algorithms are verified by a series of experiments from two aspects: the accuracy and the efficiency. The algorithms are novel and can be considered as a contribution to the network theory independently of opinion dynamics as they can be used to calculate node centrality in any weighted graph.},
  archive      = {J_COR},
  author       = {Chi Zhao and Elena Parilina},
  doi          = {10.1016/j.cor.2025.107245},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107245},
  shortjournal = {Comput. Oper. Res.},
  title        = {Centrality measures and opinion dynamics in two-layer networks with replica nodes},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI automatic decision in newsvendor model with nash bargaining fairness concern. <em>COR</em>, <em>185</em>, 107227. (<a href='https://doi.org/10.1016/j.cor.2025.107227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of artificial intelligence (AI) automatic ordering and producing decisions on fairness-concerned supply chains under the newsvendor model. We develop a dyadic supply chain model in which the manufacturer acts as the Stackelberg leader while the retailer serves as the follower in a push supply chain. In contrast, their roles are switched in a pull supply chain. We assume that only human decision-making leads to decision regret behavior, whereas AI-automated decision-making does not. Without adopting AI, our results show that fairness concern does not necessarily lead to a decreasing quantity in ordering or producing, which is different from most previous studies. Different from the prior findings, our work reveals that in binding equilibrium, if fairness concerns are considered, the order quantity will decrease, while in non-binding equilibrium, the order quantity may not necessarily be less than the previous results. Interestingly, when decision regret bias is considered for fairness-concerned decision-makers, we can obtain quantity coordination solutions for supply chains under specific conditions. With adopting AI, our results show that increasing fairness concerns are beneficial for improving the follower’s profit while at the expense of sacrificing the leader’s profit margins, while the leader can only benefit from AI adoption when the decision regret bias of the follower is relatively high. It is noteworthy that under certain conditions, AI automation may negatively impact the profits of both push and pull decentralized supply chains. For instance, in low-margin profit scenarios where decision-makers exhibit moderate regret bias and fairness concerns, such effects can emerge. This indicates that under specific circumstances, the human behavioral factors — regret bias and fairness concerns — may sometimes enhance the performance of decentralized supply chain members. Our research findings provide significant practical implications for the adoption of AI-automated decision-making in real-world supply chains.},
  archive      = {J_COR},
  author       = {Rui Hou and Yishen Cen and Jianxin Chen},
  doi          = {10.1016/j.cor.2025.107227},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107227},
  shortjournal = {Comput. Oper. Res.},
  title        = {AI automatic decision in newsvendor model with nash bargaining fairness concern},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Green horizons: Sustainable global logistics in dynamic supply chain management. <em>COR</em>, <em>185</em>, 107226. (<a href='https://doi.org/10.1016/j.cor.2025.107226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain management in a global scale involves addressing numerous uncertainties, from demand fluctuations to unforeseen disruptions. Developing advanced solution approaches is critical to manage such complexities and ensure resilience. This study presents a multi-stage stochastic–dynamic model for the global supply chain, incorporating hedging policies. The aim is to identify optimal order scheduling for bill of materials, production planning, and inventory management across warehouses (i.e., materials and finished products). Due to the dynamic nature of the global supply chain (e.g., demand fluctuations, disruptions, and lead time), a multi-stage stochastic model is developed for the stochastic–dynamic supply chain network. To address dynamic factors of real-world global supply chain, an accelerated parallel stochastic dual dynamic integer programming (SDDiP) approach is proposed to deal with disruptions (e.g., political unrest, natural disasters, and pandemics), enhancing supply chain resiliency. To validate the proposed parallel SDDiP , various scenarios with different sizes are generated using the case study and compared to the SDDiP with Benders cuts and integrated stage-wise Lagrangian dual cut ( SWLDC ) (i.e., SDDiP-SWLDC ). According to the obtained results, the proposed parallel node strategy for accelerated SDDiP consistently outperforms the basic stochastic dual dynamic programming (SDDP) and demonstrated robust CPU scalability. Evaluation across various scenario sizes shows stochastic dual dynamic integer programming-mixed integer rounding cuts ( SDDiP-MIR ) achieving faster computation and a smaller 7% optimality gap compared to SDDiP-SWLDC and SDDiP in large-size instances, highlighting its superior performance in complex supply chain settings.},
  archive      = {J_COR},
  author       = {Mahsa Mohammadi and Babak Mohamadpour Tosarkani},
  doi          = {10.1016/j.cor.2025.107226},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107226},
  shortjournal = {Comput. Oper. Res.},
  title        = {Green horizons: Sustainable global logistics in dynamic supply chain management},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="csda">CSDA - 7</h2>
<ul>
<li><details>
<summary>
(2026). An algorithm for estimating threshold boundary regression models. <em>CSDA</em>, <em>214</em>, 108274. (<a href='https://doi.org/10.1016/j.csda.2025.108274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an innovative iterative two-stage algorithm designed for estimating threshold boundary regression (TBR) models. By transforming the non-differentiable least-squares (LS) problem inherent in fitting TBR models into an optimization framework, our algorithm combines the optimization of a weighted classification error function for the threshold model with obtaining LS estimators for regression models. To improve the efficiency and flexibility of TBR model estimation, we integrate the weighted support vector machine (WSVM) as a surrogate method for solving the weighted classification problem. The TBR-WSVM algorithm offers several key advantages over recently developed methods: it eliminates pre-specification requirements for threshold parameters, accommodates flexible estimation of nonlinear threshold boundaries, and streamlines the estimation process. We conducted several simulation studies to illustrate the finite-sample performance of TBR-WSVM. Finally, we demonstrate the practical applicability of the TBR model through a real data analysis.},
  archive      = {J_CSDA},
  author       = {Chih-Hao Chang and Takeshi Emura and Shih-Feng Huang},
  doi          = {10.1016/j.csda.2025.108274},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108274},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {An algorithm for estimating threshold boundary regression models},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rate accelerated inference for integrals of multivariate random functions. <em>CSDA</em>, <em>214</em>, 108273. (<a href='https://doi.org/10.1016/j.csda.2025.108273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of integrals is a fundamental task in the analysis of functional data, where the data are typically considered as random elements in a space of squared integrable functions. Effective unbiased estimation and inference procedures are proposed for integrals of uni- and multivariate random functions. Applications to key problems in functional data analysis involving random design points are examined and illustrated. In the absence of noise, the proposed estimates converge faster than the sample mean and standard numerical integration algorithms. The estimator also supports effective inference by generally providing better coverage with shorter confidence and prediction intervals in both noisy and noiseless settings.},
  archive      = {J_CSDA},
  author       = {Valentin Patilea and Sunny G․ W․ Wang},
  doi          = {10.1016/j.csda.2025.108273},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108273},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Rate accelerated inference for integrals of multivariate random functions},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust selection of the number of change-points via FDR control. <em>CSDA</em>, <em>214</em>, 108272. (<a href='https://doi.org/10.1016/j.csda.2025.108272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust quantification of uncertainty regarding the number of change-points presents a significant challenge in data analysis, particularly when employing false discovery rate (FDR) control techniques. Emphasizing the detection of genuine signals while controlling false positives is crucial, especially for identifying shifts in location parameters within flexible distributions. Traditional parametric methods often exhibit sensitivity to outliers and heavy-tailed data. Addressing this limitation, a robust method accommodating diverse data structures is proposed. The approach constructs component-wise sign-based statistics. Leveraging the global symmetry inherent in these statistics enables the derivation of data-driven thresholds suitable for multiple testing scenarios. Method development occurs within the framework of U-statistics, which naturally encompasses existing cumulative sum-based procedures. Theoretical guarantees establish FDR control for the component-wise sign-based method under mild assumptions. Demonstrations of effectiveness utilize simulations with synthetic data and analyses of real data.},
  archive      = {J_CSDA},
  author       = {Hui Chen and Chengde Qian and Qin Zhou},
  doi          = {10.1016/j.csda.2025.108272},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108272},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Robust selection of the number of change-points via FDR control},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Kernel density estimation with a markov chain monte carlo sample. <em>CSDA</em>, <em>214</em>, 108271. (<a href='https://doi.org/10.1016/j.csda.2025.108271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference relies on the posterior distribution, which is often estimated with a Markov chain Monte Carlo sampler. The sampler produces a dependent stream of variates from the limiting distribution of the Markov chain, the posterior distribution. When one wishes to display the estimated posterior density, a natural choice is the histogram. However, abundant literature has shown that the kernel density estimator is more accurate than the histogram in terms of mean integrated squared error for an i.i.d. sample. With this as motivation, a kernel density estimation method is proposed that is appropriate for the dependence in the Markov chain Monte Carlo output. To account for the dependence, the cross-validation criterion is modified to select the bandwidth in standard kernel density estimation approaches. A data-driven adjustment to the biased cross-validation method is suggested with introducing the integrated autocorrelation time of the kernel. The convergence of the modified bandwidth to the optimal bandwidth is shown by adapting theorems from the time series literature. Simulation studies show that the proposed method finds the bandwidth close to the optimal value, while standard methods lead to smaller bandwidths under Markov chain samples and hence to undersmoothed density estimates. A study with real data shows that the proposed method has a considerably smaller integrated mean squared error than standard methods. The R package KDEmcmc to implement the suggested algorithm is available on the Comprehensive R Archive Network.},
  archive      = {J_CSDA},
  author       = {Hang J. Kim and Steven N. MacEachern and Young Min Kim and Yoonsuh Jung},
  doi          = {10.1016/j.csda.2025.108271},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108271},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Kernel density estimation with a markov chain monte carlo sample},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Measure selection for functional linear model. <em>CSDA</em>, <em>214</em>, 108270. (<a href='https://doi.org/10.1016/j.csda.2025.108270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in modern science have led to an increased prevalence of functional data, which are usually viewed as elements of the space of square-integrable functions L 2 . Core methods in functional data analysis, such as functional principal component analysis, are typically grounded in the Hilbert structure of L 2 and rely on inner products based on integrals with respect to the Lebesgue measure over a fixed domain. A more flexible framework is proposed, where the measure can be arbitrary, allowing natural extensions to unbounded domains and prompting the question of optimal measure choice. Specifically, a novel functional linear model is introduced that incorporates a data-adaptive choice of the measure that defines the space, alongside an enhanced function principal component analysis. Selecting a good measure can improve the model’s predictive performance, especially when the underlying processes are not well-represented when adopting the default Lebesgue measure. Simulations, as well as applications to COVID-19 data and the National Health and Nutrition Examination Survey data, show that the proposed approach consistently outperforms the conventional functional linear model.},
  archive      = {J_CSDA},
  author       = {Su I Iao and Hans-Georg Müller},
  doi          = {10.1016/j.csda.2025.108270},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108270},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Measure selection for functional linear model},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of normal-reference tests for high-dimensional means with implementation in the r package ‘HDNRA’. <em>CSDA</em>, <em>214</em>, 108269. (<a href='https://doi.org/10.1016/j.csda.2025.108269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of testing for equal mean vectors in high-dimensional data poses significant difficulties in statistical inference. Much of the existing literature introduces methods that often rely on stringent regularity conditions for the underlying covariance matrices, enabling asymptotic normality of test statistics. However, this can lead to complications in controlling test size. To address these issues, a new set of tests has emerged, leveraging the normal-reference approach to improve reliability. The latest normal-reference methods for testing equality of mean vectors in high-dimensional samples, potentially with differing covariance structures, are reviewed. The theoretical underpinnings of these tests are revisited, providing a new unified justification for the validity of centralized L 2 -norm-based normal-reference tests (NRTs) by deriving the convergence rate of the distance between the null distribution of the test statistic and its corresponding normal-reference distribution. To facilitate practical application, an R package, HDNRA , is introduced, implementing these NRTs and extending beyond the two-sample problem to accommodate general linear hypothesis testing (GLHT). The package, designed with user-friendliness in mind, achieves efficient computation through a core implemented in C++ using Rcpp , OpenMP , and RcppArmadillo . Examples with real datasets are included, showcasing the application of various tests and providing insights into their practical utility.},
  archive      = {J_CSDA},
  author       = {Pengfei Wang and Tianming Zhu and Jin-Ting Zhang},
  doi          = {10.1016/j.csda.2025.108269},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108269},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Overview of normal-reference tests for high-dimensional means with implementation in the r package ‘HDNRA’},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional subgroup functional quantile regression with panel and dependent data. <em>CSDA</em>, <em>214</em>, 108268. (<a href='https://doi.org/10.1016/j.csda.2025.108268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional additive functional partial linear single-index quantile regression with high-dimensional parameters under subgroup panel data is investigated. Based on spline-based approach, we construct oracle estimators of the unknown parameter and functions, and discuss their consistency with rates and asymptotic normality under α -mixing assumptions. A penalized estimation method by using the SCAD technique is introduced to estimate the additive functions and parameter, enabling variable selection and automatic identification of the number of groups. Hypothesis testing for the parameter is also considered, and the asymptotic distributions of the restricted estimators and the test statistic are derived under both the null and local alternative hypotheses. Simulation studies and real data analysis are conducted to verify the validity of the proposed methods and applications.},
  archive      = {J_CSDA},
  author       = {Xiao-Ge Yu and Han-Ying Liang},
  doi          = {10.1016/j.csda.2025.108268},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108268},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {High-dimensional subgroup functional quantile regression with panel and dependent data},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cviu">CVIU - 9</h2>
<ul>
<li><details>
<summary>
(2025). Two-stage attribute-guided dual attention network for fine-grained fashion retrieval. <em>CVIU</em>, <em>261</em>, 104497. (<a href='https://doi.org/10.1016/j.cviu.2025.104497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained clothing retrieval is essential for intelligent shopping and personalized recommendation systems. However, conventional methods often fail to capture subtle attribute variations. This paper proposes a novel two-stage attribute-guided dual attention network. The network combines global and local feature extraction with Attribute-aware Multi-Scale Spatial Attention (AMSA) and Attribute-guided Dynamic Channel Attention (ADCA). AMSA captures attribute-specific spatial details at multiple scales, while ADCA dynamically adjusts channel importance based on attribute embeddings, enabling precise attribute-level similarity modeling. A multi-level joint loss function further optimizes both global and local representations and enhances feature alignment. Experiments on FashionAI and the self-built FGDress dataset show that the proposed method achieves mAP scores of 66.01% and 73.98%, respectively, outperforming baseline approaches. Attribute-level analysis confirms robust recognition of both well-defined and challenging attributes. These results validate the practicality and generalizability of the proposed framework, with promising applications in personalized recommendation, fashion trend analysis, and design evaluation.},
  archive      = {J_CVIU},
  author       = {Bo Pan and Jun Xiang and Ning Zhang and Ruru Pan},
  doi          = {10.1016/j.cviu.2025.104497},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104497},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Two-stage attribute-guided dual attention network for fine-grained fashion retrieval},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JSF: A joint spatial-frequency domain network for low-light image enhancement. <em>CVIU</em>, <em>261</em>, 104496. (<a href='https://doi.org/10.1016/j.cviu.2025.104496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enhancement of low-light images remains a prominent focus in the field of image processing. The degree of lightness significantly influences vision-based intelligent recognition and analysis. Departing from conventional methods, this paper proposes an innovative joint spatial-frequency domain network for low-light image enhancement, referred to as JSF. In the spatial domain, brightness is optimized through the amalgamation of global and local information. In the frequency domain, noise is reduced and details are amplified using Fourier Transformation to carry out amplitude and phase enhancement. Additionally, the enhanced results from the aforementioned domains are fused by linear and nonlinear stretching. To validate the effectiveness of JSF, this paper presents both qualitative and quantitative comparison results, demonstrating its superiority over several existing state-of-the-art methods.},
  archive      = {J_CVIU},
  author       = {Yahong Wu and Feng Liu and Rong Wang},
  doi          = {10.1016/j.cviu.2025.104496},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104496},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {JSF: A joint spatial-frequency domain network for low-light image enhancement},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCNet: A feature complementary network for nighttime flare removal. <em>CVIU</em>, <em>261</em>, 104495. (<a href='https://doi.org/10.1016/j.cviu.2025.104495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nighttime image flare removal is a very challenging task due to the presence of various types of unfavorable degrading effects, including glare, shimmer, streak and saturated blobs. Most of the existing methods focus on the spatial domain and limited perception field, resulting in incomplete flare removal and severe artifacts. To address these challenges, we propose a two-stage feature complementary network for nighttime flare removal, which is used for flare perception and removal, respectively. In the first stage, a Spatial-Frequency Complementary Module (SFCM) is designed to perceive the flare region from different domains to get a mask of the flare. In the second stage, the flare mask and image are fed into the Spatial-Frequency Complementary Gating Module (SFCGM) to preserve the background information, while removing the flares from different angles and restoring the detailed features. Finally the flare and non-flare regions are modeled by the Flare Interactive Module (FIM) to refine the flare regions at a fine-grained level to suppress the artifact problem. Extensive experiments on Flare 7K++ validate the superiority of the proposed approach over state-of-the-arts, both qualitatively and quantitatively.},
  archive      = {J_CVIU},
  author       = {Kejing Qi and Bo Wang and Chongyi Li},
  doi          = {10.1016/j.cviu.2025.104495},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104495},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {FCNet: A feature complementary network for nighttime flare removal},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRE-net: A forgery image detection framework based on gradient feature and reconstruction error. <em>CVIU</em>, <em>261</em>, 104494. (<a href='https://doi.org/10.1016/j.cviu.2025.104494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous technological breakthroughs in Generative Adversarial Networks (GANs) and diffusion models, remarkable progress has been achieved in the field of image generation. These technologies enable the creation of highly realistic images, thereby intensifying the risk of spreading fake information. However, traditional image detectors face a growing challenge of inadequate generalization capabilities when confronted with images generated by models that were not included during the training phase. To tackle this challenge, we introduce a novel detection framework, named GRE-Net (Network integrating Gradient and Reconstruction Error), which extracts gradient feature through the DPG module and calculates the reconstruction error utilizing the DIRE method. By integrating these two aspects into a comprehensive feature representation, GRE-Net effectively detects the authenticity of images. Specifically, we devise a dual-branch model that leverages the proposed DPG (Discriminator of ProjectedGAN to extract Gradient) module to extract gradient feature from images and concurrently employs the DIRE (DIffusion Reconstruction Error) method to obtain the diffusion reconstruction error of images. By fusing the features extracted from these two modules as a universal representation, we describe the artifacts produced by generative models, crafting a comprehensive detector capable of identifying both GAN-generated and diffusion model-generated images. Notably, the DPG approach utilizes the discriminator of ProjectedGAN as an intermediary bridge, mapping all data into the gradient domain. This transformation process effectively captures the intrinsic feature differences during the image generation process. Subsequently, the gradient feature are fed into a classifier to achieve efficient discrimination between authentic and fake images. To validate the efficacy of our proposed detector, we conducted evaluations on a dataset comprising images generated by ten diverse diffusion models and GANs. Extensive experiments demonstrate that our detector exhibits stronger generalization capabilities and higher robustness, rendering it suitable for real-world generated image detection tasks.},
  archive      = {J_CVIU},
  author       = {Wenqing Wu and Xinyi Shi and Jinghai Ai and Xiaodong Wang},
  doi          = {10.1016/j.cviu.2025.104494},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104494},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {GRE-net: A forgery image detection framework based on gradient feature and reconstruction error},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating forgetting in the adaptation of CLIP for few-shot classification. <em>CVIU</em>, <em>261</em>, 104493. (<a href='https://doi.org/10.1016/j.cviu.2025.104493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adapter-style efficient transfer learning has demonstrated outstanding performance in fine-tuning vision-language models, especially in scenarios with limited data. However, existing methods fail to effectively balance the prior knowledge acquired during the pre-training process and the training samples. To address this problem, we propose a method called Mitigating Forgetting in the Adaptation (MiFA) of CLIP. MiFA first employs class prototypes to represent the most prominent features of a class, and these prototypes provide a robust initialization for the classifier. To overcome the forgetting of prior knowledge, MiFA then leverages a memory module that retains the initial parameters and the parameters of training history by creating a memory weight through momentum. The weight is used to initialize a new classification layer, which, along with the original layer, guides each other to balance prior knowledge and feature adaptation. Similarly, in the text processing branch, a parallel initialization strategy is adopted to ensure that the model’s performance is improved. Text features are employed to initialize a text classification layer, and CLIP logits help prevent excessive forgetting of useful text information. Extensive experiments have demonstrated the effectiveness of our method.},
  archive      = {J_CVIU},
  author       = {Jiale Cao and Yuanheng Liu and Zhong Ji and Jingren Liu and Aiping Yang and Yanwei Pang},
  doi          = {10.1016/j.cviu.2025.104493},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104493},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Mitigating forgetting in the adaptation of CLIP for few-shot classification},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint multi-dimensional dynamic attention and transformer for general image restoration. <em>CVIU</em>, <em>261</em>, 104491. (<a href='https://doi.org/10.1016/j.cviu.2025.104491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outdoor images often suffer from severe degradation due to rain, haze, and noise, impairing image quality and challenging high-level tasks. Current image restoration methods struggle to handle complex degradation while maintaining efficiency. This paper introduces a novel image restoration architecture that combines multi-dimensional dynamic attention and self-attention within a U-Net framework. To leverage the global modeling capabilities of transformers and the local modeling capabilities of convolutions, we integrate sole CNNs in the encoder–decoder and sole transformers in the latent layer. Additionally, we design convolutional kernels with selected multi-dimensional dynamic attention to capture diverse degraded inputs efficiently. A transformer block with transposed self-attention further enhances global feature extraction while maintaining efficiency. Extensive experiments demonstrate that our method achieves a better balance between performance and computational complexity across five image restoration tasks: deraining, deblurring, denoising, dehazing, and enhancement, as well as superior performance for high-level vision tasks. The source code will be available at https://github.com/House-yuyu/MDDA-former .},
  archive      = {J_CVIU},
  author       = {Huan Zhang and Xu Zhang and Nian Cai and Jianglei Di and Yun Zhang},
  doi          = {10.1016/j.cviu.2025.104491},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104491},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Joint multi-dimensional dynamic attention and transformer for general image restoration},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO. <em>CVIU</em>, <em>261</em>, 104489. (<a href='https://doi.org/10.1016/j.cviu.2025.104489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone-based target detection presents inherent challenges, including the high density and overlap of targets in drone images, as well as the blurriness of targets under varying lighting conditions, which complicates accurate identification. Traditional methods often struggle to detect numerous small, densely packed targets against complex backgrounds. To address these challenges, we propose LAM-YOLO, an object detection model specifically designed for drone-based applications. First, we introduce a light-occlusion attention mechanism to enhance the visibility of small targets under diverse lighting conditions. Additionally, we incorporate Involution modules to improve feature layer interactions. Second, we employ an improved SIB-IoU as the regression loss function to accelerate model convergence and enhance localization accuracy. Finally, we implement a novel detection strategy by introducing two auxiliary detection heads to better identify smaller-scale targets. Our quantitative results demonstrate that LAM-YOLO outperforms methods such as Faster R-CNN, YOLOv11, and YOLOv12 in terms of mAP@0.5 and mAP@0.5:0.95 on the VisDrone2019 public dataset. Compared to the original YOLOv8, the average precision increases by 7.1%. Additionally, the proposed SIB-IoU loss function not only accelerates convergence speed during training but also improves average precision compared to the traditional loss function.},
  archive      = {J_CVIU},
  author       = {Yuchen Zheng and Yuxin Jing and Jufeng Zhao and Guangmang Cui},
  doi          = {10.1016/j.cviu.2025.104489},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104489},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camera pose in SfT and NRSfM under isometric and weaker deformation models. <em>CVIU</em>, <em>261</em>, 104488. (<a href='https://doi.org/10.1016/j.cviu.2025.104488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camera pose is a very natural concept in 3D vision in the rigid setting. It is however much more difficult to work with in deformable settings. Consequently, numerous deformable reconstruction methods simply ignore camera pose. We analyse the concept of pose in deformable settings and prove that it is unconstrained with the existing formulations, properly justifying the existing pose-less methods reconstructing structure only. We explain this result intuitively by the impossibility to define an intrinsic coordinate frame to a general deforming object. The proposed analysis uses the isometric deformation model and extends to the weaker models including conformality and equiareality We propose a novel prior to rescue camera pose estimation in deformable settings, which attributes the deforming object’s dominant rigid-body motion to the camera. We show that adding this prior to any existing formulation fully constrains camera pose and leads to elegant two-step solution methods, involving deformable structure reconstruction using a base method in the first step, and absolute orientation or Procrustes analysis in the second step. We derive the proposed approach for the template-based and template-less settings, respectively implemented using Shape-from-Template (SfT) and Non-Rigid Structure-from-Motion (NRSfM) as base methods and validate them experimentally, showing that the computed pose is qualitatively and quantitatively plausible.},
  archive      = {J_CVIU},
  author       = {Adrien Bartoli and Agniva Sengupta},
  doi          = {10.1016/j.cviu.2025.104488},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104488},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Camera pose in SfT and NRSfM under isometric and weaker deformation models},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-granularity balance learning for long-tailed image classification. <em>CVIU</em>, <em>261</em>, 104469. (<a href='https://doi.org/10.1016/j.cviu.2025.104469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In long-tailed datasets, the training of deep neural network-based models faces challenges, where the model may become biased towards the head classes with abundant training data, resulting in poor performance on tail classes with limited samples. Most current methods employ contrastive learning to learn more balanced representations by finding the class center. However, these methods use class centers to address local imbalance within a mini-batch, they overlook the global imbalance between batches throughout an epoch, caused by the long-tailed distribution of the dataset. In this paper, we propose bi-granularity balance learning to address the two-layer imbalance. We decouple the attraction–repulsion term in contrastive loss into two independent components: global and local balance. The global balance component focuses on capturing semantic information from different perspectives of the image and shifting learning attention from the head classes to the tail classes in the global perspective. The local balance component aims to learn inter-class separability from the local perspective. The proposed method efficiently learns the intra-class compactness and inter-class separability in long-tailed model training and improves the performance of the long-tailed model. Experimental results show that the proposed method achieves competitive performance on long-tailed benchmarks such as CIFAR-10/100-LT, TinyImageNet-LT, and iNaturalist 2018.},
  archive      = {J_CVIU},
  author       = {Ning Ren and Xiaosong Li and Yanxia Wu and Yan Fu},
  doi          = {10.1016/j.cviu.2025.104469},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104469},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Bi-granularity balance learning for long-tailed image classification},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="disopt">DISOPT - 3</h2>
<ul>
<li><details>
<summary>
(2025). Computational aspects of lifted cover inequalities for knapsacks with few different weights. <em>DISOPT</em>, <em>58</em>, 100912. (<a href='https://doi.org/10.1016/j.disopt.2025.100912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cutting planes are frequently used for solving integer programs. A common strategy is to derive cutting planes from building blocks or a substructure of the integer program. In this paper, we focus on knapsack constraints that arise from single row relaxations. Among the most popular classes derived from knapsack constraints are lifted minimal cover inequalities. The separation problem for these inequalities is NP-hard though, and one usually separates them heuristically, therefore not fully exploiting their potential. For many benchmarking instances however, it turns out that many knapsack constraints only have few different coefficients. This motivates the concept of sparse knapsacks where the number of different coefficients is a small constant, independent of the number of variables present. For such knapsacks, we observe that there are only polynomially many different classes of structurally equivalent minimal covers. This opens the door to specialized techniques for using lifted minimal cover inequalities. In this article we will discuss two such techniques, which are based on specialized sorting methods. On the one hand, we present new separation routines that separate equivalence classes of inequalities rather than individual inequalities. On the other hand, we derive compact extended formulations that express all lifted minimal cover inequalities by means of a polynomial number of constraints. These extended formulations are based on tailored sorting networks that express our separation algorithm by linear inequalities. We conclude the article by a numerical investigation of the different techniques for popular benchmarking instances.},
  archive      = {J_DISOPT},
  author       = {Christopher Hojny and Cédric Roy},
  doi          = {10.1016/j.disopt.2025.100912},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100912},
  shortjournal = {Discret. Optim.},
  title        = {Computational aspects of lifted cover inequalities for knapsacks with few different weights},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved bound for the price of anarchy for related machine scheduling. <em>DISOPT</em>, <em>58</em>, 100911. (<a href='https://doi.org/10.1016/j.disopt.2025.100911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce an improved upper bound for the efficiency of Nash equilibria in utilitarian scheduling games on related machines. The machines have varying speeds and adhere to the shortest processing time first policy. The goal of each job is to minimize its completion time, while the social objective is to minimize the sum of completion times. Our main finding establishes an upper bound of 2 − 1 / ( 4 m − 2 ) on the price of anarchy for the general case of m machines. We improve this bound to 3/2 for the case of two machines, and to 2 − 1 / ( 2 m ) for the general case of m machines when the machines have divisible speeds, i.e., if the speed of each machine is divisible by the speed of any slower machine.},
  archive      = {J_DISOPT},
  author       = {André Berger and Arman Rouhani and Marc Schröder},
  doi          = {10.1016/j.disopt.2025.100911},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100911},
  shortjournal = {Discret. Optim.},
  title        = {An improved bound for the price of anarchy for related machine scheduling},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the circuit diameter conjecture for counterexamples to the hirsch conjecture. <em>DISOPT</em>, <em>58</em>, 100910. (<a href='https://doi.org/10.1016/j.disopt.2025.100910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circuit diameters of polyhedra are a fundamental tool for studying the complexity of circuit augmentation schemes for linear programming and for finding lower bounds on combinatorial diameters. The main open problem in this area is the circuit diameter conjecture, the analogue of the Hirsch conjecture in the circuit setting. A natural question is whether the well-known counterexamples to the Hirsch conjecture carry over. Previously, Stephen and Yusun showed that the Klee-Walkup counterexample to the unbounded Hirsch conjecture does not transfer to the circuit setting. Our main contribution is to show that the original counterexamples for other variants, using monotone walks or for bounded polytopes, also do not transfer. A challenge lies in the dependence of circuit diameters on the specific realization of a polyhedron. We discuss for which realizations, in addition to the original ones from the literature, our tools resolve this question. Our results rely on new observations on structural properties of these counterexamples. To analyze the bounded case, we exploit the geometry of certain 2-faces of the polytopes underlying all known bounded Hirsch counterexamples in Santos’ work. For Todd’s monotone Hirsch counterexample, we study linear programs on spindles and prove sufficient conditions for short monotone circuit walks to exist. We then enumerate all linear programs over Todd’s polytope and find four new orientations that contradict the monotone Hirsch conjecture, while the remaining 7107 satisfy the bound. The conclusion then follows by applying these sufficient conditions to Todd’s counterexample.},
  archive      = {J_DISOPT},
  author       = {Alexander E. Black and Steffen Borgwardt and Matthias Brugger},
  doi          = {10.1016/j.disopt.2025.100910},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100910},
  shortjournal = {Discret. Optim.},
  title        = {On the circuit diameter conjecture for counterexamples to the hirsch conjecture},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="dke">DKE - 13</h2>
<ul>
<li><details>
<summary>
(2026). A graph-based model for semantic textual similarity measurement. <em>DKE</em>, <em>161</em>, 102509. (<a href='https://doi.org/10.1016/j.datak.2025.102509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring semantic similarity between sentence pairs is a fundamental problem in Natural Language Processing with applications in various domains, including machine translation, speech recognition, automatic question answering, and text summarization. Despite its significance, accurately assessing semantic similarity remains a challenging task, particularly for underrepresented languages such as Vietnamese. Existing methods have yet to fully leverage the unique linguistic characteristics of Vietnamese for semantic similarity measurement. To address this limitation, we propose GBNet-STS (Graph-Based Network for Semantic Textual Similarity), a novel framework for measuring the semantic similarity of Vietnamese sentence pairs. GBNet-STS integrates lexical-grammatical similarity scores and distributional semantic similarity scores within a multi-layered graph-based model. By capturing different semantic perspectives through multiple interconnected layers, our approach provides a more comprehensive and robust similarity estimation. Experimental results demonstrate that GBNet-STS outperforms traditional methods, achieving state-of-the-art performance in Vietnamese semantic similarity tasks.},
  archive      = {J_DKE},
  author       = {Van-Tan Bui and Quang-Minh Nguyen and Van-Vinh Nguyen and Duc-Toan Nguyen},
  doi          = {10.1016/j.datak.2025.102509},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102509},
  shortjournal = {Data Knowl. Eng.},
  title        = {A graph-based model for semantic textual similarity measurement},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rule-guided process discovery. <em>DKE</em>, <em>161</em>, 102508. (<a href='https://doi.org/10.1016/j.datak.2025.102508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event data extracted from information systems serves as the foundation for process mining, enabling the extraction of insights and identification of improvements. Process discovery focuses on deriving descriptive process models from event logs, which form the basis for conformance checking, performance analysis, and other applications. Traditional process discovery techniques predominantly rely on event logs, often overlooking supplementary information such as domain knowledge and process rules. These rules, which define relationships between activities, can be obtained through automated techniques like declarative process discovery or provided by domain experts based on process specifications. When used as an additional input alongside event logs, such rules have significant potential to guide process discovery. However, leveraging rules to discover high-quality imperative process models, such as BPMN models and Petri nets, remains an underexplored area in the literature. To address this gap, we propose an enhanced framework, IMr, which integrates discovered or user-defined rules into the process discovery workflow via a novel recursive approach. The IMr framework employs a divide-and-conquer strategy, using rules to guide the selection of process structures at each recursion step in combination with the input event log. We evaluate our approach on several real-world event logs and demonstrate that the discovered models better align with the provided rules without compromising their conformance to the event log. Additionally, we show that high-quality rules can improve model quality across well-known conformance metrics. This work highlights the importance of integrating domain knowledge into process discovery, enhancing the quality, interpretability, and applicability of the resulting process models.},
  archive      = {J_DKE},
  author       = {Ali Norouzifar and Marcus Dees and Wil van der Aalst},
  doi          = {10.1016/j.datak.2025.102508},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102508},
  shortjournal = {Data Knowl. Eng.},
  title        = {Rule-guided process discovery},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LQ-FJS: A logical query-digging fake-news judgment system with structured video-summarization engine using LLM. <em>DKE</em>, <em>161</em>, 102507. (<a href='https://doi.org/10.1016/j.datak.2025.102507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of online social platforms can greatly benefit people by fostering remote relationships, but it also inevitably amplifies the impact of multimodal fake news on societal trust and ethics. Existing fake-news detection AI systems are still vulnerable to the inconspicuous and indiscernible multimodal misinformation, and often lacking interpretability and accuracy in cross-platform settings. Hence, we propose a new innovative logical query-digging fake-news judgment system (LQ-FJS) to tackle the above problem based on multimodal approach. The LQ-FJS verifies the truthfulness of claims made within multimedia news by converting video content into structured textual summaries. It then acts as an interpretable agent, explaining the reasons for identified fake news by the structured video-summarization engine (SVSE) to act as an interpretable detection intermediary agent. The SVSE generates condensed captions for raw video content, converting it into structured textual narratives. Then, LQ-FJS exploits these condensed captions to retrieve reliable information related to the video content from LLM. Thus, LQ-FJS cross-verifies external knowledge sources and internal LLM responses to determine whether contradictions exist with factual information through a multimodal inconsistency verification procedure. Our experiments demonstrate that the subtle summarization produced by SVSE can facilitate the generation of explanatory reports that mitigate large-scale trust deficits caused by opaque “black-box” models. Our experiments show that LQ-FJS improves F1 scores by 4.5% and 7.2% compared to state-of-the-art models (FactLLaMA 2023 and HiSS 2023), and increases 14% user trusts through interpretable conclusions.},
  archive      = {J_DKE},
  author       = {Jhing-Fa Wang and Din-Yuen Chan and Hsin-Chun Tsai and Bo-Xuan Fang},
  doi          = {10.1016/j.datak.2025.102507},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102507},
  shortjournal = {Data Knowl. Eng.},
  title        = {LQ-FJS: A logical query-digging fake-news judgment system with structured video-summarization engine using LLM},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ABBA: Index structure for sequential pattern-based aggregate queries. <em>DKE</em>, <em>161</em>, 102506. (<a href='https://doi.org/10.1016/j.datak.2025.102506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern-based aggregate (PBA) queries constitute an important and widely used type of analytical queries in sequence OLAP (S-OLAP) systems. Unfortunately, finding accurate answers to PBA queries in the S-OLAP system is often very expensive both in terms of time and memory consumption. In this paper we propose an efficient and easily maintainable index structure called the ABBA Index, which addresses the problem of PBA query processing. Experiments conducted using the KDD Cup data and public transport passengers’ travel behavior data show that our index outperforms state-of-the art solutions while requiring much less memory. The ABBA Index can be easily extended to support pattern-based aggregate queries over hierarchy (PBA-H), a novel class of analytical queries which we introduce as the second main contribution of the paper. Sensitivity, scalability and complexity analysis of the ABBA Index is also provided.},
  archive      = {J_DKE},
  author       = {Witold Andrzejewski and Tadeusz Morzy and Maciej Zakrzewicz},
  doi          = {10.1016/j.datak.2025.102506},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102506},
  shortjournal = {Data Knowl. Eng.},
  title        = {ABBA: Index structure for sequential pattern-based aggregate queries},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Elevating human-machine collaboration in NLP for enhanced content creation and decision support. <em>DKE</em>, <em>161</em>, 102505. (<a href='https://doi.org/10.1016/j.datak.2025.102505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-machine collaboration in Natural Language Processing (NLP) is revolutionizing content creation and decision support by seamlessly combining the strengths of both entities for enhanced efficiency and quality. The lack of seamless integration between human creativity and machine efficiency in NLP hinders optimal content creation and decision support. The objective of this study is to explore and promote the integration of human-machine collaboration in NLP to enhance both content creation and decision support processes. Data Acquisition for NLP requests involves defining the task and target audience, identifying relevant data sources like text documents and web data, and incorporating human expertise for data curation through validation and annotation. Machine processing techniques like tokenization, stemming/lemmatization, and removal of stop words, as well as human input for tasks like data annotation and error correction, to improve data quality and relevance for NLP applications. The combination of automated processing and human feedback leads to more precise and dependable effects. Techniques such as sentiment analysis, topic modelling, and entity recognition are utilized to excerpt valued perceptions from the data and enhance collaboration between humans and machines. These techniques help to streamline the NLP process and ensure that the system is providing accurate and relevant information to users. The analysis of NLP models in machine processing involves training the models to perform specific tasks, such as summarization, sentiment analysis, information extraction, trend identification, and creative content generation. The results show that social media leads with 90% usage, pivotal for audience engagement, while blogs at 78% highlight their depth in content creation implementation using Python software. These trained models are then used to improve decision-making processes, generate creative content, and enhance the accuracy of search results. The future scope involves leveraging advanced NLP techniques to deepen the collaboration between humans and machines for more effective content creation and decision support.},
  archive      = {J_DKE},
  author       = {Priyanka V. Deshmukh and Aniket K. Shahade},
  doi          = {10.1016/j.datak.2025.102505},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102505},
  shortjournal = {Data Knowl. Eng.},
  title        = {Elevating human-machine collaboration in NLP for enhanced content creation and decision support},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ELEVATE-ID: Extending large language models for end-to-end entity linking evaluation in indonesian. <em>DKE</em>, <em>161</em>, 102504. (<a href='https://doi.org/10.1016/j.datak.2025.102504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their effectiveness in low-resource languages remains underexplored, particularly in complex tasks such as end-to-end Entity Linking (EL), which requires both mention detection and disambiguation against a knowledge base (KB). In earlier work, we introduced IndEL — the first end-to-end EL benchmark dataset for the Indonesian language — covering both a general domain (news) and a specific domain (religious text from the Indonesian translation of the Quran), and evaluated four traditional end-to-end EL systems on this dataset. In this study, we propose ELEVATE-ID, a comprehensive evaluation framework for assessing LLM performance on end-to-end EL in Indonesian. The framework evaluates LLMs under both zero-shot and fine-tuned conditions, using multilingual and Indonesian monolingual models, with Wikidata as the target KB. Our experiments include performance benchmarking, generalization analysis across domains, and systematic error analysis. Results show that GPT-4 and GPT-3.5 achieve the highest accuracy in zero-shot and fine-tuned settings, respectively. However, even fine-tuned GPT-3.5 underperforms compared to DBpedia Spotlight — the weakest of the traditional model baselines — in the general domain. Interestingly, GPT-3.5 outperforms Babelfy in the specific domain. Generalization analysis indicates that fine-tuned GPT-3.5 adapts more effectively to cross-domain and mixed-domain scenarios. Error analysis uncovers persistent challenges that hinder LLM performance: difficulties with non-complete mentions, acronym disambiguation, and full-name recognition in formal contexts. These issues point to limitations in mention boundary detection and contextual grounding. Indonesian-pretrained LLMs, Komodo and Merak, reveal core weaknesses: template leakage and entity hallucination, respectively—underscoring architectural and training limitations in low-resource end-to-end EL. 1},
  archive      = {J_DKE},
  author       = {Ria Hari Gusmita and Asep Fajar Firmansyah and Hamada M. Zahera and Axel-Cyrille Ngonga Ngomo},
  doi          = {10.1016/j.datak.2025.102504},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102504},
  shortjournal = {Data Knowl. Eng.},
  title        = {ELEVATE-ID: Extending large language models for end-to-end entity linking evaluation in indonesian},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-aware complex question answering over temporal knowledge graph. <em>DKE</em>, <em>161</em>, 102503. (<a href='https://doi.org/10.1016/j.datak.2025.102503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Question Answering (KGQA) is a crucial topic in Knowledge Graphs (KGs), with the objective of retrieving the corresponding facts from KGs to answer given questions. In practical applications, facts in KGs usually have time constraints, thus, question answering on Temporal Knowledge Graphs (TKGs) has attracted extensive attention. Existing Temporal Knowledge Graph Question Answering (TKGQA) methods focus on dealing with complex questions involving multiple facts, and mainly face two challenges. First, these methods only consider matching questions with facts in TKGs to identify the answer, ignoring the temporal order between different facts, which makes it challenging to solve the questions involving temporal order. Second, they usually focus on the representation of the question text while neglecting the rich semantic information within the questions, which leads to certain limitations in understanding question. To address the above challenges, this research proposes a model named Time-Aware Complex Question Answering (TA-CQA). Specifically, we extend the Temporal Knowledge Graph Embedding (TKGE) model by incorporating temporal order information into the embedding vectors, ensuring that the model can distinguish the temporal order of different facts. To enhance the semantic representation of the question, we integrate question information using attention mechanism and learnable encoder. Different from the previous TKGQA methods, we propose time relevance measurement to further enhance the accuracy of answer prediction by better capturing the correlation between question information and time information. Multiple sets of experiments on CronQuestions and TimeQuestions demonstrate our model’s superior performance across all question types. In particular, for complex questions involving multiple facts, the hit@1 values are increased by 3.2% and 3.5% respectively.},
  archive      = {J_DKE},
  author       = {Luyi Bai and Tongyue Zhang and Guangchen Feng},
  doi          = {10.1016/j.datak.2025.102503},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102503},
  shortjournal = {Data Knowl. Eng.},
  title        = {Time-aware complex question answering over temporal knowledge graph},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conceptual modeling of user perspectives — From data warehouses to alliance-driven data ecosystems. <em>DKE</em>, <em>161</em>, 102502. (<a href='https://doi.org/10.1016/j.datak.2025.102502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of modern information systems has highlighted the need for advanced conceptual modeling techniques that incorporate multi-perspective and view-based approaches. This paper explores the role of multi-perspective modeling and view modeling in designing distributed, heterogeneous systems while addressing diverse user requirements and ensuring semantic consistency. These methods enable the representation of multiple viewpoints, traceability, and dynamic integration across different levels of abstraction. Key advancements in schema mapping, view maintenance, and semantic metadata management are examined, illustrating how they support query optimization, data quality, and interoperability. We discuss how data management architectures, such as data ecosystems, data warehouses, and data lakes, leverage these innovations to enable flexible and sustainable data sharing. By integrating user-centric and goal-oriented modeling frameworks, the alignment of technical design with organizational and social requirements is emphasized. Future challenges include the need for enhanced reasoning capabilities and collaborative tools to manage the growing complexity of interconnected systems while maintaining adaptability and trust.},
  archive      = {J_DKE},
  author       = {Sandra Geisler and Christoph Quix and István Koren and Matthias Jarke},
  doi          = {10.1016/j.datak.2025.102502},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102502},
  shortjournal = {Data Knowl. Eng.},
  title        = {Conceptual modeling of user perspectives — From data warehouses to alliance-driven data ecosystems},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Source-free domain adaptation with complex distribution considerations for time series data. <em>DKE</em>, <em>161</em>, 102501. (<a href='https://doi.org/10.1016/j.datak.2025.102501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained model from a labeled source domain to an unlabeled target domain without accessing source domain data, thereby protecting source domain privacy. Although SFDA has recently been applied to time series data, the inherent complex distribution characteristics including temporal variability and distributional diversity of such data remain underexplored. Time series data exhibit significant dynamic variability influenced by collection environments, leading to discrepancies between sequences. Additionally, multidimensional time series data face distributional diversity across dimensions. These complex characteristics increase the learning difficulty for source models and widen the adaptation gap between the source and target domains. To address these challenges, this paper proposes a novel SFDA method for time series data, named Adaptive Latent Subdomain feature extraction and joint Prediction (ALSP). The method divides the source domain, which has a complex distribution, into multiple latent subdomains with relatively simple distributions, thereby effectively capturing the features of different subdistributions. It extracts latent domain-specific and domain-invariant features to identify subdomain-specific characteristics. Furthermore, it combines domain-specific classifiers and a domain-invariant classifier to enhance model performance through multi-classifier joint prediction. During target domain adaptation, ALSP reduces domain dependence by extracting invariant features, thereby narrowing the distributional gap between the source and target domains. Simultaneously, it leverages prior knowledge from the source domain distribution to support the hypothesis space and dynamically adapt to the target domain. Experiments on three real-world datasets demonstrate that ALSP achieves superior performance in cross-domain time series classification tasks, significantly outperforming existing methods.},
  archive      = {J_DKE},
  author       = {Jing Shang and Zunming Chen and Zhiwen Xiao and Zhihui Wu and Yifei Zhang and Jibing Wang},
  doi          = {10.1016/j.datak.2025.102501},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102501},
  shortjournal = {Data Knowl. Eng.},
  title        = {Source-free domain adaptation with complex distribution considerations for time series data},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conceptual modeling: A large language model assistant for characterizing research contributions. <em>DKE</em>, <em>161</em>, 102497. (<a href='https://doi.org/10.1016/j.datak.2025.102497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The body of conceptual modeling research publications is vast and diverse, making it challenging for a single researcher or research group to fully comprehend the field’s overall development. Although some approaches have been proposed to help organize these research contributions, it is still unrealistic to expect human experts to manually comprehend and characterize all of this research. However, as generative AI tools based on large language models, such as ChatGPT, become increasingly sophisticated, it may be possible to replace or augment tedious, manual work with semi-automated approaches. In this research, we present a customized version of ChatGPT that is tuned to the task of characterizing conceptual modeling research. Experiments with this AI tool demonstrate that it is feasible to create a usable knowledge survey for the continually evolving body of conceptual modeling research contributions.},
  archive      = {J_DKE},
  author       = {Stephen W. Liddle and Heinrich C. Mayr and Oscar Pastor and Veda C. Storey and Bernhard Thalheim},
  doi          = {10.1016/j.datak.2025.102497},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102497},
  shortjournal = {Data Knowl. Eng.},
  title        = {Conceptual modeling: A large language model assistant for characterizing research contributions},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic time warping for classifying long-term trends in time series. <em>DKE</em>, <em>161</em>, 102495. (<a href='https://doi.org/10.1016/j.datak.2025.102495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the potential of dynamic time warping (DTW) for recognizing different segments in time series data characterized by their long-term trends and curvature. To perform classification, a set of reference data for each class is required, where each time series in the reference set represents a typical shape of that class. The classification process involves computing the DTW distance between a given time series and each reference time series, then assigning the time series to the class with the minimum distance. Experiments on both simulated and real-world time series data from two different use cases demonstrate that DTW can correctly classify the different segments. Additionally, the paper investigates whether incorrectly classified phases could indicate data security issues. Additional experiments are performed to assess the number of data points required to reliably classify a segment correctly. These experiments highlight the limitations and emphasize the importance of selecting good reference data.},
  archive      = {J_DKE},
  author       = {Anna-Christina Glock and Klaus Chmelina and Johannes Fürnkranz and Thomas Hütter},
  doi          = {10.1016/j.datak.2025.102495},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102495},
  shortjournal = {Data Knowl. Eng.},
  title        = {Dynamic time warping for classifying long-term trends in time series},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semantic-aware query answering with large language models. <em>DKE</em>, <em>161</em>, 102494. (<a href='https://doi.org/10.1016/j.datak.2025.102494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern data-driven world, answering queries over heterogeneous and semantically inconsistent data remains a significant challenge. Modern datasets originate from diverse sources, such as relational databases, semi-structured repositories, and unstructured documents, leading to substantial variability in schemas, terminologies, and data formats. Traditional systems, constrained by rigid syntactic matching and strict data binding, struggle to capture critical semantic connections and schema ambiguities, failing to meet the growing demand among data scientists for advanced forms of flexibility and context-awareness in query answering. In parallel, the advent of Large Language Models (LLMs) has introduced new capabilities in natural language interpretation, making them highly promising for addressing such challenges. However, LLMs alone lack the systematic rigor and explainability required for robust query processing and decision-making in high-stakes domains. In this paper, we propose Soft Query Answering (Soft QA), a novel hybrid approach that integrates LLMs as an intermediate semantic layer within the query processing pipeline. Soft QA enhances query answering adaptability and flexibility by injecting semantic understanding through context-aware, schema-informed prompts, and leverages LLMs to semantically link entities, resolve ambiguities, and deliver accurate query results in complex settings. We demonstrate its practical effectiveness through real-world examples, highlighting its ability to resolve semantic mismatches and improve query outcomes without requiring extensive data cleaning or restructuring.},
  archive      = {J_DKE},
  author       = {Paolo Atzeni and Teodoro Baldazzi and Luigi Bellomarini and Eleonora Laurenza and Emanuel Sallinger},
  doi          = {10.1016/j.datak.2025.102494},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102494},
  shortjournal = {Data Knowl. Eng.},
  title        = {Semantic-aware query answering with large language models},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated requirements framework for analytical and AI projects. <em>DKE</em>, <em>161</em>, 102493. (<a href='https://doi.org/10.1016/j.datak.2025.102493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To this day, the requirements of data warehouses, user visualizations and ML projects have been tackled in an independent manner, ignoring the possible cross-requirements, collective constraints and dependencies between the outputs of the different systems that should be taken into account to ensure a successful analytical project. In this work, we take a holistic approach and propose a methodology that supports modeling and subsequent analysis while taking into account these three aspects. This methodology has several advantages, mainly that (i) it enables us to identify possible conflicts between actors on different tasks that are overlooked if the systems are treated in an isolated manner and (ii) this holistic view enables modeling multi-company systems, where the information or even the analytical results can be provided by third-parties, identifying key participants in federated environments. After presenting the required formalism to carry out this kind of analysis, we showcase it on a real-world running example of the tourism sector.},
  archive      = {J_DKE},
  author       = {Juan Trujillo and Ana Lavalle and Alejandro Reina-Reina and Jorge García-Carrasco and Alejandro Maté and Wolfgang Maaß},
  doi          = {10.1016/j.datak.2025.102493},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102493},
  shortjournal = {Data Knowl. Eng.},
  title        = {An integrated requirements framework for analytical and AI projects},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="dss">DSS - 6</h2>
<ul>
<li><details>
<summary>
(2025). Decision support for integrated trade agent's procurement and sales planning under uncertainty. <em>DSS</em>, <em>198</em>, 114537. (<a href='https://doi.org/10.1016/j.dss.2025.114537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a trade agent decision optimization problem (TADOP), in which a trade agent (TA) selects a subset of retailers and suppliers to maximize its profit under uncertain demand and spot price. The TA operates between suppliers and retailers as a third-party platform and decide which subset of retailers to serve, taking into account capacity reservations with option suppliers in advance. Once demand and spot price are realized, the TA decides how much to procure from each channel to fulfill retailers' demand. The problem is formulated as a two-stage stochastic program. Due to the high complexity and large number of scenarios, we reformulate the problem as a set-partition model, where the master problem (MP) selects the combination of retailers to serve, and the subproblem (SP) identifies the optimal procurement plans, thus reducing the number of variables and constraints. To further enhance tractability, the SP is transformed into an equivalent shortest-path problem (SPP) to address issues of non-linearity and non-convexity. Experimental results demonstrate the effectiveness of the decomposition approach, providing TAs with a practical decision-making tool for procurement and sales. Furthermore, the insights gained into TAs' procurement and sales strategies across various scenarios offer valuable guidance for decision-making in uncertain supply chain environments.},
  archive      = {J_DSS},
  author       = {An Liu and Xinyu Wang and Jiafu Tang},
  doi          = {10.1016/j.dss.2025.114537},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114537},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Decision support for integrated trade agent's procurement and sales planning under uncertainty},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling hybrid firm relationships with graph neural networks for stock investment decisions. <em>DSS</em>, <em>198</em>, 114528. (<a href='https://doi.org/10.1016/j.dss.2025.114528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The highly volatile nature of the stock market makes predicting data patterns challenging. Significant efforts have been dedicated to modeling complex stock correlations to improve stock return forecasting and support better investor decision-making. Although various predefined intrinsic associations and learned implicit graph structures have been discovered, they have limitations in fully exploring and leveraging both types of graph information. In this paper, we proposed a Hybrid Structure-aware Graph Neural Network (HSGNN) framework. Unlike models that rely solely on predefined or learned graphs, HSGNN utilizes money-flow graphs to complementarily learn implicit graph structures and applies sparse supply-chain graphs to jointly enhance stock return forecasting. Extensive experiments on real stock benchmarks demonstrate our proposed HSGNN outperforms various state-of-the-art forecasting methods, offering a robust decision-support system for financial stakeholders.},
  archive      = {J_DSS},
  author       = {Yang Du and Biao Li and Zhichen Lu and Gang Kou},
  doi          = {10.1016/j.dss.2025.114528},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114528},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Modeling hybrid firm relationships with graph neural networks for stock investment decisions},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social capital matters: Towards comprehensive user preference for product recommendation with deep learning. <em>DSS</em>, <em>198</em>, 114527. (<a href='https://doi.org/10.1016/j.dss.2025.114527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommender systems help address data sparsity in user–product interactions by leveraging social relationships to infer user preferences. However, existing models often overlook the role of social capital that influence decision-making in social commerce. Social capital consists of structural, relational, and cognitive dimensions, all of which shape user preferences. To better understand these influences, we propose a multi-task learning framework named DeepSC that integrates social capital theory into preference modeling. Its user preference learning module extracts structural features through graph-based pre-training, learns relational features from dynamic user embeddings, and models cognitive features using a hypergraph attention network. Additionally, the dual graph-based product feature learning module enhances cognitive feature extraction by incorporating product co-interactions. DeepSC is optimized through a joint learning objective, combining point-wise and pair-wise learning with an auxiliary social link prediction task to refine user representations. Experiments on three e-commerce datasets demonstrate that DeepSC significantly outperforms the state-of-the-art recommendation models, highlighting the effectiveness of integrating social capital into social preference learning. Our research advances social recommendation by providing a social capital theory-driven approach to modeling user behavior in digital commerce.},
  archive      = {J_DSS},
  author       = {Weiyue Li and Ming Gao and Bowei Chen and Jingmin An and Yeming Gong},
  doi          = {10.1016/j.dss.2025.114527},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114527},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Social capital matters: Towards comprehensive user preference for product recommendation with deep learning},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cybersecurity risk assessment using temporal knowledge graph-based explainable decision support system. <em>DSS</em>, <em>198</em>, 114526. (<a href='https://doi.org/10.1016/j.dss.2025.114526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing cybersecurity policies is crucial for any organization to combat evolving cyber threats. The absence of a comprehensive dataset has prevented previous studies from analyzing the risk of organizations’ cybersecurity policies. Past studies have not considered temporal information in the policies. Analysis of cybersecurity policies using attention mechanism requires automated determination of optimal number of attention units which remains unaddressed. Moreover, absence of interpretation in cybersecurity studies creates a barrier to understanding policy vulnerabilities and developing targeted solutions. To address these challenges, we develop a decision support system which (i) enhances risk classification of organization’s cybersecurity policies, (ii) develops a comprehensive cybersecurity policy dataset from the websites of 190 companies, transformed into a knowledge graph to capture entity relationships among various policies, (iii) integrates temporal information into the knowledge graph by incorporating time stamps from event sequences in cyberattack information, (iv) develops Explainable Factor Analysis based Multi-Head Attention mechanism, which automates the determination of the optimal number of attention units and optimizes data allocation across attention units using factor analysis, and (v) utilizes attention heatmaps and shapley values for interpretability. Our cybersecurity policy dataset is used as a case study with four benchmark datasets for further validation. Results reveal that our model outperforms the other state-of-the-art, achieving an 87.78% F 1 score, followed by robustness checking and statistical significance testing. Finally, Shapley values are used to interpret the model’s output to identify vulnerabilities within the organizational policies, providing crucial insights enabling decision-makers to enhance their cybersecurity policies and mitigate potential threats.},
  archive      = {J_DSS},
  author       = {Subhajit Bag and Sobhan Sarkar and Indranil Bose},
  doi          = {10.1016/j.dss.2025.114526},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114526},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Enhancing cybersecurity risk assessment using temporal knowledge graph-based explainable decision support system},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A field study on the impact of the counter ad-blocking wall strategy on user engagement. <em>DSS</em>, <em>198</em>, 114525. (<a href='https://doi.org/10.1016/j.dss.2025.114525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ad-blocking tools prevent ads from being shown to web users. Their increasingly widespread usage poses an existential risk to online publishers who provide free content and rely on display ads for revenue. Studies on counter ad-blocking strategies taken by publishers are limited, especially with regard to how these strategies affect user engagement, thus posing additional uncertainties to the selection of a suitable counter ad-blocking strategy. Through a randomized field experiment with a large global publisher, our study seeks to understand how the two most common counter ad-blocking strategies, (i) Wall and (ii) Acceptable Ads Exchange (AAX), affect user engagement differently. Our results show that the Wall strategy causes a lower overall engagement compared to AAX, mainly due to users who refuse to whitelist and leave the website. Over time, the negative impact increases, albeit at a slower speed. Furthermore, heavier users, identified based on the amount of engagement in the pre-treatment period, are less affected by the Wall strategy than lighter users; instrumental users, who read for practical purposes, are less affected than entertainment users. Finally, the Wall strategy has a bigger negative impact on the engagement of popular and new articles, compared to niche and old articles, respectively, as observed by a longer tail in engagement distribution with respect to content. These results on the heterogeneous effects of counter ad-blocking strategies on engagement offer novel and important managerial implications on a publisher’s choice of counter ad-blocking strategy and editorial decisions.},
  archive      = {J_DSS},
  author       = {Michael K. Chen and Shuai Zhao and Cristian Borcea and Yi Chen},
  doi          = {10.1016/j.dss.2025.114525},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114525},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A field study on the impact of the counter ad-blocking wall strategy on user engagement},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-platform rumor detection framework considering data privacy protection and different detection capabilities of online social platforms. <em>DSS</em>, <em>198</em>, 114524. (<a href='https://doi.org/10.1016/j.dss.2025.114524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anonymity and widespread popularity of online social platforms (OSPs) allow users to share uncertain posts freely, leading to numerous rumors. Similar rumors spread widely across OSPs, resulting in frequent cross-platform rumors (CPRs). Owing to the unique nature of the cross-platform spread, the dual challenges of data privacy protection constraints and differences in the data and detection capabilities of OSPs exacerbate the difficulty of CPR detection. Thus, to detect CPRs effectively, we designed and implemented a novel deep learning framework named Cross Platform Rumor Detection based on Improved Federated Learning (CPRDIFL), which integrates and improves federated learning and the pre-trained Masked and Contextualized BERT (MacBERT). Our framework uses FL to analyze data from OSPs independently, thus avoiding the need for data integration and ensuring the data privacy protection of OSPs. Moreover, MacBERT is deployed on the clients of CPRDIFL to extract contextual features from posts and dynamically update local weights based on the data and detection performance. Weight parameters are dynamically shared between clients and servers and between clients to achieve complementary advantages across OSPs. Our framework was used in six comprehensive experiments in different scenarios, and the experimental results showed that it achieved the best results in CPR detection. This study not only provides an effective solution for CPR detection but also marks a significant step toward the automated detection of cross-OSP information pollution.},
  archive      = {J_DSS},
  author       = {Xuelong Chen and Jinchao Pan},
  doi          = {10.1016/j.dss.2025.114524},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114524},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A cross-platform rumor detection framework considering data privacy protection and different detection capabilities of online social platforms},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="eaai">EAAI - 29</h2>
<ul>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ejor">EJOR - 21</h2>
<ul>
<li><details>
<summary>
(2025). Optimal lot-sizing and service level weighting in sequential multi-attribute global transportation service procurement. <em>EJOR</em>, <em>327</em>(3), 1052-1072. (<a href='https://doi.org/10.1016/j.ejor.2025.05.037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of on-demand global transportation service procurement (oGTSP) through digital trading platforms has accelerated due to frequent fluctuations in transport capacity. In the oGTSP model, the exporter must consider logistics service quality and transport prices when sourcing global logistics services. To satisfy the continuous transport needs, procurement is conducted sequentially throughout multiple auction cycles. For a single auction, we constructed a service-level weight-scoring function and analysed the trading parties’ behavioural strategies to obtain an auction equilibrium strategy in a specific context. Then, we developed a multi-cycle sequential decision method based on a single-cycle equilibrium decision by forwarders that can dynamically adjust the auction lot size to help the exporter obtain optimal utility. Finally, based on the real case of a large electronic product exporter, the proposed approach was verified. The results demonstrated that exporters should pay more attention to the quality of service when choosing freight forwarders to improve the utility of transportation service procurement. The exporter can attract more forwarders to participate in auctions to obtain more capacity supply by increasing the weighting of service levels. Besides, the proposed auction system could effectively accommodate strategic forwarders with learning abilities. The exporter’s utility will significantly improve if the freight forwarders have learning ability. There is a marginal diminishing effect in that the benefits from additional participation of learning-oriented bidders are initially large but eventually stabilized. The strategic auction participation of learning-oriented freight forwarders smooths the capacity supply trend, reduces extreme fluctuations and makes multi-cycle predictions more accurate.},
  archive      = {J_EJOR},
  author       = {Xiang T.R. Kong and Zhan He and Kaize Yu and Pengyu Yan},
  doi          = {10.1016/j.ejor.2025.05.037},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1052-1072},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal lot-sizing and service level weighting in sequential multi-attribute global transportation service procurement},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Government’s optimal inter-temporal subsidy and manufacturer’s dynamic pricing in the presence of strategic consumers. <em>EJOR</em>, <em>327</em>(3), 1039-1051. (<a href='https://doi.org/10.1016/j.ejor.2025.05.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Governments in many countries offer fiscal incentives—such as subsidies or tax breaks—to consumers to encourage the purchase of environmentally-friendly products like solar panels and electric vehicles. Early adoption by consumers facilitates manufacturers’ learning-by-doing and reduces production cost over time, although the cost reduction itself is subject to uncertainty. Governments face a challenge: should they commit to a multi-period subsidy path (commitment policy) or adjust the subsidy contingent on the realized production cost reduction (dynamic policy)? What are the implications for manufacturers and consumers? We consider a two-period monopoly setting to study these policies. Given the subsidy policy, the manufacturer sets its prices, whereas consumers strategically decide when to purchase the product, if at all. Naturally, the two policies result in different subsidy paths. We find that products with higher initial unit cost (implying higher prices) do not deserve higher subsidies. Our key result is that governments, who seek to maximize expected social welfare, should adopt the dynamic policy. Insightfully, the four components of social welfare—consumer surplus, manufacturer’s profit, environmental benefit and subsidy expenditure—may all be realized higher under the commitment policy than under the dynamic policy when the realized cost reduction falls short of its expected value. This is because the second-period effective price (price minus subsidy) is more sensitive to cost uncertainty under the dynamic policy. Nevertheless, the dominance of the dynamic policy persists also when considering the realized social welfare. We study several extensions demonstrating the robustness of our results, while highlighting certain exceptions.},
  archive      = {J_EJOR},
  author       = {Weichun Chen and Benny Mantin and Bo Li},
  doi          = {10.1016/j.ejor.2025.05.027},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1039-1051},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Government’s optimal inter-temporal subsidy and manufacturer’s dynamic pricing in the presence of strategic consumers},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated model for predictive maintenance and inventory management under a reliability chance constraint. <em>EJOR</em>, <em>327</em>(3), 1023-1038. (<a href='https://doi.org/10.1016/j.ejor.2025.05.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new model that integrates opportunistic maintenance and routine maintenance to enhance the effectiveness of predictive maintenance and inventory management in complex manufacturing systems subject to a reliability chance constraint. It considers both hard and soft failure modes and their mutual dependence. When a machine experiences a hard failure, an opportunistic maintenance policy is utilized on the machine’s components. When the soft failure degradation level of a machine component surpasses a threshold, imperfect preventive maintenance or replacement maintenance is carried out. The choice of component supplier, including OEM and aftermarket suppliers, significantly impacts the joint decision model. To improve the model’s realism and applicability, a random variable representing supplier availability intervals is introduced, reflecting a more nuanced understanding of supply chain dynamics. We develop a simulation optimization method to determine the degradation thresholds for opportunistic and regular maintenance, the component inventory policy, and supplier selection. The objective is to minimize the total maintenance and inventory cost, while ensuring a high level of system reliability. The proposed algorithm effectively addresses the system reliability chance constraint by formulating a surrogate model of the quantile of system downtime. A numerical study is conducted to verify the efficacy of the proposed model and to demonstrate the efficiency of the solution method in finding the optimal feasible solution. Furthermore, the influence of critical factors in the model on the optimal policy is analyzed to derive useful managerial insights.},
  archive      = {J_EJOR},
  author       = {Kuo-Hao Chang and Xin-Pei Wu and Robert Cuckler},
  doi          = {10.1016/j.ejor.2025.05.018},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1023-1038},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An integrated model for predictive maintenance and inventory management under a reliability chance constraint},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ordinal regression meets online learning: Interactive preference learning for multiple criteria choice and ranking with provable guarantees. <em>EJOR</em>, <em>327</em>(3), 1003-1022. (<a href='https://doi.org/10.1016/j.ejor.2025.05.045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a theoretical and practical bridge between ordinal regression for multiple criteria choice and ranking problems and the framework of sequential prediction, also known as online learning. By reframing the ordinal regression as a sequential prediction task, we study a general class of algorithms that assign probabilities to a sequence of the preferences expressed by the Decision Maker (DM). This approach allows us to evaluate various statistical algorithms on a common basis, providing theoretical guarantees on their regret. To model the likelihood, we employ an additive value function that scores pairwise comparisons given by the DM. We explore two likelihood models: (1) a linear model, which we demonstrate is analogous to sequential investment, and (2) the Bradley–Terry model, widely used in statistics and preference learning. For both models, we establish theoretical bounds for the Bayesian method and the Regularized Maximum Likelihood algorithm (also known as Follow the Regularized Leader). We design Monte Carlo Markov Chain methods based on Metropolis–Hastings and Nested Sampling for efficient approximation of the posterior in Bayesian methods. Extensive empirical testing on synthetic and real-world data shows that our methods outperform the best existing approaches in the literature.},
  archive      = {J_EJOR},
  author       = {Marco Grillo and Wojciech Kotłowski and Miłosz Kadziński},
  doi          = {10.1016/j.ejor.2025.05.045},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1003-1022},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ordinal regression meets online learning: Interactive preference learning for multiple criteria choice and ranking with provable guarantees},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternative ranking in trust network group decision-making: A distributionally robust optimization method. <em>EJOR</em>, <em>327</em>(3), 986-1002. (<a href='https://doi.org/10.1016/j.ejor.2025.05.052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In group decision making problems, preference information can be conveniently and productively used to express the decision-makers’ evaluations over the given set of alternatives. However, the inherent imprecision of preference information may lead to fragile priority weights and unreliable alternative ranking. In this study, we propose a distributionally robust ranking model based on social networks to derive stable priorities, which takes into account the influence of uncertain preference information and the strength of relationships among decision-makers. Specifically, to capture the true data-generating distribution of uncertain parameters, we first develop a distributionally robust ranking model with a moment-based ambiguity set that contains all possible probability distributions over a support set. Then, we verify that the solutions exhibit strong finite-sample performance guarantees. Additionally, the developed model can be reformulated into an equivalent semidefinite programming model. To account for the strength of relationships among decision-makers, we employ propagation efficiency based on Shannon’s theorem, and develop the trust propagation and aggregation operators to obtain decision-makers’ weights. Finally, a numerical experiment is provided, in which the justification and robustness of the distributionally robust ranking model outperform several benchmark models by comparative discussions and robustness analyses.},
  archive      = {J_EJOR},
  author       = {Longlong Shao and Jinpei Liu and Chenyi Fu and Ning Zhu and Huayou Chen},
  doi          = {10.1016/j.ejor.2025.05.052},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {986-1002},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Alternative ranking in trust network group decision-making: A distributionally robust optimization method},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When and should streamers choose high-quality products? effects of streamer types. <em>EJOR</em>, <em>327</em>(3), 971-985. (<a href='https://doi.org/10.1016/j.ejor.2025.05.057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of live-streaming commerce, research has largely focused on manufacturers, leaving streamer decision-making underexplored. This study uses game theory to analyze streamers’ product selection strategies, while also examining how streamer types influence these decisions. The findings reveal that: (a) Streamers do not always prioritize high-quality products. Their choices are shaped by various factors, including product pricing, quality gaps, commission ratios, fan-shoppers’ trust, and sales abilities. High-quality manufacturers are advised to collaborate with knowledge-based streamers, while low-quality manufacturers should partner with entertainment-based streamers. Moderate commission ratios can optimize profits for all parties. (b) For well-known products, knowledge-based streamers with strong sales abilities are more likely to select high-quality items, as they can leverage fan-shoppers' willingness to pay. In contrast, entertainment-based streamers do not exhibit this preference. For unknown products, entertainment-based streamers with strong sales abilities may promote low-quality items, even resorting to deception. Interestingly, entertainment-based streamers with weaker sales abilities may promote high-quality products, while knowledge-based streamers may opt for lower-quality options. (c) When product quality is endogenous, streamers with lower sales abilities should focus on entertainment-based content to attract attention. As their sales abilities improve and fan-shoppers’ trust grows, they should transition to knowledge-based content.},
  archive      = {J_EJOR},
  author       = {Shengyan Cheng and Qiang Guo and Chris K Anderson},
  doi          = {10.1016/j.ejor.2025.05.057},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {971-985},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When and should streamers choose high-quality products? effects of streamer types},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting two-dimensional projection-efficient units in data envelopment analysis under big data scenarios. <em>EJOR</em>, <em>327</em>(3), 957-970. (<a href='https://doi.org/10.1016/j.ejor.2025.05.053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data, traditional estimation methods may struggle to process large datasets efficiently. Ali (1993) laid the foundation for improving efficiency assessment using Data Envelopment Analysis (DEA). Building on this work, we demonstrate how to detect two-dimensional projection-efficient units. This is achieved by projecting the multidimensional DEA production frontier onto two-dimensional subspaces and utilizing slope analysis to identify key efficient units. These units are then linked to their full-dimensional counterparts to define projection-efficient units. We propose using these key efficient units as a preliminary step to speed up the identification of full-dimensional efficient units or to estimate the relative density of datasets. Simulations show that our method reduces computation time for the two fastest approaches by an average of 54.2 % across different datasets.},
  archive      = {J_EJOR},
  author       = {Shuqi Xu and Qingyuan Zhu and Zhiyang Shen and Michael Vardanyan and Yinghao Pan},
  doi          = {10.1016/j.ejor.2025.05.053},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {957-970},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Detecting two-dimensional projection-efficient units in data envelopment analysis under big data scenarios},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deck of cards method for hierarchical, robust and stochastic ordinal regression. <em>EJOR</em>, <em>327</em>(3), 937-956. (<a href='https://doi.org/10.1016/j.ejor.2025.05.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the recently introduced application of the Deck of Cards Method (DCM) to ordinal regression proposing two extensions related to two main research trends in Multiple Criteria Decision Aiding, namely scaling and ordinal regression generalizations. On the one hand, procedures, different from DCM (e.g. AHP, BWM, MACBETH) to collect and elaborate Decision Maker’s (DM’s) preference information are considered to define an overall evaluation of reference alternatives. On the other hand, Robust Ordinal Regression and Stochastic Multicriteria Acceptability Analysis are used to offer the DM more detailed and realistic decision-support outcomes. More specifically, we consider preference imprecision and indetermination through a set of admissible comprehensive evaluations of alternatives provided by the whole set of value functions compatible with DM’s preference information rather than relying on a single definitive evaluation based on one value function. In addition, we also consider alternatives evaluated on a set of criteria hierarchically structured. The methodology we propose allows the DM to provide precise or imprecise information at different levels of the hierarchy of criteria. Like scaling procedures, the compatible value function we consider can be of a different nature, such as weighted sum, linear or general monotone value function, or Choquet integral. Consequently, the approach we propose is versatile and well-equipped to be adapted to DM’s characteristics and requirements. The applicability of the proposed methodology is shown by a didactic example based on a large ongoing research project in which Italian regions are evaluated on criteria representing Circular Economy, Innovation-Driven Development and Smart Specialization Strategies.},
  archive      = {J_EJOR},
  author       = {Salvatore Corrente and Salvatore Greco and Silvano Zappalà},
  doi          = {10.1016/j.ejor.2025.05.025},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {937-956},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Deck of cards method for hierarchical, robust and stochastic ordinal regression},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum likelihood probability measures over sets: Existence, computation, and convergence. <em>EJOR</em>, <em>327</em>(3), 922-936. (<a href='https://doi.org/10.1016/j.ejor.2025.07.054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider maximum likelihood estimation of a distribution over a general measurable space where realizations of the uncertainty are not directly observable but instead are known to lie within observable sets. We show that maximum likelihood estimates concentrate on a collection of maximal intersections (CMI) and can be found by solving a convex optimization problem whose size is linear in the size of the CMI. We provide an enumerative algorithm to compute the estimates and show that there are estimates that assign positive weight only to T + 1 elements of the CMI ( T being the number of observed sets). Motivated by this, we provide a column generation algorithm to compute the estimates that avoids enumerating the CMI. Under the assumption that either the observed sets are mixed-integer representable, or that the range of the underlying distribution is finite and known, we provide formulations of the algorithms that can be solved with commercial solvers. We study convergence properties of the maximum likelihood estimate both in terms of traditional notions of converge, as well as in terms of Wasserstein distances. Our results show that convergence to the underlying distribution cannot be guaranteed in general, but we identify sufficient conditions for convergence. We also perform numerical experiments that show that the estimates can be computed within minutes, that column generation can significantly reduce computational times, and that there is convergence even in cases where no theoretical guarantees are known.},
  archive      = {J_EJOR},
  author       = {Juan S. Borrero and Denis Sauré},
  doi          = {10.1016/j.ejor.2025.07.054},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {922-936},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximum likelihood probability measures over sets: Existence, computation, and convergence},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Worst-case values of target semi-variances with applications to robust portfolio selection. <em>EJOR</em>, <em>327</em>(3), 905-921. (<a href='https://doi.org/10.1016/j.ejor.2025.07.057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected regret and target semi-variance are two of the most important risk measures for downside risk. When the distribution of a loss is uncertain, and only partial information of the loss is known, their worst-case values play important roles in robust risk management for finance, insurance, and many other fields. Jagannathan (1977) derived the worst-case expected regrets when only the mean and variance of a loss are known and the loss is arbitrary, symmetric, or non-negative. While Chen et al. (2011) obtained the worst-case target semi-variances under similar conditions but focusing on arbitrary losses. In this paper, we first complement the study of Chen et al. (2011) on the worst-case target semi-variances and derive the closed-form expressions for the worst-case target semi-variance when only the mean and variance of a loss are known and the loss is symmetric or non-negative. Then, we investigate worst-case target semi-variances over uncertainty sets that represent undesirable scenarios faced by an investor. Our methods for deriving these worst-case values are different from those used in Jagannathan (1977) and Chen et al. (2011). As applications of the results derived in this paper, we propose robust portfolio selection methods that minimize the worst-case target semi-variance of a portfolio loss over different uncertainty sets. To explore the insights of our robust portfolio selection methods, we conduct numerical experiments with real financial data and compare our portfolio selection methods with several portfolio selection models related to the models proposed in this paper.},
  archive      = {J_EJOR},
  author       = {Jun Cai and Zhanyi Jiao and Tiantian Mao},
  doi          = {10.1016/j.ejor.2025.07.057},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {905-921},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Worst-case values of target semi-variances with applications to robust portfolio selection},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint model for longitudinal and spatio-temporal survival data. <em>EJOR</em>, <em>327</em>(3), 892-904. (<a href='https://doi.org/10.1016/j.ejor.2025.07.060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In credit risk analysis, survival models with fixed and time-varying covariates are commonly used to predict a borrower’s time-to-event. When time-varying covariates are endogenous, jointly modeling their evolution with the event time — known as the joint model for longitudinal and time-to-event data — provides a principled approach. In addition to temporal dynamics, incorporating borrowers’ geographical information can enhance predictive accuracy by capturing spatial clustering and its variation over time. We propose the Spatio-Temporal Joint Model (STJM), a Bayesian hierarchical model that accounts for spatial and temporal effects and their interaction. The STJM captures the impact of unobserved heterogeneity across regions, affecting borrowers residing in the same area at a given time. To ensure scalability to large datasets, we implement the model using the Integrated Nested Laplace Approximation (INLA) framework. We apply the STJM to predict the time to full prepayment on a large dataset of 57,258 US mortgage borrowers with more than 2.5 million observations. Empirical results indicate that including spatial effects consistently improves the performance of the joint model. However, the gains are less definitive when we additionally include spatio-temporal interactions.},
  archive      = {J_EJOR},
  author       = {Victor Medina-Olivares and Finn Lindgren and Raffaella Calabrese and Jonathan Crook},
  doi          = {10.1016/j.ejor.2025.07.060},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {892-904},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint model for longitudinal and spatio-temporal survival data},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Staggered routing in autonomous mobility-on-demand systems. <em>EJOR</em>, <em>327</em>(3), 875-891. (<a href='https://doi.org/10.1016/j.ejor.2025.06.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In autonomous mobility-on-demand systems, effectively managing vehicle flows to mitigate induced congestion and ensure efficient operations is imperative for system performance and positive customer experience. Against this background, we study the potential of staggered routing, i.e., purposely delaying trip departures from a system perspective, in order to reduce congestion and ensure efficient operations while still meeting customer time windows. We formalize the underlying planning problem and show how to efficiently model it as a mixed integer linear program. Moreover, we present a matheuristic that allows us to efficiently solve large-scale real-world instances both in an offline full-information setting and its online rolling horizon counterpart. We conduct a numerical study for Manhattan, New York City, focusing on low- and highly-congested scenarios. Our results show that in low-congestion scenarios, staggering trip departures allows mitigating, on average, 98 % of the induced congestion in a full information setting. In a rolling horizon setting, our algorithm allows us to reduce 82 % of the induced congestion. In high-congestion scenarios, we observe an average reduction of 60 % as the full information bound and an average reduction of 30 % in our online setting. Surprisingly, we show that these reductions can be reached by shifting trip departures by a maximum of six minutes in both the low and high-congestion scenarios.},
  archive      = {J_EJOR},
  author       = {Antonio Coppola and Gerhard Hiermann and Dario Paccagnan and Maximilian Schiffer},
  doi          = {10.1016/j.ejor.2025.06.008},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {875-891},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Staggered routing in autonomous mobility-on-demand systems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The storage location assignment and picker routing problem: A generic branch-cut-and-price algorithm. <em>EJOR</em>, <em>327</em>(3), 857-874. (<a href='https://doi.org/10.1016/j.ejor.2025.05.041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Storage Location Assignment Problem (SLAP) and the Picker Routing Problem (PRP) have received significant attention in the literature due to their pivotal role in the performance of the Order Picking (OP) activity, the most resource-intensive process of warehousing logistics. The two problems are traditionally considered at different decision-making levels: tactical for the SLAP, and operational for the PRP. However, this paradigm has been challenged by the emergence of modern practices in e-commerce warehouses, where decisions are more dynamic. This shift makes the integrated problem, called the Storage Location Assignment and Picker Routing Problem (SLAPRP), pertinent to consider. Scholars have investigated several variants of the SLAPRP, including different warehouse layouts and routing policies. Nevertheless, the available computational results suggest that each variant requires an ad-hoc formulation. Moreover, achieving a complete integration of the two problems, where the routing is solved optimally, remains out of reach for commercial solvers, even on trivial instances. In this paper, we propose an exact solution framework that addresses a broad class of variants of the SLAPRP, including all the previously existing ones. This paper proposes a Branch-Cut-and-Price framework based on a novel formulation with an exponential number of variables, which is strengthened with a novel family of non-robust valid inequalities. We have developed an ad-hoc branching scheme to break symmetries and maintain the size of the enumeration tree manageable. Computational experiments show that our framework can effectively solve medium-sized instances of several SLAPRP variants and outperforms the state-of-the-art methods from the literature.},
  archive      = {J_EJOR},
  author       = {Thibault Prunet and Nabil Absi and Diego Cattaruzza},
  doi          = {10.1016/j.ejor.2025.05.041},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {857-874},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The storage location assignment and picker routing problem: A generic branch-cut-and-price algorithm},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust parallel machine selection and scheduling with uncertain release times. <em>EJOR</em>, <em>327</em>(3), 838-856. (<a href='https://doi.org/10.1016/j.ejor.2025.05.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a parallel machine selection and scheduling (PMSS) problem with uncertain release times. To handle uncertain release times, we propose a two-stage robust PMSS model where the release time deviation (RTD) is characterized by a budget uncertainty set. In the first stage, machine selection and job assignment decisions are made to minimize startup costs before the uncertainties are revealed. In the second stage, once release times are known, job sequences are optimized to minimize the makespan on each machine. Robust constraints are introduced to ensure that the worst-case minimum makespan on each machine does not exceed a pre-specified due date. The proposed model is a tri-level min–max–min optimization problem with mixed-integer recourse decisions, which cannot be solved efficiently by existing algorithms. To this end, we propose a novel logic-based Benders decomposition (LBBD) algorithm with strengthened Benders cuts and speedup techniques. Specifically, we first provide an equivalent mixed-integer linear programming reformulation for the max–min subproblem by analyzing an optimality condition of the worst-case RTD. Second, we design novel combinatorial and analytical Benders cuts, which dominate cuts found in the literature, and we further strengthen them by lifting procedures. Third, we design a relaxation-and-correction procedure and a warm-start procedure to speed up the LBBD algorithm. Numerical experiments show the proposed robust model greatly reduces job tardiness compared with the deterministic model. The proposed cuts efficiently reduce the runtime, and the LBBD algorithm is at least three orders of magnitude faster than the state-of-the-art column-and-constraint-generation algorithm.},
  archive      = {J_EJOR},
  author       = {Linyuan Hu and Yuli Zhang and Muyang Wen and Roel Leus and Ningwei Zhang},
  doi          = {10.1016/j.ejor.2025.05.032},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {838-856},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust parallel machine selection and scheduling with uncertain release times},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast optimization approach for a complex real-life 3D multiple bin size bin packing problem. <em>EJOR</em>, <em>327</em>(3), 820-837. (<a href='https://doi.org/10.1016/j.ejor.2025.05.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a real-life air cargo loading problem which is a variant of the three-dimensional Variable Size Bin Packing Problem with special bin forms of cuboid and non-cuboid unit load devices (ULDs). Packing is constrained by additional practical restrictions, such as load stability, (non-)stackable items, and weight distribution constraints. To solve the problem, we present an insertion heuristic embedded into a Randomized Greedy Search. The solution space is limited by only considering certain candidate points (so-called extreme points), which are promising positions to load an item. We extend the concept of extreme points proposed in the literature and allow moving extreme points for non-cuboid ULDs. A special sorting of the items, which combines a layered structure and free packing, is suggested. Moreover, we propose dividing the space of each ULD into smaller cells to accelerate the collision, non-floating, and stackability check while loading items. In a computational study, we analyze individual algorithm components and show the effectiveness of our method on adapted real-life instances from the literature.},
  archive      = {J_EJOR},
  author       = {Katrin Heßler and Timo Hintsch and Lukas Wienkamp},
  doi          = {10.1016/j.ejor.2025.05.016},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {820-837},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fast optimization approach for a complex real-life 3D multiple bin size bin packing problem},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning assisted differential evolution for the dynamic resource constrained multi-project scheduling problem with static project schedules. <em>EJOR</em>, <em>327</em>(3), 808-819. (<a href='https://doi.org/10.1016/j.ejor.2025.05.059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large modular construction projects, such as shipbuilding, multiple similar projects arrive stochastically. At project arrival, a schedule has to be created, in which future modifications are difficult and/or undesirable. Since all projects use the same set of shared resources, current scheduling decisions influence future scheduling possibilities. To model this problem, we introduce the Dynamic Resource Constrained Multi-project Scheduling Problem with Static project Schedules. To find schedules, both a greedy approach and simulation-based approach with varying scenarios are introduced. Although the simulation-based approach schedules projects proactively, the computing times are long, even for small instances. Therefore, a method is introduced that learns from schedules obtained in the simulation-based method and uses a neural network to estimate the objective function value. It is shown that this method achieves a significant improvement in objective function value over the greedy algorithm, while only requiring a fraction of the computation time of the simulation-based method.},
  archive      = {J_EJOR},
  author       = {T. van der Beek and J.T. van Essen and J. Pruyn and K. Aardal},
  doi          = {10.1016/j.ejor.2025.05.059},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {808-819},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Machine learning assisted differential evolution for the dynamic resource constrained multi-project scheduling problem with static project schedules},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible mathematical model for home health care problems. <em>EJOR</em>, <em>327</em>(3), 791-807. (<a href='https://doi.org/10.1016/j.ejor.2025.05.055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the health and social care sectors it is common for some specialized teams to travel to patients homes to provide care. These teams are typically made up of by a number of staff members with varying skills, starting locations and working hours. Patients require different types of care, during specific time windows, and may have special requirements, such as needing two staff members, or multiple visits with some sort of temporal dependency between them. Since teams need to decide which staff member will visit each patient, as well as the routes they will take to do so, this kind of planning problem is known in the literature as the Home Health Care Routing and Scheduling Problem (HHCRSP). We introduce a new mixed integer linear programming formulation for the HHCRSP that extends previous models. Our formulation can readily be adapted to address more specific variants in the scientific literature, proving a larger number of optimal solutions and stronger lower bounds on benchmark instances using the same computational framework. We further propose an instance generator for producing scenarios that closely resemble those of the National Health Service in the United Kingdom.},
  archive      = {J_EJOR},
  author       = {Miguel Reula and Consuelo Parreño-Torres and Carlos Lamas-Fernandez and Antonio Martinez-Sykora},
  doi          = {10.1016/j.ejor.2025.05.055},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {791-807},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A flexible mathematical model for home health care problems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The dial-a-ride problem with limited pickups per trip. <em>EJOR</em>, <em>327</em>(3), 776-790. (<a href='https://doi.org/10.1016/j.ejor.2025.05.051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dial-a-Ride Problem (DARP) is an optimization problem that involves determining optimal routes and schedules for several vehicles to pick up and deliver items at minimum cost. Motivated by real-world carpooling and crowdshipping scenarios, we introduce an additional constraint imposing a maximum number on the number of pickups per trip. This results in the Dial-a-Ride Problem with Limited Pickups per Trip (DARP-LPT). We apply a fragment-based method for DARP-LPT, where a fragment is a partial path. Specifically, we extend two formulations from Rist and Forbes (2021): the Fragment Flow Formulation (FFF) and the Pickup-Space Fragment Formulation (PSFF). Furthermore, our results show that PSFF outperforms FFF, which in turn surpasses traditional arc-based formulations in both solution quality and computational efficiency. Additionally, we compare several existing fragment sets that differ in the length of their partial paths and find that the sets with shorter partial paths yield the best solution times when used with PSFF. In addition, we propose a new mixed fragment set, which is useful when the sets with longer partial paths become too large. In such cases, it yields the lowest CPU time.},
  archive      = {J_EJOR},
  author       = {Boshuai Zhao and Kai Wang and Wenchao Wei and Roel Leus},
  doi          = {10.1016/j.ejor.2025.05.051},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {776-790},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The dial-a-ride problem with limited pickups per trip},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new class of lower bounds for scheduling a batch processing machine to minimize makespan. <em>EJOR</em>, <em>327</em>(3), 754-775. (<a href='https://doi.org/10.1016/j.ejor.2025.05.047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of minimizing makespan on a batch-processing machine with limited capacity. Each job has a size and processing time, and multiple jobs can be processed simultaneously in a batch, provided the machine’s capacity is not exceeded. The batch processing time is determined by the longest processing time in batch. We show that the existing lower bound method has a worst-case performance ratio of 1/2, and propose a class of lower bound procedures ( LB m ) and its improved variant ( ILB m ). The new procedures take integer m , used to partition jobs depending on whether their sizes are greater than B / m or not, and provide tighter bounds as m increases. We prove that the worst-case performance ratio of LB m and ILB m is no worse than 4/7. Additionally, we show that they can be computed efficiently for m ≤3. Based on the structure of the proposed lower bound procedures, we introduce different valid inequalities ( VI ) and embed them into an existing MILP model to achieve a formulation with a tighter LP bound. To gain understanding on the quality of the bounds, we employ them in a branch and bound ( B & B ) algorithm. Results indicate that the B&B with new lower bound methods increases the number of optimally solved problem instances by 44% and 35% compared to the existing B&B and branch and price algorithms, respectively. Furthermore, the lower bound-driven VI s help increase the number of solved problems by more than 30%, achieving an optimality rate exceeding 96% across a wide range of problem instances.},
  archive      = {J_EJOR},
  author       = {Ali Husseinzadeh Kashan and Onur Ozturk},
  doi          = {10.1016/j.ejor.2025.05.047},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {754-775},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new class of lower bounds for scheduling a batch processing machine to minimize makespan},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EATKG: An open-source efficient exact algorithm for the two-dimensional knapsack problem with guillotine constraints. <em>EJOR</em>, <em>327</em>(3), 735-753. (<a href='https://doi.org/10.1016/j.ejor.2025.05.033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the Two-Dimensional Knapsack Problem with Guillotine Constraints, which is a famous NP -hard problem and is commonly encountered in industries where rectangular raw materials are cut into smaller pieces using guillotine cuts. We propose an efficient exact algorithm (EATKG) to solve this problem, which incorporates advanced techniques and novel elements, including an adapted preprocessing procedure, two enhanced upper bounds, an improved bidirectional tree search approach, and an iterative combination enumeration process. These components effectively balance the computation of upper and lower bounds and handle the issue of memory overflow. We extensively evaluate EATKG on eight classic benchmark sets, comprising 1,277 instances. Our algorithm solves 87% of the instances with an average computing time of 7 seconds, and 93% with an average computing time of 49 seconds. Moreover, EATKG efficiently solves nearly all small- and medium-sized instances, providing better solutions for 46 instances and tighter upper bounds for 109 instances. These results demonstrate the superior performance of our algorithm compared to leading algorithms. To support future research, we have made the source code for the proposed algorithm, along with the corresponding instance data, aggregated results, and detailed solutions, publicly available. This will facilitate further investigations and comparisons of solution methods.},
  archive      = {J_EJOR},
  author       = {Sunkanghong Wang and Roberto Baldacci and Qiang Liu and Lijun Wei},
  doi          = {10.1016/j.ejor.2025.05.033},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {735-753},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {EATKG: An open-source efficient exact algorithm for the two-dimensional knapsack problem with guillotine constraints},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Greedy randomized adaptive search procedures with path relinking. an analytical review of designs and implementations. <em>EJOR</em>, <em>327</em>(3), 717-734. (<a href='https://doi.org/10.1016/j.ejor.2025.02.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a comprehensive review of the Greedy Randomized Adaptive Search Procedure (GRASP) metaheuristic and its hybridization with Path Relinking (PR). GRASP with PR has become a widely adopted approach for solving hard optimization problems since its proposal in 1999. The paper covers the historical development of GRASP with PR and its theoretical foundations, as well as recent advances in its implementation and application. The review includes a careful analysis of PR variants, paying special attention to memory-based and randomized designs, with a total of ten different implementations. It identifies the design questions that are still open in the scientific literature. The experimental section applies advanced PR implementations on two well-known combinatorial optimization problems, linear ordering and max-cut, in an effort to answer these open questions. The paper also explores the hybridization of PR and other metaheuristics, such as tabu search, scatter search, and random-keys genetic algorithms. Overall, this review provides valuable insights for researchers and practitioners seeking to implement GRASP with PR for solving optimization problems.},
  archive      = {J_EJOR},
  author       = {Manuel Laguna and Rafael Martí and Anna Martínez-Gavara and Sergio Pérez-Peló and Mauricio G.C. Resende},
  doi          = {10.1016/j.ejor.2025.02.022},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {717-734},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Greedy randomized adaptive search procedures with path relinking. an analytical review of designs and implementations},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="eswa">ESWA - 158</h2>
<ul>
<li><details>
<summary>
(2026). Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system. <em>ESWA</em>, <em>298</em>, 129779. (<a href='https://doi.org/10.1016/j.eswa.2025.129779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology foresight analyses technological trends and potential impacts to provide strategic guidance. However, existing methods either rely on experts to discover emerging directions leading to subjective bias or adopt machine learning to predict without explanation. We propose a Machine Learning and Weak Signal-based Technology Forecasting System (MLWS-TF), which is entirely data-driven to enhance the objectivity of technology foresight and can interpret emerging directions through weak signals. The system adopts a two-phase machine learning model (2P-ML), the first phase identifies papers related to the robotics field, while the second further classifies them into fine-grained research directions. Keywords are extracted from the papers using a Word2Vec-based approach, and a three-dimensional signal classification method (DVI) is developed to quantify the foresight value of keywords across the Diffusion, Visibility, and Impact dimensions, identifying weak signals for technology forecasting. Experiments evaluate various machine learning algorithms, and XGBoost outperforms in constructing the 2P-ML classifier. The model achieved over 90% accuracy, demonstrating its effectiveness in identifying the theme of scientific documents based on textual features. For each research theme, the DVI provides a more comprehensive assessment of signal strength to detect weak signals. Finally, MLWS-TF analyses the growth potential of themes and successfully identifies critical development directions. Our approach offers a novel automated technology foresight system, which completely avoids the subjectivity and dependence on expert judgment that characterize traditional technology foresight approaches, and extends weak signal theory by introducing the Impact dimension to evaluate signal strength.},
  archive      = {J_ESWA},
  author       = {Ruihan Wang and Yuhao Zhu},
  doi          = {10.1016/j.eswa.2025.129779},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129779},
  shortjournal = {Expert Syst. Appl.},
  title        = {Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. <em>ESWA</em>, <em>298</em>, 129766. (<a href='https://doi.org/10.1016/j.eswa.2025.129766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding in encrypted images (RDHEI) is a promising technique for multimedia cloud computing that enables the embedding of secret data into encrypted images while preserving confidentiality. However, the existing RDHEI algorithms fail to meet the high-security requirements of distributed storage systems in the cloud. Although, secret sharing based RDHEI (SS-RDHEI) may solve this problem, the current methods have weakness such as insufficient embedding capacity and unsatisfactory balance between image security and redundancy. To enhance the algorithm’s ability to carry information, this paper proposes a SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. Firstly, pixel-difference preservation based modulation (PDPM) ensures secure encryption by modifying all pixels except for a reference block, minimizing damage; moreover, an improved block-level pixel predictor enhances carrier redundancy. Secondly, auxiliary data free coding (ADFC) marks prediction errors directly in the binary sequence of the original pixel without auxiliary information while maintaining accuracy, and reduces the impact of different textures on embedding performance byselecting optimal parameters for each share image. Finally, by combining PDPM with secret sharing, it achieves independent embedding for multiple data hiders while ensuring fair information embedding. Experimental results demonstrate that the proposed algorithm outperforms existing state-of-the-art schemes in terms of information-carrying capability.},
  archive      = {J_ESWA},
  author       = {Zhihua Gan and Zongwei Tang and Yalin Song and Gongyao Cao and Xiuli Chai and Yushu Zhang},
  doi          = {10.1016/j.eswa.2025.129766},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129766},
  shortjournal = {Expert Syst. Appl.},
  title        = {SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards. <em>ESWA</em>, <em>298</em>, 129762. (<a href='https://doi.org/10.1016/j.eswa.2025.129762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation of quadrotors is a fundamental prerequisite for numerous applications. This work proposes a novel deep reinforcement learning (DRL) framework that explicitly addresses quadrotor attitude dynamics during autonomous navigation, a critical yet underexplored challenge in existing learning-based UAV navigation studies. In the proposed method, high-level velocity commands will be generated by a deep neural network policy and translated by a low-level control algorithm to achieve precise control of both positions and rotations of quadrotors. A specialized network structure is designed to effectively extract environmental obstacle features and quadrotor sequence features to improve navigation performance. In addition, a novel tangent path reward (TPR) calculation method is developed to adequately utilize the known contours and positions of obstacles during the training phase. Experimental results demonstrate that the proposed method enables quadrotors to autonomously navigate complex virtual obstacle environments with superior efficiency compared with other algorithms. Furthermore, the feasibility and adaptability of the proposed method are validated through simulations by varying obstacle density and map size, as well as replicating real-world obstacle distributions.},
  archive      = {J_ESWA},
  author       = {Qizhang Luo and Yuqi Li and Jiaheng Zeng and Guohua Wu and Yalin Wang},
  doi          = {10.1016/j.eswa.2025.129762},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129762},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china. <em>ESWA</em>, <em>298</em>, 129740. (<a href='https://doi.org/10.1016/j.eswa.2025.129740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsurface lithological distribution is essential for extrapolating geological information from core to block or basin scales. Given the limited availability of core data, there is a critical need to develop a reliable method for establishing robust correlations between logging curves and lithologies in cores, thereby maximizing the value of large historical logging data. Here, we propose a novel attention-based convolutional neural network (ATT-CNN), which employs a 1D-CNN to transform six types of logging curves into high-dimensional feature space at each depth, and applies an attention mechanism to the 1D-CNN outputs along both the depth and feature dimensions. The architecture is designed to mimic human perceptual processing for lithology identification, leveraging curve combination, thresholding, and local pattern recognition within this enriched and high-dimensional feature representation. In addtion, the study employs wavelet-based preprocessing on logging curves to eliminate the impact of compaction-induced data drift on model generalization—an issue rarely considered in prior studies. The result showes that: ① The proposed ATT-CNN model demonstrates superior performance over benchmark models—the bidirectional gated recurrent unit (BiGRU) and an ensemble of machine learning models (En-ML)—across all evaluation metrics; ②Wavelet-based preprocessing enhances the generalization capability of both ATT-CNN and BiGRU, yielding higher metric scores and improved predictions, particularly in shallow-depth intervals; ③ For blind wells, the ATT-CNN outperforms BiGRU and En-ML in both accuracy and its ability to capture lithological variations even from low-amplitude curve deviations. The integration of ATT-CNN with wavelet-based preprocessing demonstrates significant potential for accurately characterizing subsurface lithological distribution, then provides critical support for key petroleum geology workflows, including provenance analysis, sedimentary facies mapping, and reservoir property prediction.},
  archive      = {J_ESWA},
  author       = {Jianguo Yin and Shuai Zhang and Zhixiong Wu and Shouji Pang and Rui Wang},
  doi          = {10.1016/j.eswa.2025.129740},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129740},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models. <em>ESWA</em>, <em>298</em>, 129739. (<a href='https://doi.org/10.1016/j.eswa.2025.129739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a clustering-based framework for the analysis of functional magnetic resonance imaging (fMRI) data, with a particular focus on brain segmentation into functional sub-regions. The proposed approach comprises two key modules: representation learning and brain functional segmentation. To extract meaningful latent representations from high-dimensional fMRI signals while preserving temporal dependencies, we introduce the Spherical Variational Recurrent Autoencoder (SVRAE), a deep generative model built upon the Variational Autoencoder (VAE) architecture. Unlike conventional VAEs that assume a Gaussian prior, SVRAE employs the von Mises-Fisher (vMF) distribution to model latent variables on a unit hypersphere, which is more suitable for L 2 -normalized data. To further enhance temporal modeling, we replace standard fully connected layers with Long Short-Term Memory (LSTM) networks. For the segmentation module, we adopt a Collapsed Nonparametric von Mises-Fisher Mixture Model (Co-vMFMM), formulated within a Bayesian nonparametric framework. This model automatically adapts its complexity to the input data without requiring a predefined number of clusters. An efficient variational Bayes learning algorithm is developed to perform inference in a collapsed parameter space. Extensive experiments on publicly available fMRI datasets demonstrate the effectiveness and robustness of the proposed method in delineating functionally coherent brain sub-regions.},
  archive      = {J_ESWA},
  author       = {Wentao Fan and Wenchuan Zhang and Xiao Dong and Nizar Bouguila},
  doi          = {10.1016/j.eswa.2025.129739},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129739},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer. <em>ESWA</em>, <em>298</em>, 129734. (<a href='https://doi.org/10.1016/j.eswa.2025.129734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver cancer is a complex and life-threatening disease with significant diagnostic and therapeutic challenges. Automated liver cancer detection assists radiologists in identifying tumors and their severity accurately. In recent years, several deep-learning techniques have been implemented for diagnosing liver tumors and classification. Despite advancements in deep learning for medical imaging, existing liver cancer detection approaches continue to face several critical limitations. These include suboptimal diagnostic accuracy due to inadequate feature extraction, excessive computational demands that hinder real-time deployment, significant class imbalance within medical datasets leading to biased predictions, and overfitting caused by limited annotated training data. To address these challenges, this study introduces a novel and automated deep learning framework called CustomLiverNet, specifically designed for accurate and efficient liver cancer diagnosis using Computed Tomography images. The Generative Adversarial Network is introduced for generating realistic synthetic images, effectively improving the performance of the proposed technique and reducing class imbalance problems. The proposed technique integrates the strengths of Residual Networks and Vision Transformer to extract significant information from the input images and further enhance the performance of the proposed framework. The Residual Networks capture both low-level and high-level semantic features, whereas the Vision Transformer derives global and contextual feature representations from the input images. The model designs a customized fusion layer for combining the extracted features from both Residual Networks and Vision Transformer models. The classification layer predicts whether the liver tumor is benign or malignant. Further, Gradient-Weighted Class Activation Mapping is applied to highlight the critical regions of the image to enhance model transparency. The CustomLiverNet framework was trained and validated on two publicly available liver cancer datasets, including the liver tumor segmentation dataset, which contains 131 contrast-enhanced abdominal Computed Tomography scans, and the 3D image reconstruction for comparison of algorithm database, which includes 20 computed tomography scans. Experimental evaluation using standard metrics shows that CustomLiverNet achieved an accuracy of 98.79 %, precision of 98.64 %, recall of 98.58 %, and specificity of 98.35 %. These results demonstrate that the proposed model holds strong potential for enhancing early and accurate liver cancer diagnosis compared to previous studies.},
  archive      = {J_ESWA},
  author       = {Shivani Joshi and Avinash Dwivedi and Rajiv Kumar and Ashish Kumar and Raju Kumar and Amrita},
  doi          = {10.1016/j.eswa.2025.129734},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129734},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach. <em>ESWA</em>, <em>298</em>, 129724. (<a href='https://doi.org/10.1016/j.eswa.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing complexity and scale of technological knowledge ecosystems, organizations face challenges in identifying intra- and inter-organizational collaboration opportunities. In this respect, prior studies have proposed patent-based approaches, but they are subject to several limitations: (1) insufficient consideration of technological relationships within the ecosystem, (2) simplified unit of analysis, and (3) limited organization-centric assessments. This study proposes a network embedding and text-reranking approach to explore potential intra- and inter-organizational collaboration opportunities. First, the technological knowledge ecosystem is represented as a heterogeneous patent network comprising patents, inventors, assignees, and technology classification codes. Second, inventor nodes are embedded using metapath2vec, which performs random walks along predefined metapaths to capture diverse knowledge flows within the ecosystem. Third, potential collaborators are explored through (1) screening candidates based on technological reachability, which measures the possibility of knowledge exploration based on contextual similarity within the network, and (2) reranking candidates based on technological relevance, which quantifies the possibility of knowledge exploitation based on the similarity of technological know-how and experiences. Finally, ten quantitative patent indicators are developed to assess the implications of these opportunities at both the inventor and organization levels. The validity of the proposed approach is demonstrated through a case study involving 28,888 US patents and 9,196 inventors in the field of energy storage technology. This study contributes to advancing the theoretical understanding of technological knowledge ecosystems while also serving as a supplementary tool to explore organizational collaboration opportunities.},
  archive      = {J_ESWA},
  author       = {Jaemin Chung and Jaewoong Choi and Janghyeok Yoon},
  doi          = {10.1016/j.eswa.2025.129724},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129724},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning. <em>ESWA</em>, <em>298</em>, 129717. (<a href='https://doi.org/10.1016/j.eswa.2025.129717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dendritic or cellular morphologies of alloys and metals formed during casting processes significantly influence key properties such as mechanical strength, toughness, hardness, and electrical or thermal conductivities. The literature presents correlations between these properties and the microstructural length scale, which requires accurate characterization at the micrometer level. However, traditional evaluation methods demand extensive experimental efforts, including careful metallographic preparation, high-quality imaging, and a large number of measurements for statistical reliability - often relying on analyst proficiency. This study proposes a machine learning-based workflow tailored for the automated processing of microstructure images. The approach enables the autonomous measurement of key microstructural features while minimizing bias and inconsistencies among analysts. By integrating advanced image processing techniques with object detection algorithms based on Convolutional Neural Networks (CNNs), the method autonomously identifies microstructural morphologies and quantifies their spacing scales. Three model types-Cell, Dendrite, and Hybrid (exhibiting both dendritic and cellular features)-were trained and validated on using a dataset of 200 images. Among them, the Cell detection model achieved the highest performance, with a mean Average Precision (mAP) of 78.77 %, followed by the Hybrid (75.63 %) and Dendrite (72.87 %) models. Finally, the automated measurements models were applied to literature images and compared to reported microstructural growth correlations.},
  archive      = {J_ESWA},
  author       = {Guilherme Marim da Silva and Rafael Kakitani and Carlos Henrique da Silva Santos and Amauri Garcia and Noé Cheung},
  doi          = {10.1016/j.eswa.2025.129717},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129717},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time. <em>ESWA</em>, <em>298</em>, 129716. (<a href='https://doi.org/10.1016/j.eswa.2025.129716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of manufacturing systems, reentrancy has become prevalent in many production environments. This study investigates a bi-objective distributed reentrant flow shop scheduling problem with sequence-dependent setup times (DRFSP-SDST). The objectives are to minimize the total energy consumption (TEC) and the maximum completion time (makespan), simultaneously. First, a bi-objective mathematical model for the DRFSP-SDST is formulated based on practical reentrant production scenarios. Second, the artificial bee colony (ABC) algorithm and its variants are employed to solve the DRFSP-SDST. According to the characteristics of the DRFSP-SDST, six local search operators are specifically designed to enhance the performance of the proposed algorithms. For promoting greener and more energy-efficient production, two speed-scaling strategies are developed. Third, two reinforcement learning (RL) algorithms, Q-learning and State-Action-Reward-State-Action (SARSA), are integrated into the iterative process as online learning strategies to guide the selection of high-quality local search strategies during the iterations of the proposed algorithms. For each RL algorithm, two distinct selection strategies for local search operators are designed. Finally, the effectiveness of the proposed enhancement strategies is evaluated through comprehensive numerical experiments on 36 benchmark instances. The performance of the proposed algorithms is further validated via the Friedman test. The experimental results and analysis demonstrate that the ABC algorithm enhanced by SARSA-based local search exhibits superior competitiveness in solving the DRFSP-SDST.},
  archive      = {J_ESWA},
  author       = {Ao Yao and Kaizhou Gao and Ponnuthurai Nagaratnam Suganthan and Hongyan Sang},
  doi          = {10.1016/j.eswa.2025.129716},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129716},
  shortjournal = {Expert Syst. Appl.},
  title        = {Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Defects inspection system for building facades using drones and deep learning method. <em>ESWA</em>, <em>298</em>, 129715. (<a href='https://doi.org/10.1016/j.eswa.2025.129715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular inspection and maintenance of building facades are essential for preserving structural integrity and aesthetic quality, especially in aging urban high-rises. While drone-based visual inspection powered by artificial intelligence (AI) offers benefits in speed, safety, and scalability, existing methods are typically limited to single defect types or uniform facade categories due to the challenges of detecting multi-scale defects in complex, heterogeneous environments. This study introduces an automated multiclass defects inspection system for building facades by integrating drone technology, an AI-driven segmentation platform, and automatic report generation. Central to the system is a segmentation AI model capable of detecting multiclass defects with orders-of-magnitude differences in scale across diverse facade backgrounds. To handle the pixel imbalance of defects ranging from fine cracks to large spalling and glass breakage, the model is built upon EfficientUNet++, trained on a carefully curated dataset and optimized using adjustable batch sizes and active learning rates to improve multi-scale feature learning and mitigate overfitting. Evaluations on validation and out-of-sample datasets demonstrate that the proposed model achieves superior performance across all defect classes. Real-world drone experiments further confirm the model’s practical applicability, with high recall rates in detecting spalling, water seepage, cracks, and glass breakage across different types of facades. This work pioneers a robust, scalable, and efficient AI-based framework for automated multiclass facade defect inspection, providing actionable information for engineers and supporting urban infrastructure maintenance.},
  archive      = {J_ESWA},
  author       = {Xiaoling Zhou and Robert Lee Kong Tiong},
  doi          = {10.1016/j.eswa.2025.129715},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129715},
  shortjournal = {Expert Syst. Appl.},
  title        = {Defects inspection system for building facades using drones and deep learning method},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects. <em>ESWA</em>, <em>298</em>, 129713. (<a href='https://doi.org/10.1016/j.eswa.2025.129713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative characterization of apparent quality defects in infrastructure is a crucial component of operations and maintenance. It enables rapid assessment of defect severity and supports the timely formulation of preventive strategies. However, a singular visual modality struggles to simultaneously ensure the dual tasks of defect detection and measurement accuracy. To solve these problems, this paper proposes a novel framework for cross-modal multitask learning networks, which comprehensively integrates the advantages of image detection and point cloud measurement. The pixel points identified in the image are mapped to their corresponding three-dimensional coordinates in the point cloud through intensive feature matching. A measurement strategy for the inherent characteristics of the defect is subsequently proposed. Based on prior knowledge of the defect, the area and volume of defects are quantified accurately. Finally, extensive experiments on detection, matching and measurement demonstrate the efficacy of the proposed method. The results provide a valuable reference for the quantitative characterization of infrastructure defects.},
  archive      = {J_ESWA},
  author       = {Yu Wang and Yingchao Dai and Xiaodong Gan and Zhengtao Yang and Zhou Wu},
  doi          = {10.1016/j.eswa.2025.129713},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129713},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language proficiency assessment of autistic children using large language models. <em>ESWA</em>, <em>298</em>, 129712. (<a href='https://doi.org/10.1016/j.eswa.2025.129712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language impairment is a common comorbidity in children with autism spectrum disorder (ASD), and language proficiency assessment is a primary method for identifying such impairments. However, traditional assessment tools are often subjective and inefficient, while existing computer-assisted methods are limited by a narrow focus and insufficient use of natural language samples. To address these issues, this study proposes a framework for assessing children’s language abilities based on large language models (LLMs). We first preprocess the natural language samples from children and design multiple assessment dimensions and workflows. To enhance the stability of the assessment, we introduce a multi-expert voting mechanism and perform a comparative analysis of various large language models’ performance. The experimental results demonstrate a strong correlation between the framework’s assessment results and the Mullen Scales of Early Learning (MSEL) verbal developmental quotients, with a Pearson correlation coefficient of 0.8 ( p < 0.001). Furthermore, the results show that the multi-dimensional evaluation can accurately differentiate between ASD and typically developing (TD) children, achieving a classification accuracy of 0.98. These findings suggest that the proposed framework has significant potential for improving the accuracy of ASD identification.},
  archive      = {J_ESWA},
  author       = {Saige Qin and Min Liu and Tongquan Wei and Qiaoyun Liu},
  doi          = {10.1016/j.eswa.2025.129712},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129712},
  shortjournal = {Expert Syst. Appl.},
  title        = {Language proficiency assessment of autistic children using large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EQUINAS: Equilibrium-guided differentiable neural architecture search. <em>ESWA</em>, <em>298</em>, 129711. (<a href='https://doi.org/10.1016/j.eswa.2025.129711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has significantly mitigated the performance collapse issue in Differentiable Architecture Search (DARTS) by either refining architecture parameters to better reflect the true strengths of operations or developing alternative metrics for evaluating operation significance. However, the actual role and impact of architecture parameters remain insufficiently explored, creating critical ambiguities in the search process. To address this gap, we conduct a rigorous theoretical analysis demonstrating that the change rate of architecture parameters reflects the sensitivity of the supernet’s validation loss in architecture space, thereby influencing the derived architecture’s performance by shaping supernet training dynamics. Building on these insights, we introduce the concept of a Stable Equilibrium State to capture the stability of the bi-level optimization process and propose the Equilibrium Influential ( E I ) metric to assess operation importance. By integrating these elements, we propose EQUINAS, a differentiable NAS approach that leverages the Stable Equilibrium State to identify the optimal state during the search process and derives the final architecture using the E I metric. Extensive experiments across diverse datasets and search spaces demonstrate that EQUINAS achieves competitive test accuracy compared to state-of-the-art methods while significantly reducing search costs. Additionally, EQUINAS shows remarkable performance in Transformer-based architectures and excels in real-world applications such as image classification and text recognition.},
  archive      = {J_ESWA},
  author       = {Weisheng Xie and Xiangxiang Gao and Xuwei Fang and Hui Li and Chen Hang and Shaoyuan Li},
  doi          = {10.1016/j.eswa.2025.129711},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129711},
  shortjournal = {Expert Syst. Appl.},
  title        = {EQUINAS: Equilibrium-guided differentiable neural architecture search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Companion learning networks: A deep reinforcement learning algorithm with partner networks. <em>ESWA</em>, <em>298</em>, 129709. (<a href='https://doi.org/10.1016/j.eswa.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep reinforcement learning (DRL) agents suffer from severe reward instability during late-stage exploration, particularly when encountering novel states in complex continuous environments. A variety of existing studies focus on improving an agent’s reward exploration. However, they ignore the instability problem that arises when the agent faces new states in the later stages of exploration. This paper proposes a novel companion learning network (CLN) based on the idea that the guidance can accelerate human learning efficiency and reduce the risk of making mistakes. The CLN integrates a short-term partner network to intensively learn localized environmental patterns, offering adaptive action guidance for recent states. Simultaneously, a global Q-network dynamically incorporates the partner’s decaying guidance signals, balancing autonomous exploration with error mitigation. As training progresses, the partner’s influence gradually diminishes, allowing the Q-network to solidify robust policies without persistent dependence. Extensive experiments on four OpenAI Gym environments demonstrate that the CLN can significantly improve the exploration stability in most tested scenarios, achieving up to 49% reduction in late-stage reward standard deviation compared to baseline DRL methods.},
  archive      = {J_ESWA},
  author       = {Jin Xu and Jinfeng Bu and Yu Zhang and Jia-Dong Zhang and Chi-Yin Chow},
  doi          = {10.1016/j.eswa.2025.129709},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129709},
  shortjournal = {Expert Syst. Appl.},
  title        = {Companion learning networks: A deep reinforcement learning algorithm with partner networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation. <em>ESWA</em>, <em>298</em>, 129707. (<a href='https://doi.org/10.1016/j.eswa.2025.129707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User reviews reflect user preferences and item characteristics, optimizing the predictive accuracy and explanation generation of personalized recommendation systems. However, existing models face challenges due to subjective uncertainty in user feedback and a lack of transparency. Reviews often contain ambiguous emotional expressions, with the same product receiving positive, neutral, and negative sentiments. Many recommendation models assume alignment between ratings and review sentiments, but in practice, users may give high ratings while expressing dissatisfaction or vice versa. These inconsistencies complicate accurate modeling of user preferences. To address these issues, a Large Language Model (LLM)-driven sentiment-enhanced heterogeneous graph neural network framework is proposed. This framework jointly models interaction data and fuzzy sentiment information from reviews to improve both recommendation accuracy and explainability. By leveraging LLM with dual-prompt strategies, high-quality sentiment distributions and semantic insights are extracted. Review sentiments are then quantified using intuitionistic fuzzy numbers to address data sparsity and uncertainty, capturing implicit relationships between users, items, and entities in a sentiment-enhanced heterogeneous relational graph. A fuzzy sentiment-weighted graph convolutional network (FSGCN) is introduced for dynamic higher-order feature learning, adjusting sentiment weights based on user-item interactions and emotional context. The framework also integrates LLM-driven query interpretation to generate recommendations with transparent, context-aware rationales. This approach enables users to understand the reasoning behind recommendations, significantly enhancing explainability and trust.},
  archive      = {J_ESWA},
  author       = {Zhinan Li and Zhenyu Liu and Guodong Sa and Mingjie Hou and Jiacheng Sun and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129707},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129707},
  shortjournal = {Expert Syst. Appl.},
  title        = {Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Geodesic-based path planning for port transfer robots on riemannian manifolds. <em>ESWA</em>, <em>298</em>, 129706. (<a href='https://doi.org/10.1016/j.eswa.2025.129706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid intelligent transformation of the automotive industry and the surge in production volume, intelligent autonomous robots equipped with integrated perception and planning systems are playing an increasingly vital role in vehicle transfer operations. Optimizing dispatch paths of robots is essential for improving overall operational efficiency, yet achieving a balance among path length, feasibility, and safety margin remains a significant challenge. To address this issue, we propose a geodesic-based path planning method formulated on Riemannian manifolds. The approach jointly considers directional motion constraints, steering effort, and obstacle accessibility boundaries to construct a Riemannian metric tensor that encodes local path cost structures. This transforms the planning task into a geodesic shortest path problem, which is efficiently solved using the Geometric heat flow (GHF) method. The resulting paths naturally comply with kinematic constraints and exhibit strong obstacle-avoidance capabilities, significantly enhancing safety and executability. Extensive simulations and real-world experiments in high-density port yard environments demonstrate the practicality and robustness of the proposed method under complex spatial constraints and obstacle configurations.},
  archive      = {J_ESWA},
  author       = {Runjiao Bao and Junzheng Wang and Shoukun Wang},
  doi          = {10.1016/j.eswa.2025.129706},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129706},
  shortjournal = {Expert Syst. Appl.},
  title        = {Geodesic-based path planning for port transfer robots on riemannian manifolds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation. <em>ESWA</em>, <em>298</em>, 129705. (<a href='https://doi.org/10.1016/j.eswa.2025.129705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by empirical decision-making (EDM) processes, we propose a novel modeling framework where agents iteratively integrate social neighbors’ opinions into their cognitive inertia sequences (CISs), gradually prioritizing their accumulated CISs over time. This framework simulates the transition from group decision-making (GDM) to EDM through dynamic trust/distrust propagation and aggregation mechanisms grounded in social balance theory–capturing relational scenarios such as “a friend of a friend is a friend”, “a friend of an enemy is an enemy”, “an enemy of a friend is an enemy”, and “an enemy of an enemy is a stranger”. The paradigm incorporates two core mechanisms: (1) an endogenous cognitive inertia mechanism that uses the psychological serial-positioning effect to model cognitive inertia weights, accounting for primacy, recency, and U-shaped memory effects; and (2) an exogenous mechanism that quantifies comprehensive trust/distrust degrees via opinion similarity, stability similarity, and network structure similarity. To prevent followers from falling into cognitive freezing, a cluster leader-based consensus-reaching strategy is introduced. Extensive comparative experiments on real-world network datasets confirm the model’s effectiveness and robustness.},
  archive      = {J_ESWA},
  author       = {Jianglin Dong and Yiyi Zhao and Shangqun Mu and Haixia Mao and Jiangping Hu},
  doi          = {10.1016/j.eswa.2025.129705},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129705},
  shortjournal = {Expert Syst. Appl.},
  title        = {A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features. <em>ESWA</em>, <em>298</em>, 129704. (<a href='https://doi.org/10.1016/j.eswa.2025.129704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is essential for indoor service robots to achieve reliable navigation and mapping. While point and line features have been extensively utilized to enhance the accuracy of visual odometry (VO), current methods often overlook the rich geometric information embedded in the spatial relationships among structural lines. In particular, the parallelism and collinearity within groups of line segments are underexploited, and geometric constraints are typically applied only heuristically or post hoc, limiting robustness in low-texture and repetitive environments. To address these challenges, a robust VO system is proposed that integrates structural feature grouping with adaptive MW tracking. A unified feature extraction strategy is introduced to detect point and line features simultaneously, improving computational efficiency. To mitigate pose drift caused by unreliable line segments, a set of parallel line features is constructed based on local geometric constraints, and a novel reprojection error model is formulated to enhance pose estimation. Furthermore, a tracking strategy based on local Manhattan World (MW) structure is developed to ensure low-drift estimation across various structured indoor scenes. Extensive experiments on multiple public datasets and a custom-built service robot platform demonstrate that the proposed method outperforms existing state-of-the-art approaches under dynamic lighting conditions and in environments rich in lines and planes. The system also operates at a real-time speed of 30 frames per second, meeting the requirements of practical robotic applications.},
  archive      = {J_ESWA},
  author       = {Zhiyu Wang and Weili Ding and Ying Zhang and Changchun Hua},
  doi          = {10.1016/j.eswa.2025.129704},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129704},
  shortjournal = {Expert Syst. Appl.},
  title        = {OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated meta graph retention network: A model for urban traffic flow prediction. <em>ESWA</em>, <em>298</em>, 129703. (<a href='https://doi.org/10.1016/j.eswa.2025.129703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for urban transportation systems. Existing models are still deficient in training efficiency and modeling dynamic spatial-temporal dependencies, various external factors, time-varying topology. Based on this, this paper introduces the Adaptive Gated Meta Graph Retention Network (AGMGRN), a novel model for spatial-temporal traffic flow prediction. Specifically, the AGMGRN integrates the attention mechanism with the retention network to model spatial-temporal dependencies. The AGMGRN proposes a gated dynamic connection block to enhance the model’s dynamic modeling capabilities. The AGMGRN considers the influence of external factors on traffic conditions through meta-learning approaches. The AGMGRN proposes an adaptive graph block to construct time-varying topologies. Experiments on four actual large-scale datasets demonstrate that the AGMGRN achieves superior prediction accuracy and high applicability.},
  archive      = {J_ESWA},
  author       = {Xing Li and Yuequan Bao},
  doi          = {10.1016/j.eswa.2025.129703},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129703},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated meta graph retention network: A model for urban traffic flow prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations. <em>ESWA</em>, <em>298</em>, 129702. (<a href='https://doi.org/10.1016/j.eswa.2025.129702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defensive Counter-Air (DCA) operations are pivotal for modern air defense, but existing studies are limited by static defender populations and oversimplified attacker models. We address these limitations with the Dynamic Agent-Scaling Framework with Game-Augmented Reinforcement Learning (DASF-GRL), which dynamically scales defender populations based on real-time threat levels. Specifically, we introduce a hybrid imitation-reinforcement training strategy that integrates attention mechanisms into critic networks to enable dynamic agent scaling. By incorporating a safety barrier function rooted in differential game theory, we constrain agents’ action spaces and enhance policy reliability. Furthermore, we developed a DCA simulation platform supporting reinforcement learning validation and designed a novel Apollonius-based penetration strategy for attackers to improve algorithmic robustness. Experiments demonstrate that DASF-GRL adaptively adjusts defender populations across scenarios involving 20, 40, and 60 attackers, markedly outperforming baseline methods in convergence speed and defense success rates. This framework offers novel theoretical paradigms and practical tools for intelligent decision-making in DCA environments.},
  archive      = {J_ESWA},
  author       = {Yuxuan Chen and He Luo and Guoqiang Wang},
  doi          = {10.1016/j.eswa.2025.129702},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129702},
  shortjournal = {Expert Syst. Appl.},
  title        = {DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction. <em>ESWA</em>, <em>298</em>, 129701. (<a href='https://doi.org/10.1016/j.eswa.2025.129701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven spatial and temporal distribution of renewable energy resources poses significant challenges for multi-microgrid (MG) systems, resulting in high operational costs and low renewable energy utilization. To overcome these challenges, this work investigates a peer-to-peer electricity transaction and hydrogen-methanol-hydrogen technology-based methanol transaction among multi-MG. Besides, to realize net-zero emissions and carbon cycle utilization, the carbon capture system and hydrogen blending system are introduced into MG to reduce carbon dioxide emissions and capture and reform carbon dioxide for methanol synthesis equipment. Additionally, a cooperative operation model based on the Nash bargaining theory for multi-MGs under the transaction amount and price constraints of electricity and methanol is constructed. Due to the characteristics of non-convex and non-linear, the Nash bargaining is transformed into minimizing operation costs (sub-problem one) and maximizing payment benefits (sub-problem two). During the process of benefit allocation in sub-problem two, this work adopts a nonlinear energy sharing mapping method to quantify the comprehensive contribution rate of each MG to the multi-MG system, thereby achieving fair allocation of benefits. Finally, the alternating direction multiplier method is used to solve the model, effectively protecting the privacy of each MG. The simulation results demonstrate that a multi-MG system considering electricity and methanol transactions can effectively decrease carbon emissions and the total operational costs by 21.53% and 27.01% compared to only considering electricity transactions, respectively. Overall, the proposed electricity and methanol transactions strategy simultaneously reduces the overall system operation costs and carbon emissions, underscoring its advantages and significance.},
  archive      = {J_ESWA},
  author       = {Jiale Li and Bo Yang and Yiming Zhou and Hongchun Shu and Hongbiao Li and Dengke Gao and Lin Jiang},
  doi          = {10.1016/j.eswa.2025.129701},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129701},
  shortjournal = {Expert Syst. Appl.},
  title        = {Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming. <em>ESWA</em>, <em>298</em>, 129700. (<a href='https://doi.org/10.1016/j.eswa.2025.129700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosion in popularity of crowdsourced live streaming (CLS) has led to a huge increase in demand for cloud resources to support real-time video transcoding. CLS transcoding is real-time, geographically distributed and computationally intensive. Therefore, transcoding service providers need to cost-effectively utilize diverse heterogeneous cloud resources, while guaranteeing quality of service standards to ensure a good streaming experience for the viewers. To support the above, we developed a novel proactive-reactive resource allocation framework that optimizes the overall cost of supporting the CLS transcoding service using heterogeneous edge and cloud computing resources. The offline proactive policy evaluator aims to provide a good and adaptable resource usage plan in advance, matching the predicted demand with the heterogeneous resources. The reactive execution module monitors the actual demand online and controls the resource usage to compensate for deviations from the offline prediction. Our experiments show that the proposed approach leads to a cost reduction of 42 % compared to the fixed usage ratio strategy based on expert knowledge.},
  archive      = {J_ESWA},
  author       = {Yinuo Li and Jin-Kao Hao and Kwong Meng Teo and Liwei Song},
  doi          = {10.1016/j.eswa.2025.129700},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129700},
  shortjournal = {Expert Syst. Appl.},
  title        = {Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach. <em>ESWA</em>, <em>298</em>, 129699. (<a href='https://doi.org/10.1016/j.eswa.2025.129699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-robot path planning problem requires algorithms with high convergence speed and accuracy, as well as the completeness of the search probability for the optimal path. The integration of metaheuristic algorithms in path planning has proven to be remarkably efficient. This paper introduces a novel hybrid metaheuristic algorithm, Beluga Whale-Crayfish Optimization (BWCOA), for enhanced global optimization in path planning applications. While the Crayfish Optimization (COA) demonstrates superior convergence speed, its inherent probabilistic path completeness remains suboptimal. To address this limitation, we present three key innovations: a dynamic probability completion mechanism, adaptive convergence acceleration factors, and balanced exploration–exploitation trade-off parameters. The proposed BWCOA synergizes Beluga Whale Optimization (BWO)’s basin-hopping capability with COA’s swarm intelligence through parallel combined exploration strategies. To prove its powerfulness, a series of comparative analyses were conducted between BWCOA and other leading algorithms across two comprehensive test function suites. The numerical experiment results underscore the significant superiority of BWCOA over its counterparts. In the context of path planning simulations, BWCOA demonstrated notable improvements over COA within the same number of function evaluations, with average enhancement rates of 6.49 %, 7.42 %, 15.09 %, 76.42 %, and 0.73 % across five evaluation metrics. Similarly, when compared to BWO on the same set of indicators, BWCOA showed average improvement rates of 22.39 %, 27.71 %, 70.53 %, 260.86 %, and 41.22 %. Furthermore, the running time of BWCOA is comparable to that of similar algorithms.},
  archive      = {J_ESWA},
  author       = {Liguo Yao and Guanghui Li and Taihua Zhang and Abdelazim G. Hussien and Yao Lu},
  doi          = {10.1016/j.eswa.2025.129699},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129699},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”. <em>ESWA</em>, <em>298</em>, 129697. (<a href='https://doi.org/10.1016/j.eswa.2025.129697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ESWA},
  author       = {Ngaiming Kwok},
  doi          = {10.1016/j.eswa.2025.129697},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129697},
  shortjournal = {Expert Syst. Appl.},
  title        = {Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time. <em>ESWA</em>, <em>298</em>, 129696. (<a href='https://doi.org/10.1016/j.eswa.2025.129696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of global data volume, the usage of hard disk drives (HDDs) is also increasing rapidly. Consequently, the number of failed disks is continuously rising, which can affect storage service quality and even lead to data loss when failures occur.In recent years, the active fault-tolerant technology, which collects hard disks’ Self Monitoring Analysis and Reporting Technology (SMART) data-set, predicts hard disk failure by machine learning model, and repairs near-failure disks’ data to health disks in advance, has become a common research hotspot in both academia and industry. Aiming at the existing problems such as interference characteristics, inaccurate failure time prediction, competition of system resources between data migration and front service, this paper researches the two-stage prediction model and data migration strategy based on hard disk failure time, including the two-stage hard disk information feature selection method, the two-stage prediction method of hard disk failure time, and the data migration elastic system resource allocation strategy. Feature selection is performed by combining embedding methods with visualization, and the importance of the selected features is evaluated using a random forest model. Based on the feature importance, further refinement is carried out to obtain the final feature set. Before predicting the failure time of hard drives, XGBoost is first used in a voting manner to identify drives predicted to be faulty. Then, a trained Bidirectional Long Short-Term Memory network (Bidirectional LSTM) enhanced with a self-attention mechanism is employed to predict the exact failure time.Experimental results show that on the Backblaze dataset, the model achieves a mean absolute error of 1.24 when predicting failure times. The recall rate for predicting failures within 7 days reaches 98.79 %, the error rate is 0.30 %, the F1 score is 99.24 %, and the precision is 99.69 %. The elastic system resource allocation strategy for data migration improves business IOPS by 47.19 % and reduces latency by 38.68 %.},
  archive      = {J_ESWA},
  author       = {Huiyuan Qiang and Yuequan Li and Hongzhang Yang and Ping Wang and Yaofeng Tu and Shang Yang},
  doi          = {10.1016/j.eswa.2025.129696},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129696},
  shortjournal = {Expert Syst. Appl.},
  title        = {2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm. <em>ESWA</em>, <em>298</em>, 129692. (<a href='https://doi.org/10.1016/j.eswa.2025.129692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time delay and Doppler shift parameters in radar system echo signals serve as effective tools for multi-target identification and localization in covert environments. However, the nonlinear characteristics of stationary targets are often masked by surrounding environmental factors, and traditional joint parameter estimation algorithms tend to suffer from high computational complexity and errors during demodulation. To address these challenges, this paper proposes an acoustic-electromagnetic intermodulation detection system based on a novel atomic-paradigm algorithm, which ensures localization accuracy with minimal computational complexity and zero false alarms. Specifically, the system excites the target by introducing acoustic field energy coupling, generating discernible micromotion features. The resulting acoustically modulated signal is then modeled as a two-dimensional line spectral estimation problem, capturing the target’s time delay and Doppler shift. Furthermore, the joint parameter estimation algorithm is enhanced by relaxing dyadic constraints under sufficient conditions. In our experiments, a harmonic radar physical system is constructed to simultaneously localize and measure multiple non-clustered micromotion targets. The recognition accuracy is quantitatively evaluated using a classical neural network model, achieving 86.9 % accuracy across five classified targets. The improved algorithm’s performance in joint parameter estimation is also assessed under varying signal-to-noise ratios and demodulation error rates, with a detailed time complexity analysis provided.},
  archive      = {J_ESWA},
  author       = {Sheng Wu and Yilin Cai and Yijing Zheng and Dingzhao Li and Hongjun Lai and Haixin Sun},
  doi          = {10.1016/j.eswa.2025.129692},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129692},
  shortjournal = {Expert Syst. Appl.},
  title        = {An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data. <em>ESWA</em>, <em>298</em>, 129691. (<a href='https://doi.org/10.1016/j.eswa.2025.129691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a fundamental task in supervised machine learning. This problem becomes challenging when dealing with imbalanced and overlapping datasets. In such cases, learning algorithms often perform well in identifying the labels of majority class data points but exhibit high error rates in predicting the minority class. This paper proposes an innovative method based on the convex-hull concept to enhance classification for imbalanced and overlapping datasets. Unlike undersampling approaches that may lead to the loss of valuable information, our method focuses on preserving the data. The process begins by clustering the data points for each class separately in such a way that no points from the opposite class fall within the convex-hull of each cluster. Then, the support vector machine (SVM) is used to separate every cluster of a given class from the data points of the opposite class. Afterward, data points inside the SVM boundaries are considered as non-overlapping, while those outside the SVM boundaries are identified as overlapping data. The XGBoost algorithm is then employed to classify the data points within the overlapping region. Extensive experiments on a variety of simulated and real-world datasets confirm the effectiveness of the proposed method in terms of various evaluation metrics, compared to existing relevant algorithms for handling imbalanced and overlapping datasets.},
  archive      = {J_ESWA},
  author       = {Farnaz Hooshmand and Sogol Peik-Mortazavi},
  doi          = {10.1016/j.eswa.2025.129691},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129691},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy. <em>ESWA</em>, <em>298</em>, 129689. (<a href='https://doi.org/10.1016/j.eswa.2025.129689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presented an Automatic Role Prompting System that seeks to improve the performance of the Large Language Model (LLM) by allowing models to assume varied roles through role-based prompting and, as a result, qualitatively improve the relevance of outputs. Our Automatic Role Prompting System’s target audience is people who do not have domain knowledge. The guiding framework (consisting of an Automated Script for discovering roles and fields layered on top of prompt engineering, and Natural Language Inference (NLI) models trained in advance), was robustly tested through the use of three datasets: our set of 1990 curated prompts, WikiQA, and the AwesomeChatGPTPrompts. We implemented a novel evaluation strategy using GPT-Eval, which scales prompts according to completeness, clarity, and relevance. We found substantially better performance than traditional rule- and template-based approaches, yielding accuracy improvements as high as 97.6 %. Overall, this work demonstrates the promise of an Automated Role Prompting System to help people engage and work more effectively and efficiently with Large Language Models (LLMs).},
  archive      = {J_ESWA},
  author       = {Samar Hendawi and Tarek Kanan and Mohammed Elbes and Ala Mughaid and Shadi Alzu’bi},
  doi          = {10.1016/j.eswa.2025.129689},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129689},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid fusion network using convolutional vision transformers for landslide identification. <em>ESWA</em>, <em>298</em>, 129688. (<a href='https://doi.org/10.1016/j.eswa.2025.129688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have made great strides in the segmentation of remote sensing images, but they still have certain inherent drawbacks when working with small targets and complex geological structures. These drawbacks include incomplete contextual information integration, blurry edges, and inaccurate target localisation. This study suggests using a hybrid CNN-Transformer network to improve the segmentation of landslide regions in high-resolution remote sensing images in order to overcome these difficulties. A comprehensive investigation has been conducted on the use of CNN and transformers to accomplish the task of semantic segmentation. According to experimental data, our model outperforms the state-of-the-art CNN-based, Transformer-based, and even CNN-plus-Transformer combination models for image segmentation tasks by a large margin. When it comes to landslide area segmentation, it performs exceptionally well.},
  archive      = {J_ESWA},
  author       = {S. Sreelakshmi and S.~S. Vinod Chandra},
  doi          = {10.1016/j.eswa.2025.129688},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129688},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid fusion network using convolutional vision transformers for landslide identification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection. <em>ESWA</em>, <em>298</em>, 129679. (<a href='https://doi.org/10.1016/j.eswa.2025.129679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral Object Detection has shown significant advantages under various lighting and weather conditions, with efficient fusion of RGB and thermal information playing a key role. Previous studies have demonstrated the effectiveness of feature fusion based on convolutional neural networks, but limited local feature interactions hinder the capture of global complementary information. To address these limitations, some methods adopt complex fusion strategies to enhance complementary feature extraction, yet fail to mitigate feature redundancy, which negatively impacts detection performance. In this paper, we propose a novel Global-aware Cross-attention and Mask-guided Fusion (GCMF) module for Multispectral Object Detection, following a fusion-refinement paradigm. In the fusion stage, we first introduce Efficient Channel Attention with Weighted Max-Pooling (ECA-WM) to focus on key information within each modality and achieve implicit alignment before fusion. Subsequently, the Global-aware Cross-Attention Transformer (GCAT) effectively captures complementary cross-modal information and models global features. In the refinement stage, the Mask-guided Refinement Strategy (MRS) generates segmentation masks to distinguish target features from the background. These masks are applied before and after cross-modal interaction to highlight target-relevant information while suppressing irrelevant features, resulting in highly discriminative fused representations. Extensive experimental comparisons demonstrate that the proposed GCMF fusion strategy achieves state-of-the-art performance on the publicly available FLIR, LLVIP and DVTOD datasets, with absolute improvements of 2.8 %, 4.2 % and 4.0 % over the previous methods, respectively. Moreover, the proposed strategy is general and effective, making it adaptable to various detection frameworks.},
  archive      = {J_ESWA},
  author       = {Zhong Qu and Jin Yang and Shufang Xia},
  doi          = {10.1016/j.eswa.2025.129679},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129679},
  shortjournal = {Expert Syst. Appl.},
  title        = {GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Oriented bounding box detection algorithm for dense scenarios of robotic arm operation. <em>ESWA</em>, <em>298</em>, 129678. (<a href='https://doi.org/10.1016/j.eswa.2025.129678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the national promotion of intelligent manufacturing and the ’Industry4.0’ strategy, the demand for intelligent robotic arms in industrial production has steadily increased. However, challenges such as occlusion, significant object scale variations, and strict real-time requirements have made target detection in densely packed environments more challenging. This study, based on the YOLOv11 algorithm, proposes an efficient oriented bounding box detection method aimed at improving the model’s performance in feature extraction, computational efficiency, and network lightweighting to tackle target detection challenges in dense industrial settings. A Dynamic-Cross-Stage-Dual-Conv module was designed to enhance the Bottleneck section, employing a parallel dual-branch structure for local feature extraction and global context fusion. Simultaneously, a CIoU loss function with geometric perception was introduced to improve object localization accuracy and strengthen the network’s ability to handle densely stacked objects. Next, a Modulated-Deform-Conv deformable convolution module was integrated into the Backbone structure, dynamically adjusting the convolution kernel sampling positions, enabling the network to learn deformation features in dense scenes, improving adaptability to shape and scale variations while reducing computational load. Additionally, a C3K2_FasterBlock lightweight structure, utilizing partial convolutions and sparse connections, was proposed to minimize redundant calculations and optimize feature interactions. On a custom-built dense object dataset, the model achieved a 2.9 % increase in mAP@0.5 and reduced computational cost by 14 %. Finally, the improved model was deployed on the Jetson Orin Nano development board, demonstrating its practical value in robotic arm recognition and grasping tasks in dense industrial environments, offering a new paradigm for future applications.},
  archive      = {J_ESWA},
  author       = {Jinshun Dong and Lixia Deng and Dapeng Wan and Chenxu Liu and Jianqin Yin and Meiqi Guo and Hongyu Zhang and Shoujun Lin and Haiying Liu and Lida Liu},
  doi          = {10.1016/j.eswa.2025.129678},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129678},
  shortjournal = {Expert Syst. Appl.},
  title        = {Oriented bounding box detection algorithm for dense scenarios of robotic arm operation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction. <em>ESWA</em>, <em>298</em>, 129677. (<a href='https://doi.org/10.1016/j.eswa.2025.129677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in complex environments, particularly under conditions such as low illumination or adverse weather, remains a significant challenge. Multispectral detection techniques that integrate visible and infrared imagery offer a promising solution by leveraging complementary modality information. However, substantial discrepancies between these modalities hinder traditional fusion strategies, which often fail to adaptively align and integrate features, resulting in information loss and diminished detection performance. To overcome this limitation, we propose CrossModalNet, a novel cross-modal fusion and channel interaction framework. CrossModalNet comprises two key modules: Convolutional Attention Interaction Module (CAIM) and Bidirectional Cross-Modal Attention Module (BiCAM). CAIM enables effective cross-modal integration across varying semantic levels by employing convolutional attention mechanisms combined with pixel-wise channel guidance. In parallel, BiCAM enhances inter-modal feature complementarity by modeling channel-level interactions through bidirectional attention pathways. Extensive experiments conducted on four public multispectral datasets, FLIR, LLVIP, M3FD, and VEDAI, demonstrate that the proposed method consistently outperforms existing state-of-the-art approaches across multiple performance metrics. Moreover, with an inference speed of 12.6 FPS on embedded platforms, the proposed model is suitable for real-time deployment.},
  archive      = {J_ESWA},
  author       = {Hanyun Li and Linsong Xiao and Lihua Cao and Di Wu and Yangfan Liu and Yi Li and Yunfeng Zhang and Haiyang Bao},
  doi          = {10.1016/j.eswa.2025.129677},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129677},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification. <em>ESWA</em>, <em>298</em>, 129676. (<a href='https://doi.org/10.1016/j.eswa.2025.129676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear segmentation and classification play a crucial role in pathological image analysis. However, it is frequently challenged by blurred nuclear boundaries and complex structures in digital pathology slides, due to factors such as staining techniques and imaging methods, posing a significant challenge for accurate segmentation and classification. To this end, we propose a novel and efficient approach for nuclear identification, termed Information Propagation with Multi-Granularity Morphology-Guided Network (IPMMG). Specifically, IPMMG progressively captures edge morphology information from different network layers while simultaneously incorporating structural morphology features at multiple granularities. By explicitly propagating features related to both the edge and the structure, our approach constrains semantic features to focus on contours of the region of interest in the nuclear segmentation task, thus mitigating the challenge of blurred morphology. Experiments on public datasets demonstrate that IPMMG achieves state-of-the-art (SOTA) performance in segmentation, as measured by Dice and IoU scores, while also attaining competitive results in classification with DQ, SQ, and PQ metrics. In particular, our proposal IPMMG excels in handling nuclei with blurred edges and complex structures.},
  archive      = {J_ESWA},
  author       = {Dawei Fan and Jun Li and Chengfei Cai and Lihui Lin and Riqing Chen and Yanping Chen and Lifang Wei},
  doi          = {10.1016/j.eswa.2025.129676},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129676},
  shortjournal = {Expert Syst. Appl.},
  title        = {IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication. <em>ESWA</em>, <em>298</em>, 129674. (<a href='https://doi.org/10.1016/j.eswa.2025.129674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG-based personal identification confronts critical hurdles, including high dimensionality, noise, and real-time variability. While RSVP and P300 paradigms provide cognitive-response-driven security, feature extraction challenges prevent practical deployment. Although deep learning has addressed unstructured EEG data, pinpointing optimal RSVP and P300-specific features remains an unresolved issue. To overcome these limitations, we introduced a hybrid GWO-MSE-XAI framework integrating Grey Wolf Optimization (GWO), Multiscale Entropy (MSE), and SHAP-based Explainable AI (XAI) to select the most relevant features from RSVP-evoked P300 EEG signals. The framework prioritizes discriminative feature selection, improves class separability, and incorporates a hybrid cross-entropy loss function fused with Fisher’s score-based feature selection. Benchmark-driven optimization refines EEG-specific feature subsets, while evaluation using classifiers (Random Forest, LightGBM, CatBoost, XGBoost) demonstrates substantial dimensionality reduction, faster convergence, and superior performance (98.89% accuracy). Experimental results confirm robustness, scalability, and enhanced interpretability, positioning the framework as a viable solution for EEG-based identity authentication in real-world RSVP and P300 applications.},
  archive      = {J_ESWA},
  author       = {S Abinayaa and S.S. Sridhar},
  doi          = {10.1016/j.eswa.2025.129674},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129674},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKT-ML: An efficient knowledge tracing model with multi-task learning. <em>ESWA</em>, <em>298</em>, 129671. (<a href='https://doi.org/10.1016/j.eswa.2025.129671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) aims to trace a student’s mastery of knowledge, known as knowledge states, and has become a popular research area, with Self-Attention (SA)-based KT models achieving the state-of-the-art performance. However, existing SA-based KT models seem to still have issues that need further investigation. Firstly, there commonly exists incorrect question-knowledge concept (Q-KC) mapping, yet most models fail to address this issue. Secondly, existing SA-based KT models suffer from high time complexity due to their extensive use of the SA mechanism. Finally, from real-world datasets, we observe that there exists a repeated attempts pattern which is often overlooked by existing KT models. Motivated by the above observations, we propose a novel Efficient Knowledge Tracing Model with Multi-task Learning (EKT-ML), an SA-based model with three crucial features. Firstly, we formulate the KT as a Multi-task Learning, with Q-task and KC-task as two tasks; by training them simultaneously and treating Q-KC mapping as shared information, the proposed EKT-ML tends to mitigate the impact of incorrect Q-KC mapping. Moreover, we propose an SVD-MLP component to replace the initial SA layers commonly used in existing SA-based KT models, thereby reducing the time complexity of EKT-ML. Finally, experimental results show that EKT-ML improves performance by up to 8.84 % across four metrics on three widely used datasets. Furthermore, it demonstrates that the EKT-ML has reduced time complexity compared with the benchmark baseline.},
  archive      = {J_ESWA},
  author       = {Wei Liu and Bo Yang and Haotian Su and Yaowei Wang and Qing Li},
  doi          = {10.1016/j.eswa.2025.129671},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129671},
  shortjournal = {Expert Syst. Appl.},
  title        = {EKT-ML: An efficient knowledge tracing model with multi-task learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm. <em>ESWA</em>, <em>298</em>, 129668. (<a href='https://doi.org/10.1016/j.eswa.2025.129668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is a key technique for extracting object structures and region boundaries in images, serving as an important foundation for visual tasks such as image segmentation and object recognition. However, during real-world image acquisition, various types of noise are inevitably introduced into the images. Traditional edge detection methods suffer significant performance degradation in noisy environments, often resulting in false edges or missing true edges. To address this issue, this paper proposes a novel edge detection method for noisy images. The method begins by adaptively selecting an optimal fractional order p , based on the distribution characteristics of the image’s subband modulus coefficients. This order is then used to perform a p -order discrete fractional wavelet transform (DFRWT) on the noisy image. Then, within the DFRWT domain, an enhanced Canny algorithm is applied to detect edges. This algorithm improves upon the standard method by replacing the traditional gradient operator with a more robust fractional-order Sobel operator to compute the gradient magnitude. This detection process is performed on both the low- and high-frequency subbands to capture features at different scales. Finally, the edge images from the low- and high-frequency components are reconstructed to obtain the final edge detection result. Experimental results demonstrate that, compared to four representative edge detection algorithms, the proposed method exhibits superior noise robustness and edge preservation capability in noisy environments.},
  archive      = {J_ESWA},
  author       = {Xiaozhong Yang and Chunmeng Li},
  doi          = {10.1016/j.eswa.2025.129668},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129668},
  shortjournal = {Expert Syst. Appl.},
  title        = {A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning. <em>ESWA</em>, <em>298</em>, 129667. (<a href='https://doi.org/10.1016/j.eswa.2025.129667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electron Backscatter Diffraction (EBSD) is a crucial characterisation method in materials engineering. The reliability of EBSD data is essential in the aerospace, nuclear, and automotive industries, as material performance greatly affects operational safety. While industrial practice makes perfect EBSD data difficult, with sample preparation errors, beam drift, and instrumental noise corrupting up to one-third of datasets. Automated crystallographic fidelity restoration solutions are needed because corrupted data force engineers to abandon valuable experiments or manually restore datasets at risk of errors. Current image inpainting techniques fail to maintain crystallographic constraints, resulting in restorations that violate the basic rules for crystalline materials. A novel physics-constrained framework is proposed to fill this gap. It integrates adversarial learning with graph neural networks (GNNs) for crystallographically consistent EBSD image inpainting. The proposed GTRG method consists of three elements: i ) a generative adversarial network (GAN) for reconstructing grain boundaries; i i ) a crystallography-guided graph transformer (T) that converts pixel data into orientation-boundary graphs; and i i i ) a regression graph convolutional network (RGCN) that links grain, orientation and boundaries to predict missing crystal orientations. The framework mandates a single orientation per grain and preserves grain boundary structure through structured graph representations. A strategy for creating automated EBSD datasets that incorporates realistic corruption patterns supports effective model training and evaluation. Experimental validation shows better performance than current methods, with a 3.5 % improvement in SSIM (0.950 vs. 0.918) and a 63.0 % reduction in FID (16.55 vs. 44.70) compared to AOT-GAN. The study on aerospace niobium alloys further validates practical utility, showing statistically consistent grain orientation and size distributions (Kolmogorov-Smirnov D = 0.02 , p > 0.98 ). This work introduces two key advancements: 1) the first integration of graph neural networks with adversarial learning for topology-aware image inpainting, and 2) a physics-informed framework bridging computer vision and materials science, enabling effective restoration of corrupted EBSD data for subsequent engineering applications.},
  archive      = {J_ESWA},
  author       = {Baiyang Zheng and Jiongran Wen and Yat-Sze Choy and Chengwei Fei},
  doi          = {10.1016/j.eswa.2025.129667},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129667},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks. <em>ESWA</em>, <em>298</em>, 129666. (<a href='https://doi.org/10.1016/j.eswa.2025.129666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gathering and sharing of information lay the groundwork for decision-making, while large-scale group decision-making (LSGDM) strategies address biases, promoting a more comprehensive evaluation of alternatives. Regarding information representation, incomplete multi-scale information systems (MSISs), as an application of granular computing, combine inputs from decision-makers (DMs) and tackle data gaps through multi-level analysis to foster LSGDM. Furthermore, given the interference effect among DMs, quantum social networks (SNs) and three-way decisions (TWD) are vital for effective decision-making. Quantum SNs provide a framework for modeling complex trust relationships among DMs, while TWD offers a structured approach to manage uncertainty. Therefore, this paper seeks to investigate quantum SN-guided three-way LSGDM under incomplete MSISs. First, MSISs are designed to gather information across spatial dimensions. Second, trust propagation paths within SNs are aggregated using quantum theory. Following community clustering through the Leiden algorithm, each community is further divided into core and fringe regions by three-way clustering (TWC), where core alternatives reflect the central members and fringe alternatives represent uncertain members. Third, to achieve intra-group consensus, the weights of DMs in fringe regions and those with low consensus levels are adjusted, while for inter-group consensus, the weight and decision information of community representatives with low consensus levels are modified. Fourth, alternatives are classified using the TWD method, which is grounded in the Dempster-Shafer theory and incorporates the enhanced belief Jensen-Sharma-Mittal ( E B J S M ) divergence. Finally, air quality datasets are used to validate the practicality of this method through sensitivity analysis, simulation analysis, comparative analysis, and statistical analysis.},
  archive      = {J_ESWA},
  author       = {Rui Li and Chao Zhang and Hamido Fujita and Wentao Li and Witold Pedrycz and Oscar Castillo},
  doi          = {10.1016/j.eswa.2025.129666},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129666},
  shortjournal = {Expert Syst. Appl.},
  title        = {Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GDCR: Geometry-enhanced directional consistency representation for point cloud analysis. <em>ESWA</em>, <em>298</em>, 129665. (<a href='https://doi.org/10.1016/j.eswa.2025.129665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds provide discrete representations of 3D scenes. The relative positions and directions between points collectively describe the objects. Variations in sampling angles, distances, or noises can introduce perturbations, disrupting these spatial and directional relationships. These pose significant challenges for achieving robust feature representations. However, research on the robust representation of point clouds is limited. Although advanced models achieve impressive performance, they exhibit poor robustness to perturbations. To address this issue, we propose Geometry-enhanced Directional Consistency Representation (GDCR), a novel method designed to enhance robustness. In GDCR, we introduce Statistic-based Geometric Reasoning (SGR) to achieve precise spatial geometric estimation for discrete point sets, explicitly enriching spatial geometric information. Furthermore, GDCR vectorizes features embedded with SGR information and applies feature rotation and relative direction refinement in the expanded feature space for robust directional representation. GDCR improves the flexibility and directional expressiveness of point cloud features, significantly improving robustness against perturbations. Extensive experiments demonstrate that GDCR exhibits outstanding robustness while surpassing or matching the performance of state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Ziming Wang and Boxiang Zhang and Ming Ma and Yue Wang and Taoli Du and Ying Wang and Wenhui Li},
  doi          = {10.1016/j.eswa.2025.129665},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129665},
  shortjournal = {Expert Syst. Appl.},
  title        = {GDCR: Geometry-enhanced directional consistency representation for point cloud analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement. <em>ESWA</em>, <em>298</em>, 129664. (<a href='https://doi.org/10.1016/j.eswa.2025.129664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-Light Image Enhancement (LLIE) plays a crucial role in computer vision applications. Beyond spatial-based approaches, recent works have explored the Fourier domain. To better preserve structural details in extremely dark scenes, infrared modality has also been introduced as a robust prior for capturing scene geometry. However, existing methods suffer from limited enhancement performance due to the independent modeling of Fourier amplitude and phase, the limitations of cross-modal guidance, and the information loss in sequential feature extraction. To address these challenges, we propose APMoE-Net, a dual-stage Fourier network framework with amplitude-phase joint enhancement and spatial Mixture of Experts (MoE) compensation. Stage one performs coarse enhancement by leveraging infrared images to jointly optimize Fourier amplitude and phase, enabling mutual guidance learning between them. Subsequently, a Modality Refinement Module leverages edge information to refine infrared inputs, producing a refined modality map as a more accurate cross-modal prior for subsequent processing. The second stage employs a dual-branch design for texture refinement. Our key innovation lies in the MoE Compensation Module integrated within the Multi-scale Convolution Branch. This module employs a dynamic routing network to selectively activate specialized experts, enabling the recovery of fine-grained textures that are lost during sequential processing. Meanwhile, the Fourier Branch integrates the refined modality map to improve overall detail and contrast. Comprehensive experiments demonstrate that APMoE-Net surpasses state-of-the-art (SOTA) methods in both qualitative and quantitative evaluations. Notably, APMoE-Net achieves outstanding performance with a lightweight design, offering an efficient LLIE solution.},
  archive      = {J_ESWA},
  author       = {Mengen Cai and Tongshun Zhang and Pingping Liu and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129664},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129664},
  shortjournal = {Expert Syst. Appl.},
  title        = {APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms. <em>ESWA</em>, <em>298</em>, 129663. (<a href='https://doi.org/10.1016/j.eswa.2025.129663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection and identification of harmful algal bloom (HAB) images are crucial for developing effective early warning systems for HABs. However, existing edge detection models, primarily designed for natural scenes, struggle with HAB-specific challenges such as blurred cell contours and interference from impurity bubbles. To address these issues, we propose a novel edge detection approach tailored for marine HABs, integrating a diffusion probability model with Sobel convolutional inter-layer attention mechanisms. Firstly, we develop an image enhancement algorithm specifically for HABs images, significantly improving real-time dynamic sampling data by enhancing contrast, edges, and texture features. Next, we introduce the SIAnet network, which utilizes inter-layer attention and convolutional operations to generate comprehensive global information. This network enhances feature correlation by aggregating shared features across multiple layers and modeling both long-range and short-range dependencies, effectively suppressing noise and background interference. This facilitates precise extraction of algae boundaries and morphological characteristics. Additionally, an improved Sobel operator is employed to generate supplementary edge features, accelerating the training process. Experimental results demonstrate that the proposed method achieves robust performance on the HABs dataset, with an Optimal Dataset Scale (ODS) of 0.645, an Optimal Image Scale (OIS) of 0.702, and an Average Precision (AP) of 0.813. Compared to existing methodologies, our approach demonstrates strong generalization on BSDS and BIPED datasets, significantly enhancing performance and mitigating typical CNN issues of edge thickening and fragmentation. It offers essential technical support for efficient HAB early warning system development.},
  archive      = {J_ESWA},
  author       = {Gengkun Wu and Yining Fan and Xin Tian and Chao Cui and Jiazheng Han},
  doi          = {10.1016/j.eswa.2025.129663},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129663},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches. <em>ESWA</em>, <em>298</em>, 129662. (<a href='https://doi.org/10.1016/j.eswa.2025.129662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring an individual’s BioGeographical Ancestry (BGA) through DNA analysis is a valuable tool in various fields such as forensic science, especially when traditional methods fail to identify suspects or victims. Advances in Next-Generation Sequencing (NGS) have revolutionized genomic data acquisition, enabling the development of comprehensive Single Nucleotide Polymorphism (SNP) panels for ancestry inference. This study assessed the effectiveness of a novel panel containing 3234 SNPs at both inter-continental and a more detailed BGA level, using various supervised Machine Learning (ML) models, including Categorical Naive Bayes, Penalized Multinomial Logistic Regression, Linear Support Vector Machines, Random Forest, and tree-based Gradient Boosting. A nested cross-validation approach was employed for model tuning and evaluation, with balanced accuracy as the main performance metric to address class imbalance. At the inter-continental level, all ML models demonstrated high balanced accuracy, confirming their reliability for BGA inference. However, performance declined at the more detailed continental level, likely due to a combination of factors including increased class imbalance, reduced sample sizes for certain populations, and the inherent complexity of distinguishing genetically and geographically proximate groups. Nonetheless, promising results were observed for South Asians, Northeast Asians, Europeans, and West Africans classes. In contrast, performance was notably lower for underrepresented classes such as Inner Asians. Misclassification patterns at both levels appeared to reflect known geographical and historical relationships, although further analysis revealed that these were often concentrated in underrepresented or genetically complex groups. These findings highlighted the potential of this SNP panel and ML approaches as valuable tools for forensic investigations.},
  archive      = {J_ESWA},
  author       = {Cosimo Grazzini and Giorgia Spera and Stefania Morelli and Daniele Castellana and Giulia Cosenza and Michela Baccini and Giulia Cereda and Elena Pilli},
  doi          = {10.1016/j.eswa.2025.129662},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129662},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image. <em>ESWA</em>, <em>298</em>, 129661. (<a href='https://doi.org/10.1016/j.eswa.2025.129661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting small regions of interest (ROIs) from abdominal CT images presents significant challenges, particularly due to class imbalance and variations in the sizes of foreground objects. A commonly adopted solution is the two-stage segmentation. However, this approach has two key limitations: i) Difficulty in balancing localization accuracy and target preservation. To reduce information loss in the first stage, existing methods typically enlarge the predicted bounding boxes, which improves coverage but compromises localization precision. ii) Independent optimization of the two stages, which lacks a collaborative mechanism. This fragmented pipeline limits the flow of information between stages, thereby constraining performance improvements. To address these limitations, we propose a reinforcement learning-based collaborative localization and segmentation (RL-CoSeg) framework, which comprises three sub-networks: localization network (LN), segmentation network, and localization-segmentation collaboration network (LSCN). The LN integrates prior knowledge and incorporates a dynamic reward mechanism to enhance the accuracy and efficiency of target detection through reinforcement learning (RL) strategies. The LSCN further introduces segmentation predictions as a reward signal, which, together with the localization reward, jointly drives policy learning. In addition, a heuristic exploration strategy is employed to avoid local optima and improve training stability. This design strengthens the information interaction and collaborative performance between the two tasks. Experimental results demonstrate that the proposed method achieves superior collaborative performance in small-target medical image segmentation.},
  archive      = {J_ESWA},
  author       = {Feilong Xu and Feiyang Yang and Xiaoli Zhang and Zhaojun Liu},
  doi          = {10.1016/j.eswa.2025.129661},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129661},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction. <em>ESWA</em>, <em>298</em>, 129660. (<a href='https://doi.org/10.1016/j.eswa.2025.129660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to extract relations between entity pairs across the entirety of a document. Current methods have begun to adopt logical rules to enhance the performance of DocRE models. However, the pipeline’s rule learning framework will suffer from the issue of error propagation, and the end-to-end method may lead to mistakes in rule reasoning. Additionly, they ignore entity type information when learning the rules. To address these issues, we propose a novel framework named Soft-Hard Rules with Entity Type Constraints (SH-ETRs) for improving the rules’ expressiveness and quality. Specifically, we first propose a Hard Entity Type Rules Module (H-ETRs) to learn entity type information and provide hard rule constraints. Then, we propose a Soft Entity Type Rule Reasoning Module (S-ETRs), which parameterizes the rule inference process and reduces error propagation during the process. Furthermore, by applying a rule consistency loss function to S-ETRs, we achieve the learning of soft rules under hard rule constraints, thereby aiming to prevent the learning of inaccurate rules during the training process. The experimental results demonstrate that our method outperforms existing rule learning frameworks, achieving state-of-the-art performance with an F1 score of 74.39 and an IgnF1 score of 67.43 across three public datasets and two baseline models.},
  archive      = {J_ESWA},
  author       = {Haisong Chen and Nisuo Du and Qing He and Yuji Wang},
  doi          = {10.1016/j.eswa.2025.129660},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129660},
  shortjournal = {Expert Syst. Appl.},
  title        = {SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable knowledge tracing with dual-level knowledge states. <em>ESWA</em>, <em>298</em>, 129658. (<a href='https://doi.org/10.1016/j.eswa.2025.129658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is a critical technology for achieving personalized learning. It estimates learners’ knowledge states and predicts future performance using historical interaction data. Despite recent advances, two significant challenges remain. First, the accuracy of knowledge state modeling is limited by the insufficient fusion of multi-scale information across temporal and spatial dimensions. Second, a trade-off persists between improving predictive performance and enhancing interpretability. This paper proposes an interpretable knowledge tracing method based on dual-level knowledge states (DIKT) to address these challenges. From the temporal perspective, DIKT incorporates a forgetting-aware RoLinear Transformer and a semantic similarity-based review mechanism to model learners’ problem-level knowledge states. From the spatial perspective, it leverages a Knowledge Concept (KC) relational graph to propagate influence among related KCs and dynamically update learners’ concept-level knowledge states through three sequential learning phases: forgetting, aggregation, and updating. Student performance is predicted using a two-parameter Item Response Theory (IRT) model, which incorporates guess and slip parameters to account for response anomalies. We conduct extensive comparisons between DIKT and 20 state-of-the-art KT models on five widely used public datasets. Experimental results demonstrate that DIKT achieves superior performance while preserving interpretability, highlighting its practical potential for real-world educational applications. The code is available at https://github.com/ting214/DIKT .},
  archive      = {J_ESWA},
  author       = {Yanting Li and Tao Zhou and Tianyu Cai and Shenggen Ju},
  doi          = {10.1016/j.eswa.2025.129658},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129658},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interpretable knowledge tracing with dual-level knowledge states},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RASpan: Improving toponym recognition through span representation model with retrieval augmentation. <em>ESWA</em>, <em>298</em>, 129657. (<a href='https://doi.org/10.1016/j.eswa.2025.129657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toponym recognition aims to identify place names from natural language texts, which is vital for various applications including geographic information retrieval, emergency response, and natural disaster analysis. Currently, mainstream studies mainly adopt deep learning models for toponym recognition. However, these approaches encounter significant limitations due to the inherent ambiguity, variation, and abbreviation of toponyms. To address these issues, we propose a novel Span Representation Model with R etrieval A ugmentation ( RASpan ) that leverages more accurate span representation and effective external geo-entity information to enhance the semantic representation of place names for improving the performance of toponym recognition. On the one hand, RASpan retrieves diverse geo-entities and concatenates geo-entity knowledge with an input sequence to construct a new prompt sequence. On the other hand, RASpan utilizes the prompt encoder based on the language model to encode this prompt sequence and employs a dedicated span representation module to obtain more accurate span representations. In addition, a new geo-entity prediction task is designed to learn the entire representation of each geo-entity while minimizing noise interference. Experiments on three publicly available datasets demonstrate that our model achieves new state-of-the-art results, highlighting the effectiveness of RASpan in toponym recognition by introducing prior geo-entity knowledge.},
  archive      = {J_ESWA},
  author       = {Hui Wu and Anran Yang and Zhinong Zhong and Ye Wu and Fei Yang and Luo Chen and Ning Jing},
  doi          = {10.1016/j.eswa.2025.129657},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129657},
  shortjournal = {Expert Syst. Appl.},
  title        = {RASpan: Improving toponym recognition through span representation model with retrieval augmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An interpretable automated optimized machine learning for predicting concrete compressive strength. <em>ESWA</em>, <em>298</em>, 129656. (<a href='https://doi.org/10.1016/j.eswa.2025.129656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel, interpretable, and automated machine learning (AutoML) framework for accurately predicting the compressive strength of environmentally sustainable concrete mixtures that incorporate supplementary cementitious materials (SCMs) by addressing the growing need for transparent and data driven tools in structural material design, particularly for concrete mixes enriched with various SCMs. A robust unified dataset of 1,317 samples was curated by integrating peer-reviewed experimental studies for this study. The proposed methodology incorporates feature contribution ranking through mutual information, model screening with AutoML to identify the most effective regression models, Bayesian optimization for fine-tuning model parameters, and interpretability techniques including SHAP and counterfactual analysis. The best performance metrics, in training include R 2 of 0.999, a mean absolute error 0.114, root mean squared error 0.7094, and mean absolute percentage error of 0.51 %, in testing phase R 2 of 0.944, a mean absolute error 3.479, root mean squared error 4.8173, and mean absolute percentage error of 9.86 %. The weakest performance, with a training R 2 of 0.982 and a mean absolute error of 1.911 MPa, root mean squared error 2.7990 and mean absolute percentage error 5.43 %, in testing phase R 2 of 0.786 and a mean absolute error of 5.754 MPa, root mean squared error 9.4336 and mean absolute percentage error 16.16 %. The interpretability analysis values provided insights into the most important features, such as curing time and cement are crucial in predicting the strength. Counterfactual analysis further validated the model by illustrating the significant impact of cement, age and water on concrete strength.},
  archive      = {J_ESWA},
  author       = {Aparna Kamarthi and Baskar Kaliyamoorthy},
  doi          = {10.1016/j.eswa.2025.129656},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129656},
  shortjournal = {Expert Syst. Appl.},
  title        = {An interpretable automated optimized machine learning for predicting concrete compressive strength},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT. <em>ESWA</em>, <em>298</em>, 129655. (<a href='https://doi.org/10.1016/j.eswa.2025.129655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI paraphrased text can be used for copyright infringement and the AI paraphrased content can deprive substantial revenue from original content creators. Despite this recent surge of malicious use of generative AI, there are few academic publications that research this threat. In this article, we demonstrate the ability of pattern-based similarity detection for AI paraphrased news recognition. We propose an algorithmic scheme, which is not limited to detect whether an article is an AI paraphrase, but, more importantly, to identify that the source of infringement is the ChatGPT. The proposed method is tested with a benchmark dataset specifically created for this task that incorporates real articles from BBC, incorporating a total of 2,224 articles across five different news categories, as well as 2,224 paraphrased articles created with ChatGPT. Results show that our pattern similarity-based method, that makes no use of deep learning, can detect ChatGPT assisted paraphrased articles at percentages 96.23% for accuracy, 96.25 for precision, 96.21% for sensitivity, 96.25% for specificity and 96.23% for F1 statistic.},
  archive      = {J_ESWA},
  author       = {Konstantinos F. Xylogiannopoulos and Petros Xanthopoulos and Panagiotis Karampelas and Georgios A. Bakamitsos},
  doi          = {10.1016/j.eswa.2025.129655},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129655},
  shortjournal = {Expert Syst. Appl.},
  title        = {The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition. <em>ESWA</em>, <em>298</em>, 129654. (<a href='https://doi.org/10.1016/j.eswa.2025.129654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant progress has been made in emotion recognition research based on electroencephalogram (EEG) signals. However, existing methods face two key limitations: on one hand, the reliance on fixed physical connections or static topological relationships makes it difficult to effectively represent the dynamic non-Euclidean spatial characteristics between EEG electrodes; on the other hand, spatiotemporal feature extraction is often conducted independently. This lack of a collaborative mechanism for spatiotemporal features results in insufficient fine-grained emotional representation capability. To address these issues, a dynamic collaborative evolutionary network (DCENet) is proposed based on graph-aware enhancement and global convolutional Transformer for EEG emotion recognition. DCENet constructs the causal relationship between electrodes by constructing the graph-aware enhancement (GAE) module, obtains spatial features with the causal relationship, and enhances key features. At the same time, DCENet constructs the global convolutional Transformer (GCT) module, which utilizes the global modeling advantage of the Transformer and the local perception ability of the convolutional operation to capture the temporal features with different scales. In addition, DCENet adaptively fuses temporal and spatial features through the local differential fusion (LDF) module to achieve cross-domain feature alignment and feature alignment of emotion categories to collaboratively evolve emotion representation features with more fine-grained information. This paper conducts experiments on the SEED, SEED-IV, and MPED datasets to validate the effectiveness of DCENet. The experimental results show that the model achieves cross-subject average accuracies of 87.55 %, 73.04 %, and 27.72 % on SEED, SEED-IV, and MPED, respectively, outperforming the state-of-the-art methods. The source code is publicly available at: https://github.com/cvmdsp/DCENet .},
  archive      = {J_ESWA},
  author       = {Shuaiqi Liu and Zhihui Gu and Yuan Zhang and Yanling An and Shuhuan Zhao and Bing Li and Yudong Zhang},
  doi          = {10.1016/j.eswa.2025.129654},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129654},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation. <em>ESWA</em>, <em>298</em>, 129651. (<a href='https://doi.org/10.1016/j.eswa.2025.129651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synthesis of cross-modal medical images plays a vital role in bridging diagnostic gaps between imaging modalities such as CT, MRI, and PET. This integration enables a more comprehensive evaluation of a patient’s condition, improving diagnostic accuracy and aiding clinical decision-making. However, the performance of conditional denoising diffusion probabilistic models is often hindered by pronounced structural and intensity discrepancies between modalities, as well as the inherently slow nature of the diffusion process. To address these challenges, this paper proposes Wavelet-Based Diffusion in the Difference Domain for Cross-Modality Medical Image Generation (Med-D3CG), a novel framework that transforms the synthesis process by emphasizing the difference domain. Instead of directly generating target images like conventional methods, Med-D3CG models the residual information between conditioned and target images. This strategy allows the framework to accurately capture essential structural and intensity variations between modalities, leading to more precise and realistic image synthesis. Additionally, Med-D3CG integrates the Discrete Wavelet Transform (DWT) to improve efficiency, accelerating the diffusion process while maintaining high image fidelity. On SynthRAD2023 and HMIFD datasets, state-of-the-art performance is achieved on pelvis and HMIFD using Med-D3CG , with the best Learned Perceptual Image Patch Similarity (LPIPS) and competitive FID observed on brain. Code and pretrained models are provided at https://github.com/ZgzTTTer/Med-D3CG .},
  archive      = {J_ESWA},
  author       = {Guangzhen Zhu and Midi Wan and Wenming Cao and Zhiwen Yu and Jin Hu and Bing Li and Xiaotao Fan},
  doi          = {10.1016/j.eswa.2025.129651},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129651},
  shortjournal = {Expert Syst. Appl.},
  title        = {Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search. <em>ESWA</em>, <em>298</em>, 129650. (<a href='https://doi.org/10.1016/j.eswa.2025.129650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set model(NRSM) has shown its powerful capacity in feature selection. However, a challenge still exists in describing the diversity between the attributes deeply while avoiding the impact caused by the neighborhood parameters. To address this problem, in this paper, we propose a two-stage feature selection by utilizing a three-way adaptive characteristic measure and an optimal combination search. First, we define a fitness function for applying the Stochastic Fractal Search(SFS) to design an novel adaptive neighborhood rough set model(ANRSM). To better utilize the construction characteristic of the adaptive model and reduce the computational cost, the lower and upper approximations of the SFS-based ANRSM are redefined through the fitness function. Second, based on the two approximations, we analyze the fitness function thresholds that can partition the universe into three regions and design the three-way adaptive neighborhood characteristic regions, which provide a more direct classification of samples without the inclusion and union operations. Third, we design different measures for the samples in diverse regions based on their corresponding characteristic. Afterward, a three-way adaptive characteristic measure is designed by integrating the three measures to evaluate the uncertainty of attributes. Then, we apply the measure to design a feature selection approach with greedy search. Considering that the greedy strategy may output redundant attributes, we introduce an optimal combination search approach through a novel wrapper technology to explore the potential optimal feature combinations. Compared with nine algorithms on fourteen public datasets, the experimental results show the effectiveness of our algorithm.},
  archive      = {J_ESWA},
  author       = {Bowen Lin and Duoqian Miao and Caihui Liu and Hongyun Zhang and Ruizhi Wang and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.129650},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129650},
  shortjournal = {Expert Syst. Appl.},
  title        = {Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm. <em>ESWA</em>, <em>298</em>, 129648. (<a href='https://doi.org/10.1016/j.eswa.2025.129648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering leverages prior information to improve algorithm performance and is widely valued by researchers. This paper analyzes the traditional semi-supervised fuzzy C-means (SFCM) objective function, noting that as a labeled sample’s membership degree aligns with its prior information, the impact of this information on the deviation constraint weakens. This reduces its supervisory effect on optimizing the membership partition matrix, especially with a large regularization factor. To overcome this, we propose a novel semi-supervised fuzzy C-means method based on an asymmetric deviation constraint and develop a two-level alternating iterative optimization algorithm, supported by theoretical convergence analysis using Zangwill’s theorem and the bordered Hessian matrix. To address the slow convergence and high computational cost typical of semi-supervised fuzzy clustering, we further enhance the algorithm with affinity filtering and a membership scaling scheme for improved efficiency. Experimental results demonstrate that our methods significantly outperform existing state-of-the-art techniques, advancing semi-supervised fuzzy C-means clustering.},
  archive      = {J_ESWA},
  author       = {Chengmao Wu and Jun Hou},
  doi          = {10.1016/j.eswa.2025.129648},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129648},
  shortjournal = {Expert Syst. Appl.},
  title        = {New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm. <em>ESWA</em>, <em>298</em>, 129644. (<a href='https://doi.org/10.1016/j.eswa.2025.129644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In screw whirling milling, the relationship between machining quality and processing parameters exhibits highly nonlinear characteristics. The traditional multiple regression models may not be able to capture this complex relationship accurately. Therefore, it is necessary to consider more flexible and applicable algorithms to establish their connections and optimize processing parameters. It can improve the accuracy and reliability of products, and provide more scientific method guidance for screw whirling milling processing. The originality of this article lies in proposing an adaptive dynamic optimization hybrid model. This model combines improved sparrow search algorithm optimized backpropagation (ISSA-BP) and non-dominated sorting genetic algorithm (NSGA-III). It can effectively adapt to dynamic data and find the optimal balance point among multiple objectives to better predict and optimize responses (cutting force, vibration, roughness, and residual compressive stress) in screw whirling milling. Firstly, a suitable network structure is identified by comparing the effects of five improvement strategies, population size, and the ratio of producers to scouters on the sparrow search algorithm. Then, an ISSA-BP prediction model is developed for four responses based on this structure. On this basis, the superiority of the established ISSA-BP model is verified by comparing prediction performance of five algorithms, and the relative prediction errors are all within 2%. The R 2 values of the models are all above 0.99, and they also perform well in indicators such as MAE (Mean Absolute Error), MSE (Mean Squared Error), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Squared Error). Then, ISSA-BP model is encapsulated and embedded into the optimization algorithm as the fitness function of NSGA-III. Finally, with the processing parameters of whirling milling as constraints, the NSGA-III algorithm is used to solve the proposed model and obtain the Pareto optimal solution set. Choosing appropriate processing parameters according to different needs in actual machining can help improve the quality and efficiency of screw machining.},
  archive      = {J_ESWA},
  author       = {Chao Liu and Hao Ding and Juanjuan Zheng and Yan He and Shaofu Huang and Junbo Tuo and Zuqing Luo and Gang Shen},
  doi          = {10.1016/j.eswa.2025.129644},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129644},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of large language models for data challenges in graphs. <em>ESWA</em>, <em>298</em>, 129643. (<a href='https://doi.org/10.1016/j.eswa.2025.129643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. While graph learning has achieved remarkable progress, real-world graph data presents a number of challenges that significantly hinder the learning process. In this survey, we focus on four fundamental data-centric challenges: (1) Incompleteness , real-world graphs have missing nodes, edges, or attributes; (2) Imbalance , the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity , graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability , graphs evolve over time in unpredictable ways. Recently, Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey focuses on how LLMs can address four fundamental data-centric challenges in graph-structured data, thereby improving the effectiveness of graph learning. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges: https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges .},
  archive      = {J_ESWA},
  author       = {Mengran Li and Pengyu Zhang and Wenbin Xing and Yijia Zheng and Klim Zaporojets and Junzhou Chen and Ronghui Zhang and Yong Zhang and Siyuan Gong and Jia Hu and Xiaolei Ma and Zhiyuan Liu and Paul Groth and Marcel Worring},
  doi          = {10.1016/j.eswa.2025.129643},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129643},
  shortjournal = {Expert Syst. Appl.},
  title        = {A survey of large language models for data challenges in graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129642. (<a href='https://doi.org/10.1016/j.eswa.2025.129642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic multi-objective optimization problems, effectively predicting and tracking the Pareto optimal front (POF) under environmental changes has been one of the core challenges. In this paper, we propose a region-aware prediction strategy based on shared points and multiple scales (RADMOEA) that combines global and local characteristics, aiming to enhance the algorithm’s ability to sense and adapt to POF. Firstly, the center-point movement strategy is used to move the non-dominated solution set from the previous moment to obtain the non-dominated solution set after the movement. The actual non-dominated solution set at the current moment and the non-dominated solution set after the movement share points in the objective space, and these shared points divide the non-dominated solution set at the current moment into several subregions. Within each region, all individuals are appropriately rescaled, and a local coordinate system is established. Then, within the local coordinate system, each individual is associated with the nearest post-movement non-dominated individual. Finally, new populations adapted to environmental changes are generated by combining centroid movement directions, Gaussian perturbations, and multi-scale individual association relationships. The proposed strategy is compared with six advanced algorithms, and the experimental results demonstrate that RADMOEA is effective in tracking the POF under dynamic environments.},
  archive      = {J_ESWA},
  author       = {Yaru Hu and Sitong Wang and Junwei Ou and Zhenlin Mei and Juan Zou and Shengxiang Yang},
  doi          = {10.1016/j.eswa.2025.129642},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129642},
  shortjournal = {Expert Syst. Appl.},
  title        = {Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion. <em>ESWA</em>, <em>298</em>, 129641. (<a href='https://doi.org/10.1016/j.eswa.2025.129641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passive microwave remote sensing plays a vital role in Earth observation, with applications in soil moisture, ocean salinity, and atmospheric monitoring. However, improving spatial resolution at low frequencies remains challenging. Recently, combining multiple small antenna arrays into a larger one has emerged as a technological approach to enhance spatial resolution. Nevertheless, aperture synthetic radiometers formed by such combinations usually consist of non-uniform antenna arrays (one-dimensional, two-dimensional, or three-dimensional). Compared with regular antenna arrays, they complicate the inversion of brightness temperature (BT) images. This paper proposes NASRT, a transformer-based inversion method designed for multi-dimensional non-uniform ASRs. The network extracts and fuses spectral and UVW spatial distribution features from the visibility function (VF), and introduces a learnable position weight matrix during training to capture spatial information of the non-uniform array. Through supervised learning, NASRT effectively maps the VF to BT images. Simulations across 1-D, 2-D, and 3-D NASR scenes demonstrate that NASRT achieves higher accuracy and stability than traditional methods. In a 1-D NASR indoor experiment, the proposed method also shows improved inversion accuracy and lower sidelobes, validating its effectiveness.},
  archive      = {J_ESWA},
  author       = {Jian Dong and Jiaxin Li and Chengwang Xiao and Rigeng Wu and Haofeng Dou and Wenjing Wang and Yuanchao Wu and Liangbing Chen},
  doi          = {10.1016/j.eswa.2025.129641},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129641},
  shortjournal = {Expert Syst. Appl.},
  title        = {A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OceanAgent: A small-scale multi-modal assistant for ocean exploration. <em>ESWA</em>, <em>298</em>, 129640. (<a href='https://doi.org/10.1016/j.eswa.2025.129640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of key information and the subsequent generation of actionable knowledge from multimodal data are critical for ocean exploration. Traditional knowledge generation methods rely heavily on expert experience and are labor-intensive. Recently, Large Multimodal Models (LMMs) have shown exceptional capabilities for knowledge generation from multimodal data in many complex tasks. These models also have potential to assist knowledge mining in ocean exploration. However, two major challenges faced by the LMMs when used in ocean exploration include the scarcity of ocean instruction-following data and the degradation of underwater visual environments. In this paper, a small-scale LMM for ocean exploration, named the OceanAgent, is designed. First, a swarm-intelligence-based leaderless multi-agent collaboration framework is proposed to generate visual instruction-following data. Subsequently, we present a visual-language connector to simultaneously extract multi-scale features. It is formed by integrating a multi-scale residual network with a multi-layer perceptron, which can enhance the model’s performance on severely low-quality images. Experiments show that the proposed method for constructing visual instruction-following datasets improves both the textual quality and visual dialogue. When severely degraded ocean visual data are processed using the trained OceanAgent, the image description accuracy and image comprehension are improved by 23.6 % and 21.6 %, respectively, compared to existing models. Additionally, the model demonstrates superior domain expertise, with a 95.7 % win rate in dialogue quality assessments.},
  archive      = {J_ESWA},
  author       = {Yun Xu and Yue Liu and Junpeng Shang and Jianmin Lin and Dongfang Ma},
  doi          = {10.1016/j.eswa.2025.129640},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129640},
  shortjournal = {Expert Syst. Appl.},
  title        = {OceanAgent: A small-scale multi-modal assistant for ocean exploration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs. <em>ESWA</em>, <em>298</em>, 129639. (<a href='https://doi.org/10.1016/j.eswa.2025.129639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection(GAD) plays a critical role in fields such as fraud detection and network security. Although existing graph anomaly detection methods have achieved promising performance, most graph neural networks (GNNs) rely on the homophily assumption, which presumes that connected nodes share similar labels. However, real-world graphs frequently exhibit pronounced heterophily. Owing to class imbalance, normal nodes tend to have lower heterophily while anomalous nodes display higher heterophily. Furthermore, feature inconsistency induced by node camouflage exacerbates the detection challenge, rendering many existing approaches ineffective. To overcome these limitations, we propose SPS-GAD, a spectral-spatial graph structure learning framework specifically designed for detecting anomalous nodes in heterophilic graphs. First, to alleviate the feature inconsistency resulting from node camouflage, we develop a node reconstruction module that learns intermediate node representations to mitigate camouflage-induced bias, and applies spectral filters to extract the graph’s inherent structural features. Second, to address the heterophily disparities arising from class imbalance, we introduce a subgraph-type-aware spectral filtering module that leverages edge scores generated by an edge partitioner to segregate the graph into homophilic, ambiguous, and heterophilic subgraphs. Distinct spectral filters are subsequently applied to capture features across various frequency bands. Additionally, we integrate a neighbor-type-aware graph attention module that employs edge scores within an attention mechanism to guide the feature aggregation process, thereby enhancing spatial representation learning. Experimental evaluations on six real-world datasets reveal that SPS-GAD significantly outperforms all baseline methods in key metrics such as F1-Macro and AUC, thereby confirming its effectiveness in graph anomaly detection. The source code is publicly available at https://github.com/cozy24/SPS-GAD .},
  archive      = {J_ESWA},
  author       = {Chen Zhu and Yaying Zhang},
  doi          = {10.1016/j.eswa.2025.129639},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129639},
  shortjournal = {Expert Syst. Appl.},
  title        = {SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach. <em>ESWA</em>, <em>298</em>, 129636. (<a href='https://doi.org/10.1016/j.eswa.2025.129636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the dual pressure of explosive growth in cross-border e-commerce demand and increasing timeliness requirements from overseas customers, cross-border logistics service providers are compelled to establish logistics facilities and deploy fleets across multiple regions to ensure rapid response. However, during freight transportation, the lack of effective management over these complex and heterogeneous fleets—particularly in terms of fleet composition and routing decisions—has led to high transportation costs and low operational efficiency. This study is grounded in the practical operational context of cross-border logistics in the Guangdong–Hong Kong–Macau Greater Bay Area and models a multi-level, multi-node cross-border transportation network. To minimize the overall operational cost, the problem is addressed from two interrelated decision-making perspectives: fleet composition at the strategic level and routing planning at the operational level. Thus, a bi-level programming model is proposed to systematically capture the hierarchical structure and the logical relationship between these two decision layers. Furthermore, the model incorporates cost differences among trucks with different functional capabilities to reflect the significant disparity in logistics cost structures between domestic and overseas operations. To address the above multi-objective mixed-integer linear programming (MILP) problem, a tailored Non-dominated Sorting Genetic Algorithm II (MNSGA-II) is developed. Several key components of the algorithm are modified and enhanced to improve its search efficiency and solution quality in handling the problem’s complexity. Comparative experiments against classical algorithms demonstrate the superior solution quality and robustness of the proposed approach. The influence of cost differentials on composition and scheduling decisions is further analyzed, providing practical insights for the strategic planning of cross-border logistics systems.},
  archive      = {J_ESWA},
  author       = {Zhi Tang and Ting Qu and Yanghua Pan and George Q. Huang},
  doi          = {10.1016/j.eswa.2025.129636},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129636},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems. <em>ESWA</em>, <em>298</em>, 129635. (<a href='https://doi.org/10.1016/j.eswa.2025.129635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) has long been a fundamental challenge in the field of optimization. Due to the existence of multiple roots, such problems often exhibit complex and multimodal characteristics. Although numerous differential evolution-based algorithms have been developed to solve NESs, most of them employ only a single mutation operator, which is not adaptable to different problem scenarios. To this end, a diversity-based niching differential evolution with neighborhood competition (DNDE) is proposed to solve NESs. First, a control mechanism that takes into account population diversity and the evolutionary stage is proposed to adaptively assign appropriate mutation strategies to each subpopulation (niche), thereby enhancing the efficiency of root-finding. Second, a neighborhood priority competition mechanism is proposed to reduce cross-peak competition between populations, which ensures local convergence while improving global convergence. Finally, a reinitialization strategy based on opposition learning is introduced to guide the population toward more promising areas of the search space. Experimental results on 18 complex NESs and two real-world engineering problems show that DNDE outperforms many advanced algorithms in both root rate and success rate, demonstrating its effectiveness and value in practical applications.},
  archive      = {J_ESWA},
  author       = {Jianwei Li and Xinchao Zhao and Lingyu Wu and Yizhan Wu and Lingjuan Ye},
  doi          = {10.1016/j.eswa.2025.129635},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129635},
  shortjournal = {Expert Syst. Appl.},
  title        = {A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGNet: Texture-enhanced guidance network for RGB-D salient object detection. <em>ESWA</em>, <em>298</em>, 129633. (<a href='https://doi.org/10.1016/j.eswa.2025.129633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection achieves salient region localization in complex scenes by fusing RGB images and depth images. Existing methods typically employ two-stream networks to extract features separately followed by cross-modal fusion. However, differences between heterogeneous modalities can easily lead to feature degradation during cross-modal fusion, while the inherent noise interference in low-quality depth maps may generate cumulative effects during multi-stage propagation, severely constraining detection performance. To address these challenges, this paper proposes a texture-enhanced guided network. The core innovations lie in three aspects: during the feature encoding stage, a texture-enhanced module is constructed to utilize high-frequency texture information from RGB images through attention mechanisms for hierarchical optimization of depth features; in the feature fusion stage, a dual-path adaptive interaction module is designed to establish cross-modal semantic correlations via channel-spatial cooperative driving mechanisms, effectively suppressing redundant feature interference; for the decoding reconstruction stage, a dynamic hierarchical guidance mechanism is proposed to drive progressive calibration of low-level spatial details by high-level semantic features through learnable cross-scale transformation modules. Extensive experiments conducted on five benchmark datasets demonstrate that our method achieves competitive performance compared to other approaches.},
  archive      = {J_ESWA},
  author       = {Xiaogang Song and Hexiang Huang and Qin Zhao and Xinwei Guo and Xinhong Hei},
  doi          = {10.1016/j.eswa.2025.129633},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129633},
  shortjournal = {Expert Syst. Appl.},
  title        = {TGNet: Texture-enhanced guidance network for RGB-D salient object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling. <em>ESWA</em>, <em>298</em>, 129632. (<a href='https://doi.org/10.1016/j.eswa.2025.129632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake, as a generative technology, has opened up new avenues for the development of the film, television, and art industries. However, its abusive use has triggered serious social security threats, such as infringement of portrait rights and the spread of misinformation, which has drawn widespread attention to research on deepfake detection techniques. Current deep learning-based face forgery detection methods face critical challenges: 1) insufficient focus on common forgery traces leads to poor generalization performance on datasets generated by unknown forgery methods; 2) traditional spatio-temporal feature fusion mechanisms struggle to balance the representational weights of spatial details and temporal dynamics, and exhibit inadequate robustness against post-processing operations like compression and cropping. To address these issues, this paper first designs a phase consistency edge artifact mining module is designed to extract common forgery traces from edge textures by leveraging the deep-phase information of images, significantly enhancing the model’s generalization ability. Second, a multi-frame synthesis strategy is designed to effectively integrate spatial and temporal features while balancing the network’s attention to these two feature domains. Third, a visual state-space model based on 3D scanning is designed, which for the first time employs the Mamba model to analyze spatio-temporal forgery patterns, notably improving the robustness of the model against unknown perturbations. Experimental results on standard benchmarks–FaceForensics++, Celeb-DFv2, WildDeepfake and DFDC(Preview)–demonstrate that the proposed method achieves state-of-the-art performance in three core dimensions: detection accuracy, cross-dataset generalization, and robustness against perturbations.},
  archive      = {J_ESWA},
  author       = {Zhong Chen and Siyang Wang and Zuxi Wang},
  doi          = {10.1016/j.eswa.2025.129632},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129632},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LSTT: Long short-term feature enhancement transformer for video small object detection. <em>ESWA</em>, <em>298</em>, 129631. (<a href='https://doi.org/10.1016/j.eswa.2025.129631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging temporal information is crucial for small object detection in videos. Existing methods typically incorporate long-term or short-term temporal information uniformly, neglecting distinct cues from different frames that are essential for small object detection. In this paper, we propose LSTT, an end-to-end multi-frame fusion network that concurrently extracts global scene context from long-term frames and fine-grained appearance and motion cues from short-term frames. First, we introduce a progressive spatiotemporal sampling module that sparsely samples long-range frames and densely samples short-range frames. Second, we design a spatiotemporal alignment encoder module to extract frame-level temporal and spatial pixel features. Finally, We propose a long short-term feature aggregation module that employs a dynamic query generator to derive adaptive queries by implicitly modeling motion relationships among short-term frames, and guides a cascaded fusion of aggregated features from long-term, short-term, and current frames to fuse temporal information. Compared to state-of-the-art methods, our LSTT achieves absolute gains of 1.4 % and 2.1 % in detection precision on VisDrone-VID and UAVDT datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jinsheng Xiao and Wenbo Liu and Ruidi Chen and Yuchen Yan and Wei Yang},
  doi          = {10.1016/j.eswa.2025.129631},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129631},
  shortjournal = {Expert Syst. Appl.},
  title        = {LSTT: Long short-term feature enhancement transformer for video small object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scale-invariant information bottleneck for domain generalization. <em>ESWA</em>, <em>298</em>, 129628. (<a href='https://doi.org/10.1016/j.eswa.2025.129628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One significant challenge in deep learning is the inability to effectively generalize to new data whose distribution differs from that of the training data. Hence, domain generalization has received increasing attention in related fields. Classical methods aim to identify an invariant predictor that can recognize invariant representations across all the training domains. However, these methods limit the model to rely solely on invariant representations, which hinders the learning of important finer details. To address this challenge, we propose a Scale-invariant Information Bottleneck (SIB) method to identify both invariant and scale-invariant features. We subsequently introduce a tractable loss function derived from the variational analysis. This novel method captures more detailed information, including fine textures and unique characteristics, while also eliminating irrelevant or spurious representations by using information bottleneck. Finally, extensive experiments conducted on Rotated MNIST, Colored MNIST, Colored Fashion-MNIST, PACS, Office-Home and Camelyon17-WILDS validate the effectiveness of our SIB method in addressing the domain generalization problems. Notably, our approach outperforms 14 existing methods with an average improvement of 4.74 %. More significantly, it surpasses 6 recent, related methods by an average of 2.21 %. Furthermore, we demonstrate the superiority of our method through the analysis of hidden feature maps and representations.},
  archive      = {J_ESWA},
  author       = {Mengyao Li and Jiangshe Zhang and Chunxia Zhang and Junmin Liu and Lizhen Ji},
  doi          = {10.1016/j.eswa.2025.129628},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129628},
  shortjournal = {Expert Syst. Appl.},
  title        = {Scale-invariant information bottleneck for domain generalization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading. <em>ESWA</em>, <em>298</em>, 129627. (<a href='https://doi.org/10.1016/j.eswa.2025.129627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific and rational prices are determinant for the success of transfer of development rights (TDR). Nevertheless, previous studies largely overlook the multifaceted impacts of risks on pricing, hampering market participation and value revelation. This is especially relevant in the context of China’s inter-provincial construction land quota trading due to its broader scope and dynamic complexities. This study addresses this gap by proposing an integrated decision-making framework to identify TDR risk factors and determine the optimal pricing for TDR under risk sharing. Results show that among 28 identified risk factors across the trading lifecycle, pre-transaction (remediation application and remediation acceptance) risk factors exhibit lower weights (0.017 and 0.218) but demand greater responsibility from quota-sending governments (80.5% and 73.0%); quota transfer risk factors hold the highest weight (0.306), with nearly balanced responsibility sharing between trading parties; while post-transaction (remediation acceptance and post monitoring) risk factors (weighted at 0.215 and 0.218) should be borne mainly by quota-receiving governments (64.1% and 60.9%). A paradigmatic trading case study between Muli and Jiashan Counties empirically reveals that risk factors elevate the optimal price to 621171.89 yuan/mu—24.23% above the current national standard price—by increasing costs, reducing profits, decreasing the supply–demand ratio, and complicating ecological compensation. These findings underscore the importance of risk responsibility management and risk-based pricing mechanisms.},
  archive      = {J_ESWA},
  author       = {Jia-He Zhou and Yu-Jia Wei and Yu-Ming Zhu and Hong-Li Lin},
  doi          = {10.1016/j.eswa.2025.129627},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129627},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent urban on-street parking space management for autonomous vehicles. <em>ESWA</em>, <em>298</em>, 129626. (<a href='https://doi.org/10.1016/j.eswa.2025.129626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curbside lanes are valuable spatial assets, with on-street parking, driving, and other travel modes competing for the space. Autonomous vehicle (AV) transport is expected to park at the curbside for diverse purposes, raising conflicts between driving and parking in the city centre. This study presents a framework to determine on-street parking configurations under different traffic flow and parking supply scenarios for the downtown region. The main contribution stems from solving the macro-level parking configuration problem using customised metaheuristics while considering microscopic AV operations. We tested the framework using a road network comprising a downtown central business district and adjacent urban areas. Among the considered metaheuristics, the discrete particle swarm optimisation outperformed the genetic algorithm in minimising network-level travel delays but at the cost of higher computational time. Three main empirical findings are derived. First , parking lanes are more likely to be assigned to edges in downtown areas or those with lower traffic and driving speeds. Second , high parking supply negatively affects the macroscopic fundamental diagram by increasing congestion and reducing flow efficiency, but such an effect diminishes in congested networks. Third , there exists an optimal parking supply level (40 % in the case study) for most flow rate conditions that can help reduce congestion. The proposed framework was validated through a case study in Midtown Manhattan, New York City. This study provides valuable insights for urban and transportation agencies to manage on-street parking lane assignments to balance parking and driving demands in the AV transport era. The approach has broader applicability as it is transferable to human-driven vehicles and mixed autonomy scenarios.},
  archive      = {J_ESWA},
  author       = {Qiming Ye and Prateek Bansal and Yuxiang Feng and Simon Hu and Panagiotis Angeloudis},
  doi          = {10.1016/j.eswa.2025.129626},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129626},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent urban on-street parking space management for autonomous vehicles},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-session interest extraction for recommendation. <em>ESWA</em>, <em>298</em>, 129625. (<a href='https://doi.org/10.1016/j.eswa.2025.129625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, due to device privacy restrictions, sometimes we can only obtain anonymous users’ interaction behavior within a single session. This type of recommendation is called session-based recommendation. Modeling users’ interest based on session data is one of the core issues in session-based recommendation. However, most existing methods only model users’ interest within individual sessions, neglecting information propagation across sessions. This paper addresses this challenge by designing a contrastive learning module based on clustering to model inter-session information propagation. Specifically, in addition to propagating information within sessions using hypergraph convolution, a cluster algorithm is applied to group all nodes across sessions. Then a contrastive learning loss is designed based on the clustering results to facilitate information propagation across sessions, thereby explicitly modeling the semantic similarity of similar items across different sessions. We call our model Clustering Hypergraph Neural Network (CluHNN). CluHNN explicitly learns the correlation between similar items across different sessions, improving the quality of item representations and, consequently, yielding better interest representations through cross-session information propagation. Experimental results on two real-world datasets show the effectiveness of the proposed CluHNN. For example, in terms of MRR@20, CluHNN achieves significant improvements of 1.3 % and 2.0 % relative gains over the strongest baseline, respectively.},
  archive      = {J_ESWA},
  author       = {Jin Jin and Chaoqun Li and Liangxiao Jiang},
  doi          = {10.1016/j.eswa.2025.129625},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129625},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-session interest extraction for recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images. <em>ESWA</em>, <em>298</em>, 129624. (<a href='https://doi.org/10.1016/j.eswa.2025.129624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a burgeoning theme in optical remote sensing image (ORSI) analysis, salient object detection (SOD) plays a vital role in traffic monitoring, agriculture, disaster management, and other fields. However, the existing ORSI-SOD methods are all single-modal (RGB images primarily), which suffer from performance drop when facing complex scenes (e.g., intricate backgrounds, low contrast scenes, and similar objects). To address this challenge, we introduce estimated depth map to complement RGB image in ORSI-SOD for the first time, which provides 3D geometric cues to improve detection accuracy in complex scenes, thus advancing ORSI-SOD from single-modal to multi-modal. Furthermore, we design a novel pretraining framework: multi-modal reconstructed image pretraining (MMRIP) to pretrain SOD model in multi-modal ORSI-SOD. MMRIP initially utilizes a masked autoencoder (MAE) to restore the masked RGB image; subsequently, it feeds the restored RGB image and clean depth map to the SOD model to generate the saliency map, which can help SOD model more effectively integrate cross modal information and extract better feature. Besides, we present a simple RGB-D SOD model, namely SimSOD, which is pretrained by MMRIP for ORSI-SOD. SimSOD has two major components: DFormer (encoder) and MLP head (decoder). Specifically, we first input RGB image and depth data into the encoder to generate four multi-scale features, then use the decoder to fuse these features and yield the prediction result. Without bells and whistles, our proposed method outperforms the state-of-the-art methods on three public ORSI-SOD datasets. The code can be accessed at: https://github.com/Voruarn/MMRIP .},
  archive      = {J_ESWA},
  author       = {Yuxiang Fu and Wei Fang},
  doi          = {10.1016/j.eswa.2025.129624},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129624},
  shortjournal = {Expert Syst. Appl.},
  title        = {Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An approach for linking dynamic network information models based on ontology matching. <em>ESWA</em>, <em>298</em>, 129622. (<a href='https://doi.org/10.1016/j.eswa.2025.129622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic network information models are typically heterogeneous and isolated systems that impede effective interoperability, significantly hindering end-to-end service integration and data sharing across network segments. To address this challenge, we propose a new approach for linking heterogeneous dynamic network models based on ontology matching, which can be applied in various domains utilizing dynamic networks. For ontologies matching we use different existing duplicate detection algorithms but we reduce the computational complexity of ontology matching due to splitting initial set of matched entities into a number of subsets using domain knowledge. Using telecommunications as case study, we represent operator networks as knowledge graphs and match them with standardized model ontologies using business process context to create an Extended Operator Network Ontology. Our approach ensures linking of dynamic network models used in operators information systems that is of primary importance for implementing complex business processes, and providing integrated services while maintaining existing models.},
  archive      = {J_ESWA},
  author       = {Tianxing Man and Igor Kulikov and Jiafeng Yang and Nataly Zhukova},
  doi          = {10.1016/j.eswa.2025.129622},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129622},
  shortjournal = {Expert Syst. Appl.},
  title        = {An approach for linking dynamic network information models based on ontology matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem. <em>ESWA</em>, <em>298</em>, 129621. (<a href='https://doi.org/10.1016/j.eswa.2025.129621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional irregular layout problem, which involves placing convex or non-convex components within a confined boundary without overlaps, is NP-complete and widely encountered in industrial applications such as glass cutting, garment manufacturing, and packaging. To overcome the limitations of existing methods in computational efficiency and material utilization, we propose a new hybrid algorithm IDE-V-NFP-MIP: (1) An improved differential evolution (IDE) algorithm combines the memory mechanism to guide the crossover and mutation operations; (2) A vector No-Fit Polygon (V-NFP) algorithm effectively handles complex geometric constraints, including voids and degradation; (3) A mixed-integer programming (MIP) model ensures accurate layout and non-overlapping constraints. Experimental results demonstrate superior performance: IDE ranked first in CEC2022 Friedman tests, while practical applications show 22.10% reduction in board length and 41.47% improvement in filling rate. The framework successfully handles real-world garment cutting applications and large-scale problems up to 1,280 polygons, demonstrating significant improvements in both computational efficiency and solution quality for industrial layout optimization. The source code for the algorithm is available at https://github.com/xhj-6/IDE-V-NFP-MIP .},
  archive      = {J_ESWA},
  author       = {Huijie Xu and Qifang Luo and Yongquan Zhou},
  doi          = {10.1016/j.eswa.2025.129621},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129621},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach. <em>ESWA</em>, <em>298</em>, 129620. (<a href='https://doi.org/10.1016/j.eswa.2025.129620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of smart grid security, the precise identification of False Data Injection Attack (FDIA) is crucial for ensuring the stable operation of power systems. Existing approaches for handling measurement data often overlook the correlation between local time–frequency variations caused by FDIA nodes and global spatial information in analyzing measurement data, leading to inaccurate localization. To address this issue, we propose a novel approach: a multilevel wavelet spatio-temporal map embedded FDIA localization method. Initially, a multi-resolution time–frequency signal decomposition model is utilized to separate the time–frequency mutation signals induced by FDIA from the measurement data using fast wavelet transform. Subsequently, a multi-channel time–frequency feature extraction technique is developed to capture the mutation characteristics of FDIA in time–frequency signals. This involves extracting detailed features of the time–frequency signals pre and post-attack via a multi-channel convolution operation encompassing “temporal-local-global” aspects. Finally, we propose an FDIA localization model based on multi-level graph wavelet embedding. The model embeds spatio-temporal information into time–frequency features via graph wavelet convolution and builds a spatio-temporal dependency map through multi-level neighborhood sampling. To mitigate measurement loss and noise, graph smoothing regularization and graph dropout are introduced during training. A graph attention mechanism further captures spatio-temporal dependencies among nodes, enabling accurate FDIA localization. Experimental results verify the effectiveness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhaoyang Qu and Feng Liang and Nan Qu and Tao Jiang and Xiaoyu Xu},
  doi          = {10.1016/j.eswa.2025.129620},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129620},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management. <em>ESWA</em>, <em>298</em>, 129619. (<a href='https://doi.org/10.1016/j.eswa.2025.129619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the integration of the 5G-enabled Internet of Things has revolutionized through high-speed data transmission, ultra-low latency, and interconnectivity of massive devices. However, the proliferation of 5G-enabled Internet of Things introduces major challenges, such as energy inefficiency and unreliable data delivery in the resource constrained Internet of Things devices. This research proposes a novel Q-Learning-based optimization framework tailored to address these challenges by integrating Radio Frequency energy harvesting, adaptive beamforming, and dynamic resource allocation within the massive Multiple-Input-Multiple-Output system. The proposed model utilizes reinforcement learning to manage the network resources including modulation schemes, beamforming, and energy allocation. By modeling the optimization problem as a Markov Decision Process, the proposed framework dynamically adapts to real-time network conditions to enhance energy efficiency, reliable data delivery, and throughput. The experimental validation demonstrates that the Q-Learning-based strategy effectively optimizes the energy efficiency as well as data transmission and achieves a higher energy efficiency of 98.87 %, higher packet delivery ratio of 98.85 %, lower latency of 1.5 ms, and higher throughput of 200Mbps compared to existing methodologies. This result indicates that the proposed Q-Learning-based framework has the potential to enhance the sustainability and reliability of the 5G-enabled Internet of Things.},
  archive      = {J_ESWA},
  author       = {Bavethra Murthy and Palani Uthirapathy},
  doi          = {10.1016/j.eswa.2025.129619},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129619},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-behavioral recommendation algorithm based on decoupled graph convolution. <em>ESWA</em>, <em>298</em>, 129618. (<a href='https://doi.org/10.1016/j.eswa.2025.129618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation models primarily rely on display feedback and typically utilize a single type of user-item interaction data, which often results in significant data sparsity issues. In contrast, multi-behavioral recommendation models leverage various behaviors such as browsing, favoriting, and other interactions. These additional behaviors help improve the prediction of user-item interactions. Existing multi-behavioral recommendation methods often overlook the potential factors influencing multi-behavioral interactions and the differences between various behavior types. In this study, we introduce a multi-behavioral recommendation algorithm utilizing decoupled graph convolution (MBR-DGC), which effectively mitigates the data sparsity of the target behaviors and improves recommender system performance by capturing the differences between the semantics of different behaviors. Specifically, we construct multiple non-overlapping independent isomorphic graphs and separate potential factors affecting the interactions among users, items, and behaviors using decoupled convolutional networks to reconstruct the node features of users in different behaviors. Afterwards, multi-behavioral features of users are aggregated using contrastive learning to achieve personalized multi-behavioral information aggregation. Experimental results on multiple datasets show that MBR-DGC effectively leverages multi-behavioral data, significantly enhancing recommendation performance compared to other state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xu Yu and Pengju Ding and Jie Yu and Junyu Lin and Lei Guo and Guanfeng Liu and Liang Xi},
  doi          = {10.1016/j.eswa.2025.129618},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129618},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-behavioral recommendation algorithm based on decoupled graph convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy. <em>ESWA</em>, <em>298</em>, 129617. (<a href='https://doi.org/10.1016/j.eswa.2025.129617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swarm intelligence aggregation system represents a key capability in current-generation UAV swarm, demonstrating robust collective intelligence. Currently, leveraging Multi-Agent Deep Reinforcement Learning (MADRL) offers a promising approach for building UAV swarm intelligence aggregation systems. However, the MADRL methods are difficult to cope with the challenge of exponential increase in computation when facing the collaboration problem of large-scale swarms, and the agents also have the problem of partial observability of the environment. This paper proposes an Information Aggregation Decision Method for UAV swarm based on Joint Communication and Proximal Strategy (IADM-JCPS). This method designs a communication information aggregation (CIA) network to enable UAVs to gather observation information from neighbor UAVs, and uses the attention mechanism to screen important information. Then, the aggregated information is used as part of the input of the policy network to increase the information diversity of the decision-making process. Finally, the gradient clipping mechanism is used to trim the policy gradient to enhance the stability of the training process. A UAV swarm multi-target tracking (MTT) mission scenario is designed to verify the effectiveness of the proposed IADM-JCPS algorithm. Experimental results show that the proposed algorithm is superior to the baseline algorithm in terms of task collaboration and scalability.},
  archive      = {J_ESWA},
  author       = {Zhaotian Wei and Ruixuan Wei},
  doi          = {10.1016/j.eswa.2025.129617},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129617},
  shortjournal = {Expert Syst. Appl.},
  title        = {An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-based trajectory planning for AGVs in dynamic environment. <em>ESWA</em>, <em>298</em>, 129616. (<a href='https://doi.org/10.1016/j.eswa.2025.129616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a learning-based framework for rapid trajectory planning of autonomous ground vehicles (AGVs) in dynamic environments. The approach integrates optimization techniques with deep learning to design a real-time planner capable of generating kinematically feasible trajectories. A continuous iterative method is first developed for dataset construction, enabling efficient generation of optimal trajectory sets. Based on this dataset, a neural network is trained to learn the mapping between AGV states and actions while capturing their temporal dependencies. During online planning, the trained model produces decision actions from the current state and sensor feedback, enabling real-time planning of safe and feasible trajectories. Results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_ESWA},
  author       = {Runda Zhang and Zhida Xing and Senchun Chai and Yuanqing Xia and Runqi Chai},
  doi          = {10.1016/j.eswa.2025.129616},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129616},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning-based trajectory planning for AGVs in dynamic environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Model-agnostic post-hoc explainability for recommender systems. <em>ESWA</em>, <em>298</em>, 129608. (<a href='https://doi.org/10.1016/j.eswa.2025.129608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems often benefit from complex feature embeddings and deep learning algorithms, which deliver sophisticated recommendations that enhance user experience, engagement, and revenue. However, these methods frequently reduce the interpretability and transparency of the system. In this research, we develop a systematic application, adaptation, and evaluation of deletion diagnostics in the recommender setting. The method compares the performance of a model to that of a similar model trained without a specific user or item, allowing us to quantify how that observation influences the recommender, either positively or negatively. To demonstrate its model-agnostic nature, the proposal is applied to both Neural Collaborative Filtering (NCF), a widely used deep learning-based recommender, and Singular Value Decomposition (SVD), a classical collaborative filtering technique. Experiments on the MovieLens and Amazon Reviews datasets provide insights into model behavior and highlight the generality of the approach across different recommendation paradigms.},
  archive      = {J_ESWA},
  author       = {Irina Arévalo and Jose L. Salmeron},
  doi          = {10.1016/j.eswa.2025.129608},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129608},
  shortjournal = {Expert Syst. Appl.},
  title        = {Model-agnostic post-hoc explainability for recommender systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS. <em>ESWA</em>, <em>298</em>, 129607. (<a href='https://doi.org/10.1016/j.eswa.2025.129607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable assessment of precipitation is crucial for incorporating meteorological and hydrological research into industrial and agricultural applications. Accurately estimating precipitation is a challenging task. In addressing this problem, we propose to develop AERO-Net, a novel deep learning framework designed to correct spatial, temporal, and amplitude biases in WRF-ROMS precipitation data. The integration of the Weather Research and Forecasting (WRF) model with the Regional Ocean Modeling System (ROMS) makes it a valuable tool for precipitation forecasting. AERO-Net incorporates autoencoders (AEs) for handling fluctuation and generalizing latent space representations, a latent module (LM) for transforming WRF-ROMS data into bias-corrected representations, a residual module (RM) for error minimization via boost, and a calibration module (CM) for improving near-zero precipitation. Empirical results show that AERO-Net achieves a balanced error reduction across precipitation cohorts grouped by intensity, reducing the macro-averaged root mean square error (macro RMSE) by 3.6 mm/day and the macro-averaged mean absolute deviation (macro MAD) by 0.68 mm/day compared to the original WRF-ROMS. AERO-Net is seen to improve the correlation coefficient (CC) by 26.32 %, increasing it from 0.38 to 0.48, in comparison to the original WRF-ROMS. These findings underscore its potential as an effective solution for enhancing precipitation estimates in high-resolution modeling systems.},
  archive      = {J_ESWA},
  author       = {Passin Pornvoraphat and Kanoksri Sarinnapakorn and Ken-Ichi Fukui and Peerapon Vateekul},
  doi          = {10.1016/j.eswa.2025.129607},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129607},
  shortjournal = {Expert Syst. Appl.},
  title        = {AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography. <em>ESWA</em>, <em>298</em>, 129606. (<a href='https://doi.org/10.1016/j.eswa.2025.129606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are now achieving strong results for segmentation tasks, and the standard metric for evaluating methods is the Intersection over Union (IOU). However, we show in this paper that IOU is not efficient in evaluating the quality of segmentation for electron tomography (ET) images of zeolites. We perform a physics-oriented evaluation to ensure that the segmentation results yield coherent physical measures. We also formalize Mixed Supervised / Self-Supervised Contrastive Learning Segmentation (M3S-CLS), a semi-supervised approach using a contrastive learning approach that uses expert annotations to train the neural network model. A detailed comparison of this method with a standard cross-entropy-based model is provided. In addition, we publish a database of five fully segmented ET volumes along with corresponding baseline results. The code and the database is available at http://gitlab.univ-st-etienne.fr/labhc-iscv/M3S-CLS .},
  archive      = {J_ESWA},
  author       = {Cyril Li and Christophe Ducottet and Maxime Moreaud and Sylvain Desroziers and Valentina Girelli Consolaro and Virgile Rouchon and Ovidiu Ersen},
  doi          = {10.1016/j.eswa.2025.129606},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129606},
  shortjournal = {Expert Syst. Appl.},
  title        = {Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy. <em>ESWA</em>, <em>298</em>, 129605. (<a href='https://doi.org/10.1016/j.eswa.2025.129605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged objects often closely resemble their surroundings, causing standard RGB images to be confounded by background, texture, and color variations. This often leads to incomplete or absent target segmentation, reducing overall accuracy. To address this issue, we present a Deep Surrounding-Awareness Mirror Network (DSANet) for camouflaged object detection, leveraging depth information to expose objects incongruent with their environment, thus improving localization accuracy. First, a Convolutional Spatial Gating module processes batched RGB and depth inputs, suppressing extraneous background noise while isolating fine-grained segmentation and structural features and unifying channel representation. Subsequently, a Deep Surrounding-Awareness Localization module and a Contour-Guided Integrity Aggregation module collaboratively refine and merge multi-level features, focusing on the global form of camouflaged objects while iteratively enhancing segmentation detail. Finally, a Guided Residual Channel Attention module further refines low-layer structural cues. Extensive experiments on ten challenging benchmark datasets using four widely used evaluation metrics demonstrate that our method exhibited superior performance, outperforming 40 state-of-the-art methods. The results demonstrate the versatility of our model. The source code and results of our method are available at https://github.com/lixu11/DSANet.},
  archive      = {J_ESWA},
  author       = {Xu Li and Xiaosheng Yu and Peng Chen},
  doi          = {10.1016/j.eswa.2025.129605},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129605},
  shortjournal = {Expert Syst. Appl.},
  title        = {DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FTUAttack: Feature truncation unrestricted attack based on stable diffusion model. <em>ESWA</em>, <em>298</em>, 129604. (<a href='https://doi.org/10.1016/j.eswa.2025.129604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of adversarial example generation and defense, compared to restricted attacks with L p -norm constraints, unrestricted attacks without L p -norm constraints emanate better visual imperceptibility. Existing unrestricted attacks typically manipulate the semantic content of examples (e.g. texture or color) to generate adversarial examples. However, current works usually ignore multifaceted features or loss optimization strategy, which limits attack performance. In this paper, we draw inspiration from stable diffusion model and propose a unrestricted attack method called Feature Truncation Unrestricted Attack (FTUAttack) to achieve both better transferability and imperceptibility. Specifically, we promote the performance of unrestricted attacks from the perspectives of both diffusion principle and feature truncation for the first time. Firstly, we propose a Global Deep Feature Extractor (GDFE) module to truncate global feature for the subsequent diffusion denoising process. Secondly, to further boost the transferability, we design a novel Critical Latent Feature Extractor (CLFE) module to obtain critical local feature that need to be truncated during the denoising process and investigate the influence of the different segmentation ways on critical local feature. Thirdly, we propose Multi-Loss Fusion (MLF) strategy to balance the conflict between perturbations and examples’ quality by guiding the optimization direction. Extensive experiments on various model structures and datasets demonstrate the superiority of our attack over the existing attack methods.},
  archive      = {J_ESWA},
  author       = {Shaojie Han and Gangzheng Zhai and Kun Chen and Shihui Zhang},
  doi          = {10.1016/j.eswa.2025.129604},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129604},
  shortjournal = {Expert Syst. Appl.},
  title        = {FTUAttack: Feature truncation unrestricted attack based on stable diffusion model},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram. <em>ESWA</em>, <em>298</em>, 129603. (<a href='https://doi.org/10.1016/j.eswa.2025.129603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of labeling Electrocardiogram (ECG) has prompted researchers to use self-supervised learning to enhance diagnostic performance. Masked autoencoders (MAE) are a mainstream paradigm where models learn a latent representation of the signal by reconstructing masked portions of the ECG. However, existing methods lack a specific design for the spatial–temporal characteristics of ECG. Specifically, leads represent spatial projections of cardiac activity, while timestamps capture temporal patterns, and the two correspond to different axes of information. Existing MAE frameworks tend to unify them prematurely, potentially weakening critical local dependencies. In this paper, we propose a Spatial-Temporal Hierarchical Decoupled Masked Autoencoder (STHD-MAE). This framework decouples ECG into isolated leads or time steps in the shallow layer to capture local dependencies with different views, then aligns spatial–temporal representations and re-establishes global dependencies in the deep layer to comprehensively represent pathological information. We also design a medical report fusion module during pre-training, which uses cross-attention to align the ECG report text encoded by a medical language model with the signal’s latent representation, thereby guiding the encoder to focus on pathological information through implicit cross-modal learning. We validate the effectiveness of STHD-MAE on multiple downstream classification and reconstruction tasks. The results show that STHD-MAE outperforms existing self-supervised learning methods by approximately 2% in F1-scores for both coarse-grained and fine-grained classification performance, and its reconstruction quality also exceeds the baseline generative model.},
  archive      = {J_ESWA},
  author       = {Xiaoyang Wei and Zhiyuan Li and Yuanyuan Tian and Mengxiao Wang and Yanrui Jin and Weiping Ding and Chengliang Liu},
  doi          = {10.1016/j.eswa.2025.129603},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129603},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching. <em>ESWA</em>, <em>298</em>, 129602. (<a href='https://doi.org/10.1016/j.eswa.2025.129602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The local correspondence learning has gained increasing attention in image-text matching, which establishes fine-grained alignments between image regions and textual words to improve both interpretability and accuracy. While these approaches have made significant progress in identifying meaningful semantic correspondences, one critical limitation persists in current methods, i.e., overlooking the crucial spatial position information of visual regions in cross-modal interaction. To address this challenge, we propose a novel Geometric contextual Aggregation and Regional contextual Enhancement Network (GARE-Net) that introduces two innovative components: the Geometric Contextual Feature Aggregation (GCFA) module and the Regional Contextual Feature Enhancement (RCFE) module. Specifically, GCFA generates the spatial geometric information of visual regions to enhance the region features by feature aggregation. RCFE further refines the aggregated region features by constructing a region graph and graph convolution. Extensive experiments and analyses are conducted on Flickr30k and MSCOCO to evaluate the importance of our framework. The results demonstrate the superiority of our method in image-text matching. Moreover, the ablation studies and visualization case studies also highlight the importance of geometric contextual feature aggregation and regional contextual feature enhancement. The code is available at https://github.com/chinaBoy123/GARE-Net .},
  archive      = {J_ESWA},
  author       = {Fangming Zhong and Tao Zhou and Zhikui Chen and Suhua Zhang},
  doi          = {10.1016/j.eswa.2025.129602},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129602},
  shortjournal = {Expert Syst. Appl.},
  title        = {GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation. <em>ESWA</em>, <em>298</em>, 129600. (<a href='https://doi.org/10.1016/j.eswa.2025.129600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing quantum group decision-making models face significant challenges in the bid evaluation of engineering projects, including the strong subjectivity of expert evaluations, the difficulty in aggregating expert opinions, the large gap of expert opinions, and the complexity of expert psychological behaviors. To address these issues, this paper proposes a novel quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation. Firstly, a quantum Bayesian network is constructed to aggregate expert opinions and capture the interference effect among experts. Secondly, the matrix fluctuation grey correlation degree is defined and applied to the calculation of quantum interaction terms that reflect the intricate psychological behavior of experts. Subsequently, a decision item search model is proposed and applied to adjust preferences during the consensus reaching process, thereby narrowing the gap of expert opinions. The consensus effect optimization model is utilized to determine optimal values for unknown parameters within this process, effectively reducing the subjectivity of expert evaluations. Finally, the proposed model is applied to a bid evaluation of bridge anti-collision engineering project, which verifies the feasibility and effectiveness of the model, and evaluates the stability and superiority of the model through sensitivity analysis and comparative analysis.},
  archive      = {J_ESWA},
  author       = {Jiuru Zhu and Xinping Xiao and Congjun Rao},
  doi          = {10.1016/j.eswa.2025.129600},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129600},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks. <em>ESWA</em>, <em>298</em>, 129599. (<a href='https://doi.org/10.1016/j.eswa.2025.129599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical node detection is an important tool for measuring network robustness. The main purpose of critical node detection is to detect a set of nodes that cause the greatest damage to the network connectivity, and it has been applied in many fields such as social network analysis and traffic network management. As a classic non-deterministic polynomial time complete problem, critical node detection faces enormous challenges with the continuous expansion of network size. The existing methods are difficult to achieve a good balance between effectiveness and efficiency, especially when the scale of complex networks becomes larger. To this end, this paper proposes a dual population based critical node detection method (DPCND) to effectively and efficiently obtain a set of critical nodes, which utilizes the co-evolution of auxiliary population generated from reduced graph and main population generated from original graph to find the optimal solution. In the proposed algorithm, a dual population interaction mechanism consists of influence and expansion strategies is proposed for information exchange, where the influence strategy transfers candidate good solutions from the auxiliary population to the main population to improve search efficiency, and the expansion strategy provides node information of the main population to guide the expansion of search space for the auxiliary population. Finally, the experimental results on 20 real-world complex networks clearly demonstrate the effectiveness of the proposed algorithm comparing to the state-of-the-arts.},
  archive      = {J_ESWA},
  author       = {Lei Zhang and Xinyi Feng and Yuanyuan Ge and Zhanpeng Wang and Haipeng Yang},
  doi          = {10.1016/j.eswa.2025.129599},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129599},
  shortjournal = {Expert Syst. Appl.},
  title        = {DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem. <em>ESWA</em>, <em>298</em>, 129598. (<a href='https://doi.org/10.1016/j.eswa.2025.129598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern agriculture, efficiently picking and distributing fresh product is crucial for the competitiveness of smart farms within the globalized agricultural market. However, the integrated scheduling problem involving both picking and distribution processes has received limited attention in existing research. To bridge this gap, this study establishes a mathematical model with dual objectives: (1) minimizing the picking completion time and (2) reducing penalties incurred due to early or delayed deliveries. A novel two-stage evolutionary algorithm incorporating a restart mechanism is proposed to effectively balance the optimization of these objectives with a high degree of consistency. The algorithm features an efficient encoding scheme and advanced genetic operators, specifically designed to enhance exploration and exploitation based on the characteristics of the problem. A comprehensive set of test instances is generated and the proposed method is benchmarked against several state-of-the-art metaheuristics from the literature. Experimental results demonstrate that the proposed algorithm outperforms the competing approaches by a significant margin for solving the problem under consideration.},
  archive      = {J_ESWA},
  author       = {Yiran Pan and Xuan He and Nan Li and Zhonghua Miao},
  doi          = {10.1016/j.eswa.2025.129598},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129598},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm. <em>ESWA</em>, <em>298</em>, 129597. (<a href='https://doi.org/10.1016/j.eswa.2025.129597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful simulation of constrained differential evolution (CDE) algorithm for solving phase equilibrium calculation has first verified that heuristic optimization algorithms are effective ways to solve this kind of problems. Their insensitivity to initial values overcomes the limitations associated with two kinds of traditional methods, i.e., direct solution methods based on Newton’s method and indirect solution methods based on thermodynamic principles. This article proposes a constrained quadratic interpolation optimization algorithm (CQIO) for obtaining the satisfactory solutions of phase equilibrium calculation under given volume, temperature, and moles (NVT-flash). The proposed CQIO regards the total Helmholtz free energy of a NVT-flash problem as its objective function, while the moles vector and volume of a certain phase as its decision variables. The consistency between the four cases’ experimental results of CQIO and those of published articles demonstrates the effectiveness of CQIO in solving NVT-flash problems. Then the computational overhead and algorithmic stability of CQIO were analyzed. In Cases 1, 2 and 3, the average CPU time of CQIO compared to CDE has increased by 46.98 % , 54.56 % and 21.02 % respectively. The Std values of CQIO are significantly smaller than those of CDE in all cases except for Example 2. The proposed CQIO greatly promotes the application of heuristic algorithm in the field of phase equilibrium calculation.},
  archive      = {J_ESWA},
  author       = {Wangyu Tong and Baoduo Su and Yaqian Zhan},
  doi          = {10.1016/j.eswa.2025.129597},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129597},
  shortjournal = {Expert Syst. Appl.},
  title        = {An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets. <em>ESWA</em>, <em>298</em>, 129595. (<a href='https://doi.org/10.1016/j.eswa.2025.129595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a novel VRP variant integrating seasonal demand fluctuations, heterogeneous vehicle sources, and multi-endpoint constraints, focusing on the distribution of seasonal products in a steel parts enterprise. It tackles the complex vehicle routing problem with time windows involving heterogeneous fleets, which encompass different vehicle sources (owned and rented), types (fuel-powered and electric), capacities, ranges, and endpoints. To balance enterprise profitability, greenhouse gas emissions, and environmental quality, we develop a mathematical model centered on optimizing distribution costs, greenhouse gas emissions, and vehicle utilization. Drawing inspiration from ancient competitive activities, we propose a novel Huashan Swords Algorithm (HSSA). Through simulations using real enterprise data, we demonstrate the HSSA’s effectiveness, with comparative experiments against existing advanced algorithms highlighting its superiority. Applying the algorithm to design logistics distribution schemes, we conduct in-depth tests considering different customer groups and fuel station distributions. Analyzing the results from the perspectives of profitability, emissions, and environmental quality, we offer targeted operational suggestions for the enterprise based on its situation, geographical characteristics, and fiscal policies. Moreover, we provide recommendations to local governments on fuel station construction and vehicle subsidy policies, contributing practical solutions to both enterprise operations and regional development.},
  archive      = {J_ESWA},
  author       = {Zhang Yanhu and Yan Lijuan and Kong ShuMei and Miao Decheng},
  doi          = {10.1016/j.eswa.2025.129595},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129595},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch. <em>ESWA</em>, <em>298</em>, 129594. (<a href='https://doi.org/10.1016/j.eswa.2025.129594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting gold prices through the analysis of key economic indicators such as inflation rates, Government Bond Yields, and the U.S. Dollar Index, alongside historical Gold Prices, is crucial for enabling investors to better understand market dynamics and make vital decisions to maximize returns. However, previous studies have faced challenges in extracting hidden factors related to gold price prediction from diverse economic indicators, and the comprehensive exploration of gold price data is yet to be fully achieved. To address this, the present study introduces a mid to long-term gold price prediction model named DPformer. This model utilizes a patching strategy to investigate the relationships between different economic indicators and Gold Prices. It also employs a decomposition approach to discover the mid to long-term trend characteristics and yearly seasonal patterns of Gold Prices. The core of the model integrates a Transformer module, which is solely based on an Encoder structure, and enhances it with multiple attention mechanisms and convolutions. This enhancement allows the improved Transformer model to more effectively capture the long-term dependencies of Gold Prices. The empirical results demonstrate that DPformer consistently outperforms a suite of advanced models widely adopted in terms of mid to long-term forecasting accuracy, including LSTM, GRU, Transformer, DLinear, and PatchTST. Notably, for the 30-step gold price prediction task, DPformer achieves a 21.78 % reduction in Mean Squared Error compared to PatchTST. Moreover, by quantitatively analyzing how various economic indicators influence gold price forecasts, this study provides substantial support for investors in making informed decisions at critical moments.},
  archive      = {J_ESWA},
  author       = {Guanhao Bao and Yunbo Niu and Baisheng Cui and Wanying Ji},
  doi          = {10.1016/j.eswa.2025.129594},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129594},
  shortjournal = {Expert Syst. Appl.},
  title        = {Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches. <em>ESWA</em>, <em>298</em>, 129592. (<a href='https://doi.org/10.1016/j.eswa.2025.129592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a systematic mapping of machine learning in class imbalance scenarios, offering a broad overview of key challenges, promising emerging techniques, and established methodologies across various application domains. The investigation stands out by employing a hybrid search and selection protocol that combines methodological rigor with technical innovation. The adopted strategy integrated manual searches in reference sources with automated processes based on machine learning, semantic embeddings, and graph-based ranking algorithms. To enhance selection quality, the Quasi-Golden Set (QGS) method was used to build a reference set from manually selected articles – a critical foundation for calibrating and evaluating automated search strings. This combination ensured broad coverage of the topic while improving sensitivity and precision in identifying relevant studies. The initial analysis reviewed 25,593 publications. After screening and applying eligibility criteria, 468 articles were included in the final dataset. The results indicate that 55 % of the studies address multiple domains, with a strong predominance of tabular data ( 84 % ). SMOTE and hybrid approaches were among the most common techniques, present in 61 % of the studies. In terms of evaluation metrics, ROC-AUC was the most frequently used, followed by F1-score and accuracy – the latter noted for limitations in highly imbalanced scenarios. Building on these findings, we derive an empirically grounded taxonomy that links problem context, solution algorithms, and scenario-appropriate evaluation metrics, and we provide a minimal selection guideline table to support applied use. While sampling-based methods remain prevalent, deep learning approaches such as convolutional neural networks and graph-based models are increasingly adopted. Additionally, federated, contrastive, and semi-supervised learning are emerging as relevant paradigms, particularly suited for privacy-aware or low-label environments. This study consolidates current knowledge, identifies methodological and application gaps, and highlights trends that are likely to shape future research. It contributes both a comprehensive synthesis of the field and strategic insights for advancing machine learning techniques in the presence of class imbalance.},
  archive      = {J_ESWA},
  author       = {Gilberto Sussumu Hida and André Câmara Alves Do Nascimento},
  doi          = {10.1016/j.eswa.2025.129592},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129592},
  shortjournal = {Expert Syst. Appl.},
  title        = {Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches. <em>ESWA</em>, <em>298</em>, 129591. (<a href='https://doi.org/10.1016/j.eswa.2025.129591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process planning in reconfigurable manufacturing systems usually considers a single product, this reduces the efficiency of the overall production plan when multiple products are combined. This paper tackles the Multi-Product Process Planning Problem (MPPP), optimizing both individual process plans and their sequencing. We propose a 0–1 LP model, the model is relaxed by fixing the product sequencing variables and implemented in a Normal-Boundary Intersection method (NBI-es), the method uses a function for iteratively updating β values. Three metaheuristics are also developed: NSGA-II, and two variants of MOEA/D, one enhanced by Opposition-based learning (OBL). Computational experiments show that the update function enhances the performance of NBI over simple Normalized-Weighted Sum (NWS) method. Additionally, NBI-es performs better in HV metric for small size instances if it is given enough CPU times, while MOEA/D significantly outperforms NSGA-II on larger instances on most convergence and spread based metrics. OBL further enhances solution diversity for MOEA/D, albeit with less convergence. A special case of the MPPP is investigated, involving identical products: the Multi-Unit Process Planning (MUPP). An integrated approach was compared with a sequential separated approach. Results indicate that the integrated approach outperforms the separated method for smaller problem instances. Moreover, the analysis of high-quality MUPP solutions revealed a tendency towards diverse process plan combinations rather than repetitive identical ones.},
  archive      = {J_ESWA},
  author       = {Abdelkader Mechaacha and Fayçal Belkaid and Nadjib Brahimi},
  doi          = {10.1016/j.eswa.2025.129591},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129591},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs. <em>ESWA</em>, <em>298</em>, 129590. (<a href='https://doi.org/10.1016/j.eswa.2025.129590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing has attracted increasing attention for its environmental and economic benefits. Since it is difficult to achieve economies of scale when processing small amounts of remanufacturing jobs alone, these jobs are processed in the same job-shop for new jobs in some enterprises. The processing times of remanufacturing jobs are uncertain due to unpredictable status, leading to certain impacts on scheduling performance. Therefore, we address a flexible job-shop scheduling problem with new and remanufacturing jobs to minimize makespan. To solve this problem, a slack-based two-stage improved particle optimization algorithm is proposed. The first stage aims to yield a solution set with minimum makespan, while the second stage aims to search the best robust solution with maximum total slack from the set. Both stages are executed alternately to optimize makespan and total slack. Moreover, a position updating mechanism with genetic operators and a tabu search inspired local search strategy are implemented to improve algorithmic performance. Computational experiments are conducted using adapted benchmark problems and an industrial case to validate the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Jun Liu and Zhui Gui and An Li and Qiong Liu},
  doi          = {10.1016/j.eswa.2025.129590},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129590},
  shortjournal = {Expert Syst. Appl.},
  title        = {A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach. <em>ESWA</em>, <em>298</em>, 129589. (<a href='https://doi.org/10.1016/j.eswa.2025.129589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates and predicts green economic efficiency (GEE) across 248 Chinese cities from 2010 to 2021 using a three-stage network SBM model based on subsystems of economic production, social development, and environmental governance. To enhance accuracy in both assessment and forecasting, machine learning methods are incorporated, and the Dagum Gini coefficient is employed to analyze regional disparities. This study innovatively proposes a three-stage network SBM model to resolve the “black box” limitation of conventional DEA approaches, while a DEA-ML model is developed to achieve enhanced prediction accuracy. The results reveal that GEE in Chinese cities remains low, with the eastern region leading and the western region trailing. However, efficiency has improved since 2016, primarily driven by advancements in environmental governance. Regional disparities, largely attributed to interregional differences, are gradually decreasing. Among forecasting models, the backpropagation neural network (BPNN) delivers the highest accuracy, predicting sustained leadership in the east, strong growth in the northeast, and a reduction in national disparities. This study offers a comprehensive framework for evaluating and predicting GEE, providing valuable insights for sustainable development policies.},
  archive      = {J_ESWA},
  author       = {Zhishuo Zhang and Hu Liu and Yunpeng Gong and Huayong Niu},
  doi          = {10.1016/j.eswa.2025.129589},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129589},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization. <em>ESWA</em>, <em>298</em>, 129587. (<a href='https://doi.org/10.1016/j.eswa.2025.129587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid algorithm integrating a couple of individual evolutionary algorithms (sub-algorithms) is widely recognized as an effective approach to enhance both robustness and optimization performance. Nevertheless, such integration often destroys the structure of the sub-algorithm and makes it difficult to incorporate additional evolutionary algorithms. To address these limitations, this study introduces a novel framework, the Heterogeneous Alternating Evolutionary Algorithm (HAEA), designed to integrate multiple evolutionary algorithms while enabling the flexible addition, removal, and replacement of internal sub-algorithms. To facilitate the integration of a broad spectrum of sub-algorithms, this study draws inspiration from the particle swarm optimization algorithm to devise a suite of information indicators for the transmission of optimization information between sub-algorithms with disparate structures. Furthermore, HAEA is endowed with an adaptive mechanism that dynamically modifies the selection probabilities of its sub-algorithms based on their long-term and short-term performance throughout the evolutionary process. We conducted a comparative analysis of HAEA against all its sub-algorithms across three widely recognized function test sets: CEC2013, CEC2017, and CEC2022. Meanwhile, we applied the HAEA separately to basic metaheuristic algorithms and advanced evolutionary algorithms in recent years and conducted two comparative experiments. Both experimental results show that HAEA outperforms all sub-algorithms in terms of robustness and optimization performance. Its distinctive flexibility allows for the incorporation of additional superior evolutionary algorithms in the future, thereby enhancing its overall performance.},
  archive      = {J_ESWA},
  author       = {Taiyong Li and Tianhao Yi and Zhenda Hu and Wu Deng and Donglin Zhu and Zhilong Xie and Jiang Wu},
  doi          = {10.1016/j.eswa.2025.129587},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129587},
  shortjournal = {Expert Syst. Appl.},
  title        = {HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients. <em>ESWA</em>, <em>298</em>, 129586. (<a href='https://doi.org/10.1016/j.eswa.2025.129586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, free quadratic coefficients are proposed in order to deeply study the flexible criteria of synchronization problem for two kinds of fractional-order higher-dimension-valued neural networks (FOHDVNN) with usual neurons and threshold ones, respectively. First, the uniform system is constructed for two kinds of FOHDVNN which contains both fractional-order octonion-valued neural networks (FOOVNN) and fractional-order quaternion-valued neural networks (FOQVNN). Based on higher-dimension algebra multiplication rules, the studied FOHDVNN are directly decomposed into the eight or four subsystems in real-valued field. Subsequently, free quadratic coefficients are taken into the establishment of two types of Lyapunov-Krasovskii functional (LKF) which is newer and more general. Then, mainly based on the very recent lemmas and Lyapunov theories, the flexible criteria are generally acquired for the global Mittag-Leffler synchronization (MLSY) problem of FOHDVNN. The final criteria have the advantage in being easily calculated and widely used. It is worth noting that the optimal solutions of these criteria can be obtained through the genetic algorithm and the synchronization performance can be improved by optimizing the quadratic coefficients. Finally, three simulation examples are presented to express the availability and progress of the derived results.},
  archive      = {J_ESWA},
  author       = {Jianying Xiao and Yongtao Li},
  doi          = {10.1016/j.eswa.2025.129586},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129586},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex-order darwinian particle swarm optimization. <em>ESWA</em>, <em>298</em>, 129584. (<a href='https://doi.org/10.1016/j.eswa.2025.129584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Particle Swarm Optimization (PSO) algorithm has been one of the most effective methods for solving various complex optimization problems. However, non-adaptive versions of the PSO do not use historical information for performance enhancement and suffer from performance degradation problems. This paper presents a Complex-Order Darwinian PSO (CoDPSO) algorithm, which effectively enhances the performance of the PSO. A complex-order derivative mechanism is introduced into the velocity update rule to improve local exploitation using historical velocity information. Additionally, a Degradation Elimination (DE) strategy is designed to mitigate performance drop during the optimization process. Sensitivity analysis is conducted to evaluate the impact of control parameters on the algorithm’s behavior, demonstrating its robustness across a wide range of settings. Comparative experiments on CEC 2022 benchmark functions show that the CoDPSO outperforms other PSO variants in terms of accuracy, stability, and convergence. Wilcoxon statistical tests further confirm the significance of these improvements. The experimental results indicate the feasibility and efficiency of the CoDPSO.},
  archive      = {J_ESWA},
  author       = {Xiaobo Wu and Liping Chen and Huafeng Li and António M. Lopes and Chuang Liu and Yangquan Chen and Yi Chai},
  doi          = {10.1016/j.eswa.2025.129584},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129584},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complex-order darwinian particle swarm optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions. <em>ESWA</em>, <em>298</em>, 129583. (<a href='https://doi.org/10.1016/j.eswa.2025.129583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting public opinion trends during major infectious disease outbreaks is critical for guiding effective public health responses. However, predicting public opinion remains challenging because it is influenced by socio-economic, psychological, and media factors. This paper presents a novel framework for predicting public opinion trends related to significant infectious diseases, with a focus on COVID-19 as a case study. The proposed framework identifies the key factors influencing public opinion development and enables both point and interval predictions. The framework uses information ecology theory and applies the NSGA-II algorithm to select the features that best drive public opinion trends. By incorporating this framework, accurate point forecasts are produced alongside prediction intervals, effectively quantifying the uncertainty inherent in public opinion dynamics. This approach minimizes the quality-driven loss function to generate precise prediction intervals, providing decision-makers with critical insights into public opinion fluctuations during epidemics. The results offer valuable, real-time public sentiment warnings, supporting timely and effective interventions in epidemic prevention and control efforts.},
  archive      = {J_ESWA},
  author       = {Futian Weng and Meng Su and Petr Hajek and Mohammad Zoynul Abedin},
  doi          = {10.1016/j.eswa.2025.129583},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129583},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism. <em>ESWA</em>, <em>298</em>, 129581. (<a href='https://doi.org/10.1016/j.eswa.2025.129581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge for multimodal multi-objective problem (MMOP) resolution lies in maintaining synergistic interactions between convergence and diversity. However, the existing algorithms usually consider convergence-first, which neglect to consider both diversity and convergence into account during the evolutionary process. Likewise, the optimization methods tend to gravitate toward locally optimal regions rapidly, leading to lose diversity for the local PS. This paper proposes a Deep Reinforcement Learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism (DRLMMEA) to investigate the impact of different operator selection on the performance of MMEAs, which greatly helps to balance the convergence and diversity. DRLMMEA utilizes Q-Network to select the operator with the highest reward to enhance the population’s search ability. An improved sorting method (ISM) based on neighborhood dominance updates the population by sorting individuals according to their convergence quality, thereby enhancing convergence performance in the objective space. Moreover, this study proposes a series-parallel mechanism, a series structure enhances the diversity in the decision space, while the parallel structure reduces the computational burden of the algorithm evidently. The proposed Deep Reinforcement Learning-assisted operator selection mechanism, which enables effective balance between diversity and convergence, and an improved crowding distance approach that enhances convergence performance. DRLMMEA undergoes comprehensive testing against 6 contemporary approaches using MMF and IDMP benchmark problems, achieving supremacy in 4 principal performance metrics according to experimental findings. The multimodal gearbox parameter optimization is addressed using the proposed DRLMMEA, which demonstrates superior performance against 6 algorithms in comparative evaluations. It has demonstrated a significant role in solving the MMOPs with the imbalance between convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Ying Huang and Xiaojian Cao and Benben Zhou and Wei Li and Shuling Yang and S.M. Shafi and Zhou Yang},
  doi          = {10.1016/j.eswa.2025.129581},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129581},
  shortjournal = {Expert Syst. Appl.},
  title        = {A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evolutionary multitasking optimization based on cross-task association mapping strategy. <em>ESWA</em>, <em>298</em>, 129580. (<a href='https://doi.org/10.1016/j.eswa.2025.129580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multitasking optimization, knowledge transfer between tasks through subspace generation has been widely employed to enhance the convergence performance of algorithms. However, this approach fails to account for the inter-task knowledge mapping relationships. Therefore, cross-task knowledge transfer during the optimization process remains inherently blind, potentially leading to mismatched subspace information and consequently degrading the algorithm’s performance. To address this issue, this paper proposes a multitask evolutionary algorithm based on an association mapping strategy and an adaptive population reuse mechanism, namely PA-MTEA. Specifically, to fully represent the correlations between multitask domains and enhance the adaptability of transfer solutions in target tasks, this paper introduces a subspace projection strategy based on partial least squares, which achieves the correlation mapping between the source and target tasks during the dimensionality reduction of the search space. Additionally, to further enhance knowledge transfer across tasks, an alignment matrix is obtained by adjusting the subspace Bregman divergence after deriving the respective subspaces, minimizing variability between task domains. Finally, to balance the global exploration of algorithms with local exploitation, an adaptive population reuse mechanism based on the residual structure is designed. This mechanism reuses historically successful individuals to guide the evolutionary direction of the population, thus improving the algorithm’s convergence performance. Experimental results on various benchmark suites and real-world cases demonstrate that PA-MTEA exhibits significantly superior performance compared to six other advanced multitask optimization algorithms.},
  archive      = {J_ESWA},
  author       = {Tao Yin and Lizhong Yao and Xin Zong and Pengjie Qin and Haoming Dong},
  doi          = {10.1016/j.eswa.2025.129580},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129580},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evolutionary multitasking optimization based on cross-task association mapping strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation. <em>ESWA</em>, <em>298</em>, 129578. (<a href='https://doi.org/10.1016/j.eswa.2025.129578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of different tissues within blastocysts is essential for embryologists to objectively observe and evaluate embryos, thereby contributing to a higher success rate of in vitro fertilization treatment. Inspired by the primary observation of skeletal patterns and boundary information by clinical doctors, we present an interesting task-aware view for blastocyst segmentation with semi-supervised learning, focusing on task-invariant and task-specific dependencies of segmentation. Firstly, we explore one strong-correlation task with bidirectional transformation between its outputs and the segmentation results, and another weak-correlation task with monodirectional transformation from segmentation maps. The correlation among different tasks inspires us to propose Task-Aware Smoothness (TAS) Assumption , thereby deducing different types of task-aware consistency. Then, a new Unified Task-aware Consistency Interaction (UniTask+) framework is developed to unify and fully take advantage of these strong, weak, and strong-to-weak task-aware consistency. It is comprised of a medical segmentation (MS) branch to implement segmentation and two extra branches performing strong/weak-correlation tasks based on the same backbone. Concretely, a level-set (LS) branch promotes the strong consistency while a point-set (PS) branch stimulates the weak consistency with underlying task perturbations. Numerous experiments have been conducted on the inner cell mass (ICM), blastocyst, proving the effectiveness of our tactics. Furthermore, we have also conducted experiments with datasets from the left atrium (LA), which shares similar structural features with embryos, to validate the robustness of the model. Our methods have shown prominent improvements over up-to-date SSL methods, which advocates our precedent hypothesis.},
  archive      = {J_ESWA},
  author       = {Hua Wang and Linwei Qiu and Jingfei Hu and Jicong Zhang},
  doi          = {10.1016/j.eswa.2025.129578},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129578},
  shortjournal = {Expert Syst. Appl.},
  title        = {UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval. <em>ESWA</em>, <em>298</em>, 129577. (<a href='https://doi.org/10.1016/j.eswa.2025.129577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has been widely used in large-scale multimedia retrieval due to its advantages in terms of low storage cost and computational efficiency. Deep hashing algorithms can jointly learn semantic features and hash functions, encoding the original data into compact binary codes with significant discriminative power. However, in multi-label scenarios, especially when the number of samples is extremely large, a high negative-positive imbalance may occur, particularly when the proportion of negative samples is too high, which can lead to bias in the semantic relationships between the learned images. To solve this problem, symmetric losses such as focal loss were proposed, which treat positive and negative samples equally, but the retrieval results are suboptimal. This may be because the equal-weighted processing strategy causes the model to over-focus on hard negative samples and ignore the learning of positive sample features. Besides, mislabeled negative samples, especially those with a probability close to 1, can lead the model to learn incorrect features, harming its discrimination ability, reducing accuracy and recall, and causing overfitting and poor generalization. Accordingly, this paper proposes a novel hashing model, Deep Asymmetric Semantic Hashing with Probability Shifting framework (DASH-PS), for discriminative binary code learning. Specifically, by combining asymmetric focusing strategy and probability shifting strategy, asymmetric semantic loss is designed to solve negative-positive imbalance and ground-truth mislabeling. To keep the contribution of positive samples while focusing on hard negative samples, asymmetric focusing strategy is proposed to decouple negative and positive samples and assign different attenuation factors. By offsetting the probability of negative samples, probability shifting strategy completely discards easy negative samples and very hard negative samples suspected of being mislabeled. Additionally, an adaptive asymmetric learning mechanism is proposed to reduce the fixed difference in average probabilities between positive and negative samples, thereby simplifying hyperparameter selection and improving retrieval efficiency. Extensive experimental results on multiple benchmark datasets validate that our DASH-PS outperforms various state-of-the-art hashing methods. The code for the implementation of our DASH-PS framework is available at https://github.com/QinLab-WFU/DASH-PS.},
  archive      = {J_ESWA},
  author       = {Yongyue Fu and Qibing Qin and Jinkui Hou and Congcong Zhu and Lei Huang and Wenfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129577},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129577},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed tensor autoencoder with memory for video anomaly detection. <em>ESWA</em>, <em>298</em>, 129576. (<a href='https://doi.org/10.1016/j.eswa.2025.129576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video data can be naturally represented as tensors. Despite great progress in anomaly detection with memory-augmented autoencoders, the memory module therein can only handle vectors and inevitably breaks tensor structures, thus leading to performance degradation. Moreover, after the mapping of the encoder, some abnormal features may directly fall into the normal convex polytope, as autoencoders only use the output error to guide the construction of latent variables without imposing any constraint. The memory module can not handle these abnormal features, so that the abnormal observations may not be identified. To solve these problems, we propose a Physics-Informed Tensor AutoEncoder (PITAE) framework, which incorporates both neural networks and physical laws, i.e., tensor operation rules. Specifically, we design a tensor decomposition network followed by an explicit tensor operation to decompose the latent variable into low-rank and sparse components, and only the low-rank component is inputted to the decoder. In this way, we reserve the tensor structure and meanwhile impose a low-rank constraint on the latent variable, thereby compressing the features of normal samples into a ”smaller” region where anomalies are less likely to fall into. Consequently, the non-low-rank anomalies can be identified. But the low-rank anomalies may still not be identified. To further solve this problem, we design a tensor Memory module, and the overall model is named as PITAEM. Finally, based on the proposed framework, we design a novel composite anomaly score to identify anomalies of various kinds. Experiments on various video datasets demonstrate the effectiveness of the proposed method, especially in the small data regime.},
  archive      = {J_ESWA},
  author       = {Jianan Liu and Chunguang Li},
  doi          = {10.1016/j.eswa.2025.129576},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129576},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-informed tensor autoencoder with memory for video anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust medical image encryption technique using inverse cosine chaotic map. <em>ESWA</em>, <em>298</em>, 129574. (<a href='https://doi.org/10.1016/j.eswa.2025.129574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid proliferation of digital imaging technologies, the need for robust and lightweight image encryption techniques has become increasingly critical, particularly for medical, military, and personal data applications. In this paper, we propose a novel image encryption scheme based on a one-dimensional inverse cosine chaotic map (1D-ICC), which introduces a highly sensitive and structurally complex nonlinear dynamical system. The proposed method integrates a dynamic Josephus-based intra-block scrambling mechanism, a global zigzag permutation strategy, and an adaptive diffusion process guided by chaotic sequences, thereby enhancing the confusion and diffusion characteristics of the cipher. Unlike conventional approaches, our scheme dynamically derives the encryption key from the SHA-512 hash of the original image, ensuring both sensitivity to plaintext changes and resistance to known-plaintext and chosen-plaintext attacks. The use of the 1D-ICC map, featuring a tunable control parameter r 5 enables rich chaotic behavior even in one dimension, reducing computational complexity without sacrificing security. Comprehensive experiments validate the robustness and efficiency of the encryption scheme, with performance metrics including correlation coefficients below 0.003, information entropy of 7.9993, a Number of Pixels Change Rate (NPCR) of 99.61 %, and a Unified Averaged Changed Intensity (UACI) of 33.42 %. These results demonstrate that our method surpasses several existing techniques in both security strength and computational performance, underscoring the potential of the 1D-ICC map for practical image encryption applications.},
  archive      = {J_ESWA},
  author       = {Jackson J and Perumal R},
  doi          = {10.1016/j.eswa.2025.129574},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129574},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust medical image encryption technique using inverse cosine chaotic map},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing text classification with neural label embedding and weakly-supervised learning. <em>ESWA</em>, <em>298</em>, 129569. (<a href='https://doi.org/10.1016/j.eswa.2025.129569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the widespread adoption of deep-learning-based models in a range of linguistic tasks including the fundamental text classification. These deep neural networks, however, often face challenges due to the limited availability of large-scale training data with high-quality label annotations. Furthermore, while supervised learning has proven to be superior in training sentence representations for downstream tasks like text classification, this aspect has received relatively little attention. In this study, a novel model named L abel Em bedding joint with We akly-supervised C lassification ( LemWec ) is proposed, which aims to establish a unified framework by combining supervised sentence embedding with multiclass classification. For supervised sentence embeddings, the model incorporates seed information such as label names and designs an encoder network with a new pooling layer. Additionally, the model adopts a pseudo-labeling approach to leverage a substantial amount of unlabeled samples. This approach specifically addresses the drawback of generating pseudo-labels with the highest confidence and introduces a noise adaptation method to mitigate this issue. The results of extensive experiments conducted on four real-world datasets demonstrate that the proposed LemWec model can significantly enhance the performance of text classification when compared to a comprehensive set of baselines.},
  archive      = {J_ESWA},
  author       = {Xiao Jing and Zhe Li and Zhiang Wu and Dejun Mu},
  doi          = {10.1016/j.eswa.2025.129569},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129569},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing text classification with neural label embedding and weakly-supervised learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data. <em>ESWA</em>, <em>298</em>, 129568. (<a href='https://doi.org/10.1016/j.eswa.2025.129568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell clustering plays a vital role in single-cell RNA sequencing (scRNA-seq) data analysis. Although many deep cell clustering methods have been proposed to cluster the scRNA-seq data, they overlook the structural partitioning objectives during the representation learning process, leading to challenges with non-linearly separable structures. In this paper, we present a novel end-to-end deep kernel cell clustering model for scRNA-seq data based on self-supervised ZINB-based kernel representation learning, named scDKC, which simultaneously learns cell kernel representations and identifies cell clusters. Specifically, a kernel-aid hybrid representation learning encoder is developed to effectively learn the separable kernel representation of cells, consisting of cells’ expression characteristics and cell-cell topological interactions. To guide the direction of kernel representation learning, a ZINB-based kernel representation learning decoder is designed by capturing the global probabilistic structure, the representation and the cell graph structure of the scRNA-seq data. By leveraging the clustering self-supervised strategy, representation self-supervised strategy, ZINB-based distribution self-supervised strategy, and kernel self-supervised strategy, scDKC optimizes cell cluster label assignment and learns cell kernel representations through a joint mutual self-supervised mechanism. Extensive experiments on 15 real scRNA-seq datasets, comparing scDKC with 10 competing methods, highlight its competitive advantages.},
  archive      = {J_ESWA},
  author       = {Lina Ren and Maoxuan Yao and Ruizhang Huang and Yongbin Qin},
  doi          = {10.1016/j.eswa.2025.129568},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129568},
  shortjournal = {Expert Syst. Appl.},
  title        = {Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dual uncertainty-aware fusion framework for face expression recognition in the wild. <em>ESWA</em>, <em>298</em>, 129567. (<a href='https://doi.org/10.1016/j.eswa.2025.129567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition(FER) is a key task in the broader landscape of affective computing and human-computer interaction, enabling machines to interpret human emotions. To better learn discriminative features under complex facial variations, recent FER research has increasingly adopted multi-branch fusion architectures that aim to capture complementary features from diverse perspectives. However, existing multi-branch fusion strategies, including static weighting, simple concatenation, or uncertainty-aware modeling, lack the capacity to comprehensively capture and reconcile the reliability variations across both individual instances and structural branches. To overcome these limitations, we propose a novel multi-branch fusion strategy, named Dual Uncertainty-Aware Fusion Framework(DUAFF), which improves the discriminability of integrated features by simultaneously modeling instance-wise uncertainty and inter-branch correlations. Specifically, the proposed method comprises two complementary modules: Instance-Discrepant Uncertainty-Aware Fusion Module (ID-UAFM) and Branch-Discrepant Uncertainty-Aware Fusion Module (BD-UAFM). ID-UAFM is introduced to perform channel-wise entropy analysis between semantically distinct samples to estimate instance-level uncertainty, enabling selective channel-wise fusion that emphasizes reliable representations while suppressing uncertain responses. BD-UAFM is further proposed to capture structural uncertainty by evaluating the relative reliability of features across multiple branches and adaptively weighting their contributions based on inter-branch discrepancies. Experimental results demonstrate that the proposed DUAFF consistently outperforms POSTER across three benchmark datasets, achieving accuracy improvements of 0.23 % on RAF-DB, 0.69 % on FER2013, and 0.29 % on AffectNet (7-class), thereby confirming its effectiveness in enhancing the reliability and discriminability of facial representations.},
  archive      = {J_ESWA},
  author       = {Wenfeng Jiang and Ziyi Zhao and Lin Wang and Fang Liu and Chunmei Qing and Xiaofen Xing and Xiangmin Xu and Weiquan Fan and Zhanpeng Jin},
  doi          = {10.1016/j.eswa.2025.129567},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129567},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dual uncertainty-aware fusion framework for face expression recognition in the wild},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data. <em>ESWA</em>, <em>298</em>, 129566. (<a href='https://doi.org/10.1016/j.eswa.2025.129566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel multiscale and multivariable deep learning framework for tourism stock index forecasting. To address the research gap concerning emerging media’s impact on the tourism sector, our study innovatively integrate multi-source data, including Douyin (China’s prominent short video platform), into our predictive model. Our methodology employs a multiscale decomposition strategy to streamline feature extraction complexity, coupled with an enhanced temporal convolutional network model incorporating soft-thresholding denoising to mitigate noise interference. Furthermore, we implement an adaptive differentiated prediction strategy to optimize model flexibility. Empirical analysis utilizing the CSI Tourism Stock Index demonstrates that our proposed model outperforms benchmark models in both predictive accuracy and stability, thereby validating its efficacy in tourism stock index forecasting.},
  archive      = {J_ESWA},
  author       = {Feng Shen and Shuai Huang and Wanqing Zhao and Dao Lan},
  doi          = {10.1016/j.eswa.2025.129566},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129566},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing adversarial transferability through frequency-domain boundary samples tuning. <em>ESWA</em>, <em>298</em>, 129565. (<a href='https://doi.org/10.1016/j.eswa.2025.129565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer-based attacks evaluate the robustness of deep learning models and advance adversarial research to improve the security and reliability of deep learning and its applications. Previous efforts have improved the transferability through advanced gradients, augmented models, or augmented data. In this paper, we understand and enhance the transferability from a new perspective. Delving into intermediate features, we empirically find a difference between the distances of adversarial and original samples from cluster centers of the original classes. The adversarial samples are simultaneously far from both the original samples and the cluster centers, close to generalized decision boundaries. Based on this observation, we propose a novel spectrum tuning attack. Boundary samples are utilized to guide the generation of adversarial samples that are far away from the cluster centers. Specifically, randomized boundary samples are generated by frequency-domain transformations. With the gradients of the diverse boundary samples, the adversarial perturbation moves the examples away from cluster centers, thus approaching generalized decision boundaries. In the optimization process, conjugate directions are employed to avoid oscillations and stabilize the update direction. Given the strong Wolfe parameters, the analysis of the descent direction and current gradient further ensures the convergence speed and stability of the optimization. In addition, Gaussian preprocessing is introduced to smooth the update direction, further stabilize the direction and enhance the transferability. The proposed method is flexible enough to be combined with existing methods to further improve the transferability. Experiments conducted on the ImageNet-compatible dataset validate the effectiveness of the proposed method, e.g., 92.6 % success rate against nine defense methods.},
  archive      = {J_ESWA},
  author       = {Shuyan Cheng and Peng Li and Keji Han and Yangjun Xiong and He Xu and Ruchuan Wang},
  doi          = {10.1016/j.eswa.2025.129565},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129565},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing adversarial transferability through frequency-domain boundary samples tuning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When graph anomaly breaks the coherence: A multi-evidence approach with language models. <em>ESWA</em>, <em>298</em>, 129557. (<a href='https://doi.org/10.1016/j.eswa.2025.129557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is critical in domains such as healthcare and economics, where identifying deviations can prevent substantial losses. However, current detection methods, primarily reliant on Graph Neural Networks (GNNs), suffer from a critical limitation: they make judgment on a single piece of evidence – the classification of learned node representations. This “single-verdict” approach is inherently susceptible to misjudgments arising from noisy or biased representations. To address this limitation, we introduce Multi-AD, a novel Multi-evidence-based graph Anomaly Detection framework that leverages the power of Language Models (LMs) to enable more robust and reliable anomaly detection. We provide a paradigm shift by constructing multiple evidence sequences for each target node, and employing LMs to assess the coherence of these sequences. By aggregating coherence scores across multiple sequences, Multi-AD leverages converging evidence to make more informed decisions about anomaly status as the presence of anomalous nodes disrupts coherence. Furthermore, we introduce a coherence-aware edge representation method to enhance the discriminative power of the constructed sequences and a multi-round adaptive integration strategy to handle challenging scenarios where normal nodes might be surrounded by anomalies. Extensive experiments demonstrate that Multi-AD consistently outperforms state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xuan Cheng and Jiahui Lu and Chunjing Xiao and Meiyi Yang and Meihui Zhong and Fan Zhou},
  doi          = {10.1016/j.eswa.2025.129557},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129557},
  shortjournal = {Expert Syst. Appl.},
  title        = {When graph anomaly breaks the coherence: A multi-evidence approach with language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal joint subspace model for parkinson’s disease diagnosis. <em>ESWA</em>, <em>298</em>, 129556. (<a href='https://doi.org/10.1016/j.eswa.2025.129556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is an irreversible neurodegenerative disorder that significantly impacts patients’ lives. Accurate early diagnosis prediction is crucial for providing timely treatment to delay disease progression. However, current diagnostic methods predominantly rely on the experience and judgment of clinicians, introducing subjectivity and a lack of standardized, quantitative measures. Sparse subspace learning, as a machine learning technique, can extract critical information from multimodal data while addressing issues such as noise, high-dimensional complexity, and class imbalance. Our study utilizes longitudinal, multimodal neuroimaging data collected at multiple time points to develop a diagnostic model for PD. The approach involves extracting latent local features and leveraging deep learning techniques to generate a comprehensive global feature subset. Adaptive sparse selection is employed to reduce feature redundancy. Finally, support vector machine is used for classification and regression tasks, specifically for PD diagnosis and disease progression score prediction. Extensive experiments were conducted on the PPMI dataset, achieving an accuracy of 90.78 % for Scan Without Evidence of Dopaminergic Deficit (SWEDD) vs. Normal Control (NC) classification, 83.79 % for PD vs. NC, and 91.50 % for PD vs. SWEDD. The results demonstrate that the proposed method improves PD classification and prediction performance, showing promise for early diagnostic applications.},
  archive      = {J_ESWA},
  author       = {Haojie Song and Haijun Lei and Yukang Lei and Zhongwei Huang and Jiaqiang Li and Tianfu Wang and Peng Yang and Baiying Lei},
  doi          = {10.1016/j.eswa.2025.129556},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129556},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal joint subspace model for parkinson’s disease diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spectral relevance analysis approach to pattern recognition of financial time series. <em>ESWA</em>, <em>298</em>, 129555. (<a href='https://doi.org/10.1016/j.eswa.2025.129555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding patterns in financial time series is crucial for improving prediction accuracy in algorithmic trading and risk management. This paper presents a novel AI-based computer vision approach for classifying financial time series. Historical price sequences are transformed into Gramian Angular Difference Field (GADF) images and fed into a convolutional neural network (CNN) for pattern recognition. To interpret the CNN’s decision-making process, we apply Spectral Relevance Analysis (SpRAy), enabling the identification of distinct clusters based on relevance maps. Clustering the images according to their relevance profiles reveals groups with significantly higher predictive performance compared to the full dataset. The corresponding relevance patterns highlight favorable price movement structures and are identified via the associated clusters.},
  archive      = {J_ESWA},
  author       = {Christine Distler and Yarema Okhrin and Jonathan Pfahler},
  doi          = {10.1016/j.eswa.2025.129555},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129555},
  shortjournal = {Expert Syst. Appl.},
  title        = {A spectral relevance analysis approach to pattern recognition of financial time series},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector. <em>ESWA</em>, <em>298</em>, 129554. (<a href='https://doi.org/10.1016/j.eswa.2025.129554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object identification is one of the computer vision-based methods used in locating and labelling objects in images. Object detection has been greatly advanced as it is now applicable for detecting night vision images with great accuracy. Most accurate object detection at night can be useful in many applications like nighttime driving, regulating harsh traffic in harsh weather conditions, and surveillance. Object detection in normal conditions can be smoother, but low illumination and harsh weather can lead to low versatility. Images captured at night can reflect a lot of noise with low visual features. Due to its challenging nature, a highly effective object detection model is a challenge for high-level applications. Traditional models still face issues and challenges related to uneven light conditions, brightness variations, different light sources, and noisy backgrounds that need to be addressed. Thus, it is necessary to develop an object detection model for dealing with images with low illumination and varying light conditions. Hence, in this work, an effective object detection framework is implemented for night vision images. At first, from the standard datasets, the significant night vision images are fetched and fed into the proposed model as a Residual 3D Transformer-based YoloV8 with an Adaptive Gated Recurrent Unit (R3DT-YAGRU) for detecting the objects. This includes combining spatial–temporal modelling capabilities into YOLOv8, particularly using 3D transformers for improved feature extraction and an adaptive GRU to manage temporal dependencies at night. Here, the Modified Random Variable-based Dollmaker Optimization Algorithm (MRV-DOA), which is a metaheuristic algorithm motivated by the doll-making procedure. Also, it helps in balancing the exploration phase and exploitation phase to discover the best solutions and is used for tuning the parameters of the R3DT-YAGRU model. At last, the experimental validation is carried out for the recommended object detection process by comparing with other models to establish the supremacy of the suggested work. From the study, the suggested framework achieves an accuracy of 96%, leading to enhanced decision making and better accuracy than other conventional models. The work has prepared its implementation accessible at https://github.com/charlesvprabhu56/Object-Detection .},
  archive      = {J_ESWA},
  author       = {V.Charles Prabu and Queen Mary Vidya. M and V. Sathiyamoorthi and P. Durgadevi and M. Gowthami},
  doi          = {10.1016/j.eswa.2025.129554},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129554},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning diversified features for pulmonary hypertension detection using chest X-ray. <em>ESWA</em>, <em>298</em>, 129553. (<a href='https://doi.org/10.1016/j.eswa.2025.129553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional Computed Tomography (CT) scans and floatation catheters, chest X-ray offers an efficient, safe and timely examination paradigm, with broader range of scenarios (including intensive care units), for the detection of Pulmonary Arterial Hypertension (PAH). However, it is difficult to learn the variable radiological features of PAH from X-rays due to its low resolution and low contrast. To address the above issues, we propose a diversified features learning framework to fully explore the PAH-related representation from chest X-ray. We first employ a Chest Feature Enhancement Attention (CFEA) module to enhance the initial feature representation. Then, we employ the Deep Temporal Anti-Interference Metric Learning (TAIML) module to fully explore the PAH-related features. We incorporate the information on the temporal evolution of patients’ conditions. Specifically, a patient x , after undergoing treatment, may exhibit two possible states: x + (ill) and x − (cured). Therefore, we can define the distance d ( x , x + ) as the intra-class structural distance, and the distance d ( x , x − ) as the inter-class safe distance. Unlike existing metric learning, we adopt a new strategy: we push positive samples towards negative samples, but ensure distance between them is no less than d ( x , x − ) , thereby enhancing intra-class diversity while maintaining discriminability. Meanwhile, we ensure that the distance between positive samples is greater than d ( x , x + ) , thereby preserving the intra-class structure. Through these two steps, we can learn a diversified but discriminative representation of PAH. Comprehensive experiments showed the our model achieved an impressive accuracy of 86.27 % and an AUC of 0.857 in identifying PAH patients. The code is available at https://github.com/zgfdmn/PAH .},
  archive      = {J_ESWA},
  author       = {Chengjin Yu and Huanghui Wang and Yuanting Yan and Zhuyang Chu and Dongsheng Ruan},
  doi          = {10.1016/j.eswa.2025.129553},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129553},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning diversified features for pulmonary hypertension detection using chest X-ray},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data. <em>ESWA</em>, <em>298</em>, 129552. (<a href='https://doi.org/10.1016/j.eswa.2025.129552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the emergency triage has faced several challenges, including insufficient manual triage with physicians, limited medical resources contributing to incorrect triage, overcrowding in the emergency department (ED), and extended patient waiting time. Hence, the Medical Emergency prediction remains the major research area that identifies emergencies about specific diseases using the Medical Transcriptions (MT) provided by physicians. However, the existing methods face the challenges of handling the ambiguity of words, unstructured data, and increased computation complexity. Consequently, this research proposes the Tri-Head Attention-based Bidirectional Encoder Representations from Transformers enabled Distributed Bidirectional Long-Short Term Memory (TriHAtt-BERT-DBiLSTM) for predicting medical emergencies. Specifically, the proposed approach integrates the Tri-Head Attention mechanisms into BERT, which is further hybridized with the DBiLSTM model that offers the synergic strength of providing the dense feature representations to capture the complex dependencies, and enhancement of model ability with the structured parameters to facilitate the medical emergency prediction. Besides, the utilization of BERT in the proposed approach assists in capturing more complex language representations and further executes a better embedding representation of words. The TriHAtt-BERT-DBiLSTM model surpasses other state-of-the-art techniques and achieves 96.40% of accuracy, 96.12% of F1-score, 96.09% of precision, and 96.15% of recall for medical emergency prediction.},
  archive      = {J_ESWA},
  author       = {Amita Mishra and Sunita Soni},
  doi          = {10.1016/j.eswa.2025.129552},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129552},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing. <em>ESWA</em>, <em>298</em>, 129551. (<a href='https://doi.org/10.1016/j.eswa.2025.129551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contact ring seals (CRSs) used in electroplating processes during semiconductor manufacturing are susceptible to degradation through chemical etching, electrochemical dissolution, and mechanical wear mechanisms. Despite the implementation of state-of-the-art surface treatment and coating technologies to mitigate CRS corrosion, manual intervention remains frequently required to address this problem. Conventional static defect detection systems for CRSs rely on predefined regions of interest (ROIs) and threshold-based defect area calculations, with surface anomalies identified by comparing the percentage of defective areas within these ROIs. However, this approach exhibits detection failures for millimeter-scale defects, low-contrast anomalies, and geometrically irregular patterns, especially under complex or dynamic environmental conditions. To address these systematic detection failures, we developed a dynamic defect detection system for CRSs by integrating artificial intelligence and traditional computer vision algorithms, achieving a 5.2x improvement in defect detection sensitivity. This system achieved detection accuracy and recall values of over 99 % as well as a response time of 1.43 s average latency, thereby demonstrating a substantial performance improvement compared to a static system, which achieved a recall rate of 18.9 % on the adopted dataset. The system satisfies real-time processing requirements while substantially reducing the need for manual intervention in defect detection and increases production efficiency. Finally, the experimental results of this study indicated that the postprocessing approaches used in the developed system enabled it to flexibly adapt to the different requirements of various production environments.},
  archive      = {J_ESWA},
  author       = {Ting-Han Chen and Hsin-Hung Chou and Shuang Zou and Yu-Han Chen and Sun-Yuan Hsieh},
  doi          = {10.1016/j.eswa.2025.129551},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129551},
  shortjournal = {Expert Syst. Appl.},
  title        = {System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification. <em>ESWA</em>, <em>298</em>, 129549. (<a href='https://doi.org/10.1016/j.eswa.2025.129549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of land remote sensing using single-modal data has reached a bottleneck, which has spurred significant interest in the joint utilization of multimodal remote sensing data to enhance classification performance. However, existing methods exhibit limitations in extracting intricate local and global features. Furthermore, achieving effective information interaction and deep fusion between multimodal datasets remains an unresolved challenge. To address these issues, we propose a Complementary Information-Guided Interactive Fusion Network (CIGIF-Net) for the classification of hyperspectral image (HSI) and light detection and ranging (LiDAR) data. The core idea of our approach leverages the capability of Convolutional Neural Networks (CNNs) to extract local spatial features while utilizing the strengths of Transformers in modeling long-range dependencies. Furthermore, our method facilitates deep fusion by designing mechanisms for the interactive integration of multimodal local spatial features, complemented by guidance from multimodal data during long-range dependency modeling, thereby improving overall classification performance. Specifically, CIGIF-Net incorporates multiscale feature learning, interactive feature fusion, and the complementary information-guided attention mechanism. Initially, CNNs are used to learn multiscale local spatial features. Subsequently, we perform an interactive fusion of multimodal spatial information based on channel attention techniques. Finally, the complementary information-guided attention mechanism dynamically utilizes complementary insights to inform deeper attention distributions, which guide global feature construction and enable efficient information aggregation. This methodology allows for the comprehensive extraction and synergistic utilization of complementary information across multimodal datasets. Extensive experiments conducted on three widely recognized HSI and LiDAR datasets demonstrate that the proposed CIGIF-Net achieves superior classification performance.},
  archive      = {J_ESWA},
  author       = {Shufang Xu and Qiyuan Xue and Zhonghao Chen and Shuyu Fei and Hongmin Gao},
  doi          = {10.1016/j.eswa.2025.129549},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129549},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach. <em>ESWA</em>, <em>298</em>, 129544. (<a href='https://doi.org/10.1016/j.eswa.2025.129544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced Decision Support System (DSS) for long-term open-pit mine planning that integrates established optimization techniques—Large Neighborhood Search (LNS), Simulated Annealing (SA), and Dantzig-Wolfe decomposition—within a novel GPU-accelerated framework addressing geological uncertainty and computational complexity. The key methodological contributions include dynamic uncertainty modelling with time-dependent factors capturing geological confidence degradation and GPU-parallelized evaluation architecture enabling industrial-scale mine planning. Validation using 50,000 blocks across 10 geological scenarios demonstrates robust economic performance, achieving mean NPV of $1.514 billion with limited variability (standard deviation $16 million). The GPU-parallelized architecture achieves 29.6 % average computational speedup with peaks of 37 % compared to CPU implementations, enabling concurrent evaluation of 262,144 mining scenarios. Risk analysis reveals P90 Value-at-Risk of $1.488 billion, indicating strong downside protection. The system maintains profit margins exceeding 95 % across all scenarios with cumulative cash flow reaching $1.789.4 million by period 6. Narrow risk envelopes (P10-P90 spread <$60 M) demonstrate robust performance under uncertainty, providing mining companies with practical tools for risk-informed strategic decision-making.},
  archive      = {J_ESWA},
  author       = {Iman Rahimi},
  doi          = {10.1016/j.eswa.2025.129544},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129544},
  shortjournal = {Expert Syst. Appl.},
  title        = {A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment. <em>ESWA</em>, <em>298</em>, 129543. (<a href='https://doi.org/10.1016/j.eswa.2025.129543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of IoT devices in daily applications, securing them against intrusions has become increasingly critical. Domain adaptation (DA)-based intrusion detection is a promising approach that transfers knowledge from a source domain to improve detection in a target IoT domain. However, effective DA methods must address various types of domain heterogeneity - such as differences in feature representation, intrusion distribution, and attack strategies. Existing intrusion detection datasets rarely consider these aspects, limiting their utility for evaluating heterogeneous DA approaches. To bridge this gap, we introduce TriHID , a new dataset specifically designed to capture heterogeneities from three perspectives. We evaluate four types of DA-based IoT intrusion detectors - multi-source, semi-supervised, unsupervised, and open-set on TriHID. Experimental results demonstrate that TriHID enables robust training and comprehensive evaluation of DA-based intrusion detection methods in heterogeneous IoT settings.},
  archive      = {J_ESWA},
  author       = {Jiashu Wu and Yang Wang},
  doi          = {10.1016/j.eswa.2025.129543},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129543},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning. <em>ESWA</em>, <em>298</em>, 129542. (<a href='https://doi.org/10.1016/j.eswa.2025.129542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing environments, job shop scheduling systems are characterized by heightened complexity and ever-changing dynamics, often involving multi-objective optimization and the need to accommodate unanticipated events like new job insertions and uncertain machine availability, underscores the necessity for effective real-time multi-objective scheduling approaches. Therefore, to tackle the multi-objective dynamic flexible job shop scheduling problem (MODFJSP) involving new job insertions, this paper introduces an online scheduling framework called multi-head deep Q network (MHDQN), designed to simultaneously minimize both total tardiness and total machine idle time. The core architecture of MHDQN framework is an innovative multi-head network agent based on Dueling deep Q network (Deuling DQN), consisting of a shared network layer and objective-specific network layers. The shared network layer extracts and transforms the input global state features layer by layer, generating a high-dimensional, semantically rich shared feature. This provides a unified input foundation for the objective-specific network layers, which are responsible for extracting the specialized information related to each objective from the shared features and calculating the corresponding Q -values, thereby enabling the parallel optimization of each objective. Six combined scheduling rules are developed to form the action set, each incorporating both job and machine selection. An improved multi-objective action selection strategy is proposed, incorporating inverse sigmoid ϵ decay and Q -value maximum absolute (max-abs) normalization to optimize decision-making. Additionally, a multi-head network training mechanism leveraging the Double deep Q network (Double DQN) architecture has been developed. Extensive computational experiments demonstrate that the MHDQN outperforms widely used traditional scheduling rules, multi-objective metaheuristic algorithms, and other reinforcement learning (RL) based scheduling methods, showing significant advantages and strong generalizability in multi-objective optimization tasks.},
  archive      = {J_ESWA},
  author       = {Kai Li and Bao Zheng and Liping Xu and Fulong Xie and Zhicheng Wang},
  doi          = {10.1016/j.eswa.2025.129542},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129542},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain. <em>ESWA</em>, <em>298</em>, 129539. (<a href='https://doi.org/10.1016/j.eswa.2025.129539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing platelet supply chains poses significant challenges due to the product’s short shelf life, highly uncertain demand, and the critical nature of its medical use. Previous studies in the blood supply chain rely on fixed-order quantities and ignore collaborative inventory-sharing strategies, which can lead to either excessive waste or severe shortages. However, in many real-world situations, fixed order quantities are often insufficient to accommodate fluctuating demand, especially in healthcare systems. Moreover, existing distribution models in the literature often overlook the equitable allocation of services across hospitals, leading to disparities in access to critical healthcare resources. This study proposes a novel two-phase decision-making framework that integrates a fuzzy periodic review inventory model with a cluster-based reactive transshipment strategy to optimize platelet supply and distribution. In Phase I, a fuzzy periodic review model determines optimal order quantities under uncertain demand using a possibilistic chance-constrained programming approach. In Phase II, hospitals are clustered based on service levels, enabling equitable transshipment among facilities to reduce disparities and improve overall responsiveness. A real-world case study from Tehran province is used to evaluate the model’s effectiveness. Results show an approximate 6% reduction in total shortages and a 2% improvement in average service levels. The proposed framework offers actionable insights for healthcare managers aiming to enhance resilience, equity, and efficiency in critical medical supply chains.},
  archive      = {J_ESWA},
  author       = {Seyyed-Mahdi Hosseini-Motlagh and Mohammad Reza Ghatreh Samani and Hannaneh Kordhaghi},
  doi          = {10.1016/j.eswa.2025.129539},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129539},
  shortjournal = {Expert Syst. Appl.},
  title        = {A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-insights guided evolutionary algorithm for optimization. <em>ESWA</em>, <em>298</em>, 129538. (<a href='https://doi.org/10.1016/j.eswa.2025.129538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are a class of optimization algorithms inspired by the theory of biological evolution. They solve optimization problems by emulating the processes of natural selection. EAs produce abundant data during evolution, which contains valuable information that reflects their evolutionary patterns. Effectively utilizing this information can enhance the algorithms’ effectiveness and efficiency. Deep learning excels at extracting knowledge from data. Inspired by this, we propose a novel insights-infused framework that utilizes deep neural networks to learn the evolutionary processes of EAs and extract useful synthesis insights from the evolutionary data. These synthesis insights not only guide the algorithm to evolve in a better direction on the original problems, but also improve its performance on new problems. The choice of neural networks is important. During pre-training, to reduce the inductive bias introduced by human prior knowledge, we design an MLP model to process the data. Additionally, we develop a variable-length encoding method to enable MLP networks to handle variable-length data. To verify the transfer evolution ability of synthesis insights, we devise a self-evolution strategy that fine-tunes the network using only the data generated by the algorithm itself, without introducing any external knowledge, when dealing with new problems. Experimental results demonstrate that the synthesis insights extracted from the CEC2014 dataset guide the algorithms to evolve in a better direction for the CEC2014 problems, and in addition enhance their performance on new problems like CEC2017, CEC2022 and the real-world optimization problems.},
  archive      = {J_ESWA},
  author       = {Kun Bian and Juntao Zhang and Hong Han and Jun Zhou and Yifei Sun and Shi Cheng},
  doi          = {10.1016/j.eswa.2025.129538},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129538},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-insights guided evolutionary algorithm for optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MambaGen: Efficient visual representation learning for automatic radiology report generation. <em>ESWA</em>, <em>298</em>, 129537. (<a href='https://doi.org/10.1016/j.eswa.2025.129537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation focuses on producing comprehensive and clinically precise medical reports based on radiographic images, thereby improving medical efficiency and alleviating the burden on radiologists. Although existing deep learning methods have demonstrated superior performance, they are constrained by the local receptive field of convolutional neural networks and are inadequate for modeling long-range dependencies, making it challenging to detect critical lesion features in medical images. Recently, State Space Models (SSMs), particularly Mamba, have shown great potential in modeling long-range dependencies with linear computational complexity. Inspired by this, we propose MambaGen, the enhanced Mamba model specifically designed for radiology report generation tasks. Specifically, we design a Mamba-Visual Recalibration Module (MVRM), which utilizes a two-stage training strategy to effectively capture the efficient visual representation of medical images. This first stage combines convolutional layers with SSMs to model long-sequence dependencies and learn multi-level visual feature information. This second stage introduces local convolution and a channel attention mechanism to further recalibrate the local feature and mitigate channel redundancy. Comprehensive experiments on widely available datasets, such as IU X-Ray and MIMIC-CXR, demonstrate our model’s superior performance compared to existing methods, particularly with an improvement of 2.7 % on the BLEU-4 metric. The code is available at https://github.com/Eleanorhxd/MambaGen.git .},
  archive      = {J_ESWA},
  author       = {Xiaodi Hou and Xiaobo Li and Simiao Wang and Mingyu Lu and Hongfei Lin and Yijia Zhang},
  doi          = {10.1016/j.eswa.2025.129537},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129537},
  shortjournal = {Expert Syst. Appl.},
  title        = {MambaGen: Efficient visual representation learning for automatic radiology report generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction. <em>ESWA</em>, <em>298</em>, 129532. (<a href='https://doi.org/10.1016/j.eswa.2025.129532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling nitrogen oxide (NO x ) emissions from diesel vehicles is a critical environmental challenge. Advanced SCR strategies depend on accurate multistep forecasting of NO x and ammonia (NH 3 ), but existing models often struggle with error accumulation and the non-stationary dynamics of emissions data. In this work, we first establish a new benchmark for this task, confirming that handling data non-stationarity is essential for robust prediction. Building on this insight, we propose FiTformer, a novel Transformer architecture that adopts an encoder-only framework to jointly forecast both NO x and NH 3 concentrations, where we introduce Intra-series Temporal-Frequency Fusion mechanism to capture intrinsic emissions dynamics and Inter-series Covariate Interaction mechanism to model external influences. Validated on real-world engine data, FiTformer consistently outperforms baseline models across all evaluated prediction horizons, with up to 44.1 % MAE and 36.9 % SMAPE reductions in 24-step NO x prediction and similarly strong gains for NH 3 prediction, compared to the state-of-the-art baseline TimesNet. Its high computational efficiency (0.30G MACs and 8.3 ms/iter) along with robust generalization and high resilience to data imperfections, underscores its suitability for real-time embedded SCR control, enabling more effective strategies for NO x reduction and NH 3 slip minimization.},
  archive      = {J_ESWA},
  author       = {Yuhan Luo and Yujun Zhang and Ying He and Kun You and Wei Huang and Wenqing Liu and Hao Xie},
  doi          = {10.1016/j.eswa.2025.129532},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129532},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes. <em>ESWA</em>, <em>298</em>, 129530. (<a href='https://doi.org/10.1016/j.eswa.2025.129530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-limited epilepsy with centrotemporal spikes (SeLECTS) is the most common form of focal epilepsy in childhood, accounting for 20–25 % of all childhood epilepsy cases and may be associated with cognitive dysfunction and behavioral issues. Accurate detection and assessment of epileptic discharges in EEG signals, particularly the spike-wave index (SWI), are crucial for timely intervention and treatment. Manual analysis of EEG data is labor-intensive and prone to errors, underscoring the need for automated methods. In the present study, we propose a novel D ual-Str e am Sp a tial- S pectral- T emporal L arge model (DeaSTL) that leverages a large-scale EEG architecture to effectively capture the multidimensional characteristics of EEG signals associated with SeLECTS syndrome. Our model integrates multi-view temporal representations and spatial-spectral representations through a dual-stream approach, enhancing the learning of complex patterns in EEG data. We introduce the S JTU Se L ECTS E EG D ataset (SLED), a comprehensive EEG dataset from 212 patients diagnosed with SeLECTS, including annotations for abnormal discharge detection, wake-sleep period classification, and SWI estimation. Addressing the previously unexplored problem of SWI prediction, we provide a novel method for quantifying the severity of epileptic discharges during sleep. Extensive experiments demonstrate that our DeaSTL model significantly outperforms several state-of-the-art methods across multiple tasks, showcasing its potential for clinical application in assisting diagnosis and treatment planning.},
  archive      = {J_ESWA},
  author       = {Lin Zhang and Yun Ren and Fang Yuan and Xuqin Chen and Shikui Tu and Lei Xu},
  doi          = {10.1016/j.eswa.2025.129530},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129530},
  shortjournal = {Expert Syst. Appl.},
  title        = {An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic learning of sample ambiguity-driven sample weighting for medical image classification. <em>ESWA</em>, <em>298</em>, 129527. (<a href='https://doi.org/10.1016/j.eswa.2025.129527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have delivered impressive results in medical image classification tasks. However, their performance is still challenging in medical scenarios with limited data, where training set biases such as label noise or class imbalance impede model learning. Dynamic learning based sample weighting achieves adaptive adjustment of sample importance through learnable weight functions and shows great potential in improving model robustness. Nevertheless, existing methods directly employ model states such as loss value or training accuracy to evaluate sample importance, ignoring the role of ambiguous samples in model optimization. This limitation hinders the performance of dynamic learning based sample weighting in medical image classification. In this paper, we propose a new sample weighting approach based on sample ambiguity and dynamic learning for improving medical image classification, named DLSA-SW. We introduce a dual-space sample ambiguity method by evaluating the category proximity in the feature space and the prediction confidence in the label space. Subsequently, to dynamically calculate sample weights according to sample ambiguity, a learnable sample weighting network is developed to adaptively adjust the weights during training to guide the task model. DLSA-SW performs alternate optimization to enable mutual adaptation of the sample weighting network and the task network. We evaluate the effectiveness of our approach on three medical image classification benchmarks: PatchCamelyon for lymph node histopathology classification, ISIC 2020 for skin lesion classification, and MTC for medullary thyroid cancer classification. DLSA-SW outperforms existing state-of-the-art sample weighting methods on all three datasets and yields substantial improvements over methods without sample weighting. These results demonstrate the robustness and practical applicability of our approach in clinical diagnostic tasks.},
  archive      = {J_ESWA},
  author       = {Guanxiu Yi and Xiabi Liu and Ling Ma and Mengqiao Han and Lijuan Niu},
  doi          = {10.1016/j.eswa.2025.129527},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129527},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic learning of sample ambiguity-driven sample weighting for medical image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement. <em>ESWA</em>, <em>298</em>, 129526. (<a href='https://doi.org/10.1016/j.eswa.2025.129526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact manner of measuring heart rate variability (HRV) by deriving blood volume pulse (BVP) signals from facial videos. The performance of rPPG-based HRV measurement is challenging due to short-range noises (e.g., head movements) suppression and sufficient-duration BVP signal generation. Recent Transformer-based rPPG methods have shown advantages of global spatio-temporal feature modeling in eliminating noise and recovering high-quality BVP signals. However, these methods often face significant computational and memory constraints, limiting duration scalability of the generated BVP signals that might decrease HRV measurement performance. To address the above issue, this paper proposes a duration-scalable Transformer-based rPPG method, capable of global Long-range Spatio-Temporal modelling (LST), termed LST-rPPG, to generate high-quality BVP signals with a much longer duration. On the one hand, by employing spatial and temporal encoders, the original image-based rPPG issue is converted to a time-series problem. Besides, a sparse computation mechanism is integrated into the temporal encoder. This combination allows LST-rPPG to recover flexible-duration BVP signals, supporting continuous modeling of segments beyond 30 s with low computation and memory overhead. On the other hand, a dynamic loss function with stringent temporal constraints is designed to guarantee the quality of the generated BVP signals. Comprehensive experiments are performed on two public datasets, PURE and UBFC-RPPG, and the results demonstrate the feasibility of LST-rPPG for generating high-quality BVP signals with a much longer duration while requiring substantially fewer computational resources. Besides, LST-rPPG achieves at least the second-best results during all experiments.},
  archive      = {J_ESWA},
  author       = {Jiajie Li and Juan Cheng and Rencheng Song and Yu Liu},
  doi          = {10.1016/j.eswa.2025.129526},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129526},
  shortjournal = {Expert Syst. Appl.},
  title        = {LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking. <em>ESWA</em>, <em>298</em>, 129523. (<a href='https://doi.org/10.1016/j.eswa.2025.129523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding models have demonstrated strong performance in tasks like clustering, retrieval, and feature extraction while offering computational advantages over generative models and cross-encoders. Benchmarks such as MTEB have shown that text embeddings from large language models (LLMs) capture rich semantic information, but their ability to reflect code-level functional semantics remains unclear. Existing studies largely focus on code clone detection, which emphasizes syntactic similarity and overlooks functional understanding. In this paper, we focus on the functional consistency of LLM code embeddings, which determines if two code snippets perform the same function regardless of syntactic differences. We propose a novel data synthesis framework called Functionality-Oriented Code Self-Evolution to construct diverse and challenging benchmarks. Specifically, we define code examples across four semantic and syntactic categories and find that existing datasets predominantly capture syntactic properties. Our framework generates four unique variations from a single code instance, providing a broader spectrum of code examples that better reflect functional differences. Extensive experiments on three downstream tasks-code clone detection, code functional consistency identification, and code retrieval-demonstrate that embedding models significantly improve their performance when trained on our evolved datasets. These results highlight the effectiveness and generalization of our data synthesis framework, advancing the functional understanding of code.},
  archive      = {J_ESWA},
  author       = {Zhuohao Li and Wenqing Chen and Jianxing Yu and Zhichao Lu},
  doi          = {10.1016/j.eswa.2025.129523},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129523},
  shortjournal = {Expert Syst. Appl.},
  title        = {Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129522. (<a href='https://doi.org/10.1016/j.eswa.2025.129522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have demonstrated the effectiveness for hyperspectral image (HSI) classification, but still face challenges, such as insufficient exploitation of data structure information, limited labeled samples, and high susceptibility to noise and outliers. To address these issues, a semisupervised graph U-Net with graph convolutional long short-term memory is proposed for HSI classification, abbreviated as SSGU-Net. Specifically, we design a novel graph convolutional long short-term memory feature extractor to learn discriminative spatial-spectral joint features by simultaneously modeling the correlations in the spatial and spectral domains. Then, we develop a semisupervised graph U-Net with mutually inverse operation of the graph pooling and the graph unpooling modules which uses both labeled samples and unlabeled samples to train a well-parameterized network for HSI classification. In particular, to suppress the effects of noise and outliers, the graph pooling module is designed to selectively retain discriminative samples and fully learn the optimal correlation between these retained samples. Meanwhile, the graph unpooling module employs the local spatial context to reconstruct the reduced samples, thus restoring the pooled data to its original scale for classification task. Extensive experiments show the effectiveness of the proposed method, achieving overall accuracy gains of 5.22 %, 1.58 %, and 1.57 % over the state-of-the-art competitors on the Indian Pines, University of Pavia, and Houston datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jin-Yu Yang and Heng-Chao Li and Xin-Ru Feng and Feng Gao and Qian Du and Antonio Plaza},
  doi          = {10.1016/j.eswa.2025.129522},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129522},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems. <em>ESWA</em>, <em>298</em>, 129521. (<a href='https://doi.org/10.1016/j.eswa.2025.129521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet, building a multilingual dialogue generation system to attract more users while reducing costs in the global market has become increasingly important. However, current end-to-end multilingual approaches often face semantic disparity issues across languages. When given parallel queries with the same semantics but in different languages, the generated responses may vary in meaning across languages, which may greatly affect the stability and reliability of multilingual systems in different language scenarios. We attribute this issue to open-domain/model uncertainty and language differences. To mitigate this issue, we first propose a novel Anchor-based Semantic Constraint (ASC) designed to reduce semantic disparity across languages for Encoder-Decoder Transformers. ASC employs language-independent anchor signal to guide the behaviors in both the encoder and decoder, thereby reducing uncertainty. Additionally, ASC incorporates a two-stage tuning process to further minimize the impact of language differences by ensuring the encoder remains language-independent. Extensive experiments and in-depth analyses conducted on XDailyDialog demonstrate that ASC can effectively mitigate semantic disparity across languages and will not compromise dialogue response quality like the previous related baselines.},
  archive      = {J_ESWA},
  author       = {Sixing Wu and Jiahao Chen and Jiong Yu and Wei Zhou},
  doi          = {10.1016/j.eswa.2025.129521},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129521},
  shortjournal = {Expert Syst. Appl.},
  title        = {Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards CPU performance prediction: New challenge benchmark dataset and novel approach. <em>ESWA</em>, <em>298</em>, 129520. (<a href='https://doi.org/10.1016/j.eswa.2025.129520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CPU performance prediction based on hardware characteristics is crucial for system design and resource management. However, this field faces two major challenges. First, collecting real-world data is challenging due to the diversity of CPU products and the specialized nature of hardware characteristics. This field lacks a standard dataset with unified hardware characteristics, wide data coverage, and comprehensive benchmarks. Second, existing methods based on hardware simulation models or machine learning exhibit notable shortcomings, such as lengthy simulation test cycles and low prediction accuracy. To bridge these gaps, we first collect, preprocess, and standardize historical data from the 4th Generation Intel® Xeon® Scalable Processors across multiple benchmark suites to create a new dataset, named PerfCastDB. Subsequently, we design a deep learning based model called Nova CPU Performance Predictor (NCPP) as the baseline for this new dataset. The NCPP network is designed based on group attention mechanism. It effectively quantifies the implicit relationships between hardware characteristics within and across groups and comprehensively models the impact of various hardware characteristics on CPU performance prediction. We conduct comparative experiments using the proposed PerfCastDB dataset. Compared to existing approaches, NCPP achieves superior evaluation results, demonstrating its effectiveness. Furthermore, we have open-sourced part of the dataset and the NCPP network code to facilitate subsequent research. The resources can be accessed at https://github.com/xiaoman-liu/NCPP .},
  archive      = {J_ESWA},
  author       = {Xiaoman Liu},
  doi          = {10.1016/j.eswa.2025.129520},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129520},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards CPU performance prediction: New challenge benchmark dataset and novel approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Glyph graph isomorphism network for structure recognition of oracle bone inscription. <em>ESWA</em>, <em>298</em>, 129519. (<a href='https://doi.org/10.1016/j.eswa.2025.129519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure recognition of oracle bone inscription glyphs plays an important role in studying the evolutionary process of oracle bone inscriptions and the history of the Shang Dynasty. Currently, most methods have decomposed oracle bone inscription glyphs into multilevel features, which are used to recognize hierarchical feature fusion. This strategy cannot recognize the primitive internal structures of keypoints, strokes, and components. Moreover, mainstream graph neural networks cannot fully utilize the rich structural information of oracle bone inscription glyphs, resulting in their inability to meet the needs of structure recognition. So we have developed a graph structure recognition method to implement structure recognition of oracle bone inscription glyphs. A graph extraction method is given to get the structure of oracle bone inscription glyphs; each graph structure’s representation vector can be learned by a glyph graph isomorphism network, which is developed to recognize the graph of oracle bone inscription glyphs to enhance the discriminability representation of the structure. Our model has achieved advanced results across structure recognition experiments in the HWOBC dataset and the Oracle-50K dataset.},
  archive      = {J_ESWA},
  author       = {Zhan Zhang and Hanbin Liu and Xingkun Zhang and Yiyuan Wang and Feng Gao and An Guo and Han Zhang and Qingju Jiao and Bang Li and Yongge Liu},
  doi          = {10.1016/j.eswa.2025.129519},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129519},
  shortjournal = {Expert Syst. Appl.},
  title        = {Glyph graph isomorphism network for structure recognition of oracle bone inscription},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation. <em>ESWA</em>, <em>298</em>, 129516. (<a href='https://doi.org/10.1016/j.eswa.2025.129516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overweight and oversized transport (O&OT) has become one of the most critical elements of project logistics, driven by advancements in transportation and lifting technologies that now allow high-volume loads to be moved across long distances. This type of transportation operation, also called abnormal transportation, is greatly affected by technical factors such as the weight and geometry of the load, road surface, axle load limitations, slope, and ground strength, as well as external variables such as weather conditions, traffic density, and legal regulations. In planning and operational processes, Decision-Makers (DMs) and practitioners who plan and execute operations without adequately considering these factors and variables can lead to delays in operations, serious risks, and loss of productivity. This research proposes a flexible decision support model that integrates Step-wise Weight Assessment Ratio Analysis (SWARA) and Logarithmic Percentage Change-driven Objective Weighting (LOPCOW), and a ranking technique; i.e., Mixed Aggregation by Comprehensive Normalization Technique (MACONT) techniques to address the decision problems related to route selection, one of the most critical problems in transporting heavy and bulky loads, and to produce reasonable solutions. The proposed model significantly reduces information losses by processing subjective and objective information and integrating subjective (SWARA) and objective (LOPCOW) methods. Unlike traditional ranking approaches, the MACONT method combines three different normalization techniques to determine the ranking performance of alternatives. In this way, it provides more reliable and accurate results by reducing the deviations of the results provided by the single normalization technique. In addition, it shows each alternative’s good and bad performance compared to the others and is more convincing about the results obtained. According to the results obtained by applying the proposed model, fuel consumption (0.096) is determined as the most effective and critical factor in selecting the route on which heavy and bulky loads will be transported. In this context, choosing routes that allow lower fuel consumption can contribute to reducing carbon emissions and external costs arising from transportation. The extensive robustness and validation check to test the proposed model prove that the proposed model is a reliable, robust, and practical decision-making tool for making reasonable and rational decisions in O&OT.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Pradip Kundu and Hande Küçükönder and Gürkan Doğan and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129516},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129516},
  shortjournal = {Expert Syst. Appl.},
  title        = {An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EvoMapX: An explainable framework for metaheuristic optimization algorithms. <em>ESWA</em>, <em>298</em>, 129514. (<a href='https://doi.org/10.1016/j.eswa.2025.129514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based optimization algorithms (POAs) are widely adopted solutions for NP-hard and complex high-dimensional optimization problems. However, their internal dynamics often remain opaque, limiting trust and insight into how solutions evolve. This paper introduces EvoMapX, a novel explainable framework designed to interpret the internal dynamics of population-based optimization algorithms. EvoMapX includes three interpretable structures to visualize evolutionary optimization dynamics: the Operator Attribution Matrix (OAM) quantifies the contribution of specific operators over iterations; the Population Evolution Graph (PEG) traces the ancestry and transformation of candidate solutions; and the Convergence Driver Score (CDS) identifies which operators drive convergence, helping interpret why the algorithm improved. EvoMapX was evaluated across four POAs on the CEC 2021 test suite in order to demonstrate how it reveals meaningful textual and graphical insights into algorithm behavior. EvoMapX paves the way for interpretable metaheuristic optimization. The source code of EvoMapX is available at https://www.github.com/Bilal20252025/EvoMapX},
  archive      = {J_ESWA},
  author       = {Bilal H. Abed-Alguni},
  doi          = {10.1016/j.eswa.2025.129514},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129514},
  shortjournal = {Expert Syst. Appl.},
  title        = {EvoMapX: An explainable framework for metaheuristic optimization algorithms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set. <em>ESWA</em>, <em>298</em>, 129513. (<a href='https://doi.org/10.1016/j.eswa.2025.129513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random permutation set (RPS) extends Dempster-Shafer evidence theory by incorporating event order information, providing a powerful framework for modeling uncertainty. However, existing orthogonal sum methods within the RPS framework may encounter loss of order information and counterintuitive belief distribution during permutation event fusion. To address these two issues, this paper proposes a new method termed belief-distance-based orthogonal sum (BDOS). BDOS operates through three core mechanisms: order-information preservation via mathematical constructs like order-space and inverse mapping; belief-value weighting that prioritizes events with high belief mass for rational outcomes; and element-distance weighting that incorporates dissimilarity among permutations to improve ordinal accuracy. Numerical examples validate the effectiveness of BDOS in permutation event fusion, with comparative results demonstrating its advantages in order retention and belief distribution. Furthermore, BDOS is applied to threat assessment, illustrating its rationality and effectiveness in handling uncertainty and threat ranking.},
  archive      = {J_ESWA},
  author       = {Xiaoyan Su and Xu Chen and Hong Qian and Cheng Jiang},
  doi          = {10.1016/j.eswa.2025.129513},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129513},
  shortjournal = {Expert Syst. Appl.},
  title        = {BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks. <em>ESWA</em>, <em>298</em>, 129510. (<a href='https://doi.org/10.1016/j.eswa.2025.129510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objective With the rapid growth in the number of medical images, the need for content- based medical image retrieval (CBMIR) in clinical aid diagnosis is becoming increasingly important. Most current content-based CT image similarity retrieval methods use the entire CT image, ignoring the fact that the localized lesion region is the main target of similarity retrieval; Methods To address this issue, the paper proposes a fine-grained similarity retrieval method for lung CT images based on image block( IB ) similarity matching, taking lung CT images as an example. In this method, two enabling techniques are introduced: 1) a hybrid Convolution and Vision Transformer Model(CVTM) that effectively captures both local texture and global context features of lesion regions; 2) the iDS high-dimensional index designed to accelerate retrieval among IB ; Results With the aid of these techniques, fine-grained similarity retrieval optimization of lung CT images can be achieved, which facilitates more accurate lesion-level comparison and supports clinical decision-making; Conclusions Extensive experiments are conducted to indicate that the proposed fine-grained similarity retrieval method achieves excellent performance, with a mAP of 91.33%. Meanwhile, the retrieval efficiency of the iDS high-dimensional index is about 150% higher than that of sequential retrieval, especially when the retrieval radius is large and the database size is substantial.},
  archive      = {J_ESWA},
  author       = {Yi Zhuang and Jiayu Zhang and Yujia Ge and Nan Jiang},
  doi          = {10.1016/j.eswa.2025.129510},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129510},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traffic prediction using an active causality recurrent graph convolutional network. <em>ESWA</em>, <em>298</em>, 129506. (<a href='https://doi.org/10.1016/j.eswa.2025.129506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of our daily lives is significantly influenced by traffic conditions, highlighting the importance of incorporating complex spatiotemporal dependencies in interconnected traffic data for effective prediction. Although recent advancements have demonstrated prediction accuracy using graph convolutional networks, their depends heavily on the accuracy of the graph structures that represent the spatial relationships within the traffic network. To address this challenge, we introduce a novel approach to traffic prediction, the Active Causal Recurrent Graph Convolution Network (ACRGCN), as shown in Fig. 2. ACRGCN offers a new framework that effectively integrates a causal-embedded approach for traffic prediction, leveraging both structural and feature information from correlated traffic time series. Additionally, it incorporates a time-varying dynamic Bayesian network to capture the intricate spatiotemporal topology of traffic data. The model extracts spatiotemporal dependencies from traffic signals using the Active Causality Graph Recurrent Module (ACGRM), while efficiently modeling nonlinear traffic propagation patterns. Furthermore, ACRGCN employs a deep learning-based module that functions as a hyper-network, progressively generating dynamic causal graphs. Finally, extensive experiments on multiple real-world traffic graph datasets validate ACRGCN, and the results demonstrate its superiority over state-of-the-art method},
  archive      = {J_ESWA},
  author       = {Jinde Zhu and Junhao Yuan and Fulan Ye and Trong-The Nguyen and Ruoxi Wang and Wu Zeng and Chien-Chun Liu},
  doi          = {10.1016/j.eswa.2025.129506},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129506},
  shortjournal = {Expert Syst. Appl.},
  title        = {Traffic prediction using an active causality recurrent graph convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system. <em>ESWA</em>, <em>298</em>, 129502. (<a href='https://doi.org/10.1016/j.eswa.2025.129502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical computing architecture of cloud-edge-client (CEC) formed with the combination of cloud computing and edge computing can provide processing, storage and low-latency services close to end devices. To protect data privacy, federated learning (FL), as a novel intelligent edge computing framework with localized training mechanisms, has been integrated into edge computing to form a system called CEC-FL and is widely studied. However, they are susceptible to potential poisoning attacks. Existing poisoning attack methods are mostly explored by performing malicious operations on training samples or labels directly and implementing corresponding defense strategies: they are designed to ignore the label transferability and diverse attack environments and are not work against stealthy security threats, mainly because they do not take into account the inherent vulnerabilities of the attack environment. Yet few general defense schemes have been developed. In response to the above vulnerabilities, in this work, we explore a B arycenter Po isoning method with L abel T ransferability (BPoLT) initiated by malicious attackers, resulting in a dynamic attack capability on the CEC-FL system. To address poisoning attacks, we provide a two-phase defense algorithm Res isting L abel T ransferability Pois oning called ResLT-Pois to distinguish malicious attackers from benign participants. Extensive experimental results demonstrate that our scheme is feasible and effective in dealing with the vulnerability of the CEC-FL system.},
  archive      = {J_ESWA},
  author       = {Yaru Zhao and Yihao Cao and Jianbiao Zhang and Zhaoqian Zhang and Weiru Wang},
  doi          = {10.1016/j.eswa.2025.129502},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129502},
  shortjournal = {Expert Syst. Appl.},
  title        = {Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting. <em>ESWA</em>, <em>298</em>, 129498. (<a href='https://doi.org/10.1016/j.eswa.2025.129498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting faces significant challenges due to the variability and complexity of real-world data. Traditional methods often require manual adjustments of wavelet transform parameters, which are labor-intensive and prone to over-fitting or inadequate feature extraction. To address these limitations, this study proposes SAMForecast, a novel hybrid model that integrates Adaptive Wavelet Transform, self-attention mechanisms, and the selective state space model. We introduce an Adaptive Wavelet Block that dynamically adjusts decomposition levels and basis functions using a Mixture of Experts network and lifting scheme, eliminating the need for manual parameter tuning. Furthermore, the model deeply integrates the attention mechanism of the Transformer architecture, leveraging its advantages in capturing complex dependencies to identify correlations between time series data. By combining self-attention with Mamba, SAMForecast effectively captures both global dependencies and local key features in time series, enhancing robustness against noise and redundant information. SAMForecast demonstrates promising performance in multivariate time series forecasting tasks, showcasing an average 2 % performance improvement compared to existing models across datasets in energy, transportation, and other fields. The code is available at https://github.com/Kiki-V/SAMForecast-main .},
  archive      = {J_ESWA},
  author       = {Dunlu Peng and Qiqi Lin},
  doi          = {10.1016/j.eswa.2025.129498},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129498},
  shortjournal = {Expert Syst. Appl.},
  title        = {SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting. <em>ESWA</em>, <em>298</em>, 129497. (<a href='https://doi.org/10.1016/j.eswa.2025.129497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate PM2.5 prediction is crucial for effective environmental management and public health protection, yet current models show limited dynamic adaptability to complicated air pollution scenarios. Robust models are essential to support timely interventions in response to sudden pollution events or rapidly changing air quality patterns. However, existing models predominantly rely on predefined graph structures and pairwise spatial relationships, limiting their ability to capture the complex and dynamic interactions inherent in PM2.5 pollution. Furthermore, such models often assume equal contributions from neighboring nodes, neglecting heterogeneity and compromising predictive accuracy. To address these limitations, we propose an Adaptive Hypergraph-based Convolution Network with a Dual Spatiotemporal Attention mechanism (AHCN-DA) for PM2.5 forecasting. This framework leverages representation learning and hypergraph structures to capture and integrate pairwise as well as higher-order spatial interactions, producing richer spatial-feature representations. The dual spatiotemporal attention mechanism dynamically assigns time-varying weights to neighboring nodes based on their relevance to target nodes, effectively mitigating the impact of irrelevant inputs. Additionally, AHCN-DA integrates a dilated convolution network with multi-scale kernels to capture temporal patterns effectively across varying scales. Extensive experiments on the 2023 China National Air Quality Dataset show significant improvements in predictive accuracy, particularly in enhancing the proportion of high-precision monitoring stations, with an R 2 of 0.9224, outperforming baseline models. Our findings underscore the effectiveness of AHCN-DA in enhancing prediction accuracy under complex pollution response patterns, contributing to more informed decision-making in environmental management.},
  archive      = {J_ESWA},
  author       = {Haipeng Gao and Chonghui Qian and Yang Su and Wei Zhang and Hengjun Huang},
  doi          = {10.1016/j.eswa.2025.129497},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129497},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans. <em>ESWA</em>, <em>298</em>, 129496. (<a href='https://doi.org/10.1016/j.eswa.2025.129496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial team games represent scenarios where cooperation and competition coexist and hold numerous applications in the real world. These scenarios are particularly challenging due to asymmetric information among team members and limited communication capabilities. Fictitious team-play extend self-play algorithms to these scenarios, offering a novel approach to obtain equilibrium. However, it depends on normal-form team plans, which expand exponentially with game size, significantly constraining their applicability in large games. To overcome the challenge of computing equilibrium in large scale imperfect information team games, we propose a team self-play algorithm that utilizes refined team plans. Specifically, we pre-solve the equilibrium in a perfect recall environment to extract essential team plans from the original strategy space. To adapt these plans to an imperfect recall environment, we construct an auxiliary game with transformed ex ante coordinated information based on the original game and then solve equilibrium in auxiliary game to derive equilibrium for the original game. The experiments demonstrate the effectiveness of our team self-play algorithm in eight different Kuhn poker scenarios. Compared to existing team self-play algorithms, our method efficiently handles large games and exhibits superior convergence compared to reinforcement learning based algorithms. Additionally, our experiments offer valuable insights and guidance on adapting equilibrium strategies from perfect recall environments to those with imperfect recall.},
  archive      = {J_ESWA},
  author       = {Jinheng Xiao and Chen Qiu and Yingying Xu and Jiajia Zhang and Shuhan Qi and Xuan Wang},
  doi          = {10.1016/j.eswa.2025.129496},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129496},
  shortjournal = {Expert Syst. Appl.},
  title        = {Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images. <em>ESWA</em>, <em>298</em>, 129490. (<a href='https://doi.org/10.1016/j.eswa.2025.129490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma detection identifies the early signs of eye conditions that can lead to vision loss by analyzing the retinal images to detect abnormalities, such as increased intraocular pressure, changes in the optic nerve head, or structural alterations in the retina. The challenges faced by the existing models include the difficulty in detecting subtle features, variability in image quality, and complex patterns that may resemble normal variations. Moreover, the traditional models struggle to adapt to the evolving patient data, capture long-term dependencies, and often suffer from lower accuracy. Hence, this research proposes the Proactive Hybridized Bidirectional Long Short-Term Memory (BiLSTM) model for Glaucoma detection. The proactive hybridized BiLSTM model is designed to enhance the detection of glaucoma by processing the retinal images. The proactive hybridized BiLSTM model enables the model to capture complex temporal dependencies and relationships within the data, which are crucial for identifying subtle patterns indicative of glaucoma, for which multifaceted feature extraction is employed. Moreover, the Proactive Hybridized BiLSTM model adapts to dynamic changes in the data to learn and predict glaucoma-related features, ultimately improving detection performance over time. The proposed Proactive hybridized BiLSTM model attains higher accuracy, sensitivity, and specificity of 96.65%, 96.51%, and 96.79% using the OCT and FUNDUS image dataset.},
  archive      = {J_ESWA},
  author       = {M.Kiran Mayee and M.Humera Khanam and Shaik Lathifa Tabasum},
  doi          = {10.1016/j.eswa.2025.129490},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129490},
  shortjournal = {Expert Syst. Appl.},
  title        = {Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks. <em>ESWA</em>, <em>298</em>, 129487. (<a href='https://doi.org/10.1016/j.eswa.2025.129487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current deep learning methods for community detection in attributed networks face a critical limitation: they often fail to identify communities that are both structurally cohesive and semantically similar, thereby falling short of the balance typically observed in human-labeled partitions. This shortcoming stems from the absence of explicit mechanisms to jointly optimize these two objectives. In this paper, this challenge is addressed by proposing Deep Balanced Community Detection (DBCD), a novel unsupervised framework for community detection that balances topology and semantics. DBCD first constructs a powerful topology-semantic clustering consensus by integrating insights from both structural and attribute spaces. This consensus then steers a Graph Neural Network to simultaneously maximize global neural modularity and local cross-view consistency, while adaptively determining the number of communities. Extensive experiments reveal a striking result: DBCD consistently discovers communities that surpass the topology-semantic balance of the ground truth across multiple real-world networks. An empirical Pareto frontier analysis further validates that DBCD achieves a non-dominated solution, establishing it as a strong competitor among state-of-the-art methods. The source code of DBCD is available at https://github.com/wy980125/DBCD .},
  archive      = {J_ESWA},
  author       = {Yan Wang and Yupeng Liu and Xiaojie Sun and Jun Fu},
  doi          = {10.1016/j.eswa.2025.129487},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129487},
  shortjournal = {Expert Syst. Appl.},
  title        = {DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Network traffic forecasting with transfer learning-based algorithm for long continuous missing data. <em>ESWA</em>, <em>298</em>, 129484. (<a href='https://doi.org/10.1016/j.eswa.2025.129484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate network traffic forecasting is critical for power dispatch networks. Network traffic forecasting aims to use historical data to predict future network traffic trends. Different from other networks, the traffic data of the power dispatch network is mainly composed of the port traffic from routers and switches. However, network accidents in power enterprises can cause long periods of missing network traffic data, reducing the number of learning samples for network traffic prediction models and making the forecasting results unreliable. Due to the long periods of missing data, this paper uses transfer learning (TL) to impute missing data with the knowledge from a relevant task, which has ample samples. However, the imputation result contains complex source and target data characteristics. Therefore, this paper introduces the idea of frequency decomposition to decompose the imputation results into different sub-sequences through variational mode decomposition (VMD). Additionally, this paper uses long short-term memory (LSTM) networks to extract the potential features of decomposition results. Finally, this paper combines TL, VMD, and LSTM to design the TL-VMD-LSTM algorithm. The effectiveness of the proposed algorithm is validated using inflow and outflow traffic data from two State Grid Corp. of China networks. The results demonstrate that TL-VMD-LSTM has excellent generalization performance, with mean absolute percentage errors (MAPEs) of 0.380 % and 0.734 % for the Provincial access network and Information region network, respectively.},
  archive      = {J_ESWA},
  author       = {Yang Yang and Zhihao Chen and Yuchao Gao and Zijin Wang and Zhe Ding and Jinran Wu},
  doi          = {10.1016/j.eswa.2025.129484},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129484},
  shortjournal = {Expert Syst. Appl.},
  title        = {Network traffic forecasting with transfer learning-based algorithm for long continuous missing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional multi-objective feature selection with niche-based binary differential evolution. <em>ESWA</em>, <em>298</em>, 129478. (<a href='https://doi.org/10.1016/j.eswa.2025.129478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a critical step in machine learning and data mining, aiming to identify the most relevant features from a dataset to improve model performance while reducing computational costs. In high-dimensional data, as the dimensionality of data increases rapidly, feature selection faces an enormous search space, limiting the efficiency and effectiveness of traditional methods. To address these challenges, multi-objective optimization algorithms have emerged as a promising strategy for feature selection due to their ability to optimize multiple conflicting objectives simultaneously. We propose a niche-based binary differential evolution algorithm (MONBDE) for high-dimensional multi-objective feature selection. MONBDE enhances feature selection performance through several mechanisms: a niche-based binary differential evolution operator, redundant solution repair mechanism and an environmental selection strategy. In experiments, the proposed algorithm was compared with five advanced multi-objective optimization algorithms and tested on 15 benchmark datasets using three common metrics. Experimental results show that the MONBDE algorithm outperforms comparative algorithms in terms of classification accuracy and feature subset size across most datasets. The proposed strategy effectively eliminates redundant and irrelevant solutions in feature selection, leading to a significant improvement in model classification performance.},
  archive      = {J_ESWA},
  author       = {Xuezhi Yue and Xiang Zuo and Pengfei Ling and Chao Xiong and Hu Peng and Yuan Zeng},
  doi          = {10.1016/j.eswa.2025.129478},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129478},
  shortjournal = {Expert Syst. Appl.},
  title        = {High-dimensional multi-objective feature selection with niche-based binary differential evolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation. <em>ESWA</em>, <em>298</em>, 129477. (<a href='https://doi.org/10.1016/j.eswa.2025.129477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and rapid segmentation of the clinical target volume (CTV) is essential for cervical cancer radiotherapy. However, due to the soft boundaries of CTV, complex connections with surrounding tissues, and high interpatient variability, existing deep learning methods still face significant challenges, particularly for image slices that lack clear boundary information or where applicators are distant from CTV edges. Hence, we introduce DFCNet, a dual-path fusion network with cross-slice consistency constraints for CTV segmentation. The first path employs a dual-stream intra-slice feature encoding module to capture local and inter-regional details, thereby refining boundary delineation amidst the complex interplay with adjacent tissues. The second path integrates a cross-slice consistency constraint module to address soft boundaries and high interpatient variability, while ensuring the coherence and smoothness of the segmentation results. A feature fusion and decoding module combines semantic features from both paths, improving CTV region accuracy. Tests on 432 cervical cancer brachytherapy cases show DFCNet outperforms eighteen state-of-the-art segmentation methods, with Dice score improvements over two percentage points. The second path and feature fusion module can enhance other U-Net-based models, boosting their CTV segmentation performance. DFCNet excels in high-precision CTV segmentation, particularly for challenging slices, demonstrating its potential to improve cervical cancer radiotherapy accuracy, efficiency, and patient outcomes.},
  archive      = {J_ESWA},
  author       = {Mingxu Huang and Deyu Sun and Chaolu Feng and Ming Cui and Dazhe Zhao and Yuhua Gao},
  doi          = {10.1016/j.eswa.2025.129477},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129477},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users. <em>ESWA</em>, <em>298</em>, 129466. (<a href='https://doi.org/10.1016/j.eswa.2025.129466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of data, numerous e-commerce platforms are actively collecting consumer data to obtain business insights. However, consumers and merchants on platforms exhibit diverse attribution behaviors, including single-homing and multi-homing (access to only one platform/multiple platforms), not only affecting the platform’s market scale but also complicating their data provision strategies and data pricing strategies. Inspired by this practice, this paper considers varying attribution behaviors and studies the data operation strategies of competitive platforms. By constructing a two-period game model, we capture the entire process of platform’s data collection and provision, and solve the equilibrium decisions by reverse solution method. This research aims to identify the impact of attribution behaviors on platforms’ data strategies, thereby filling the gap in analyzing this issue from the perspective of two-sided platforms. Results show that when both groups of users (consumers and merchants) are multi-homing, platform facing higher operational costs may benefit more from implementing low data provision but high data pricing strategy, while more cost-efficient platform may choose the opposite strategy. This strategy is still applicable when only one group of users (consumers) becomes single-homing. However, once both groups of users are single-homing, both platforms’ strategies will change. Specifically, when merchant’s cross-side network effect (CNE) intensity is relatively low (high), compared with less cost-efficient platform, platform enjoying cost efficiencies should provide more (less) data at a relatively high (low) price. Moreover, platforms should cautiously provide data when both groups of users are single-homing, as it may hurt profits.},
  archive      = {J_ESWA},
  author       = {Wei Chen and Yijia Hu and Ronghua Sui and Zili Guan and Yi Liu},
  doi          = {10.1016/j.eswa.2025.129466},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129466},
  shortjournal = {Expert Syst. Appl.},
  title        = {Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration. <em>ESWA</em>, <em>298</em>, 129465. (<a href='https://doi.org/10.1016/j.eswa.2025.129465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the multi-trip vehicle routing problem with time windows (MTVRPTW) and its variants have been extensively studied, their application in natural disaster contexts remains underexplored. This study addresses this gap by developing a model and solution algorithm for the MTVRPTW with limited trip duration (MTVRPTW-LD), tailored to emergency supplies distribution in the early post-disaster phase. First, we replace the service-dependent loading time in traditional models with service-dependent unloading time and formulate an MTVRPTW-LD model to minimize total operational time, encompassing travel, service, and unloading times, based on the characteristics of emergency supplies distribution. Furthermore, a more practical method for calculating travel time is proposed to enhance the model’s applicability. Subsequently, a branch-and-price algorithm is designed to solve the MTVRPTW-LD model, in which the cumulative relative deprivation cost (CRDC) is introduced to improve equity in emergency supplies distribution. Finally, we conduct numerical experiments on Solomon instances and test instances generated based on emergency scenarios. The results show that, in the test instances, incorporating CRDC can improve the equity by up to 34.3 %.},
  archive      = {J_ESWA},
  author       = {Longfei Fan and Zhongming Wu and Zaiwu Gong and David Z.W. Wang},
  doi          = {10.1016/j.eswa.2025.129465},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129465},
  shortjournal = {Expert Syst. Appl.},
  title        = {Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy. <em>ESWA</em>, <em>298</em>, 129460. (<a href='https://doi.org/10.1016/j.eswa.2025.129460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pareto set (PS) of a continuous multi-objective optimization problem exhibit a distribution along a low-dimensional manifold structure. This regularity property significantly contributes to generating high-quality offspring in large-scale multi-objective evolutionary algorithms (LSMOEAs). However, conventional regularity model-based algorithms face several challenges when dealing with large-scale multi-objective optimization problems (LSMOPs), including high computational costs for modeling, difficulty in capturing the true PS structure, and neglecting individual directional information. To address these challenges, we propose a dual-information offspring reproduction strategy that considers both the distribution information of the population and the directional information of the outstanding individuals. Specifically, this strategy comprises a sampling approach based on an augmented regularity model specifically designed for LSMOPs. Leveraging this model, we explore and exploit the decision space to sample a promising set of solutions. Additionally, the strategy also involves a search method based on competitive learning among individuals. By assigning a positive evolutionary direction to losing solutions, we update the losing solutions to generate high-quality offspring. We continuously refine the proposed regularity model to approximate the true PS more closely. In extensive experiments on large-scale multi-objective benchmark functions, we compare our algorithm with eight state-of-the-art algorithms. The results demonstrate that our approach excels in handling LSMOPs.},
  archive      = {J_ESWA},
  author       = {Ying Wu and Ziliang Du and Gonglin Yuan and Zhenzhou Tang and Ferrante Neri and Yaqing Hou},
  doi          = {10.1016/j.eswa.2025.129460},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129460},
  shortjournal = {Expert Syst. Appl.},
  title        = {Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning. <em>ESWA</em>, <em>298</em>, 129448. (<a href='https://doi.org/10.1016/j.eswa.2025.129448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying product defects and process anomalies in manufacturing processes is a critical task for product quality and system stability. Although the existing unsupervised anomaly detection methods do not require the annotation of anomalies, they are difficult to deal with the zero-shot scenario faced by multi-variety and small-batch production where there is no available data. In addition, many zero-shot detection algorithms need to represent the image features in tensor form with multiple local feature vectors, and then measure each local feature to infer the overall anomaly of the object. In this paper, we propose GlobalCLIP, a novel approach for zero-shot anomaly detection using only global feature vectors to enhance performance. Specifically, we use CLIP model to aggregate the global features, and design two kinds of adaptive modules from the error level and uncertainty level to realize the series integration of different discriminant models. The adaptive modules encourage the model to learn both normal and abnormal patterns with different granularity, and the self-cyclic training progressively improves model performance. Experiments show that compared to many unsupervised/weakly supervised methods, the performance of GlobalCLIP maintains its advantage even without known samples, and achieves significant improvement over available zero-shot methods.},
  archive      = {J_ESWA},
  author       = {Haoyuan Shen and Enrico Zio and Jiawei Xiong and Yizhong Ma},
  doi          = {10.1016/j.eswa.2025.129448},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129448},
  shortjournal = {Expert Syst. Appl.},
  title        = {GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Key performance indicator-related process monitoring for irregular scenarios with incomplete data. <em>ESWA</em>, <em>298</em>, 129440. (<a href='https://doi.org/10.1016/j.eswa.2025.129440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industries exhibit irregular characteristics due to factors such as mode transitions, incomplete data and outliers. Accurate monitoring of key performance indicators (KPIs) in irregular processes is essential for improving product quality and reducing scrap rates. This paper proposes a novel KPI-related process monitoring method that leverages the multiple kernel learning (MKL) technique, designed specifically for irregular scenarios with incomplete data. First, a novel MKL-based nonlinear matrix completion is proposed that utilizes a hierarchical strategy-based algorithm to estimate the missing values in incomplete data and the linear coefficients of multiple kernels. In addition, the corresponding convergence analysis is given. Based on the estimated completed data matrix, a novel MKL-based feature correlation analysis is proposed for indirect prediction of KPIs. Two statistics are established for detecting KPI-related and KPI-unrelated faults, respectively. A numerical case and an industrial example demonstrate that the proposed method not only accurately identifies the missing data, but also effectively detects the KPI-related faults.},
  archive      = {J_ESWA},
  author       = {Yanyu Chen and Hao Ma and Yan Wang and Xiang Liu},
  doi          = {10.1016/j.eswa.2025.129440},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129440},
  shortjournal = {Expert Syst. Appl.},
  title        = {Key performance indicator-related process monitoring for irregular scenarios with incomplete data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm. <em>ESWA</em>, <em>298</em>, 129437. (<a href='https://doi.org/10.1016/j.eswa.2025.129437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, practical machine learning methodologies are extensively employed for the automation of detecting the intrusion available in the network. In key infrastructure scenarios involving communication strategies, the interplay between different industrial control systems and the inherent connection to the Internet environment through the Internet of Things renders them vulnerable to cyber threats. Considering the substantial volume of network traffic within critical Cyber-Physical Systems, conventional machine-learning approaches utilized for detecting anomalies prove to be ineffective. Hence, newly designed machine learning methods, with a focus on deep learning, are demonstrating effective applications in identifying and categorizing anomalies on both network and individual device levels. This article introduces an innovative Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm designed for the identification of cyber threats. To augment the effectiveness of the suggested method, it employs a dual-step process for the detection of network irregularities. During the initial phase, the approach involves data pre-processing and dimensionality reduction through the application of Kernel Principal Component Analysis to select the most suitable features. In the subsequent stage, the novel Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm is employed for classification. The effectiveness of the approach presented in this study is evaluated on diverse datasets, encompassing information collected within the Internet of Things context, specifically IoT-23 and LITNET-2020 datasets. The findings of the assessment of the suggested method are deliberated upon, including the examination of statistical significance and a comparative analysis with contemporary approaches in the field of network anomaly detection. Evaluations confirmed this robust model attained 98.56% accuracy, 97.78% precision, 98.2% F1-score, and produced less FPR of 1.55%.},
  archive      = {J_ESWA},
  author       = {Prabakeran Saravanan and Annamalai Balaji and Hemalatha Murugan and Manickam Muruganantham and Indumathi Varadharajan},
  doi          = {10.1016/j.eswa.2025.129437},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129437},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved DQN-based recommender system on three-way decision. <em>ESWA</em>, <em>298</em>, 129431. (<a href='https://doi.org/10.1016/j.eswa.2025.129431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems, which utilize algorithms and data analysis to provide personalized suggestions to users, have become an indispensable part of modern life. However, traditional recommendation algorithms face challenges such as the cold start problem, lack of diversity, and limited scalability. Reinforcement learning (RL), particularly deep reinforcement learning (DRL), emerges as a promising solution to these problems by allowing agents to learn optimal strategies through interaction with their environment. Nevertheless, as the scale of data increases, RL-based recommendation systems often struggle to achieve a good balance between exploration and exploitation, impacting the overall performance of the algorithms. In this paper, we propose a reinforcement learning-based recommendation algorithm enhanced by a three-way decision (3WD) framework to address the exploration-exploitation balance challenge. The 3WD algorithm, rooted in rough set theory, categorizes decision outcomes into acceptance, rejection, and uncertainty regions. By applying 3WD in the action selection process of RL, we optimize the trade-off between exploration and exploitation, thereby improving the quality and computational efficiency of recommendations. Additionally, we introduce a dynamic threshold adjustment mechanism to adaptively refine the decision boundary during the action selection process in reinforcement learning, further enhancing the algorithm’s performance. Using the MovieLens dataset as a foundation, we conduct extensive experiments with several randomly generated data sets to evaluate the proposed method. Our results demonstrate that the 3WD-based RL algorithm outperforms traditional methods, such as epsilon-greedy and Softmax, in terms of runtime, recommendation accuracy, and error rate. Notably, the dynamic threshold adjustment model exhibits greater stability and surpasses static methods in recommendation success rates. These findings highlight the effectiveness of combining 3WD with RL in recommendation systems, providing a powerful and efficient solution to the challenges faced by traditional methods. Finally, we analyze the limitations of the model based on the experimental results and propose avenues for future research.},
  archive      = {J_ESWA},
  author       = {Zian Chen and Bao Qing Hu},
  doi          = {10.1016/j.eswa.2025.129431},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129431},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved DQN-based recommender system on three-way decision},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports. <em>ESWA</em>, <em>298</em>, 129429. (<a href='https://doi.org/10.1016/j.eswa.2025.129429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an Integral Gaussian Process (IntegralGP) framework for volumetric estimation of subterranean properties in mineral deposits. It provides a unified representation for data with different spatial supports, which enables blasthole geochemical assays to be properly modelled as interval observations rather than points. This approach is shown to improve regression performance and boundary delineation. A core contribution is a description of the mathematical changes to the covariance expressions which allow these benefits to be realised. The gradient and anti-derivatives are obtained to facilitate learning of the kernel hyperparameters. Numerical stability issues are also discussed. To illustrate its application, an IntegralGP data fusion algorithm is described. The objective is to assimilate line-based blasthole assays and update a block model that provides long-range prediction of Fe concentration beneath the drilled bench. Heteroscedastic GP is used to fuse chemically compatible but spatially incongruous data with different resolutions and sample spacings. Domain knowledge embodied in the structure and empirical distribution of the block model must be generally preserved while local inaccuracies are corrected. Using validation measurements within the predicted bench, our experiments demonstrate an improvement in bench-below grade prediction performance. For material classification, IntegralGP fusion reduces the absolute error and model bias in categorical prediction, especially instances where waste blocks are mistakenly classified as high-grade.},
  archive      = {J_ESWA},
  author       = {Anna Chlingaryan and Arman Melkumyan and Raymond Leung},
  doi          = {10.1016/j.eswa.2025.129429},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129429},
  shortjournal = {Expert Syst. Appl.},
  title        = {IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer. <em>ESWA</em>, <em>298</em>, 129406. (<a href='https://doi.org/10.1016/j.eswa.2025.129406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a Deep Multi-view Least Squares Support Vector Machine with Consistency and Complementarity Principles based on Cross-Output Knowledge Transfer (MDCTM), which has four distinctive features: 1) It integrates the idea of deep stacking architecture, which is the first attempt to use transfer learning to form deep architectures in multi-view learning. It can enhance the ability to handle complex problems. Starting from the second layer, it incorporates extra input attributes that consider the predictions made by all preceding layers, effectively revealing the manifold structure of the original data. 2) Each layer follows the consistency and complementarity principles, which can fully excavate the information in multi-view data. In each layer, the model is solved by an alternating optimization strategy. 3) Cross-output knowledge transfer leverages predictions from earlier layers to improve the learning of subsequent ones, which can improve the classification performance of the model. Additionally, the extent of cross-output knowledge transfer between sequential layers can be assessed autonomously and effectively by utilizing a fast leave-one-out cross-validation method. 4) The model allows random assignment of model parameters in each layer, such as weights and kernel widths, boosting learning speed. Numerical experiments demonstrate the model’s effectiveness and efficiency.},
  archive      = {J_ESWA},
  author       = {Shuangrui Jia and Sijie Liang and Ziyi Mo and Chunxiao Liu and Huiru Wang and Chen Chen},
  doi          = {10.1016/j.eswa.2025.129406},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129406},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting. <em>ESWA</em>, <em>298</em>, 129388. (<a href='https://doi.org/10.1016/j.eswa.2025.129388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Koopman operator provides a new way to model complex data patterns, revealing the intrinsic dynamics of time series from a dynamical system perspective. Despite its potential, the Koopman operator has received limited attention in time series forecasting, particularly in addressing these complex, real-world challenges such as carbon emission dynamics characterized by nonlinearity, non-stationarity, and multi-scale coupling effects. To this end, this study proposes a novel forecasting paradigm, Fourier-Enhanced adaptive Koopman operator for carbon emission forecasting (F-KOCE). This approach conceptually extends traditional Koopman frameworks by embedding a spectral-decoupled time series representation into a dual Koopman learning structure, which enables the model to linearize nonlinear dynamics across multiple time scales in a theoretically grounded and practically adaptive manner. By integrating Fourier filter decomposition into Koopman operator theory, F-KOCE separates raw emissions into long-term trends and short-term fluctuations while achieving global linearization of system dynamics. A learnable Koopman operator captures intrinsic temporal structures, while a multi-granularity adaptive weight learning strategy enhances resilience against data variability. To further improve robustness, we introduce an adaptive residual fusion structure for block-level feature compression, noise suppression, and cross-scale information fusion. Additionally, the effective Trend Corrector mechanism dynamically modulates the influence of trend and fluctuation components, refining predictive accuracy. Beyond point forecasting, the framework is also extended to interval forecasting, providing uncertainty-aware predictions. Extensive experiments conducted on 36 Carbon Monitor datasets across six regions and six sectors demonstrate the superiority of F-KOCE over advanced existing models across multiple evaluation metrics. These results confirm the framework’s efficacy in capturing high-dimensional emission dynamics and underscore the potential of Koopman operator theory in carbon forecasting. By offering a robust, interpretable, and data-driven approach, F-KOCE provides valuable insights for climate policy formulation.},
  archive      = {J_ESWA},
  author       = {Jinxing Che and Wei Dong and Qian Sun and Yuhua Zhang},
  doi          = {10.1016/j.eswa.2025.129388},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129388},
  shortjournal = {Expert Syst. Appl.},
  title        = {A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems. <em>ESWA</em>, <em>298</em>, 129364. (<a href='https://doi.org/10.1016/j.eswa.2025.129364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 0–1 knapsack problem (KP) is a well-known combinatorial optimization problem with wide real-world applications. While evolutionary algorithms have demonstrated promise in solving 0–1 KPs, their performance deteriorates as the problem dimension increases. Cooperative co-evolution (CC) is an algorithmic framework based on a divide-and-conquer strategy, which has been used in solving large-scale optimization problems. Inspired by the similarity between item grouping in the 0–1 KP and decomposition strategies in CC, this paper proposes a novel grouping strategy that uses the position information of break items and profit-to-weight ratio to solve large-scale 0–1 KP. The strategy aims to divide the large-scale 0–1 KP into multiple subproblems, thus having a reduced search space for each subproblem. To enhance population diversity and search efficiency, the profit-to-weight ratio is used to generate an initial elite population. Additionally, to obtain the complete solution for the original large-scale KP, a subgroup merging method is designed to accelerate convergence and further improve population diversity. A three-phase repair operator is developed to fix infeasible solutions directly to create more feasible solutions. The resulting cooperative co-evolutionary algorithm is compared with ten state-of-the-art algorithms for solving 0–1 KPs with variables ranging from 100 to 5,000, including EAs, CC-based approaches, and a deep reinforcement learning method. Experimental results show that the proposed algorithm exhibits higher solution accuracy and faster convergence than other competing algorithms. The CC framework takes considerably less running time than high-performing algorithms, providing an overall novel approach for solving large-scale 0–1 KPs.},
  archive      = {J_ESWA},
  author       = {Xiaotong Li and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.eswa.2025.129364},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129364},
  shortjournal = {Expert Syst. Appl.},
  title        = {A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing forecast accuracy and switching costs in online optimization of energy management systems. <em>ESWA</em>, <em>298</em>, 129305. (<a href='https://doi.org/10.1016/j.eswa.2025.129305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the integration of forecasting and optimization in energy management systems, focusing on how switching costs, penalties incurred from frequent operational adjustments, affect the balance between forecast accuracy and stability in online decision-making. We develop a theoretical framework analyzing Fixed Horizon Control (FHC) algorithms under switching costs, deriving performance bounds that reveal trade-offs between commitment periods and forecast properties. We introduce a novel Scenario Distribution Change (SDC) metric for measuring temporal consistency in probabilistic forecasts. The framework is validated through empirical evaluation using a real-world battery scheduling case study based on the CityLearn 2022 challenge, comparing deterministic and stochastic optimization approaches across different commitment periods. Theoretical analysis reveals that switching costs create a U-shaped relationship between commitment period and performance, with optimal commitment depending on forecast stability. Empirical results demonstrate that switching costs significantly alter the accuracy-stability trade-off: while traditional approaches favor frequent updates (1-hour commitment), incorporating switching costs makes longer commitment periods (3+ hours) optimal when combined with stable forecasts. Stochastic optimization with scenario averaging reduces forecast error sensitivity by up to 2.9 % in grid costs compared to deterministic approaches. This work contributes the first theoretical bounds linking forecast stability to switching costs in energy systems, the SDC metric for evaluating probabilistic forecast stability, empirical evidence that longer commitment periods can outperform frequent updates under switching costs, and practical guidelines showing that forecast stability should be factored into decision-making frameworks for energy management systems in the presence of switching costs.},
  archive      = {J_ESWA},
  author       = {Evgenii Genov and Julian Ruddick and Christoph Bergmeir and Majid Vafaeipour and Thierry Coosemans and Salvador García and Maarten Messagie},
  doi          = {10.1016/j.eswa.2025.129305},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129305},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing forecast accuracy and switching costs in online optimization of energy management systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation. <em>ESWA</em>, <em>298</em>, 129267. (<a href='https://doi.org/10.1016/j.eswa.2025.129267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arm trajectory planning of crack repair is critical for automated road maintenance. However, existing crack repair face two main challenges: loss of trajectory edge information and redundant planned distances. This study introduces an automated pavement crack repair system that integrates a lightweight crack segmentation model (Lightweight Focal Modulation, LFM-Net) and a repair trajectory planning algorithm (Fixed Neighborhood Search-Artificial Bee Colony, FNS-ABC). Specifically, LFM-Net incorporates conformer-based focal modulation attention (CFMA), enhancing the detailed information during the decoding phase. Additionally, the FNS-ABC enhances the ABC algorithm by incorporating a fixed neighborhood search strategy, effectively reducing redundant planning paths. The system is executed using a self-developed robotic arm with an edge computing unit. Extensive testing in three typical road scenarios-independent cracks, intersection cracks, and complex cracks-demonstrated that the system achieved a mean Intersection over Union (mIoU) of 83.93 %. Finally, the system exhibited an idle trajectory of 79.51 mm when addressing complex cracks, highlighting its superior performance in repair trajectory planning.},
  archive      = {J_ESWA},
  author       = {Jianqi Zhang and Xu Yang and Wei Wang and Yuhang Zhao and Hainian Wang and Yixue Chen},
  doi          = {10.1016/j.eswa.2025.129267},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129267},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-learning based big data analysis for developing a smart supply chain for increased efficiency. <em>ESWA</em>, <em>298</em>, 129246. (<a href='https://doi.org/10.1016/j.eswa.2025.129246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analysis (BDA) in supply chain management (SCM) is receiving growing attention in the present business environment. This is due to the fact that BDA has a wide range of applications in SCM, including customer behaviour analysis, trend analysis, and demand prediction. The increase in information volume has caused the efficiency and effectiveness of traditional procedures to decline, considering this, researchers have developed techniques that have a high capacity to investigate and comprehend vast amounts of data due to the limitations of these tactics in dissecting and interpreting a lot of information. This study represents a hybrid paper that combines a systematic literature review, a methodological proposal using BP neural networks. The main objective of this paper is to recognize the uses of deep learning in SCM. By fostering a calculated system, this paper recognizes the commitments of deep learning strategies in choosing and sectioning providers, foreseeing store network gambles, and assessing requests and deals, creation, stock administration, transportation and circulation, manageable turn of events, and roundabout economy. The novelty in this paper is the Backpropagation (BP) neural networks with big data-driven demand forecasting in supply chains. This method can improve the accuracy of demand forecasting in supply chain management. The study includes a thorough survey of the applications of predictive BDA in SC request gauging. The review highlighted the BDA methodologies used for production network request estimation and comparatively classified them. We collected and analysed these studies as tactics and methodologies for the popular forecast. Seven standard tactics were selected and studied, along with their benefits and drawbacks. Finally, the box-cox transformation representation over years in which for the year 2011–01, it starts with a box-cox value of 9.7 and it inclined till 2011–06 and then declined very exponentially in 2012–07 at 9 and then it keeps on incrementing and reached at 11 at the year 2013–07. Then from 2014 to 2015, the pattern didn’t lower below the box-cox value 10.},
  archive      = {J_ESWA},
  author       = {Sreekumar Narayanan and Sudhir Ramadass and K. Thilagavathi and Rajiv Kumar},
  doi          = {10.1016/j.eswa.2025.129246},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129246},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-learning based big data analysis for developing a smart supply chain for increased efficiency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="iandc">IANDC - 9</h2>
<ul>
<li><details>
<summary>
(2025). Polynomial turing compressions for some graph problems parameterized by modular-width. <em>IANDC</em>, <em>307</em>, 105355. (<a href='https://doi.org/10.1016/j.ic.2025.105355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A polynomial Turing compression (PTC) for a parameterized problem L is a polynomial time Turing machine that has access to an oracle for a problem L ′ such that a polynomial in the input parameter bounds each query. Meanwhile, a polynomial compression (PC) can be regarded as a restricted variant of PTC where the machine can query the oracle exactly once and must output the same answer as the oracle. Bodlaender et al. (ICALP 2008) and Fortnow and Santhanam (STOC 2008) initiated an impressive hardness theory for PC under the assumption coNP ⊈ NP/poly. Let C be the set of all problems with PTCs but without PCs assuming coNP ⊈ NP/poly. Fernau et al. (STACS 2009) identified Leaf Out-tree( k ) as the first problem in C . However, little is known about C , with only a dozen problems confirmed in it over the last fifteen years. Open questions remain, such as whether CNF-SAT( n ) and k -path are in C , requiring novel ideas to clarify the differences between PTCs and PCs. In this paper, we enrich our knowledge about C by demonstrating that 17 problems parameterized by modular-width ( mw ), such as Chromatic Number( mw ) and Hamiltonian Cycle( mw ) , belong to C . Additionally, we develop a general recipe to prove the existence of PTCs for a class of problems, including these 17.},
  archive      = {J_IANDC},
  author       = {Weidong Luo},
  doi          = {10.1016/j.ic.2025.105355},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105355},
  shortjournal = {Inf. Comput.},
  title        = {Polynomial turing compressions for some graph problems parameterized by modular-width},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On cardinalities of rogers semilattices for families in the ershov hierarchy. <em>IANDC</em>, <em>307</em>, 105354. (<a href='https://doi.org/10.1016/j.ic.2025.105354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of numberings provides classification results for families of sets in various computability-theoretic hierarchies. The algorithmic content of numberings is typically calibrated via the reducibility between numberings. For a given family of sets S , this reducibility gives rise to an upper semilattice of degrees that is often called the Rogers semilattice of S . This paper studies the cardinalities of Rogers semilattices for families of sets at finite levels of the Ershov hierarchy. The classical result of Khutoretskii (1971) shows that the Rogers semilattice of a family of c.e. sets is either one-element or countably infinite. Badaev and Lempp (2009) constructed a family of d.c.e. sets that demonstrates that the methods of Khutoretskii cannot be applied to obtain a similar result for Rogers semilattices already at the second level of the Ershov hierarchy. We prove that for any finite family of sets S at any finite level of the Ershov hierarchy, the corresponding Rogers semilattice is either one-element or countably infinite. We also obtain another sufficient condition for a Rogers semilattice to be infinite. This condition implies that the Rogers semilattice of Badaev and Lempp is also infinite.},
  archive      = {J_IANDC},
  author       = {Keng Meng Ng and Nikolay Bazhenov and Birzhan Kalmurzayev and Dias Nurlanbek},
  doi          = {10.1016/j.ic.2025.105354},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105354},
  shortjournal = {Inf. Comput.},
  title        = {On cardinalities of rogers semilattices for families in the ershov hierarchy},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact counting of subtrees with diameter no more than d in trees: A generating function approach. <em>IANDC</em>, <em>307</em>, 105353. (<a href='https://doi.org/10.1016/j.ic.2025.105353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network motifs, regarded as fundamental building blocks, offer crucial insights into the structure and function of complex networks, with broad applications across disciplines including sociology, computer science, bioinformatics, chemoinformatics, and pharmaceutics. However, the identification of network motifs remains a significant and computationally challenging problem. Among various motifs, subtree enumeration has garnered substantial attention in recent years, particularly due to its relevance in network science and bioinformatics. For an n -vertex tree T , by introducing novel generating functions with ( d + 2 ) variables, we propose an innovative algorithm for the exact enumeration of T 's subtrees rooted at fixed vertex v , where the distance between v and the farthest leaf is k = 0 , 1 , … , d , and the distance between any two leaves is no more than d . Building on this algorithm, we develop novel recursive algorithms for exact enumerating various diameter no more than d subtrees (abbreviated as DNMT- d subtrees) of T . As applications, we apply these algorithms to derive the number of DNMT- d subtrees in a full binary tree B h with h ≥ 2 levels, and briefly discuss the density of DNMT- d subtrees in general trees. Our research generalizes the work of Frank Ruskey on Listing and Counting Subtrees of a Tree in 1981 and makes it a special case of our study where d equals the diameter of the tree T . Moreover, the proposed O ( d n 2 ) algorithms introduce new approaches for enumerating subtrees under diameter constraints and lay the groundwork for counting diameter-constrained subgraphs (motifs) in complex networks.},
  archive      = {J_IANDC},
  author       = {Yu Yang and Bang-Bang Jin and Xiaoming Sun and Xiao-Dong Zhang and Bo Li and Kai Zhao and Hua Wang},
  doi          = {10.1016/j.ic.2025.105353},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105353},
  shortjournal = {Inf. Comput.},
  title        = {Exact counting of subtrees with diameter no more than d in trees: A generating function approach},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision problems for systems of language equations and inequations. <em>IANDC</em>, <em>307</em>, 105344. (<a href='https://doi.org/10.1016/j.ic.2025.105344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems of language equations φ ( X 1 , … , X n ) = ψ ( X 1 , … , X n ) and inequations φ ( X 1 , … , X n ) ≠ ψ ( X 1 , … , X n ) are studied, where φ and ψ may contain Boolean operations and concatenation. It is proved that the problem whether such a system has a solution is Σ 2 0 -complete in the arithmetical hierarchy (cf. the earlier studied case of equations only, where it is co-r.e.-complete), the problem whether it has a unique solution is in Σ 3 0 ∩ Π 3 0 , and is both Σ 2 0 -hard and Π 2 0 -hard, existence of a finite or regular solution is an r.e.-complete problem, while testing whether a system has finitely many solutions is Σ 3 0 -complete. Furthermore, it is shown that the class of languages representable by unique solutions of such systems is exactly the class of recursive sets, but decision procedures for the set cannot be algorithmically constructed out of a system. All results hold already for equations over a unary alphabet.},
  archive      = {J_IANDC},
  author       = {Alexander Okhotin},
  doi          = {10.1016/j.ic.2025.105344},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105344},
  shortjournal = {Inf. Comput.},
  title        = {Decision problems for systems of language equations and inequations},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards a theoretical understanding of why local search works for clustering with fair-center representation. <em>IANDC</em>, <em>307</em>, 105343. (<a href='https://doi.org/10.1016/j.ic.2025.105343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The representative k -median problem generalizes the classical clustering formulations in that it partitions the data points into ℓ disjoint demographic groups and imposes a lower-bound constraint on the number of opened facilities from each group, such that all the groups are fairly represented by the opened facilities. Due to its simplicity, the local-search heuristic, which iteratively swaps a bounded number of closed facilities for the same number of opened ones to improve the solution, has been frequently used in the representative k -median problem. It is known that the local-search heuristic, when restricted to constant-size swaps, yields a constant-factor approximation if ℓ = 2 , and has an unbounded approximation ratio if ℓ is super-constant. However, for any constant ℓ > 2 , the existence of a constant-factor approximation under constant-size swaps remained an open question for a long time. In response to this question, we demonstrate that the local-search heuristic guarantees a ( 4 ℓ + 5 ) -approximation when up to ℓ ( ℓ + 1 ) facilities are allowed to be swapped in each iteration, thus providing an affirmative answer to the question. Our main technical contribution is a novel approach for theoretically analyzing the local-search heuristic, which bounds its approximation ratio by linearly combining the clustering cost increases induced by a set of hierarchically organized swaps. Our techniques also generalize to the k -means clustering formulation and reveal similar approximation guarantees for the local-search heuristic.},
  archive      = {J_IANDC},
  author       = {Zhen Zhang and Junfeng Yang and Limei Liu and Xuesong Xu and Guozhen Rong and Qilong Feng},
  doi          = {10.1016/j.ic.2025.105343},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105343},
  shortjournal = {Inf. Comput.},
  title        = {Towards a theoretical understanding of why local search works for clustering with fair-center representation},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The billaud conjecture for alphabet size 4. <em>IANDC</em>, <em>307</em>, 105342. (<a href='https://doi.org/10.1016/j.ic.2025.105342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Billaud Conjecture, first stated in 1993, is a fundamental problem on finite words and their heirs, i.e., the words obtained by a projection deleting a single letter. The conjecture states that every morphically primitive word, i.e., a word that is not a fixed point of any non-identity morphism, has at least one morphically primitive heir. The correctness of the conjecture has so far been established in a few special cases, which mainly restrict the alphabet size. In this paper we give a proof for the next such case, i.e., for alphabet size 4.},
  archive      = {J_IANDC},
  author       = {Szymon Łopaciuk and Daniel Reidenbach},
  doi          = {10.1016/j.ic.2025.105342},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105342},
  shortjournal = {Inf. Comput.},
  title        = {The billaud conjecture for alphabet size 4},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The g-good-neighbor diagnosability of product networks under the PMC model. <em>IANDC</em>, <em>307</em>, 105341. (<a href='https://doi.org/10.1016/j.ic.2025.105341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of neighbor connectivity originated from the assessment of the subversion of espionage networks caused by underground resistance movements, and it has now been applied to measure the disruption of networks caused by cascading failures through neighbors. In this paper, we give two necessary and sufficient conditions of the existence of g -good-neighbor diagnosability. We introduce a new concept called g -good neighbor cut-component number (gc number for short), which has close relation with g -good-neighbor diagnosability. Sharp lower and upper bounds of the gc number of general graphs in terms of the g -good neighbor connectivity have been proposed, which provide a formula to compute the g -good-neighbor diagnosability for general graphs (therefore for Cartesian product graphs). As their applications, we get the exact values or bounds for the gc numbers and g -good-neighbor diagnosability of grid, torus networks and generalized cubes.},
  archive      = {J_IANDC},
  author       = {Zhao Wang and Yaping Mao and Sun-Yuan Hsieh and Ralf Klasing},
  doi          = {10.1016/j.ic.2025.105341},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105341},
  shortjournal = {Inf. Comput.},
  title        = {The g-good-neighbor diagnosability of product networks under the PMC model},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-state spin systems with negative interactions. <em>IANDC</em>, <em>307</em>, 105340. (<a href='https://doi.org/10.1016/j.ic.2025.105340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the approximability of computing the partition functions of two-state spin systems. The problem is parameterized by a 2 × 2 symmetric matrix. Previous results on this problem were restricted either to the case where the matrix has non-negative entries, or to the case where the diagonal entries are equal, i.e. Ising models. In this paper, we study the generalization to arbitrary 2 × 2 interaction matrices with real entries. We show that in some regions of the parameter space, it's #P-hard to even determine the sign of the partition function, while in other regions there are fully polynomial approximation schemes for the partition function. Our results reveal several new computational phase transitions.},
  archive      = {J_IANDC},
  author       = {Yumou Fei and Leslie Ann Goldberg and Pinyan Lu},
  doi          = {10.1016/j.ic.2025.105340},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105340},
  shortjournal = {Inf. Comput.},
  title        = {Two-state spin systems with negative interactions},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competition among parallel contests. <em>IANDC</em>, <em>307</em>, 105339. (<a href='https://doi.org/10.1016/j.ic.2025.105339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the model of multiple rank-order contests held in parallel, where each contestant only selects one contest to join and each contest designer decides the prize structure to compete for the participation of contestants. We first analyze the strategic behaviors of contestants and completely characterize the symmetric Bayesian Nash equilibrium. As for the strategies of contest designers, when other designers' strategies are known, we show that computing the best response is NP-hard and propose a fully polynomial time approximation scheme to output the ϵ -approximate best response. When other designers' strategies are unknown, we provide a worst-case analysis on one designer's strategy. We give an upper bound on the worst-case utility of any strategy and propose a method to construct a strategy whose utility can guarantee a constant ratio of this upper bound in the worst case.},
  archive      = {J_IANDC},
  author       = {Xiaotie Deng and Ningyuan Li and Weian Li and Qi Qi},
  doi          = {10.1016/j.ic.2025.105339},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105339},
  shortjournal = {Inf. Comput.},
  title        = {Competition among parallel contests},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="icv">ICV - 11</h2>
<ul>
<li><details>
<summary>
(2025). Mining fine-grained attributes for vision–semantics integration in few-shot learning. <em>ICV</em>, <em>163</em>, 105739. (<a href='https://doi.org/10.1016/j.imavis.2025.105739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Few-Shot Learning (FSL) have been significantly driven by leveraging semantic descriptions to enhance feature discrimination and recognition performance. However, existing methods, such as SemFew, often rely on verbose or manually curated attributes and apply semantic guidance only to the support set, limiting their effectiveness in distinguishing fine-grained categories. Inspired by human visual perception, which emphasizes crucial features for accurate recognition, this study introduces concise, fine-grained semantic attributes to address these limitations. We propose a Visual Attribute Enhancement (VAE) mechanism that integrates enriched semantic information into visual features, enabling the model to highlight the most relevant visual attributes and better distinguish visually similar samples. This module enhances visual features by aligning them with semantic attribute embeddings through a cross-attention mechanism and optimizes this alignment using an attribute-based cross-entropy loss. Furthermore, to mitigate the performance degradation caused by methods that supply semantic information exclusively to the support set, we propose a semantic attribute reconstruction (SAR) module. This module predicts and integrates semantic features for query samples, ensuring balanced information distribution between the support and query sets. Specifically, SAR enhances query representations by aligning and reconstructing semantic and visual attributes through regression and optimal transport losses to ensure semantic–visual consistency. Experiments on five benchmark datasets, including both general datasets and more challenging fine-grained Few-Shot datasets consistently demonstrate that our proposed method outperforms state-of-the-art methods in both 5-way 1-shot and 5-way 5-shot settings.},
  archive      = {J_ICV},
  author       = {Juan Zhao and Lili Kong and Deshang Sun and Deng Xiong and Jiancheng Lv},
  doi          = {10.1016/j.imavis.2025.105739},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105739},
  shortjournal = {Image Vis. Comput.},
  title        = {Mining fine-grained attributes for vision–semantics integration in few-shot learning},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable deepfake detection across different modalities: An overview of methods and challenges. <em>ICV</em>, <em>163</em>, 105738. (<a href='https://doi.org/10.1016/j.imavis.2025.105738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of deepfake technology enables the creation of realistic and deceptive content, raising concerns about several serious issues, including biometric authentication, misinformation, politics, privacy, and trust. Many Deepfake Detection (DD) models are entering the market to combat the misuse of deepfakes. With these developments, one primary issue occurs in ensuring the explainability of the proposed detection models to understand the rationale of the decision. This paper aims to investigate the state-of-the-art explainable DD models across multiple modalities, including image, video, audio, and text. Unlike existing surveys that focus on detection methodologies with minimal attention to explainability and limited modality coverage, this paper directly focuses on these gaps. It offers a comprehensive analysis of advanced explainability techniques, including Grad-CAM, LIME, SHAP, LRP, Saliency Maps, and Anchors, for detecting deceptive content across the modalities. It identifies the strengths and limitations of existing models and outlines research directions to enhance explainability and interpretability in future works. By exploring these models, we aim to enhance transparency, provide deeper insights into model decisions, and bridge the gap between detection accuracy with explainability in DD models.},
  archive      = {J_ICV},
  author       = {MD Sarfaraz Momin and Abu Sufian and Debaditya Barman and Marco Leo and Cosimo Distante and Naser Damer},
  doi          = {10.1016/j.imavis.2025.105738},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105738},
  shortjournal = {Image Vis. Comput.},
  title        = {Explainable deepfake detection across different modalities: An overview of methods and challenges},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MITS: A large-scale multimodal benchmark dataset for intelligent traffic surveillance. <em>ICV</em>, <em>163</em>, 105736. (<a href='https://doi.org/10.1016/j.imavis.2025.105736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General-domain large multimodal models (LMMs) have achieved significant advances in various image-text tasks. However, their performance in the Intelligent Traffic Surveillance (ITS) domain remains limited due to the absence of dedicated multimodal datasets. To address this gap, we introduce MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale multimodal benchmark dataset specifically designed for ITS. MITS includes 170,400 independently collected real-world ITS images sourced from traffic surveillance cameras, annotated with eight main categories and 24 subcategories of ITS-specific objects and events under diverse environmental conditions. Additionally, through a systematic data generation pipeline, we generate high-quality image captions and 5 million instruction-following visual question-answer pairs , addressing five critical ITS tasks : object and event recognition, object counting, object localization, background analysis, and event reasoning. To demonstrate MITS’s effectiveness, we fine-tune mainstream LMMs on this dataset, enabling the development of ITS-specific applications. Experimental results show that MITS significantly improves LMM performance in ITS applications, increasing LLaVA-1.5’s performance from 0.494 to 0.905 (+83.2%), LLaVA-1.6’s from 0.678 to 0.921 (+35.8%), Qwen2-VL’s from 0.584 to 0.926 (+58.6%), and Qwen2.5-VL’s from 0.732 to 0.930 (+27.0%). We release the dataset, code, and models as open-source , providing high-value resources to advance both ITS and LMM research.},
  archive      = {J_ICV},
  author       = {Kaikai Zhao and Zhaoxiang Liu and Peng Wang and Xin Wang and Zhicheng Ma and Yajun Xu and Wenjing Zhang and Yibing Nan and Kai Wang and Shiguo Lian},
  doi          = {10.1016/j.imavis.2025.105736},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105736},
  shortjournal = {Image Vis. Comput.},
  title        = {MITS: A large-scale multimodal benchmark dataset for intelligent traffic surveillance},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UNIR-net: A novel approach for restoring underwater images with non-uniform illumination using synthetic data. <em>ICV</em>, <em>163</em>, 105734. (<a href='https://doi.org/10.1016/j.imavis.2025.105734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoring underwater images affected by non-uniform illumination (NUI) is essential to improve visual quality and usability in marine applications. Conventional methods often fall short in handling complex illumination patterns, while learning-based approaches face challenges due to the lack of targeted datasets. To address these limitations, the Underwater Non-uniform Illumination Restoration Network (UNIR-Net) is proposed. UNIR-Net integrates multiple components, including illumination enhancement, attention mechanisms, visual refinement, and contrast correction, to effectively restore underwater images affected by NUI. In addition, the Paired Underwater Non-uniform Illumination (PUNI) dataset is introduced, specifically designed for training and evaluating models under NUI conditions. Experimental results on PUNI and the large-scale real-world Non-Uniform Illumination Dataset (NUID) show that UNIR-Net achieves superior performance in both quantitative metrics and visual outcomes. UNIR-Net also improves downstream tasks such as underwater semantic segmentation, highlighting its practical relevance. The code is available at https://github.com/xingyumex/UNIR-Net .},
  archive      = {J_ICV},
  author       = {Ezequiel Pérez-Zarate and Chunxiao Liu and Oscar Ramos-Soto and Diego Oliva and Marco Pérez-Cisneros},
  doi          = {10.1016/j.imavis.2025.105734},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105734},
  shortjournal = {Image Vis. Comput.},
  title        = {UNIR-net: A novel approach for restoring underwater images with non-uniform illumination using synthetic data},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFENet: A frequency fusion and enhancement network for camouflaged object detection. <em>ICV</em>, <em>163</em>, 105733. (<a href='https://doi.org/10.1016/j.imavis.2025.105733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of camouflaged object detection (COD) is to accurately find camouflaged objects hidden in their surroundings. Although most of the existing frequency-domain based COD models can boost the performance of COD to a certain extent by utilizing the frequency domain information, the frequency feature fusion strategies they adopt tend to ignore the complementary effects between high-frequency features and low-frequency features. In addition, most of the existing frequency-domain based COD models also do not consider enhancing camouflaged objects using low-level frequency-domain features. In order to solve these problems, we present a frequency fusion and enhancement network (FFENet) for camouflaged object detection, which mainly includes three stages. In the frequency feature extraction stage, we design a frequency feature learning module (FLM) to extract corresponding high-frequency features and low-frequency features. In the frequency feature fusion stage, we design a frequency feature fusion module (FFM) that can increase the representation ability of the fused features by adaptively assigning weights to the high-frequency features and the low-frequency features using a cross-attention mechanism. In the frequency feature guidance information enhancement stage, we design a frequency feature guidance information enhancement module (FGIEM) to enhance the contextual information and detail information of camouflaged objects in the fused features under the guidance of the low-level frequency features. Extensive experimental results on the COD10K, CHAMELEON, NC4K and CAMO datasets show that our model is superior to most existing COD models.},
  archive      = {J_ICV},
  author       = {Haishun Du and Wenzhe Zhang and Sen Wang and Zhengyang Zhang and Linbing Cao},
  doi          = {10.1016/j.imavis.2025.105733},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105733},
  shortjournal = {Image Vis. Comput.},
  title        = {FFENet: A frequency fusion and enhancement network for camouflaged object detection},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UpAttTrans: Upscaled attention based transformer for facial image super-resolution. <em>ICV</em>, <em>163</em>, 105731. (<a href='https://doi.org/10.1016/j.imavis.2025.105731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) aims to reconstruct high-quality images from low-resolution inputs, a task particularly challenging in face-related applications due to extreme degradations and modality differences (e.g., visible, low-resolution, near-infrared). Conventional convolutional neural networks (CNNs) and GAN-based approaches have achieved notable success; however, they often struggle with preserving identity and fine structural details at high upscaling factors. In this work, we introduce UpAttTrans, a novel attention mechanism that connects original and upsampled features for better detail recovery based on vision transformer for SR. The core generator leverages a custom UpAttTrans module that translates input image patches into embeddings, processes them through transformer layers enhanced with connector-up attention, and reconstructs high-resolution outputs with improved detail retention. We evaluate our model on the CelebA dataset across multiple upscaling factors ( 4 × , 8 × , 16 × , 32 × , and 64 × ). UpAttTrans achieves a 24.63% increase in PSNR, 21.56% in SSIM, and 19.61% reduction in FID for 4 × and 8 × SR, outperforming state-of-the-art baselines. Additionally, for higher magnification levels, our model maintains strong performance, with average gains of 6.20% in PSNR and 21.49% in SSIM, indicating its robustness in extreme SR settings. These findings suggest that UpAttTrans holds significant promise for real-world applications such as face recognition in surveillance, forensic image enhancement, and cross-spectral matching, where high-quality reconstruction from severely degraded inputs is critical.},
  archive      = {J_ICV},
  author       = {Neeraj Baghel and Shiv Ram Dubey and Satish Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105731},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105731},
  shortjournal = {Image Vis. Comput.},
  title        = {UpAttTrans: Upscaled attention based transformer for facial image super-resolution},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation. <em>ICV</em>, <em>163</em>, 105729. (<a href='https://doi.org/10.1016/j.imavis.2025.105729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation is a vital early detection method for several severe ocular diseases. Despite significant progress in retinal vessel segmentation with the advancement of Neural Networks, there are still challenges to overcome. Specifically, retinal vessel segmentation aims to predict the class label for every pixel within a fundus image, with a primary focus on intra-image discrimination, making it vital for models to extract more discriminative features. Nevertheless, existing methods primarily focus on minimizing the difference between the output from the decoder and the label, but ignore fully using feature-level fine-grained representations from the encoder. To address these issues, we propose a novel Attention U-shaped Kolmogorov–Arnold Network named AttUKAN along with a novel Label-guided Pixel-wise Contrastive Loss for retinal vessel segmentation. Specifically, we implement Attention Gates into Kolmogorov–Arnold Networks to enhance model sensitivity by suppressing irrelevant feature activations and model interpretability by non-linear modeling of KAN blocks. Additionally, we also design a novel Label-guided Pixel-wise Contrastive Loss to supervise our proposed AttUKAN to extract more discriminative features by distinguishing between foreground vessel-pixel pairs and background pairs. Experiments are conducted across four public datasets including DRIVE, STARE, CHASE_DB1, HRF and our private dataset. AttUKAN achieves F1 scores of 82.50%, 81.14%, 81.34%, 80.21% and 80.09%, along with MIoU scores of 70.24%, 68.64%, 68.59%, 67.21% and 66.94% in the above datasets, which are the highest compared to 11 networks for retinal vessel segmentation. Quantitative and qualitative results show that our AttUKAN achieves state-of-the-art performance and outperforms existing retinal vessel segmentation methods. Our code will be available at https://github.com/stevezs315/AttUKAN .},
  archive      = {J_ICV},
  author       = {Shuang Zeng and Chee Hong Lee and Micky C. Nnamdi and Wenqi Shi and J. Ben Tamo and Hangzhou He and Xinliang Zhang and Qian Chen and May D. Wang and Lei Zhu and Yanye Lu and Qiushi Ren},
  doi          = {10.1016/j.imavis.2025.105729},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105729},
  shortjournal = {Image Vis. Comput.},
  title        = {Novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence content detection techniques using watermarking: A survey. <em>ICV</em>, <em>163</em>, 105728. (<a href='https://doi.org/10.1016/j.imavis.2025.105728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement in AI-generated content has catalyzed artistic creation, advertising, and media dissemination. Despite their widespread applications across several domains, AI-generated content inherently poses risks of identity fraud, copyright violation and unauthorized use. Watermarking has emerged as a critical tool for copyright protection, allowing embedding of identification information in AI-generated content, and enhances traceability and verification without hurting user experience. In this study, we provide a systematic literature review of the technique for detecting AI content, especially text and images, using watermarking, spanning studies from 2010 to 2025. Studies included in this review were peer-reviewed articles that applied watermarking to effectively distinguish AI-generated content from real or human-written content. We report strong past and current approaches to detecting watermarking-based AI content, especially text and images. This includes an analysis of how watermarking methods are used on AI-generated content, their role in enhancing performance, and a detail comparative analysis of notable techniques. Furthermore, we discuss how these methods have been evaluated, identify the research gaps and potential solutions. Our findings provide valuable insights for future watermarking-based AI content detection researchers, applications and organizations seeking to implement watermarking solutions in potential applications. To the best of our knowledge, we are the first to explore the detection of AI content, especially text and image, detection using watermarking.},
  archive      = {J_ICV},
  author       = {Nishant Kumar and Amit Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105728},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105728},
  shortjournal = {Image Vis. Comput.},
  title        = {Artificial intelligence content detection techniques using watermarking: A survey},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Your image generator is your new private dataset. <em>ICV</em>, <em>163</em>, 105727. (<a href='https://doi.org/10.1016/j.imavis.2025.105727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative diffusion models have emerged as powerful tools to synthetically produce training data, offering potential solutions to data scarcity and reducing labelling costs for downstream supervised deep learning applications. However, existing approaches for synthetic dataset generation face significant limitations: previous methods like Knowledge Recycling rely on label-conditioned generation with models trained from scratch, limiting flexibility and requiring extensive computational resources, while simple class-based conditioning fails to capture the semantic diversity and intra-class variations found in real datasets. Additionally, effectively leveraging text-conditioned image generation for building classifier training sets requires addressing key issues: constructing informative textual prompts, adapting generative models to specific domains, and ensuring robust performance. This paper proposes the Text-Conditioned Knowledge Recycling (TCKR) pipeline to tackle these challenges. TCKR combines dynamic image captioning, parameter-efficient diffusion model fine-tuning, and Generative Knowledge Distillation techniques to create synthetic datasets tailored for image classification. The pipeline is rigorously evaluated on ten diverse image classification benchmarks. The results demonstrate that models trained solely on TCKR-generated data achieve classification accuracies on par with (and in several cases exceeding) models trained on real images. Furthermore, the evaluation reveals that these synthetic-data-trained models exhibit substantially enhanced privacy characteristics: their vulnerability to Membership Inference Attacks is significantly reduced, with the membership inference AUC lowered by 5.49 points on average compared to using real training data, demonstrating a substantial improvement in the performance-privacy trade-off. These findings indicate that high-fidelity synthetic data can effectively replace real data for training classifiers, yielding strong performance whilst simultaneously providing improved privacy protection as a valuable emergent property. The code and trained models are available in the accompanying open-source repository .},
  archive      = {J_ICV},
  author       = {Nicolò Francesco Resmini and Eugenio Lomurno and Cristian Sbrolli and Matteo Matteucci},
  doi          = {10.1016/j.imavis.2025.105727},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105727},
  shortjournal = {Image Vis. Comput.},
  title        = {Your image generator is your new private dataset},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the noise robustness of class activation maps: A framework for reliable model interpretability. <em>ICV</em>, <em>163</em>, 105717. (<a href='https://doi.org/10.1016/j.imavis.2025.105717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class Activation Maps (CAMs) are one of the important methods for visualizing regions used by deep learning models. Yet their robustness to different noise remains underexplored. In this work, we evaluate and report the resilience of various CAM methods for different noise perturbations across multiple architectures and datasets. By analyzing the influence of different noise types on CAM explanations, we assess the susceptibility to noise and the extent to which dataset characteristics may impact explanation stability. The findings highlight considerable variability in noise sensitivity for various CAMs. We propose a robustness metric for CAMs that captures two key properties: consistency and responsiveness. Consistency reflects the ability of CAMs to remain stable under input perturbations that do not alter the predicted class, while responsiveness measures the sensitivity of CAMs to changes in the prediction caused by such perturbations. The metric is evaluated empirically across models, different perturbations, and datasets along with complementary statistical tests to exemplify the applicability of our proposed approach.},
  archive      = {J_ICV},
  author       = {Syamantak Sarkar and Revoti P. Bora and Bhupender Kaushal and Sudhish N. George and Kiran Raja},
  doi          = {10.1016/j.imavis.2025.105717},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105717},
  shortjournal = {Image Vis. Comput.},
  title        = {Assessing the noise robustness of class activation maps: A framework for reliable model interpretability},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InceptionWTMNet: A hybrid network for alzheimer’s disease detection using wavelet transform convolution and mixed local channel attention on finely fused multimodal images. <em>ICV</em>, <em>163</em>, 105693. (<a href='https://doi.org/10.1016/j.imavis.2025.105693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has emerged as a critical technique for the diagnosis of Alzheimer’s Disease (AD), with the aim of effectively extracting and utilising complementary information from diverse modalities. Current fusion methods frequently cause the precise alignment of source images and do not adequately address parallax issues. This oversight can result in artifacts during the fusion process when images are misaligned. In response to this challenge, we propose a refined registration fusion technique, termed MURF, which integrates multimodal image registration and fusion within a cohesive framework. The Vision Transformer (ViT) has inspired the application of large-kernel convolutions in the diagnosis of Alzheimer’s disease (AD) because of its ability to model long-range dependencies. This approach aims to expand the receptive field and enhance the performance of diagnostic models. Despite requiring a minimal number of floating-point operations (FLOPs), these deep operators encounter challenges associated with over-parameterisation because of high memory access costs, which ultimately compromises computational efficiency. By utilising wavelet transform convolutions (WTConv), we decompose large-kernel depth-wise convolutions into four parallel branches. One branch employs a wavelet-transform convolution with square kernels, while the other two branches incorporate orthogonal wavelet-transform kernels with an identity mapping. This innovative method, with a Mixed Local Channel Attention mechanism, has facilitated the development of the InceptionWTConvolutions network. This network maintains a receptive field comparable to that of large-kernel convolutions, while concurrently minimising over-parameterisation and enhancing computational efficiency. InceptionWTMNet classified AD, MCI, and NC using MRI and PET data from ADNI dataset with 98.69% accuracy, 98.65% recall, 98.70% F1-score, and 98.98% AUC. and provide Graphical abstract in correct format.},
  archive      = {J_ICV},
  author       = {Zenan Xu and Zhengyao Bai and Han Ma and Mingqiang Xu and Qiqin Huang and Tao Lin},
  doi          = {10.1016/j.imavis.2025.105693},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105693},
  shortjournal = {Image Vis. Comput.},
  title        = {InceptionWTMNet: A hybrid network for alzheimer’s disease detection using wavelet transform convolution and mixed local channel attention on finely fused multimodal images},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijar">IJAR - 1</h2>
<ul>
<li><details>
<summary>
(2026). Choosing the center of star-shaped set-valued data compatible with measure-preserving arithmetic. <em>IJAR</em>, <em>188</em>, 109575. (<a href='https://doi.org/10.1016/j.ijar.2025.109575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set-valued data has traditionally been represented by considering non-empty compact and convex subsets of R d with the usual Minkowski addition. An alternative and flexible setting that admits a functional representation are the star-shaped sets. A framework based on a center-radial characterization has been introduced to treat these sets from a statistical point of view. The arithmetic is defined directionally, which is more natural for representing imprecision propagation in higher dimensions. Nevertheless, the problem of determining a center for star-shaped sets coherent with the arithmetic and sound for statistical purposes has not been fully addressed yet. The aim is to advance on the directional characterization for star-shaped sets by considering a measure-preserving arithmetic together with a center selection fully compatible with this arithmetic. The practicability of the new framework will be illustrated using a classical dataset in set-valued statistics.},
  archive      = {J_IJAR},
  author       = {Gil González-Rodríguez},
  doi          = {10.1016/j.ijar.2025.109575},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109575},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Choosing the center of star-shaped set-valued data compatible with measure-preserving arithmetic},
  volume       = {188},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="ipl">IPL - 10</h2>
<ul>
<li><details>
<summary>
(2026). Tighter bounds on non-clairvoyant parallel machine scheduling with prediction to minimize makespan. <em>IPL</em>, <em>191</em>, 106598. (<a href='https://doi.org/10.1016/j.ipl.2025.106598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the non-clairvoyant parallel machine scheduling problem with prediction, with the objective of minimizing the makespan. Improved lower bounds for the problem and competitive ratios of online algorithms with respect to the prediction error are presented for both the non-preemptive and preemptive cases on m identical machines.},
  archive      = {J_IPL},
  author       = {Tianqi Chen and Zhiyi Tan},
  doi          = {10.1016/j.ipl.2025.106598},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106598},
  shortjournal = {Inf. Process. Lett.},
  title        = {Tighter bounds on non-clairvoyant parallel machine scheduling with prediction to minimize makespan},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Note on pancake sorting. <em>IPL</em>, <em>191</em>, 106597. (<a href='https://doi.org/10.1016/j.ipl.2025.106597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present generalized approach to the proof of the lower bound for unburnt pancake sorting problem, where we search for the number f ( n ) of prefix reversals required to sort a stack (permutation) of n pancakes. For this purpose we introduce a new concept of guarded pancake blocks. Gates and Papadimitriou proved that f ( n ) ≥ 17 n / 16 for n a multiple of 16. Heydari and Sudborough improved this bound to f ( n ) ≥ 15 n / 14 for n a multiple of 14. We extend that result to f ( n ) ≥ ⌊ ( 15 n + 9 ) / 14 ⌋ for every n ≥ 6 .},
  archive      = {J_IPL},
  author       = {Marcin Peczarski},
  doi          = {10.1016/j.ipl.2025.106597},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106597},
  shortjournal = {Inf. Process. Lett.},
  title        = {Note on pancake sorting},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Logical characterization of branching bisimilarity over random processes. <em>IPL</em>, <em>191</em>, 106596. (<a href='https://doi.org/10.1016/j.ipl.2025.106596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative aspects like probabilities play an important role in concurrent processes. Providing a (modal) logic for a randomized concurrency model can augment the toolbox of analyzing probabilistic processes, and thus is a frequent topic in the field. In this paper, we are interested in logically characterizing uniformly randomized processes, whose semantical behavior is defined in a model-independent manner. Specifically, we present two modal logics for the uniformly randomized version of finite-state CCS (RCCS fs for short). Our logics extend the Hennessy-Milner logic, and one of them is equipped with the μ operator. Indeed, we prove that both logics characterize the branching bisimilarity for RCCS fs , i.e., two RCCS fs processes are branching bisimilar if and only if they are logically equivalent. To facilitate the proof, we also develop for RCCS fs an up-to proof method, which may be of independent interest.},
  archive      = {J_IPL},
  author       = {Xian Xu and Wenbo Zhang},
  doi          = {10.1016/j.ipl.2025.106596},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106596},
  shortjournal = {Inf. Process. Lett.},
  title        = {Logical characterization of branching bisimilarity over random processes},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Notes about the linear complexity of quaternary cyclotomic sequences of order four. <em>IPL</em>, <em>191</em>, 106595. (<a href='https://doi.org/10.1016/j.ipl.2025.106595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the linear complexity of quaternary cyclotomic sequences with period p , where p > 2 is a prime. Considered sequences are based on classical cyclotomic classes of order four modulo p . We show that any balanced quaternary cyclotomic sequence of order four with period p has high linear complexity over finite ring of order four. Our results generalize those obtained earlier by other authors.},
  archive      = {J_IPL},
  author       = {Vladimir Edemskiy and Zeyu Cao},
  doi          = {10.1016/j.ipl.2025.106595},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106595},
  shortjournal = {Inf. Process. Lett.},
  title        = {Notes about the linear complexity of quaternary cyclotomic sequences of order four},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finding the cyclic covers of a string. <em>IPL</em>, <em>191</em>, 106594. (<a href='https://doi.org/10.1016/j.ipl.2025.106594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the concept of cyclic covers, which generalizes the classical notion of covers in strings. Given any string X , a factor W of X is called a cyclic cover if each position of X belongs to an occurrence of a cyclic shift of W in X . Two cyclic covers are distinct if one is not a cyclic shift of the other. The cyclic covers problem asks for all distinct cyclic covers of an input string X . We present an algorithm that solves the cyclic covers problem in O ( n log ⁡ n ) time, where n is the length of X . It is based on finding a well-structured set of standard occurrences of a constant number of factors of a cyclic cover candidate W , computing the regions of X covered by cyclic shifts of W , extending those factors, and taking the union of the results.},
  archive      = {J_IPL},
  author       = {Roberto Grossi and Costas S. Iliopoulos and Jesper Jansson and Zara Lim and Wing-Kin Sung and Wiktor Zuba},
  doi          = {10.1016/j.ipl.2025.106594},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106594},
  shortjournal = {Inf. Process. Lett.},
  title        = {Finding the cyclic covers of a string},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rank-2 module-LIP with special matrices. <em>IPL</em>, <em>191</em>, 106593. (<a href='https://doi.org/10.1016/j.ipl.2025.106593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice isomorphism problem (LIP) has been studied since 1990s. In 2023, a post-quantum signature scheme known as HAWK was submitted in the NIST standardization of additional signature scheme, which is based on the module lattice isomorphism problem (module-LIP). Module-LIP was formally defined by Mureau et al. at Eurocrypt'24 and Luo et al. reduced the problem of solving module-LIP over CM number fields to a problem of finding the special type of symplectic automorphism. In this paper, we extend this idea further by establishing a reduction of the module-LIP to a problem of finding special types of matrices.},
  archive      = {J_IPL},
  author       = {Manoj Gyawali},
  doi          = {10.1016/j.ipl.2025.106593},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106593},
  shortjournal = {Inf. Process. Lett.},
  title        = {Rank-2 module-LIP with special matrices},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “On the complexity of co-secure dominating set problem” [Inf. process. lett. 185 (2024) 106463]. <em>IPL</em>, <em>191</em>, 106592. (<a href='https://doi.org/10.1016/j.ipl.2025.106592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We correct an error in Theorem 4 in our published paper Panda et al. [3] .},
  archive      = {J_IPL},
  author       = {Bhawani Sankar Panda and Soumyashree Rana and Sounaka Mishra},
  doi          = {10.1016/j.ipl.2025.106592},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106592},
  shortjournal = {Inf. Process. Lett.},
  title        = {Corrigendum to “On the complexity of co-secure dominating set problem” [Inf. process. lett. 185 (2024) 106463]},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On some families of binary codes. <em>IPL</em>, <em>191</em>, 106591. (<a href='https://doi.org/10.1016/j.ipl.2025.106591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give further results on the weight distributions of the two families of binary codes recently constructed by simplicial complexes by (Wu, Lee, 2020), and show that the converse of the above results is also correct, that is, the binary codes with such weight distributions properties must be these two families of codes. Based on the above results, we also construct another family of binary self-orthogonal codes and present their separating properties and applications to the secret sharing scheme, cryptography and other aspects of information security.},
  archive      = {J_IPL},
  author       = {Zihui Liu},
  doi          = {10.1016/j.ipl.2025.106591},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106591},
  shortjournal = {Inf. Process. Lett.},
  title        = {On some families of binary codes},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The complexity of computing the period and the exponent of a digraph. <em>IPL</em>, <em>191</em>, 106590. (<a href='https://doi.org/10.1016/j.ipl.2025.106590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The period of a strongly connected digraph is the greatest common divisor of the lengths of all its cycles. The period of a digraph is the least common multiple of the periods of its strongly connected components. These notions play an important role in the theory of Markov chains and the analysis of powers of nonnegative matrices. While the time complexity of computing the period is well-understood, little is known about its space complexity. We show that the problem of computing the period of a digraph is NL -complete, even if all its cycles are contained in the same strongly connected component. However, if the digraph is strongly connected, we show that this problem becomes L -complete. For primitive digraphs (that is, strongly connected digraphs of period one), there always exists a number m such that there is a path of length exactly m between every two vertices. We show that computing the smallest such m , called the exponent of a digraph, is NL -complete. The exponent of a primitive digraph is a particular case of the index of convergence of a nonnegative matrix, which we also show to be computable in NL , and thus NL -complete.},
  archive      = {J_IPL},
  author       = {Stefan Kiefer and Andrew Ryzhikov},
  doi          = {10.1016/j.ipl.2025.106590},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106590},
  shortjournal = {Inf. Process. Lett.},
  title        = {The complexity of computing the period and the exponent of a digraph},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A simple supercritical tradeoff between size and height in resolution. <em>IPL</em>, <em>191</em>, 106589. (<a href='https://doi.org/10.1016/j.ipl.2025.106589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe CNFs in n variables which, over a range of parameters, have small resolution refutations but are such that any small refutation must have height larger than n (even exponential in n ), where the height of a refutation is the length of the longest path in it. This is called a supercritical tradeoff between size and height because, if we do not care about size, every CNF is refutable in height n . Our proof method uses a simple construction, based on or-ification and base d representations of integers, to reduce the number of variables. A similar result appeared in [Fleming, Pitassi and Robere, ITCS '22], for different formulas using a more complicated construction for reducing the number of variables. Small refutations of our formula are necessarily highly irregular, making it a plausible candidate to separate resolution from pool resolution, which amounts to separating CDCL with restarts from CDCL without restarts. We are not able to show this. In the other direction, we show that a simpler version of our formula, with a similar irregularity property, does have polynomial size pool resolution refutations and thus does not provide such a separation for CDCL.},
  archive      = {J_IPL},
  author       = {Sam Buss and Neil Thapen},
  doi          = {10.1016/j.ipl.2025.106589},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106589},
  shortjournal = {Inf. Process. Lett.},
  title        = {A simple supercritical tradeoff between size and height in resolution},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="isat">ISAT - 39</h2>
<ul>
<li><details>
<summary>
(2025). Voltage tracking and regulation of vehicle PEMFC system under low load condition based on fuzzy LQG hybrid strategy. <em>ISAT</em>, <em>165</em>, 510-523. (<a href='https://doi.org/10.1016/j.isatra.2025.06.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In automotive fuel cell systems, high-voltage operation accelerates carbon support and platinum catalyst degradation, significantly compromising system durability. This study develops a dynamic system model with active cathode recirculation to capture the transient response of voltage, and proposes a hybrid control scheme that combines a proportional compensator with a fuzzy LQG controller to effectively enhance voltage regulation and disturbance tracking capabilities. Extensive simulation and hardware-in-the-loop (HiL) confirm the precision and rapid response of the developed controller. Compared to single LQG and fuzzy LQG controllers, the error reduction achieved is 49.3 % and 40.3 %, respectively, and the overall control benefit ratio improves by 19.2 % and 11 %. This method balances dynamic response with control efforts, effectively reducing the risk of high voltage-induced degradation under low-load conditions.},
  archive      = {J_ISAT},
  author       = {Ze Liu and Sichuan Xu and Baitao Zhang and Sida Guo},
  doi          = {10.1016/j.isatra.2025.06.008},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {510-523},
  shortjournal = {ISA Trans.},
  title        = {Voltage tracking and regulation of vehicle PEMFC system under low load condition based on fuzzy LQG hybrid strategy},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade alarm systems: A study on singular value analysis. <em>ISAT</em>, <em>165</em>, 497-509. (<a href='https://doi.org/10.1016/j.isatra.2025.06.023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel alarm system designed for use with both Independent and Identically Distributed (IID) and non-IID variables. The proposed algorithm, termed the Cascade Alarm System (CAS), utilizes the largest singular value of the signal as the basis for fault detection, employing k alarm subsystems. The greatest singular values extracted from the Lagged Covariance Matrix (LCM) of a sliding window constitute the output of the first alarm subsystem. The CAS offers two primary advantages. First, each subsystem independently generates its own alarm signal, resulting in a more flexible multilevel architecture. Second, the multilevel structure, founded on singular value decomposition (SVD), exhibits a filtering property that enhances its resilience to noise and inaccuracies. The maximum singular value effectively captures the essential information of the signal, ensuring that the filtering capabilities of the proposed method do not significantly compromise the performance of the alarm system or the integrity of critical signal information. The experimental results from the implementation of the proposed alarm system under various fault conditions demonstrate satisfactory performance. Additionally, the performance of the Cascade Alarm System has been compared with leading contemporary alarm system design methodologies, including median, moving average filters, delay timers, Cumulative Sum Control Chart (CUSUM), and serial method.},
  archive      = {J_ISAT},
  author       = {J. Taheri-Kalani and M. Aliyari-Shoorehdeli and Gh. Latif-Shabgahi},
  doi          = {10.1016/j.isatra.2025.06.023},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {497-509},
  shortjournal = {ISA Trans.},
  title        = {Cascade alarm systems: A study on singular value analysis},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow pulsation compensation based composite adaptive active disturbance rejection control for electro-hydrostatic actuators. <em>ISAT</em>, <em>165</em>, 486-496. (<a href='https://doi.org/10.1016/j.isatra.2025.06.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the residual pressure accumulated during the reciprocating movement of the plunger pump, there is a deviation between the flow pulsation and the theoretical calculation value. Current nonlinear control methods for the electro-hydrostatic actuator (EHA) often oversimplify and compensate for flow pulsation linearly, neglecting its nonlinear characteristics and deviation effects. This approach increases matching uncertainties and amplifies noise due to higher control gains, thus limiting the improvement of control performance. To address this issue, this paper proposes a composite adaptive disturbance rejection control method based on flow pulsation compensation for the EHA. This method equates the flow pulsation model of the pump to a combination of a theoretical flow pulsation control input term and a bounded disturbance term (the difference between the theoretical and actual flow pulsation), followed by the design of a composite adaptive law to handle parameter uncertainties, and the design of the expanded state observers based on position and pressure signals to estimate and compensate for the uncertainties nonlinearly. Finally, the effectiveness of the proposed method is verified by comparing with other control methods through experiments.},
  archive      = {J_ISAT},
  author       = {Yaowen Ge and Xiaowei Yang and Weilin Zhu and Wenxiang Deng and Jianyong Yao},
  doi          = {10.1016/j.isatra.2025.06.014},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {486-496},
  shortjournal = {ISA Trans.},
  title        = {Flow pulsation compensation based composite adaptive active disturbance rejection control for electro-hydrostatic actuators},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polytopic inclusion-based model predictive control for quasi-LPV systems using vertex system models and gain scheduling. <em>ISAT</em>, <em>165</em>, 474-485. (<a href='https://doi.org/10.1016/j.isatra.2025.05.051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Model Predictive Control (MPC) strategy for a class of Quasi-Linear Parameter-Varying (quasi-LPV) systems characterized by a measurable time-varying parameter. The core of the proposed quasi-LPV-MPC controller lies in the utilization of a polytopic representation along with a gain-scheduled controller. A terminal cost that depends explicitly on the scheduling parameter is used. However, for the implementation, a complementary cost function is used to frame the optimization problem at each vertex level so that the requirement of updating the varying parameters over the prediction horizon is relaxed. Though the resulting suboptimal controller involves more computational burden, the proposed method demonstrates improvement in control performance over traditional MPC schemes. Experimental validation on a cascaded coupled tank system underscores the practical efficacy of the proposed quasi-LPV-MPC controller, while simulation studies on a twin rotor multi-input multi-output system serve as an additional demonstration example case. Comparative performance evaluations against both linear and nonlinear MPCs clearly illustrate that the quasi-LPV-MPC offers better control precision, adaptability, and the overall system responsiveness, thus positioning it as an effective solution for quasi-LPV systems.},
  archive      = {J_ISAT},
  author       = {Rangoli Singh and Sandip Ghosh and Devender Singh},
  doi          = {10.1016/j.isatra.2025.05.051},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {474-485},
  shortjournal = {ISA Trans.},
  title        = {Polytopic inclusion-based model predictive control for quasi-LPV systems using vertex system models and gain scheduling},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the global energy optimization of multi-source and multi-actuator hydraulic systems based on dynamic programming and improved adaptive genetic algorithm. <em>ISAT</em>, <em>165</em>, 450-473. (<a href='https://doi.org/10.1016/j.isatra.2025.06.010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source and multi-actuator hydraulic systems (MSAHSs) are widely used in high-power energy transmission and construction machinery. However, individual control of each component without considering the overall power matching leads the system to the low-efficiency zone, results in environmental pollution and huge economic loss. Therefore, it is highly desirable to find a way of obtaining energy-saving green MSAHSs. In this paper, the power consumption model of closed MSAHSs is established firstly to analyze theoretical factors affecting the component efficiency and find that the hydraulic pressure is the key factor. On this basis, a multi-algorithm integration global power matching method is then proposed, which consist of back propagation (BP) neural network, dynamic programming (DP) and improved adaptive genetic algorithm (IAGA). BP is used to construct efficiency prediction models for power elements (pumps, motors and engines) respectively, DP is used for elements’ high efficiency zone preliminary search, and IAGA is used to realize the global power matching of the multiple power units with energy conversion and transfer finally through optimal control parameters precise searching. Experiment is conducted on the closed MSAHS in a hydraulic fracturing vehicle. Results demonstrate that the MSAHS applied with multi-algorithm integration method improves the overall efficiency to a highest fuel savings of 35.5 % under normal conditions compared with local power matching control.},
  archive      = {J_ISAT},
  author       = {Yuhang Zhong and Wenting Chen and Zihao Chen and Guanyu Zhai and Chao Ai and Gexin Chen},
  doi          = {10.1016/j.isatra.2025.06.010},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {450-473},
  shortjournal = {ISA Trans.},
  title        = {Research on the global energy optimization of multi-source and multi-actuator hydraulic systems based on dynamic programming and improved adaptive genetic algorithm},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent energy adaptive control of loader shoveling system. <em>ISAT</em>, <em>165</em>, 437-449. (<a href='https://doi.org/10.1016/j.isatra.2025.06.021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loaders are often faced with various working objects during the shoveling process. The differences in working resistance and its time-varying unpredictability when shoveling different objects are the main causes of high energy consumption during the shoveling stage. In this paper, through the analysis of the shoveling process, the influence of the compacted layer on the working resistance is obtained. The constructed Discrete Element Method (DEM) simulation model is used to elucidate that the timely lifting of the boom can have a destructive effect on the compacted layer. Moreover, considering the diversity of working objects, a study was carried out on the effect of different boom lifting ranges on the destruction of the compacted layer. The loader shoveling system's intelligent Energy Adaptive Control (EAC) strategy is constructed by integrating the material recognition model based on the Back Propagation (BP) neural network algorithm. This control strategy can output the set pilot pressure according to the material type, realize the intelligent adjustment of the lifting range of the boom with the change of material type, and reduce the working resistance during the shoveling stage. The peak engine power consumed while shoveling sand, gravel, and boulders decreased by 20.6 %, 19.1 %, and 10.9 %, respectively, improving the energy utilization rate of the loader shoveling system when facing different working objects.},
  archive      = {J_ISAT},
  author       = {Bingwei Cao and Changhao Mu and Jiaqi Dong and Guangliang Tian and Yuqi Wang},
  doi          = {10.1016/j.isatra.2025.06.021},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {437-449},
  shortjournal = {ISA Trans.},
  title        = {Intelligent energy adaptive control of loader shoveling system},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis and design of oscillation frequency correction for servo resonance suppression. <em>ISAT</em>, <em>165</em>, 422-436. (<a href='https://doi.org/10.1016/j.isatra.2025.06.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical resonance poses significant hazards to the normal operation of the servo systems. To mitigate mechanical resonance, online adaptive notch filter is extensive used, thus the precise determination of resonant frequency holds significant importance. However, in certain scenarios involving the high-bandwidth servo system, a phenomenon known as frequency shift can make the notch filter ineffective in addressing servo resonance. To solve this problem, an oscillation frequency correction scheme based on two improved sliding-mode observers (ISMOs) utilizing a dual-power approximation law is proposed. First, the oscillation frequency shift is analyzed around the system delay, which can be equivalently modeled using a Pade approximation method. Subsequently, a feedback loop featuring two adaptive feedback coefficients is designed to automatically tune the time factor. Remarkably, the scheme can dynamically correct oscillation frequency, thereby promoting resonance suppression. At the same time, ISMOs-identified mechanical parameters provide critical foundations for feedback coefficient adjustment. It is worth noting that the dual-power approximation law effectively suppresses high-frequency chatter while maintaining parameter identification accuracy. Finally, the effectiveness of the scheme is validated through simulation and experimental results.},
  archive      = {J_ISAT},
  author       = {Yanan Tang and Shaowu Lu and Puliang Yu and Bao Song},
  doi          = {10.1016/j.isatra.2025.06.011},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {422-436},
  shortjournal = {ISA Trans.},
  title        = {Analysis and design of oscillation frequency correction for servo resonance suppression},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A segmented model based internal model control scheme of electromagnetic micro-mirror systems. <em>ISAT</em>, <em>165</em>, 408-421. (<a href='https://doi.org/10.1016/j.isatra.2025.06.003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a segmented internal model control (SIMC) scheme based on the segmented combination model of the electromagnetic micro-mirror system (EMMS) is established. Notice that highly underdamped oscillation and rate-dependent hysteresis exist in the EMMS, so it is a complex nonlinear dynamic system. In order to control the deflection angle of the EMMS using the internal model control strategy, it is necessary to establish the inverse model of the EMMS. Therefore, a new model structure that is convenient for inversion is proposed in this paper to describe the characteristics of the EMMS with underdamped and rate-dependent hysteresis. In the proposed scheme, the model is a combination of a group of weighted sub-models based on the segmentation of the system's operating frequency. The weight of each segmented sub-model is not a constant but a new type of function which is also called the smoothing factor. Its function is to smooth the switching between sub-models, thereby reducing the dynamic error caused by model switching. In addition, the particle swarm optimization (PSO) algorithm is used to determine the optimal frequency segmentation points, which helps to obtain the optimal model for describing the system characteristics. Based on the proposed segmented combination model, the corresponding segmented internal model control with two-degree-of-freedom filters is proposed, and the corresponding filters in the internal model control are designed based on the small gain theorem. Finally, the proposed control strategy is applied to the control of the deflection angle of the electromagnetic micro-mirror to verify the proposed control method. Moreover, the non-smooth internal model control strategy is also used for comparison in the experiments.},
  archive      = {J_ISAT},
  author       = {Ruili Dong and Qingyuan Tan and Yonghong Tan and Xiaoli Song and Tianyu Wang},
  doi          = {10.1016/j.isatra.2025.06.003},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {408-421},
  shortjournal = {ISA Trans.},
  title        = {A segmented model based internal model control scheme of electromagnetic micro-mirror systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PPAC-pilot: Prescribed-performance augmented control for fixed-wing autopilots. <em>ISAT</em>, <em>165</em>, 395-407. (<a href='https://doi.org/10.1016/j.isatra.2025.06.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a Prescribed-Performance Augmented Control (PPAC) framework designed for fixed-wing Unmanned Aerial Vehicle (UAV) autopilots. The PPAC strategy aims to enhance, rather than replace, existing PID control loops in open-source autopilots. Although traditional autopilots effectively manage routine tasks in most applications, their reliance on meticulous tuning remains a limitation. To address this, PPAC leverages historical flight data, a frequently overlooked resource, to derive dynamic linearization models and control laws without requiring explicit UAV models. The PPAC framework is then integrated with the Total Energy Control System (TECS) for practical deployment in takeoff and cruising scenarios. Comprehensive numerical simulations and Hardware-in-the-Loop (HIL) tests validate the strategy by comparing baseline autopilot performance with PPAC-augmented systems. Results confirm that PPAC ensures prescribed performance bounds for altitude tracking errors across evaluated scenarios, demonstrating its effectiveness in augmenting autopilots with minimized redesign efforts.},
  archive      = {J_ISAT},
  author       = {Qiuyang Tian and Zelin Wang and Tianjiang Hu},
  doi          = {10.1016/j.isatra.2025.06.001},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {395-407},
  shortjournal = {ISA Trans.},
  title        = {PPAC-pilot: Prescribed-performance augmented control for fixed-wing autopilots},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hysteresis observer enhanced integral terminal sliding mode control of piezoelectric platform for precision tracking applications. <em>ISAT</em>, <em>165</em>, 384-394. (<a href='https://doi.org/10.1016/j.isatra.2025.06.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinearity of piezo-actuated positioning platforms significantly impacts their performance in high-precision applications. In this work a dynamic model of piezoelectric platform was developed firstly with the asymmetric Bouc-Wen model. Next, a terminal sliding mode observer with the super-twisting mechanism was designed to accurately estimate the state of the system. Then, a novel control strategy named Hysteresis Observer Enhanced Integral Terminal Sliding Mode Controller (HO-ITSMC) was proposed to achieve precise displacement tracking. Its stability is theoretically proved by the Lyapunov theorem. A key feature of this controller lies in its ability to drive the state of the system into zero in finite time, regardless of the initial state. Extensive experiments have thoroughly validated the effectiveness of the proposed control method, demonstrating its superior precision-tracking performance compared to traditional controllers.},
  archive      = {J_ISAT},
  author       = {Jie Chen and Lei Ni and Xuan Liao and Geng Wang and Lanqiang Zhang and Na Yao and Yijun Li and Sumeet S. Aphale},
  doi          = {10.1016/j.isatra.2025.06.022},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {384-394},
  shortjournal = {ISA Trans.},
  title        = {Hysteresis observer enhanced integral terminal sliding mode control of piezoelectric platform for precision tracking applications},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive robust control for ball-screw drives with flexible transmission and nonlinear friction via dynamic surface control approach. <em>ISAT</em>, <em>165</em>, 372-383. (<a href='https://doi.org/10.1016/j.isatra.2025.05.050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible deformation and nonlinear friction in ball-screw drive systems are important factors that restrict the improvement of tracking performance. In this paper, a high-performance adaptive controller is presented for ball screw drives to suppress vibration and improve tracking accuracy. A two-inertia model with torsional vibration state is established to fit the dynamics of the drive system while the continuously differentiable LuGre model characterizes the nonlinear friction disturbance. Based on the established nonlinear model, an adaptive robust controller (ARC) is designed by using the backstepping approach to overcome the parametric uncertainties and hard-to-model dynamics. The dual-observer is employed in the controller to observe and compensate for the nonlinear friction, which improves the low-velocity tracking performance of the ball-screw drives. Meanwhile, first-order filters are introduced by dynamic surface control (DSC) technique to eliminate the “complexity explosion” problem caused by the backstepping method. The controller theoretically guarantees that all signals of the closed-loop system are bounded, and the convergence of tracking error is also ensured via Lyapunov analysis. The effectiveness of the proposed controller is verified through simulation and experimental results.},
  archive      = {J_ISAT},
  author       = {Yanliang Sheng and Guofeng Wang and Fei Wang and Decai Li and Mantang Hu},
  doi          = {10.1016/j.isatra.2025.05.050},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {372-383},
  shortjournal = {ISA Trans.},
  title        = {Adaptive robust control for ball-screw drives with flexible transmission and nonlinear friction via dynamic surface control approach},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-sensing framework for weak fault detection of planetary gearbox. <em>ISAT</em>, <em>165</em>, 358-371. (<a href='https://doi.org/10.1016/j.isatra.2025.06.009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planetary gearbox fault detection has attracted wide attention due to the planetary gearbox’s key role in modern electro-mechanic equipment. However, traditional fault detection technologies still heavily rely on additional sensors. The resulting enormous cost of sensors restricts the application of those technologies. Given this situation, a self-sensing fault detection framework to explore the weak fault impulses of the planetary gearbox is presented without additional sensors. In this framework, we first capture the preliminary signals from the servo control systems. Then, the hole control model of the motor driving planetary gearbox is constructed. After this step, the feasibility of fault detection for the planetary gearbox through the motor servo control signals is investigated. With the measured servo control signals, a multi-signal assisting adaptive time synchronous averaging method is first proposed to explore fault impulses. This method first introduces a periodic enhanced Gini to select optimal parameters adaptively. Finally, experiments on a weak fault of three components in the planetary gearbox are carried out separately, certifying our framework's validation of planetary gearbox fault detection. This framework hopes to provide a novel scheme for the weak fault self-sensing of planetary gearboxes.},
  archive      = {J_ISAT},
  author       = {Dexin Chen and Ming Zhao and Shudong Ou and Sen Li and Xiaolong Han},
  doi          = {10.1016/j.isatra.2025.06.009},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {358-371},
  shortjournal = {ISA Trans.},
  title        = {A self-sensing framework for weak fault detection of planetary gearbox},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear self-triggered MPC without terminal conditions for trajectory tracking. <em>ISAT</em>, <em>165</em>, 347-357. (<a href='https://doi.org/10.1016/j.isatra.2025.06.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a trajectory tracking problem for a class of nonlinear discrete-time systems is investigated by a model predictive control (MPC) strategy. Compared with the standard MPC strategy, the proposed MPC strategy removes terminal conditions, including terminal penalty terms and terminal state constraints. This novel design requires fewer parameters to be determined, which leads to high practicability. Moreover, to reduce the computational burden, a self-triggered mechanism is presented by using the discrepancy in the cost function between adjacent time instants. Then, an additional compensation variable is designed for the redundancy from the self-triggered mechanism. Finally, we present a mathematical proof for the recursive feasibility of the optimization problem. The effectiveness and practicality of the proposed self-triggered MPC strategy are verified through simulation examples and experimental results on a mobile vehicle experimental platform.},
  archive      = {J_ISAT},
  author       = {Hai Zhao and Hongjiu Yang and Yuanqing Xia and Jinhui Zhang},
  doi          = {10.1016/j.isatra.2025.06.005},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {347-357},
  shortjournal = {ISA Trans.},
  title        = {Nonlinear self-triggered MPC without terminal conditions for trajectory tracking},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control of multi-bus DC microgrids based on distributed dual-projection-layer recurrent neural network considering bus voltage regulation. <em>ISAT</em>, <em>165</em>, 335-346. (<a href='https://doi.org/10.1016/j.isatra.2025.06.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the broad application of plug-and-play loads, it brings new challenges to conventional control issues in DC microgrids. This work addresses the joint optimization of generation costs and transmission line power losses considering bus voltage regulation. Specifically, the concept of virtual load nodes is first introduced so that loads can be implemented as plug-and-play. Through Kron Reduction, bus voltage of load nodes is indirectly controlled by DG nodes. Then, a distributed dual-projection-layer recurrent neural network (DRNN) is proposed for real-time optimal control. The coupled voltage and current are simultaneously maintained within safe bounds. By using Lyapunov synthesis, the convergence of the DRNN is demonstrated. The effectiveness of the proposed methods is evaluated by simulations in terms of plug-and-play test and comparative analysis.},
  archive      = {J_ISAT},
  author       = {Yuanyuan Zhu and Fan Yang and Guoyu Lin},
  doi          = {10.1016/j.isatra.2025.06.029},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {335-346},
  shortjournal = {ISA Trans.},
  title        = {Optimal control of multi-bus DC microgrids based on distributed dual-projection-layer recurrent neural network considering bus voltage regulation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic nonlinear system modelling and parametric oscillation response characteristics of gas turbines. <em>ISAT</em>, <em>165</em>, 320-334. (<a href='https://doi.org/10.1016/j.isatra.2025.06.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas turbines, as highly complex thermal systems, exhibit significant nonlinearity and stochastic coupling in process control. Under closed-loop automatic speed regulation, persistent parametric oscillations may arise, posing serious threats to system reliability and safety. Aiming to reveal the stochastic response characteristics of parametric oscillations in gas turbines, this paper proposes a novel framework for analyzing the evolution law of parametric oscillation and multi-source stochastic excitations based on stochastic dynamics model, which is derived from thermodynamic equations and verified by measurement data. The internal stochastic excitation is determined by information entropy, while the form of the stochastic process of the external stochastic excitation is identified through data-driven reverse identification. The PDF evolution law of parametric oscillation is studied for different excitation forms, and the bifurcation behavior and sensitivity analysis of them are carried out. Under typical operating conditions, the synergistic effect of internal and external stochastic excitations reduces parametric oscillation amplitude by approximately 31 % compared to internal excitation alone. Moreover, the originally tri-modal distribution evolves into a unimodal pattern, revealing the transition trend of parametric oscillation behavior in gas turbines. These findings offer an effective approach to analyze parametric oscillation.},
  archive      = {J_ISAT},
  author       = {Xingyun Jia and Dengji Zhou},
  doi          = {10.1016/j.isatra.2025.06.028},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {320-334},
  shortjournal = {ISA Trans.},
  title        = {Stochastic nonlinear system modelling and parametric oscillation response characteristics of gas turbines},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy modal time-scheduled control and l2-gain analysis for switched nonlinear systems. <em>ISAT</em>, <em>165</em>, 308-319. (<a href='https://doi.org/10.1016/j.isatra.2025.06.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the fuzzy modal time-scheduled control problem for switched nonlinear systems with L 2 -gain performance. Combined with the hybrid dwell time method, we propose a switched fuzzy modal time-scheduled control (FMTSC) strategy, and establish a criterion for H ∞ performance in systems comprising both unstable and stable subsystems. Meanwhile, we further develop a class of time-scheduled multiple discontinuous Lyapunov functions (TMDLFs) for the switched Takagi-Sugeno (T-S) fuzzy system with L 2 -gain property. Finally, comparative and practical examples are provided to demonstrate the validity of derived theoretical result.},
  archive      = {J_ISAT},
  author       = {Jinling Wang and Jun-Guo Lu and Jiarong Li and Qinghao Zhang and Cheng Hu},
  doi          = {10.1016/j.isatra.2025.06.026},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {308-319},
  shortjournal = {ISA Trans.},
  title        = {Fuzzy modal time-scheduled control and l2-gain analysis for switched nonlinear systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving a class of resource allocation problem under dynamic constraints: A predefined-time distributed optimization scheme. <em>ISAT</em>, <em>165</em>, 295-307. (<a href='https://doi.org/10.1016/j.isatra.2025.05.045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a predefined-time distributed optimization algorithm is designed to solve the resource allocation problem (RAP) with dynamic constraints. This algorithm updates auxiliary variables in real time through a distributed approach and allocates resources to each node based on dynamic constraints. Its advantages include ensuring all nodes quickly converge to the optimal value within a predefined time, thereby enhancing algorithm efficiency. Moreover, the auxiliary variables exchanged between nodes do not contain any real physical information, effectively preventing privacy data leakage. In addition, the convergence of the algorithm is analyzed strictly by the Lyapunov method, which ensures the accuracy of the algorithm. Finally, application examples in smart grids and multi-UAV dynamic collaboration are provided to demonstrate the effectiveness and advantages of the algorithm in different application scenarios.},
  archive      = {J_ISAT},
  author       = {Chuxiong Su and Zhongxu Chen and Zhengyuan Zhu and Hao Dai and Jing Chang},
  doi          = {10.1016/j.isatra.2025.05.045},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {295-307},
  shortjournal = {ISA Trans.},
  title        = {Solving a class of resource allocation problem under dynamic constraints: A predefined-time distributed optimization scheme},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-optimal global path planning and collision-avoidance local path planning for USVs in traffic separation scheme-implemented coastal waters. <em>ISAT</em>, <em>165</em>, 280-294. (<a href='https://doi.org/10.1016/j.isatra.2025.06.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under multiple constraints including unmanned surface vehicle (USV) dynamics, traffic separation scheme (TSS) requirements, navigable water boundaries, and safety thresholds for collision risks, time-optimal path planning and collision-avoidance (COLAV) path planning for USVs in TSS-implemented coastal waters remain challenging. To overcome this challenge, we innovatively develop a hierarchical Gaussian-process-based nonlinear programming (GPNLP) approach for the USV time-optimal global path planning and COLAV local path planning. We model irregular static obstacles using Gaussian process regression for the first time, such that navigable waters are more sufficiently utilized for path planning. A TSS compliance assessment function is created to output violation penalties for the TSS requirements that should be satisfied as far as practicable. Accordingly, we plan the time-optimal global path and the COLAV local path hierarchically by minimizing two integral objective functions (with respect to the TSS violation penalties) subject to the multiple constraints. Simulations and simulation comparison results demonstrate that both the planned USV time-optimal global path and COLAV local path under the proposed hierarchical GPNLP approach are USV dynamics compliant and TSS compliant.},
  archive      = {J_ISAT},
  author       = {Yihan Tao and Jialu Du},
  doi          = {10.1016/j.isatra.2025.06.030},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {280-294},
  shortjournal = {ISA Trans.},
  title        = {Time-optimal global path planning and collision-avoidance local path planning for USVs in traffic separation scheme-implemented coastal waters},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time switching tracking control for unmanned helicopter with multiple constraints. <em>ISAT</em>, <em>165</em>, 268-279. (<a href='https://doi.org/10.1016/j.isatra.2025.06.017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a fixed-time switching tracking control scheme based on the fixed-time disturbance observer (FTDO) is proposed for a 6-DOF unmanned helicopter (UH) with multiple constraints and composite disturbances. The developed fixed-time controller guarantees that the system tracks the desired trajectory within a certain time, regardless of initial conditions. The multiple constraints include input saturation and time-varying output constraints. An improved fixed-time auxiliary system is applied to compensate for the effects of input saturation nonlinearity. By developing a novel switching boundary protection algorithm, a switching control scheme is further designed to solve the output constraints better. An improved FTDO is developed to estimate composite disturbances containing saturation function approximation errors and external disturbances. On this basis, a fixed-time switching back-stepping control method is employed for the position and attitude loops, which enables the UH to track the desired trajectory within the flight path constraints. The experimental results verify the effectiveness of the proposed scheme.},
  archive      = {J_ISAT},
  author       = {Haibo Wang and Shuang Shi and Ziyang Zhen and Ju Jiang},
  doi          = {10.1016/j.isatra.2025.06.017},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {268-279},
  shortjournal = {ISA Trans.},
  title        = {Fixed-time switching tracking control for unmanned helicopter with multiple constraints},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leaderless attitude synchronization control of multiple flexible spacecraft on SO(3). <em>ISAT</em>, <em>165</em>, 254-267. (<a href='https://doi.org/10.1016/j.isatra.2025.06.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents adaptive controllers for leaderless attitude synchronization of multiple flexible spacecraft on S O ( 3 ) under communication topologies containing spanning tree(s). To provide a reference attitude for each spacecraft, distributed observers in 9-dimensional Euclidean space are proposed based on a smooth mapping from Euclidean space ℝ 3 × 3 to Lie group S O ( 3 ) . Both the scenarios with arbitrary and almost zero final angular velocities are considered. Subsequently, adaptive continuous controllers on S O ( 3 ) are presented to achieve the leaderless attitude synchronization subject to external disturbance, while guaranteeing boundedness of flexible vibration. Rigorous proofs are presented to show the convergence of the proposed control methods. The effectiveness of the proposed strategies is further demonstrated by numerical simulations.},
  archive      = {J_ISAT},
  author       = {Chenlu Feng and Weicheng Jin and Ti Chen and Lifeng Wang},
  doi          = {10.1016/j.isatra.2025.06.031},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {254-267},
  shortjournal = {ISA Trans.},
  title        = {Leaderless attitude synchronization control of multiple flexible spacecraft on SO(3)},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust predefined fixed-time formation-containment control for multiple unmanned surface vehicles with input saturation. <em>ISAT</em>, <em>165</em>, 241-253. (<a href='https://doi.org/10.1016/j.isatra.2025.06.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predefined fixed-time formation-containment (PFTFC) control problem for unmanned surface vehicles (USVs) under unknown disturbances and input saturation is investigated, where the leaders form a formation configuration and the followers converge to the predefined convex hull formed by the leaders within a fixed time. To address this issue, a two-layer framework is introduced, decomposing the problem into trajectory estimation and trajectory tracking components. In the first layer, a novel fixed-time trajectory estimator is proposed for the leaders and the followers to estimate the desired trajectory. In the second layer, to eliminate the effects of unknown disturbances and input saturation, a fixed-time disturbance observer and an auxiliary system are proposed. Then combining fixed-time Lyapunov stability and integral sliding mode control, fixed-time control laws are proposed for both the leaders and the followers, respectively. Finally, a numerical simulation example is presented to illustrate the effectiveness of the method introduced in this paper.},
  archive      = {J_ISAT},
  author       = {Yong Chen and Jinlong Huang and Fuxi Niu and Xunhua Dai and Haoyue Huang},
  doi          = {10.1016/j.isatra.2025.06.019},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {241-253},
  shortjournal = {ISA Trans.},
  title        = {Robust predefined fixed-time formation-containment control for multiple unmanned surface vehicles with input saturation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-following control for follow-up support systems under model deviation and time delay. <em>ISAT</em>, <em>165</em>, 232-240. (<a href='https://doi.org/10.1016/j.isatra.2025.06.015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Follow-up support technology can flexibly and effectively suppress machining chatter in thin-walled components. This paper proposes a servo collaborative constraint handling scheme that focuses on achieving coordinated control for the follow-up support system under multi-source coupled constraints and uncertainties. Firstly, a four-point constraint method is introduced, which simplifies the description of pose coordination through the introduction of auxiliary points, and constructs the coordinated relationship of the dual robots’ end-effectors under complex geometric constraints in an intuitive and analytical manner. Secondly, a robust controller based on constraint-following theory is designed, providing an effective means to parameterize the total uncertainty boundary structure caused by model deviation and time delay. Finally, the practical stability of the control algorithm is proven, and its effectiveness and strong robustness are validated through comparative simulations.},
  archive      = {J_ISAT},
  author       = {Fangfang Dong and Zhao Liu and Xiaomin Zhao and Jiang Han and Xiaoyong Huang},
  doi          = {10.1016/j.isatra.2025.06.015},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {232-240},
  shortjournal = {ISA Trans.},
  title        = {Constraint-following control for follow-up support systems under model deviation and time delay},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability analysis of delayed neural networks via novel delay-dependent LKF and integral inequality. <em>ISAT</em>, <em>165</em>, 222-231. (<a href='https://doi.org/10.1016/j.isatra.2025.06.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current paper is concerned with the stability analysis of delayed neural networks. In the case that the delay derivative is restricted with an upper bound only, the augmented LKFs often contain high-degree terms of the time-varying delay, resulting in the non-convex derivatives of LKFs, which can be solved by introducing extra delay-multiplied state variables to transform the non-convex delay-dependent terms into convex ones. To make fuller use of the delay-multiplied state variables and the delay-derivative-dependent information, these delay-multiplied state variables are introduced into an LKF and the integral inequality through the proper augmentation in this paper. Meanwhile, some free-matrix-based zero equations are introduced into this delay-dependent inequality to provide more freedom. By applying the augmented LKF and the novel integral inequality, a delay-dependent stability criterion of delayed neural networks with less conservatism is established, whose advantages are verified by three examples.},
  archive      = {J_ISAT},
  author       = {Fei Long and Chuan-Ke Zhang and Yanjun Shen and Qicheng Mei and Qing Chen},
  doi          = {10.1016/j.isatra.2025.06.027},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {222-231},
  shortjournal = {ISA Trans.},
  title        = {Stability analysis of delayed neural networks via novel delay-dependent LKF and integral inequality},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predefined-time adaptive learning control of nonlinear strict-feedback systems via dynamic regressor extension and mixing. <em>ISAT</em>, <em>165</em>, 209-221. (<a href='https://doi.org/10.1016/j.isatra.2025.06.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a parameter identification algorithm and a novel adaptive tracking control strategy for a specific group of nonlinear strict-feedback systems incorporating the concept of predefined time under model uncertainties. A three-layer transformation-based parameter estimation method with predefined-time convergence properties is proposed to relax the strict persistent excitation condition imposed by conventional approaches. The singular terms that may occur in traditional backstepping design procedures are avoided by using a hyperbolic tangent function to design new control laws and filters. Composite learning control approach that incorporates the algorithm for parameter identification into the framework for adaptive dynamic surface control can achieve error convergence within a practical predefined time. By using Lyapunov analysis, the semi-global uniformly predefined-time boundedness for the closed-loop dynamics is demonstrated. Numerical experiments demonstrate the viability of developed control scheme.},
  archive      = {J_ISAT},
  author       = {Zhonghua Wu and Kuncheng Ma and Junkang Ni},
  doi          = {10.1016/j.isatra.2025.06.016},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {209-221},
  shortjournal = {ISA Trans.},
  title        = {Predefined-time adaptive learning control of nonlinear strict-feedback systems via dynamic regressor extension and mixing},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive PI nonlinear cooperative control for motor cluster. <em>ISAT</em>, <em>165</em>, 191-208. (<a href='https://doi.org/10.1016/j.isatra.2025.05.047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the effects of nonlinearities and uncertainties in the speed regulation of permanent magnet synchronous motors (PMSMs), an adaptive PI nonlinear control strategy is introduced. First, a nonlinear system model is developed using the PMSM mathematical model, and an adaptive PI nonlinear control approach is designed. Numerical simulations are conducted to demonstrate that this control method effectively tracks the system’s desired values. Then, through a group of comparative simulation experiments, the comparison effect of the designed adaptive PI nonlinear control method and the traditional PI control method is analyzed and compared. Additionally, four PMSM collaborative control system models, including the speed tracking and speed synchronization control structures, are constructed. Finally, a simulation model for a cooperative PMSM control system is developed to evaluate the system’s speed tracking capability and the synchronization between multiple motors. The results show that in the designed motor cluster cooperative control system, the PMSM motor cluster using adaptive PI nonlinear control method can achieve cooperative control in speed tracking and speed synchronization, and can maintain stable operation against nonlinear problems and unknown disturbances.},
  archive      = {J_ISAT},
  author       = {Yiting Chen and Yushen Wu and Kairui Chen and Jianhui Wang and Zian Wang},
  doi          = {10.1016/j.isatra.2025.05.047},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {191-208},
  shortjournal = {ISA Trans.},
  title        = {Adaptive PI nonlinear cooperative control for motor cluster},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven parallel linear controllers for reference tracking in nonlinear systems. <em>ISAT</em>, <em>165</em>, 183-190. (<a href='https://doi.org/10.1016/j.isatra.2025.05.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference tracking control for nonlinear systems presents significant challenges, particularly when system models are unavailable and real-time computation is required. We present a purely data-driven approach for reference tracking control, referred to as parallel linear controllers (PLIC), which leverages an architecture composed of two linear controllers operating concurrently in distinct dimensional spaces. These controllers are employed for inverse control and mismatch error compensation, respectively. The first controller utilizes the Koopman operator for lifting the system to a high dimension and solves a quadratic program that facilitates constraint handling. The second controller, which works in the original state space, employs the direct data-driven virtual reference tuning approach with some appropriate modifications. The closed-loop properties of the proposed PLIC are analyzed, and the efficacy of the proposed method is exemplified through benchmark simulation.},
  archive      = {J_ISAT},
  author       = {Yao Shi and José M. Maestre and Lei Xie and Hongye Su},
  doi          = {10.1016/j.isatra.2025.05.048},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {183-190},
  shortjournal = {ISA Trans.},
  title        = {Data-driven parallel linear controllers for reference tracking in nonlinear systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time random reference tracking nonlinear model predictive control: A case study on wind turbines. <em>ISAT</em>, <em>165</em>, 170-182. (<a href='https://doi.org/10.1016/j.isatra.2025.06.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a research effort to extend nonlinear model predictive control methods from setpoint stabilization to reference tracking has been felt increasingly. On the other hand, uncertainty in the reference signal and the requirement for its dynamic forecasting in applications such as wind turbine control motivate the need for robust tracking nonlinear model predictive control approaches more and more. Therefore, this study proposes a random reference tracking nonlinear model predictive control with dynamic forecasting of stochastic references. Convergence to a robust invariant set is guaranteed by an additional constraint limiting the previous step’s tracking stage cost function. The proposed predictive approach is implemented using a parallel Newton-type method to make it more efficient and applicable. The proposed approach for wind turbine control is designed considering the random wind speed reference. Simulations are performed for extreme and fatigue load scenarios. The results show that the proposed controller performs more robustly than the nominal nonlinear model predictive control approach, performing better in optimal power extraction and reducing aerodynamic loads.},
  archive      = {J_ISAT},
  author       = {Mohammad Soleymani and Nooshin Bigdeli and Mehdi Rahmani},
  doi          = {10.1016/j.isatra.2025.06.018},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {170-182},
  shortjournal = {ISA Trans.},
  title        = {Real-time random reference tracking nonlinear model predictive control: A case study on wind turbines},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel MPC-based cascaded control for multi-area smart grids: Tackling renewable energy and EV integration challenges. <em>ISAT</em>, <em>165</em>, 143-169. (<a href='https://doi.org/10.1016/j.isatra.2025.06.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced cascaded control scheme for load frequency regulation in multi-area power systems incorporating renewable energy sources (RES) and electric vehicles (EVs). The proposed design (Model predictive control cascaded with one plus proportional-integral control cascaded with tilt control in parallel with one plus fractional-order integral derivative controller (MPC-((1+PI)-(T+(1+I λ D μ )))) combines predictive, tilt, and fractional-order dynamics to improve adaptability and robustness under uncertainties. Controller parameters are tuned using the Lyrebird Optimization Algorithm (LOA), ensuring fast convergence and effective global search. Simulation results under varying operational conditions, including nonlinearity effects such as Generation Rate Constraints (GRC), Governor Dead Band (GDB), and Communication Time Delays (CTD), confirm the controller’s superiority. It achieves a 96.4 % ITAE reduction, 98.6 % undershoot mitigation, and a settling time of just 5.8 s outperforming existing benchmark strategies (GOA: PDf+(0.75+PI), CBOA: PI-PD, JSA: PI, and ARA: 1+PID).},
  archive      = {J_ISAT},
  author       = {Muhammad S. Tolba and Muhammad Majid Gulzar and Ali Arishi and Mohamed Soliman and Ali Faisal Murtaza},
  doi          = {10.1016/j.isatra.2025.06.024},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {143-169},
  shortjournal = {ISA Trans.},
  title        = {A novel MPC-based cascaded control for multi-area smart grids: Tackling renewable energy and EV integration challenges},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency handling by reinforcement of predictive 2DoF-MPC and state observer LADRC for smart power system. <em>ISAT</em>, <em>165</em>, 128-142. (<a href='https://doi.org/10.1016/j.isatra.2025.05.046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preservation of stability is essential for the efficient and reliable functioning of the electrical transmission system. Frequency oscillations are prevalent in interconnected power systems (IPS) and may lead to instability; therefore, it is crucial to monitor and examine them meticulously. Effective frequency management is essential for regulating frequency output in an interconnected smart power system (ISPS) that includes renewable energy sources (RESs), redox flow batteries (RFBs) and static synchronous series compensators (SSSCs). In view of the challenge presented, this research introduces an efficient control architecture that utilizes a 2 degree of freedom-based model predictive controller (2DoF-MPC) to enhance system performance. Additionally, it integrates a linear active disturbance rejection control (LADRC) to employ a state observer alongside the evolving frequency management. The convergence of the predictive and state observer frameworks results in a robust 2DoF-MPC-LADRC to manage frequency disturbances and uncertainties in the power system. The suggested technique is thoroughly validated across several parameters for ISPS, instilling confidence in its capacity to attain minimal frequency variation in multiple scenarios. The performance of the proposed controller design shows that the frequency performance in area 1 and area 2 settles in 5.085 sec and 3.965 sec, when the load changes by 3 %, and it settles in 4.655 sec and 4.050 sec, respectively, when the load changes by 5 %.},
  archive      = {J_ISAT},
  author       = {Muhammad Majid Gulzar},
  doi          = {10.1016/j.isatra.2025.05.046},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {128-142},
  shortjournal = {ISA Trans.},
  title        = {Frequency handling by reinforcement of predictive 2DoF-MPC and state observer LADRC for smart power system},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional-order sliding mode coordinated controller using super-twisting disturbance observer for an NSSS with predefined-time stability. <em>ISAT</em>, <em>165</em>, 111-127. (<a href='https://doi.org/10.1016/j.isatra.2025.06.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a fractional-order sliding mode coordinated control (FOSMCC) strategy incorporating dual super-twisting disturbance observers (STDOs) to enhance the control performance, stability, and reliability of the nuclear steam supply system (NSSS) under complex, time-varying operating conditions and compound disturbances. The FOSMCC strategy synthesizes the fractional-order control and predefined-time theory with sliding mode control, augmented by the disturbance feedforward compensation loop driven by dual STDOs. Such control framework provides enhanced control performance guarantees, including fast transient response, high steady-state precision, and reinforced disturbance rejection. Furthermore, by employing Lyapunov’s direct approach, it is theoretically demonstrated that the entire NSSS, under the developed coordinated strategy, achieves superior predefined-time stability. Finally, comprehensive numerical validation and comparative studies reveal that the developed FOSMCC strategy with STDOs significantly outperforms both the latest fractional-order fixed-time sliding mode controller (FOFTSMC) and the practically adopted coordinated controller (PACC), exhibiting better transient/steady-state control response and stronger robustness against disturbances. Simulation results validate that, in the presence of compound disturbances, the proposed FOSMCC strategy reduces the integral absolute control error of nuclear power and water level by 89.37 % and 87.67 %, respectively, compared to FOFTSMC, and by 99.97 % and 99.99 %, respectively, compared to PACC.},
  archive      = {J_ISAT},
  author       = {Jiuwu Hui},
  doi          = {10.1016/j.isatra.2025.06.032},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {111-127},
  shortjournal = {ISA Trans.},
  title        = {Fractional-order sliding mode coordinated controller using super-twisting disturbance observer for an NSSS with predefined-time stability},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time observer-based saturated nonsingular terminal sliding mode controller design for an over-actuated ROV with time-varying saturation limits. <em>ISAT</em>, <em>165</em>, 98-110. (<a href='https://doi.org/10.1016/j.isatra.2025.06.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Input saturation is critical in over-actuated systems when multiple degrees of freedom (DOF) with different levels of disturbance rejection are controlled simultaneously by a set of actuators. The current study introduces a novel saturated non-singular terminal sliding mode controller to address input saturation for an over-actuated remotely-operated vehicle (ROV). The proposed controller consists of a tuning algorithm to ensure that the control commands do not violate the time-varying saturation limits of each DOF. In addition, a fixed-time extended-state observer is designed to estimate the vehicle’s velocity along with the lumped unknown dynamics of the system. The observer is also employed as a tool to maintain the orientation of the ROV in extreme environmental conditions. The stability analysis shows that all system’s states, except for yaw angle, are globally finite-time stable and the yaw angle is globally asymptotically stable. Several sets of simulations are carried out and the results demonstrate the superiority of the proposed controller in terms of positioning accuracy, saturation compensation and transient behaviour under different environmental conditions.},
  archive      = {J_ISAT},
  author       = {Alireza Hosseinnajad and Navid Mohajer},
  doi          = {10.1016/j.isatra.2025.06.025},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {98-110},
  shortjournal = {ISA Trans.},
  title        = {Fixed-time observer-based saturated nonsingular terminal sliding mode controller design for an over-actuated ROV with time-varying saturation limits},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonsingular fast terminal sliding mode control scheme for robust trajectory tracking of the underactuated EvoBot modular mobile robot in the vertical plane. <em>ISAT</em>, <em>165</em>, 83-97. (<a href='https://doi.org/10.1016/j.isatra.2025.06.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust control strategy for the vertical plane motion of an underactuated EvoBot mobile robot, modeled as a serial double inverted pendulum, is presented in this study. The control objectives include controlling both the directly actuated generalized coordinates and the non-actuated generalized coordinate, which is controllable through dynamic coupling with the actuated coordinates. In this regard, the system's dynamic equations are derived using the Lagrangian approach. A new nonlinear and nonsingular sliding manifold is introduced, based on which a nonsingular fast terminal sliding mode control scheme is proposed for the trajectory tracking control of the robot. This approach addresses the challenges posed by underactuation, system nonlinearities, instability, parameter uncertainties, and external disturbances. Through Lyapunov stability analysis, it is proven that finite-time asymptotic convergence of the tracking error to zero is ensured when the uncertainty upper bound is known, and convergence to a residual set is achieved when the upper bound is unavailable. The theoretical guarantees provided by the proposed control scheme are further validated through comprehensive MATLAB simulations, where its effectiveness is demonstrated under both low- and high-frequency disturbances as well as parameter uncertainties.},
  archive      = {J_ISAT},
  author       = {H. Jokar and S. Amini Serajgah},
  doi          = {10.1016/j.isatra.2025.06.013},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {83-97},
  shortjournal = {ISA Trans.},
  title        = {A nonsingular fast terminal sliding mode control scheme for robust trajectory tracking of the underactuated EvoBot modular mobile robot in the vertical plane},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time event-triggered sliding mode control for fuzzy singular systems under cyber-attacks. <em>ISAT</em>, <em>165</em>, 72-82. (<a href='https://doi.org/10.1016/j.isatra.2025.06.012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a novel secure control scheme for a particular class of Takagi–Sugeno (TS) fuzzy singular systems susceptible to deception attacks. During these attacks, adversaries can randomly introduce erroneous data into the output and control signals. The proposed strategy addresses the impact of attacks and disturbances using an observer-based sliding mode control (SMC) approach. Moreover, an event-triggering protocol is implemented to manage network resources efficiently. Furthermore, by employing the stochastic Lyapunov theory and the finite-time analysis method, sufficient conditions are established to ensure the finite-time boundedness of the resulting closed-loop system throughout both the reaching and sliding motion phases. To mitigate the attack’s effects and improve the system’s performance, the Secretary Bird Optimization Algorithm (SBOA) with the linear matrix inequality (LMI) is explored as a new approach for designing the optimal gains of controllers and observers. Finally, a simulation study based on a disc rolling on a surface is performed to showcase the efficacy and resilience of the proposed control scheme.},
  archive      = {J_ISAT},
  author       = {Mourad Kchaou and Rabeh Abassi and Houssem Jerbi},
  doi          = {10.1016/j.isatra.2025.06.012},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {72-82},
  shortjournal = {ISA Trans.},
  title        = {Finite-time event-triggered sliding mode control for fuzzy singular systems under cyber-attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-based dynamic event-triggered secure control of active suspension systems against deception attacks. <em>ISAT</em>, <em>165</em>, 64-71. (<a href='https://doi.org/10.1016/j.isatra.2025.06.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study deals with the issue of a memory-based dynamic event-triggered control strategy for active quarter-vehicle suspension systems (QVSSs). The main objective is to design an effective event-triggered mechanism (ETM) that ensures suspension performance while reducing network resource usage, even under deception attacks. To this end, an innovative memory-based dynamic ETM is proposed to coordinate sensor data transmission efficiently in the presence of such attacks. The proposed transmission scheme integrates historical release information, which helps suppress false triggering by utilizing averaged data. Additionally, the proposed ETM dynamically updates triggering conditions over time, facilitating dynamic scheduling of network data transmission. Sufficient conditions are derived to guarantee satisfactory performance of the QVSS under the proposed control strategy. A numerical example is provided to validate the effectiveness of the approach.},
  archive      = {J_ISAT},
  author       = {Wangrui Cheng and Tingting Yin and Zhou Gu},
  doi          = {10.1016/j.isatra.2025.06.007},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {64-71},
  shortjournal = {ISA Trans.},
  title        = {Memory-based dynamic event-triggered secure control of active suspension systems against deception attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-varying formation control for heterogeneous multi-agent systems in the presence of actuator faults and deception attacks. <em>ISAT</em>, <em>165</em>, 54-63. (<a href='https://doi.org/10.1016/j.isatra.2025.06.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the control of time-varying formations in a class of heterogeneous multi-agent systems. The key innovation lies in the simultaneous consideration of hybrid actuator faults and deception attacks. To achieve the control objective, a novel distributed double-layer control scheme, comprising a network layer and a physical layer, is proposed. In the network layer, a distributed observer with secure output feedback control is developed to mitigate severe deception attacks, ensuring that the mean square observer error remains within an acceptable range. In the physical layer, fault compensators are designed to address both additive and multiplicative faults. As a result, the followers achieve time-varying formation control, and closed-loop stability analysis is conducted using the Lyapunov method. Finally, to verify the validity of the theoretical findings, numerical simulations are subsequently conducted.},
  archive      = {J_ISAT},
  author       = {Shicheng Cao and Yanhui Yin and Wenyu Li and Zhongxin Liu and Zengqiang Chen},
  doi          = {10.1016/j.isatra.2025.06.004},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {54-63},
  shortjournal = {ISA Trans.},
  title        = {Time-varying formation control for heterogeneous multi-agent systems in the presence of actuator faults and deception attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered consensus of multi-agent systems with uncertain control gain via distributed fuzzy logic observer. <em>ISAT</em>, <em>165</em>, 40-53. (<a href='https://doi.org/10.1016/j.isatra.2025.06.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An event-triggered adaptive backstepping control methodology is proposed to achieve leader-following consensus of uncertain nonlinear high-order multi-agent systems with unknown control gains. In light of the partial observability limitation, adaptive distributed observers are employed to estimate the unobservable states of the leader, whereas local state observers are utilized to reconstruct the states of the followers. By integrating fuzzy logic systems, the unknown nonlinear dynamics are modeled, guaranteeing reliable state prediction in complex and partially observable scenarios. Moreover, the novel relative threshold event-triggered scheme is designed to reduce the frequency of data interactions while ensuring that the tracking error approaches near-zero. Eventually, the effectiveness and superiority of the devised controller are clearly demonstrated through comprehensive simulation results.},
  archive      = {J_ISAT},
  author       = {Konghao Xie and Xiujuan Zhao and Shiming Chen and Zheng Zhang and Yuanshi Zheng},
  doi          = {10.1016/j.isatra.2025.06.020},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {40-53},
  shortjournal = {ISA Trans.},
  title        = {Event-triggered consensus of multi-agent systems with uncertain control gain via distributed fuzzy logic observer},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consensus seeking in large-scale multi-agent systems with homogeneous connections by incorporating two-hop neighbor states. <em>ISAT</em>, <em>165</em>, 27-39. (<a href='https://doi.org/10.1016/j.isatra.2025.06.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of multi-agent consensus raises the importance of network topology. As the number of agents increases, multi-agent systems (MAS) in a large-scale and high-density topology demand higher resources, which consequently degrades efficiency of consensus. Existing approaches that consider only direct point-to-point neighbors may overlook potential topological information, further hindering consensus performance. To achieve fast consensus in large-scale and high-density topologies, a framework named Homogeneous Connections Based on Agents State Fusions MAS (HCASFMAS) is proposed. The framework extracts broader topology information of consensus degree by fusing states of two-hop neighbors. Leveraging homogeneous idea, agents establish homogeneous connections with neighbors that exhibit a higher consensus degree, ultimately accelerating the consensus process while preserving connectivity. First, a neighbor selection strategy based on consensus degree of agent state fusion is introduced to construct candidate neighbors, aiming to reduce redundant connections. Second, an adaptive consensus algorithm is formulated to flexibly adapt to the distribution of neighbors. Finally, a candidate constraints set is established to accelerate consensus by expanding the scope of constraints while preserving connectivity. In this study, connectivity and convergence of the system are theoretically analyzed from a geometric perspective. Simulation experiments are conducted to compare the proposed method with existing approaches under different densities and topologies. Simulation results demonstrate the superiority of this method in achieving fast convergence, particularly in large-scale and high-density scenarios.},
  archive      = {J_ISAT},
  author       = {Guangqiang Xie and Chaohao Shen and Yang Li and Yanda Feng and Fengyang Qiu},
  doi          = {10.1016/j.isatra.2025.06.002},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {27-39},
  shortjournal = {ISA Trans.},
  title        = {Consensus seeking in large-scale multi-agent systems with homogeneous connections by incorporating two-hop neighbor states},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic formation tracking and fault-tolerant control of multi-agent systems based on distance and topology reconstruction methods. <em>ISAT</em>, <em>165</em>, 15-26. (<a href='https://doi.org/10.1016/j.isatra.2025.06.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a distributed approach for dynamic formation tracking and formation fault-tolerant control within the port-Hamiltonian energy framework for multi-agent system (MAS) affected by Coulomb friction. The coupling relationships between agents are equivalently modeled as virtual springs, which simulate the interaction forces between agents to reflect the relative positions and motion states of the agents. A distance-based distributed control scheme is designed, to ensure that the formation composed of multiple agents can continuously adjust the direction and size of the formation while achieving target tracking. Additionally, considering the possibility of communication failure due to agent motion faults, a fault-tolerant algorithm based on topological reconstruction is proposed to reconstruct the formation topology after faults. The feasibility of this control method is verified through numerical simulations.},
  archive      = {J_ISAT},
  author       = {Lu Liu and Yu Cui and Yonghua Wang and Jinglong Wen and Shuaishuai Kong and Yuhang Ma and Dan Liu and Peng Shi and Chenyang Xue},
  doi          = {10.1016/j.isatra.2025.06.006},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {15-26},
  shortjournal = {ISA Trans.},
  title        = {Dynamic formation tracking and fault-tolerant control of multi-agent systems based on distance and topology reconstruction methods},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast actuator fault-tolerant control for a class of nonlinear sampled-data systems via deterministic learning. <em>ISAT</em>, <em>165</em>, 1-14. (<a href='https://doi.org/10.1016/j.isatra.2025.05.049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the fast fault-tolerant control (FTC) problem based on deterministic learning approach (DLA) for a class of nonlinear sampled-data systems with actuator faults, which consist of two stages: incipient faults with small magnitudes and faults with larger magnitudes. First, a learning controller and a learning identifier are constructed. Based on DLA and the exponential stability of a class of linear time-varying (LTV) discrete-time systems, the control knowledge and the diagnosis knowledge of the actuator faults are obtained. Second, a set of controllers and a set of diagnosis estimators are constructed based on the learnt control and diagnosis knowledge. When an incipient actuator fault occurs, fast fault detection and isolation (FDI) can be achieved using the diagnosis estimators. Then, the pattern-based FTC scheme is implemented to improve the control performance. When the small fault grows to a larger one, the rapid FDI and FTC are implemented again, providing fast responses to the occurred larger fault. The advantages of the proposed method are that: (i) a simple adaptive learning controller with the filtering technique is designed, in which the exponential convergence of the tracking error and parameter estimation errors can be achieved simultaneously; (ii) the sensitivity to small actuator faults is enhanced, and the fast FTC to larger actuator faults is achieved by utilizing the learnt knowledge. Simulation results are also included to illustrate the effectiveness of these schemes.},
  archive      = {J_ISAT},
  author       = {Yu Zeng and Tianrui Chen and Fukai Zhang and Cong Wang},
  doi          = {10.1016/j.isatra.2025.05.049},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {1-14},
  shortjournal = {ISA Trans.},
  title        = {Fast actuator fault-tolerant control for a class of nonlinear sampled-data systems via deterministic learning},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="isci">ISCI - 27</h2>
<ul>
<li><details>
<summary>
(2026). Robust watermarking for diffusion model generated images. <em>ISCI</em>, <em>723</em>, 122686. (<a href='https://doi.org/10.1016/j.ins.2025.122686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of diffusion models in the field of image generation, image copyright protection and traceability have become increasingly complex and challenging. To address these problems, this paper proposes a robust watermarking method for diffusion model generated images to achieve their copyright protection and traceability. The method designs an invertible mapping module to replicate and cryptographically map the watermark information into an approximately Gaussian distributed noise, which is highly consistent with the distribution of the original generation model. The mapped watermark noise serves as the latent space vector of the generative model, preserving both image generation quality and model performance. In the watermark extraction stage, the original watermark information can be accurately recovered from the generated image through the reverse extraction and voting mechanism. Experimental results show that the proposed method demonstrates excellent performance in terms of image watermark extraction accuracy, robustness and watermark image generation quality. It can still maintain 99 % true positive rate and 97.5 % bit accuracy under various attacks, and the overall performance in the detection and traceability scenarios is significantly better than the existing baseline methods.},
  archive      = {J_ISCI},
  author       = {Ziqi Liu and Yuan Guo and Liansuo Wei},
  doi          = {10.1016/j.ins.2025.122686},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122686},
  shortjournal = {Inf. Sci.},
  title        = {Robust watermarking for diffusion model generated images},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis. <em>ISCI</em>, <em>723</em>, 122684. (<a href='https://doi.org/10.1016/j.ins.2025.122684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on enhancing the extraction of sentiment quadruples consisting of target, aspect, opinion, and sentiment from multi-turn dialogs, which remains a challenging problem in conversational sentiment analysis. Existing methods frequently encounter challenges with complex sentence structures, presence of multiple sentiment quadruples, and interference from irrelevant contextual information. These challenges often result in suboptimal performance. These limitations are addressed by introducing Schrödinger equation-based adaptive dropout multi-granular feature enhancement network (SEAD-MGFE-Net), a novel framework that synergizes multigranular feature extraction with quantum-inspired adaptive regularization. The proposed methodology incorporates a multi-layer tree structure to segment sentences into semantically coherent fragments, thereby improving the alignment between aspect and opinion terms while simultaneously mitigating noise impact. Moreover, we engineer a multi-angle dynamic adjacency learning enhancement module that adeptly captures both local and global features inherent in graph-structured representations. Additionally, we devise an adaptive dropout mechanism based on the Schrödinger equation, facilitating automatic modulation of the regularization strength throughout training. Extensive evaluations on benchmark datasets in both Chinese and English validate the state-of-the-art effectiveness of our proposed SEAD-MGFE-Net model, achieving Micro-F1 scores of 46.53 % (Chinese) and 40.97 % (English), surpassing the strongest baseline models by 2.04 % and 1.57 %, respectively. SEAD-MGFE-Net exhibits efficacy in extracting cross-utterance quadruples and managing long-range dependencies. These findings confirm the effectiveness and broad applicability of SEAD-MGFE-Net for conversational sentiment analysis.},
  archive      = {J_ISCI},
  author       = {Wei Liu and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
  doi          = {10.1016/j.ins.2025.122684},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122684},
  shortjournal = {Inf. Sci.},
  title        = {SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy. <em>ISCI</em>, <em>723</em>, 122682. (<a href='https://doi.org/10.1016/j.ins.2025.122682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing concerns regarding data privacy exacerbate the challenges associated with “data silos”. Federated learning (FL) effectively addresses these issues by facilitating distributed machine learning without necessitating direct data exchange. However, the dependence on a central server in conventional FL architectures exacerbates privacy risks and limits cross-domain data sharing. Existing blockchain-based FL frameworks often employ static consensus protocols, such as classical Practical Byzantine Fault Tolerance (PBFT), which typically rely on fixed weight aggregation strategies. While these methods simplify implementation, they fail to adaptively adjust aggregation weights according to heterogeneous privacy budgets. Attempts to implement adaptive weight aggregation often require achieving consensus for each individual weight, significantly reducing efficiency and creating scalability challenges in large-scale networks. To address these gaps, we propose DSM-PBFT, a variant PBFT consensus enhanced with dynamic scoring matrices (DSM), which enables parallelized validation of multiple models while adaptively adjusting aggregation weights based on differential privacy budgets. Our noise-aware aggregation mechanism dynamically reweights models through cross-validation of accuracy, F1 score, and loss-transformed metrics, effectively decoupling privacy guarantees from model utility degradation. Security analyses affirm the robustness of this framework against Byzantine attacks, with experimental results on MNIST, FashionMNIST and CIFAR-10 demonstrating superior model accuracy across diverse privacy budgets while effectively curbing accuracy degradation under attack scenarios.},
  archive      = {J_ISCI},
  author       = {Wentai Yang and Xian Xu and Kai Yu and Guoqiang Li},
  doi          = {10.1016/j.ins.2025.122682},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122682},
  shortjournal = {Inf. Sci.},
  title        = {Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Subsequence heterogeneity contrastive learning for time series anomaly detection. <em>ISCI</em>, <em>723</em>, 122680. (<a href='https://doi.org/10.1016/j.ins.2025.122680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is widely applied across various real-world scenarios. Recently, contrastive learning has shown remarkable ability in learning discriminative representations for detecting anomalies. However, most existing contrastive-based methods rely on complex contrastive mechanisms and specially designed model architectures, which make it difficult to maintain efficiency and flexibility across various application scenarios. To address this limitation, we introduce Subsequence-Heterogeneity that defined as the discrepancies in variation patterns and statistical characteristics between subsequences obtained through fixed-interval sampling, which are more pronounced in anomalous sequences than in normal ones. It can serve as a natural discrimination criterion and eliminate the need for complex contrastive mechanisms and specialized model architectures. Specifically, we adopt an efficient temporal hierarchical masking strategy with linear complexity to construct two branches for learning representations at different granularities. The Subsequence-Heterogeneity Contrastive Learning (SHCL) is implemented with different neural networks and enables flexible application to anomaly detection across diverse scenarios. Experiments on eight benchmark datasets demonstrate that SHCL not only achieves state-of-the-art performance with reduced time and resource costs but also significantly improves the ability of different neural networks to distinguish normal from anomalous patterns. The source code is publicly available at https://github.com/Zhangzzbzzb/SHCL/ .},
  archive      = {J_ISCI},
  author       = {Zhibin Zhang and Xiaohong Zhang and Qiang Li and Chun Huang and Tao Yin and Meng Yan},
  doi          = {10.1016/j.ins.2025.122680},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122680},
  shortjournal = {Inf. Sci.},
  title        = {Subsequence heterogeneity contrastive learning for time series anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Escrow-free attribute based signature with constant-size for the internet of things. <em>ISCI</em>, <em>723</em>, 122679. (<a href='https://doi.org/10.1016/j.ins.2025.122679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute based signature (ABS) provides a promising solution for anonymous authentication. However, numerous prevailing ABS algorithms are ill-suited for anonymous authentication in the Internet of Things (IoT), due to problems such as key escrow, high computational overhead, inflexible access policies, and vulnerability to collusion attacks. Considering these shortcomings, we present an escrow-free attribute based signature with constant-size signature for IoT. Our proposal uses the linear secret-sharing scheme (LSSS) and the notion of certificateless cryptography to restrict the authorities of each attribute authority and the system authority. In addition, it generates a constant-size signature and achieves high verification efficiency by aggregating attribute keys. Theoretical analyses demonstrate that our proposal achieves anonymous authentication and is provably secure under the standard model. Simulation experiments show that the execution time of our algorithm is less than 50 ms to run during both the signature and verification phases, making it well-suited for applications with limited resources.},
  archive      = {J_ISCI},
  author       = {Xudong Liu and Xiaojun Tong and Yihui Wang},
  doi          = {10.1016/j.ins.2025.122679},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122679},
  shortjournal = {Inf. Sci.},
  title        = {Escrow-free attribute based signature with constant-size for the internet of things},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep dual contrastive learning for multi-view subspace clustering. <em>ISCI</em>, <em>723</em>, 122678. (<a href='https://doi.org/10.1016/j.ins.2025.122678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) aims to learn a consistent shared self-representation by utilizing the consistency and complementarity of all views, numerous MVSC algorithms have attempted to obtain the optimal representation directly from raw features. However, they might overlook the noisy or redundant information in raw feature space, resulting in learning suboptimal self-representation and poor performance. To address this limitation, an intuitive idea is introducing deep neural networks to eliminate the noise and redundancy, yielding a potential embedding space. Nevertheless, existing deep MVSC methods merely focus on either the embeddings or self-expressions to explore the complementary information, which hinders subspace learning. In this paper, we present a deep multi-view dual contrastive subspace clustering framework to exploit the complementarity to learn latent self-representations effectively. Specifically, multi-view encoders are constructed to eliminate noise and redundancy of the original features and capture low-dimensional subspace embeddings, from which the self-representations are learned. Moreover, two diverse specific fusion methods are conducted on the latent subspace embeddings and the self-expressions to learn shared self-representations, and dual contrastive constraints are proposed to fully exploit the complementarity among views. Extensive experiments are conducted to verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xincan Lin and Jie Lian and Zhihao Wu and Jielong Lu and Shiping Wang},
  doi          = {10.1016/j.ins.2025.122678},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122678},
  shortjournal = {Inf. Sci.},
  title        = {Deep dual contrastive learning for multi-view subspace clustering},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parameter-free discrete clustering via adaptive hypergraph fusion. <em>ISCI</em>, <em>723</em>, 122677. (<a href='https://doi.org/10.1016/j.ins.2025.122677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering has garnered significant attention due to its outstanding performance in uncovering sample structures. However, existing graph-based methods face two major challenges: 1) In graph construction, they typically focus only on direct connections between samples or an exact high-order relationship, neglecting the impact of hidden complex relationships on clustering performance; 2) The separation of spectral analysis and category acquisition into two distinct stages often results in a loss of effectiveness. To handle these problems, we propose a parameter-free discrete clustering method, called parameter-free discrete clustering via adaptive hypergraph fusion (DCAHF). Specifically, DCAHF first produces multiple different hypergraphs, each serving as a biased approximation of the data's intrinsic manifold. These complementary approximations capture distinct local-to-global geometric patterns. Then, it introduces an adaptive fusion strategy that learns optimal weights to combine them into a single consensus hypergraph on manifold space, effectively reconstructing the real manifold structure with reduced bias and improved integrity. Finally, discrete spectral analysis is performed directly on the consensus hypergraph to generate discrete sample categories, thereby avoiding the performance loss associated with two-stage approaches. Thus, DCAHF is a high-performance, parameter-free clustering model that can flexibly adapt to various clustering tasks. Since the DCAHF model cannot be solved using gradient descent methods, we develop a coordinate descent-based optimization algorithm to efficiently solve the model. Extensive experimental results demonstrate that DCAHF significantly enhances clustering effectiveness while maintaining comparable efficiency to state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Ben Yang and Xuetao Zhang and Badong Chen},
  doi          = {10.1016/j.ins.2025.122677},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122677},
  shortjournal = {Inf. Sci.},
  title        = {Parameter-free discrete clustering via adaptive hypergraph fusion},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-branch semantic alignment for few-shot image classification. <em>ISCI</em>, <em>723</em>, 122676. (<a href='https://doi.org/10.1016/j.ins.2025.122676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable progress of deep learning in computer vision has significantly stimulated research interest in few-shot image classification. This field aims to transfer knowledge from previous experiences to recognize new concepts with limited samples. However, most existing approaches primarily concentrate on aligning semantic information at high-level features, neglecting the importance of middle-level or low-level feature representations. In this paper, we propose a novel approach called Multi-Branch Semantic Alignment (MBSA) for few-shot image classification, with the objective of investigating the role of multi-level features. Instead of using standard convolutional layers, we employ diverse convolutional layers to generate enhanced representations in each branch. These representations are then utilized by a dense classifier, which is supervised by a powerful guidance mechanism to incorporate semantic information into their spatial locations. During the inference stage, the multi-branch semantic alignment is designed to align multi-level features between query images and support images. This alignment process effectively establishes semantic correspondences between representations at different levels, thereby enhancing the ability to recognize novel categories. Comprehensive experiments are conducted on various few-shot benchmarks to demonstrate the superiority of our approach compared to those of several previous approaches, and ablation studies are performed to analyze the impact of different components.},
  archive      = {J_ISCI},
  author       = {Zijun Zheng and Heng Wu and Laishui Lv and Changchun Zhang and Hongcheng Guo and Shanzhou Niu and Gaohang Yu},
  doi          = {10.1016/j.ins.2025.122676},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122676},
  shortjournal = {Inf. Sci.},
  title        = {Multi-branch semantic alignment for few-shot image classification},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partition-based differentially private synthetic data generation. <em>ISCI</em>, <em>723</em>, 122675. (<a href='https://doi.org/10.1016/j.ins.2025.122675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private synthetic data sharing is beneficial as it better retains the distribution and nuances of the original data compared to summary statistics such as means and frequencies. Current state-of-the-art methods follow a select-measure-generate paradigm, but measuring large-domain marginals often leads to significant errors, and managing the privacy budget poses challenges. Our partition-based approach addresses these issues, effectively reducing errors and improving the quality of synthetic data, even with a limited privacy budget. Experimental results show that our method outperforms existing approaches, yielding synthetic data with enhanced quality and utility, making it a preferred option for private data sharing.},
  archive      = {J_ISCI},
  author       = {Meifan Zhang and Dihang Deng and Lihua Yin},
  doi          = {10.1016/j.ins.2025.122675},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122675},
  shortjournal = {Inf. Sci.},
  title        = {Partition-based differentially private synthetic data generation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transferable adversarial attacks on human pose estimation: A regularization and pruning framework. <em>ISCI</em>, <em>723</em>, 122674. (<a href='https://doi.org/10.1016/j.ins.2025.122674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Pose Estimation (HPE) is a core component in real-time decision systems, supporting critical applications such as healthcare monitoring, autonomous driving, and sports analytics. While deep learning models—particularly CNNs and Transformer-based architectures—have significantly improved HPE accuracy, they remain vulnerable to adversarial perturbations that subtly distort keypoint localization, thereby undermining system reliability. To address this challenge, we propose regularization and pruning transferable adversarial attack (RPA), a novel framework designed to enhance the transferability of adversarial samples in Transformer-based HPE models. RPA integrates two synergistic strategies: gradient regularization, which suppresses dominant feature correlations to reduce overfitting, and adaptive weight pruning, which removes redundant parameters to reduce model-specific noise. This dual mechanism enables the generation of transferable adversarial attacks that are effective across diverse model architectures. Extensive experiments on state-of-the-art HPE networks demonstrate that RPA consistently outperforms existing attack methods. In white-box settings, RPA reduces average precision (AP) by 0.05-0.30; in black-box scenarios, it yields AP drops of 0.01-0.04. These findings expose critical vulnerabilities in IoT-enabled HPE applications and establish a new benchmark for evaluating adversarial robustness in real-time perception systems.},
  archive      = {J_ISCI},
  author       = {Renguang Chen and Xuechao Yang and Xun Yi and Zhide Chen and Chen Feng and Xu Yang and Kexin Zhu and Iqbal Gondal},
  doi          = {10.1016/j.ins.2025.122674},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122674},
  shortjournal = {Inf. Sci.},
  title        = {Transferable adversarial attacks on human pose estimation: A regularization and pruning framework},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection. <em>ISCI</em>, <em>723</em>, 122673. (<a href='https://doi.org/10.1016/j.ins.2025.122673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) aims to automatically identify anomalous events in surveillance videos that are significantly different from the normal pattern. Most existing methods learn the spatial-temporal distribution of normal features and detect deviations as anomalies. Typically, they employ autoencoders to independently learn appearance and motion features, but this separate learning limits the exploitation of their interrelation in real-world scenarios. To enhance the representation of normal patterns by capturing feature interrelation, we propose a cross-feature fusion and memory-constraint network (CF 2 M-Net) for VAD. Specifically, inspired by the representational ability of cross-attention in multimodal fusion, we design a cross-attention and memory-constraint (CM) module to enrich appearance features with motion information. To prevent overfitting to anomalous events, the memory-constraint module further constrains fused features within the distribution of normal patterns. We design an attention fusion (AF) decoder to predict normal features closer to the normal distribution, enhancing their separability from anomalies. By jointly modeling appearance and motion through feature fusion and memory constraints, CF 2 M-Net provides more discriminative normal representations for anomaly detection. Experimental evaluations on three benchmark datasets show that the CF 2 M-Net performs comparably with leading approaches. Moreover, the detailed evaluations indicate the effectiveness of normal representation based appearance-motion fusion features for VAD.},
  archive      = {J_ISCI},
  author       = {Qiming Ma and Chengyou Wang and Xiao Zhou},
  doi          = {10.1016/j.ins.2025.122673},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122673},
  shortjournal = {Inf. Sci.},
  title        = {CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method. <em>ISCI</em>, <em>723</em>, 122672. (<a href='https://doi.org/10.1016/j.ins.2025.122672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed data-driven event-triggered secure consensus control issue for model-free multi-agent systems (MASs) under sensor faults and denial-of-service (DoS) attacks, while satisfying prescribed performance constraints. First, a global preset-time performance function (PTPF) is constructed to guarantee the global stability of model-free MASs within the preset time. The proposed PTPF ensures that the preset time remains unaffected by variations in the sampling period. Second, a proportional-integral-derivative (PID) sliding surface is designed to enhance MAS performance regulation, while a novel generalized fuzzy hyperbolic model (GFHM) is constructed to eliminate the dependency on fault information and achieve high-accuracy estimation of unknown fault signals. Third, a hybrid event-triggered mechanism integrating both dynamic and memory features is developed to optimize communication resource utilization while guaranteeing robust performance at extremes. Furthermore, an event-triggered secure control scheme leveraging the memory feature is proposed to reduce communication overhead while avoiding the dangerous open-loop scenario, where control inputs must be zeroed under DoS attacks as in the existing methods. Finally, the stability proof together with simulations confirms the feasibility of the control strategy.},
  archive      = {J_ISCI},
  author       = {Run-Ze Chen and Xiang-Gui Guo and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2025.122672},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122672},
  shortjournal = {Inf. Sci.},
  title        = {Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization. <em>ISCI</em>, <em>723</em>, 122671. (<a href='https://doi.org/10.1016/j.ins.2025.122671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimization problems (MaOPs) are widely used in scientific research and engineering practices, which mainly consider joint optimization of multiple objectives simultaneously. Despite the numerous multi-objective evolutionary algorithms proposed in recent years, they often struggle with challenges in fitness assignment arising from objective conflicts. Meanwhile, they tend to perform well in only one aspect of convergence, diversity, and computational complexity. To address these issues, this paper proposes an improved multi-population co-evolutionary algorithm for many-objective optimization (termed MPCMO), which leverages the advantages of multi-population co-evolutionary techniques. The primary objective of MPCMO is to achieve a more balanced performance across convergence, diversity, and complexity. MPCMO comprises three essential components. Initially, an adaptive evolutionary strategy is employed to dynamically allocate evolutionary opportunities to subpopulations so as to conserve computational resources and enhance convergence. Subsequently, a migration strategy is developed to ensure a more global approximation of whole Pareto front. Additionally, an archive update-truncation strategy, based on angle selection and shift-based density estimation, is adopted to enhance diversity. We conduct comprehensive comparative experiments on a variety of many-objective benchmark problems with complicated characteristics. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art algorithms in terms of both diversity and convergence.},
  archive      = {J_ISCI},
  author       = {Weichao Ding and Jiahao Liu and Wenbo Dong and Fei Luo and Chunhua Gu},
  doi          = {10.1016/j.ins.2025.122671},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122671},
  shortjournal = {Inf. Sci.},
  title        = {MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforced heterogeneous graphlet design for knowledge graph representation learning. <em>ISCI</em>, <em>723</em>, 122670. (<a href='https://doi.org/10.1016/j.ins.2025.122670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are practical tools that represent and integrate plentiful structural and semantic information in mainstream industrial scenarios. Despite their potential, the heterogeneity and complexity of KGs pose a formidable obstacle, especially for graph representation learning. Most existing KG embedding models omit dynamic high-order connectivity patterns to gain insights into heterogeneous networks and heavily rely on handcrafted patterns to handle complex semantic relationships, which limits their capability to adaptively capture the nuanced and intricate relationships of KGs in different tasks. To fill this gap, we present Reinforced Heterogeneous Graphlet Design (ReHGD)—a model designed for KGs that focuses on the adaptive design of typed graphlets (heterogeneous chains and motifs) through a cooperative multi-agent reinforcement learning algorithm. This task-driven approach can learn discriminative graph representations tailored to specific downstream tasks. Specifically, ReHGD engages in the creation of typed graphlets through a two-stage process: it (1) establishes a reinforced chain design module to generate chains without predefined rules and (2) employs a buffer-aware sampling technique to derive episodic chains from prior experiences. Subsequently, motifs are deduced through the application of commute count and Hadamard product operations to the episodic chain-based subgraphs. In the final step toward learning graph representations, ReHGD undertakes chain and motif aggregations. Experimental results and analyses reveal that ReHGD outperforms strong baselines on three real-world graph data and practical tasks.},
  archive      = {J_ISCI},
  author       = {Jibing Gong and Yuting Lin and Yi Zhao and Tianyu Lin and Xiaohan Fang and Xinchao Feng and Jiquan Peng},
  doi          = {10.1016/j.ins.2025.122670},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122670},
  shortjournal = {Inf. Sci.},
  title        = {Reinforced heterogeneous graphlet design for knowledge graph representation learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis. <em>ISCI</em>, <em>723</em>, 122669. (<a href='https://doi.org/10.1016/j.ins.2025.122669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture analysis is crucial for understanding images by extracting features that define spatial patterns. Recently, bi-dimensional extensions of entropy measures have gained attention due to their simplicity and strong theoretical foundations. However, existing methods primarily operate in the spatial domain and thus overlook frequency-domain and multiscale information. To address this, we introduce bidimensional wavelet increment entropy (wavelet IncrEn 2 D ). A one-level discrete wavelet transform (DWT) with the Haar wavelet decomposes each image into approximation (low-frequency) and, for some neuroimaging data, detail (high-frequency) subbands; IncrEn 2 D is then applied both to capture global structural patterns and fine, detailed texture variations. We evaluated wavelet IncrEn 2 D on synthetic and real datasets, demonstrating its effectiveness in distinguishing between different noise types (white Gaussian, salt-and-pepper, and speckle noise). Comparisons between periodic and synthesized images revealed lower wavelet IncrEn 2 D values for periodic textures. Tests on real texture datasets highlight the method's ability to differentiate various patterns. In particular, wavelet IncrEn 2 D achieved 86.69% accuracy in distinguishing MRI images of healthy versus multiple sclerosis–affected brains. Overall, wavelet IncrEn 2 D offers a robust, frequency-aware descriptor that outperforms existing 2D entropy methods.},
  archive      = {J_ISCI},
  author       = {Muqaddas Abid and Muhammad Suzuri Hitam and Rozniza Ali and Hamed Azami and Anne Humeau-Heurtier},
  doi          = {10.1016/j.ins.2025.122669},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122669},
  shortjournal = {Inf. Sci.},
  title        = {Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved query specialization for transformer-based visual relationship detection. <em>ISCI</em>, <em>723</em>, 122668. (<a href='https://doi.org/10.1016/j.ins.2025.122668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Relationship Detection (VRD) has significantly advanced with Transformer-based architectures. However, we identify two fundamental drawbacks in conventional label assignment methods used for training Transformer-based VRD models, where ground-truth (GT) annotations are matched to model predictions. In conventional assignment, queries are trained to detect all relations rather than specializing in specific ones, resulting in ‘unspecialized’ queries. Also, each ground-truth (GT) annotation is assigned to only one prediction under conventional assignment, suppressing other near-correct predictions by labeling them as ‘no relation’. To address these issues, we introduce a novel method called Groupwise Query Spe ci a lization and Q uality-Aware Multi-Assignment (SpeaQ). Groupwise Query Specialization clusters queries and relations into exclusive groups, promoting specialization by assigning a set of relations only to a corresponding query group. Quality-Aware Multi-Assignment enhances training signals by allowing multiple predictions closely matching the GT to be positively assigned. Additionally, we introduce dynamic query reallocation, which transfers queries from high- to low-performing groups for balanced training. Experimental results demonstrate that SpeaQ+, combining SpeaQ with dynamic query reallocation, consistently improves performance across seven baseline models on five benchmarks without additional inference cost.},
  archive      = {J_ISCI},
  author       = {Jongha Kim and Jihwan Park and Jinyoung Park and Jinyoung Kim and Sehyung Kim and Hyunwoo J. Kim},
  doi          = {10.1016/j.ins.2025.122668},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122668},
  shortjournal = {Inf. Sci.},
  title        = {Improved query specialization for transformer-based visual relationship detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling. <em>ISCI</em>, <em>723</em>, 122656. (<a href='https://doi.org/10.1016/j.ins.2025.122656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modeling of spatio-temporal dynamic systems, tasks such as fluid dynamics, weather forecasting, and traffic flow prediction face highly complex spatio-temporal dependencies and nonlinear dynamics. These characteristics make it challenging for traditional physical models and data-driven methods to balance accuracy and computational efficiency. To address these challenges, we propose a multi-scale spatio-temporal convolutional network named ConvDiff, optimized specifically for dynamic system modeling tasks by integrating a latent space denoising diffusion model. ConvDiff effectively captures complex spatio-temporal features and handles uncertainties in physical systems by introducing multi-scale convolutional modules combined with a physics-guided diffusion mechanism. Specifically, our model incorporates eight temporal modules and four spatial modules, using a hierarchical convolutional and diffusion structure to capture the intricate dynamics of physical systems. The experiments involved different spatio-temporal data, such as those from TaxiBJ and the Navier-Stokes dataset. According to the findings, ConvDiff demonstrates substantial improvements in essential performance indicators. For example, in the TaxiBJ dataset, ConvDiff obtained a mean squared deviation of 0.29 and a PSNR value of 40.31, outperforming the best-performing models. Moreover, on the Navier-Stokes dataset, ConvDiff reduced the MSE by 51.15% compared to the best baseline model. These results indicate that ConvDiff effectively captures complex spatio-temporal dependencies and improves prediction accuracy, particularly in physics-driven dynamic systems. Our code is available at https://github.com/Ray-zyy/ConvDiff .},
  archive      = {J_ISCI},
  author       = {Yuyang Zhao and Yuhan Wu and Yongmei Wang},
  doi          = {10.1016/j.ins.2025.122656},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122656},
  shortjournal = {Inf. Sci.},
  title        = {ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis. <em>ISCI</em>, <em>723</em>, 122655. (<a href='https://doi.org/10.1016/j.ins.2025.122655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing influence of investor sentiment on market dynamics, sentiment analysis has emerged as an effective tool for enhancing financial forecasting models. This study proposes a diversity-enhanced semi-heterogeneous ensemble forecasting framework that integrates sentiment analysis into the forecasting of stock index returns. A supervised stock market sentiment index set is constructed, in which prior knowledge regarding term importance is integrated into the data augmentation process. This enables higher weights to be assigned to sentiment-related terms with superior predictive capacity, thereby allowing the model to prioritize more informative features and enhance its forecasting performance. A series of diverse base models are generated through the integration of multiple attention-PCA techniques and forecasting algorithms based on variable perturbation strategies. These base models are subsequently combined through a suite of ensemble strategies, forming a semi-heterogeneous ensemble model for forecasting S&P 500 returns. The experiment results demonstrate that the proposed approaches significantly outperform benchmark methods, with notable improvements in both accuracy and diversity.},
  archive      = {J_ISCI},
  author       = {Xiao Zhang and Peide Liu and Jing Feng},
  doi          = {10.1016/j.ins.2025.122655},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122655},
  shortjournal = {Inf. Sci.},
  title        = {A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-related controllability of corona product networks. <em>ISCI</em>, <em>723</em>, 122654. (<a href='https://doi.org/10.1016/j.ins.2025.122654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the energy-related controllability for a category of ‘large’ composite networks generated by ‘small’ simple factor networks with Laplacian dynamics under a leader-follower framework via corona product. Different from most existing literature on network controllability, this work characterizes the controllability of corona product networks (CPNs) from an energy point of view. This can quantify the difficulty of controlling CPNs based on controllability Gramian measures, involving average controllability and volumetric control energy, etc., where the energy is triggered by the leaders. The energy-related controllability of a CPN can be explored from the eigenvalues and eigenvectors of its factor networks. An algorithm for solving the maximum average controllability is provided, which can help one select the leaders to optimize network control and be applied in practice.},
  archive      = {J_ISCI},
  author       = {Qiang Zhang and Junjie Huang and Bo Liu and Housheng Su and Alatancang Chen},
  doi          = {10.1016/j.ins.2025.122654},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122654},
  shortjournal = {Inf. Sci.},
  title        = {Energy-related controllability of corona product networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SeqRFM: Fast RFM analysis in sequence data. <em>ISCI</em>, <em>723</em>, 122652. (<a href='https://doi.org/10.1016/j.ins.2025.122652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data mining technologies have been well applied to many domains, including e-commerce. In customer relationship management (CRM), the Recency-Frequency-Monetary (RFM) analysis model is one of the most effective approaches to increase the profits of major enterprises. However, with the rapid development of e-commerce, the diversity and abundance of e-commerce data pose a challenge to mining efficiency. Moreover, in actual market transactions, the chronological order of transactions reflects customer behavior and preferences. To address these challenges, we develop an effective algorithm called SeqRFM, which combines sequential pattern mining with RFM models. SeqRFM considers each customer's R, F, and M scores to represent the significance of the customer and identifies sequences with high recency, high frequency, and high monetary value. A series of experiments demonstrates the superiority and effectiveness of the SeqRFM algorithm compared to the most advanced RFM algorithms based on sequential pattern mining. Moreover, another algorithm named MSeqRFM is developed to compress the result of SeqRFM. The experiments demonstrate the effectiveness of MSeqRFM in compressing sequences. The source code and datasets are available at GitHub https://github.com/DSI-Lab1/SeqRFM .},
  archive      = {J_ISCI},
  author       = {Yanxin Zheng and Wensheng Gan and Zefeng Chen and Pinlyu Zhou and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2025.122652},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122652},
  shortjournal = {Inf. Sci.},
  title        = {SeqRFM: Fast RFM analysis in sequence data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems. <em>ISCI</em>, <em>723</em>, 122651. (<a href='https://doi.org/10.1016/j.ins.2025.122651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a finite-time dynamic event-triggered actor-critic-identifier (FT-DET-ACI) framework for the optimal control problem of nonlinear systems with uncertain drift dynamics. A theoretical foundation is established by reformulating the value function within a finite-time stable space, which facilitates system state stabilization within predetermined temporal constraints. The proposed approach derives finite-time optimal controllers through a transformed Hamilton-Jacobi-Bellman (HJB) equation. To address unknown system dynamics, an integrated actor-critic-identifier architecture is constructed to concurrently approximate the value function, synthesize the finite-time optimal controller, and identify system parameters. A dynamic event-triggering rule is designed to reduce computational and communication loads by selectively updating the control signal. Lyapunov stability analysis is provided to demonstrate the finite-time convergence properties of the closed-loop system. Numerical experiments are conducted to validate the efficacy of the proposed FT-DET-ACI methodology.},
  archive      = {J_ISCI},
  author       = {Shuangsi Xue and Junkai Tan and Zihang Guo and Qingshu Guan and Hui Cao and Badong Chen},
  doi          = {10.1016/j.ins.2025.122651},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122651},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Set membership filter with nonlinear state inequality constraints. <em>ISCI</em>, <em>723</em>, 122650. (<a href='https://doi.org/10.1016/j.ins.2025.122650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set membership filter is a promising method to provide a bounding estimation containing the true state for dynamic systems with unknown but bounded noises. In this paper, we investigate the state bounding estimation problem of nonlinear dynamic systems with nonlinear state inequality constraints. Three types of ellipsoidal state bounding estimation methods are proposed by incorporating nonlinear state inequality constraints into nonlinear set membership filter. They are called model reduction method, system measurement method, and constraint dimension reduction method, respectively. We analyze the computation complexity of the three methods, which decrease in the order of model reduction method, system measurement method, and constraint dimension reduction method. Due to the nonlinearity of the dynamic systems, all the three methods are approximation algorithms and the state estimation accuracy cannot be analyzed explicitly. Consequently, a typical illustrative numerical experiment is conducted to compare the performance of the three methods. The results show that the accuracy increases in the order of the model reduction method, the constraint dimension reduction method, and the system measurement method.},
  archive      = {J_ISCI},
  author       = {Xiaowei Li and Xuqi Zhang and Zhiguo Wang and Xiaojing Shen},
  doi          = {10.1016/j.ins.2025.122650},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122650},
  shortjournal = {Inf. Sci.},
  title        = {Set membership filter with nonlinear state inequality constraints},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration. <em>ISCI</em>, <em>723</em>, 122649. (<a href='https://doi.org/10.1016/j.ins.2025.122649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-to-grid (V2G) technology leverages the distributed energy-storage potential of electric vehicles (EVs), transforming the challenges of large-scale EV integration into opportunities to enhance grid flexibility and reliability. This study investigates the optimization of EV charging-discharging schedules by exploiting V2G capabilities. First, considering the spatiotemporal distribution of EVs, a Markov chain is constructed to describe probabilistic transitions between spatiotemporal states, which is then embedded in a traffic-network-based path decision model. Second, a dynamic battery energy consumption model is established, incorporating multiple factors that influence battery performance. Using Monte Carlo simulation results, a bi-objective optimization model is formulated to schedule charging and discharging, simultaneously minimizing (i) total cost — including user recharging time and battery degradation — and (ii) grid-load fluctuation. Given the NP-hard nature of the problem, an improved multi-objective bitterling fish optimization (IMOBFO) algorithm is developed to balance global exploration and local exploitation. Empirical studies in a region of Shanghai compare three strategies: disordered charging, ordered charging, and the proposed optimized charging–discharging strategy. Experimental results confirm the feasibility of the proposed model and the effectiveness of IMOBFO. Comparative analysis with seven other algorithms further validates the superior performance and stability of IMOBFO according to multiple multi-objective evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Bing Yu and Yong Liu and Liang Ma},
  doi          = {10.1016/j.ins.2025.122649},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122649},
  shortjournal = {Inf. Sci.},
  title        = {Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified graph-based framework for visual explainability in convolutional neural networks. <em>ISCI</em>, <em>723</em>, 122648. (<a href='https://doi.org/10.1016/j.ins.2025.122648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, understanding the decision-making processes of complex models is essential for advancing interpretability and trust in artificial intelligence systems. We introduce Causal Relational Attribution Graph (C-RAG), designed to deliver comprehensive, multi-perspective explanations of convolutional neural networks (CNNs) via a graph representation. C-RAG integrates gradient-based local attribution with global feature importance by constructing a graph-based representation that captures hierarchical feature inter-dependencies. In this framework, feature clusters are represented as graph nodes, and their interactions are quantified through combined localized and global attribution metrics, ensuring interpretable insights into model behavior. We evaluate C-RAG across diverse benchmark datasets (ImageNet, CIFAR-10, MNIST) and CNN architectures (ResNet18, VGG19, DenseNet201, LeNet), demonstrating significant advancements over state-of-the-art explainability methods in faithfulness, robustness, and computational efficiency. The proposed approach facilitates accurate spatial feature localization, robust dependency mapping, and efficient explanation generation, making it a valuable tool for critical applications such as medical imaging and autonomous systems. We provide a novel graph-based explainability framework, which bridges the gap between local and global interpretability, C-RAG addresses key limitations in existing methods, establishing a robust foundation for explainable AI in computer vision.},
  archive      = {J_ISCI},
  author       = {Basim Azam and Pubudu Sanjeewani and Brijesh Verma and Ashfaqur Rahman and Lipo Wang},
  doi          = {10.1016/j.ins.2025.122648},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122648},
  shortjournal = {Inf. Sci.},
  title        = {Unified graph-based framework for visual explainability in convolutional neural networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting. <em>ISCI</em>, <em>723</em>, 122647. (<a href='https://doi.org/10.1016/j.ins.2025.122647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) has been a significant research focus across various domains. Recent studies have utilized deep neural networks to identify pattern relationships in MTSF. Despite these developments, accurately forecasting multivariate time series remains challenging due to the trend of time series and spatial-temporal heterogeneity. In this paper, we propose a unified multivariate time series forecasting framework for long-term, short-term, and spatial-temporal forecasting with attention-based spatial-temporal interactive coupled neural networks (ASTIC). Specifically, we proposed a spatial-temporal interactive couple block that contains both temporal and spatial branches to investigate the relationships between global and local patterns in temporal and spatial perspectives. In the temporal branch, we design a hybrid network module capable of enhancing representation learning using convolution and attention mechanisms, which dynamically capture the local trendiness and long-term time dependence implicit in time series. In the spatial branch, a novel dynamic graph learners are designed to learn global and local spatial patterns. Then a novel interactive coupling method is proposed to link the two branches together. ASTIC predicts time series effectively by using a multilevel structure to model the trendiness of the series and mining the spatial-temporal heterogeneity. Experimental results show that our method outperforms state-of-the-art baseline methods on nine real-world datasets.},
  archive      = {J_ISCI},
  author       = {Bingsheng Wei and Yonghua Hei and Yuan Wan},
  doi          = {10.1016/j.ins.2025.122647},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122647},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New solutions based on the generalized eigenvalue problem for the data collaboration analysis. <em>ISCI</em>, <em>723</em>, 122642. (<a href='https://doi.org/10.1016/j.ins.2025.122642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the data collaboration (DC) analysis, a privacy-preserving method for analyzing decentralized datasets held by multiple parties. In this method, privacy-preserving intermediate representations of original datasets are collected from multiple parties and then converted into collaboration representations for collaborative data analysis. However, conventional methods for creating collaboration representations suffer from several challenges; namely, the optimization problem being considered is not well defined, and the process of solving it is very difficult to understand. We thus propose a new solution for creating high-quality collaboration representations for the DC analysis. Specifically, we formulate a revised optimization problem for creating collaboration representations and then transform this optimization problem into a generalized eigenvalue problem. We also propose a reduction of the generalized eigenvalue problem to a singular value decomposition through the QR decomposition. Computational experiments using publicly available datasets demonstrate that our method can outperform the conventional methods for the DC analysis in terms of both prediction accuracy and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Yuta Kawakami and Yuichi Takano and Akira Imakura},
  doi          = {10.1016/j.ins.2025.122642},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122642},
  shortjournal = {Inf. Sci.},
  title        = {New solutions based on the generalized eigenvalue problem for the data collaboration analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data. <em>ISCI</em>, <em>723</em>, 122641. (<a href='https://doi.org/10.1016/j.ins.2025.122641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear causal discovery from observational data imposes strict identifiability assumptions on the formulation of structural equations utilized in the data-generating process. However, in real-life settings, the ground-truth mechanism responsible for cause-effect transformations is unknown. Thus, it is impossible to verify its identifiability. This is the first research to assess the performance of structure learning algorithms from seven different families in non-identifiable settings with an increasing degree of nonlinearity. The evaluation of structure learning methods under assumption violations requires a rigorous and interpretable approach that quantifies both the structural similarity of the estimation with the ground truth and the capacity of the discovered graphs to be used for causal inference. Motivated by the lack of a unified performance assessment indicator, we propose an interpretable, multidimensional evaluation framework, specifically tailored to the field of causal discovery from i.i.d. data. In particular, we introduce a six-dimensional evaluation metric, called distance to the optimal solution, which aims at providing a holistic overview of the performance of structure learning techniques. Our large-scale simulation study, which incorporates seven experimental factors, shows that hybrid Bayesian networks outperform most recently introduced continuous optimization techniques under certain conditions. Additionally, causal order-based methods yield results with comparatively high proximity to the optimal solution.},
  archive      = {J_ISCI},
  author       = {Georg Velev and Stefan Lessmann},
  doi          = {10.1016/j.ins.2025.122641},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122641},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jaim">JAIM - 6</h2>
<ul>
<li><details>
<summary>
(2025). A non-archimedean theory of complex spaces and the cscK problem. <em>JAIM</em>, <em>481</em>, 110543. (<a href='https://doi.org/10.1016/j.aim.2025.110543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we develop an analogue of the Berkovich analytification for non-necessarily algebraic complex spaces. We apply this theory to generalize to arbitrary compact Kähler manifolds a result of Chi Li, [42] , proving that a stronger version of K-stability implies the existence of a unique constant scalar curvature Kähler metric.},
  archive      = {J_JAIM},
  author       = {Pietro Mesquita-Piccione},
  doi          = {10.1016/j.aim.2025.110543},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110543},
  shortjournal = {Adv. Math.},
  title        = {A non-archimedean theory of complex spaces and the cscK problem},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An almost kurepa suslin tree with strongly non-saturated square. <em>JAIM</em>, <em>481</em>, 110540. (<a href='https://doi.org/10.1016/j.aim.2025.110540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For uncountable downwards closed subtrees U and W of an ω 1 -tree T , we say that U and W are strongly almost disjoint if their intersection is a finite union of countable chains. The tree T is strongly non-saturated if there exists a strongly almost disjoint family of ω 2 -many uncountable downwards closed subtrees of T . In this article we construct a Knaster forcing which adds a Suslin tree together with a family of ω 2 -many strongly almost disjoint automorphisms of it (and thus the square of the Suslin tree is strongly non-saturated). To achieve this goal, we introduce a new idea called ρ-separation , which is an adaptation to the finite context of the notion of separation which was recently introduced by Stejskalová and the first author for the purpose of adding automorphisms of a tree with a forcing with countable conditions.},
  archive      = {J_JAIM},
  author       = {John Krueger and Eduardo Martinez Mendoza},
  doi          = {10.1016/j.aim.2025.110540},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110540},
  shortjournal = {Adv. Math.},
  title        = {An almost kurepa suslin tree with strongly non-saturated square},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sharp localized weighted inequality related to gagliardo and sobolev seminorms and its applications. <em>JAIM</em>, <em>481</em>, 110537. (<a href='https://doi.org/10.1016/j.aim.2025.110537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we establish a nearly sharp localized weighted inequality related to Gagliardo and Sobolev seminorms, respectively, with the sharp A 1 -weight constant or with the specific A p -weight constant when p ∈ ( 1 , ∞ ) . As applications, we further obtain a new characterization of Muckenhoupt weights and, in the framework of ball Banach function spaces, an inequality related to Gagliardo and Sobolev seminorms on cubes, a Gagliardo–Nirenberg interpolation inequality, and a Bourgain–Brezis–Mironescu formula. All these obtained results have wide generality and are proved to be (nearly) sharp.},
  archive      = {J_JAIM},
  author       = {Pingxu Hu and Yinqin Li and Dachun Yang and Wen Yuan},
  doi          = {10.1016/j.aim.2025.110537},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110537},
  shortjournal = {Adv. Math.},
  title        = {A sharp localized weighted inequality related to gagliardo and sobolev seminorms and its applications},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-moduli spaces of log del pezzo pairs. <em>JAIM</em>, <em>481</em>, 110536. (<a href='https://doi.org/10.1016/j.aim.2025.110536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish the full explicit wall-crossings for K-moduli space P ‾ K ( c ) of degree 8 del Pezzo pairs ( X , c C ) , where generically X ≅ F 1 and C ∼ − 2 K X . We also show that the K-moduli spaces P ‾ K ( c ) coincide with the Hassett-Keel-Looijenga (HKL) models F ( s ) of an 18-dimensional locally symmetric space associated with the lattice E 8 ⊕ U 2 ⊕ E 7 ⊕ A 1 under the transformation s ( c ) = 1 − 2 c 56 c − 4 . This implies that the K-moduli spaces interpolate the GIT partial compactification and the Baily-Borel compactification for the moduli space of smooth Del Pezzo pairs. Some discussions concerning the relationship to KSBA moduli spaces are also provided.},
  archive      = {J_JAIM},
  author       = {Long Pan and Fei Si and Haoyu Wu},
  doi          = {10.1016/j.aim.2025.110536},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110536},
  shortjournal = {Adv. Math.},
  title        = {K-moduli spaces of log del pezzo pairs},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrality of mirror maps and arithmetic homological mirror symmetry for Greene–Plesser mirrors. <em>JAIM</em>, <em>481</em>, 110535. (<a href='https://doi.org/10.1016/j.aim.2025.110535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the ‘integrality of Taylor coefficients of mirror maps’ conjecture for Greene–Plesser mirror pairs as a natural byproduct of an arithmetic refinement of homological mirror symmetry. We also prove homological mirror symmetry for Greene–Plesser mirror pairs in all characteristics such that the B-side family has good reduction, generalizing work of the fifth author and Smith over the complex numbers. A key technical ingredient is a new versality argument which allows us to work throughout over a Novikov-type ring with integer coefficients.},
  archive      = {J_JAIM},
  author       = {Sheel Ganatra and Andrew Hanlon and Jeff Hicks and Daniel Pomerleano and Nick Sheridan},
  doi          = {10.1016/j.aim.2025.110535},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110535},
  shortjournal = {Adv. Math.},
  title        = {Integrality of mirror maps and arithmetic homological mirror symmetry for Greene–Plesser mirrors},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intermediate subalgebras of cartan embeddings in rings and c*-algebras. <em>JAIM</em>, <em>481</em>, 110534. (<a href='https://doi.org/10.1016/j.aim.2025.110534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let D ⊆ A be a quasi-Cartan pair of algebras. Then there exists a unique discrete groupoid twist Σ → G whose twisted Steinberg algebra is isomorphic to A in a way that preserves D . In this paper, we show there is a lattice isomorphism between wide open subgroupoids of G and subalgebras C such that D ⊆ C ⊆ A and D ⊆ C is a quasi-Cartan pair. We also characterize which algebraic diagonal/algebraic Cartan/quasi-Cartan pairs have the property that every subalgebra C with D ⊆ C ⊆ A has D ⊆ C a diagonal/Cartan/quasi-Cartan pair. In the diagonal case, when the coefficient ring is a field, it is all of them. Beyond that, only pairs that are close to being diagonal have this property. We then apply our techniques to C*-algebraic inclusions and give a complete characterization of which Cartan pairs D ⊆ A have the property that every C*-subalgebra C with D ⊆ C ⊆ A has D ⊆ C a Cartan pair.},
  archive      = {J_JAIM},
  author       = {Jonathan H. Brown and Lisa Orloff Clark and Adam H. Fuller},
  doi          = {10.1016/j.aim.2025.110534},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110534},
  shortjournal = {Adv. Math.},
  title        = {Intermediate subalgebras of cartan embeddings in rings and c*-algebras},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jat">JAT - 2</h2>
<ul>
<li><details>
<summary>
(2026). Asymptotics of the humbert functions Ψ1 and Ψ2. <em>JAT</em>, <em>314</em>, 106233. (<a href='https://doi.org/10.1016/j.jat.2025.106233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A compilation of new results on the asymptotic behaviour of the Humbert functions Ψ 1 and Ψ 2 , and also on the Appell function F 2 , is presented. As a by-product, we confirm a conjectured limit which appeared recently in the study of the 1 D Glauber–Ising model. We also propose two elementary asymptotic methods and confirm through some illustrative examples that both methods have great potential and can be applied to a large class of problems of asymptotic analysis. Finally, some directions of future research are pointed out in order to suggest ideas for further study.},
  archive      = {J_JAT},
  author       = {Peng-Cheng Hang and Malte Henkel and Min-Jie Luo},
  doi          = {10.1016/j.jat.2025.106233},
  journal      = {Journal of Approximation Theory},
  month        = {3},
  pages        = {106233},
  shortjournal = {J. Approx. Theory},
  title        = {Asymptotics of the humbert functions Ψ1 and Ψ2},
  volume       = {314},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nevai’s condition for measures with unbounded supports. <em>JAT</em>, <em>314</em>, 106232. (<a href='https://doi.org/10.1016/j.jat.2025.106232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study Nevai’s condition from the theory of orthogonal polynomials on the real line. We prove that a large class of measures with unbounded Jacobi parameters satisfies Nevai’s condition locally uniformly on the support of the measure away from a finite explicit set. This allows us to give applications to relative uniform and weak asymptotics of Christoffel–Darboux kernels on the diagonal and to limit theorems for unconventionally normalized global linear statistics of orthogonal polynomial ensembles.},
  archive      = {J_JAT},
  author       = {Grzegorz Świderski},
  doi          = {10.1016/j.jat.2025.106232},
  journal      = {Journal of Approximation Theory},
  month        = {3},
  pages        = {106232},
  shortjournal = {J. Approx. Theory},
  title        = {Nevai’s condition for measures with unbounded supports},
  volume       = {314},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jde">JDE - 6</h2>
<ul>
<li><details>
<summary>
(2026). Fine boundary regularity for fully nonlinear mixed local-nonlocal problems. <em>JDE</em>, <em>452</em>, 113780. (<a href='https://doi.org/10.1016/j.jde.2025.113780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Dirichlet problems for fully nonlinear mixed local-nonlocal non-translation invariant operators. For a bounded C 2 domain Ω ⊂ R d , let u ∈ C ( R d ) be a viscosity solution of such Dirichlet problem. We obtain global Lipschitz regularity and fine boundary regularity for u by constructing appropriate sub and supersolutions coupled with a Harnack type inequality. We apply these results to obtain Hölder regularity of Du up to the boundary.},
  archive      = {J_JDE},
  author       = {Mitesh Modasiya and Abhrojyoti Sen},
  doi          = {10.1016/j.jde.2025.113780},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113780},
  shortjournal = {J. Diff. Equ.},
  title        = {Fine boundary regularity for fully nonlinear mixed local-nonlocal problems},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weak and mild solutions to the MHD equations and the viscoelastic Navier–Stokes equations with damping in wiener amalgam spaces. <em>JDE</em>, <em>452</em>, 113777. (<a href='https://doi.org/10.1016/j.jde.2025.113777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the three-dimensional incompressible magnetohydrodynamic (MHD) equations and the incompressible viscoelastic Navier–Stokes equations with damping. Building on techniques developed by Bradshaw, et al. (2024) [1] , we prove the existence of mild solutions in Wiener amalgam spaces that satisfy the corresponding spacetime integral bounds. In addition, we construct global-in-time local energy weak solutions in these amalgam spaces using the framework introduced by Bradshaw and Tsai (2021) [4] . As part of this construction, we also establish several properties of local energy solutions with L uloc 2 initial data, including initial and eventual regularity as well as small-large uniqueness, extending analogous results obtained for the Navier–Stokes equations by Bradshaw and Tsai (2020) [3] .},
  archive      = {J_JDE},
  author       = {Chen-Chih Lai},
  doi          = {10.1016/j.jde.2025.113777},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113777},
  shortjournal = {J. Diff. Equ.},
  title        = {Weak and mild solutions to the MHD equations and the viscoelastic Navier–Stokes equations with damping in wiener amalgam spaces},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Positive periodic solutions to the planar lp dual minkowski problem in the critical case. <em>JDE</em>, <em>452</em>, 113776. (<a href='https://doi.org/10.1016/j.jde.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the planar L p dual Minkowski problem x ″ + x = x p − 1 ( x 2 + x ′ 2 ) 2 − q 2 f ( t ) , where p and q are two constants, f ∈ L 1 ( R / T Z ; R + ) , and T > 0 . Notice that in the critical case T = π , the L p dual Minkowski problem is closely related to the half-period symmetry problem in convex geometry. By using Krasnosel'skii-Guo fixed point theorem and Schauder's fixed point theorem, we derive sufficient conditions for the existence of positive π -periodic solutions to this equation. In addition, we employ numerical bifurcation analysis to explore the dynamical behavior of positive π -periodic solutions.},
  archive      = {J_JDE},
  author       = {Zhibo Cheng and Shujing Yuan and Qigang Yuan and Jingli Ren},
  doi          = {10.1016/j.jde.2025.113776},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113776},
  shortjournal = {J. Diff. Equ.},
  title        = {Positive periodic solutions to the planar lp dual minkowski problem in the critical case},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discrete lyapunov functional for cyclic systems of differential equations with time-variable or state-dependent delay. <em>JDE</em>, <em>452</em>, 113768. (<a href='https://doi.org/10.1016/j.jde.2025.113768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider nonautonomous cyclic systems of delay differential equations with variable delay. Under suitable feedback assumptions, we define an integer-valued Lyapunov functional related to the number of sign changes of the coordinate functions of solutions. We prove that this functional possesses properties analogous to those established by Mallet-Paret and Sell for the constant delay case and by Krisztin and Arino for the scalar case. We also apply the results to equations with state-dependent delays.},
  archive      = {J_JDE},
  author       = {István Balázs and Ábel Garab},
  doi          = {10.1016/j.jde.2025.113768},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113768},
  shortjournal = {J. Diff. Equ.},
  title        = {Discrete lyapunov functional for cyclic systems of differential equations with time-variable or state-dependent delay},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Thermo-elasticity problems with evolving microstructures. <em>JDE</em>, <em>452</em>, 113764. (<a href='https://doi.org/10.1016/j.jde.2025.113764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the mathematical analysis and homogenization of a moving boundary problem posed for a highly heterogeneous, periodically perforated domain. More specifically, we are looking at a one-phase thermo-elasticity system with phase transformations where small inclusions, initially periodically distributed, are growing or shrinking based on a kinetic under-cooling-type law and where surface stresses are created based on the curvature of the phase interface. This growth is assumed to be uniform in each individual cell of the perforated domain. After transforming to the initial reference configuration (utilizing the Hanzawa transformation), we use the contraction mapping principle to show the existence of a unique solution for a possibly small but ε independent time interval ( ε is here the scale of heterogeneity). In the homogenization limit, we recover a macroscopic thermo-elasticity problem which is strongly non-linearly coupled (via an internal parameter called height function) to local changes in geometry. As a direct by-product of the mathematical analysis work, we present an alternative equivalent formulation which lends itself to an effective pre-computing strategy that is very much needed as the limit problem is computationally expensive.},
  archive      = {J_JDE},
  author       = {Michael Eden and Adrian Muntean},
  doi          = {10.1016/j.jde.2025.113764},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113764},
  shortjournal = {J. Diff. Equ.},
  title        = {Thermo-elasticity problems with evolving microstructures},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Travelling wave solutions to a microtube-driven glioma invasion model. <em>JDE</em>, <em>452</em>, 113759. (<a href='https://doi.org/10.1016/j.jde.2025.113759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we establish the existence of travelling wave solutions for a non-cooperative reaction-diffusion model representing glioma cell invasion. The model describes the microtube-driven migration of glioma consisting of an ODE equation describing the dynamics of the tumour bulk and a reaction-diffusion equation for the tumour microtubes. We derive an explicit formula for the minimum wave speed c ¯ based on system parameters such that travelling waves exist for speeds c ≥ c ¯ while no travelling wave solution exists for c < c ¯ . We prove the existence of travelling wave solutions by constructing upper and lower solutions and employing Schauder's fixed point theorem. We obtain non-existence for small speeds by use of the negative one-sided Laplace transform. Our result is one of the few complete results on travelling waves of a non-cooperative partially degenerate reaction-diffusion systems. The findings have implications for understanding glioma spread dynamics and potential modelling applications in predicting tumour progression based on cellular migration speeds.},
  archive      = {J_JDE},
  author       = {Ryan Thiessen and Thomas Hillen},
  doi          = {10.1016/j.jde.2025.113759},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113759},
  shortjournal = {J. Diff. Equ.},
  title        = {Travelling wave solutions to a microtube-driven glioma invasion model},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jmaa">JMAA - 6</h2>
<ul>
<li><details>
<summary>
(2026). An application of a discrete sobolev inequality to discretised kirchhoff equations. <em>JMAA</em>, <em>555</em>(2), 130066. (<a href='https://doi.org/10.1016/j.jmaa.2025.130066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a discrete Sobolev inequality, and we use this inequality to analyse the nonlocal discretised Kirchhoff equation − A ( ( a ⁎ ( g ∘ | Δ u | ) ) ( b + 1 ) ) ( Δ 2 u ) ( n ) = λ f ( n , u ( n + 1 ) ) , n ∈ { 0 , 1 , 2 , … , b } , where ⁎ represents a finite convolution. The equation is a discrete analogue of the classical steady-state Kirchhoff equation in one space dimension. Existence of at least one positive solution is investigated under the assumption that the equation is subject to two-point boundary data such that u ( 0 ) = 0 . Thus, both Dirichlet and right-focal data are captured by our results. An interesting aspect of our theory is that the coefficient function A may be both vanishing and sign-changing.},
  archive      = {J_JMAA},
  author       = {Christopher S. Goodrich},
  doi          = {10.1016/j.jmaa.2025.130066},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130066},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {An application of a discrete sobolev inequality to discretised kirchhoff equations},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traveling wave solutions for a density-suppressed motility model with strong allee effect. <em>JMAA</em>, <em>555</em>(2), 130063. (<a href='https://doi.org/10.1016/j.jmaa.2025.130063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a density-suppressed motility model with strong Allee effect. By leveraging existing results on asymptotic autonomous systems, along with Fredholm theory and the Banach fixed-point theorem, we establish the existence of bistable traveling wave solutions using a perturbation argument. This result holds when the density-suppressed sensitivity is relatively small. Finally, we validate our main results through numerical simulations and further discuss wave patterns and the sign of the wave speed as the density-suppressed sensitivity varies.},
  archive      = {J_JMAA},
  author       = {Cui Song and Zhi-Cheng Wang},
  doi          = {10.1016/j.jmaa.2025.130063},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130063},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Traveling wave solutions for a density-suppressed motility model with strong allee effect},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Numerical dynamics of infection-age models with logistic growth and general nonlinear incidence. <em>JMAA</em>, <em>555</em>(2), 130062. (<a href='https://doi.org/10.1016/j.jmaa.2025.130062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an age-structured viral dynamics model with Logistic growth and a general nonlinear incidence rate. We present the basic reproduction number of the continuous model and conduct a theoretical analysis of the model. For such a hybrid infinite-dimensional system with abstract nonlinear terms, the comprehensive numerical analysis is still pending. We address this problem by establishing a fully discrete linearly implicit scheme, and the non-negativity of the numerical scheme is confirmed by utilizing the theory of M -matrix. With a solvability analysis, the finite time convergence is proved for strong solutions. For long-time dynamics, by utilizing the exponential decay characteristic of the fundamental solution matrix, we established a 1-order convergence analysis for the numerical reproduction number R 0 Δ t , and further proved the 1-order convergence property of numerical equilibria. By applying linearization techniques and comparison principles, we demonstrate that the disease-free equilibrium is globally asymptotically stable when R 0 Δ t < 1 , and the endemic equilibrium is locally asymptotically stable when R 0 Δ t > 1 . Hence, numerical processes almost completely replicate the dynamic properties of continuous system. At last, some numerical experiments demonstrate the obtained results.},
  archive      = {J_JMAA},
  author       = {Zhuzan Wang and Zhanwen Yang and Huiqing Xie and Zhijie Chen},
  doi          = {10.1016/j.jmaa.2025.130062},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130062},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Numerical dynamics of infection-age models with logistic growth and general nonlinear incidence},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hopf bifurcation in a time-delayed multi-group SIR epidemic model for population behavior change. <em>JMAA</em>, <em>555</em>(2), 130061. (<a href='https://doi.org/10.1016/j.jmaa.2025.130061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we construct a time-delayed multi-group SIR epidemic model to discuss the impact of population behavior change on the occurrence of recurrent epidemic waves. We obtain the basic reproduction number R 0 and show that if R 0 ≤ 1 , then the disease-free equilibrium is globally asymptotically stable, whereas if R 0 > 1 , then the disease-free equilibrium is unstable and an endemic equilibrium exists. In a special two-group case, we show sufficient conditions for Hopf bifurcation and obtain index values that determine the direction, stability and period of bifurcated periodic solutions. By numerical simulation, we investigate the occurrence of periodic solutions in two groups representing an urban area and a non-urban area. We conclude that the epidemic size, response intensity of population behavior change and heterogeneity in two different groups can be the key factors of the occurrence of recurrent epidemic waves.},
  archive      = {J_JMAA},
  author       = {Toshikazu Kuniya},
  doi          = {10.1016/j.jmaa.2025.130061},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130061},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Hopf bifurcation in a time-delayed multi-group SIR epidemic model for population behavior change},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integral operators in the schatten class on dirichlet spaces. <em>JMAA</em>, <em>555</em>(2), 130060. (<a href='https://doi.org/10.1016/j.jmaa.2025.130060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We characterize three integral operators in Schatten p -classes on Dirichlet spaces D α in the unit disk D for α > 0 and 0 < p < ∞ . The main results are threefold: (1) If 0 < α < 1 < p < ∞ and g is a holomorphic function in D , then the Volterra operator T g , defined by T g f ( z ) = ∫ 0 z f ( ζ ) g ′ ( ζ ) d ζ , is in the Schatten p -class on D α if and only if ∫ D ( ( 1 − | w | 2 ) α ∫ D | g ′ ( z ) | 2 d A α ( z ) | 1 − w ¯ z | 2 + 2 α ) p 2 ( 1 − | w | 2 ) p − 2 d A ( w ) < ∞ . (2) If α > 0 and 0 < p < ∞ , μ is a finite Borel measure on D , then the Toeplitz operator Q μ α acting on D α is in the Schatten p -class if and only if ∫ D ( ( 1 − | w | 2 ) α + 2 t ∫ D d μ ( z ) | 1 − w ¯ z | 2 α + 2 t ) p ( 1 − | w | 2 ) − 2 d A ( w ) < ∞ , where t is any (or some) nonnegative number such that α + 2 t > max ⁡ { 1 , 1 p } . (3) If g is a holomorphic function in D , α > 0 and 0 < p ≤ 1 , then the small Hankel operator h g α acting from D α to the Sobolev space L α 2 is in the Schatten p -class if and only if g belongs to the Besov space B p . These results answer the corresponding open problems left by Pau-Peláez [12] (J. Anal. Math. 120 (2013), 255-289).},
  archive      = {J_JMAA},
  author       = {Xin-Qi Wen and Cheng Yuan},
  doi          = {10.1016/j.jmaa.2025.130060},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130060},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Integral operators in the schatten class on dirichlet spaces},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Kernels for composition of positive linear operators. <em>JMAA</em>, <em>555</em>(2), 130052. (<a href='https://doi.org/10.1016/j.jmaa.2025.130052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the composition of Bernstein–Durrmeyer operators and Szász–Mirakjan–Durrmeyer operators, focusing on the structure and properties of the associated kernel functions. In the case of the Bernstein–Durrmeyer operators, we establish new identities for the kernel arising from the composition of two and three operators. Like the well-known representation in terms of Legendre polynomials, they show the commutativity of these operators naturally. While this Legendre representation contains all possible products p k , i ( x ) p k , j ( y ) , 0 ≤ i , j ≤ k ≤ n , of Bernstein basis polynomials, the new representation has the beautiful property to contain only products p k , ℓ ( x ) p k , ℓ ( y ) , 0 ≤ ℓ ≤ k ≤ n , where n is the smallest degree of the Bernstein–Durrmeyer polynomials involved. This fact immediately implies that the composition can be written as a linear combination of the operators themselves. Building on the eigenstructure of the Bernstein–Durrmeyer operator M n , we obtain a representation of its r -th iterate as a linear combination of the operators M k , for k = 0 , 1 , … , n . We also address the composition of Szász–Mirakjan–Durrmeyer operators and revisit a known result giving an elementary proof.},
  archive      = {J_JMAA},
  author       = {Ulrich Abel and Ana Maria Acu and Margareta Heilmann and Ioan Raşa},
  doi          = {10.1016/j.jmaa.2025.130052},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130052},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Kernels for composition of positive linear operators},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jocs">JOCS - 16</h2>
<ul>
<li><details>
<summary>
(2025). Approach to global path planning and optimization for mobile robots based on multi-local gravitational potential fields bias-P-RRT*. <em>JOCS</em>, <em>92</em>, 102718. (<a href='https://doi.org/10.1016/j.jocs.2025.102718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sampling-based method has strong environmental adaptability and probability completeness, providing an effective solution for mobile robot path planning. However, the conventional rapidly-exploring random trees (RRT) algorithm often presents slow convergence and inefficient search paths. In this sense, this paper proposes a mobile robot path planning and optimization algorithm based on P-RRT* that incorporates multi-local gravitational potential fields and bias sampling, i.e., multi-local gravitational potential fields Bias-P-RRT* (MLGPFB-P-RRT*). The algorithm adds a local gravitational field between the starting point and the target point to better guide the direction of random tree growth, and directly connects the center of the last local gravitational field to the target point to accelerate the convergence of the random tree at the target point. Meanwhile, the introduction of bias sampling based on local potential fields to optimize the generation quality of random points, thereby improving the generation position of new nodes and reducing the randomness of sampling for mobile robots in the workspace. Then, a collision detection method between sampling nodes and obstacles was developed, which can quickly determine the feasibility of the sampling path. Finally, the generated path is optimized and smoothed through pruning optimization and quadratic B-spline function. A series of simulation studies and mobile robot experiments demonstrate the superior performance of the proposed algorithm.},
  archive      = {J_JOCS},
  author       = {Leiwen Yuan and Jingwen Luo},
  doi          = {10.1016/j.jocs.2025.102718},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102718},
  shortjournal = {J. Comput. Sci.},
  title        = {Approach to global path planning and optimization for mobile robots based on multi-local gravitational potential fields bias-P-RRT*},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid nutcracker optimization algorithm for multi-objective energy scheduling in grid-connected microgrid systems. <em>JOCS</em>, <em>92</em>, 102716. (<a href='https://doi.org/10.1016/j.jocs.2025.102716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for clean and sustainable energy has driven rapid advancements in hybrid microgrid systems to mitigate climate change and environmental degradation. This paper proposes a novel multi-objective scheduling framework for hybrid microgrids aimed at minimizing operational costs while maximizing environmental benefits. To efficiently solve this complex optimization problem, we introduce a Hybrid Nutcracker Optimization Algorithm (HNOA), which combines the recently developed Nutcracker Optimization Algorithm (NOA) with the Bat Algorithm (BAT). This hybridization enhances NOA’s exploration–exploitation balance and search capability, as demonstrated by rigorous validation on 12 benchmark functions. HNOA achieves superior accuracy and computational efficiency compared to several state-of-the-art metaheuristics. The proposed HNOA is then applied to solve the scheduling of a grid-connected hybrid microgrid under various scenarios to evaluate its performance. Simulation results indicate that the optimal microgrid configuration, consisting of PV/WT/turbine/diesel/battery, achieves an investment cost of 80,789.02 yuan. The findings of this study offer valuable insights for advancing renewable energy integration and promoting environmental sustainability.},
  archive      = {J_JOCS},
  author       = {Yiwei Liu and Yinggan Tang and Changchun Hua},
  doi          = {10.1016/j.jocs.2025.102716},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102716},
  shortjournal = {J. Comput. Sci.},
  title        = {Hybrid nutcracker optimization algorithm for multi-objective energy scheduling in grid-connected microgrid systems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Darcy-scale digital core models for rock properties upscaling and computational domain reduction. <em>JOCS</em>, <em>92</em>, 102715. (<a href='https://doi.org/10.1016/j.jocs.2025.102715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Digital Rock Physics (DRP) requires the elaboration of robust techniques for closing the gaps between different scales of rock studies (upscaling). The upscaling workflows are especially needed to support the applicability of DRP for heterogeneous rocks. Basically, DRP involves two primary stages: model construction and simulation of physical processes on the models created. For heterogeneous rocks, there is an inherent trade-off between the spatial resolution of the data and the representativeness of the model size. The primary objective of this study was to implement and test a technique for upscaling digital core models from microscale to macroscale, enabling the computation of rock properties while accounting for heterogeneity of various scales. The upscaling is based on establishing correlations between tomography data of different resolutions and transforming low-resolution tomography into a multi-class model according to the defined correlation. The convolutional neural network for high-resolution tomography data was considered as the optimal algorithm for transforming low-resolution tomography into a multi-class model. The output of the neural network was an upscaled model of lower resolution than the original tomography image. Each cell in the upscaled model belonged to one of several types of formation, whose generalized characteristics were determined on the basis of the analysis of high-resolution tomography data. To validate the upscaling technique, we constructed a digital model of a complex carbonate reservoir based on data from multi-scale microtomography ( μ CT). A Darcy-scale model has been used and validated as a multi-class model, enabling the computation of flows in pore samples of various scales. By incorporating diverse pore space structures as different classes in the Darcy-scale model, it is possible to preserve the substantial physical size of the model while enhancing its level of complexity.},
  archive      = {J_JOCS},
  author       = {Denis Orlov and Batyrkhan Gainitdinov and Dmitry Koroteev},
  doi          = {10.1016/j.jocs.2025.102715},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102715},
  shortjournal = {J. Comput. Sci.},
  title        = {Darcy-scale digital core models for rock properties upscaling and computational domain reduction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical study of two-dimensional sediment transport using momentum-conserving staggered grid scheme. <em>JOCS</em>, <em>92</em>, 102714. (<a href='https://doi.org/10.1016/j.jocs.2025.102714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sediment transport plays a crucial role in the evolution of bed morphology through deposition and erosion. This study presents numerical simulations of two-dimensional sediment transport induced by fluid flow. The fluid-sediment interaction is governed by a capacity model, i.e., the coupled system of shallow water and Exner equations, a simplification of more physically advanced non-capacity models. The system is solved using a momentum-conserving staggered grid (MCS) scheme. Model validation is performed using the Meyer-Peter and Müller (MPM) bedload transport formula, applied to experimental data from dam-break flows in various channel configurations. The proposed method successfully reproduces trends in the evolution of the water surface and quasi-steady sediment profiles. In general, the MCS scheme provides more accurate water level predictions than the numerical benchmark schemes. Although the predictions of maximum depths of deposition and erosion are less accurate, the overall results are consistent with those obtained from non-capacity models. Furthermore, the model is applied to the Kampar River estuary to simulate sediment transport due to the tidal bore.},
  archive      = {J_JOCS},
  author       = {Riski Kurniawan and Sri Redjeki Pudjaprasetya and Rani Sulvianuri},
  doi          = {10.1016/j.jocs.2025.102714},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102714},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical study of two-dimensional sediment transport using momentum-conserving staggered grid scheme},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cellular automaton towards structural balance—Long cycles of link dynamics. <em>JOCS</em>, <em>92</em>, 102712. (<a href='https://doi.org/10.1016/j.jocs.2025.102712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cellular automaton is defined on a line graph of a fully connected network. The automaton rule drives the system to a structural balance in most cases. Here, we investigate cycles with special symmetries, the so-called ’perfect cycles’ Burda et al. (2022). Two new characteristics of the cycles are investigated, as potential markers of perfect cycles: an equivalence of sets of states attained after external damage of links, and the homogeneity of the distribution of phase shifts between local trajectories. Only the second characteristic works as a criterion of the perfectness of the cycles. The results can be useful for generating pseudorandom numbers.},
  archive      = {J_JOCS},
  author       = {Malgorzata J. Krawczyk and Krzysztof Kułakowski},
  doi          = {10.1016/j.jocs.2025.102712},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102712},
  shortjournal = {J. Comput. Sci.},
  title        = {A cellular automaton towards structural balance—Long cycles of link dynamics},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hamiltonian circuit of virtual sample generation for a small dataset. <em>JOCS</em>, <em>92</em>, 102711. (<a href='https://doi.org/10.1016/j.jocs.2025.102711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small datasets often lead to poor performance of data-driven prediction models due to uneven data distribution and large data spacing. One popular approach to address this issue is to use virtual samples during machine learning (ML) model training. This study proposes a Hamiltonian Circuit Virtual Sample Generation (HCVSG) method to distribute virtual samples generated using interpolation techniques while integrating the K-Nearest Neighbors (KNN) algorithm in model development. The Hamiltonian circuit is chosen because it doesn’t depend on the distribution assumption and provides multiple circuits that allow adaptive sample distribution, allowing the selection of circuits that produce minimum errors. This method supports improving feature-target correlation, reducing the risk of overfitting, and stabilizing error values as model complexity increases. Applying this method to three datasets in material research (MLCC, PSH, and EFD) shows that HCVSG significantly improves prediction accuracy compared to conventional KNN and eight MTD-based methods. The distribution of virtual samples along the Hamiltonian circuit helps fill the information gap and makes the data distribution more even, ultimately improving the predictive model's performance.},
  archive      = {J_JOCS},
  author       = {Totok Sutojo and Supriadi Rustad and Muhamad Akrom and Wahyu Aji Eko Prabowo and De Rosal Ignatius Moses Setiadi and Hermawan Kresno Dipojono and Yoshitada Morikawa},
  doi          = {10.1016/j.jocs.2025.102711},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102711},
  shortjournal = {J. Comput. Sci.},
  title        = {An adaptive hamiltonian circuit of virtual sample generation for a small dataset},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tuning sensitivity of black phosphorene surface doped SnS, SnSe, GeS, and GeSe quantum dots toward water molecule and other small toxic molecules. <em>JOCS</em>, <em>92</em>, 102707. (<a href='https://doi.org/10.1016/j.jocs.2025.102707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, Density Functional Theory (DFT) was employed to investigate the impact of SnS, GeS, SnSe, and GeSe quantum dots doped black phosphorene on the sensitivity of black phosphorene toward various adsorbed gas molecules namely NO 2 and H 2 S. The interaction of H 2 O molecule with doped black phosphorene surface is also investigated to evaluate the impact of humidity on the sensing response. The results revealed the large electronic changes in bands distribution upon exposure to the selected gas molecules, giving rise to a variation in the electronic band nature from hole to electron doping which can promote the electrical conductivity and the sensing properties of the doped phosphorene structures.},
  archive      = {J_JOCS},
  author       = {Mamori Habiba and Moatassim Hajar and El Kenz Abdallah and Benyoussef Abdelilah and Taleb Abdelhafed and Abdel Ghafour El Hachimi and Zaari Halima},
  doi          = {10.1016/j.jocs.2025.102707},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102707},
  shortjournal = {J. Comput. Sci.},
  title        = {Tuning sensitivity of black phosphorene surface doped SnS, SnSe, GeS, and GeSe quantum dots toward water molecule and other small toxic molecules},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CKDTA: A chemical knowledge-enhanced framework for drug–target affinity prediction. <em>JOCS</em>, <em>92</em>, 102706. (<a href='https://doi.org/10.1016/j.jocs.2025.102706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate drug–target affinity (DTA) prediction is a cornerstone of efficient drug discovery, as it directly accelerates the screening of potential therapeutic candidates, reduces the cost of preclinical experiments, and shortens the development cycle of new drugs. However, existing deep learning-based methods face two main challenges: (I) Purely data-driven approaches struggle to capture the functional semantics of molecules, such as the role of specific functional regions and chemical element properties in binding interactions, due to the lack of integration with chemical prior knowledge, leading to unreliable predictions; (II) the integration of topological structure from graphs and long-range dependencies from sequences is insufficient, often failing to capture complementary features, limiting the model’s generalization ability, especially for novel drugs or targets commonly encountered in early drug discovery . To address these issues, we propose CKDTA , a C hemical K nowledge Enhanced framework for D rug- T arget A ffinity prediction. Our framework introduces two key innovations: (1) a chemical knowledge-enhanced molecular modeling approach, which constructs a multi-layer molecular graph incorporating atom-level features, chemical element information, and functional regions, enabling the capture of functional semantics through a hierarchical attention mechanism, while leveraging chemical prior knowledge; (2) a co-attention module designed to optimize sequence interaction information by leveraging graph-based interaction data, compensating for the lack of spatial structural information in sequence data. This module fully exploits the topological structure of graphs and the long-range dependencies in sequences, capturing complementary features. Extensive experiments on benchmark datasets demonstrate that CKDTA outperforms state-of-the-art methods. Furthermore, cold-start experiments validate its generalizability, highlighting its potential for drug discovery applications.},
  archive      = {J_JOCS},
  author       = {Xingran Zhao and Yanbu Guo and Bingyi Wang and Weihua Li},
  doi          = {10.1016/j.jocs.2025.102706},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102706},
  shortjournal = {J. Comput. Sci.},
  title        = {CKDTA: A chemical knowledge-enhanced framework for drug–target affinity prediction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient numerical simulation of variable-order fractional diffusion processes with a memory kernel. <em>JOCS</em>, <em>92</em>, 102705. (<a href='https://doi.org/10.1016/j.jocs.2025.102705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion equations are fundamental in modeling the transport of heat, mass, or contaminants in porous media. However, classical models often fail to capture the anomalous diffusion behavior inherent in heterogeneous and memory-dependent materials. To address this, we investigate a fractional diffusion integro-differential equation involving variable-order derivatives in both time and space, subject to suitable conditions. The solutions are shown to exist and be unique through the rigorous application of fixed-point theorems. A finite difference-based numerical scheme is formulated to handle the variable-order fractional operators and convolution-type integral terms efficiently. Stability analysis confirms the accuracy and robustness of the method. In addition, approximate solutions are computed for three representative cases:(i) constant-order fractional diffusion ( α = constant ), (ii) time-dependent order α ( t ) , and (iii) fully variable-order α ( x , t ) . By incorporating variable order dynamics and integro-differential structures, this work extends conventional models and provides a unified framework for simulating complex transport processes in porous media.},
  archive      = {J_JOCS},
  author       = {Sabita Bera and Mausumi Sen and Sujit Nath},
  doi          = {10.1016/j.jocs.2025.102705},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102705},
  shortjournal = {J. Comput. Sci.},
  title        = {Efficient numerical simulation of variable-order fractional diffusion processes with a memory kernel},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical solution of the biological SIR model for COVID-19 with convergence analysis. <em>JOCS</em>, <em>92</em>, 102704. (<a href='https://doi.org/10.1016/j.jocs.2025.102704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the numerical solution of the biological Susceptible–Infectious–Recovered model for COVID-19 over extended time intervals using the shifted Chebyshev polynomial collocation method. Initially, the original problem is reformulated into a nonlinear Volterra integral equation for the susceptible population. The shifted Chebyshev polynomials are then employed to derive the numerical solution. A comprehensive convergence analysis of the collocation method is conducted to ensure the reliability and accuracy of the proposed approach. Finally, numerical simulations are performed for various parameter configurations that influence the system’s coefficients. Our method is compared with existing approaches, providing insights into the model’s dynamics under different conditions.},
  archive      = {J_JOCS},
  author       = {Walid Remili and Wen-Xiu Ma},
  doi          = {10.1016/j.jocs.2025.102704},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102704},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical solution of the biological SIR model for COVID-19 with convergence analysis},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decomposition based imputation algorithm for long consecutive missing atmospheric pollution data and its application. <em>JOCS</em>, <em>92</em>, 102697. (<a href='https://doi.org/10.1016/j.jocs.2025.102697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the intensification of environmental air pollution, the impact of air pollutants on both the ecological environment and human health has attracted widespread attention. However, due to the relatively late introduction of environmental monitoring systems, there were long consecutive missing values in early pollutant data. In this paper, we propose a decomposition-based imputation method for long consecutive missing pollution data. Firstly, wavelet coherence analysis is employed to investigate the periodic relationship between the pollution data and the relevant air data, decomposing them into periodic and non-periodic components. Then, machine learning and transfer learning are used to impute the periodic and non-periodic components, respectively. Furthermore, the effectiveness of the method is validated on artificially missing NO 2 and SO 2 concentration data from five regions of China. Comparison results show that the proposed method significantly outperforms some other imputation methods in the literature in terms of both mean absolute error and mean absolute percentage error. Finally, the proposed imputation method is applied in the study of accelerated aging of polycarbonate materials. Experimental results show that the predictive accuracy of the aging model is improved when using the imputed pollutant data.},
  archive      = {J_JOCS},
  author       = {Xinyi Wei and Hao Meng and Lizhen Shao and Dongmei Fu and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.jocs.2025.102697},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102697},
  shortjournal = {J. Comput. Sci.},
  title        = {A decomposition based imputation algorithm for long consecutive missing atmospheric pollution data and its application},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Helium focused ion beam damage in silicon: Physics-informed neural network modeling of helium bubble nucleation and early growth. <em>JOCS</em>, <em>92</em>, 102696. (<a href='https://doi.org/10.1016/j.jocs.2025.102696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the time and cost required to obtain large datasets limit the application of data-driven machine learning in nanoscale manufacturing. Here, we focus on predicting the nanoscale damage induced by helium focused ion beams (He-FIBs) on silicon substrates. We briefly review the most relevant atomistic defects and the partial differential equations (PDEs), or rate equations, that describe the mutual creation and annihilation of the defects, eventually leading to the amorphization of the substrate and, the nucleation and early growth of helium bubbles. The novelty comes from the use of a physics-informed neural network (PINN) to simulate quantitatively the evolution of the bubbles, thus bypassing the dataset availability problem. As usual, the proposed PINN learns the underlying physics through the incorporation of the residuals of the PDEs and corresponding Initial Conditions (ICs) and Boundary Conditions (BCs) in the network’s loss function. Meanwhile, the system of PDEs poses some challenges to the PINN modeling strategy. We find that (i) hard constraints need to be imposed on the network output in order to satisfy both BCs and ICs, (ii) all the inputs and outputs of the PINN need to be cautiously normalized to ensure convergence during training, and (iii) customized weights need to be carefully applied to all the PDE loss terms in order to balance their contributions, thus improving the accuracy of the PINN predictions. Once trained, the network achieves good prediction accuracy over the entire space-time domain for various ion beam energies and doses. Comparisons are provided against previous experiments and traditional numerical simulations, which are also implemented in this study using the Finite Difference Method (FDM). While the L2 relative errors for all collocated points remain below 10%, the accuracy of the PINN decreases at lower beam energies and larger ion doses, due to the presence of higher numerical gradients.},
  archive      = {J_JOCS},
  author       = {Shupeng Gao and Qi Li and M.A. Gosalvez and Xi Lin and Yan Xing and Zaifa Zhou and Qianhuang Chen},
  doi          = {10.1016/j.jocs.2025.102696},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102696},
  shortjournal = {J. Comput. Sci.},
  title        = {Helium focused ion beam damage in silicon: Physics-informed neural network modeling of helium bubble nucleation and early growth},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the dopant diffusion dynamics with physics-informed neural networks. <em>JOCS</em>, <em>92</em>, 102695. (<a href='https://doi.org/10.1016/j.jocs.2025.102695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation plays a crucial role in the semiconductor chip manufacturing. In particular, process simulation is primarily used to solve the dopant diffusion dynamics, which describes the temporal evolution of doping profiles during the thermal annealing process. The diffusion dynamics constitutes a multiscale problem, formulated as a set of coupled partial differential equations (PDEs) with respect to the concentration of dopants and point defects. In this paper, we demonstrate that Physics-Informed Neural Networks (PINNs) can accurately predict not only the evolution of the doping profile, but also the unknown physical parameters, specifically the diffusivities appearing as PDE coefficients. Furthermore, we propose a physics-informed calibration method, which performs PDE-constrained optimization by leveraging a pre-trained PINN model. We experimentally verify that this post-processing significantly improves the accuracy of coefficients fine-tuning. To the best of our knowledge, this is the first demonstration of an annealing simulation for the semiconductor diffusion process using a physics-informed machine learning approach. This framework is expected to enable more efficient calibration of simulation parameters based on measurement data.},
  archive      = {J_JOCS},
  author       = {Sungyeop Lee and Jisu Ryu and Young-Gu Kim and Dae Sin Kim and Hiroo Koshimoto and Jaeshin Park},
  doi          = {10.1016/j.jocs.2025.102695},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102695},
  shortjournal = {J. Comput. Sci.},
  title        = {Solving the dopant diffusion dynamics with physics-informed neural networks},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on pest control models based on nonlinear threshold control. <em>JOCS</em>, <em>92</em>, 102694. (<a href='https://doi.org/10.1016/j.jocs.2025.102694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pest number trigger threshold strategy has been widely used in the control of pests in agricultural production. In this study, pest populations are managed by using an integrated nonlinear threshold function and a saturation function. The existence conditions of various equilibrium points and sliding sections in the system are derived. Theoretical analysis and numerical simulation results show the existence of boundary equilibrium bifurcations, tangency bifurcations and limit cycle bifurcations caused by discontinuous boundary. It is worth noting that persistence and non-smooth folding can be observed in the boundary equilibrium bifurcations. At the same time, because the nonlinear threshold control strategy is adopted in this study, the change of the sliding section of the model is more complicated. The numerical simulation results show that if there is an unstable focus in the model, a sliding homoclinic cycle will appear with the occurrence of boundary saddle point bifurcation, and then form a crossing limit cycle. The sensitivity analysis results of the system show that if the threshold level is too low, the control measures do not achieve the desired results. Too high threshold selection will cause unnecessary economic losses. Therefore, our results show that an appropriate threshold should be set to reduce economic losses while ensuring that the number of pests is in a lower stable state.},
  archive      = {J_JOCS},
  author       = {Yongfeng Li and Leyan Liang and Zhong Zhao},
  doi          = {10.1016/j.jocs.2025.102694},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102694},
  shortjournal = {J. Comput. Sci.},
  title        = {A study on pest control models based on nonlinear threshold control},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private linear equation solving: An application to federated learning and extreme learning machines. <em>JOCS</em>, <em>92</em>, 102693. (<a href='https://doi.org/10.1016/j.jocs.2025.102693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, multiple devices compute each a part of a common machine learning model using their own private data. These partial models (or their parameters) are then exchanged in a central server that builds an aggregated model. This sharing process may leak information about the data used to train them. This problem intensifies as the machine learning model becomes simpler, indicating a higher risk for single-hidden-layer feedforward neural networks, such as extreme learning machines. In this paper, we establish a mechanism to disguise the input data to a system of linear equations while guaranteeing that the modifications do not alter the solutions, and propose two possible approaches to apply these techniques to federated learning. Our findings show that extreme learning machines can be used in federated learning with an extra security layer, making them attractive in learning schemes with limited computational resources.},
  archive      = {J_JOCS},
  author       = {Daniel Heinlein and Anton Akusok and Kaj-Mikael Björk and Leonardo Espinosa-Leal},
  doi          = {10.1016/j.jocs.2025.102693},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102693},
  shortjournal = {J. Comput. Sci.},
  title        = {Private linear equation solving: An application to federated learning and extreme learning machines},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BAHA: Binary artificial hummingbird algorithm for feature selection. <em>JOCS</em>, <em>92</em>, 102686. (<a href='https://doi.org/10.1016/j.jocs.2025.102686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Datasets classification accuracy depends on their features. The presence of irrelevant and redundant features in the dataset leads to the reduction of classification accuracy. Identifying and removing such features is the main purpose in feature selection, which is an important step in the data science lifecycle. The objective of the Wrapper feature selection method is to reduce the number of selected feature (NSF) while improving the classification accuracy by working on a set of features. The feature selection is a challenging and computationally expensive problem that falls under the NP-complete category, so it requires computationally cheap and efficient algorithm to solve it. The artificial hummingbird algorithm (AHA) is a biological inspired optimization technique that mimics the unique flight capabilities and intelligent foraging tactics of hummingbirds in nature. Since feature selection is inherently a binary problem. In this paper, the binary form of the AHA meta-heuristic algorithm is proposed to show that binarizing the AHA meta-heuristic algorithm improves its performance for solving feature selection problems. The proposed method is tested on a standard benchmark dataset and compared with four state-of-the-art feature selection algorithms: Automata-based improved equilibrium optimizer with U-shaped transfer function (AIEOU), Whale optimization approaches for wrapper feature selection (WOA-CM), Ring theory-based harmony search (RTHS), and Adaptive switching gray-whale optimizer (ASGW). The results show the effectiveness of the proposed algorithm in searching for optimal features subset. The source code for the algorithm being proposed is accessible to the public on https://github.com/alihamdipour/baha .},
  archive      = {J_JOCS},
  author       = {Ali Hamdipour and Abdolali Basiri and Mostafa Zaare and Seyedali Mirjalili},
  doi          = {10.1016/j.jocs.2025.102686},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102686},
  shortjournal = {J. Comput. Sci.},
  title        = {BAHA: Binary artificial hummingbird algorithm for feature selection},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joe">JOE - 4</h2>
<ul>
<li><details>
<summary>
(2025). Structural periodic vector autoregressions. <em>JOE</em>, <em>252</em>, 106099. (<a href='https://doi.org/10.1016/j.jeconom.2025.106099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While seasonality inherent to raw macroeconomic data is commonly removed by seasonal adjustment techniques before it is used for structural inference, this may distort valuable information in the data. As an alternative method to commonly used structural vector autoregressions (SVARs) for seasonally adjusted data, we propose to model potential periodicity in seasonally unadjusted (raw) data directly by structural periodic vector autoregressions (SPVARs). This approach does not only allow for periodically time-varying intercepts, but also for periodic autoregressive parameters and innovations variances. As this larger flexibility leads to an increased number of parameters, we propose linearly constrained estimation techniques. Moreover, based on SPVARs, we provide two novel identification schemes and propose a general framework for impulse response analyses that allows for direct consideration of seasonal patterns. We provide asymptotic theory for SPVAR estimators and impulse responses under flexible linear restrictions and introduce a test for seasonality in impulse responses. For the construction of confidence intervals, we discuss several residual-based (seasonal) bootstrap methods and prove their bootstrap consistency under different assumptions. A real data application shows that useful information about the periodic structure in the data may be lost when relying on common seasonal adjustment methods.},
  archive      = {J_JOE},
  author       = {Daniel Dzikowski and Carsten Jentsch},
  doi          = {10.1016/j.jeconom.2025.106099},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106099},
  shortjournal = {J. Econ.},
  title        = {Structural periodic vector autoregressions},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Misspecification-robust bootstrap t-test for irrelevant factor in linear stochastic discount factor models. <em>JOE</em>, <em>252</em>, 106097. (<a href='https://doi.org/10.1016/j.jeconom.2025.106097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the applicability of the bootstrap approach to test for irrelevant risk factors that are potentially useless in misspecified linear stochastic discount factor (SDF) models. In the literature, the misspecification-robust inference with useless factors is known to give rise to nonstandard limiting distributions bounded stochastically to compute critical values. We show how and to what extent the wild bootstrap yields a more accurate approximation of the distribution of t -statistics when testing for an unpriced factor in the context of linear SDF models. Simulation experiments and empirical tests are also used to document the relevance of the bootstrap method.},
  archive      = {J_JOE},
  author       = {Antoine A. Djogbenou and Ulrich Hounyo},
  doi          = {10.1016/j.jeconom.2025.106097},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106097},
  shortjournal = {J. Econ.},
  title        = {Misspecification-robust bootstrap t-test for irrelevant factor in linear stochastic discount factor models},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On-line detection of changes in the shape of intraday volatility curves. <em>JOE</em>, <em>252</em>, 106089. (<a href='https://doi.org/10.1016/j.jeconom.2025.106089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise an on-line detector for temporal instability in the shape of average intraday volatility curves under a general semimartingale setup for the price-volatility dynamics. We adopt a block-based strategy to estimate volatility nonparametrically from the intraday observations over local time windows with asymptotically shrinking size. Our detector then tracks sequential changes in running means of the intraday volatility curve estimates. Asymptotic size and power properties of the detector follow from a weak form invariance principle, which is established under the strong mixing condition aligned with our semimartingale setup. Simulation and empirical results demonstrate good finite-sample performance of the proposed detection method.},
  archive      = {J_JOE},
  author       = {Torben G. Andersen and Yingwen Tan and Viktor Todorov and Zhiyuan Zhang},
  doi          = {10.1016/j.jeconom.2025.106089},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106089},
  shortjournal = {J. Econ.},
  title        = {On-line detection of changes in the shape of intraday volatility curves},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High dimensional factor analysis with weak factors. <em>JOE</em>, <em>252</em>, 106086. (<a href='https://doi.org/10.1016/j.jeconom.2025.106086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the principal components (PC) estimator for high dimensional approximate factor models with weak factors in that the factor loading ( Λ 0 ) scales sublinearly in the number N of cross-section units, i.e., Λ 0 ⊤ Λ 0 / N α is positive definite in the limit for some α ∈ ( 0 , 1 ) . While the consistency and asymptotic normality of these estimates are by now well known when the factors are strong, i.e., α = 1 , the statistical properties for weak factors remain less explored. Here, we show that the PC estimator maintains consistency and asymptotic normality for any α ∈ ( 0 , 1 ) , provided suitable conditions regarding the dependence structure in the noise are met. This complements earlier result by Onatski (2012) that the PC estimator is inconsistent when α = 0 , and the more recent work by Bai and Ng (2023) who established the asymptotic normality of the PC estimator when α ∈ ( 1 / 2 , 1 ) . Our proof strategy integrates the traditional eigendecomposition-based approach for factor models with leave-one-out analysis similar in spirit to those used in matrix completion and other settings. This combination allows us to deal with factors weaker than the former and at the same time relax the incoherence and independence assumptions often associated with the later.},
  archive      = {J_JOE},
  author       = {Jungjun Choi and Ming Yuan},
  doi          = {10.1016/j.jeconom.2025.106086},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106086},
  shortjournal = {J. Econ.},
  title        = {High dimensional factor analysis with weak factors},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joma">JOMA - 7</h2>
<ul>
<li><details>
<summary>
(2026). A novel martingale difference correlation via data splitting with applications in feature screening. <em>JOMA</em>, <em>211</em>, 105508. (<a href='https://doi.org/10.1016/j.jmva.2025.105508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel sample martingale difference correlation via data splitting to measure the departure of conditional mean independence between a response variable Y and a vector predictor X . The proposed correlation converges to zero and has an asymptotically symmetric sampling distribution around zero when Y and X are conditionally mean independent. In contrast, it converges to a positive value when Y and X are conditionally mean dependent. Leveraging these properties, we develop a new model-free feature screening method with false discovery rate (FDR) control for ultrahigh-dimensional data. We demonstrate that this screening method achieves FDR control and the sure screening property simultaneously. We also extend our approach to conditional quantile screening with FDR control. To further enhance the stability of the screening results, we implement multiple splitting techniques. We evaluate the finite sample performance of our proposed methods through simulations and real data analyses, and compare them with existing methods.},
  archive      = {J_JOMA},
  author       = {Zhengyu Zhu and Jicai Liu and Riquan Zhang},
  doi          = {10.1016/j.jmva.2025.105508},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105508},
  shortjournal = {J. Multi. Anal.},
  title        = {A novel martingale difference correlation via data splitting with applications in feature screening},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tree pólya splitting distributions for multivariate count data. <em>JOMA</em>, <em>211</em>, 105507. (<a href='https://doi.org/10.1016/j.jmva.2025.105507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop a new class of multivariate distributions adapted for count data, called Tree Pólya Splitting. This class results from the combination of a univariate distribution and singular multivariate distributions along a fixed partition tree. Known distributions, including the Dirichlet-multinomial, the generalized Dirichlet-multinomial and the Dirichlet-tree multinomial, are particular cases within this class. As we will demonstrate, these distributions offer some flexibility, allowing for the modeling of complex dependence structures (positive, negative, or null) at the observation level. Specifically, we present theoretical properties of Tree Pólya Splitting distributions by focusing primarily on marginal distributions, factorial moments, and dependence structures (covariance and correlations). A dataset of abundance of Trichoptera is used, on one hand, as a benchmark to illustrate the theoretical properties developed in this article, and on the other hand, to demonstrate the interest of these types of models, notably by comparing them to other approaches for fitting multivariate data, such as the Poisson-lognormal model in ecology or singular multivariate distributions used in microbial analysis.},
  archive      = {J_JOMA},
  author       = {Samuel Valiquette and Jean Peyhardi and Éric Marchand and Gwladys Toulemonde and Frédéric Mortier},
  doi          = {10.1016/j.jmva.2025.105507},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105507},
  shortjournal = {J. Multi. Anal.},
  title        = {Tree pólya splitting distributions for multivariate count data},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficiency of markov chains for bayesian linear regression models with heavy-tailed errors. <em>JOMA</em>, <em>211</em>, 105506. (<a href='https://doi.org/10.1016/j.jmva.2025.105506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider posterior simulation for a linear regression model when the error distribution is given by a scale mixture of multivariate normals. We first show that a sampler given in the literature for the case of the conditionally conjugate normal-inverse Wishart prior continues to be geometrically ergodic even when the error density is heavier-tailed. Moreover, we prove that the ergodicity is uniform by verifying the minorization condition. In the second half of this note, we treat an improper case and, using a simple energy function, show that a data augmentation algorithm in the literature is geometrically ergodic under a significantly different condition.},
  archive      = {J_JOMA},
  author       = {Yasuyuki Hamura},
  doi          = {10.1016/j.jmva.2025.105506},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105506},
  shortjournal = {J. Multi. Anal.},
  title        = {Efficiency of markov chains for bayesian linear regression models with heavy-tailed errors},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified selection consistency theorem for information criterion-based rank estimators in factor analysis. <em>JOMA</em>, <em>211</em>, 105498. (<a href='https://doi.org/10.1016/j.jmva.2025.105498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, numerous rank estimators for factor models have been proposed in the literature. This article focuses on information criterion-based rank estimators and investigates their consistency in rank selection. The gap conditions serve as necessary and sufficient conditions for rank estimators to achieve selection consistency under the general assumptions of random matrix theory. We establish a unified theorem on selection consistency, presenting the gap conditions for information criterion-based rank estimators with a unified formulation. To validate the theorem’s assertion that rank selection consistency is solely determined by the gap conditions, we conduct extensive numerical simulations across various settings. Additionally, we undertake supplementary simulations to explore the strengths and limitations of information criterion-based estimators by comparing them with other types of rank estimators.},
  archive      = {J_JOMA},
  author       = {Toshinari Morimoto and Hung Hung and Su-Yun Huang},
  doi          = {10.1016/j.jmva.2025.105498},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105498},
  shortjournal = {J. Multi. Anal.},
  title        = {A unified selection consistency theorem for information criterion-based rank estimators in factor analysis},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On nonparametric functional data regression with incomplete observations. <em>JOMA</em>, <em>211</em>, 105497. (<a href='https://doi.org/10.1016/j.jmva.2025.105497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider the problem of nonparametric estimation of a regression function m ( χ ) = E ( Y | χ = χ ) with the functional covariate χ when the response Y may be missing according to a missing-not-at-random (MNAR) setup, i.e., when the underlying missing probability mechanism can depend on both χ and Y . Our proposed estimator is based on a particular representation of the regression function m ( χ ) in terms of four associated conditional expectations that can be estimated nonparametrically. To assess the theoretical performance of our estimators, we study their convergence properties in general L p norms where we also look into their rates of convergence. Our numerical results show that the proposed estimators have good finite-sample performance. We also explore the applications of our results to the problem of statistical classification with missing labels and establish a number of convergence results for new kernel-type classification rules.},
  archive      = {J_JOMA},
  author       = {Majid Mojirsheibani},
  doi          = {10.1016/j.jmva.2025.105497},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105497},
  shortjournal = {J. Multi. Anal.},
  title        = {On nonparametric functional data regression with incomplete observations},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Matérn and generalized wendland correlation models that parameterize hole effect, smoothness, and support. <em>JOMA</em>, <em>211</em>, 105496. (<a href='https://doi.org/10.1016/j.jmva.2025.105496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A huge literature in statistics and machine learning is devoted to parametric families of correlation functions, where the correlation parameters are used to understand the properties of an associated spatial random process in terms of smoothness and global or compact support. However, most of current parametric correlation functions attain only non-negative values. This work provides two new families of correlation functions that can have some negative values (aka hole effects), along with smoothness, and global or compact support. They generalize the celebrated Matérn and Generalized Wendland models, respectively, which are obtained as special cases. A link between the two new families is also established, showing that a specific reparameterization of the latter includes the former as a special limit case. Their performance in terms of estimation accuracy and goodness of best linear unbiased prediction is illustrated through synthetic and real data.},
  archive      = {J_JOMA},
  author       = {Xavier Emery and Moreno Bevilacqua and Emilio Porcu},
  doi          = {10.1016/j.jmva.2025.105496},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105496},
  shortjournal = {J. Multi. Anal.},
  title        = {Matérn and generalized wendland correlation models that parameterize hole effect, smoothness, and support},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust semi-functional censored regression. <em>JOMA</em>, <em>211</em>, 105491. (<a href='https://doi.org/10.1016/j.jmva.2025.105491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a robust methodological framework for analyzing randomly censored responses within the semi-functional partial linear regression models, utilizing the exponential squared loss criterion. The proposed methodology capitalizes on the robustness of the exponential squared loss function against outliers and heavy-tailed error distributions, while preserving the flexibility and interpretability of semi-functional regression, which accommodates scalar and functional predictors in a unified framework. To account for the divergent convergence rates of the parametric and nonparametric components, we introduce a novel three-step estimation procedure designed to enhance computational efficiency, ensure model robustness, and achieve asymptotically optimal estimation performance. The parametric component is estimated through a quasi-Newton algorithm, for which we establish global convergence under standard regularity conditions using a Wolfe-type line search strategy. Additionally, we suggest a cross-validation criterion based on the exponential squared loss function to guide the data-driven selection of tuning parameters. The theoretical properties, including consistency and asymptotic normality of the proposed estimators, are established under mild conditions. The efficacy and robustness of the method are demonstrated through a series of simulation studies and an empirical application to Alzheimer’s disease progression, highlighting its practical applicability in addressing complex and censored data structures.},
  archive      = {J_JOMA},
  author       = {Tao Wang},
  doi          = {10.1016/j.jmva.2025.105491},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105491},
  shortjournal = {J. Multi. Anal.},
  title        = {Robust semi-functional censored regression},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jomp">JOMP - 3</h2>
<ul>
<li><details>
<summary>
(2025). Experiment-based calibration in psychology: Foundational and data-generating model. <em>JOMP</em>, <em>127</em>, 102950. (<a href='https://doi.org/10.1016/j.jmp.2025.102950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experiment-based calibration is a novel method for measurement validation, which – unlike classical validity metrics – does not require stable between-person variance. In this approach, the latent variable to be measured is manipulated by an experiment, and its predicted scores – termed standard scores – are compared against the measured scores. Previous work has shown that under plausible boundary conditions, the correlation between standard and measured scores – termed retrodictive validity – is informative about measurement accuracy, i.e. combined trueness and precision. Here, I expand these findings in several directions. First, I formalise the approach in a probability-theoretic framework with the concept of a standardised calibration space. Second, I relate this framework to classical validity theory and show that the boundary conditions in fact apply to any form of criterion validity, including classical convergent validity. Thus, I state precise and empirically quantifiable boundary conditions under which criterion validity metrics are informative on validity. Third, I relate these boundary conditions to confounding variables, i.e. correlated latent variables. I show that in the limit, calibration will converge on the latent variable that is most closely related to the standard. Finally, I provide a framework for modelling the data-generating process with Markov kernels, and identify sufficient conditions under which the data generation model results in a calibration space. In sum, this article provides a formal probability-theoretic framework for experiment-based calibration and facilitates modelling and empirical assessment of the data generating processes.},
  archive      = {J_JOMP},
  author       = {Dominik R. Bach},
  doi          = {10.1016/j.jmp.2025.102950},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102950},
  shortjournal = {J. Math. Psychol.},
  title        = {Experiment-based calibration in psychology: Foundational and data-generating model},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On iverson’s law of similarity. <em>JOMP</em>, <em>127</em>, 102943. (<a href='https://doi.org/10.1016/j.jmp.2025.102943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iverson (2006b) proposed the law of similarity ξ s ( λ x ) = γ ( λ , s ) ξ η ( λ , s ) ( x ) for the sensitivity functions ξ s ( s ∈ S ) . Compared to the former models, the generality of this one lies in that here γ and η can also depend on the variables λ and s . In the literature, this model (or its special cases) is usually considered together with a given psychophysical representation (e.g. Fechnerian, subtractive, or affine). Our goal, however, is to study at first Iverson’s law of similarity on its own. We show that if certain mild assumptions are fulfilled, then ξ can be written in a rather simple form containing only one-variable functions. The obtained form proves to be very useful when we assume some kind of representation. Motivated by Hsu and Iverson (2016) , we then study the above model assuming that the mapping η is multiplicatively translational. First, we show how these mappings can be characterized. Later we turn to the examination of Falmagne’s power law. According to our results, the corresponding function ξ can have a Fechnerian representation, and also it can have a subtractive representation. We close the paper with the study of the shift invariance property.},
  archive      = {J_JOMP},
  author       = {Eszter Gselmann and Christopher W. Doble and Yung-Fong Hsu},
  doi          = {10.1016/j.jmp.2025.102943},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102943},
  shortjournal = {J. Math. Psychol.},
  title        = {On iverson’s law of similarity},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal analysis of absolute and relative risk reductions. <em>JOMP</em>, <em>127</em>, 102942. (<a href='https://doi.org/10.1016/j.jmp.2025.102942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any medical innovation must first prove its benefits with reliable evidence from clinical trials. Evidence is commonly expressed using two metrics, summarizing treatment benefits based on either absolute risk reductions (ARRs) or relative risk reductions (RRRs). Both metrics are derived from the same data, but they implement conceptually distinct ideas. Here, we analyze these risk reductions measures from a causal modeling perspective. First, we show that ARR is equivalent to Δ P , while RRR is equivalent to causal power, thus clarifying the implicit causal assumptions. Second, we show how this formal equivalence establishes a relationship with causal Bayes nets theory, offering a basis for incorporating risk reduction metrics into a computational modeling framework. Leveraging these analyses, we demonstrate that under dynamically varying baseline risks, ARRs and RRRs lead to strongly diverging predictions. Specifically, the inherent assumption of a linear parameterization of the underlying causal graph can lead to incorrect conclusions when generalizing treatment benefits (e.g, predicting the effect of a vaccine in new populations with different baseline risks). Our analyses highlight the shared principles underlying risk reduction metrics and measures of causal strength, emphasizing the potential for explicating causal structure and inference in medical research.},
  archive      = {J_JOMP},
  author       = {Björn Meder and Charley M. Wu and Felix G. Rebitschek},
  doi          = {10.1016/j.jmp.2025.102942},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102942},
  shortjournal = {J. Math. Psychol.},
  title        = {Causal analysis of absolute and relative risk reductions},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jpdc">JPDC - 1</h2>
<ul>
<li><details>
<summary>
(2026). A scalable tensor-based MDTW approach for multi-modal time series patterns clustering. <em>JPDC</em>, <em>207</em>, 105173. (<a href='https://doi.org/10.1016/j.jpdc.2025.105173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal Time Series (MTS) is a vital ingredient to Predictive Multi-modal Artificial Intelligence (PMAI). MTS systems capture varying temporal modalities and their inherent dependencies for their accurate analytics. However, efficiently exploring these cross-modalities relationships is a challenging research due to their complexity facets and information redundancies. MTS patterns' pairwise similarity measures precede PMAI. Multi-modal Dynamic Time Warping (MDTW) is frequently explored to quantify similar MTS. Yet, it's reliant on the orthogonal conditioned local similarity measures that ignore the contributions of MTS' underlying structural relationships in the warping process and, hence, susceptible to unrealistic matching. This paper addresses the setbacks by recommending a scalable MTS recognition model, named Tensor-Slices Distance (TSD)-based MDTW (TSD-MDTW), that's subsequently advanced to two more distinct models termed Weighted modality and TSD (WmTSD-MDTW) and TSD-Mahalanobis (TSDMaha-MDTW). To quantify an alignment's cost, TSD-MDTW incorporates intrinsic spatial dependencies between modalities' coordinates, while WmTSD-MDTW relaxes information redundancies through weighing modalities based on information richness, whereas TSDMaha-MDTW embodies modalities dependencies and their coordinates' innate spatial dependencies. Besides, it proposes a scalable Tensor-based DTW (TDTW) model that re-formulates MDTW into multiple dimensions that are found paralleling warping processes. Theoretical and empirical experimental results on MTS multi-modal datasets encompassing load patterns and meteorological modalities reveal TDTW's efficiency and proposals' superior performances in terms of cluster compactness and separation over MDTW employing the state-of-the-art local similarity measures.},
  archive      = {J_JPDC},
  author       = {Bahati Alam Sanga and Laurence T. Yang and Shunli Zhang and Zecan Yang and Nicholaus Gati},
  doi          = {10.1016/j.jpdc.2025.105173},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {1},
  pages        = {105173},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {A scalable tensor-based MDTW approach for multi-modal time series patterns clustering},
  volume       = {207},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jtb">JTB - 6</h2>
<ul>
<li><details>
<summary>
(2026). A kinetic study of multi-substrate uniporters. <em>JTB</em>, <em>616</em>, 112267. (<a href='https://doi.org/10.1016/j.jtbi.2025.112267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transporters play key roles in regulating the movement of molecules into and out of cells. Uniporters, the simplest class of transporters, use facilitated diffusion to translocate molecules across membranes down their concentration gradient. This process can be affected by the presence of additional substrates in the intra- and extracellular environment, which can either increase the net transport rate of a molecule via trans acceleration or decrease it via competitive inhibition. In this study, we derived mathematical models to describe the net transport rate of uniporters in the presence of multiple extracellular substrates or inhibitors. Analyses of these models identified four possible states for the system when two substrates are present, with two states leading to trans acceleration and the other two states resulting in inhibition. Finally, we found that the relation between kinetic constants that controls the fraction of transporters in the inward-facing open state is responsible for these behaviors. Our theoretical results provide a mathematical framework for understanding the dynamic response of uniporters in the presence of multiple substrates and inhibitors, which could have implications for various processes, from nutrient utilization to metabolic engineering.},
  archive      = {J_JTB},
  author       = {Ana S. de Pereda and Jihyun Park and Lily S. Cheung},
  doi          = {10.1016/j.jtbi.2025.112267},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112267},
  shortjournal = {J. Theor. Biol},
  title        = {A kinetic study of multi-substrate uniporters},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Phenomenological modeling of gene transcription by approximating cooperativity of transcription factors improves prediction and reduces complexity in gene regulatory network models. <em>JTB</em>, <em>616</em>, 112264. (<a href='https://doi.org/10.1016/j.jtbi.2025.112264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several computational models are available for representing the gene expression process, with each having their advantages and disadvantages. Phenomenological models are widely used as they make appropriate simplifications that aim to find a middle ground between accuracy and complexity. The existing phenomenological models compete in terms of how the transcription initiation process is approximated, to achieve high accuracy while having the lowest complexity possible. However, most current models still suffer from high parameter complexity in the case of complex promoters. Herein, we formally derive a phenomenological approach to model RNA polymerase recruitment, stating approximations on cooperativity between transcription factors that are applicable to promoters requiring multifactorial input, which reduces parameter complexity. We then apply this method to biologically relevant networks of varying complexities to show that the approximations improved predictive ability compared to existing models. In summary, our reduced parameter model (RPM) had lower complexity while maintaining high accuracy, which leads to better scalability for complex networks.},
  archive      = {J_JTB},
  author       = {Thiruvickraman Jothiprakasam and Siddharth Jhunjhunwala},
  doi          = {10.1016/j.jtbi.2025.112264},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112264},
  shortjournal = {J. Theor. Biol},
  title        = {Phenomenological modeling of gene transcription by approximating cooperativity of transcription factors improves prediction and reduces complexity in gene regulatory network models},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mathematical model suggests current CAR-macrophage dosage is efficient to low pre-infusion tumour burden but refractory to high tumour burden. <em>JTB</em>, <em>616</em>, 112263. (<a href='https://doi.org/10.1016/j.jtbi.2025.112263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chimeric antigen receptor (CAR)-macrophage therapy is a promising approach for tumour treatment due to antigen-specific phagocytosis and tumour clearance. However, the precise impact of tumour burden, dose and dosing regimens on therapeutic outcomes remains poorly understood. We developed ordinary differential equation (ODE) mathematical modelling and utilised parameter inference to analyse in vitro FACS-based phagocytosis assay data testing CD19-positive Raji tumour cell against CAR-macrophage, and revealed that phagocytosing efficiency of CAR-macrophage increases but saturates as both Raji cell and CAR-macrophage concentrations increase. This interaction resulted in bistable Raji cell kinetics; specifically, within a particular range of CAR-macrophage concentration, low tumour burdens are effectively inhibited, while high tumour burdens remain refractory. Furthermore, our model predicted that CAR-macrophage dosages typically suggested by current clinical trials yield favourable therapeutic outcomes only when tumour burden is low. For split CAR-macrophage infusion with fixed total dosage, the first infusion with high CAR-macrophage dose delivers superior treatment outcomes. Finally, we identified alternative infusion regimens: five billion cells administered monthly for three months, or seven billion cells every two months for six months, can efficiently suppress Raji cell replication irrespective of tumour burden. Our findings highlight CAR-macrophage therapeutic outcomes are strongly influenced by both tumour burden and different dosing regimens. This work underscores that reducing tumour burden, increasing CAR-macrophage dose in the first infusion and prolonging CAR-macrophage persistence are key strategies for achieving durable responses.},
  archive      = {J_JTB},
  author       = {Shilian Xu and Maoxuan Liu},
  doi          = {10.1016/j.jtbi.2025.112263},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112263},
  shortjournal = {J. Theor. Biol},
  title        = {Mathematical model suggests current CAR-macrophage dosage is efficient to low pre-infusion tumour burden but refractory to high tumour burden},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergent microtubule properties in a model of filament turnover and nucleation. <em>JTB</em>, <em>616</em>, 112254. (<a href='https://doi.org/10.1016/j.jtbi.2025.112254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microtubules (MTs) are dynamic protein filaments essential for intracellular organization and transport, particularly in long-lived cells such as neurons. The plus and minus ends of neuronal MTs switch between growth and shrinking phases, and the nucleation of new filaments is believed to be regulated in both healthy and injury conditions. We propose stochastic and deterministic mathematical models to investigate the impact of filament nucleation and length-regulation mechanisms on emergent properties such as MT lengths and numbers in living cells. We expand our stochastic continuous-time Markov chain model of filament dynamics to incorporate MT nucleation and capture realistic stochastic fluctuations in MT numbers and tubulin availability. We also propose a simplified partial differential equation (PDE) model, which allows for tractable analytical investigation into steady-state MT distributions under different nucleation and length-regulating mechanisms. We find that the stochastic and PDE modeling approaches show good agreement in MT length distributions, and that both MT nucleation and the catastrophe rate of large-length MTs regulate MT length distributions. In both frameworks, multiple mechanistic combinations achieve the same average MT length. The models proposed can predict parameter regimes where the system is scarce in tubulin, the building block of MTs, and suggest that low filament nucleation regimes are characterized by high variation in MT lengths, while high nucleation regimes drive high variation in MT numbers. These mathematical frameworks have the potential to improve our understanding of MT regulation in both healthy and injured neurons.},
  archive      = {J_JTB},
  author       = {Anna C. Nelson and Scott A. McKinley and Melissa M. Rolls and Maria-Veronica Ciocanel},
  doi          = {10.1016/j.jtbi.2025.112254},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112254},
  shortjournal = {J. Theor. Biol},
  title        = {Emergent microtubule properties in a model of filament turnover and nucleation},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modelling phylogeny in 16S rRNA gene sequencing datasets using string-based kernels. <em>JTB</em>, <em>616</em>, 112249. (<a href='https://doi.org/10.1016/j.jtbi.2025.112249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bacterial microbiome is increasingly being recognised as a key factor in human health, driven in large part by datasets collected using 16S rRNA (ribosomal ribonucleic acid) gene sequencing, which enable cost-effective quantification of the composition of an individual’s bacterial community. One of the defining characteristics of 16S rRNA datasets is the evolutionary relationships that exist between taxa (phylogeny). Here, we demonstrate the utility of modelling these phylogenetic relationships in two statistical tasks (the two sample test and host trait prediction) and propose a novel family of kernels for analysing microbiome datasets by leveraging string kernels from the natural language processing literature. We show via simulation studies that a kernel two-sample test using the proposed kernel is sensitive to the phylogenetic scale of the difference between the two populations. In a second set of simulations we also show how Gaussian process modelling with string kernels can infer the distribution of bacterial-host effects across the phylogenetic tree and apply this approach to a real host-trait prediction task. The results in the paper can be reproduced by running the code at https://github.com/jonathanishhorowicz/modelling_phylogeny_in_16srrna_using_string_kernels .},
  archive      = {J_JTB},
  author       = {Jonathan Ish-Horowicz and Sarah Filippi},
  doi          = {10.1016/j.jtbi.2025.112249},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112249},
  shortjournal = {J. Theor. Biol},
  title        = {Modelling phylogeny in 16S rRNA gene sequencing datasets using string-based kernels},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Approximate bayesian computation for markovian binary trees in phylogenetics. <em>JTB</em>, <em>616</em>, 112246. (<a href='https://doi.org/10.1016/j.jtbi.2025.112246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phylogenetic trees describe the relationships between species in the evolutionary process, and provide information about the rates of diversification. To understand the mechanisms behind macroevolution, we consider a class of multitype branching processes called Markovian binary trees (MBTs). MBTs allow for trait-based variation in diversification rates, and provide a flexible and realistic probabilistic model for phylogenetic trees. We develop an approximate Bayesian computation (ABC) scheme to infer the rates of MBT parameters by exploiting the information in the shapes of phylogenetic trees. We evaluate the accuracy of this inference method using simulation studies, and find that our method is able to detect variation in the diversification rates, with accuracy comparable to, and generally better than, likelihood-based methods. In an application to a real-life phylogeny of squamata, we reinforce conclusions drawn from earlier studies, in particular supporting the existence of ovi-/viviparity transitions in both directions. Our method demonstrates the potential for more complex models of evolution to be employed in phylogenetic inference, in conjunction with likelihood-free schemes.},
  archive      = {J_JTB},
  author       = {Mingqi He and Sophie Hautphenne and Yao-ban Chan},
  doi          = {10.1016/j.jtbi.2025.112246},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112246},
  shortjournal = {J. Theor. Biol},
  title        = {Approximate bayesian computation for markovian binary trees in phylogenetics},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="kbs">KBS - 17</h2>
<ul>
<li><details>
<summary>
(2025). Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning. <em>KBS</em>, <em>330</em>, 114483. (<a href='https://doi.org/10.1016/j.knosys.2025.114483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop knowledge graph reasoning aims to leverage the relations between multiple nodes in a knowledge graph to reason information about an event or entity. This reasoning process requires traversing multiple interconnected facts or knowledge points, which aids in understanding the model’s decision-making process. Multi-hop knowledge graph reasoning has driven the development of knowledge-based technologies, such as question-answering systems and recommendation systems. However, multi-hop reasoning relies on the connectivity between different entities in the knowledge graph. This characteristic makes multi-hop reasoning lack robustness when dealing with sparse data. To address the challenges of sparsity, recent studies pre-train knowledge graph embedding models to complete potential triples. The completion methods introduce noisy triples, which increases the risk of model selection errors and spurious paths. In this work, we propose a framework based on potential subgraph rule and reasoning context enhancement to mitigate the challenges of sparsity. On one hand, we leverage reasoning context to enhance state information and the reasoning process; on the other hand, we design an action perceptron based on the importance of reasoning context to reduce the introduction of noisy triples. Additionally, we analyze the phenomenon of data augmentation introducing spurious paths, and further utilize data augmentation-based potential subgraph rules to guide the reasoning process. This dual mechanism demonstrates stronger robustness in addressing sparsity challenges and spurious paths. Diverse experiments demonstrate that our model outperforms the existing multi-hop reasoning models across five datasets. Our implementations will be publicly available at: https://github.com/jianruichen/PreKGR .},
  archive      = {J_KBS},
  author       = {Congcong Sun and Jianrui Chen and Deguang Chen and Junjie Huang},
  doi          = {10.1016/j.knosys.2025.114483},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. <em>KBS</em>, <em>330</em>, 114482. (<a href='https://doi.org/10.1016/j.knosys.2025.114482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful self-supervised approach for learning generalized graph representations, achieving remarkable advancements in recent years. However, most existing GCL methods ignore the noise of the augmented global structure and the dynamic change in training, and lack detailed consideration in calculating local structural homogeneity. These limitations may lead to the model’s insufficient performance in capturing fine-grained semantic features at the node level, making it difficult to fully explore the potential semantic associations between adjacent nodes. Meanwhile, on a global scale, there is also a lack of the ability to model complex topological structures. To this end, we propose a new multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. This method dynamically adjusts the global structure via graph reconstruction and adaptively learns node representations; Meanwhile, a mutual rectification module is designed to predict the support scores of neighbors relative to anchors and quantify each neighbor’s contribution to view agreement. Both reconstruction and rectification are integrated into the training objective and effectively capture the graph structure information from both global and local scales, improving the quality and robustness of graph representations. We conduct extensive experiments on three downstream tasks: node classification, node clustering, and link prediction. The experimental results demonstrate that our method outperforms existing GCL methods across multiple tasks and datasets, validating the effectiveness and generalizability of the proposed model.},
  archive      = {J_KBS},
  author       = {Dengdi Sun and Zhixiang Wu and Mingwei Cao and Zhifu Tao and Zhuanlian Ding},
  doi          = {10.1016/j.knosys.2025.114482},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114482},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer. <em>KBS</em>, <em>330</em>, 114471. (<a href='https://doi.org/10.1016/j.knosys.2025.114471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied in optimization because of their flexibility and ability to address complex and high-dimensional problems. Nevertheless, they face persistent challenges, including susceptibility to local optima, limited parameter adaptability, and premature convergence. Leadership-based metaheuristics, in which leaders guide the search process, encounter additional difficulties such as limited exploration capacity, leader stagnation, and reduced diversity, often stemming from underutilization of data generated during the search. To overcome these limitations, this study proposes a reinforcement learning–based approach, RL-LGWO, which enhances the Grey Wolf Optimizer (GWO) by integrating multi-agent reinforcement learning. In RL-LGWO, agents share experiences to improve decision-making, and reinforcement learning is employed to decouple and adapt the leader update mechanism, thereby improving the exploration–exploitation balance and enabling leaders to dynamically escape local optima. The proposed method was evaluated against two GWO-enhancing algorithms, three RL-based GWO variants, PSO, WOA, and the original GWO across 23 well-known benchmark functions, in addition to the recent CEC2022 benchmark suite. Experimental results show that RL-LGWO achieved the best solutions on 17 of the 23 benchmark functions, with superior convergence speed and improved stability, while incurring only a minor runtime increase compared with the original GWO. Furthermore, on the CEC2022 suite, RL-LGWO outperformed competing algorithms on 10 of 12 test functions, underscoring its robustness and adaptability to recent and challenging benchmarks. Overall, the findings indicate that RL-LGWO delivers a substantive improvement over state-of-the-art alternatives and holds strong potential to advance leadership-based metaheuristics for a wide range of optimization problems.},
  archive      = {J_KBS},
  author       = {Afifeh Maleki and Mehdy Roayaei and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.114471},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling. <em>KBS</em>, <em>330</em>, 114454. (<a href='https://doi.org/10.1016/j.knosys.2025.114454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of supervised medical image segmentation models, relying on a large amount of labeled data is impractical in real-world situations. Semi-supervised learning approaches aim to alleviate this challenge using unlabeled data through pseudo-label generation. Yet, existing semi-supervised segmentation methods still suffer from noisy pseudo-labels and insufficient supervision within the feature space. To solve these challenges, this paper proposes a novel semi-supervised 3D medical image segmentation framework based on a dual-network architecture. Specifically, we investigate a Cross Consistency Enhancement module using both cross pseudo and entropy-filtered supervision to reduce the noisy pseudo-labels, while we design a dynamic weighting strategy to adjust the contributions of pseudo-labels using an uncertainty-aware mechanism (i.e., Kullback–Leibler divergence). In addition, we use a self-supervised contrastive learning mechanism to align uncertain voxel features with reliable class prototypes by effectively differentiating between trustworthy and uncertain predictions, thus reducing prediction uncertainty. Extensive experiments are conducted on three 3D segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed approach consistently exhibits superior performance across various settings (e.g., 89.95 % Dice score on left Atrial with 10 % labeled data) compared to the state-of-the-art methods. Furthermore, the usefulness of the proposed modules is further validated via ablation experiments. The code repository is available at https://github.com/AIPMLab/Semi-supervised-Segmentation .},
  archive      = {J_KBS},
  author       = {Yunyao Lu and Yihang Wu and Ahmad Chaddad and Tareef Daqqaq and Reem Kateb},
  doi          = {10.1016/j.knosys.2025.114454},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. <em>KBS</em>, <em>330</em>, 114452. (<a href='https://doi.org/10.1016/j.knosys.2025.114452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of transfer learning strategies to solve cross-domain fault diagnosis problems has achieved significant results. However, most existing multi-source domain generalization fault diagnosis methods use a single classifier or introduce auxiliary classifiers, focusing on learning domain-invariant features or global feature distribution matching. Furthermore, since the data distributions of different source domains may be significantly different, this may lose the data distribution information specific to each source domain. In addition, how to reduce the variation in risk between samples within the same domain training is also a challenging issue. Finally, it is also crucial to balance the predictive outputs of multiple classifiers to adapt them to the data distribution of the target domain. Based on the above challenges, this paper proposes a multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. Feature weakly decoupled mechanism is achieved by employing multiple classifiers and incorporating the variance of samples within the same sample domain as a penalty term. This reduces the model’s sensitivity to changes in the extreme distribution of samples within the domain. Classifier weakly decoupled mechanism, on the other hand, reduces the inter-domain risk variance by minimizing the loss of variance in the predicted output of the source domain classifiers. This improves the robustness of the model to inter-domain distributional changes and covariate changes. Experimental results on three datasets validate the effectiveness and general applicability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Yawei Sun and Hongfeng Tao and Vladimir Stojanovic},
  doi          = {10.1016/j.knosys.2025.114452},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114452},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing large language models for bitcoin time series forecasting. <em>KBS</em>, <em>330</em>, 114449. (<a href='https://doi.org/10.1016/j.knosys.2025.114449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.},
  archive      = {J_KBS},
  author       = {Owen Chaffard and Pablo Mollá and Marc Cavazza and Helmut Prendinger},
  doi          = {10.1016/j.knosys.2025.114449},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing large language models for bitcoin time series forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAT: Federated causal adversarial training. <em>KBS</em>, <em>330</em>, 114440. (<a href='https://doi.org/10.1016/j.knosys.2025.114440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference has been proven to be a crucial technique for improving the efficacy and explainability of adversarial training (AT). However, its applicability in the decentralized adversarial training paradigm has not been fully explored. Where one potential challenge is to apply the causal inference in the settings of non-independent and identically distributed (Non-IID) federated learning. In particular, the imbalanced data distributions among various clients will unavoidably hinder the efficacy and adaptability of causal inference. To address this issue, this paper proposes a novel yet practical method dubbed Federated Causal Adversarial Training (FCAT), which seeks to improve causal models via calibrated correction information. Additionally, we introduce a lightweight slack aggregation method aimed at addressing client model disparities and minimizing the communication overhead in each iteration. Extensive experimental results demonstrate that FCAT significantly improves the efficacy of causal models in federated adversarial training, and remarkably outperforms the current state-of-the-art (SOTA) competitors on multiple widely-adopted benchmarks.},
  archive      = {J_KBS},
  author       = {Yunhao Feng and Yanming Guo and Mingrui Lao and Yulun Wu and Yishan Li and Yuxiang Xie},
  doi          = {10.1016/j.knosys.2025.114440},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114440},
  shortjournal = {Knowl. Based Syst.},
  title        = {FCAT: Federated causal adversarial training},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem. <em>KBS</em>, <em>330</em>, 114439. (<a href='https://doi.org/10.1016/j.knosys.2025.114439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The polynomial robust knapsack problem (PRKP) is a variant of the classic knapsack problem by incorporating uncertain costs and benefits from item combinations, leading to a nonlinear objective function and exponential solution space. These complexities make the PRKP suitable for real-world scenarios where interactions between items unpredictably impact outcomes. However, existing algorithms struggle to efficiently solve large instances of the PRKP due to its computational complexity. Therefore, this paper presents an iterative heuristic algorithm leveraging a neural network (NN) to address the PRKP, reducing the solution space and enabling efficient resolution of subproblems. The framework integrates an NN trained in two steps: general training and fine-tuning. The trained model is then embedded in the iterative heuristic algorithm to tackle the PRKP. A synthetic dataset comprising 2500 instances, ranging from 100 to 1500 items, is created to train the NN. Comparative evaluations are conducted using 1600 benchmark instances from the literature and 140 larger instances containing between 2000 and 15,000 items. We compare our approach against two state-of-the-art algorithms for the PRKP: a genetic algorithm and a random forest-based heuristic. Computational results demonstrate that the proposed algorithm outperforms the genetic algorithm, providing superior solution quality with significantly reduced computing times. Meanwhile, against random forest-based heuristic, it delivers better solution quality with only a moderate increase in computing time. For larger instances, it maintains its advantage in solution quality while remaining computationally efficient. These results highlight the algorithm’s scalability, effectiveness, and potential to address the PRKP.},
  archive      = {J_KBS},
  author       = {José González-Cortés and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114439},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114439},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TWDT: Training-free word-level controllable diffusion model for text generation. <em>KBS</em>, <em>330</em>, 114437. (<a href='https://doi.org/10.1016/j.knosys.2025.114437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controlled text generation (CTG) methods typically require the training of additional components, whereas diffusion models have already achieved fine control in image generation by adjusting latent feature information during the inference process. However, existing diffusion models still face issues such as “attribute leakage” and “overgeneration” when applied to text generation, leading to generated texts lacking precise control. To address these problems, we propose a training-free word-level controllable diffusion language network (TWDT). This network achieves fine-grained control of text generation by adjusting latent space features during the inference process. Specifically, TWDT introduces an Alignment and Word Evaluation (AWE) module, which ensures accurate mapping of the text to a predefined set of feature words through syntactic segmentation and multi-level semantic alignment. At the same time, a similarity threshold filtering mechanism is applied to inject Gaussian noise into low-consistency nodes, ensuring semantic consistency and stability during generation. To evaluate the rigor and accuracy of the model, we have developed a high-quality multi-disease dental diagnostic dataset, all of which are annotated by experienced dental experts, serving as the benchmark for model evaluation. Experimental results show that TWDT outperforms existing diffusion models in terms of generation accuracy and rigor.},
  archive      = {J_KBS},
  author       = {Nan Gao and Yangjie Lu and Peng Chen and Guodao Sun and Ronghua Liang and Yilong Zhang},
  doi          = {10.1016/j.knosys.2025.114437},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114437},
  shortjournal = {Knowl. Based Syst.},
  title        = {TWDT: Training-free word-level controllable diffusion model for text generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network. <em>KBS</em>, <em>330</em>, 114436. (<a href='https://doi.org/10.1016/j.knosys.2025.114436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern vehicles depend on the Controller Area Network (CAN) for electronic control unit (ECU) communication, but its inherent vulnerabilities necessitate robust intrusion detection systems (IDS). Current machine learning and deep learning IDS solutions struggle with limited labeled data, class imbalances, and costly data collection processes. Few-shot learning, effective with few labeled samples, remains underexplored for in-vehicle networks (IVNs) despite its potential in data-scarce automotive cybersecurity scenarios. To bridge this gap, we introduce the first few-shot learning approach for multi-class intrusion detection in IVNs, leveraging a novel, lightweight Convolutional Anomaly Transformer. By integrating a 1D convolutional layer with an Anomaly Transformer, our model effectively classifies diverse attack types with minimal training data, mitigating class imbalance. Experiments on the widely-used real-world Car Hacking dataset, the complex ROAD dataset, and the distinct CAN-ML dataset validate its efficacy. On the Car Hacking dataset, we achieve an exceptional F1 score of 0.9994 with only 2 % of training data, improving to 0.9999 with 10 %. On the challenging ROAD dataset, characterized by diverse attacks and high variability, the model achieves an F1 score of up to 0.9980 using just 10 % of training data. Demonstrating strong generalization capabilities, the model also attains an impressive F1 score of 0.9918 on the CAN-ML dataset, which features entirely different vehicles and attack distributions. Furthermore, the lightweight architecture of our proposed IDS enables practical deployment in resource-constrained automotive environments.},
  archive      = {J_KBS},
  author       = {Nguyen Thanh Minh Duy and Truong Hoang Bao Huy and Pham Van Phu and Tien-Dat Le and Daehee Kim},
  doi          = {10.1016/j.knosys.2025.114436},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining. <em>KBS</em>, <em>330</em>, 114434. (<a href='https://doi.org/10.1016/j.knosys.2025.114434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have displayed their effectiveness in predicting sequence modelling compared to various systems. Nevertheless, some limitations of existing methods are the demand for enormous databases, computational expense, and the risk of overfitting. To address these problems, this study proposes a novel DL technique using knowledge distillation and sequence illness pattern recognition from medical databases. Firstly, the input data is pre-processed using the data cleaning method. The size of the sequence dataset and the duration of the sequential patterns are both considered during the process of using PREFIXSPAN to manage long sequential patterns. In the proposed strategy, a lightweight student network is employed to train a strong teacher network, which is produced by a Knowledge Distillation framework. A teacher network is assessed by the Attention Based Densely Connected Capsule Model (Attention-DC). An efficient, low-weight Depthwise Separable Convolutional Neural Network (DSCNN) model is then chosen as the student network. This study uses three datasets to solve enormous database issues. The KD helps prevent the student model from overfitting to noise or specific patterns in the training data. The Improved Coot Optimization Algorithm (ICOA) is applied to adjust the parameter. The hyperparameters used to optimize the performance of the proposed model are Epochs (300), learning rate (0.001), and batch size (32), respectively. The experiments use the resources of three different datasets, and Python is employed to analyze the results. The proposed technique achieves accuracy of 99.512 %, 99.329 % and 99.351 % for the heart disease, cardiovascular disease, and Diabetes dataset.},
  archive      = {J_KBS},
  author       = {Dinesh Kumar Bhawnani and Sunita Soni and Arpana Rawal},
  doi          = {10.1016/j.knosys.2025.114434},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural chain of thoughts for radiology education. <em>KBS</em>, <em>330</em>, 114433. (<a href='https://doi.org/10.1016/j.knosys.2025.114433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology education requires trainees to develop both perceptual and interpretive expertise. However, refinement of these skills is often impeded by the limited availability of mentorship, a consequence of the demanding schedules of experienced radiologists. This lack of personalized guidance makes it difficult for learners to recognize the mistakes they make, understand why those errors occurred and how to refine their perceptual processes. Many of these errors arise from subtle differences in visual attention, such as failing to fixate on an abnormality, allocating an insufficient fixation time, or overlooking an abnormality despite scanning the correct region. Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been explored for radiology tasks, they often struggle to detect such fine-grained multimodal variations, particularly when comparing gaze behavior between experts and trainees. To address these limitations, we introduce Structural Chain of Thoughts (SCoT), a novel framework that enhances LLMs and LMMs sensitivity to nuanced multimodal differences by structuring gaze data and radiology report into a thought graph. By leveraging a structural prior, SCoT systematically identifies key perceptual and interpretive discrepancies, allowing models to provide targeted, context-aware feedback. This structured approach not only highlights missed findings but also explains the reasoning behind perceptual errors, turning them into learning opportunities. Applied within radiology education, SCoT bridges the gap between expert and novice performance, offering a scalable solution for AI-driven diagnostic training. We further contribute a simulated dataset of perceptual errors in chest X-ray (CXR) interpretation, facilitating future research into multimodal reasoning and AI-driven medical education. Unlike conventional Chain-of-Thought approaches, SCoT explicitly integrates gaze and textual information into a structured reasoning process, yielding interpretable, fine-grained, and personalized feedback tailored to the unique needs of radiology training. The code and data will be available here: GitHub Repository .},
  archive      = {J_KBS},
  author       = {Akash Awasthi and Brandon Chung and Anh Mai Vu and Saba Khan and Ngan Le and Zhigang Deng and Rishi Agrawal and Carol C. Wu and Hien Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114433},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural chain of thoughts for radiology education},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing. <em>KBS</em>, <em>330</em>, 114431. (<a href='https://doi.org/10.1016/j.knosys.2025.114431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables the efficient execution of compute-intensive tasks by offloading them to edge servers. However, frequent user mobility in 5 G urban networks leads to increased latency, energy consumption, and resource wastage due to continuous handovers. To address these challenges, Energy Efficient Communication and Optimal Offloading Network, a framework is proposed that combines user mobility prediction and hybrid optimization for task offloading. Energy Efficient Communication and Optimal Offloading Network utilizes a modified Long Short-Term Memory model to predict user movement with high accuracy, achieving an accuracy improvement from 65 % to 95 % over ten iterations. Additionally, a Hybrid Grey Wolf Optimization Algorithm optimizes task allocation, resulting in a 30 % reduction in energy consumption and a 25 % improvement in server utilization compared to baseline methods. The framework achieves latency as low as 5 milliseconds for augmented reality tasks while maintaining scalability in high-traffic 5 G environments. The proposed model also outperforms baseline approaches in terms of task completion time, throughput, and communication efficiency, and it achieves a 94.5 % offloading success rate and 98 % augmented reality delay compliance. The proposed model provides a scalable and useful solution for real-time Augmented Reality by combining energy-constrained task allocation with mobility-aware predictions.},
  archive      = {J_KBS},
  author       = {Anitha Jebamani Soundararaj and Godfrey Winster Sathianesan},
  doi          = {10.1016/j.knosys.2025.114431},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified multi-subgraph pre-training framework for spatio-temporal graph. <em>KBS</em>, <em>330</em>, 114428. (<a href='https://doi.org/10.1016/j.knosys.2025.114428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph (STG) learning has shown great potential in capturing complex spatio-temporal dependencies and has achieved significant success in various fields such as traffic flow prediction, climate forecasting, and epidemiological spread research. By learning general features from spatio-temporal graphs, pre-trained graph models can capture hidden semantic information in the data, thereby enhancing the learning effect of downstream tasks and improving overall model performance. However, most existing spatio-temporal graph learning methods use the entire graph for training, which may not fully capture local structure and feature information. In addition, existing methods usually adopt sequence modeling techniques without fully considering the time decay effect, i.e., the need to apply decaying attention to distant time steps. To address these issues, this paper proposes a u nified dual-phase m ulti- s ubgraph pre-training s patio- t emporal graph framework (UMSST). Specifically, in the first phase, the framework learns the global representation of the spatio-temporal graph and locates key graph nodes, while learning the “unit representations” of these key nodes. In the second phase, multiple spatio-temporal subgraphs are constructed based on these “unit representations” to further capture the implicit encoding information of more general features around the corresponding subgraphs, thereby helping the model make full use of general features. Experimental results on real datasets show that the proposed pre-trained spatio-temporal graph framework significantly improves the performance of downstream tasks and demonstrates its effectiveness in comparison with recent strong baseline models.},
  archive      = {J_KBS},
  author       = {Mingze Zhong and Zexuan Long and Xinglei Wang and Tao Cheng and Meng Fang and Ling Chen},
  doi          = {10.1016/j.knosys.2025.114428},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114428},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified multi-subgraph pre-training framework for spatio-temporal graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provide explainable clues: A generative traceable method for knowledge graph completion. <em>KBS</em>, <em>330</em>, 114426. (<a href='https://doi.org/10.1016/j.knosys.2025.114426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a G enerative T raceable M ethod, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.},
  archive      = {J_KBS},
  author       = {Ziqi Ma and Jinpeng Li and Hang Yu},
  doi          = {10.1016/j.knosys.2025.114426},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114426},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provide explainable clues: A generative traceable method for knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRTF: A new tensor factorization for irregular multidimensional data recovery. <em>KBS</em>, <em>330</em>, 114372. (<a href='https://doi.org/10.1016/j.knosys.2025.114372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorizations, although serving as paramount tools for exploiting prior knowledge of multidimensional data, are unsuitable for emerging irregular multidimensional data with the arbitrary shape spatial domain (i.e., spatial-irregular tensor), such as superpixels and spatial transcriptomics. Developing new tensor factorizations suitable for spatial-irregular tensors poses a compelling challenge. To meet this challenge, we introduce a novel Irregular Tensor Factorization (IRTF), which can fully capture the intrinsic spatial and channel information behind the spatial-irregular tensor. Concretely, a spatial-irregular tensor can be decomposed into the product of an intrinsic regular tensor, learnable channel transform matrices, and a learnable spatial transform matrix. Accompanying IRTF, we suggest the Total Variation on Channel and Spatial Transforms (TV-CST) to exploit the local information of spatial-irregular tensors, which is hardly excavated by traditional total variation methods. Combining the proposed IRTF and TV-CST, we built a spatial-irregular tensor recovery model. Extensive experiments on real-world spatial-irregular tensors demonstrate the promising performance of our IRTF and its significant advantages on downstream tasks.},
  archive      = {J_KBS},
  author       = {Jin-Yu Xie and Hao Zhang and Xi-Le Zhao and Yi-Si Luo},
  doi          = {10.1016/j.knosys.2025.114372},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114372},
  shortjournal = {Knowl. Based Syst.},
  title        = {IRTF: A new tensor factorization for irregular multidimensional data recovery},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-driven deep learning network for image splicing forgery detection. <em>KBS</em>, <em>330</em>, 114365. (<a href='https://doi.org/10.1016/j.knosys.2025.114365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image splicing is a widely used technique for manipulating images in various social activities. Detecting splicing forgery is crucial in digital forensics to identify malicious image manipulation and protect information security. However, existing methods for detecting splicing forgery typically learn features in the spatial domain and struggle to effectively capture subtle features indicative of forgery, resulting in insufficient image splicing forgery detection accuracy. To address this challenge, we propose a novel deep-learning network named the frequency-driven deep-learning network (FreNet). Specifically, FreNet comprises three innovative modules: the frequency learnable module (FLM), the spatial-aware frequency learning module (SFLM), and the high-level feature-enhancement module (HFEM). The FLM effectively extracts high- and low-frequency features, thus enhancing frequency-domain representation and capturing subtle tampered features in splicing forgery images. The SFLM utilizes spatial information to guide frequency feature learning, thus enabling spatial-aware frequency feature learning. The HFEM enhances rich contextual and high-level semantic information through multilevel and multipath extraction and fusion. Extensive experiments on five benchmark datasets indicate that FreNet can achieve superior performance. Additionally, robustness experiments demonstrate the superior robustness of FreNet against various common attacks.},
  archive      = {J_KBS},
  author       = {Enji Liang and Kuiyuan Zhang and Zhongyun Hua and Xiaohua Jia},
  doi          = {10.1016/j.knosys.2025.114365},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114365},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-driven deep learning network for image splicing forgery detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="matdes">MATDES - 39</h2>
<ul>
<li><details>
<summary>
(2025). Unveiling the SLM process-structure-property relationship of a moderate mg content al-mg-si-sc-zr-mn alloy. <em>MATDES</em>, <em>259</em>, 114787. (<a href='https://doi.org/10.1016/j.matdes.2025.114787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selective Laser Melting (SLM) holds great promise for fabricating high-precision aluminum alloy components with complex geometries and lightweight structures. However, producing high-strength aluminum alloys with excellent mechanical properties remains hindered by poor printability and complex microstructural control. In this study, an Al-4.79 Mg-1.3Si-0.51Sc-0.27Zr-0.47Mn (wt.%) alloy was developed and processed via SLM. The SLM process-structure-property relationship of this alloy was investigated. Crack-free samples were achieved across a broad process window, indicating excellent crack resistance and adaptability. Good printability and high relative density over 99.5 % can be achieved at a laser power of 200-230 W and scanning speed of 1050 and 1150 mm/s, corresponding to a volumetric energy density (VED) of 60 J/mm 3 -73 J/mm 3 . The increase in the laser energy density promoted the formation of columnar grains and the widening of subgrain structures, and made the Mg 2 Si phase transformed from continuous to discontinuous morphology. The as-printed alloy exhibited 439 MPa tensile strength and 11.3 % elongation, attributed to grain refinement, reduced porosity, and the formation of the high dislocation density, 9R phase, and nanotwin. After aging, strength increased to 483 MPa and elongation decreased to 6.5 %. This study defines the process window and demonstrates a balance between high specific strength and cost efficiency.},
  archive      = {J_MATDES},
  author       = {Rui Liu and Junquan Yu and Wenyou Zhang and Xiebin Wang and Jun Lin and Guoqun Zhao},
  doi          = {10.1016/j.matdes.2025.114787},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114787},
  shortjournal = {Mater. Des.},
  title        = {Unveiling the SLM process-structure-property relationship of a moderate mg content al-mg-si-sc-zr-mn alloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards understanding the design principle and rotation deformation mechanics of 3D chiral NPR structure with tunable mechanical responses. <em>MATDES</em>, <em>259</em>, 114784. (<a href='https://doi.org/10.1016/j.matdes.2025.114784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an innovative three-dimensional Negative Poisson’s ratio (NPR) chiral structure was designed based on a 2D staggered rib architecture. This design integrates horizontally oriented chiral alternating ribs and vertically oriented Z-shaped configurations. Two optimized architectures, namely the wave-optimized structure (W-NPR) and the node-enhanced structure (N-NPR), were proposed and compared with the original folded structure (F-NPR). Characterization analysis revealed that the N-NPR structure exhibited superior formability, making it suitable for Digital Light Processing (DLP) fabrication. A parametric study on the mechanical performance of the N-NPR structure demonstrated that an increased volume fraction enhances the mechanical properties at the expense of structural compliance. Uniaxial tensile testing along the XY-plane and Z-axis confirmed the anisotropic Young’s modulus. Experimental and finite element simulations further revealed anisotropic behavior and a unique two-stage rotation-torsion compressive deformation mechanism of N-NPR, which enables advanced mechanical designs by enhancing the degree of freedom for deformation mode conversion. This work proposes a novel method for designing 3D NPR structures and elucidates its mechanical deformation mechanism, enabling transformative advances in aerospace, personalized healthcare, and adaptive wearable technologies.},
  archive      = {J_MATDES},
  author       = {Ruiqi Pan and Ruiying Luo and Wei Xiong and Qiaoyu Chen and Jiafeng Wu and Chunze Yan and Liang Hao and Jie Yin and Zheng Li and Ronghong Zhang and Lei Yang and Yan Li},
  doi          = {10.1016/j.matdes.2025.114784},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114784},
  shortjournal = {Mater. Des.},
  title        = {Towards understanding the design principle and rotation deformation mechanics of 3D chiral NPR structure with tunable mechanical responses},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of irradiation temperature on the microstructure and hardness of W-0.3Cr alloy after irradiation with 6.4 MeV fe ions. <em>MATDES</em>, <em>259</em>, 114783. (<a href='https://doi.org/10.1016/j.matdes.2025.114783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The W-0.3 at.% Cr alloy samples were irradiated with 6.4 MeV Fe ions at 773, 1073 and 1273 K, and the damage peak was 0.26 dpa. The evolution of the microstructure, defects, and hardness was investigated using grazing-incidence X-ray diffraction (GIXRD), transmission electron microscopy (TEM) and nanoindentation tests. The GIXRD results showed that diffraction peaks shifted towards lower 2θ values, indicating that lattice swelling was caused by irradiation-induced defects after irradiation at elevated temperatures. According to the TEM observations, the size of the dislocation loops remained nearly constant, while their number density decreased with an increase in irradiation temperature. The precipitation of Cr was not observed in the W-0.3Cr alloy after irradiation at 773 K. In contrast, it was significant in the samples irradiated at temperatures of 1073 and 1273 K, showing increases in both the size and number density of the precipitates. Irradiation hardening was observed in all samples, primarily attributed to the presence of dislocation loops. The hardness change was estimated with the dispersion barrier hardening model by taking into account the contributions of dislocation loops and Cr precipitates. The values evaluated with the model were significantly larger than those obtained with the nanoindentation tests. This difference was ascribed to the depletion of solute Cr atoms from the W matrix by precipitation.},
  archive      = {J_MATDES},
  author       = {Jing Wang and Jingxian Sun and Yingying Jia and Yifan Zhang and Yuji Hatano and Diancheng Geng and Katsuya Suzuki and Chang Chen and Laima Luo and Kiyohiro Yabuuchi and Ryuta Kasada},
  doi          = {10.1016/j.matdes.2025.114783},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114783},
  shortjournal = {Mater. Des.},
  title        = {Effect of irradiation temperature on the microstructure and hardness of W-0.3Cr alloy after irradiation with 6.4 MeV fe ions},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel in-situ gas-phase alloying approach in wire arc additive manufacturing for controlling solidification mode and designing hybrid stainless steels. <em>MATDES</em>, <em>259</em>, 114781. (<a href='https://doi.org/10.1016/j.matdes.2025.114781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a thermodynamically guided in-situ gas-phase alloying approach in wire arc additive manufacturing (WAAM) to enhance duplex stainless steels by shifting the primary solidification mode from δ-ferrite to γ-austenite, producing a nitrogen-enriched alloy with a continuous austenitic matrix that combines duplex-grade strength with superior ductility. Thermodynamic calculations guided nitrogen adjustment in the shielding gas to control solidification and develop high-performance microstructures. Thermodynamic–kinetic modeling predicted nitrogen uptake from the arc plasma, enabling gas composition selection to promote a shift from δ-ferrite to γ-austenite as the primary solidification phase. Nitrogen content analysis and Scheil simulations confirmed a transition to austenite-first solidification at approximately 0.7 wt% nitrogen. Electron Backscatter Diffraction and optical microscopy revealed that nitrogen-enriched (HN) samples exhibited a continuous γ-austenitic matrix with finely dispersed δ-ferrite, whereas nitrogen-lean (LN) samples had a δ-ferritic matrix with isolated γ-austenite islands. HN samples showed greater grain orientation spread, indicating increased internal misorientation. Despite pronounced crystallographic texture, the HN samples demonstrated nearly isotropic tensile behavior along with enhanced yield strength, tensile strength, ∼11 % higher hardness, and improved elongation. These findings demonstrate that melt chemistry control via gas-phase alloying enables phase-engineered microstructures with superior mechanical performance without modifying the filler wire.},
  archive      = {J_MATDES},
  author       = {Elina Akbarzadeh Chiniforoush and Mohammad Reza Jandaghi and Johan Moverare and Tohid Saeid and Koray Yurtışık},
  doi          = {10.1016/j.matdes.2025.114781},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114781},
  shortjournal = {Mater. Des.},
  title        = {A novel in-situ gas-phase alloying approach in wire arc additive manufacturing for controlling solidification mode and designing hybrid stainless steels},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influencing the draping behaviour of solid epoxy prepregs by applying 3D-printed resin patterns. <em>MATDES</em>, <em>259</em>, 114780. (<a href='https://doi.org/10.1016/j.matdes.2025.114780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel strategy to overcome the limitations of solid resin prepregs (SRPs) − namely the inability to drape at room temperature and hindered gas evacuation during vacuum-bag-only (VBO) processing − by 3D-printing a regular, uncured solid epoxy resin (SR) pattern on a dry woven textile. The locally patterned resin distribution preserves dry textile regions, enabling room temperature drapeability and more robust VBO-processing due to improved gas evacuation. By adjusting pattern parameters such as element geometry and coverage, the draping behaviour can be controlled to adapt to a desired draping condition. In order to be able to design the right pattern for given draping conditions, the influence of these parameters on bending and shearing was studied. Manual draping showed that bending radii down to 4 mm were achievable, governed only by the element length in bending direction, while coverage had no significant effect. In contrast, picture-frame-tests showed that the shearing is mainly influenced by the coverage and that a maximal shearing angle of 30° can be achieved. These results show that the SRPs bending and shearing can be independently influenced through pattern design. The derived structure–drapeability relationships enable targeted design of SRPs for robust, autoclave-free composite manufacturing.},
  archive      = {J_MATDES},
  author       = {Jan Philipp Janzen and Hendrik Schäfer and Murat Çelik and Colin Robert and Conchúr M. Ó Brádaigh and David May and Thomas Neumeyer},
  doi          = {10.1016/j.matdes.2025.114780},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114780},
  shortjournal = {Mater. Des.},
  title        = {Influencing the draping behaviour of solid epoxy prepregs by applying 3D-printed resin patterns},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser powder bed fusion of pure silver sputtering target: Process, microstructure, and sputtering performance. <em>MATDES</em>, <em>259</em>, 114779. (<a href='https://doi.org/10.1016/j.matdes.2025.114779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silver (Ag) sputtering targets are crucial in electronic information materials, particularly with the rapid advancement of Artificial Intelligence (AI), which has further increased their demand. However, the extremely high reflectivity and poor laser absorption of pure Ag in the infrared range make it challenging to process using conventional laser-based Additive Manufacturing (AM) systems, limiting its wide application. In this study, a novel hatch spacing-to-scanning speed ratio ( h / v )-centered low-energy–density strategy was proposed to overcome this challenge and enable high-quality additive manufacturing of pure Ag. By optimizing the ( h / v ) value to 1.0E-04, we successfully fabricated dense, low-defect Ag sputtering targets without increasing energy input. The results demonstrated that this method significantly shortened the manufacturing cycle and produced high-performance Ag targets with refined grains (3–7 μm), high density (≥99.8 %), a smooth surface (Ra = 11.5 μm), and stable sputtering performance (sputtering rate = 31.8 nm/min). Furthermore, the hardness increased by 45.1 % compared to Ag targets prepared by traditional methods. This work offers a practical pathway for applying laser-based AM in the production of highly reflective metal sputtering targets, advancing their industrialization in thin-film electronics, while also contributing to the understanding of AM process–structure relationships in metallic materials.},
  archive      = {J_MATDES},
  author       = {Zheda Ning and Yipei He and Qi Tang and Yunxiu Chao and Yue Shen and Haozhang Zhong and Ming Wen and Jianfeng Gu},
  doi          = {10.1016/j.matdes.2025.114779},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114779},
  shortjournal = {Mater. Des.},
  title        = {Laser powder bed fusion of pure silver sputtering target: Process, microstructure, and sputtering performance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the performance of organic photodetectors by low-temperature electron beam annealing. <em>MATDES</em>, <em>259</em>, 114778. (<a href='https://doi.org/10.1016/j.matdes.2025.114778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organic photodetectors (OPDs) are promising candidates for next-generation optoelectronic devices due to their flexibility, low cost, and scalability. Enhancing OPD performance requires optimizing key layers such as the electron transport layer (ETL) using low-temperature processes to prevent thermal degradation. This study explores the use of low-temperature electron beam annealing (EBA) to improve the performance of Al-doped ZnO (AZO)-based ETLs. The impact of EBA irradiation time (1–8 min) on the structural, morphological, and electrical properties of AZO films was systematically analyzed. EBA effectively modulated oxygen vacancies and reduced surface roughness, lowering trap density and leakage current while enhancing charge transport. An OPD with an ETL treated by 8 min of EBA exhibited superior detectivity (2.22 × 10 13 Jones at 0 V) and significantly reduced leakage current compared to a device with conventionally annealed ETLs. Importantly, the low-temperature EBA process preserved the amorphous state of AZO, making it suitable for heat-sensitive and flexible substrates. These findings demonstrate that EBA is a powerful, scalable method for ETL optimization in OPDs and offers a pathway toward high-performance, energy-efficient, and flexible optoelectronic devices.},
  archive      = {J_MATDES},
  author       = {Jaebum Jeong and Gun woong Kim and Eun Jin Park and Seong Woo Jeong and Seok Hwan Jang and Jae Yeong Jeong and Soo Won Heo and Jun Young Kim},
  doi          = {10.1016/j.matdes.2025.114778},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114778},
  shortjournal = {Mater. Des.},
  title        = {Improving the performance of organic photodetectors by low-temperature electron beam annealing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable biopolymer design: Extraction of chitin and chitosan using natural deep eutectic solvents with improved antibacterial features. <em>MATDES</em>, <em>259</em>, 114775. (<a href='https://doi.org/10.1016/j.matdes.2025.114775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of biopolymers using natural deep eutectic solvents (NADES) offers a promising approach for developing sustainable and biocompatible materials for biomedical applications. In this study, a novel and environmentally friendly process has been developed for extracting chitin and chitosan from organic Agaricus bisporus ( A. bisporus ) mushrooms, which serves as a readily available and renewable resource. NADES not only enhances the extraction efficiency but also preserves the structural integrity of the biopolymers. The characteristics of these biopolymers were analyzed by X-ray diffraction (XRD), Fourier transform infrared spectroscopy (FT-IR), thermogravimetric (DTG/TGA) analysis, scanning electron microscopy (SEM), atomic force microscopy (AFM), and nuclear magnetic resonance ( 1 H NMR) techniques. By optimizing the NADES extraction conditions, high-purity chitin (98.58 %) and chitosan (98.69 %) were achieved, surpassing the purity levels achieved by traditional chemical methods. NADES-extracted chitosan exhibited a remarkable degree of deacetylation (DD) of up to 94.22 %, and a crystallinity index (CrI) of up to 61.77 %, highlighting its enhanced functionality for biomedical applications. Moreover, the NADES-derived biopolymers showed excellent biocompatibility with L929 fibroblast cells. They exhibited dose-dependent antibacterial activity against Staphylococcus aureus (S. aureus) and Escherichia coli (E. coli) and exhibited promising antioxidant and biodegradability properties.},
  archive      = {J_MATDES},
  author       = {Issam Thamer and Magdalena Mazurek-Budzyńska and Vignesh Kumaravel},
  doi          = {10.1016/j.matdes.2025.114775},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114775},
  shortjournal = {Mater. Des.},
  title        = {Sustainable biopolymer design: Extraction of chitin and chitosan using natural deep eutectic solvents with improved antibacterial features},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic effect of interfacial silane film and laser texturing on joining characteristics of pretreated Al/CFRTP friction stir welded joints. <em>MATDES</em>, <em>259</em>, 114774. (<a href='https://doi.org/10.1016/j.matdes.2025.114774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by lightweight requirements in the low-altitude economy, a synergistic laser ablation‒silane coupling process was developed to optimize friction stir welded joints between Al alloys and carbon fiber-reinforced thermoplastics (CFRTPs), with a focus on elucidating the sequence-dependent gradient interfacial joining mechanism. A sequence involving silane coupling prior to laser ablation was employed, enabling dual-mode enhancement of the interfacial geometric configuration and chemical bonding. Mechanical interlocking was ensured in laser-ablated zones, whereas the chemical bonding capacity in unablated regions was enhanced. The tensile–shear strength and cross-tension strength of the joints were measured at 32.6 MPa and 3.2 MPa, respectively. Detailed microstructural characterization revealed that mechanical interlocking occurred in the laser-ablated zones of the PA66 resin and that synergistic physicochemical reinforcement was achieved via covalent Al‒O‒Si bonds coupled with molecular chain entanglement/hydrogen bonding in unablated regions. Defect-free continuous interfacial transitions were confirmed through the penetration of nanolamellar structures by amorphous silane films. This synergistic strategy provides new insights for the high-performance joining of dissimilar metal and polymer materials.},
  archive      = {J_MATDES},
  author       = {Suyu Wang and Wenquan Wang and Yuhua Chen and Xinge Zhang and Shanlin Wang and Timing Zhang and Yuxin Xu},
  doi          = {10.1016/j.matdes.2025.114774},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114774},
  shortjournal = {Mater. Des.},
  title        = {Synergistic effect of interfacial silane film and laser texturing on joining characteristics of pretreated Al/CFRTP friction stir welded joints},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microcellular TLCP/SiO2 for high-frequency communication design. <em>MATDES</em>, <em>259</em>, 114772. (<a href='https://doi.org/10.1016/j.matdes.2025.114772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of high-frequency and high-speed communication technologies, especially in microwave/millimeter-wave applications, electronic devices face increased performance demands. Developing low dielectric materials with exceptional properties for these devices has become a significant challenge. Thermotropic liquid crystal polymers (TLCP) are promising due to their excellent high-frequency performance, while microcellular foaming technology is commonly used to enhance dielectric properties. In this study, TLCP was modified with ADR and nano-SiO 2 . The synergistic modification introduces long-chain branched structures and nucleation sites, improving matrix performance and optimizing foaming behavior. In addition, long-chain branched TLCP/SiO 2 foam has highly compressive properties, excellent dimensional stability, ultra-low dielectric stability at high frequencies, great flame retardant and wonderful high-temperature infrared thermal stealth performance. It is also found by simulation that the patch antenna with long-chain branched TLCP/SiO 2 foam substrate has excellent signal transmission performance. The transmission distance up to 4793 m, which is 5.8 times higher than pure TLCP before foaming, which presents a novel solution for high-frequency and high-speed communication. Furthermore, the long-chain branched TLCP/SiO 2 foams with significant performance is expected to be used in sophisticated technology fields such as wide-ranging applications in military, extreme conditions, aviation, microelectronic and other fields.},
  archive      = {J_MATDES},
  author       = {Jiayang Sun and Wenyu Zhong and Yichong Chen and Kuikui Fan and Dongdong Hu and Zhenhao Xi and Tao Gu and Ling Zhao},
  doi          = {10.1016/j.matdes.2025.114772},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114772},
  shortjournal = {Mater. Des.},
  title        = {Microcellular TLCP/SiO2 for high-frequency communication design},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent progress of manipulating microenvironment for spinal cord injury therapy using nanoparticles. <em>MATDES</em>, <em>259</em>, 114769. (<a href='https://doi.org/10.1016/j.matdes.2025.114769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spinal cord injury (SCI) is a severe traumatic condition that profoundly compromises patients’ health and quality of life. While various therapeutic strategies, including pharmacotherapy, have been developed and demonstrate some efficacy, however their clinical application is significantly limited by challenges, such as low drug bioavailability and undesirable side effects. Moreover, a critical limitation is their frequently neglect the SCI microenvironment, which serves as the essential foundation for nerve regeneration. In contrast, intelligent nanoparticles-based delivery systems, owing to their excellent biocompatibility and high drug-loading capacity, they can modulate the SCI microenvironment on demand, hold great promise for improving SCI therapy. However, how to design intelligent nanoparticles to achieve precise microenvironment regulation for SCI therapy is still lack of a systematic summary. Therefore, this review summarizes recent advances in advances in modulating the microenvironment for treating SCI using targeted nano drug delivery system, hope provide a theoretical basis for the further development of nano-drug to treatment of SCI.},
  archive      = {J_MATDES},
  author       = {Linfeng Xiao and Chunping Tian and Yinshan Hong and Jiajun Wu and Jiani Du and Yanling Yang and Xiaowei Chang},
  doi          = {10.1016/j.matdes.2025.114769},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114769},
  shortjournal = {Mater. Des.},
  title        = {Recent progress of manipulating microenvironment for spinal cord injury therapy using nanoparticles},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances and challenges of targeted protein degradation in ophthalmology: Future directions and therapeutic potential. <em>MATDES</em>, <em>259</em>, 114767. (<a href='https://doi.org/10.1016/j.matdes.2025.114767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of targeted protein degradation technologies, particularly proteolysis-targeting chimeras (PROTACs) and lysosome-targeting chimeras (LYTACs), is poised to revolutionize therapeutic strategies in ophthalmology. This review presents the first systematic analysis of these protein degradation platforms to address ’undruggable’ targets in ocular pathologies. Harnessing distinct cellular machinery through the engagement of the ubiquitin–proteasome system and the lysosomal pathway with PROTACs and LYTACs, respectively, these heterobifunctional molecules enable the targeted elimination of disease-driving proteins implicated in ocular surface diseases, such as dry eye, and fundus diseases, including age-related macular degeneration, diabetic retinopathy, and glaucoma. We review the mechanistic basis of these technologies, their translational potential in overcoming the limitations of conventional therapies, and ocular-specific challenges such as optimizing bioavailability and intraocular target selectivity. Central to this discussion is the role of advanced linker engineering in achieving spatio-temporal control of degradation activity. While barriers to ocular biodistribution and sustained delivery remain, targeted protein degradation represents a paradigm shift in ophthalmology, offering durable therapeutic effects that could significantly improve clinical outcomes and patient compliance through reduced dosing frequency.},
  archive      = {J_MATDES},
  author       = {Ke Feng and Mingyan Wei and Panqin Ma and Jiaoyue Hu and Caihong Huang and Yi Han and Zuguo Liu},
  doi          = {10.1016/j.matdes.2025.114767},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114767},
  shortjournal = {Mater. Des.},
  title        = {Advances and challenges of targeted protein degradation in ophthalmology: Future directions and therapeutic potential},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bioactive nerve conduit enhance peripheral nerve regeneration through dual functions of ion-regulated dedifferentiation and particle-anchored migration. <em>MATDES</em>, <em>259</em>, 114764. (<a href='https://doi.org/10.1016/j.matdes.2025.114764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The regeneration of long-segment peripheral nerve defects remains a critical and challenging clinical problem. The key step in nerve regeneration involves the dedifferentiation of Schwann cells into a repair phenotype, followed by their orderly migration to form Büngner bands that guide axonal elongation. However, due to the lack of bioactive factors for stimulation, the repair of current nerve conduits is generally slow. In this study, we designed a bioactive glass microspheres-embedded nerve conduit. The ions released from these microspheres activate c-Jun to induce Schwann cell dedifferentiation. Meanwhile, the microspheres coated onto the conduit surface provide physical anchoring sites, which accelerate integrin- β 1-mediated Schwann cell adhesion and orderly migration to facilitate Büngner bands assembly. This study confirms that dual-function bioactive glass microspheres promote nerve regeneration through ion-regulated dedifferentiation and particle-anchored migration, offering a novel approach for the design of nerve conduits.},
  archive      = {J_MATDES},
  author       = {Haohui Huang and Shijing Xu and Yulian Yang and Yonghao Qiu and Yujuan Liu and Xiaofeng Chen and Huichang Gao and Fujian Zhao},
  doi          = {10.1016/j.matdes.2025.114764},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114764},
  shortjournal = {Mater. Des.},
  title        = {Bioactive nerve conduit enhance peripheral nerve regeneration through dual functions of ion-regulated dedifferentiation and particle-anchored migration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of dielectric properties, radiation shielding, and electrical resistivity of alkali-activated blast furnace slag and portland cement binders. <em>MATDES</em>, <em>259</em>, 114763. (<a href='https://doi.org/10.1016/j.matdes.2025.114763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alkali-activated materials (AAMs) are increasingly explored for sustainable construction, yet their electromagnetic and radiation-related properties remain largely unknown. This study explored the radio wave propagation, gamma-ray shielding efficiency, and electrical resistivity of alkali-activated blast furnace slag (BFS-AAM) compared to hydrated Portland cement (PC). BFS-AAM demonstrated superior relative permittivity (ε r ≈ 7.6 at 2.4 GHz) and loss tangent (∼0.33) at lower radio frequencies (0.02–10 GHz), leading to enhanced signal attenuation compared to PC (ε r ≈ 5.6, loss tangent ≈ 0.07). BFS-AAM showed similar performance to PC at frequencies between 10–20 GHz, while its characteristics below 10 GHz make it suitable for secure signal environments. In terahertz spectrum (0.2–2 THz), relevant for 6G wireless communication, both materials displayed comparable permittivity (∼5.3 and ∼4.2) and loss tangent (∼0.09 and ∼0.04), indicating compatibility with residential and commercial applications. Simulations at 0.7, 2.4, and 6.0 GHz confirmed higher signal attenuation by BFS-AAM. Additionally, BFS-AAM exhibited higher resistivity (26–110 Ω·m), greater compressive strength (60 MPa), and lower porosity (∼11 %), contributing to its favorable dielectric properties. Although BFS-AAM demonstrated slightly lower gamma-ray shielding efficiency (at 0.661 MeV) than PC, its multifunctional properties position it as promising material for advanced electromagnetic and radiation shielding technologies.},
  archive      = {J_MATDES},
  author       = {Mehedi Rabbil and Mikko Kokkonen and Elijah Adesanya and Otto Mankinen and Mohammad Bhuyan and Sherif Hegazy and Sami Myllymäki and Juho Yliniemi and Tero Luukkonen},
  doi          = {10.1016/j.matdes.2025.114763},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114763},
  shortjournal = {Mater. Des.},
  title        = {Comparison of dielectric properties, radiation shielding, and electrical resistivity of alkali-activated blast furnace slag and portland cement binders},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of γ′ phase on the microstructural evolution and compressive properties of ni-based single crystal superalloys. <em>MATDES</em>, <em>259</em>, 114760. (<a href='https://doi.org/10.1016/j.matdes.2025.114760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate the evaluation and prediction of hot-end component performance, scanning electron microscopy and quasi-static compression tests were carried out on Ni-based single crystal superalloys, and the influence of γ′ phase on microstructural evolution and compressive properties was systematically investigated. Results show that γ′ phases exhibit spherical, cubic, or lath-like morphologies, and their average size increases from ∼ 180  nm to ∼ 450  nm after thermal exposure; and superalloys with higher volume fraction of γ′ phase gradually precipitate topologically close-packed (TCP) phase. The compressive properties display pronounced anisotropy, governed by both microstructure and loading direction. For superalloys with lower volume fraction of γ′ phase, yield strength decreases from 670  MPa to 505 MPa and ultimate compressive strength from 4690  MPa to 4240 MPa as the γ′ phase coarsens. In contrast, for superalloys with higher volume fraction of γ′ phase, ultimate compressive strength initially decreases and then increases, accompanied by rise in failure strain from 22 % to 46 % after thermal exposure. With increasing loading angle, ultimate compressive strength initially decreases and then rises, whereas yield strength, failure strain and hardening modulus exhibit more complex trends. These variations are closely related to γ′ and TCP phase, and microstructure and loading direction collectively affect mechanical behavior.},
  archive      = {J_MATDES},
  author       = {Shunyong Zhang and Bin Zhang and Fengpeng Zhao and Jicheng Li and Dong Jia and Xicheng Huang},
  doi          = {10.1016/j.matdes.2025.114760},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114760},
  shortjournal = {Mater. Des.},
  title        = {Influence of γ′ phase on the microstructural evolution and compressive properties of ni-based single crystal superalloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-assembly of bortezomib nanofibers for solid tumor and bone metastasis therapy. <em>MATDES</em>, <em>259</em>, 114758. (<a href='https://doi.org/10.1016/j.matdes.2025.114758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome challenges including insufficient drug loading capacity, limited targeting accuracy, and the complex preparation of conventional nanomedicine, self-assembled nanomaterials have emerged as a viable solution. To explore the peptide self-assembly theory and overcome limitations, this study used bortezomib (BTZ) as the base material, and a novel peptide self-assembly strategy utilizing Zn(II) coordination was employed to prepare cancer cell-targeting nanofiber drugs (cRGD-BTZNDs). The therapeutic efficacy was evaluated in different types of tumors. The results demonstrated that cRGD-BTZNDs effectively entered cancer cells and exhibited enhanced cytotoxic effects against cancer cells compared to BTZ. Moreover, cRGD-BTZNDs exhibited excellent therapeutic efficacy against solid tumors, significantly inhibiting 4 T1 tumor growth while reducing biological toxicity. Additionally, in the treatment of bone metastases, cRGD-BTZNDs demonstrated excellent therapeutic potency, effectively alleviating bone damage in mice with high biocompatibility. This study not only self-assembled nanomaterials with great potential in cancer therapy, but also affirmed the correctness and universality of the Zn(II) coordination peptide self-assembly theory, providing a theoretical basis for the improvement of peptide-based nanomedicine.},
  archive      = {J_MATDES},
  author       = {Dongjie Fu and Yuerong Wang and Jiaqi Xuan and Dingchang Liu and Jiawei Zhao and Yang Lei and Tianwen Xi and Hui Yang and Leming Sun},
  doi          = {10.1016/j.matdes.2025.114758},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114758},
  shortjournal = {Mater. Des.},
  title        = {Self-assembly of bortezomib nanofibers for solid tumor and bone metastasis therapy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming the challenges of fusion-based brass additive manufacturing through solid-state additive friction-stir deposition. <em>MATDES</em>, <em>259</em>, 114756. (<a href='https://doi.org/10.1016/j.matdes.2025.114756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing Cu-Zn alloys (brass) using fusion-based additive manufacturing (AM) techniques presents significant challenges due to volatile elements and the inherently high thermal conductivity of these alloys. Addressing these issues often demands increased energy input, modifications to laser systems, and compositional adjustments to mitigate zinc loss. However, such solutions are complex and remain in the early stages of development. In contrast, Additive friction stir deposition (AFSD), a solid-state AM technique, offers a promising alternative to overcome these limitations. This study represents a pioneering effort to deposit dual-phase brass (Cu-40Zn) using a closed-loop temperature-controlled AFSD. The influence of processing temperature (ranging from 0.38 to 0.61 T p /T m ) on microstructural evolution and mechanical performance was systematically investigated along the build and longitudinal direction. The resulting microstructure was predominantly governed by dynamic recrystallization and post-dynamic recrystallization (P-DRX) due to repeated thermal cycles. The as-deposited brass exhibited a balanced strength-ductility combination, with yield strength ranging from 215 to 437 MPa and elongation from 34 % to 67 %. Tensile properties in longitudinal and build directions revealed that grain boundary strengthening was the primary mechanism for improving the mechanical performance. The as-deposited properties were comparable to those of wrought counterparts, thus highlighting the potential of AFSD for fabricating high-performance brass components.},
  archive      = {J_MATDES},
  author       = {Meet Gor and Matthew Barnett and Pinaki Bhattacharjee and Daniel Fabijanic},
  doi          = {10.1016/j.matdes.2025.114756},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114756},
  shortjournal = {Mater. Des.},
  title        = {Overcoming the challenges of fusion-based brass additive manufacturing through solid-state additive friction-stir deposition},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-temperature viscoelastic mechanism for SiC fibers to elucidate creep and recovery behaviors. <em>MATDES</em>, <em>259</em>, 114755. (<a href='https://doi.org/10.1016/j.matdes.2025.114755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mastering the high-temperature creep behavior of SiC fibers plays pivotal role in designing reinforced ceramic matrix composites. Creep viscoelastic behavior is activated at higher temperatures due to complicated interactive coordination between grain interiors and grain boundaries. This study investigated the tensile creep behaviors at different generations of SiC fibers under conditions of various stress and temperatures. The creep recovery behaviors after unloading exhibits the viscoelastic nature, which comes from the possible motion of amorphous phase near massive grain boundaries. It is driven by the release of elastic energy of the grain boundary, evidenced by frequency shifts in Raman spectroscopy. Then classical diffusion creep theory is modified to a viscoelastic model incorporating physical parameters such as the elasticity, viscosity, and threshold stress for SiC fibers. The proposed equations have been well supported by creep test results. The viscosity and elasticity parameters decrease with increasing temperature, the latter being more sensitive. 3rd generation fiber exhibits higher viscosity and elasticity, explaining better creep resistance. The model can evaluate the elastic and plastic contributions and predict creep results at higher temperatures. This work helps to understand high-temperature SiC fiber creep, and to guide optimizing fiber-reinforced composites.},
  archive      = {J_MATDES},
  author       = {Wenguo Jiang and Yi Ru and Jundong Shi and Haozhang Hou and Zexu Sun and Weiwei Qu and Xiaotian Hu and Guoquan Ma and Lianyi Wang and Yanling Pei and Shusuo Li and Shengkai Gong},
  doi          = {10.1016/j.matdes.2025.114755},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114755},
  shortjournal = {Mater. Des.},
  title        = {High-temperature viscoelastic mechanism for SiC fibers to elucidate creep and recovery behaviors},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructured Y3Al5O12 single-crystal fibers for high-sensitivity quasi-distributed ultrasonic thermometry based on acoustic anisotropy engineering. <em>MATDES</em>, <em>259</em>, 114751. (<a href='https://doi.org/10.1016/j.matdes.2025.114751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of aerospace, nuclear energy, and advanced manufacturing has created a growing demand for temperature sensing in extreme environments. Ultrasonic temperature sensors (UTS) are widely used in high-temperature sensing due to their extreme operating temperature close to the melting point of the waveguide materials. In this work, YAG single-crystal fibers (SCF) with spatially distributed acoustic reflection microstructures have been successfully fabricated via the laser-heated pedestal growth (LHPG) method and employed as acoustic waveguides. Herein, anisotropic acoustic waveguide behaviors were revealed in YAG SCF, where the [110]-oriented YAG SCF demonstrates enhanced unit sensitivity with the S-wave polarization direction of [ 1 1 ¯ 0 ], primarily attributed to the lower acoustic velocity and the more substantial velocity variations with temperature. Furthermore, quasi-distributed ultrasonic temperature sensing in the range of 30-1800℃ has been achieved based on the [110]-oriented YAG SCF with two discrete sensing units, reaching the maximum unit sensitivities of 47.18 ns·℃ -1 ·m - 1 and an optimal temperature resolution of 5.04℃ at 1800℃. Superior acoustic waveguide characteristics, a wide working temperature range, and the positive temperature-dependent sensor performance suggest that the [110]-oriented microstructured YAG SCF is an ideal candidate for distributed high-temperature sensing in harsh environments.},
  archive      = {J_MATDES},
  author       = {Kaihui Zhang and Tao Wang and Mingji Zhang and Xin Guan and Zhengmin Wang and Wenchang Zhuang and Liang Zhang and Jian Zhang and Zhitai Jia},
  doi          = {10.1016/j.matdes.2025.114751},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114751},
  shortjournal = {Mater. Des.},
  title        = {Microstructured Y3Al5O12 single-crystal fibers for high-sensitivity quasi-distributed ultrasonic thermometry based on acoustic anisotropy engineering},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Static recrystallization characteristics and kinetics of austenitic stainless steels under development for LH2 storage applications. <em>MATDES</em>, <em>259</em>, 114750. (<a href='https://doi.org/10.1016/j.matdes.2025.114750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing high-strength austenitic stainless steel (ASS) grades for lightweight cryogenic storage tanks, particularly for liquefied hydrogen (LH 2 ), demands precise microstructure control achievable via optimized thermomechanically controlled processing (TMCP). In recrystallization–controlled regime of TMCP, successive rolling passes facilitate microstructural refinement through dynamic and static restoration mechanisms. This work illustrates static recrystallization (SRX) characteristics and kinetics in three ASS alloys designed by varying N, Mn and Nb contents. Interrupted (double–hit) compression tests were conducted to characterize the flow behaviour and microstructural evolution across different deformation conditions. SRX kinetics were formulated using a fractional–softening framework, where the time to 50 % recrystallization was correlated with strain, strain rate, temperature, and initial grain size. While the exponents of strain (−3.1) and strain rate (−0.3) were consistent across all compositions, the apparent activation energies of SRX varied in the range 251.5–298 kJ·mol −1 , with 7 wt% Mn showing a more noticeable effect in comparison with 0.1 wt% Nb. Detailed metallographic analysis confirmed the accuracy of the derived models. Suitable semi-empirical relations were established enabling prediction of statically recrystallised grain size across various processing conditions. These results define the processing windows needed to design TMCP schedules for advanced ASSs for LH 2 and cryogenic environments.},
  archive      = {J_MATDES},
  author       = {Mahesh Somani and Sumit Ghosh and Juha Uusitalo and Frank Hoffmann and Marta Muratori and Ali Smith and Ahmed W. Abdelghany},
  doi          = {10.1016/j.matdes.2025.114750},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114750},
  shortjournal = {Mater. Des.},
  title        = {Static recrystallization characteristics and kinetics of austenitic stainless steels under development for LH2 storage applications},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic strength and conductivity enhancement via induced 〈0 0 1〉-textured ultrafine grains in Al2O3/Cu composites. <em>MATDES</em>, <em>259</em>, 114748. (<a href='https://doi.org/10.1016/j.matdes.2025.114748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overcoming the strength–conductivity trade-off in Al 2 O 3 /Cu composites remains a key challenge. Here, we propose a microstructural design strategy that combines 〈0 0 1〉 texture with elongated ultrafine grains. Room-temperature rotary swaging (RS), assisted by the pinning effect of Al 2 O 3 particles, promotes the selective formation of 〈0 0 1〉-oriented grains through compressive–shear deformation and enhances grain aspect ratios. The resulting structure provides texture-dominated conductive paths while reducing transverse grain boundary density. Consequently, the composite achieves a yield strength of 342 MPa and an electrical conductivity of 95.3 % IACS—representing a 56.8 % strength increase over the Cu matrix without sacrificing conductivity. This work demonstrates a scalable, room-temperature route to high-performance Cu-based composites with an exceptional strength–conductivity balance for advanced electrical applications.},
  archive      = {J_MATDES},
  author       = {Song Liu and Shaolin Li and Kexing Song and Xiaowen Peng and Xiuhua Guo and Zhenhan Zhou and Shuaibin Li and Fuxiao Chen},
  doi          = {10.1016/j.matdes.2025.114748},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114748},
  shortjournal = {Mater. Des.},
  title        = {Synergistic strength and conductivity enhancement via induced 〈0 0 1〉-textured ultrafine grains in Al2O3/Cu composites},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D-printed barriers with machine learning powered image analysis for enhanced wound healing assays. <em>MATDES</em>, <em>259</em>, 114746. (<a href='https://doi.org/10.1016/j.matdes.2025.114746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wound healing assay is a standard method enabling investigation of cell proliferation and migration through a cell-free gap in a cell monolayer. Despite very common, it shows several weaknesses: lack of reproducibility and manual and time-based image analysis. Based on novel approach founded on innovative materials and AI-assisted processing of biological images, a promising automated barrier-wound healing assay is realized, achieving consistent results while retaining cells integrity. To increase assay accuracy, biocompatible 3D-printed resin inserts have been developed, facilitating precise control over shape and size of the wound. In parallel, a new image-detection algorithm powered by Deep Learning models was developed to identify cell-free area during the healing process, exceeding limitations of manual analysis. 3D-resin inserts combined with automated image analysis allowed the elimination of subjective errors and provided reproducible quantification of cell-free areas across multiple experiments. Moreover, a dataset to train a Convolutional Neural Network for monitor healing over time was developed. As proof of concept, this algorithm was tested on a cancer cell line stimulated by TGF-β, a drug stimulating cell migration. Innovative design of biocompatible materials combined with Deep Learning for automatically processing high-throughput data enables standardized wound healing assay, increasing efficiency, reliability, and accuracy of results.},
  archive      = {J_MATDES},
  author       = {Alfredo De Cillis and Valeria Garzarelli and Alessia Foscarini and Giuseppe Gigli and Antonio Turco and Elisabetta Primiceri and Maria Serena Chiriacò and Francesco Ferrara},
  doi          = {10.1016/j.matdes.2025.114746},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114746},
  shortjournal = {Mater. Des.},
  title        = {3D-printed barriers with machine learning powered image analysis for enhanced wound healing assays},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultralight pt-ALD-modified graphene aerogel achieving aluminum-class thermal resistance at 12% mass. <em>MATDES</em>, <em>259</em>, 114742. (<a href='https://doi.org/10.1016/j.matdes.2025.114742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphene aerogels (GAs), a class of three-dimensional porous structures, are limited by a fundamental challenge: low thermal conductivity stemming from high interfacial resistance between constituent layers and structural defects. This study systematically investigates a strategy to enhance thermal transport properties by engineering the interlayer bonding via platinum atomic layer deposition (Pt-ALD) and compares it with conventional high-temperature annealing (1873 K). The Pt-ALD-modified graphene aerogel (GA-ALD) exhibited a 199 % increase in thermal conductivity, significantly surpassing the 113 % enhancement from heat treatment. SEM, Raman, XRD, XPS, and FTIR data explicitly indicate that Pt-ALD forms covalent Pt O C bonds that bridge adjacent graphene layers while preserving the original porous morphology. Owing to the synergistic effect of enhanced solid-phase thermal conductivity and efficient convective heat transfer through the preserved porous structure, the GA-ALD sample achieved a total thermal resistance comparable to that of an equal-sized aluminum heat sink under identical forced-convection conditions, while weighing only ∼12 % of its aluminum counterpart. Moreover, cyclic compressive tests confirmed GA-ALD durability, retaining 99.5 % height and 94.7 % stress after 1000 cycles. These findings demonstrate that interfacial bond engineering via ALD is a powerful route to ultralight, high-performance carbon aerogels for weight-sensitive thermal-management applications.},
  archive      = {J_MATDES},
  author       = {Jiho Kang and Viet Phuong Nguyen and Seung-Mo Lee and Duckjong Kim},
  doi          = {10.1016/j.matdes.2025.114742},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114742},
  shortjournal = {Mater. Des.},
  title        = {Ultralight pt-ALD-modified graphene aerogel achieving aluminum-class thermal resistance at 12% mass},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser powder bed fusion of a novel CoNi-based high entropy superalloy. <em>MATDES</em>, <em>259</em>, 114741. (<a href='https://doi.org/10.1016/j.matdes.2025.114741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser powder bed fusion (L-PBF) is poised to revolutionize the manufacturing of high-value metallic materials, allowing for intricate, geometrically complex designs while minimizing material waste. The primary challenge lies in formulating alloys compatible with L-PBF that also maintain properties suitable for the demanding conditions encountered in energy, space, and nuclear applications. We introduce a category of high strength, defect-resistant octonary CoNi-based high entropy superalloy (CoNi-HESA), comprising roughly equal parts of Co and Ni, along with Cr, Al, V, Ti, Ta, and W. This alloy exhibits as-printed tensile strength exceeding 1 GPa and tensile ductility exceeding 30 % at room temperature. Furthermore, compression tests demonstrate that the as-printed parts maintain a yield strength of about 1 GPa at room temperature up to 700 °C, which decreases to 0.9 GPa and 0.7 GPa as the test temperature reaches 800 °C and 900 °C, respectively. With a careful combination of laser powder and scan speed, the developed HESA is well-suited for crack-resistant, high-density component production through L-PBF. Alloy design principles are elucidated through CALPHAD calculations based on the high entropy alloy (HEA) database, including the structure and properties of L-PBF processed CoNi-HESA.},
  archive      = {J_MATDES},
  author       = {Alessandro De Nardi and Ahad Mohammadzadeh and Amir Mostafaei and Jose Manuel Torralba},
  doi          = {10.1016/j.matdes.2025.114741},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114741},
  shortjournal = {Mater. Des.},
  title        = {Laser powder bed fusion of a novel CoNi-based high entropy superalloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Al alloying-driven spinodal decomposition enables ultra-strong cast refractory high-entropy alloys. <em>MATDES</em>, <em>259</em>, 114736. (<a href='https://doi.org/10.1016/j.matdes.2025.114736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strengthening in refractory high-entropy alloys (RHEAs) can be achieved through the formation of “compositional heterogeneity” at the atomic scale. Here, we chose Zr 45 Ti 15 Nb 20 Ta 20 alloy with a single-phase body-centered cubic (BCC) structure as a matrix and added a small amount of Al to promote a unique spinodal decomposition. The results show that the introduction of Al-X negative mixing enthalpy induces the RHEAs spinodal decomposition to form a nanocubic structure in the form of a basket-like fabric morphology with a characteristic periodicity of 12 nm. Nanocubic structures consist of (Nb, Ta)-rich cubes and Zr-rich channels as well as generate strong localized strain fields at the interfaces. Spinodal decomposition strengthening enables the as-cast RHEA to achieve a yield strength of 1405 MPa. Periodically distributed nanostructures make dislocations move slowly, causing plugging and cross-slip, facilitating dislocation interactions, multiplication, and accumulation. In summary, the chemical heterostructure produced by spinodal decomposition has been remarkably effective in improving the strength of RHEAs.},
  archive      = {J_MATDES},
  author       = {Yongkang Zhou and Ziyan Zhao and Yuanyuan Wang and Hong Li and Haifeng Zhang and Zhengwang Zhu},
  doi          = {10.1016/j.matdes.2025.114736},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114736},
  shortjournal = {Mater. Des.},
  title        = {Al alloying-driven spinodal decomposition enables ultra-strong cast refractory high-entropy alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving synergistic strength-ductility enhancement in a hierarchical hetero-lamellar AlCoCrFeNi2.1 eutectic high-entropy alloy via facile hot-rolling strategy. <em>MATDES</em>, <em>259</em>, 114734. (<a href='https://doi.org/10.1016/j.matdes.2025.114734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eutectic high-entropy alloys (EHEAs) have attracted considerable interest due to their superior multifunctional performance. However, the inherent tendency of stress concentration at irregular phase boundaries frequently leads to premature fracture. This study presents a facile hot-rolling strategy to achieve synergistic strength-ductility enhancement in AlCoCrFeNi 2.1 EHEA via constructing a hierarchical hetero-lamellar structure (HHLS). Through controlled per-pass rolling reduction (PPRD), we induce strain-partitioning-mediated microstructural refinement in the hot-rolled EHEA and activate synergistic deformation mechanisms including stacking faults, Lomer-Cottrell locks, and deformation twinning. The resultant HHLS (aligned FCC/B2 lamellae, partially recrystallized FCC regions, and intragranular B2 precipitates) triggers pronounced hetero-deformation-induced (HDI) strengthening. Consequently, the EHEA with HHLS exhibits exceptional properties: yield strength of 1202 MPa, ultimate tensile strength of 1489 MPa, and uniform elongation of 11.5 %, which are 112 %, 45 %, and 6 % higher than those of the as-cast alloy, respectively. The superior properties originate from HDI effect and FCC phase-mediated deformation mechanisms, which enable the EHEA to maintain exceptional work-hardening rate despite high dislocation density, effectively delaying plastic instability. These findings not only establish a readily implementable thermomechanical processing strategy for EHEAs, but also provide a novel paradigm for improving mechanical properties, paving the way for their application in high-performance structural materials.},
  archive      = {J_MATDES},
  author       = {Qidong Ren and Tianxin Li and Hengke Xie and Yuhao Jia and Mingpan Wan and Chaowen Huang and Chaoyi Chen and Junqi Li and Yiping Lu},
  doi          = {10.1016/j.matdes.2025.114734},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114734},
  shortjournal = {Mater. Des.},
  title        = {Achieving synergistic strength-ductility enhancement in a hierarchical hetero-lamellar AlCoCrFeNi2.1 eutectic high-entropy alloy via facile hot-rolling strategy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In vitro antibacterial and in vivo osteogenesis of 3D-printed magnesium peroxide–doped calcium phosphate silicate scaffolds for revision total knee arthroplasty. <em>MATDES</em>, <em>259</em>, 114731. (<a href='https://doi.org/10.1016/j.matdes.2025.114731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revision total knee arthroplasty (RTKA) often encounters tibial bone defects and high infection risk, especially from methicillin-resistant Staphylococcus aureus (MRSA). Current strategies rely on bone grafts with antibiotics, but prolonged use promotes resistance. Here, we developed a 3D-printed magnesium peroxide (MgO 2 )–doped calcium phosphate silicate (CSP) scaffold to address both structural and antibacterial demands. The MgO 2 –CSP scaffold exhibited cancellous bone-like strength (∼7.95 MPa) and an interconnected macroporous structure conducive to cell migration and healing. In vitro , the 14 wt% MgO 2 scaffold (B14M) inhibited 80.4 % of Gram-negative bacteria and 74.6 % of MRSA via Mg 2+ and H 2 O 2 release, while both B0M (no MgO 2 ) and B14M promoted BMSC proliferation and osteogenic differentiation. In vivo , the B14M scaffold markedly enhanced bone regeneration in rat tibial defects, achieving a BV/TV of ∼73.09 % versus ∼29.84 % for B0M at 8 weeks. These findings highlight MgO 2 –CSP scaffolds as a promising strategy to promote osteogenesis while combating MRSA-associated infections in RTKA.},
  archive      = {J_MATDES},
  author       = {Lisha Meng and Hao Li and Xujia Hao and Tao Wu and Jingqiu Zhou and Yadong Chen and Qiang Zheng and Xiuhong Cao and Juan Wang and Xinwei Liu and Tongmeng Jiang and Tianxing Gong and Wei Yuan},
  doi          = {10.1016/j.matdes.2025.114731},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114731},
  shortjournal = {Mater. Des.},
  title        = {In vitro antibacterial and in vivo osteogenesis of 3D-printed magnesium peroxide–doped calcium phosphate silicate scaffolds for revision total knee arthroplasty},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of synthesis routes on oxygen content, crystallography, and thermal stability of Ti3AlC2 MAX phases and resulting MXenes. <em>MATDES</em>, <em>259</em>, 114729. (<a href='https://doi.org/10.1016/j.matdes.2025.114729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current MXene research focuses on synthesising high-quality MAX phases with minimal O substitution in the C sublattice. This study provides insights into how different ball milling techniques and elemental compositions used in Ti 3 AlC 2 MAX phase synthesis affect the O incorporation into the lattice structure, which directly impacts the MAX phases’ and the resulting MXenes’ thermal stability. The unit cell lattice parameters (LPs) of a MAX phase are well-established indicators in determining the degree of O substitution. The presence of O reduced the a and c LPs of the MAX phase unit cell. However, the corresponding MXenes exhibited similar a LP ( a = 3.05 Å) values regardless of the LP values of their MAX phases. The LP observations are validated by correlative thermogravimetric analysis (TGA) carried out in air atmosphere. With the decreasing O incorporation in the MAX phase, an increase in the oxidation temperature was observed from 450 °C to 780 °C. However, the corresponding MXenes showed an average oxidation onset around 460 °C. Thus, this study reveals an important structure–property relationship between the Ti 3 AlC 2 MAX phase and the resulting Ti 3 C 2 MXenes.},
  archive      = {J_MATDES},
  author       = {Chathushka D. Hettige Dharmasiri and Konstantin L. Firestein and Joseph F.S. Fernando and Xiaodong Wang and Zhenhuan Chen and Dasun P.W. Guruge and Courtney-Elyce Lewis and Dmitri V. Golberg},
  doi          = {10.1016/j.matdes.2025.114729},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114729},
  shortjournal = {Mater. Des.},
  title        = {Influence of synthesis routes on oxygen content, crystallography, and thermal stability of Ti3AlC2 MAX phases and resulting MXenes},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ex vivo porcine urethral model for investigating intermittent catheter-associated urethral microtrauma. <em>MATDES</em>, <em>259</em>, 114727. (<a href='https://doi.org/10.1016/j.matdes.2025.114727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catheter-associated urethral microtrauma is a significant complication of intermittent catheterisation, compromising patient quality of life (QOL) and increasing urinary tract infection risk. Current research is hindered by the lack of robust physiological models to evaluate the mechanical interactions between catheter materials and urethral tissue during intermittent catheterisation. This study introduces the first ex vivo porcine urethral model to investigate tribological performance and material-tissue interactions during intermittent catheter (IC) use, enabling more informed catheter design. We examined four commercial hydrophilic polyvinylpyrrolidone (PVP)-coated ICs and a coating-free integrated amphiphilic surfactant (IAS) IC. ICs were inserted into porcine urethras using a texture analyser, held for two minutes, and withdrawn while measuring force and work done. Post-catheterisation, urethras were examined for microtrauma. Three of four PVP-coated catheters required significantly greater withdrawal force compared to the IAS catheter, correlating with increased urethral transitional membrane damage post-catheterisation. Ex vivo findings suggest that IAS catheters may lower the risk of complications compared with PVP-coated catheters in intermittent catheterisation. This study provides a new platform for comprehensive evaluation of IC-tissue interactions. It underscores the importance of tribological design in medical devices, aiding future innovation in device design and ultimately improve the QOL of patients undergoing intermittent catheterisation.},
  archive      = {J_MATDES},
  author       = {Jane Burns and Robyn N. Irwin and James Quinn and Jessica V. Moore and David Pollard and Ased Ali and James Hands and Colin P. McCoy and Louise Carson and Matthew P. Wylie},
  doi          = {10.1016/j.matdes.2025.114727},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114727},
  shortjournal = {Mater. Des.},
  title        = {An ex vivo porcine urethral model for investigating intermittent catheter-associated urethral microtrauma},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNN-based shape optimization of gradient-index phononic crystals with sensitivity analysis for tunable focal position and robust energy harvesting. <em>MATDES</em>, <em>259</em>, 114723. (<a href='https://doi.org/10.1016/j.matdes.2025.114723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-index (GRIN) phononic crystals (PnCs) enable energy harvesting (EH) by focusing elastic waves into electrical energy. Efficient EH requires maximizing focused wave intensity, typically achieved by tuning the GRIN PnCs unit-cell shape. However, existing designs often exhibit energy concentration near the GRIN lens boundary and incorporate narrow gaps and sharp corners, making them susceptible to manufacturing errors and limiting their practical applicability. Understanding the potential performance changes caused by manufacturing errors is important because geometrical alterations can compromise wave-focusing performance. Therefore, this study aims to optimize the unit-cell shape toward maximum focused intensity at the desired locations for EH devices. To assess manufacturability, the effects of minor geometric variations on the focal position and focused intensity are evaluated via a sensitivity analysis. The optimal shape is derived using a deep neural network (DNN) surrogate model trained to predict focal position and focused intensity. This model accelerates a genetic algorithm (GA) used to perform the optimization. Our optimized designs exhibit 1.5 to 2.0 times higher focused intensity across the target focal positions compared with the conventional design. Thus, these optimal shapes, along with their sensitivity analysis results, provide practical guidelines for defining manufacturing tolerances and achieving consistent, efficient EH performance.},
  archive      = {J_MATDES},
  author       = {Mary Kim and Sangryun Lee},
  doi          = {10.1016/j.matdes.2025.114723},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114723},
  shortjournal = {Mater. Des.},
  title        = {DNN-based shape optimization of gradient-index phononic crystals with sensitivity analysis for tunable focal position and robust energy harvesting},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving high oxygen tolerance in Ti6Al4V: Copper-oxygen co-doping strategy for ultrahigh strength-ductility balance. <em>MATDES</em>, <em>259</em>, 114719. (<a href='https://doi.org/10.1016/j.matdes.2025.114719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional α + β Ti6Al4V alloys lack sufficient strengthening mechanisms, limiting strength. While oxygen (O) offers a cost-effective strengthening route, exceeding ∼ 0.33 wt% causes significant embrittlement. Here, we explored how to efficiently utilize interstitial oxygen to enhance the mechanical properties of Ti6Al4V. The copper oxide (CuO) was innovatively employed as a precursor to completely dissolve into Ti6Al4V matrix, interstitial O and substitutional Cu atoms were simultaneously utilized to strengthen the primary α-phase (α p ) while inducing the abundant secondary-α (α s ) nanoprecipitates. Surprisingly, the introduction of Cu element facilitated control of lattice distortion and redistributed oxygen between α p and β-transformed (β trans ) structure, resulting in the Ti6Al4V-2.5CuO (wt.%) alloy with high oxygen tolerance (0.62 wt%) and an ultra-high ultimate strength of ∼ 1635 MPa and a favorable ductility of ∼ 5.3 %. The dual effect of interstitial solid solution strengthening and α s precipitation strengthening were achieved under the Cu/O interaction. Additionally, the addition of Cu promoted the oxygen redistribution and activation of the basal < a > and pyramidal < c + a > slip systems, thereby ensuring improved ductility. This study presented a novel strategy for high-strength Ti alloys using interstitial oxygen, maximizing strengthening while mitigating embrittlement.},
  archive      = {J_MATDES},
  author       = {Hongqiang Duan and Hongmei Zhang and Xingwang Cheng and Xiaonan Mu and Qunbo Fan and Ying Zhang and Ni Xiong and Ke Feng and Yu Wang and Xuexia Li and Taotao Cai and Kefan Zheng},
  doi          = {10.1016/j.matdes.2025.114719},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114719},
  shortjournal = {Mater. Des.},
  title        = {Achieving high oxygen tolerance in Ti6Al4V: Copper-oxygen co-doping strategy for ultrahigh strength-ductility balance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crack deflection by design – Utilizing the material inhomogeneity effect on miniaturized additively manufactured structures. <em>MATDES</em>, <em>259</em>, 114718. (<a href='https://doi.org/10.1016/j.matdes.2025.114718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A natural crack exhibits a surrounding stress field, which may overlap considerably with a stress field caused by any material inhomogeneity, influencing the crack driving force and extension direction. To utilize this effect for potentially increasing the apparent toughness, a defined pore is introduced near a potential crack path, whereby upon interaction, the crack tip can be deflected or trapped, depending on the intermediate distance. Since fundamental mechanics is well-known, a miniaturized notched bending specimen geometry incorporating a pore was selected to investigate the application potential for parts manufactured via multi-photon lithography. The size regime is representative of the smallest available objects and requires in situ SEM testing, which was completed with finite element modeling based on crack path prediction through analyzing the local crack driving force. The high dimensional repeatability of the process allowed for testing reliably reproduced specimens with variation of crack to pore distance only. The prediction represented the actual crack paths well, underlining successfully facilitated crack path alteration. The toughness was mainly increased by crack trapping within the pore, where deflection had a quantitatively negligible effect.},
  archive      = {J_MATDES},
  author       = {Alexander Jelinek and Markus Alfreider and Dražen Breščaković and Otmar Kolednik and Daniel Kiener},
  doi          = {10.1016/j.matdes.2025.114718},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114718},
  shortjournal = {Mater. Des.},
  title        = {Crack deflection by design – Utilizing the material inhomogeneity effect on miniaturized additively manufactured structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adenosine-loaded adhesive microfluidic hydrogel microspheres stimulate acupoint activation for pain management. <em>MATDES</em>, <em>259</em>, 114708. (<a href='https://doi.org/10.1016/j.matdes.2025.114708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pain represents a significant public health challenge with substantial clinical and economic burdens. While pharmacotherapy remains a mainstay of pain management, its utility is limited by adverse side effects and the potential for dependency. Acupuncture has shown great potential in pain management through its ability to induce analgesic effects via acupoint stimulation. However, its poor specificity and ill-defined stimulation parameters compromise therapeutic specificity and reproducibility. Herein, we developed a biomaterial-based acupoint activation strategy for pain management. Adhesive polydopamine-coated hydrogel microspheres were fabricated using microfluidic techniques for accurate attachment and activation of acupoints. Adhesive hydrogel microspheres loaded with adenosine can slowly release exogenous adenosine at the ST36 acupoint to simulate the analgesic effect of acupuncture. In vitro and in vivo studies demonstrated that single-dose administration of adhesive microspheres can effectively target acupoints, elevate mechanical pain thresholds, and provide systemic anti-inflammatory effects for up to 7 days. Overall, the proposed adhesive hydrogel microsphere system offers a new perspective on acupuncture practice and pain management.},
  archive      = {J_MATDES},
  author       = {Xiujuan Li and Zehao Chen and Songgen Chen and Han Wang and Lin Fu and Ban Feng and Hui Chen and Lize Xiong},
  doi          = {10.1016/j.matdes.2025.114708},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114708},
  shortjournal = {Mater. Des.},
  title        = {Adenosine-loaded adhesive microfluidic hydrogel microspheres stimulate acupoint activation for pain management},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Study and characterization of recycled ABS-GF in large format additive manufacturing to enhance mechanical properties of printed structures. <em>MATDES</em>, <em>259</em>, 114707. (<a href='https://doi.org/10.1016/j.matdes.2025.114707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large format additive manufacturing (LFAM) has proven its ability to produce high-performance components for competitive markets. By depositing material only where it's needed, it drastically reduces waste material and energy use, obtaining a sustainability advantage that is further enhanced on larger scale. However, a deeper understanding of material recycling is critical to achieving the next milestone in sustainability. In this work, a methodology was proposed that uses both molds and final parts, manufactured in acrylonitrile-butadiene-styrene reinforced with short glass fibers (ABS-GF), which had reached the end of their useful life to be used as feedstock. It is observed that recycling reduces fiber length by 47.3%, which directly impacts the mechanical properties in the longitudinal printing direction, resulting in around a 9% decrease in maximum tensile stress. However, this reduction falls to 5.1% in the transverse direction to the printing, and in some cases, the recycled material even surpasses the virgin material due to improved interlayer adhesion. An analysis on the adhesion reveals that the shorter monomer chains obtained during recycling allow better interlacing between layers. These results suggest that the reuse of the molds is viable and by adjusting the printing parameters we can obtain properties suitable for demanding applications.},
  archive      = {J_MATDES},
  author       = {Javier Bas-Bolufer and Pablo Castelló-Pedrero and Cesar García-Gascón and Juan Antonio García-Manrique},
  doi          = {10.1016/j.matdes.2025.114707},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114707},
  shortjournal = {Mater. Des.},
  title        = {Study and characterization of recycled ABS-GF in large format additive manufacturing to enhance mechanical properties of printed structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology optimization of 3D-printed material architectures: Testing toolpath consideration in design. <em>MATDES</em>, <em>259</em>, 114700. (<a href='https://doi.org/10.1016/j.matdes.2025.114700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology Optimization (TO) methods applied to the design of material architectures allow for a wider exploration of the possible design space when compared to common geometry parameter controlled design methods. These optimal designs are often realized using Direct Ink Writing methods which exhibit characteristic features of discrete bead sizes and weak bead bonding. The resultant lack of design fidelity and toolpath dependent anisotropy has been found to negatively impact structural performance if not accounted for in the design. This paper addresses both characteristics in the design process of cellular material architectures by expanding upon the Nozzle Constrained Topology Optimization algorithm and experimentally validating the results against a typical baseline. An experimental method of deriving bond region material properties is detailed. A direct toolpath generation method from topology optimized results is proposed. Comparisons are made with conventional topology optimization design methods and performance is measured both experimentally and numerically against theoretical bounds. At relative densities ≤ 70 % , designs with nozzle constraints were able to more closely align numerical and experimental results for both performance and design fidelity (measured by relative density). In contrast, conventional topology optimized designs had higher overall performance, but little alignment between intended design and resultant experimental result. Typical designs consistently overdeposited material and inconsistently predicted performance.},
  archive      = {J_MATDES},
  author       = {Hajin Kim-Tackowiak and Josephine V. Carstensen},
  doi          = {10.1016/j.matdes.2025.114700},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114700},
  shortjournal = {Mater. Des.},
  title        = {Topology optimization of 3D-printed material architectures: Testing toolpath consideration in design},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forming-induced thickness effects on structural response of arched thin-shell metal alloys. <em>MATDES</em>, <em>259</em>, 114692. (<a href='https://doi.org/10.1016/j.matdes.2025.114692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical influence of forming-induced thickness variations on arched thin-shell metal components' structural response and rupture behavior, a key challenge in safety-critical applications. An integrated predictive framework combines classical plate theory for initial deformation estimates, explicit dynamic finite element simulations for elastic-plastic analysis, and Kriging-based response surface modeling to map geometric, material, and process parameters to performance metrics. A large-scale simulation campaign across eight isotropic material models and 42,669 configurations identifies the arch rise-to-radius ratio as the dominant factor in post-forming thickness evolution, with non-uniform profiles causing up to deviations in rupture pressures and altering failure modes compared to uniform assumptions. Modal, buckling, and rupture analyses highlight significant impacts on natural frequencies, critical loads, and mechanisms. Experimental validation on 36 Monel Alloy 400 rupture discs achieves high accuracy, with thickness root-mean-square error of (maximum mean absolute percentage error ) and rupture pressure errors below , supported by uncertainty analysis (expanded uncertainties at confidence). The generalizable framework, extensible to non-metallic isotropic shells and non-arched geometries, enables enhanced prediction, optimization, and reliability by linking forming outcomes to structural integrity.},
  archive      = {J_MATDES},
  author       = {Shilin Chen and Qingxi Yang and Qingzhou Yu and Genmu Shi and Haotian Yin},
  doi          = {10.1016/j.matdes.2025.114692},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114692},
  shortjournal = {Mater. Des.},
  title        = {Forming-induced thickness effects on structural response of arched thin-shell metal alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond diameters: Decoding fabrication patterns of hierarchical micro-nano titanium implants via anodization and their geometries on region-specific soft-tissue integration. <em>MATDES</em>, <em>259</em>, 114691. (<a href='https://doi.org/10.1016/j.matdes.2025.114691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrochemical anodization creates titania nanopores (TNPs) on Ti implants with distinctive micro-nano geometries to enhance their surface bioactivity, showing the potential to improve soft-tissue integration at varied transmucosal regions. However, understanding how topography regulates TNP dimensions under voltage, and the clinical feasibility of diverse TNP geometries was limited. More crucially, existing research predominantly focused on nanopore diameter, neglecting other geometric characteristics (alignment, texture/roughness) on soft-tissue cells that impeded optimized TNPs design for ideal soft-tissue integration. This study showed nanopore dimensions were voltage-dependent on micro-patterned Ti but remain stable on smooth counterparts. Varied TNPs with similar diameters but different alignment/roughness were selected and identified with similar chemistry/hydrophilicity, but their protein adhesion and stability were length-dependent, showing their feasibility as implant devices. Finally, human gingival fibroblasts (HGFs) and HaCaT epithelial cells functions on varied selected TNPs reflected that nanopores inherently promoted cell responses, but hybrid microgroove-nanopores dramatically enhanced HGF’s collagen and fibronectin secretion, while irregular textured nanopores significantly improved HaCaT adhesion. By addressing the gaps in understanding topographical regulation and the influence of overlooked geometric features beyond diameter, this work advances spatially optimized implant designs for improved epithelial sealing and connective tissue integration at different transmucosal zones for improved implant health.},
  archive      = {J_MATDES},
  author       = {Tianqi Guo and Miaoxuan Dai and Xinxin Ding and Xiaomeng Zhang and Yingxin Gu and Hongchang Lai},
  doi          = {10.1016/j.matdes.2025.114691},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114691},
  shortjournal = {Mater. Des.},
  title        = {Beyond diameters: Decoding fabrication patterns of hierarchical micro-nano titanium implants via anodization and their geometries on region-specific soft-tissue integration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of particle size on powder velocity distribution at the nozzle outlet in directed energy deposition. <em>MATDES</em>, <em>259</em>, 114680. (<a href='https://doi.org/10.1016/j.matdes.2025.114680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal-based Directed Energy Deposition (DED) is considered one of the variations of additive manufacturing with the highest potential, particularly for space industry and in-orbital manufacturing. The technology however still faces various challenges, many of which can be traced back to poor control and understanding of the powder delivery. Velocity distribution of powder particles at the DED nozzle outlet has a key influence on the results of any predictive model of powder stream and yet remains largely disputed. Certain numerical studies highlighted a possible influence of powder particle size on the velocity condition at the nozzle exit, yet no experimental studies confirmed this effect. The experimental campaign described in this paper quantifies this relation between powder particle size and velocity distribution at the nozzle outlet and a strong decrease of particle speed with particle size is observed. Moreover, smaller particles are observed to travel at speeds higher than the mean carrier gas speed suggesting powder particle segregation within the nozzle as one of the mechanisms driving speed differences at the nozzle outlet.},
  archive      = {J_MATDES},
  author       = {Tijan Mede and Andrej Jeromen and Edvard Govekar and Michael Mallon and Matjaž Godec},
  doi          = {10.1016/j.matdes.2025.114680},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114680},
  shortjournal = {Mater. Des.},
  title        = {Influence of particle size on powder velocity distribution at the nozzle outlet in directed energy deposition},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of orifice geometry in determining fibre production efficiency in pressurized gyration. <em>MATDES</em>, <em>259</em>, 114670. (<a href='https://doi.org/10.1016/j.matdes.2025.114670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pressurized gyration allows the scaled-up production of polymeric fibre under the simultaneous application of pressure and rotation. This study investigates the influence of orifice design on fibre formation and production rate in pressurized gyration, aiming to optimize the technique for industrial-scale applications. Transparent vessels with varying orifice heights (7.5 mm, 15 mm, and 22.5 mm), orifice numbers (24 and 48), and dual-level orifice distributions were fabricated and tested under pressures of 0.1, 0.2, and 0.3 MPa. Morphological analysis showed that fibre diameter decreased from 2.2 µm to 1.8 µm when pressure was raised from 0.1 to 0.3 MPa when increasing the number of orifices to 48. Two-level orifice designs yielded mixed diameter distributions, enabling tunable fibre architectures. High-speed imaging revealed that the 7.5 mm orifice height achieved fluid ejection 7.5 % faster than 22.5 mm at 0.1 MPa and increasing pressure from 0.1 to 0.2 MPa reduced ejection time by up to 33 %. Production rate increased with more orifices (48 compared to 24), by 9.8 % at 0.2 MPa, and declined at higher pressure for vessels with dual-level designs. Overall, the findings provide quantitative insights into how vessel geometry influences fibre morphology and throughput in pressurized gyration systems.},
  archive      = {J_MATDES},
  author       = {Ahmed Alneyadi and Alexander Smith and Anthony Harker and Mohan Edirisinghe},
  doi          = {10.1016/j.matdes.2025.114670},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114670},
  shortjournal = {Mater. Des.},
  title        = {The role of orifice geometry in determining fibre production efficiency in pressurized gyration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="mla">MLA - 6</h2>
<ul>
<li><details>
<summary>
(2025). Structure-aware stable diffusion for traditional architectural decoration design. <em>MLA</em>, <em>22</em>, 100735. (<a href='https://doi.org/10.1016/j.mlwa.2025.100735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent generation of traditional architectural styles faces significant challenges in structural integrity and style consistency. While existing methods can generate numerous realistic images, they lack a deep understanding of structural elements in traditional architectural decorative design. This paper proposes a Structure-aware Stable Diffusion (SSD) model, which enhances the model's comprehension of architectural features through three key innovations. First, we design a structure-aware feature injection module that adaptively fuses extracted architectural structural information with original features during the U-net upsampling phase, enhancing the model's understanding of geometric structures. Second, we introduce a dual-path text enhancement strategy that combines structural descriptions with original descriptions to provide richer textual guidance signals for the generation process. Finally, we design a progressive injection strategy that dynamically controls the injection intensity of structural information through cosine scheduling, ultimately achieving effective internalization of structural knowledge. Experimental results show that compared to existing methods, our model effectively improves both the diversity of generated traditional architectural decorations and the rationality of their structures, thus providing an effective new technical approach for traditional architectural decorative design.},
  archive      = {J_MLA},
  author       = {Jianhong Yang and Guoyong Wang},
  doi          = {10.1016/j.mlwa.2025.100735},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100735},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Structure-aware stable diffusion for traditional architectural decoration design},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines. <em>MLA</em>, <em>22</em>, 100734. (<a href='https://doi.org/10.1016/j.mlwa.2025.100734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer experience is crucial in the airline industry, as understanding passenger satisfaction helps airlines improve service quality. This study evaluates hyperparameter optimization and feature interpretability in machine learning models for predicting airline passenger satisfaction. Support Vector Machine (SVM) and Multilayer Perceptron (MLP) models were tested for binary classification, labeling passengers as ‘Satisfied’ or ‘Neutral or Dissatisfied’ using a Kaggle dataset with ∼104,000 training and ∼26,000 test records. Hyperparameter tuning used grid search with 10-fold cross-validation. For SVM, the optimal setup included the RBF kernel, C = 10, and gamma = ‘auto’, achieving a mean score of 0.9606. For MLP, the best configuration used no regularization, "he" initialization, ReLU activation, 30 epochs, batch size of 32, two hidden layers with 32 neurons each, and a learning rate of 0.001, yielding a mean score of 0.9556. Performance metrics included accuracy, precision, recall, and F1-Score, with SVM achieving a test accuracy of 0.96, precision of 0.97, and F1-Score of 0.95, slightly outperforming MLP by <1 %, though MLP was faster at 0.3 s versus SVM’s 18 s. Both models surpassed baseline models and prior studies, benefiting from robust preprocessing and a large dataset. Permutation importance analysis identified Type of Travel, Inflight Wi-Fi Service, Customer Type, and Online Boarding as key predictors, emphasizing passenger needs for digital connectivity and personalized services. These insights guide airlines to prioritize reliable Wi-Fi and efficient online boarding to enhance satisfaction, loyalty, and competitive positioning.},
  archive      = {J_MLA},
  author       = {Hamid Mirzahossein and Soheil Rezashoar},
  doi          = {10.1016/j.mlwa.2025.100734},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100734},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation. <em>MLA</em>, <em>22</em>, 100733. (<a href='https://doi.org/10.1016/j.mlwa.2025.100733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validating performance is a key challenge facing the adoption of machine learning models in high risk applications. Current validation methods assess performance marginally over the entire testing dataset, which can fail to identify regions in the distribution with insufficient performance. In this paper, we propose Conformal Validation, a systems-based approach with a calibrated form of uncertainty quantification using a conformal prediction framework as a part of the validation process to reduce performance gaps. Specifically, the policy defers a subset of observations for which the predictive model is most uncertain and provides a human with informative prediction sets to make the ancillary decision. We evaluate this policy on an image classification task where images are distorted with varying levels of gaussian blur for a quantifiable measure of added difficulty. The model is compared to human performance on the most difficult observations, i.e., those where the model is most uncertain, to simulate the scenario when a human is the alternative decision-maker. We evaluate performance on three arms: the model independently, humans with access to a set of classes the model is most confident in, and humans independently. The deferral policy is simple to understand, applicable to any predictive model, and easy to implement while, in this case, keeping humans in the loop for improved trustworthiness. Conformal Validation incorporates a risk assessment that is conditioned on the prediction set length and can be tuned to the needs of the application.},
  archive      = {J_MLA},
  author       = {Paul Horton and Alexandru Florea and Brandon Stringfield},
  doi          = {10.1016/j.mlwa.2025.100733},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100733},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of machine learning technologies in construction maintenance: A strategic analysis. <em>MLA</em>, <em>22</em>, 100731. (<a href='https://doi.org/10.1016/j.mlwa.2025.100731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current predictive maintenance systems in construction rely on static machine learning approaches that fail to adapt to evolving operational environments, achieving only 3%–7% performance improvements over individual models and suffering 15%–25% performance degradation when transferred across domains. This research develops and validates an Adaptive Ensemble Framework that dynamically optimizes algorithm selection through real-time data assessment and performance feedback. The framework’s meta-learning architecture continuously adapts ensemble weights using data complexity measures, temporal pattern analysis, and uncertainty quantification metrics. Unlike static approaches, the system integrates scikit-learn and TensorFlow models through dynamic optimization algorithms that respond to changing conditions without manual reconfiguration. The framework provides uncertainty-aware predictions with confidence intervals essential for safety-critical construction decisions. Comprehensive evaluation across four industries using 50,000+ maintenance records from major construction firms demonstrates substantial improvements. The adaptive ensemble achieves F1-score of 0.934 in construction delay prediction, representing 15.3% improvement over individual models and 8.7% enhancement over static ensembles. Cross-industry validation reveals successful knowledge transfer with minimal performance degradation ( < 5%). This research contributes three scholarly advances: (i) the first real-time adaptive ensemble framework eliminating manual hyperparameter tuning, (ii) uncertainty quantification mechanisms for safety-critical applications, and (iii) robust cross-industry transferability through systematic domain adaptation. The framework extends beyond construction to manufacturing, energy, and transportation sectors, demonstrating computational efficiency with sub-100ms latency and linear scaling characteristics. These contributions establish new benchmarks for adaptive machine learning in industrial predictive maintenance.},
  archive      = {J_MLA},
  author       = {Assane Lo and Aysha Alshehhi},
  doi          = {10.1016/j.mlwa.2025.100731},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100731},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Implementation of machine learning technologies in construction maintenance: A strategic analysis},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning based li-ion cell state prediction using impedance spectroscopy. <em>MLA</em>, <em>22</em>, 100729. (<a href='https://doi.org/10.1016/j.mlwa.2025.100729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable monitoring of battery state parameters is crucial for ensuring optimal battery performance, safety, and lifetime. Existing methods have limitations, such as requiring modeling of each degradation mechanism involved or relying on direct measurement techniques that impose restrictions on field studies or end-user use. In this paper, we propose a machine learning-based approach that combines the strengths of electrochemical impedance spectroscopy (EIS) and machine learning algorithms to predict battery state parameters. We have developed an efficient prediction system that can learn from EIS data and accurately predict battery state parameters. Our approach is trained on an open dataset comprising of over 30,000 spectra, generated using an automated measurement technique that outperforms current machine learning-based models, particularly in terms of generalization across different cells and measurement setups.},
  archive      = {J_MLA},
  author       = {Carl Philipp Klemm and Till Frömling},
  doi          = {10.1016/j.mlwa.2025.100729},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100729},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine-learning based li-ion cell state prediction using impedance spectroscopy},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets. <em>MLA</em>, <em>22</em>, 100712. (<a href='https://doi.org/10.1016/j.mlwa.2025.100712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistic regression is a simple yet widely used classification model in spectroscopic profiling analysis. Considering the model’s output represents a probability, this paper will investigate its latent distribution assumption, i.e., its inner linear regressor unit follows a standard logistic distribution. An empirical study on five spectroscopic profiling open datasets, i.e., wine, coffee, olive oil, cheese, and milk powder, was conducted to verify this latent distribution assertion. This paper measured the GoF (Goodness of Fit) of each dataset’s latent variable from three aspects, i.e., curve fitting, P–P and Q–Q plots, and K–S test. After hyper-parameter optimization and proper training, the latent variable, as a weighted sum of the original features, has demonstrated a high level of GoF on all the five datasets. This study verifies the suitability of logistic regression in spectroscopic profiling analysis and answers why the model output can be interpreted as a conditional probability.},
  archive      = {J_MLA},
  author       = {Yinsheng Zhang and Mingming He and Haiyan Wang},
  doi          = {10.1016/j.mlwa.2025.100712},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100712},
  shortjournal = {Mach. Learn. Appl.},
  title        = {On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="neucom">NEUCOM - 78</h2>
<ul>
<li><details>
<summary>
(2025). Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks. <em>NEUCOM</em>, <em>656</em>, 131589. (<a href='https://doi.org/10.1016/j.neucom.2025.131589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of data computational science, the prediction of nonlinear systems has provided effective support for investigating complex problems in the field of natural sciences. Physics-Informed Neural Networks (PINNs) are playing an increasingly prominent role in nonlinear system prediction. Although PINNs have been widely applied across various engineering domains, their utilization in chaotic system prediction remains notably scarce. This paper proposes a novel causal PINNs framework integrated with ResNet blocks. On the one hand, the framework incorporates temporal weighting into the residual loss, utilizing maximum temporal weight as the training termination criterion. Additionally, an annealing strategy is adopted to adaptively adjust the causal parameters, ensuring that the model adheres to physical causality constraints throughout the training process. On the other hand, the framework employs a ResNet-block-based network, which transforms identity mappings into residual mappings. This architectural design significantly enhances training stability when utilizing deep networks. To validate the performance of the proposed method, numerical experiments are conducted on the Lorenz system, Dadras system, and Kuramoto-Sivashinsky equation. The results demonstrate that the causal PINNs with ResNet blocks significantly outperform conventional PINNs in predicting chaotic systems.},
  archive      = {J_NEUCOM},
  author       = {Man-Hong Fan and Jun-Hao Zhao and Lin Ding and Xiao-Ying Ma and Rui-Lin Fu},
  doi          = {10.1016/j.neucom.2025.131589},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131589},
  shortjournal = {Neurocomputing},
  title        = {Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition. <em>NEUCOM</em>, <em>656</em>, 131567. (<a href='https://doi.org/10.1016/j.neucom.2025.131567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous Sign Language Recognition (CSLR) requires capturing both spatial and temporal dependencies to accurately model sign sequences. To enhance CSLR performance, we propose a Multi-Stream Diffusion Graph Convolution Network (MSD-GCN) from input skeleton data that introduces three key innovations. First, Adaptive Motion-aware Graph Convolution with Bi-level Attention (AMGC-BA) dynamically refines joint connectivity by leveraging semantic motion correlations, improving robustness to signer variations, and enhancing long-term dependencies. Second, signal-enhanced multi-stream representation learning integrates advanced signal processing techniques, including the Adaptive Ridgelet Transform (ART) for pose representation, Variational Mode Decomposition (VMD) for motion decomposition, and Empirical Wavelet Transform (EWT) for contextual feature extraction, ensuring feature robustness, reducing noise, and improving discriminability. Third, self-supervised pretraining leverages contrastive learning, graph reconstruction, and cross-stream feature alignment to mitigate data scarcity, enhance domain adaptation, and improve representation learning. These innovations enable the proposed graph to effectively capture complex motion patterns, distinguish between critical and redundant gestures, and generalize well across diverse signers and datasets. By improving recognition accuracy, robustness, and adaptability, the proposed approach provides a significant advancement in CSLR, addressing the challenges of signer variability, limited labeled data, and the need for fine-grained motion representation. Results on three datasets confirm the superiority of the proposed model compared to 35 comparative models. To the best of our knowledge, this is the first study in CSLR to employ such an extensive range of comparative models for performance evaluation.},
  archive      = {J_NEUCOM},
  author       = {Razieh Rastgoo},
  doi          = {10.1016/j.neucom.2025.131567},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131567},
  shortjournal = {Neurocomputing},
  title        = {A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition. <em>NEUCOM</em>, <em>656</em>, 131561. (<a href='https://doi.org/10.1016/j.neucom.2025.131561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the feature representation and decoding efficiency of the steady-state visual evoked potentials (SSVEPs) is critical to enhancing the performance of neural signal decoding systems. Current deep learning models often overlook the physical topological information of EEG channels, resulting in suboptimal feature extraction and limited recognition performance. To address these challenges, this study proposes a synergistically designed SSVEP recognition framework to alleviate data insufficiency, improve the feature representation, and enhance decoding efficiency. Specifically, a slicing-and-scaling technique is adopted to improve the model generalization under limited-sample scenarios. A graph-based spatial filter leverages the topological relationships among EEG channels to suppress redundant information and enhance spatial feature quality. A lightweight convolutional neural network (CNN) with fewer parameters is developed to efficiently extract discriminative temporal–spatial features for accurate SSVEP classification. Experimental results on two public benchmark datasets and one self-collected dataset demonstrate that the proposed framework outperforms baseline deep learning models, yielding improvements of at least 6.8 %, 8.5 %, and 0.5 % in peak average classification accuracy, respectively. The maximum average information transfer rates (ITRs) achieved on the three datasets were 221.4 bits/min ,106.7 bits/min , and 133.9 bits/min , respectively. By simultaneously reducing model complexity and improving decoding performance, the proposed framework offers an effective and promising approach for efficient neural signal decoding in SSVEP recognition.},
  archive      = {J_NEUCOM},
  author       = {Rui Ma and Yu Cao and Sheng Quan Xie and Mingming Zhang and Jun Li and Zhi-Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131561},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131561},
  shortjournal = {Neurocomputing},
  title        = {LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework. <em>NEUCOM</em>, <em>656</em>, 131558. (<a href='https://doi.org/10.1016/j.neucom.2025.131558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view multi-label classification (MVMLC) seeks to enhance classification by integrating diverse data views, but its practical use is hindered by missing views and labels, posing the significant challenge of incomplete MVMLC(IMVMLC). Although various IMVMLC approaches have been proposed, most of them handle multiple objectives in a single feature space and thus overlook the conflict between learning consistent common semantics and reconstructing view-specific information. In addition, existing multi-view classification methods mainly consider utilizing the features of each view, while ignoring the inconsistent contributions of each view and usually relying on static average weighting strategies. To this end, we propose our Attention-Guided MultiSpace Consistency Alignment Framework (AMCA). In Stage 1, AMCA introduces multi-space representation learning with dual-level contrastive objectives, explicitly disentangling shared and view-specific semantics to resolve the objective conflict and yield more informative embeddings. In Stage 2, AMCA employs an attention-guided fusion module that dynamically evaluates and integrates multi-view features based on their relevance to the classification task, enabling robust decision-making even with missing data. Extensive experiments validate the effectiveness and superiority of our proposal.},
  archive      = {J_NEUCOM},
  author       = {Bingyan Nie and Wulin Xie and Lian Zhao and Jiang Long and Xiaohuan Lu and Yinghao Ye},
  doi          = {10.1016/j.neucom.2025.131558},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131558},
  shortjournal = {Neurocomputing},
  title        = {Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end transformer-based detection with density-guided query selection for small objects. <em>NEUCOM</em>, <em>656</em>, 131554. (<a href='https://doi.org/10.1016/j.neucom.2025.131554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection remains a persistent challenge in transformer-based detectors due to their limited localization precision and reliance on fixed query mechanisms. In this paper, we propose Hybrid Density-Transformer (HyDeTr), a novel transformer-based object detection framework designed to improve the detection of small and densely packed objects with only a slight trade-off in inference complexity. HyDeTr introduces several key innovations: (1) a Context-Selective Hybrid Attention Encoder (CS-HAE) that distills global context from low-resolution features through efficient kernelized attention while preserving local detail via deformable attention on higher-resolution maps; (2) a Density Map Prediction module that generates a spatial prior highlighting high-object-density regions, facilitating focus on crowded scenes; (3) a Density-Guided Uncertainty-Minimal Query Selection strategy that identifies the most informative query locations based on both classification confidence and predicted density, ensuring that even low-confidence small objects in dense areas are effectively queried; and (4) an improved Query Formulation with dual embeddings, consisting of a content embedding and a 4D anchor box, refined iteratively by the decoder. Our design enables precise, density-aware query initialization and scale adaptation, leading to improved recall and accuracy for small objects. Extensive evaluations demonstrate that HyDeTr outperforms existing methods in detecting small objects, offering significant accuracy gains with only a modest increase in inference complexity, thereby maintaining near real-time performance and full end-to-end trainability.},
  archive      = {J_NEUCOM},
  author       = {Nguyen Hoanh and Tran Vu Pham},
  doi          = {10.1016/j.neucom.2025.131554},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131554},
  shortjournal = {Neurocomputing},
  title        = {End-to-end transformer-based detection with density-guided query selection for small objects},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery. <em>NEUCOM</em>, <em>656</em>, 131553. (<a href='https://doi.org/10.1016/j.neucom.2025.131553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mechanical equipment prognostics, conventional graph neural networks encounter significant limitations when processing high-dimensional dynamic sensor data: inadequate modeling of complex feature interdependencies, insufficient sensitivity to transient fault signatures, and ineffective knowledge transfer in cross-domain applications. To overcome these challenges, we present a DSGA-SAGE, which stands for Dynamic Sparse Graph Attention - SAmpling and aGgrEgation framework. Our approach presents innovations in three aspects: (1) A decentralized graph construction paradigm establishes dynamic associations among multivariate time-series features, enabling precise identification of critical fault patterns through adaptive node-edge interactions. (2) A sparse attention mechanism with trainable topology constraints optimizes the structural weights of graph in the real-time scenarios, achieving 23 % overhead computational reduction while maintaining the accuracy of feature discriminability. (3) A unified cross-domain learning strategy synchronizes multi-condition knowledge transfer through hierarchical loss optimization, ensuring robust generalization across various operational scenarios. Extensive experiments on five industrial datasets demonstrate state-of-the-art performance: achieving the highest accuracy of 96.29 % in fault diagnosis, while realizing 99.87 % Macro-F1 and 99.88 % Micro-F1 scores in cross-domain tasks. Through a comprehensive performance analysis, the superiority of the efficiency and cross-domain adaptability in dynamic sparse graph attention mechanism has been convincingly validated.},
  archive      = {J_NEUCOM},
  author       = {Ying Xie and Jixiang Wang and Zhiqiang Xu and Junnan Shen and Lijie Wen and Rongbin Xu and Yun Yang},
  doi          = {10.1016/j.neucom.2025.131553},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131553},
  shortjournal = {Neurocomputing},
  title        = {A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management. <em>NEUCOM</em>, <em>656</em>, 131536. (<a href='https://doi.org/10.1016/j.neucom.2025.131536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for intelligent operation and maintenance of vertical mill gearboxes in the cement industry, traditional passive maintenance methods are increasingly inadequate for supporting efficient, proactive management under complex operational conditions. In particular, sudden gear failures often result in unplanned downtime, causing significant economic losses. To address this challenge, this paper proposes a dynamic control approach for gear remaining useful life (RUL) that integrates multi-source information through collaborative decision-making to enable active health management. First, a novel RUL prediction method based on multilevel multi-source domain adaptation (MMDA) is proposed to enhance the generalization capability of the model. By minimizing discrepancies between local and global feature distributions under varying working conditions and aligning the prediction boundaries among predictors, the proposed method achieves accurate RUL predictions. Then, a gear RUL dynamic control method based on multi-information collaborative decision-making is developed. This method dynamically regulates gear RUL using a model-free adaptive control (MFAC) strategy, leveraging multi-source information such as online RUL prediction results, expected usage duration, and real-time working conditions. Finally, a collaborative decision framework for dynamic control of gear RUL is proposed, which enables active gear health management to be implemented, thereby minimizing unscheduled downtime. The effectiveness of the proposed gear RUL dynamic control method is validated on a self-made gear transmission system experimental platform, achieving a 27.6 % reduction in average RMSE compared with state-of-the-art baselines and extending the operational life of gear by approximately 61 h under dynamic control.},
  archive      = {J_NEUCOM},
  author       = {Xuegang Li and Yuanyue Pu and Nian Wu and Huajun Cao and Xiaoxi Ding and Wenbin Huang},
  doi          = {10.1016/j.neucom.2025.131536},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131536},
  shortjournal = {Neurocomputing},
  title        = {A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew. <em>NEUCOM</em>, <em>656</em>, 131532. (<a href='https://doi.org/10.1016/j.neucom.2025.131532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the label distribution skew in federated learning based mechanical fault diagnosis, a federated learning based diagnosis framework combining prototypes and hybrid classifier is proposed. Firstly, prototypes are constructed based on sample feature means, and an exponential moving average strategy is introduced to smooth the aggregation of prototypes across rounds, while the prototype constraint loss function is constructed to guide the convergence of client features to the global prototype and compress the distance between similar samples. Secondly, a hybrid classifier architecture combining a local classifier with a global prototype classifier is proposed to learn local feature and global class prototypes through a two-branch structure, and a dynamic weighting strategy is used to achieve the output fusion. Finally, a prototype separation strategy is introduced on the server side, which detects pairs of confused class prototypes by Euclidean distance, increases the distance between similar prototypes, and avoids the prototype overlapping issue. In order to verify the effectiveness of the proposed method, nine kinds of faults of bearings, rotors and gears in mechanical transmission system are fabricated, and four types of fault diagnosis experiments with different degrees of label skew are designed, and the results show that the proposed method can effectively identify all the fault classes, and it still achieves an accuracy of 91.00 % in the extreme distribution skew task, which is significantly better than the other comparative methods, which provides a new feasible way for the distributed data driven federated learning based intelligent mechanical fault diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Hongwei Fan and Shenglin Liu and Xiangang Cao and Xuhui Zhang},
  doi          = {10.1016/j.neucom.2025.131532},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131532},
  shortjournal = {Neurocomputing},
  title        = {A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position. <em>NEUCOM</em>, <em>656</em>, 131531. (<a href='https://doi.org/10.1016/j.neucom.2025.131531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving time-varying linear equation flows presents a significant challenge in dynamic systems due to the continuously evolving coefficients, which undermine the effectiveness of traditional numerical methods. Moreover, the presence of external noise further exacerbates the difficulty of obtaining accurate solutions. To address these issues, this paper proposes a predefined-time double-integral zeroing neural network (PTDIZNN) model, inspired by the enhanced robustness of the conventional DIZNN framework. Specifically, a novel time-based gain is incorporated into the design of the DIZNN, ensuring predefined-time convergence of the proposed PTDIZNN model. A comprehensive theoretical analysis is conducted to verify its stability, convergence, and robustness properties. Furthermore, comparative simulations demonstrate that the PTDIZNN outperforms existing models in terms of solution accuracy and robustness under both column-full-rank and square-array coefficient scenarios. Finally, the effectiveness of the PTDIZNN is verified through its successful application in dynamic target positioning, highlighting its potential for broader real-time applications.},
  archive      = {J_NEUCOM},
  author       = {Jialiang Chen and Linju Li and Lin Xiao},
  doi          = {10.1016/j.neucom.2025.131531},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131531},
  shortjournal = {Neurocomputing},
  title        = {A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection. <em>NEUCOM</em>, <em>656</em>, 131529. (<a href='https://doi.org/10.1016/j.neucom.2025.131529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trigger-Action Programming (TAP) has emerged as a widely adopted paradigm for enabling automated interoperability among IoT devices. Despite its convenience, TAP introduces significant security vulnerabilities. To address this issue, we propose SAFE-TAP, a novel framework for detecting malicious TAP rules that integrates global semantic understanding with temporal feature analysis. To further enhance the detection performance, we introduce an innovative data augmentation strategy that leverages Large Language Models (LLMs) to generate semantically consistent rule variations. This approach improves data set balance and enhances the generalizability of the model. Experimental results demonstrate that SAFE-TAP outperforms baseline methods, and the incorporation of LLM-based data augmentation significantly improves detection performance under imbalanced data scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zhejun Kuang and Yusheng Zhu and Dawen Sun and Jian Zhao and Yongheng Xing and Feng Wang and Lei Sun},
  doi          = {10.1016/j.neucom.2025.131529},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131529},
  shortjournal = {Neurocomputing},
  title        = {SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The framework and memristive circuit design for attention-regulated working memory. <em>NEUCOM</em>, <em>656</em>, 131525. (<a href='https://doi.org/10.1016/j.neucom.2025.131525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive behavior and decision-making depend on constantly selecting relevant information from the external environment and internal states. Inspired by the working memory structure and the top-down and bottom-up attention mechanisms in cognitive neuroscience, this work proposes an attention-regulated working memory model. This model provides a brain-inspired approach to integrate perception, long-term memory, and action. It processes current external multisensory stimuli and retrieves stored knowledge from internal reinforcement simultaneously, leading to adaptive and rapid executive actions. On this basis, a memristive circuit is designed to realize rich cognitive functions in an online in-situ learning and in-memory computing manner. The designed circuit consists of four main components: (1) the phonological loop and visuospatial sketchpad consider different audio-visual input patterns and varying stimulus salience, realizing the filtration, synchronization, and encoding of multimodal signals; (2) the attention control module captures and maintains attention driven by multisensory stimulation; (3) the episodic buffer achieves reward reinforcement, forming or resetting the top-down attentional bias signal; (4) the central executive control module regulates the relationships between the two attentional pathways, thus transforming the random exploration process into a learnable final action. Finally, simulation results in LTSPICE demonstrate that our circuit can be adaptively applied to the cognitive control and execution system of robots within complicated circumstances.},
  archive      = {J_NEUCOM},
  author       = {Jihong Zhang and Xiaoping Wang and Zhanfei Chen and Chao Yang},
  doi          = {10.1016/j.neucom.2025.131525},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131525},
  shortjournal = {Neurocomputing},
  title        = {The framework and memristive circuit design for attention-regulated working memory},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporally coded multilayer spiking neural network and its memristor-based hardware implementation. <em>NEUCOM</em>, <em>656</em>, 131523. (<a href='https://doi.org/10.1016/j.neucom.2025.131523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have demonstrated remarkable progress in various domains. However, ANNs suffer from enormous time and energy consumption during training and inference processes. Brain-inspired spiking neural networks (SNNs) have recently attracted more attention due to their higher biological plausibility and potential cost-efficient properties. However, most existing SNNs significantly degrade in performance and efficiency when simulated on conventional CPU/GPU hardware. Therefore, a novel temporally coded multilayer SNN (TMSNN) is proposed in this study. It is a typical event-driven model, which encodes information in the relative timing of spikes rather than in firing rates and uses the leaky integrate-and-fire neuron as the basic unit to pursue high biological plausibility. Its multilayer architecture enables the model to solve complicated problems effectively. On the other hand, the proposed TMSNN can be implemented on memristor-based hardware, which uses customized weight quantization and sharing techniques to mitigate the size restrictions of the memristor crossbars. After refining the weights using the simulated annealing algorithm, the hardware implementation of TMSNN can achieve very competitive performance on benchmark datasets, outperforming state-of-the-art temporally coded SNNs in our experiments. The source code of TMSNN is available at https://github.com/jhc050998/Memristor-Crossbar-Based-SNN .},
  archive      = {J_NEUCOM},
  author       = {Haochang Jin and Xiuzhi Yang and Shuangbao Song and Zhenyu Song and Junkai Ji},
  doi          = {10.1016/j.neucom.2025.131523},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131523},
  shortjournal = {Neurocomputing},
  title        = {A temporally coded multilayer spiking neural network and its memristor-based hardware implementation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays. <em>NEUCOM</em>, <em>656</em>, 131522. (<a href='https://doi.org/10.1016/j.neucom.2025.131522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the exponential extended dissipative synchronization control problem of Cohen–Grossberg neural networks (CGNNs) with four kinds of time-varying delays. The types of delays involve time-varying leakage, neutral, distributed and transmission delays. Due to the increasing complexity of control requirements and time delays in practice, some performance analysis approaches and techniques cannot be directly applied, or are faced with the problem of high computational complexity. To this end, a more general and computationally efficient novel method is proposed. Firstly, a sufficient condition to guarantee the existence and uniqueness of the solution of CGNN is presented by defining a new norm, and a representation of the unique solution is first put forward. Then, the state-feedback controller and novel system solutions-based inequality are constructed to obtain exponential extended dissipative synchronization criteria. This proposed approach overcomes the difficulty of constructing a suitable Lyapunov–Krasovskii functional (LKF) under complex time delays and control requirements, and reduces computational complexity. Furthermore, to solve the nonlinear terms in the obtained criteria, an algorithm is designed. Finally, the derived results are validated for feasibility by three numerical examples, and their potential applications in image processing are showcased.},
  archive      = {J_NEUCOM},
  author       = {Kairong Tu and Yu Xue},
  doi          = {10.1016/j.neucom.2025.131522},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131522},
  shortjournal = {Neurocomputing},
  title        = {Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention. <em>NEUCOM</em>, <em>656</em>, 131518. (<a href='https://doi.org/10.1016/j.neucom.2025.131518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are one of the most important components of electrical machines and devices; however, they are prone to damage, leading to the lack of safety and the malfunction of machines. Some methods including deep-learning ones can be used for bearing fault diagnosis; however, in reality, the models have to adapt to the shortage of training data from clients while still maintaining good performance. To overcome this issue, the novel “MLFork” model is proposed, following the Few-shot algorithm for limited training with improvements in the feature extraction and the pre-classification steps. For feature extraction, a new Bi-Context Visual State Space Block is introduced, which excellently learns the global context of the sample in multiple ways. Before the Multi-Level classification module, separate routes for spatial-wise and channel-wise local vector attention are used to highlight the important details of the local descriptor. To evaluate the performance of the model, various experiments were done on the Case Western Reserve University dataset (CWRU) and the Paderborn University dataset (PU), where the “MLFork" model showed promising results. The code for this model will be available at: https://github.com/thzhere/MLFork .},
  archive      = {J_NEUCOM},
  author       = {Duy-Thai Nguyen and Van-Quoc-Viet Nguyen and Thi-Thao Tran and Van-Truong Pham},
  doi          = {10.1016/j.neucom.2025.131518},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131518},
  shortjournal = {Neurocomputing},
  title        = {MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-in-one image restoration via diffusion models with degradation perception and semantic enhancement. <em>NEUCOM</em>, <em>656</em>, 131517. (<a href='https://doi.org/10.1016/j.neucom.2025.131517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration is a fundamental task in computer vision. However, most existing methods are tailored for single-degradation scenarios, limiting their applicability in real-world conditions where multiple degradations often co-occur. To address this issue, we propose a degradation-aware image restoration framework. A bidirectional Mamba module is introduced to process fused spatial-frequency features, enabling accurate identification of degradation types via a multi-degradation encoding strategy. Based on the predicted degradation, a fine-tuned CLIP model with an attention mechanism is employed to extract semantic features. These features are then integrated with degradation representations and fed into a conditional denoising diffusion model to progressively reconstruct high-quality images. To facilitate evaluation, we construct the Multi-Degradation Perception Dataset (MDPD), specifically designed for complex degradation scenarios. Experimental results demonstrate that our method achieves over 98 % classification accuracy in identifying degradation types. On the MDPD dataset, it achieves a PSNR of 36.25 dB and improves SSIM by 0.01 to 0.04 across various degradation combinations.},
  archive      = {J_NEUCOM},
  author       = {Jiangang Jiang and Zhe Chen and Yuxin Su and Pancheng Zhang and Yihui Hu},
  doi          = {10.1016/j.neucom.2025.131517},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131517},
  shortjournal = {Neurocomputing},
  title        = {All-in-one image restoration via diffusion models with degradation perception and semantic enhancement},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems. <em>NEUCOM</em>, <em>656</em>, 131516. (<a href='https://doi.org/10.1016/j.neucom.2025.131516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel neural operator (NO)-based composite learning adaptive backstepping control scheme for stabilizing uncertain linear 2 × 2 hyperbolic PDE systems. This method addresses key challenges arising from complex PDE dynamics, model uncertainties, and high computational costs, within a backstepping design framework. Our approach integrates two main components: 1) A composite learning adaptive controller, which combines both historical and real-time data to construct informative matrices for parameter updates. This strategy enables accurate and exponential parameter convergence under finite excitation (FE) conditions, thereby improving transient performance and guaranteeing exponential system stability. 2) An efficient NO-based approximation method, where a deep operator network (DeepONet) is trained to approximate the nonlinear mapping from composite parameter estimates to backstepping kernel gains. The controller is constructed using the approximate kernels, which eliminates the need to repeatedly solve kernel PDE online, significantly improving the computational efficiency and accelerating real-time control. Furthermore, theoretical analysis proves closed-loop boundedness and exponential stability under the proposed scheme. Numerical simulations verify its effectiveness and superiority.},
  archive      = {J_NEUCOM},
  author       = {Xianhe Zhang and Yu Xiao and Xiaodong Xu and Biao Luo and Weihua Gui and Tingwen Huang},
  doi          = {10.1016/j.neucom.2025.131516},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131516},
  shortjournal = {Neurocomputing},
  title        = {Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAG-LER: Ranking adapted generation with language-model enabled regulation. <em>NEUCOM</em>, <em>656</em>, 131514. (<a href='https://doi.org/10.1016/j.neucom.2025.131514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated impressive capabilities across diverse NLP tasks, yet they still struggle with hallucination due to limited parametric knowledge. Retrieval Augmented Generation (RAG) addresses this issue by integrating non-parametric data stores. However, straightforward integration of information retrieval or end-to-end training of these components often leads to suboptimal results or computational inefficiency. In this work, we introduce RAG-LER, a framework that enhances an LM’s context understanding and improves the quality and accuracy of provided passages through an LM-supervised re-ranker. RAG-LER fine-tunes a pre-trained LM to follow instructions and discriminately use provided information. It then leverages this fine-tuned LM to generate ranking scores, which serve as supervised labels for training the re-ranker. We also introduce a confidence-weighted objective that filters unreliable LLM supervision signals while preserving the original re-ranker capabilities. By harnessing LLMs’ strong capabilities, our approach eliminates the need for manual human labeling in re-ranker training while achieving improved performance. Experiments demonstrate that RAG-LER outperforms existing retrieval-augmented LMs on open-domain QA and fact-checking tasks, while exhibiting consistently improved performance when applied to different retrieval methods, highlighting its versatility and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Fengwen Zhai and Wenyang Tang and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131514},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131514},
  shortjournal = {Neurocomputing},
  title        = {RAG-LER: Ranking adapted generation with language-model enabled regulation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces. <em>NEUCOM</em>, <em>656</em>, 131512. (<a href='https://doi.org/10.1016/j.neucom.2025.131512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are one of the most commonly used techniques in machine learning. In Mitz and Shkolnisky (2022) [27] , a framework of perturbation-based kernel matrix approximation is proposed, which is based on the tool of matrix perturbation analysis. However, there are two shortcomings in this framework. First, it requires that some dominant eigenvalues of kernel matrices are distinct in theory. However, in practical applications, when using a randomly sampled dataset, some kernel matrices generated by certain kernel functions are prone to having multiple eigenvalues due to data distribution or parameter settings. Second, from the algorithmic perspective, one has to know the error matrix of the kernel matrix in advance, which is unrealistic for real-world applications. Thus, the most common situation in practical applications is to pay attention to the case of multiple eigenvalues, and it is interesting to generalize the original perturbation-based kernel approximation framework to the scenario where there are multiple eigenvalues. In this work, we present a perturbation result on eigenvalues and eigenspaces of a kernel matrix whose dominant eigenvalues can be multiple. Based on this result, we propose a low-rank approximation to kernel matrix. On the other hand, as far as we are aware, efficient algorithms are still lacking for updating large-scale kernel matrices, and there are few algorithms addressing batch-incremental kernel methods. Based on our proposed truncated formula, we consider the incremental problem of large-scale kernel matrices and propose two incremental algorithms for updating large-scale kernel matrices. Numerical experiments demonstrate the efficiency of the proposed algorithms for solving incremental data problems and incremental kernel ridge regression.},
  archive      = {J_NEUCOM},
  author       = {Xiaxin Li and Gang Wu},
  doi          = {10.1016/j.neucom.2025.131512},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131512},
  shortjournal = {Neurocomputing},
  title        = {Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FMSF: Future-preference modeling with similar-user features for next POI recommendation. <em>NEUCOM</em>, <em>656</em>, 131511. (<a href='https://doi.org/10.1016/j.neucom.2025.131511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundant user check-in records in location-based social networks enhance the development of point-of-interest (POI) recommendation systems. The existing studies attempt to learn users’ past, current, and future preferences from their own sequential behaviors. Various approaches have been explored to model user visiting behaviors for the prediction of future preferences and have achieved considerable performance. However, most previous work ignores the impact of other users’ preferences on the prediction of current users’ future preferences. Thus, this work proposes a novel Future-preference Modeling with Similar-user Features (FMSF) model for next POI recommendation. It integrates the preferences of a user and those of other users to accurately model his/her multi-step future preferences. Specifically, it adopts a dynamically-updated similarity matrix to extract the information of similar users. Then, it incorporates an attention mechanism to assign distinct attention weights to the characteristics of both the current and similar users, which promotes the prediction of the future preferences of the current users. Therefore, the method proposed in this paper can offer users more precise recommendation results. Extensive experiments are conducted on three real-world datasets, which demonstrate the advantages of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Luan and Zhichao Feng and Liang Qi and Xiaoyu Sean Lu},
  doi          = {10.1016/j.neucom.2025.131511},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131511},
  shortjournal = {Neurocomputing},
  title        = {FMSF: Future-preference modeling with similar-user features for next POI recommendation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Permutation XOR cellular automata and direct stable periodic orbits. <em>NEUCOM</em>, <em>656</em>, 131510. (<a href='https://doi.org/10.1016/j.neucom.2025.131510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a permutation XOR cellular automaton (PXCA), a simple three-layer discrete-time dynamical system. The input-to-hidden layer corresponds to an elementary cellular automaton of the XOR rule and the hidden-to-output layer is the shift-type one-to-one permutation connection. The dynamics are described by an autonomous difference equation of binary state variables. Depending on the permutation connection, the PXCA generates a variety of direct stable periodic orbits (DBPOs) characterized by strong stability and fast transient phenomena. As a main result, we provide theoretical evidence that clarifies the number, period, and stability of DBPOs for general odd-dimensional PXCAs. Performing a precise numerical analysis, we have clarified that, depending on the dimension and a parameter, the period of DBPOs varies complicatedly and can become very long. Applications of the DBPOs include time series approximation and switching circuit control. As a fundamental step toward the applications, we present a simple FPGA based hardware prototype and have confirmed typical DBPOs experimentally.},
  archive      = {J_NEUCOM},
  author       = {Mikito Onuki and Yosuke Suzuki and Toshimichi Saito},
  doi          = {10.1016/j.neucom.2025.131510},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131510},
  shortjournal = {Neurocomputing},
  title        = {Permutation XOR cellular automata and direct stable periodic orbits},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model. <em>NEUCOM</em>, <em>656</em>, 131509. (<a href='https://doi.org/10.1016/j.neucom.2025.131509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain network representation learning leverages graph-based algorithms to enhance understanding of functional brain organization. Recently, deep learning approaches based on graph neural network (GNN) have shown promising results in various brain network analysis tasks. Nevertheless, despite significant achievements in brain graph learning, early models still exhibit limitations in dynamic modeling and multi-modal network fusion. Dynamic modeling of brain networks entails learning sequential spatial interactions across time. Inspired by recent advances in large language model architectures, particularly RWKV, which combines the strengths of recurrent neural networks (RNNs) and Transformers. We propose an e fficient t emporal m ulti-modal g raph n eural n etwork (ET_MGNN), that captures complex temporal dependencies while integrating dynamic functional connectivity (DFC) and structural connectivity (SC) into a unified brain network representation. The proposed model demonstrates competitive performance in brain disorder classification on three datasets, outperforming several strong baselines. For instance, ET_MGNN an average classification accuracy improvement of 11.8 % on autism spectrum disorder (ASD) vs healthy controls, 32.9 % on Alzheimer's disease (AD) vs. mild cognitive impairment (MCI), compared to the well-suited STAGIN model. Furthermore, we introduce an interpretable graph reading mechanism that can identify disorder-relevant brain regions. In summary, ET_MGNN combines large-scale language sequence modeling with dynamic brain graph representation learning to improve the accuracy of brain disease diagnosis, providing insightful findings for dynamic brain network modeling.},
  archive      = {J_NEUCOM},
  author       = {Jinwei Lang and Li-Zhuang Yang and Hai Li},
  doi          = {10.1016/j.neucom.2025.131509},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131509},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer. <em>NEUCOM</em>, <em>656</em>, 131508. (<a href='https://doi.org/10.1016/j.neucom.2025.131508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene flow estimation is a computer vision task that aims to estimate the 3D motion field of points from two consecutive frames of point clouds, and has a wide range of applications in various fields such as robotics and autonomous driving. Most of the existing methods estimate scene flow through point-based models, but ignore the irregularity of point clouds and the inefficiency of point-level computation. And voxel-based methods can hardly avoid the loss of detailed information. Therefore, we propose a point-voxel fusion method that contains a point branch and a voxel branch. The voxel branch projects the point cloud to regular local grids and captures coarse-grained local features from non-empty voxels through Sparse Grid Attention (SGA) with the shift window strategy. And the point branch captures fine-grained global features through dual attention consisting of Deformable Global Attention (DGA) and Channel Self-Attention (CSA), while compensating for the information loss in the voxel branch. Considering that it is difficult to directly describe the local geometric structure of complex objects in the scene with the shape of 3D objects potentially learned only through xyz coordinates, we explicitly encode the local surface information of the point cloud through the Umbrella Surface Feature Extraction (USFE) module. In addition, we introduce Density Sensitive Metric(DSM) loss to reduce the impact of outliers and density distribution mismatch problems. We validate the effectiveness of our method by performing experiments on the Flyingthings3D and KITTI datasets. Our method outperforms all other self-supervised methods and achieves highly competitive results compared to fully supervised methods. We achieve improvements in all metrics, especially EPE, which is decreased by 8.51 % on the KITTI o dataset and 15.79 % on the KITTI s dataset.},
  archive      = {J_NEUCOM},
  author       = {Xuezhi Xiang and Xi Wang and Xiaoheng Li and Xiankun Zhou and Lei Zhang and Xiantong Zhen},
  doi          = {10.1016/j.neucom.2025.131508},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131508},
  shortjournal = {Neurocomputing},
  title        = {PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models. <em>NEUCOM</em>, <em>656</em>, 131505. (<a href='https://doi.org/10.1016/j.neucom.2025.131505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image person re-identification (TIReID) aims to retrieve pedestrian images from a database that match given text queries. Currently, the most advanced methods involve transferring powerful multi-modal knowledge from the contrastive language-image pretraining (CLIP) model to perform cross-modal matching. However, CLIP primarily focuses on coarse-grained global contextual modeling of single image-text pairs, neglecting fine-grained compositional matching of complex visual-textual concepts. This makes it challenging to ensure fine-grained cross-modal matching between pedestrians and text queries. To address this issue, a novel framework, Collaborating Pre-trained Diffusion and Discriminative Models (CPDD), is proposed in this work. The CPDD comprises three modules: a fine-grained features learning (FFL) module, a semantic consistency alignment (SCA) module, and a masked-text interactive modeling (MIM) module. Firstly, the FFL learns feature representations containing fine-grained matching information between images and text through the reverse denoising process of a diffusion model. Next, a semantic consistency loss is designed in the SCA, which ensures the semantic consistency between the fine-grained matching information and the input image and text information. Then, the MIM propagates fine-grained matching information into the visual- textual context by a cross-modal interactive encoder, achieving fine-grained matching between images and text and enabling fine-grained cross-modal matching. Extensive experiments on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets show that the proposed method achieves significant performance improvements compared to current research results, achieving Rank-1 accuracy of 74.87 %, 63.31 %, and 61.26 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Zhang and Chenyue Xu and Huajing Wu and Quange Tan and Qianli Zhou and Rong Wang},
  doi          = {10.1016/j.neucom.2025.131505},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131505},
  shortjournal = {Neurocomputing},
  title        = {Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-wise contrastive learning BERT for sentence representation of GitHub. <em>NEUCOM</em>, <em>656</em>, 131504. (<a href='https://doi.org/10.1016/j.neucom.2025.131504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, on GitHub, end-users submit a large number of issues that must be addressed to ensure the success of software projects. Though BERT-based pre-trained language models achieve high performance on many downstream tasks, the sentence representation of [CLS] from the top layer of BERT has a limited ability to capture the semantic meaning of sentences. GitHub issue reports often include code snippets and user-generated terms not found in standard vocabularies. Therefore, the classification predictions of BERT are affected. To generate better sentence semantic representations of BERT for GitHub, we propose a layer-wise Contrastive Learning BERT (CLBERT), which uses contrastive learning to enhance the representation ability by contrasting the layer-by-layer representation. Further, to obtain as comprehensive information as possible, representations of each layer are extracted and learned by an attention mechanism as the final classification features. Finally, experiments conducted on two GitHub data sets show that our proposed model significantly improves classification performance.},
  archive      = {J_NEUCOM},
  author       = {Daoquan Chen and Wei Zhang and Shengyu Lu and Yuanguo Lin and Xinyu Gu and Xiuze Zhou},
  doi          = {10.1016/j.neucom.2025.131504},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131504},
  shortjournal = {Neurocomputing},
  title        = {Layer-wise contrastive learning BERT for sentence representation of GitHub},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attacking all tasks at once using adversarial examples in multi-task learning. <em>NEUCOM</em>, <em>656</em>, 131503. (<a href='https://doi.org/10.1016/j.neucom.2025.131503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual content understanding frequently relies on multi-task models to extract robust representations of a single visual input for multiple downstream tasks. However, in comparison to extensively studied single-task models, the adversarial robustness of multi-task models has received significantly less attention and many questions remain unclear: (1) How robust are multi-task models to single task adversarial attacks, (2) Can adversarial attacks be designed to simultaneously attack all tasks in a multi-task model, and (3) How does parameter sharing across tasks affect multi-task model robustness to adversarial attacks? This paper aims to answer these questions through careful analysis and rigorous experimentation. First, we analyze the inherent drawbacks of two commonly-used adaptations of single-task white-box attacks in attacking multi-task models. We then propose a novel attack framework, Dynamic Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking all tasks in a multi-task model as an optimization problem that can be efficiently solved through integer linear programming. Extensive evaluation on two popular MTL benchmarks, NYUv2 and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to baselines in attacking both clean and adversarially trained multi-task models. Our results also reveal a fundamental trade-off between improving task accuracy via parameter sharing across tasks and undermining model robustness due to increased attack transferability from parameter sharing.},
  archive      = {J_NEUCOM},
  author       = {Lijun Zhang and Xiao Liu and Kaleel Mahmood and Caiwen Ding and Hui Guan},
  doi          = {10.1016/j.neucom.2025.131503},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131503},
  shortjournal = {Neurocomputing},
  title        = {Attacking all tasks at once using adversarial examples in multi-task learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation. <em>NEUCOM</em>, <em>656</em>, 131502. (<a href='https://doi.org/10.1016/j.neucom.2025.131502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Superpixel segmentation is crucial for enhancing image processing efficiency and accuracy. To address the challenges of decreased accuracy and insufficient stability in adaptive superpixel generation faced by existing algorithms in complex image segmentation, we propose ECN, an unsupervised superpixel segmentation algorithm based on convolutional neural networks (CNN) integrating edge complexity and channel attention mechanisms. The ECN algorithm first calculates edge complexity using the Sobel operator, which guides the sequential network in determining the number of feature channels and the kernel size of the fast 1D convolution. Subsequently, low-level features with positional information are transformed into deep features through the sequential network, dynamically adjusting the weights of each feature channel using the channel attention mechanism. Finally, the target function is minimized during inference, enabling unsupervised superpixel generation. We validate ECN's applicability by combining it with Linear Discriminant Analysis (LDA) and Locality Fisher Discriminant Analysis (LFDA) to develop Superpixel Unsupervised Linear Discriminant Analysis (SULDA). Experimental results on BSDS500 and NYUv2 datasets show ECN outperforms existing methods, producing stable and higher-quality superpixel segmentation. Application tests on Indian Pines and Pavia University scenes confirm ECN's significant practical utility.},
  archive      = {J_NEUCOM},
  author       = {Fugui Luo and Shihua Li and Minghui Chang and Yuting Liu and Kaitong Liu},
  doi          = {10.1016/j.neucom.2025.131502},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131502},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge distillation-based object detection model focused on road scene perception and localization. <em>NEUCOM</em>, <em>656</em>, 131501. (<a href='https://doi.org/10.1016/j.neucom.2025.131501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is crucial for unmanned systems, as it enables real-time classification and localization of objects in road scenes. Besides detection accuracy, which remains robust to variations in object scales, an effective object detection algorithm also demands superior performance in processing time. To address these issues, this paper proposes a knowledge distillation-based object detection model, PLE-RepPoints-Lite, to compromise the performance of detection accuracy and speed for unmanned systems. We also design perception and localization enhancement (PLE) strategies, which consist of parallel dynamic attention, multi-scale composite localization confidence, and a feedback closed-loop structure, to enhance the capabilities of perception and localization in complex road environments. To improve the real-time performance, a hybrid lightweight approach for road scenes is designed. Experimental results on the Cityscapes and BDD100K datasets show that our approach achieves state-of-the-art results with average precision (AP) of 34.6 and 40.1, respectively. Furthermore, it operates at 34.2 frames per second (FPS) at a 1280 × 640 resolution, satisfying real-time requirements.},
  archive      = {J_NEUCOM},
  author       = {Yufei Xie and Ying Shi and Changjun Xie and Qin Hu and Yue Liu and Chaojun Lin},
  doi          = {10.1016/j.neucom.2025.131501},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131501},
  shortjournal = {Neurocomputing},
  title        = {A knowledge distillation-based object detection model focused on road scene perception and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confident neural network regression with bootstrapped deep ensembles. <em>NEUCOM</em>, <em>656</em>, 131500. (<a href='https://doi.org/10.1016/j.neucom.2025.131500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise in the popularity and usage of neural networks, trustworthy uncertainty estimation is becoming increasingly essential. One of the most prominent uncertainty estimation methods is Deep Ensembles [20]. A classical parametric model has uncertainty in the parameters due to the fact that the data on which the model is built is a random sample. A modern neural network has an additional uncertainty component since the optimization of the network is random. Lakshminarayanan et al. [20] noted that Deep Ensembles do not incorporate the classical uncertainty induced by the effect of finite data. In this paper, we present a computationally cheap extension of Deep Ensembles for the regression setting, called Bootstrapped Deep Ensembles , that explicitly takes this classical effect of finite data into account using a modified version of the parametric bootstrap. We demonstrate through an experimental study that our method significantly improves upon standard Deep Ensembles. The resulting confidence intervals demonstrate superior coverage without sacrificing accuracy.},
  archive      = {J_NEUCOM},
  author       = {Laurens Sluijterman and Eric Cator and Tom Heskes},
  doi          = {10.1016/j.neucom.2025.131500},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131500},
  shortjournal = {Neurocomputing},
  title        = {Confident neural network regression with bootstrapped deep ensembles},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter-free multi-view clustering via refined tensor learning. <em>NEUCOM</em>, <em>656</em>, 131497. (<a href='https://doi.org/10.1016/j.neucom.2025.131497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As multi-view data becomes more prevalent in real-world applications, multi-view clustering (MVC) has emerged as a powerful technique for unsupervised representation learning. To uncover the intrinsic structure, it is crucial to consider information from different spaces. Focusing solely on the sample space limits the method’s ability to effectively model multi-view data, as the informative patterns embedded in the feature space are often overlooked. Furthermore, to integrate high-order correlations, tensor-based MVC methods have been widely adopted to preserve the low rank structure of multi-view data. Traditional tensors can not achieve selective tensor rank minimization as they lack an explicit mechanism to model the retention of singular values based on their individual information contributions. Additionally, existing methods rely on hyper-parameters, undermining generalizability across different datasets. In response to these limitations, we propose a novel Parameter-free Multi-view Clustering via Refined Tensor Learning (PRTL), which is based on bidirectional regression matrices to perform data reconstruction and extract salient features. To further achieve an adaptive low-rank tensor structure, we propose a Quadratic Decay Tensor (QDT) regularization as a non-convex alternative to conventional rank minimization, which selectively retains salient information while filtering out noise dynamically, resulting in a more expressive joint representation. Meanwhile, we incorporate the hyper-Laplace graph to capture richer relationships than those modeled by conventional pairwise graphs. Notably, PRTL eliminates the need for hyper-parameters, making it more practical and robust. Experiments on diverse datasets demonstrate that PRTL consistently surpasses existing state-of-the-art clustering methods. Our code is available at https://github.com/jiaxinyang04/PRTL .},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Yang and Qian Liu and Yuemeng Huang and Chunyan Yang and Wengeng Chen and Yu Lu and Jiale Wang and Wenzhe Liu and Huibing Wang},
  doi          = {10.1016/j.neucom.2025.131497},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131497},
  shortjournal = {Neurocomputing},
  title        = {Parameter-free multi-view clustering via refined tensor learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis. <em>NEUCOM</em>, <em>656</em>, 131496. (<a href='https://doi.org/10.1016/j.neucom.2025.131496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have shown significant advancements in modelling complex non-linear relationships in high-dimensional biomedical data. Understanding the interplay between genetic variants and disease susceptibility is still a considerable challenge that prevents certain genomic diseases to be predicted accurately for clinical interventions. In this study, we introduce the Extensive Multi-Variant Deep Neural Network (EMV-DNN), an innovative deep learning methodology designed to enhance polygenic risk prediction. Unlike conventional polygenic risk score methods, EMV-DNN incorporates single nucleotide polymorphisms (SNPs) alongside structural variants including insertions and deletions (indels), short tandem repeats (STRs), and copy number variants (CNVs) using variant-specific subnetworks to extract informative embeddings which capture a richer and holistic genomic context. Evaluated on real-world cohorts from the UK Biobank and All of Us, EMV-DNN outperforms conventional PRS methods and classic machine learning algorithms across binary and multi-class prediction tasks. Beyond predictive performance, SHapley Additive exPlanations (SHAP) analysis revealed biologically plausible variant–gene–disease associations, highlighting pathways related to endometrial cell proliferation, fibrosis, and immune regulation. Our findings underscore the value of multi-variant integration and non-linear approaches to capture the intricate genetic architecture of complex genomic diseases. Despite challenges such as dataset limitations and the complexity of diseases with multiple contributing factors, the EMV-DNN methodology presents a promising avenue for enhancing the predictive accuracy of PRS, thereby facilitating personalized healthcare interventions and advancing our understanding of genetic predispositions to disease.},
  archive      = {J_NEUCOM},
  author       = {Zelia Soo and Hua Lin and Yue Yang and Mark Grosser and Mengjia Wu and Yi Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2025.131496},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131496},
  shortjournal = {Neurocomputing},
  title        = {An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder. <em>NEUCOM</em>, <em>656</em>, 131495. (<a href='https://doi.org/10.1016/j.neucom.2025.131495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a method for reconstructing occluded facial expressions. Firstly, a self-supervised learning Masked Auto-Encoder based facial expression recognition (MAE-FER) method is introduced, which effectively reduces the computational cost and parameter count by enhancing the multi-scale local-global self-attention interaction encoder, thereby improving the training efficiency and generalization capability of the model. Secondly, to address the problem of facial expression occlusion in real-world scenarios, a MAE-based occlusion detector is designed to detect occluded parts of the face, providing effective support for subsequent reconstruction tasks. Subsequently, the Dynamic Weight Allocation Generative Adversarial Network (DWA-GAN) for facial expression occlusion recovery is proposed, which achieves precise occlusion recovery by dynamically allocating weights to reference image blocks, significantly improving the accuracy of reconstruction. Finally, feature fusion is performed on the reconstructed results and applied to the FER task to further enhance classification accuracy and stability. Utilizing the pre-trained MAE-FER model, key hidden vectors are extracted from facial expression images, containing important feature information related to expression recognition. Through this step, closely related features to expression recognition are selected while irrelevant details are discarded, optimizing the inter-class distance issue of facial expressions. Next, to address the performance degradation caused by label ambiguity, an improved Rotate Erasing Attention Consistency (REAC) method is adopted, which effectively mitigates the negative impact of label ambiguity, further improving the accuracy and stability of FER. Experimental results demonstrate that the method achieves the best performance on the RAF-DB dataset.},
  archive      = {J_NEUCOM},
  author       = {Chaolong Zhang and Yuanping Xu and Zhijie Xu and Rongqiang Gou and Weiye Wang and Jin Jin and Jian Huang},
  doi          = {10.1016/j.neucom.2025.131495},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131495},
  shortjournal = {Neurocomputing},
  title        = {A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scattered data augmentation for generalization in visual reinforcement learning. <em>NEUCOM</em>, <em>656</em>, 131492. (<a href='https://doi.org/10.1016/j.neucom.2025.131492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation (DA) has shown a significant potential to enhance generalization performance in visual reinforcement learning (VRL). However, existing research on DA-based methods is predominantly empirical, and the mechanism for why DA enhances generalization remains theoretically under-explored. To bridge this gap, we derive a generalization error upper bound for VRL from the perspective of data distribution distance. Based on this bound, we provide a theoretical explanation of the mechanism by which DA improves generalization: we find that DA that satisfies certain conditions can reduce the distance between the training and test distributions, thus making the training and test samples closer. In addition, we conditionally prove that training data with higher variance can provide a higher generalization performance. Motivated by our analysis, we propose Scattered Data Augmentation (ScDA) framework. ScDA constructs a data transformation system with the agent serving as the discriminator, aiming to provide more diverse training data for agent training. Experiments are conducted across various tasks and numerous test modes in DeepMind Control Generalization Benchmark2 (DMC-GB2) and robotic tasks. Results demonstrate that our ScDA framework can be integrated with different baseline algorithms and significantly enhance policy generalization, outperforming the current state-of-the-art methods in the DMC-GB2 tests, confirming the effectiveness of the theoretical analysis in this work. The code for this work can be found at: https://github.com/scdadev/scdadev .},
  archive      = {J_NEUCOM},
  author       = {Hao Lei and Yu Zhao and Yi Xin and Zhang Shaonan and Ke Liangjun},
  doi          = {10.1016/j.neucom.2025.131492},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131492},
  shortjournal = {Neurocomputing},
  title        = {Scattered data augmentation for generalization in visual reinforcement learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131491. (<a href='https://doi.org/10.1016/j.neucom.2025.131491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional derivatives have gained prominence in optimization for their inherent non-locality and memory-dependent properties, effectively capturing historical dependencies. This work introduces an Adaptive Fractional-order Gradient Descent (AFGD) algorithm based on Caputo fractional derivatives, with deep integration into Temporal Convolutional Networks (TCNs). Unlike conventional fixed-order methods, AFGD employs an adaptive fractional-order mechanism to enhance optimization. Theoretically, we establish rigorous proofs for AFGD’s monotonic convergence in loss function minimization, supported by numerical simulations of its convergence behavior. Evaluated on the MIT-BIH arrhythmia five-class classification benchmark, TCNs optimized with AFGD achieve superior accuracy over established methods, demonstrating the efficacy of the proposed gradient scheme for deep learning optimization.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Xiao and Jiejie Chen and Xuewen Zhou and Bin Wei and Ping Jiang and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2025.131491},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131491},
  shortjournal = {Neurocomputing},
  title        = {Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation. <em>NEUCOM</em>, <em>656</em>, 131490. (<a href='https://doi.org/10.1016/j.neucom.2025.131490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Weighted Networks (DWN) usually appear in various big data-related complex systems and can describe real-time interactions between a large number of entities. As the number of entities increases dramatically, it is impossible for each entity to have complete interaction with each other, which results in such a DWN being High-Dimensional and Incomplete (HDI). Tensor Wheel Decomposition (TWD), as a novel tensor network, has powerful representation capabilities, but existing TWD-based methods require additional computational and storage costs to process an HDI DWN. To address these challenges, we propose an Adaptive integral separation PID–guided Tensor Wheel Decomposition (APTWD) model that: 1) employs a data density-oriented loss function, ensuring the representation learning is focused on the existing information in the target network to obtain more accurate low-rank embedding; and 2) develops a parameter learning scheme with error control feedback based on the integral separation PID controller to minimize the convergence iteration process. Experiments on six real-world DWN datasets demonstrate that APTWD consistently outperforms state-of-the-art methods, delivering higher representation accuracy and significantly reduced computational cost.},
  archive      = {J_NEUCOM},
  author       = {Jiqiu Chen and Qu Wang and Hao Wu},
  doi          = {10.1016/j.neucom.2025.131490},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131490},
  shortjournal = {Neurocomputing},
  title        = {An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view unsupervised feature selection based on graph discrepancy learning. <em>NEUCOM</em>, <em>656</em>, 131487. (<a href='https://doi.org/10.1016/j.neucom.2025.131487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view learning, unsupervised feature selection plays a vital role in reducing dimensionality while preserving discriminative information distributed across diverse data modalities. Despite notable progress, existing approaches frequently exhibit two key limitations: they often overlook the complementary benefits of integrating global and local structural information, and they inadequately model complex nonlinear relationships or align structural representations across views. To address these challenges, we propose a novel framework, termed Multi-view unsupervised feature selection based on graph discrepancy learning (GDFS). The proposed method jointly constructs global graph structures in a projected low-dimensional space and local graphs in a nonlinear kernel-induced space, effectively capturing both high-level semantic structures and fine-grained neighborhood dependencies. A graph discrepancy term is introduced to explicitly reduce structural discrepancies between global and local representations, thus enhancing consistency and robustness. In addition, a low-rank tensor constraint is applied to the stack of global graphs to uncover high-order correlations across views. A consensus clustering matrix is further learned to provide pseudo-label supervision, which guides the selection of discriminative features. Extensive experiments on six benchmark multi-view datasets demonstrate that GDFS consistently surpasses state-of-the-art methods in terms of clustering performance, thereby confirming its effectiveness, scalability, and generalizability. The code is available at https://github.com/xyw0111/2025-GDFS .},
  archive      = {J_NEUCOM},
  author       = {Yiwan Xu and Xijiong Xie and Xianliang Jiang and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131487},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131487},
  shortjournal = {Neurocomputing},
  title        = {Multi-view unsupervised feature selection based on graph discrepancy learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets. <em>NEUCOM</em>, <em>656</em>, 131486. (<a href='https://doi.org/10.1016/j.neucom.2025.131486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets have established a novel approach to anomaly detection through uncertainty handling. Nevertheless, traditional approaches are susceptible to noise. Existing kernelized methods improve feature representation via kernel transformations. However, they are typically restricted to a single-kernel framework, which limits the capacity to model the heterogeneous nature of mixed-attribute data. To address this issue, this study proposes a granular-ball generation algorithm tailored to the characteristics of mixed-attribute data. Multiple kernel functions are employed to effectively integrate the fuzzy relations of various attribute types. By integrating fuzzy rough set theory, granular-ball computing, and multi-kernel methods, a granular-ball multi-kernel fuzzy rough set model is proposed. Besides, a novel unsupervised anomaly detection method is proposed to effectively process mixed-attribute data. This method integrates kernelized fuzzy relations across various attribute types, constructs kernelized fuzzy information granules, and computes anomaly scores based on multiple granular-ball kernelized fuzzy information granules. Finally, an anomaly factor is introduced to quantify the anomaly degree of data objects. Comparative experiments were conducted on 16 public datasets. The novel approach consistently outperformed current methodologies in AUC metrics while demonstrating superior robustness across diverse data samples.},
  archive      = {J_NEUCOM},
  author       = {Cong Gao and Qiu Wang and Yanping Chen and Qingqi Pei and Zhongmin Wang},
  doi          = {10.1016/j.neucom.2025.131486},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131486},
  shortjournal = {Neurocomputing},
  title        = {A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process. <em>NEUCOM</em>, <em>656</em>, 131485. (<a href='https://doi.org/10.1016/j.neucom.2025.131485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate real-time detection of copper matte grade is critical for state identification and optimization control in flash smelting, yet remains challenging due to the complex and harsh industrial environment. To address this issue, this study proposes a knowledge-guided encoder-decoder network. In this method, Bidirectional Gated Recurrent Unit serves as the backbone architecture for both the encoding and decoding processes, enabling nonlinear dynamic modeling in the temporal domain. The encoder integrates a composite variable attention mechanism, which leverages process knowledge to prioritize key variables based on their importance. A temporal decay attention mechanism is added to the decoder, endowing the model with the ability to simulate the temporal dependency between copper matte grade and process variables through prior knowledge. These knowledge-guided designs strengthen the ability of model to capture process-specific relationships between input variables and copper matte grade. Industrial experiments based on real production data from a smelting plant in China, show that the proposed model achieves optimal performance, with 96 % absolute errors not exceeding 0.5 %. It demonstrates that the proposed model not only provides accurate and real-time copper matte grade estimation but also maintains robustness in industrial environments, verifying its potential for practical application in flash smelting process.},
  archive      = {J_NEUCOM},
  author       = {Zhou Zou and Can Zhou and Chunhua Yang},
  doi          = {10.1016/j.neucom.2025.131485},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131485},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-resolution QP-adaptive generative face video compression using multi-level generator. <em>NEUCOM</em>, <em>656</em>, 131484. (<a href='https://doi.org/10.1016/j.neucom.2025.131484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multi-resolution quantization parameter (QP)-adaptive generative face video compression (GFVC) framework to realize face video communication at an ultra-low bitrate. By leveraging deep generative models and semantic feature representation, the proposed framework achieves high perceptual quality while significantly reducing bitrate. The proposed framework dynamically adjusts feature granularity based on QP values and integrates modules such as multi-level multi-DConv head transposed attention (MDTA) and multi-level spatially adaptive denormalization (SPADE) to enhance both spatial fidelity and temporal consistency. To ensure adaptability and standardization, we further extend the proposed framework to support multi-resolution inputs and incorporate feature encoding based on Supplemental Enhancement Information (SEI) in VVC. Specifically, we introduce the flag gfv_enhancement_matrix_flag to transmit an optional 8 × 8 enhancement matrix, enabling precise refinement of inter-frame reconstruction in compliance with VVC. A multi-reference frame buffer mechanism is also implemented to improve long-term temporal coherence through attention-guided reference selection. Experimental results demonstrate that the proposed GFVC framework achieves average BD-rate gains of 63.87 % in DISTS and 61.99 % in LPIPS on benchmark datasets compared to the VVC anchor (VTM-22.2 LDB mode). Without retraining, the proposed framework operates smoothly even on face videos with a resolution of 512 × 512 , achieving 23.40 % BD-rate gain in DISTS and indicating strong scalability. These results validate the practical feasibility of the proposed GFVC framework in real-world video conferencing and telepresence scenarios, especially under ultra-low bandwidth conditions.},
  archive      = {J_NEUCOM},
  author       = {Wenbo Kang and Lu Liu and Cheolkon Jung},
  doi          = {10.1016/j.neucom.2025.131484},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131484},
  shortjournal = {Neurocomputing},
  title        = {Multi-resolution QP-adaptive generative face video compression using multi-level generator},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding. <em>NEUCOM</em>, <em>656</em>, 131480. (<a href='https://doi.org/10.1016/j.neucom.2025.131480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective Motor imagery brain-computer interface (MI-BCI) is a representative BCI system. Recent studies in MI-BCI focus on Fine Joint MI (FJMI) decoding that recognizes the motor intention of different joints from one upper limb. However, due to the low spatial difference between EEG patterns of FJMI, achieving optimal performance remains a challenge of multi-class FJMI decoding studies. Methods: We proposed a novel approach named Filter Bank Convolutional Network with Dual Channel Attention (FB-DCANet) that enables feature extraction and selection in MI-EEG across multi-class FJMI tasks. This network features a combined filter bank in frequency and time domain that simultaneously extracts spatio-temporal information from four frequency bands (alpha, beta, theta, and low gamma), accompanied with temporal convolutional modules for additional temporal information extraction. Moreover, a feature selection method based on Dual Channel Attention was proposed combining preliminary intra-band feature selection via Residual Channel Self-Attention (RCSA) and further inter-band feature selection from different frequency bands by Efficient Channel Attention (ECA). Results: We performed experiments using FJMI-EEG data from the unilateral upper limb, and FB-DCANet achieved an accuracy of 59.34 % in a 4-class classification scenario (hand MI, elbow MI, shoulder MI, and resting state), and interpretability of FB-DCANet was analyzed by visualization of Class Activation Map (CAM) and attention values. Conclusion and Significance: This work presents a novel approach with a time-frequency filter bank and Dual Channel Attention-based feature selection for multi-class FJMI decoding, which can be utilized to develop a rehabilitation system based on FJMI-BCI.},
  archive      = {J_NEUCOM},
  author       = {Jiaming Chen and Yueqi Zhang and Kaide Liu and Xinkang Hu and Meng Xu and Dan Wang and Weibo Yi},
  doi          = {10.1016/j.neucom.2025.131480},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131480},
  shortjournal = {Neurocomputing},
  title        = {Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme. <em>NEUCOM</em>, <em>656</em>, 131479. (<a href='https://doi.org/10.1016/j.neucom.2025.131479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of synchronization control for semi-Markov jump two-time-scale neural networks, in which the output-feedback mechanism is adopted and a dual event-triggered scheme is employed using a double-rate sampling method to balance system performance and communication efficiency. First, considering the two-time-scale property of the semi-Markov jump neural networks, the dual-rate sampling strategy is adopted such that two independent event-triggered conditions for different time scales can be designed, which ensure efficient resource utilization while maintaining system performance. Then, a Lyapunov–Krasovskii functional with the singular perturbation parameter is constructed to deduce sufficient conditions ensuring that the synchronization error system is stochastically stable and satisfies a given H ∞ performance index. Moreover, the solution for obtaining the controller gains is presented to guarantee synchronization of the considered system under a dual event-triggered scheme. Finally, the feasibility of the methods is demonstrated by two examples, including a numerical example and an image encryption. They show that this event-triggered mechanism provides an efficient new synchronization control scheme for semi-Markov jump two-time-scale neural network systems while reducing the network burden.},
  archive      = {J_NEUCOM},
  author       = {Wenyan Zuo and Ya-Nan Wang and Feng Li and Sangmoon Lee},
  doi          = {10.1016/j.neucom.2025.131479},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131479},
  shortjournal = {Neurocomputing},
  title        = {Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131478. (<a href='https://doi.org/10.1016/j.neucom.2025.131478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning based on graph convolutional networks boosts performance by incorporating diverse perspectives, leading to significant achievements and successful applications across various academic and practical fields. However, multi-view graph convolutional networks suffer from substantial computational challenges on large-scale graphs. To address this limitation, graph condensation has emerged as a promising direction by creating a smaller composite graph that allows for efficient network training while preserving performance. Furthermore, previous studies have demonstrated that encouraging performance in graph learning is achieved via graph compression. To this end, we attempt to introduce graph condensation into the multi-view learning for computation acceleration. This approach not only reduces training costs significantly but also achieves sub-linear time complexity and memory consumption during network training. Further, we propose a gradient flow induced graph convolutional network from partial differential equations, which offers theoretical guarantees and potential new insights for the graph-related network architecture construction with transparent model interpretability. Extensive experiments on seven real-world multi-view datasets demonstrate that the proposed method sharply decreases model training time while ensuring competitive multi-view semi-supervised classification.},
  archive      = {J_NEUCOM},
  author       = {Lu Liu and Yang Huang and Yueyang Pi and Zhicheng Wei and Jinbo Li and Shiping Wang},
  doi          = {10.1016/j.neucom.2025.131478},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131478},
  shortjournal = {Neurocomputing},
  title        = {Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning. <em>NEUCOM</em>, <em>656</em>, 131476. (<a href='https://doi.org/10.1016/j.neucom.2025.131476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal Bayesian regression (OBR) for data generated from a multidimensional vector autoregressive process of order p , denoted as VAR ( p ) , has a closed-form analytic expression that has been previously obtained. Despite the closed-form expressions to compute the “OBR-VAR”, in certain practical scenarios the computational cost involved in training OBR-VAR is a bottleneck. From a computational perspective, two common scenarios that incur excessive computational cost are: 1) given a set of training data, estimating the unknown model order p generally entails computing the OBR-VAR from scratch for every p in a range from 1 to a maximum value; and 2) in dynamic environments where data arrives sequentially, currently one must recompute OBR-VAR from scratch for every new upcoming observation. To address the first issue, in this paper, an order-recursive OBR-VAR regressor using QR decomposition is proposed. This method efficiently updates the regressor without recalculating it from scratch for each p , significantly reducing computational complexity while preserving model accuracy. Analytical results demonstrate that the proposed order-recursive method achieves a computational complexity reduction by a factor proportional to p , making it scalable to larger datasets and higher model orders. To address the second issue, an incremental version of the OBR-VAR algorithm is developed for real-time data processing. This method updates the regressor incrementally as new data points arrive, maintaining accuracy without the need for costly recomputation of key matrices. Its capability makes it well-suited for continuous-time data acquisition and streaming applications, where timely and accurate responses are critical. In all cases we assume an improper non-informative prior to model the case of having no prior knowledge about the problem. Theoretical analysis and empirical evaluations using synthetic and real datasets demonstrate that both methods significantly outperform the standard OBR-VAR algorithm in terms of computational complexity while preserving accuracy.},
  archive      = {J_NEUCOM},
  author       = {Samira Reihanian and Amin Zollanvari and Siamac Fazli},
  doi          = {10.1016/j.neucom.2025.131476},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131476},
  shortjournal = {Neurocomputing},
  title        = {Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors. <em>NEUCOM</em>, <em>656</em>, 131475. (<a href='https://doi.org/10.1016/j.neucom.2025.131475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex motion processes, different human skeleton descriptors can characterize skeletal features across various dimensions. The frequency of spatiotemporal changes in different joints is largely influenced by the type of action. This paper presents a dual-stream GCN-based action recognition framework, which involves Slow-stream and Fast-stream networks to process skeletal features of different spatiotemporal change characteristics. In the parallel processing architecture of graph convolutional layers, adaptive adjacency matrices that strengthen spatial and temporal feature extraction are proposed to learn the implicit relationships between skeletal joints. Furthermore, different skeletal features have significantly varying impacts on the accuracy of action recognition. The Dirichlet distribution and an optimized Dempster combination rule are introduced for trustworthy decision when fusing multi-branch opinions obtained from different skeleton descriptors. Extensive experiments on three authoritative datasets demonstrate that the proposed method achieves state-of-the-art performance while reducing uncertainty in action recognition.},
  archive      = {J_NEUCOM},
  author       = {Wenrui Zhu and Donghui Shi and Junqi Yu},
  doi          = {10.1016/j.neucom.2025.131475},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131475},
  shortjournal = {Neurocomputing},
  title        = {A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous federated semantic segmentation. <em>NEUCOM</em>, <em>656</em>, 131470. (<a href='https://doi.org/10.1016/j.neucom.2025.131470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) offers a promising solution for semantic segmentation in scenarios involving data distribution across isolated clients. Despite recent advances, federated semantic segmentation (FSS) continues to face key challenges. One major issue is the shift from centralized to decentralized training, where diverse and limited local data hinder consistent pixel-level representation learning. Another challenge is data heterogeneity from imbalanced class distributions across clients, which weakens feature consistency and degrades global performance. These limitations often lead to inconsistent feature learning and degraded global performance. To address the challenges of class heterogeneity and insufficient pixel-level representation learning in FSS, we propose a novel pixel-aware FSS framework that improves local adaptation and semantic consistency. Specifically, we design a fine-tuning strategy that initializes each client with a lightweight pre-trained model and performs local updates over multiple epochs. This improves model adaptability to local distributions while reducing communication overhead. To further enhance semantic consistency across heterogeneous clients, we introduce a client clustering strategy based on pixel-level semantic features. Clients with similar class distributions are grouped to encourage consistent feature learning within clusters. Cluster-level training and aggregation are then followed by a global aggregation step, promoting more robust and aligned semantic understanding. Empirical evaluation across multiple benchmark datasets confirms that our method achieves consistently high segmentation precision and enhanced model adaptability in highly heterogeneous federated scenarios.},
  archive      = {J_NEUCOM},
  author       = {Chen Zhang and Jiarui Wang and Yu Xie and Xinlei Wang and Bin Yu},
  doi          = {10.1016/j.neucom.2025.131470},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131470},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous federated semantic segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion. <em>NEUCOM</em>, <em>656</em>, 131467. (<a href='https://doi.org/10.1016/j.neucom.2025.131467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of surface defects in steel materials plays a pivotal role in ensuring industrial production quality and operational safety. However, existing deep learning-based detection methods face significant challenges in steel surface defect detection, including limited receptive field coverage, inadequate multi-scale feature integration, and insufficient feature discrimination under complex backgrounds. To address these limitations, this work introduces CBH-YOLO, a novel steel surface defect detection algorithm. The proposed framework incorporates three fundamental innovation modules: (1) Cross-stage Mamba-Enhanced Multi-scale Convolution (CMMC) module, which synergistically combines the advantages of state space models with large kernel convolutions alongside adaptive attention mechanisms, substantially expanding receptive field coverage while enhancing multi-scale feature extraction capabilities; (2) Binary Amplification Matrix (BAM) module, which innovatively integrates FlexWave (FXW) dynamic activation functions with OmniScale (OSC) multi-scale perception mechanisms to achieve adaptive nonlinear feature mapping and refined representation; (3) Hierarchical Semantic Graph Fusion Network (HSGFN), which models high-order correlations among features through hypergraph structures combined with adaptive feature fusion mechanisms, enabling more effective multi-scale feature integration. Comprehensive experimental validation on NEU-DET and GC10-DET benchmark datasets demonstrates that CBH-YOLO achieves improvements of 2.7 % and 3.2 % in mAP@50 metrics compared to the baseline YOLOv11 model, while maintaining exceptional computational efficiency. This research provides a high-precision, high-efficiency solution for steel surface defect detection, offering significant theoretical value and practical application prospects.},
  archive      = {J_NEUCOM},
  author       = {Bo Gao and Jingcheng Tong and RongRong Fu and ZhenZhen Zhang and YiLin Yuan},
  doi          = {10.1016/j.neucom.2025.131467},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131467},
  shortjournal = {Neurocomputing},
  title        = {CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network. <em>NEUCOM</em>, <em>656</em>, 131465. (<a href='https://doi.org/10.1016/j.neucom.2025.131465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the challenge of missing modality, existing multi-modal learning methods become impractical and missing modality is a serious impediment to a good multi-modal learning performance. Meanwhile, we note that the existing methods for addressing missing modality issue tend to explore complete information by using either cross-generative approaches via simply filling in missing modality data, and do not consider the specific information, resulting in a sub-optimal performance for Alzheimer’s Disease diagnosis with multi-modal data. To address this problem, we propose a novel Dual Memory Network (DMNet) that comprises the Tabular Alignment Memory bank (TAM) and Dynamic Re-optimizing Memory bank (DRM) to complement the missing modality information in multi-modal learning for Alzheimer’s disease diagnosis. More specifically, TAM stores the information aligned with clinical tabular data, and maintains the feature distribution alignment between clinical tabular data and imaging modalities. Besides, TAM is updated by a memory aligning strategy. Then, DRM stores modality specific information from complete modalities, and we design a memory optimizing strategy that incorporates Feature Consistency (FC) loss and Memory Correspondence (MC) loss to update the memory items in DRM to effectively represent specific information of modalities. This novel dual memory network enhances model performance and improves model usability in multi-modal learning with missing modality, providing a more informative feature distribution to complement the missing modality. Extensive experiments, including quantitative and qualitative analyses, as well as various ablation studies, demonstrate that our proposed method achieves state-of-the-art performance in the classification task on the ADNI dataset.},
  archive      = {J_NEUCOM},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neucom.2025.131465},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131465},
  shortjournal = {Neurocomputing},
  title        = {DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans. <em>NEUCOM</em>, <em>656</em>, 131464. (<a href='https://doi.org/10.1016/j.neucom.2025.131464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nerve net simulators of C. elegans heavily support research on its nerve net functionality by offering the possibility to conduct digital experiments instead of real ones. However, current software tools are complex and difficult to use for non-programmers. With WDWorm, we offer a user-friendly toolbox with graphical user interface for simulating and experimenting with C. elegans’ nerve net. It does not require an installation and allows for several modifications of the nerve net, including parameter changes for each neuron and connection or the deactivation of individual neurons. Furthermore, a comparison with other software tools highlights that WDWorm is currently the most runtime-efficient approach for simulating and digitally experimenting with C. elegans . To invite other developers and researchers, we provide the source code in an open-access format under a CC-BY 4.0 Creative Commons license. The code is publicly available at https://github.com/dsacri/WDWorm .},
  archive      = {J_NEUCOM},
  author       = {Sebastian Jenderny and Daniel Sacristán and Philipp Hövel and Christian Albers and Isabella Beyer and Karlheinz Ochs},
  doi          = {10.1016/j.neucom.2025.131464},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131464},
  shortjournal = {Neurocomputing},
  title        = {WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curriculum learning-based slimmable cross-component prediction for video coding. <em>NEUCOM</em>, <em>656</em>, 131463. (<a href='https://doi.org/10.1016/j.neucom.2025.131463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-component prediction plays an important role in video coding, which aims to eliminate redundancy between color components under the guidance of luma information. Recently, learning-based cross-component prediction has made significant strides in performance. However, current cross-component prediction methods typically train models directly on a dataset with different types of data, which generally results in overfitting for the flat textured data and underfitting for the complex textured data. To improve coding performance without excessively increasing the complexity, a cost-effective attention-based slimmable cross-component prediction network (SCCPN) is proposed. Although trained as a single model, SCCPN is capable of being executed at different levels of capacity, resulting in varying prediction results tailored to data with different characteristics. With the goal of further improving the generalization capability and prediction accuracy of the network, a curriculum learning strategy combined with slimmable convolutions is then designed, which employs the classification of prediction difficulty to represent whether the texture is flat or complex, and fits complex data with a small number of additional parameters. An adaptive search strategy is also introduced to speed up the selection of channels for slimmable convolutions. Experimental results demonstrate that when integrated into H.266/Versatile Video Coding (VVC), SCCPN achieves up to −0.62 %/−3.34 %/−2.68 % BD-rate reductions on Y/Cb/Cr components, respectively, over the H.266/VVC anchor. The performance gain outperforms the state-of-the-art learning-based cross-component prediction methods, while the increased complexity in both encoding and decoding is lower than the other compared cross-component prediction methods using neural networks. Moreover, performance gain can also be observed when SCCPN is integrated into the latest reference software of Beyond VVC, with BD-rate reductions of −0.17 %/−1.00 %/−1.02 % on Y/Cb/Cr components respectively.},
  archive      = {J_NEUCOM},
  author       = {Chengyi Zou and Shuai Wan and Marc Gorriz Blanch and Luka Murn and Juil Sock and Fei Yang and Luis Herranz},
  doi          = {10.1016/j.neucom.2025.131463},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131463},
  shortjournal = {Neurocomputing},
  title        = {Curriculum learning-based slimmable cross-component prediction for video coding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representative negative sampling for graph positive-unlabeled learning. <em>NEUCOM</em>, <em>656</em>, 131462. (<a href='https://doi.org/10.1016/j.neucom.2025.131462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph positive-unlabeled (GPU) learning is an important task that aims to develop binary classifiers using only positive and unlabeled nodes, which are commonly encountered in real-life applications. Although selecting reliable negative samples is a highly promising approach, it typically only selects high-confidence examples, which lack representativeness and fail to fully capture the diversity of the negative example space. To address this gap, our key insight, inspired by galactic dynamics, is to model the positive prototype center as a continuously evolving gravitational center maintained via a momentum moving average, just like the stars in the universe are always moving forward rather than remaining still. This dynamic anchor allows us to robustly define a reliable negative region—its “gravitational field”—for sampling representative “planets” (negative examples). We propose StarHunter-PU (SH-PU), a framework that operationalizes this insight by unifying graph representation learning with our dynamic, prototype-guided representative sampling algorithm. This ensures the sampled negatives are both diverse and informative, providing accurate information for training a robust binary classification model. Experimental results on real-world datasets show that our StarHunter-PU method significantly outperforms existing methods and even achieves competitive performance compared to fully labeled methods.},
  archive      = {J_NEUCOM},
  author       = {Luyue Wang and Xinyuan Feng and Rui Mao and Yin Li and Chunquan Liang},
  doi          = {10.1016/j.neucom.2025.131462},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131462},
  shortjournal = {Neurocomputing},
  title        = {Representative negative sampling for graph positive-unlabeled learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance and interpretability analysis of code generation large language models. <em>NEUCOM</em>, <em>656</em>, 131461. (<a href='https://doi.org/10.1016/j.neucom.2025.131461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Large Language Models (LLMs) are increasingly getting integrated into software development workflows, understanding their reliability, error patterns and interpretability in real-world development scenarios is crucial for establishing their practical utility. This study evaluates and interprets the performance of 15 open-source LLM models, including Code LLaMa, Granite Code, DeepSeek-Coder-V2, and Yi-Coder on code translation and generation from requirements using the Rosetta Code dataset across diverse programming languages and tasks. Syntactic correctness and code quality are quantified using metrics such as CodeBLEU, chrF, and METEOR. Interpretability is explored through Feature Ablation and Shapley Value Sampling to elucidate prompt processing mechanisms. Results indicate high syntactic correctness and quality scores for models such as DeepSeek-Coder-V2 and Yi-Coder, alongside observed sensitivities to specific prompt components. This research provides quantitative and qualitative insights into the capabilities and limitations of open-source code-generating LLMs, informing model selection and the understanding of LLM-generated code.},
  archive      = {J_NEUCOM},
  author       = {Vishnu S. Pendyala and Neha B. Thakur},
  doi          = {10.1016/j.neucom.2025.131461},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131461},
  shortjournal = {Neurocomputing},
  title        = {Performance and interpretability analysis of code generation large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing long-term memory in federated class continual learning with lightweight adapters. <em>NEUCOM</em>, <em>656</em>, 131459. (<a href='https://doi.org/10.1016/j.neucom.2025.131459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) collaboratively trains a global model by aggregating local model parameters rather than raw data. Traditional FL frameworks assume that data classes are predefined and static. However, clients often encounter continuous data streams with dynamically emerging classes in practical applications, leading to a phenomenon known as catastrophic forgetting. Federated Class-Continual Learning (FCCL) has been introduced to address this challenge but still suffers from significant performance deterioration in scenarios with expanding task scales, particularly for tasks learned in the distant past. We propose a novel FCCL framework leveraging lightweight adapters to mitigate catastrophic forgetting as the number of tasks scales. To tackle the challenge of long-term memory decline, we developed task-specific adapters for clients to enhance memory retention. Additionally, we developed an image generation method tailored for lightweight adapters and trained task discriminators using the generated images. This enables the automatic loading of lightweight modules during inference, reducing human intervention. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet achieve significant performance improvements ranging from 1.73 to 4.07 times compared to baseline methods, effectively mitigating catastrophic forgetting in class-scaling scenarios. The complete implementation is available at https://github.com/notaerfa/FCLORA .},
  archive      = {J_NEUCOM},
  author       = {Pan Wang and Ji Wang and Zhengyi Zhong and Weidong Bao and Yaohong Zhang and Jianguo Chen},
  doi          = {10.1016/j.neucom.2025.131459},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131459},
  shortjournal = {Neurocomputing},
  title        = {Enhancing long-term memory in federated class continual learning with lightweight adapters},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive granular-ball based density peak clustering. <em>NEUCOM</em>, <em>656</em>, 131458. (<a href='https://doi.org/10.1016/j.neucom.2025.131458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of data processing, the Granular-ball (GB) provides a coarse-grained data representation, offering a novel approach to improving clustering efficiency. The Fast Density Peak Clustering Algorithm based on Granular-balls (GB-DP) reduces computational granularity, which not only decreases operation time in large-scale data processing but also produces good clustering results. However, the GB-DP algorithm faces two main issues: sensitivity to the threshold parameter for generating GB and the requirement for manually selecting clustering centers, both of which affect the algorithm's efficiency and stability. To address these challenges, this paper proposes an Adaptive Granular-ball based Density Peak Clustering Algorithm (AGB-DP). First, a weighted Distribution Measure (DM) is used to dynamically generate GB. In contrast to the fixed threshold strategy used in GB-DP, this method effectively captures the data's distribution characteristics, mitigating the problem of parameter sensitivity. Second, by integrating two factors—data volume and geometric compactness—the density of GB is redefined, enhancing the accuracy of density calculations. Finally, an automatic screening strategy is employed to select GB as clustering centers, eliminating the instability introduced by manual intervention. Experimental results on both synthetic and real-world datasets demonstrate that AGB-DP, requiring only the number of clusters to be specified, achieves superior clustering results on most datasets compared to classical clustering algorithms and recent DP-based methods and shows greater robustness and stability.},
  archive      = {J_NEUCOM},
  author       = {Xingguo Zhang and Li Xu and Weikuan Jia},
  doi          = {10.1016/j.neucom.2025.131458},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131458},
  shortjournal = {Neurocomputing},
  title        = {Adaptive granular-ball based density peak clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting the connections between images and deep feature vectors in model inversion attacks. <em>NEUCOM</em>, <em>656</em>, 131457. (<a href='https://doi.org/10.1016/j.neucom.2025.131457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model inversion attack aims to reconstruct private samples from given deep neural networks. As the connections between the images and their corresponding deep feature vectors are unknown, it is difficult to utilize the information in the feature vectors during inversion. In this paper, connections between the images and their deep convolutional feature vectors are investigated. The directions of the vectors are used to represent the structures of both image vectors and feature vectors. Cosine similarity is further used to measure the structural similarity between different vectors. For a given target feature extractor, we find that the structures of the images and their feature vectors are highly correlated. Using this-property, Aug-MIA is proposed to perform model inversion with a few leaked feature vectors. In Aug-MIA, the feature vectors are first augmented by the proposed Structure Augmentation Algorithm. Then, a reconstruction model is trained using these augmented feature vectors to reconstruct images. Various experiments are performed on different datasets to validate our ideas. The results show that Aug-MIA performs better when fewer feature vectors are available. Specifically, when only 1 feature vector per class is leaked, it can improve the reconstruction rate by about 10.7 % on FaceScrub and about 4.2 % on MNIST, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zeping Zhang and Jie Huang},
  doi          = {10.1016/j.neucom.2025.131457},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131457},
  shortjournal = {Neurocomputing},
  title        = {Exploiting the connections between images and deep feature vectors in model inversion attacks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection. <em>NEUCOM</em>, <em>656</em>, 131456. (<a href='https://doi.org/10.1016/j.neucom.2025.131456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tons of prior works have leveraged Generative Adversarial Networks (GANs) to synthesize adversarial examples that exhibit visual fidelity. Nonetheless, the intricacy of GANs’ latent space complicates the generation of imperceptible adversarial noises, rendering the process difficult to control. The emergence of diffusion models, which iteratively refine images through a progressive denoising mechanism, offers a more tractable and interpretable solution for a controllable generation. Inspired by this, we propose a latent-space-based covert adversarial attack framework (LSDM) grounded in diffusion models to craft adversarial examples that are both visually natural and highly effective against object detection models. Central to our approach is the Latent Space Perceptual Consistency Constraint, which ensures visual-consistency by embedding perturbations into the latent space for each denoising step, while utilizing the original image as a condition guider during the de-noising pass. Moreover, to balance attack performance and the risk of overfitting, we also propose a Stepwise Prediction and Adaptive Optimization strategy, which dynamically modulates the perturbations at the current time step and determines optimal number of diffusion time steps based on the transferability of the attack against diverse black-box models. To further enhance the framework’s attacking transferability, we introduce a novel Multi-box Translation Attack strategy, which augments the spatial location diversities for each bounding box. Extensive experiments demonstrate that, compared with state-of-the-art methods, LSDM further reduces the average black-box detection mAP by 1.52 %, while improving image quality scores by 1.71 % on object detection datasets such as COCO and VOC, showcasing superior attack effectiveness and visual fidelity. The source code is publicly available at https://github.com/LSDM .},
  archive      = {J_NEUCOM},
  author       = {Wenxuan Wang and Huihui Qi and Zhixiang Huang and Bangjie Yin and Peng Wang},
  doi          = {10.1016/j.neucom.2025.131456},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131456},
  shortjournal = {Neurocomputing},
  title        = {Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User intent disentanglement for multi-behavior recommendation via information bottleneck principle. <em>NEUCOM</em>, <em>656</em>, 131454. (<a href='https://doi.org/10.1016/j.neucom.2025.131454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-behavior recommendation systems have advanced rapidly by leveraging users’ diverse auxiliary behavior interactions to improve recommendations for the target behavior (a.k.a. purchase). While existing methods have made strides by integrating auxiliary behaviors with purchase histories to deliver high-quality recommendations, they often fail to identify spurious correlation intents within auxiliary behaviors that conflict with users’ target intents. Indiscriminately incorporating such correlations into the prediction of target intents may lead to performance degradation. To address this issue, we propose a Multi-Behavior Intent Disentanglement framework (MBID) for multi-behavior recommendation, which focuses on disentangling spurious correlation intents via the Information Bottleneck (IB) principle. In particular, we first design a time-sensitive spurious correlation coefficient to quantify spurious correlation intents and guide the subsequent multi-intent learning. Then, to disentangle spurious correlation intents, we propose a projection-based intent extraction method to decompose the genuine and spurious correlation intents within auxiliary behaviors. Based on this, we conceive an IB-based multi-intent learning task to disentangle the spurious correlation intents and transfer the genuine correlation intents from auxiliary behaviors into the target behavior, thereby obtaining high-quality representations of the target intent. Extensive experiments on three real-world datasets demonstrate that MBID significantly outperforms the state-of-the-art baselines by effectively disentangling the spurious correlation intents. We release our model implementation at: https://github.com/LokHsu/MBID .},
  archive      = {J_NEUCOM},
  author       = {Chenzhong Bin and Tongxin Xu and Feng Zhang},
  doi          = {10.1016/j.neucom.2025.131454},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131454},
  shortjournal = {Neurocomputing},
  title        = {User intent disentanglement for multi-behavior recommendation via information bottleneck principle},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding. <em>NEUCOM</em>, <em>656</em>, 131450. (<a href='https://doi.org/10.1016/j.neucom.2025.131450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Understanding (NLU) plays a crucial role in Natural Language Processing (NLP), enabling machines to interpret and process human language across various applications. Despite advancements, challenges remain, including variations in data types, inconsistencies in labeling, computational demands, and biases in training datasets. These challenges emphasize the need for ethical and effective NLU solutions. To address these issues, the proposed PolyModNet combines techniques from NLP and computer vision to improve both text and image understanding. The model enhances data representation and compensates for limited training data using advanced augmentation methods such as mixup, gridmask, and positional encoding, optimized for Vision Transformer. By integrating RoBERTa-BERT and Vision Transformer, PolyModNet ensures accurate alignment of text and image features through Transformer-based encoding, specialized transformations, and structured positional encodings. Additionally, it employs a universal multilingual framework that enables language-independent retrieval and flexible task adaptation. Ethical concerns are addressed through bias detection and adversarial training, ensuring fairness in multimodal analysis. Extensive evaluations demonstrate the model’s effectiveness across multiple NLP tasks, achieving 85.71 % accuracy in sentiment analysis, strong text classification performance (CoLA: 64.1 %, SST2: 96.4 %), and high accuracy in text-image retrieval (R@1: 72.00, R@5: 89.25, R@10: 92.10). The model also delivers competitive results in multimodal translation (BLEU: 45.36, METEOR: 55.62) and cross-modal retrieval (text-to-image: R@1: 67.4, image-to-text: R@1: 82.3).},
  archive      = {J_NEUCOM},
  author       = {Shaharyar Alam Ansari and Mohd Anas Wajid and Mohd Arif and Mohammad Saif Wajid},
  doi          = {10.1016/j.neucom.2025.131450},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131450},
  shortjournal = {Neurocomputing},
  title        = {PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet attention is all you need in multimodal medical image fusion. <em>NEUCOM</em>, <em>656</em>, 131448. (<a href='https://doi.org/10.1016/j.neucom.2025.131448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multimodal medical image fusion, the fusion method based on frequency domain features is a research hotspot. However, “how to effectively enhance the high frequency and low frequency information in frequency domain?”, “how to fully interact the cross-modal spatial features in feature fusion?” are the keys to improve the fusion performance. To solve this problem, this paper proposes a multimodal medical image fusion network (WTA-Net) based on Wavelet Attention. The main innovations are as follows: Firstly, the Encoder-Decoder fusion network WTA-Net with dual-encoder and single-decoder is proposed. The network effectively capture the frequency domain features in different modal images and enhance the ability of information flow between modalities. Secondly, a Wavelet Attention(WA) is designed in the encoder, which effectively enhance the high frequency and low frequency information of the lesion. Thirdly, the Cross Modal Information Fusion Module(CMIFM) is designed in the fusion stage, which fully interactive cross-modal spatial features. Finally, experiments are performed on the Whole Brain Atlas dataset and the PET-CT lung dataset. In brain MRI images and PET images comparison experiment, IE, AG and EN evaluation indexes are improved by 18.92 %, 14 % and 18.25 %, respectively. In CT mediastinal window images and PET images comparison experiment, IE and SF evaluation indexes are improved by 12.08 % and 49.4 %, respectively, WTA-Net highlight the lession information, which has positive significance for computer-aided diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhou and Mingzhe Zhang and Zhe Zhang and Jiaqi Wang and Yang Liu and Huiling Lu},
  doi          = {10.1016/j.neucom.2025.131448},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131448},
  shortjournal = {Neurocomputing},
  title        = {Wavelet attention is all you need in multimodal medical image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-domain mutual compensation network for multi-modality image fusion. <em>NEUCOM</em>, <em>656</em>, 131443. (<a href='https://doi.org/10.1016/j.neucom.2025.131443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research has demonstrated that fusing both spatial and frequency domain information from images can enhance fusion model performance, particularly in terms of saliency preservation and texture enhancement. However, designing effective fusion strategies to coordinate complementary information from both domains, while maximizing the unique characteristics and advantages of each and avoiding information conflict or redundancy, remains a challenge that requires further exploration and optimization. To address this issue, we propose a spatial–frequency Dual-Domain Mutual Compensation Network, termed D2Fusion. In our approach, the Mamba module serves as the core component of the spatial branch, capturing long-range dependencies to enhance the focus on the global spatial structure of input features. Simultaneously, the frequency branch utilizes fast Fourier Transform and convolutional neural networks to extract local texture details from the phase and magnitude components of the input features. Unlike traditional dual-branch networks, we introduce a novel phase fusion operation within the frequency branch, which combines phase information from different modalities to generate salient target features that complement and enhance the spatial features. Furthermore, to maximize the exchange of complementary characteristics between spatial, frequency, and salient target features, we design a Mutual Compensation Block (MCB) that accounts for feature differences and a decomposition loss function based on discrete cosine distance. The MCB facilitates compensatory fusion, while the decomposition loss function reduces feature similarity prior to compensation, maximizing the complementary information between domain features. Extensive experiments validate the superiority of our method, demonstrating that D2Fusion outperforms existing state-of-the-art approaches in both multi-modal image fusion and downstream task performance. The code for this framework is available at https://github.com/hz777xx/D2Fusion .},
  archive      = {J_NEUCOM},
  author       = {Jiwei Hu and Zhen Hu and Ping Lou and Kin-Man Lam and Qiwen Jin},
  doi          = {10.1016/j.neucom.2025.131443},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131443},
  shortjournal = {Neurocomputing},
  title        = {A dual-domain mutual compensation network for multi-modality image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-aware representation learning for multi-view clustering. <em>NEUCOM</em>, <em>656</em>, 131441. (<a href='https://doi.org/10.1016/j.neucom.2025.131441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based multi-view clustering has garnered considerable attention in recent years owing to its ability to reduce computational overhead and enable efficient processing of large-scale datasets. However, existing anchor-based multi-view clustering models still present limitation: while orthogonality constraints are imposed on anchors to enhance their discriminative properties, the inherent relationships among anchors are neglected. To address this limitation, a novel Anchor-Aware Representation Learning for Multi-view Clustering (AARLMC) model is proposed. Specifically, anchor-wise self-representation learning is implemented, with orthogonality constraints applied to the anchor self-representation matrices to uncover intrinsic relationships among anchors. Furthermore, enhanced anchor representations are generated through this process. The anchor graphs are stacked into a third-order tensor with tensor nuclear norm constraint to explore the high-order correlations among multi-view data. Anchor-wise self-representation learning, enhanced anchor representations, and tensor representation are integrated into a unified framework. An optimization algorithm is developed to solve the proposed model. Comparative experiments on twelve benchmark datasets against thirteen state-of-the-art multi-view clustering methods demonstrate that the proposed model achieves superior performance. The source code is available on https://github.com/guowei1314/AARLMC .},
  archive      = {J_NEUCOM},
  author       = {Haotian Zhang and Wei Guo and Ruiyin Liu and Qiang Yang and Xuefei Xiao and Jilin Li and Gang Lei and Gang Chen},
  doi          = {10.1016/j.neucom.2025.131441},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131441},
  shortjournal = {Neurocomputing},
  title        = {Anchor-aware representation learning for multi-view clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft-label generator based on classifier weights. <em>NEUCOM</em>, <em>656</em>, 131436. (<a href='https://doi.org/10.1016/j.neucom.2025.131436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft labels provide rich information between classes. Classification models obtain better generalization ability when soft labels are used as training targets in addition to hard ground-truth labels. In this paper, we propose a new approach named TarSamp to derive effective soft-targets only with the model’s classifier layer. This approach offers a simple, generic, and low-cost solution for soft label generation by fully leveraging the class-level semantics captured by the classifier layer and uncertainty injection with random sampling. We apply TarSamp to both teacher-free and teacher-available scenarios by using the classifier layer from the online model and a pre-trained teacher model, respectively. Extensive experiments on five standard image datasets are provided to evaluate the proposed approach for classifier training. TarSamp achieves more than 8 % accuracy on average for the teacher-free setting with ResNet-18, and gives on par performance by getting rid of querying to the teacher model in each forward pass during distillation for the teacher-available situation. Our results demonstrate that the proposed approach makes as a fundamental yet competitive baseline for a wide range of soft label based supervised learning.},
  archive      = {J_NEUCOM},
  author       = {Xinkai Chu and Jian-Ping Mei and Hang Zhou and Jie Chen and Rui Yan and Jing Fan},
  doi          = {10.1016/j.neucom.2025.131436},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131436},
  shortjournal = {Neurocomputing},
  title        = {Soft-label generator based on classifier weights},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body. <em>NEUCOM</em>, <em>656</em>, 131429. (<a href='https://doi.org/10.1016/j.neucom.2025.131429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional deep learning pedestrian detection methods usually only use the information of the current image itself. Incorrect results that go against common sense are prone to occur when dealing with hard objects with small size, unusual pose, or occlusions. Recent approaches try to enhance the hard objects by constructing and utilizing empirical information. However, due to an insufficient understanding of human body structure, the constructed experience exhibits poor generalization ability to diverse poses. Furthermore, when leveraging experiential features to enhance the features of hard objects, the process is susceptible to interference from occlusions and background. Inspired by human vision, we propose CESDet, a novel pedestrian detection network that constructs and utilizes Cognition Experience of Structure of human body in an unsupervised manner. The key technical innovations are three folds: (1) an unsupervised Cognition Experience of Structure construction module that addresses pose generalization by automatically forming decoupled body parts and pose semantics, (2) a part-level fine-grained verification and feature enhancement module that addresses the interference of occlusions and background with the guidance of Cognition Experience of Structure, and (3) an end-to-end pedestrian detection network for hard objects based on the two proposed modules. Experiments comparing with seven methods on three datasets demonstrate that CESDet achieves state-of-the-art performance, with highest AP on the training dataset, and lowest degradation of AP on a novel unseen dataset. The proposed framework advances the detection of hard objects by exploiting the automatically constructed Cognition Experience of Structure with decoupled part-level appearance and pose.},
  archive      = {J_NEUCOM},
  author       = {Yanglin Pu and Xiaohui Hao and Shan Yang and Hangyuan Yang and Shengxin Dai},
  doi          = {10.1016/j.neucom.2025.131429},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131429},
  shortjournal = {Neurocomputing},
  title        = {CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-related potential extraction workflow based on kernel density estimation. <em>NEUCOM</em>, <em>656</em>, 131425. (<a href='https://doi.org/10.1016/j.neucom.2025.131425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-related potentials (ERPs) are a critical neuroscientific tool for investigating brain responses to external stimuli and serve as a key linking mechanism in brain–computer interface systems. Traditional ERP extraction methods rely on threshold-based trial rejection and time-locked averaging techniques, which often have limited ability to handle outlier data and are susceptible to random artifacts. To address this, we propose a novel ERP extraction workflow based on kernel density estimation. We construct trial-wise datasets at the sampling-point granularity and model the probability distribution of each trial using Gaussian kernel density estimation, effectively reducing outlier influence while preserving all trial data. The fitted probability density function serves as the objective function for ERP extraction, enabling active reconstruction of optimal ERP waveforms by incorporating inherent EEG temporal dependencies. Specifically targeting uneven noise distribution across multiple channels, we introduce an adaptively steering kernel dynamically generated from electrode covariance matrices, which optimizes the adaptive matching of inter-channel noise structures to ensure more precise density function fitting. Using two real datasets and simulated datasets, our comparative analyses of baseline root mean square error, component-level statistical metrics, and residual correlations demonstrate that, compared with the traditional trial rejection and time-locked averaging methods, our approach exhibits outstanding effectiveness in isolating ERP components from raw signals and significantly reduces the impact of outlier contamination.},
  archive      = {J_NEUCOM},
  author       = {Weizhuang Kong and Zihao Zhang and Jing Zhu and Yizhou Li and Xiaowei Li and Bin Hu},
  doi          = {10.1016/j.neucom.2025.131425},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131425},
  shortjournal = {Neurocomputing},
  title        = {Event-related potential extraction workflow based on kernel density estimation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view optimization and refinement for high-fidelity 4D gaussian splatting. <em>NEUCOM</em>, <em>656</em>, 131424. (<a href='https://doi.org/10.1016/j.neucom.2025.131424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing dynamic 3D scenes from 2D images and synthesizing temporally diverse views is challenging due to the interplay between scene complexity and temporal dynamics. While 3D Gaussian Splatting offers an efficient solution for static scene modeling, extending it to dynamic scenes faces significant challenges in motion representation and texture fidelity. We propose a novel framework based on multi-view interpolation and joint optimization to address these challenges in sparse-view dynamic scenes. This framework combines linear and spherical interpolation strategies to generate novel views, producing high-quality interpolated images from multiple fitted viewpoints. Additionally, it incorporates consistency constraints to optimize texture representation, enhancing the reconstruction performance for dynamic scenes. Experimental results demonstrate that the proposed framework significantly improves detail fidelity and motion representation in dynamic scene reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Jinhui Lin and Zhenyang Wei and Silei Shen and Fang Zhou and Xiaobin Zhu and Xu-Cheng Yin},
  doi          = {10.1016/j.neucom.2025.131424},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131424},
  shortjournal = {Neurocomputing},
  title        = {Multi-view optimization and refinement for high-fidelity 4D gaussian splatting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization. <em>NEUCOM</em>, <em>656</em>, 131423. (<a href='https://doi.org/10.1016/j.neucom.2025.131423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection and localization are crucial for improving product reliability in industrial quality inspection. Existing knowledge distillation methods often cause student networks to merely mimic features of teacher networks, which makes it difficult to achieve stable and generalized detection performance. This paper introduces the KD-KI framework, which uses a knowledge infusion mechanism to transfer structured hierarchical knowledge from the teacher network to the student network. This guides the student to learn more robust representations of normal samples. Additionally, a feature bias loss is used to optimize the similarity of shallow-layer features, improving detection accuracy and localization precision. KD-KI can be deployed with standard convolutional networks and is suitable for real-time industrial inspection systems. Experimental results demonstrate that the proposed KD-KI model can yield improved performance in anomaly detection and localization compared to other competing models.},
  archive      = {J_NEUCOM},
  author       = {Wei Huang and Zhaonan Xu and Rongchun Wan and Xuhua Yang and Bingyang Zhang},
  doi          = {10.1016/j.neucom.2025.131423},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131423},
  shortjournal = {Neurocomputing},
  title        = {KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting. <em>NEUCOM</em>, <em>656</em>, 131418. (<a href='https://doi.org/10.1016/j.neucom.2025.131418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-long time series forecasting (ULTSF) is crucial for fields like energy management, traffic planning, and climate prediction. However, as the forecast horizon increases, concept drift becomes a major challenge, as a fixed-length historical window struggles to generalize ultra-long temporal patterns. Extending the input series length increases computational costs and demands a higher model capacity for capturing longer temporal dependencies. To address these issues, we propose DFCon, a dominant frequency enhanced contrastive learning framework for ULTSF. DFCon combines dilated convolutions for feature extraction and multi-layer perceptrons for forecasting, with a dual contrastive loss based on dominant frequency enhancement. We introduce Temporal DFCon, which enhances the model’s sensitivity to these frequency-domain features during training, thereby improving its ability to model global temporal dependencies in the input series. Furthermore, cross-window Autocorrelated DFCon is proposed, which mitigates concept drift by constructing autocorrelated relative positive and negative samples without introducing noisy data. Experiments on five benchmark datasets show that DFCon outperforms existing methods, demonstrating its effectiveness in ULTSF. The code for this work is publicly available at: https://github.com/coding4qq/DFCon .},
  archive      = {J_NEUCOM},
  author       = {Qiaoqiao Liu and Hui Liu and MingJie Yang and Yuheng Wei and Junzhao Du},
  doi          = {10.1016/j.neucom.2025.131418},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131418},
  shortjournal = {Neurocomputing},
  title        = {DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach. <em>NEUCOM</em>, <em>656</em>, 131382. (<a href='https://doi.org/10.1016/j.neucom.2025.131382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal (RGBT) tracking leverages complementary information from visible and infrared modalities to improve tracking robustness in complex environments. However, its practical deployment remains constrained by the stringent requirement for precise spatiotemporal alignment between heterogeneous modalities—a condition rarely satisfied in real-world applications. To overcome this limitation, we present SAFNet, a novel Spatiotemporal Alignment-Free Network that eliminates the need for precise cross-modal alignment through innovative architectural designs. Our framework develops a spatiotemporal interaction query module incorporating cross-modal temporal attention, which re-establishes inter-modal temporal correlations for unregistered inputs by leveraging similarity learning across asynchronous data streams. For spatial discrepancy mitigation, we propose a dual-branch pre-tracking network employing deep cross-correlation analysis, combined with an adaptive feature fusion strategy under the guidance of joint response distribution. Furthermore, we devise an innovative dynamic template update mechanism that adaptively adjusts modal update rates to maintain temporal consistency across heterogeneous data streams. Comprehensive evaluations validate SAFNet’s state-of-the-art performance across four benchmark datasets (GTOT, RGBT210, RGBT234, LasHeR), demonstrating significant improvements in tracking accuracy. The proposed architecture represents a significant advancement toward practical deployment of robust RGBT tracking systems in real-world environments with asynchronous multimodal inputs.},
  archive      = {J_NEUCOM},
  author       = {Xiaodong Liu and Meibo Lv and Daming Zhou and Lingyu Si and Ruiheng Zhang and Hui Xu},
  doi          = {10.1016/j.neucom.2025.131382},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131382},
  shortjournal = {Neurocomputing},
  title        = {Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cycle cover variants: A dataless neural networks approach. <em>NEUCOM</em>, <em>656</em>, 131361. (<a href='https://doi.org/10.1016/j.neucom.2025.131361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cycle Cover, a fundamental concept in graph theory, plays a critical role in various applications, including network design, transportation optimization, and bioinformatics. A Cycle Cover is a collection of cycles covering all the vertices of a given graph, ensuring that each vertex belongs to exactly one cycle. In this paper, we explore various aspects of Cycle Cover variants. We employ the dataless neural networks framework to establish single differentiable functions for each of these variants. Recent research has demonstrated the capability of the dataless neural networks framework in representing a host of combinatorial optimization problems. Motivated by these findings, we propose dataless neural networks tailored for the Cycle Cover variants. Additionally, we present a rigorous proof of the correctness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Sangram K. Jena and K. Subramani and Alvaro Velasquez},
  doi          = {10.1016/j.neucom.2025.131361},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131361},
  shortjournal = {Neurocomputing},
  title        = {Exploring cycle cover variants: A dataless neural networks approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges. <em>NEUCOM</em>, <em>656</em>, 131357. (<a href='https://doi.org/10.1016/j.neucom.2025.131357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for the deployment of deep neural networks (DNNs) in edge devices has led to the development of lightweight deep learning (LDL) models designed to operate efficiently under resource constraints. Although DNNs have achieved remarkable success in various applications, their high computational requirements often limit their deployment on devices with restricted memory and processing power. This challenge has motivated researchers to develop optimized LDL models that balance accuracy, speed, and efficiency while maintaining competitive performance. Despite existing surveys covering specific aspects of LDL models, a comprehensive review encompassing image classification, object detection, and segmentation remains limited. This proposed survey systematically explores recent advancements in LDL models, highlighting their architectures, optimization techniques, and real-world applications. This survey conducts an empirical evaluation by testing latest state-of-the-art LDL models on the Jetson Orin edge device using benchmark datasets: ImageNet for classification, VisDrone for object detection, and COCO for segmentation. The experimental analysis focuses on key performance metrics, including inference speed, model accuracy, and computational efficiency, while comparing LDL models with their conventional counterparts. This study provides a holistic understanding of the role of LDL models in edge computing, providing insight into emerging trends, challenges, and future research directions in the field.},
  archive      = {J_NEUCOM},
  author       = {Syed Muhammad Raza and Syed Murtaza Hussain Abidi and Md Masuduzzaman and Soo Young Shin},
  doi          = {10.1016/j.neucom.2025.131357},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131357},
  shortjournal = {Neurocomputing},
  title        = {Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks. <em>NEUCOM</em>, <em>656</em>, 131351. (<a href='https://doi.org/10.1016/j.neucom.2025.131351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are biologically realistic and practically promising in low-power computation because of their event-driven mechanism. Usually, the training of SNNs suffers from accuracy loss on various tasks, yielding an inferior performance compared with ANNs. A conversion scheme is proposed to obtain competitive accuracy by mapping trained ANNs’ parameters to SNNs with the same structures. However, an enormous number of time steps are required for these converted SNNs, thus losing the energy-efficient benefit. Utilizing both the accuracy advantages of ANNs and the computing efficiency of SNNs, a novel SNN training framework is proposed, namely layer-wise ANN-to-SNN knowledge distillation (LaSNN). In order to achieve competitive accuracy and reduced inference latency, LaSNN transfers the learning from a well-trained ANN to a small SNN by distilling the knowledge rather than converting the parameters of ANN. The information gap between heterogeneous ANN and SNN is bridged by introducing the attention scheme. The knowledge in an ANN is effectively compressed and then efficiently transferred by utilizing our layer-wise distillation paradigm. We conduct detailed experiments to demonstrate the effectiveness, efficacy, and scalability of LaSNN on three benchmark data sets (CIFAR-10, CIFAR-100, and Tiny ImageNet). We achieve competitive top-1 accuracy compared to ANNs and faster inference than converted SNNs with similar performance. More importantly, LaSNN is dexterous and extensible that can be effortlessly developed for SNNs with different architectures/depths and input encoding methods, contributing to their potential development.},
  archive      = {J_NEUCOM},
  author       = {Di Hong and Yu Qi and Yueming Wang},
  doi          = {10.1016/j.neucom.2025.131351},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131351},
  shortjournal = {Neurocomputing},
  title        = {LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition. <em>NEUCOM</em>, <em>656</em>, 131350. (<a href='https://doi.org/10.1016/j.neucom.2025.131350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) signals contain rich spatio-temporal information that reflects the brain’s dynamic activity, making it widely used in depression recognition. However, effectively integrating this information to capture discriminative and complementary features remains a key challenge. To address this issue, we propose a novel Discriminative Local Low-Rank Correlation Embedding (DLLCE) to fuse spatio-temporal information of EEG. DLLCE integrates shared low-rank representation, local invariance, discriminative constraints, and enhanced correlation analysis into a unified framework. Specifically, the shared low-rank representation is used to capture the common structural patterns, while the correlation analysis aims to reduce redundancy among feature sets. In addition, the Laplacian regularization is applied to the shared representation to preserve the local geometric structure of the original data. To further enhance discriminative capability, a discriminant graph embedding term is incorporated to exploit label information. Experimental results on EEG datasets demonstrate that DLLCE achieves superior performance compared to existing methods. This work provides new insights into EEG-based mental health assessment and holds promise for early depression diagnosis and clinical decision support.},
  archive      = {J_NEUCOM},
  author       = {Lu Zhang and Peng Xu and Zhijun Yao and Xinyan Zhang and Juan Wang and Bin Hu and Gang Feng and Hong Peng},
  doi          = {10.1016/j.neucom.2025.131350},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131350},
  shortjournal = {Neurocomputing},
  title        = {Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-driven baseline for few-shot fine-grained visual recognition. <em>NEUCOM</em>, <em>656</em>, 131302. (<a href='https://doi.org/10.1016/j.neucom.2025.131302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot fine-grained visual recognition (FS-FGVR), a practical yet challenging task, aims to break the dilemma of having scarce training examples for new fine-grained tasks. Meta-learning-based methods target this issue by employing the learning-to-learn strategy to train a well-generalized meta-learner from seen fine-grained tasks for unseen fine-grained tasks. However, most existing works rely too much on small-scale fine-grained training tasks. Specifically, these works demand large amounts of fine-grained data to sample these training tasks, and they are unable to generalize well to new tasks. Consequently, model capacity can be highly restricted when limited training references are available. This paper presents a novel coarse-to-fine framework named Knowledge-Driven baseline for FS-FGVR by transferring knowledge from large-scale and coarse-grained datasets. This framework departs the meta-training phase into the coarse-grained meta-pretraining and fine-grained meta-finetuning phases. First, off-the-shelf coarse-grained data is introduced to build the initialization correlations as prior knowledge. Then, we use prior knowledge to infer the representational interactions and correlations of the fine-grained representations. Extensive experiments show that our method outperforms the current methods on the public few-shot fine-grained benchmarks. We also develop extensive studies to extend our method to few-shot texture visual recognition scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jieqi Sun and Jian Li and Yafeng Li},
  doi          = {10.1016/j.neucom.2025.131302},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131302},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-driven baseline for few-shot fine-grained visual recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba. <em>NEUCOM</em>, <em>656</em>, 131293. (<a href='https://doi.org/10.1016/j.neucom.2025.131293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machinery plays a critical role in industrial operations, yet existing diagnostic methods often struggle with missing correlations between sensor data, weak noise immunity, and insufficient long-range feature extraction. To address these challenges, this paper proposes BMTM-Net, a fault diagnosis network based on 2D-1D fusion with Bidirectional Multi-granularity Transformer-Mamba (BMTM). The network consists of two main components: a 2D sequential information interaction network and a 1D temporal information extraction network. The 2D network captures inter-sensor sequence relationships and temporal dependencies using a Bidirectional Multi-granularity Transformer (BM-Transformer) and an embedded Sequential-Temporal Attention Module (ST-Attention), while the 1D network enhances feature completeness and extracts temporal information through a Bidirectional Multi-granularity Mamba (BM-Mamba) network, integrated with a Channel Attention-based Fusion Module (CAFM) for adaptive feature fusion. To evaluate BMTM-Net’s effectiveness and stability, experiments were conducted on datasets from Southeast University and a Self-Built bogie integrated test stand, with various levels of noise introduced to assess noise immunity. The results demonstrate that BMTM-Net achieves over 99 % accuracy across all four datasets and maintains high accuracy even under severe noise interference (SNR = −10 dB), outperforming other state-of-the-art methods with accuracy rates of 99.60 %, 99.40 %, 98.54 %, and 94.38 %, respectively. Additionally, the model exhibits low complexity, further confirming its robustness and effectiveness in noisy environments.},
  archive      = {J_NEUCOM},
  author       = {E. Xia and Yirong Liu and Jinyang Gong and Xunhua Dai and Tongyang Pan and Shiyi Wang},
  doi          = {10.1016/j.neucom.2025.131293},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131293},
  shortjournal = {Neurocomputing},
  title        = {BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions. <em>NEUCOM</em>, <em>656</em>, 131192. (<a href='https://doi.org/10.1016/j.neucom.2025.131192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey paper provides an overview of different feature types used in radiomics research and their applications across various medical imaging modalities and disease domains. The paper delves into the key aspects of the radiomics workflow, including data engineering techniques for image acquisition, preprocessing, fusion, and segmentation. It then presents a comprehensive review of the most commonly employed feature categories in radiomics, such as shape-based, first-order statistical, second-order texture, and transform-based features. The paper also discusses the emerging role of deep learning features extracted using convolutional neural networks, recurrent neural networks, and transformers. The analysis of feature usage trends across different anatomical regions and imaging modalities offers valuable insights that can guide the optimization of feature engineering strategies in future radiomics research. The survey concludes by highlighting several opportunities for further advancement in the field, including the need for larger multi-center datasets, multi-modal data fusion, self-supervised learning, and the development of efficient embedded models for on-device deployment.},
  archive      = {J_NEUCOM},
  author       = {Luca Zedda and Andrea Loddo and Cecilia Di Ruberto},
  doi          = {10.1016/j.neucom.2025.131192},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131192},
  shortjournal = {Neurocomputing},
  title        = {Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive low-confidence pseudolabeling for semisupervised node classification. <em>NEUCOM</em>, <em>656</em>, 131166. (<a href='https://doi.org/10.1016/j.neucom.2025.131166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have demonstrated remarkable achievements in handling graph-structured data. However, the performance of GNNs is typically limited by the lack of sufficient labeled data, which are time-consuming to obtain in real-world scenarios. Pseudolabeling has been applied to GNNs by augmenting the training set data with unlabeled data. Most pseudolabeling methods on graphs assign pseudolabels to nodes based on high-confidence thresholds. However, nodes near labeled ones generally obtain high confidence scores during training. This results in an increasing number of similar nodes being assigned pseudolabels during training, which potentially leads to a distribution shift between the labeled dataset and the augmented dataset. The distribution of the augmented dataset diverges significantly from that of the entire graph data, causing the GNNs to perform poorly on test data. In this paper, we propose a progressive low-confidence pseudolabeling (PLCP) method to progressively leverage the low-confidence data. Specifically, pseudolabels are assigned to nodes within a predefined confidence-based ranking range. To alleviate distribution shift, we keep this range constant throughout the training process to prevent excessive nodes from being assigned pseudolabels. The range is designed to be sufficiently wide to leverage low-confidence nodes. Low-confidence nodes from the range propagate information to their neighbors, which helps the model capture patterns in uncertain regions. To alleviate the impact of noisy pseudolabels, a validation-based reassignment scheme is proposed to utilize validation metrics to assign more reliable pseudolabels. Numerous experiments are conducted to demonstrate that our proposed PLCP improves the performance of state-of-the-art GNNs on graph datasets in comparison with several established methods.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhu and Hua Mao and Hui Liu and Jie Chen},
  doi          = {10.1016/j.neucom.2025.131166},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131166},
  shortjournal = {Neurocomputing},
  title        = {Progressive low-confidence pseudolabeling for semisupervised node classification},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting. <em>NEUCOM</em>, <em>656</em>, 131103. (<a href='https://doi.org/10.1016/j.neucom.2025.131103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {House Price Index (HPI) is an indicator that reflects changes in residential house prices over time. Predicting HPI is crucial for homebuyers to determine the right time to purchase and for policymakers to formulate housing policies. Recent studies have reported that neural network approaches outperform classical methods in HPI forecasting. However, challenges remain due to limited monthly HPI data and its time-varying statistical properties. As a result, state-of-the-art time series forecasting models often respond slowly to abrupt changes and lack economic interpretability. To address these issues, we propose Deep-DFVAR, a hybrid framework that decomposes regional HPI into shared (common trends) and idiosyncratic (regional variations) components. The shared component is predicted with Vector Autoregression (VAR) based on Granger causality, which improves interpretability and responds faster to changes. The idiosyncratic component is modeled with our deep learning model, which benefits from reduced distribution shift (train–test gap). We evaluate Deep-DFVAR on South Korean and United States datasets, empirically demonstrating that our framework outperforms traditional and recent time series forecasting models. All data and code are publicly available at: https://github.com/YeoJiSu/House-Price-Index-Prediction .},
  archive      = {J_NEUCOM},
  author       = {Jisu Yeo and Artyom Stitsyuk and Jaesik Choi},
  doi          = {10.1016/j.neucom.2025.131103},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131103},
  shortjournal = {Neurocomputing},
  title        = {Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach. <em>NEUCOM</em>, <em>656</em>, 131097. (<a href='https://doi.org/10.1016/j.neucom.2025.131097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper employs the full-information dependent Lyapunov-Krasovskii functional (LKF) analysis approach to investigate the multiple weighting adaptive event-triggered triple asynchronous switching control problem for Takagi-Sugeno fuzzy neural networks with semi-Markov jump parameters. Considering the influence of factors such as network delays and disturbances, there may be asynchronous premise variables and modes among the system, event generator and controller. Therefore, a triple asynchronous switching control framework under the multiple weighting adaptive event-triggered scheme is developed. Under this control framework, a novel full-information dependent LKF analysis approach is proposed to analyze the stability of neural networks, which fully considers the system information, such as the membership functions (MFs) information, modes information and state information. Meanwhile, a new MFs dependent optimal H ∞ performance index is introduced to achieve better disturbance attenuation ability. The proposed analysis approach is helpful in determining the controller gains and reducing the conservatism. Ultimately, four simulation examples are provided to show the effectiveness and superiority of proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yiteng Zhang and Linchuang Zhang and Yonghui Sun and Wen Yang},
  doi          = {10.1016/j.neucom.2025.131097},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131097},
  shortjournal = {Neurocomputing},
  title        = {Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models. <em>NEUCOM</em>, <em>656</em>, 131071. (<a href='https://doi.org/10.1016/j.neucom.2025.131071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, pre-trained language models based on the Transformer architecture have achieved significant results in many natural language processing tasks. However, the high computational cost limits their application in real-world scenarios. Previous Transformer compression methods typically focus on single-dimensional compression, which may cause over-compression and consequently degrade model performance. Additionally, these methods lack targeted optimization for specific downstream tasks. In this paper, we propose DCHF_T, a multi-dimensional adaptive compression approach that compresses Transformer models through token compression, attention head pruning, and a lightweight FFN. This approach selects the most informative tokens during training, prunes unimportant tokens, and retains their information in a compressed form, allowing the model to focus more on task-relevant inputs. Furthermore, DCHF_T combines attention head pruning and a lightweight FFN to reduce computation and parameter size across multiple dimensions. We employ multi-objective evolutionary search to optimize the trade-off between accuracy and efficiency under various computational budgets. Experimental results on the GLUE benchmark demonstrate that DCHF_T achieves the best compression–performance trade-off. While maintaining the highest accuracy, DCHF_T achieves a reduction of 3.7 × and 3.6 × in FLOPs on BERT-base and RoBERTa-base, respectively. By implementing adaptive multi-dimensional compression, DCHF_T provides a systematic solution for deploying Transformer models in resource-constrained scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao Yan and Da Wang and Jing Ye and Hui Yu and Dianjie Lu and Yuang Zhang and Weizhi Xu and Fang’ai Liu},
  doi          = {10.1016/j.neucom.2025.131071},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131071},
  shortjournal = {Neurocomputing},
  title        = {DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key-concept thinking prompting for improved reasoning in large language models. <em>NEUCOM</em>, <em>656</em>, 130986. (<a href='https://doi.org/10.1016/j.neucom.2025.130986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large language models (LLMs) have significantly accelerated the development of natural language processing (NLP) research, demonstrating remarkable capabilities in understanding and generating human-like text. However, these models face limitations when it comes to system 2 tasks, which require slow, multi-step, and conscious reasoning. To address these limitations, we introduce a method called Key-Concept Thinking (KCT), which enhances the model’s reasoning ability by directing it to identify and prioritize key concepts within a problem. Building on the Chain-of-Thought (CoT) prompting method, KCT anchors its approach in core ideas, allowing the model to form a deeper understanding of the problem’s structure and purpose. This targeted approach aims to improve both the accuracy and efficiency of the model’s reasoning, making it better equipped to handle tasks that require precision and deep understanding. We evaluate our proposed prompting strategies using 24 reasoning tasks across four categories: arithmetic, commonsense, symbolic, and other logical reasoning tasks, with three prominent large models: ChatGLM4, Baichuan2, and DeepSeek, respectively. The results show that the Zero-shot-KCT and Zero-shot-CoT-KCT strategies outperform traditional zero-shot and few-shot prompting strategies, highlighting the effectiveness of incorporating key concept thinking into the reasoning processes of LLMs. Our findings have implications for the development of more effective prompting strategies for LLMs that can handle complex reasoning tasks with higher accuracy and coherence.},
  archive      = {J_NEUCOM},
  author       = {Minghua Tang and Chen Bian and Liming Yang and Xueling Zhong},
  doi          = {10.1016/j.neucom.2025.130986},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {130986},
  shortjournal = {Neurocomputing},
  title        = {Key-concept thinking prompting for improved reasoning in large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="nn">NN - 31</h2>
<ul>
<li><details>
<summary>
(2026). DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation. <em>NN</em>, <em>194</em>, 108118. (<a href='https://doi.org/10.1016/j.neunet.2025.108118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vascular morphology plays a crucial role in diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and stylistic augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to apply random photometric augmentations and introduce uncertainty perturbations, enriching the stylistic diversity of fundus images and further improving the model’s robustness and generalization across varying imaging conditions. Our framework, which employs a DeepLabv3+ model with a MobileNetV2 backbone as its segmentation network, has been rigorously evaluated on four challenging datasets—DRIVE, CHASEDB1, HRF, and STARE—achieving Dice Similarity Coefficient (DSC) of 78.45%, 78.62%, 72.66% and 82.17%, respectively, with an average DSC of 77.98%. These results demonstrate that our method surpasses existing approaches, validating its effectiveness and highlighting its potential for clinical application in automated retinal vessel analysis.},
  archive      = {J_NN},
  author       = {Bo Liu and Yudong Zhang and Shuihua Wang and Siyue Li and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108118},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108118},
  shortjournal = {Neural Netw.},
  title        = {DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution. <em>NN</em>, <em>194</em>, 108116. (<a href='https://doi.org/10.1016/j.neunet.2025.108116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data distribution discrepancy across datasets is one of the major obstacles hindering the improvement of the accuracy of cross-domain adaptive detection of medical images. To address this challenge, we propose a novel lightweight cross-modal adaptive detection module named LCA-Med (LCaM). The proposed module boasts a lightweight structure and a minimalistic parameter count, thereby facilitating its integration into the anterior segment of a diverse array of foundational and downstream networks. It is adept at serving as a feature preprocessor, proficiently extracting pertinent information regrading pathologies from a array of images (image modality) produced through varied medical imaging techniques, all guided by the input of prompts (text modality). We also propose a novel cross-modal medical image adaptive detection method, LCA-Med CNX (LCaM-CNX), and a novel cross-domain adaptive detection training paradigm that incorporates generated dataset groups, an attention module, and a meta-heuristic algorithm. Experimental results on six medical image datasets compared with ten state-of-the-art methods demonstrate that the LCaM-CNX trained following the proposed paradigm achieves the best performance on five datasets and competitive performance on the other dataset. Notably, our method outperforms the state-of-the-art methods more when the data distribution is more imbalanced.},
  archive      = {J_NN},
  author       = {Xiang Li and Long Lan and Husam Lahza and Shaowu Yang and Shuihua Wang and Yong Liang and Hudan Pan and Wenjing Yang and Hengzhu Liu and Yudong Zhang},
  doi          = {10.1016/j.neunet.2025.108116},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108116},
  shortjournal = {Neural Netw.},
  title        = {LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual causal inference for robust visual question answering. <em>NN</em>, <em>194</em>, 108115. (<a href='https://doi.org/10.1016/j.neunet.2025.108115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) systems have seen remarkable progress with the incorporation of multimodal data. However, their performance is still hampered by biases ingrained in language and vision modalities, frequently resulting in subpar generalization. In this study, we introduce a novel counterfactual causal framework (CC-VQA). This framework utilizes Counterfactual Sample Synthesis (CSS) and causal inference to tackle cross-modality biases. Our approach innovatively employs a strategy based on causal graphs, which effectively disentangles spurious correlations in multimodal data. This ensures a balanced and precise multimodal reasoning process, enabling the model to make more accurate and unbiased decisions. Moreover, we propose a contrastive loss mechanism. By contrasting the embeddings of positive and negative samples, this mechanism significantly enhances the robustness of VQA models. Additionally, we develop a robust training strategy that improves both the visual-explainable and question-sensitive capabilities of these models. Our experimental evaluations on benchmark datasets, such as VQA-CP v2 and VQA v2, demonstrate substantial improvements in bias mitigation and overall accuracy. The proposed CC-VQA framework outperforms state-of-the-art methods, highlighting its effectiveness in enhancing the performance of VQA systems.},
  archive      = {J_NN},
  author       = {Wei Li and Zhixin Li and Fuyun Deng and Kun Zeng and Canlong Zhang},
  doi          = {10.1016/j.neunet.2025.108115},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108115},
  shortjournal = {Neural Netw.},
  title        = {Counterfactual causal inference for robust visual question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the theoretical expressive power of graph transformers for solving graph problems. <em>NN</em>, <em>194</em>, 108112. (<a href='https://doi.org/10.1016/j.neunet.2025.108112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformers have become the dominant neural architecture in the fields of natural language processing and computer vision. The generalization of Transformers to graphs, so-called Graph Transformers, have recently emerged as a promising alternative to the successful message passing Graph Neural Networks (MPNNs). While the expressive power of MPNNs has been intensively studied in the past years, that of Graph Transformers is still underexplored. Existing results mostly rely on the employed structural/positional encodings and not on the pure architecture itself. However, gaining an understanding of the strengths and limitations of Graph Transformers would be very useful both for the scientific community and the practitioners. In this paper, we derive a connection between Graph Transformers and the Congested clique , a popular model in distributed computing. This connection allows us to translate theoretical results for different graph problems from the latter to the former. We show that under certain conditions, Graph Transformers with depth 2 are Turing universal. We also show that there exist Graph Transformers that can solve problems which cannot be solved by MPNNs. We empirically investigate whether Graph Transformers and MPNNs with depth 2 can solve graph problems on some molecular datasets. Our results demonstrate that Graph Transformers can generally address the underlying tasks, while MPNNs are incapable of learning any information about the graph.},
  archive      = {J_NN},
  author       = {Giannis Nikolentzos and Dimitrios Kelesis and Michalis Vazirgiannis},
  doi          = {10.1016/j.neunet.2025.108112},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108112},
  shortjournal = {Neural Netw.},
  title        = {On the theoretical expressive power of graph transformers for solving graph problems},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders. <em>NN</em>, <em>194</em>, 108110. (<a href='https://doi.org/10.1016/j.neunet.2025.108110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodevelopmental disorders exhibit highly similar behavioral characteristics in clinical assessments, heavily relying on subjective behavioral reports, leading to insufficient understanding of the neurobiological mechanisms behind inter-patient heterogeneity and symptom overlap between diseases. To address this issue, this study proposes a graph neural network framework that integrates neuroimaging data, focusing on three key problems: Firstly, enhance the nonlinear features in brain neural activity by introducing the Neurodynamics Rössler system. Transform raw static neural signals into simulated signals with nonlinear, temporal, and dynamic features, thereby more accurately reflecting the process of brain neural activity. Secondly, improve feature discrimination by integrating the spatial adjacency characteristics of local brain regions with the topological structure information of the global brain network to highlight key features. Thirdly, improve noise resistance and generalization ability. Introducing adaptive controllers and cross-site adversarial learning mechanisms, the interference of heterogeneous noise is effectively reduced. This study conducted experimental validation on data from neurodevelopmental disorders such as ADHD and ASD. The results indicate that this framework not only has advantages in classification accuracy but also possesses good interpretability, making it a promising tool for imaging biomarker research and auxiliary diagnosis.},
  archive      = {J_NN},
  author       = {Qiulei Han and Hongbiao Ye and Miaoshui Bai and Lili Wang and Yan Sun and Ze Song and Jian Zhao and Lijuan Shi and Zhejun Kuang},
  doi          = {10.1016/j.neunet.2025.108110},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108110},
  shortjournal = {Neural Netw.},
  title        = {MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability of large-scale probabilistic boolean networks via network aggregation. <em>NN</em>, <em>194</em>, 108108. (<a href='https://doi.org/10.1016/j.neunet.2025.108108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale probabilistic Boolean networks (LSPBNs) are a modeling tool used to simulate and analyze the dynamics of complex systems with uncertainty. However, due to its high computational complexity, previous research methods cannot be directly applied to study such systems. Inspired by network aggregation, this paper conducts network aggregation on LSPBNs to investigate its global stability with probability 1. It is worth mentioning that the stability conclusion proposed in this article holds for any form of network aggregation. First, the entire network is partitioned and the algebraic expressions for each subnetwork are given through the semi-tensor product of matrices. And then, a set of iterative formulas is constructed to describe and reflect the input-output coordination relationship among the subnetworks, and based on which, a sufficient condition for the global stability of LSPBNs is derived, greatly reducing computational complexity. The feasibilities of the proposed method and results are verified through examples.},
  archive      = {J_NN},
  author       = {Wen Liu and Shihua Fu and Jianjun Wang and Renato De Leone and Jianwei Xia},
  doi          = {10.1016/j.neunet.2025.108108},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108108},
  shortjournal = {Neural Netw.},
  title        = {Stability of large-scale probabilistic boolean networks via network aggregation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPC: Self-supervised point cloud completion. <em>NN</em>, <em>194</em>, 108107. (<a href='https://doi.org/10.1016/j.neunet.2025.108107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape incompleteness is a common issue in point clouds acquired by depth sensors. Point cloud completion aims to restore partial point clouds to their complete form. However, most existing point cloud completion methods rely on complete point clouds or multi-view information of the same object during training, which is not practical for real-world scenarios with high information acquisition costs. To overcome the above limitation, a self-supervised point cloud completion (SPC) method is proposed, which uses the training set consisting of only a single partial point cloud for each object. Specifically, an autoencoder-like network architecture that includes a two-step strategy is developed. First, a compression-reconstruction strategy is proposed to enable the network to learn the representation of complete point clouds from existing knowledge. Then, considering the potential problem of overfitting in self-supervised training, a global enhancement strategy is further designed to maintain the positional coherence of predicted points. Comprehensive experiments are conducted on the ScanNet, MatterPort3D, KITTI, and ShapeNet datasets. On real-world datasets, the unidirectional Chamfer distance (UCD) and the unidirectional Hausdorff distance (UHD) of the method are reduced by an average of 2.3 and 2.4, respectively, compared to the state-of-the-art method. In addition to its excellent completion capabilities, the proposed method has a positive impact on downstream tasks. In point cloud classification, applying the proposed method improves classification accuracy by an average of 14 %. Extensive experimental results demonstrate that the proposed SPC has a high practical value.},
  archive      = {J_NN},
  author       = {Jie Song and Xing Wu and Junfeng Yao and Qi Zhang and Chenhao Shang and Quan Qian and Jun Song},
  doi          = {10.1016/j.neunet.2025.108107},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108107},
  shortjournal = {Neural Netw.},
  title        = {SPC: Self-supervised point cloud completion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition. <em>NN</em>, <em>194</em>, 108106. (<a href='https://doi.org/10.1016/j.neunet.2025.108106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) integrates complementary information from both text and images to identify named entities within text. However, existing methods face three key issues: imbalanced handling of modality noise, the cascading effect of semantic mismatch, and information loss resulting from the lack of text dominance. To address these issues, this paper proposes a M ulti-stage I nteraction N etwork I nspired by G ene E diting for MNER (MINIGE-MNER). The core innovations of this method include: A gene knockout module based on the variational information bottleneck, which removes inferior genes (modality noise) from the text, raw image, and generated image features. This approach retains the superior genes, achieving balanced filtering of modality noise. A determination of gene recombination sites module that maximizes the mutual information between superior genes across modalities, reducing the spatial distance between them and ensuring precise, fine-grained semantic alignment. This helps to prevent the cascading effect of semantic mismatch. A text-guided gene recombination module that implements a “text-dominant, vision-supplementary” cross-modal fusion paradigm. This module dynamically filters out visual noise unrelated to the text while avoiding excessive reliance on visual information that could obscure the unique contextual information of the text, effectively mitigating information loss. Experimental results show that MINIGE-MNER achieves F1 scores of 76.45 % and 88.67 % on the Twitter-2015 and Twitter-2017 datasets, respectively, outperforming existing state-of-the-art methods by 0.83 % and 0.42 %. In addition, this paper presents comprehensive experiments that demonstrate the superiority of MINIGE-MNER and the effectiveness of its individual modules.},
  archive      = {J_NN},
  author       = {Bo Kong and Shengquan Liu and Liruizhi Jia and Yi Liang and Dongfang Han and Xu Zhang},
  doi          = {10.1016/j.neunet.2025.108106},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108106},
  shortjournal = {Neural Netw.},
  title        = {MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified gradient regularization method for heterogeneous graph neural networks. <em>NN</em>, <em>194</em>, 108104. (<a href='https://doi.org/10.1016/j.neunet.2025.108104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks (HGNNs) are advanced deep learning methods widely applied for learning representations of heterogeneous graphs. However, they face challenges such as over-smoothing and non-robustness. Existing methods can mitigate these issues by applying gradient regularization to one of the three information dimensions: node, edge, or propagation message. However, these methods have problems such as unstable training, difficulty in parameter convergence, and inadequate utilization of heterogeneous information. We propose a novel gradient regularization method called Grug, which iteratively applies regularization to the gradients derived from both node type and message matrix during the message-passing process. A detailed theoretical analysis demonstrates its advantages in Stability and Diversity. Notably, Grug potentially exceeds the theoretical upper bounds set by DropMessage. In addition, Grug offers a unified gradient regularization framework that integrates the existing dropping and adversarial training methods, and provides theoretical guidance for their further optimization in different data and tasks. We validate Grug through extensive experiments on six public datasets, showing significant improvements in performance and effectiveness.},
  archive      = {J_NN},
  author       = {Xiao Yang and Xuejiao Zhao and Zhiqi Shen},
  doi          = {10.1016/j.neunet.2025.108104},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108104},
  shortjournal = {Neural Netw.},
  title        = {A unified gradient regularization method for heterogeneous graph neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-level graph contrastive learning for community value prediction. <em>NN</em>, <em>194</em>, 108103. (<a href='https://doi.org/10.1016/j.neunet.2025.108103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Value Prediction (CVP) is an important emerging task in the field of social commerce, which aims to predict the community values. However, due to the complex structure of communities and individuals, previous graph machine learning methods have struggled to adequately address this task. This study endeavors to bridge this gap by introducing a cross-level graph contrastive learning method called Cross-level Community Contrastive Learning (CCCL) to handle such subgraph-level tasks. Specifically, we generate two views that describe different levels of social connections, the augmented node-level graph and the community-level graph that is produced by graph coarsening. Subsequently, CCCL captures the mutual information between the two views through a cross-view contrastive loss. The learned embeddings utilize community and node information at various levels, making them capable of handling subgraph-level regression problems. To the best of our knowledge, CCCL is the first graph contrastive learning method that addresses the CVP problem. We theoretically show that CCCL maximizes a lower bound of the mutual information shared between node-view and community-view representations. Experimental results demonstrate that our proposed approach is highly effective for the CVP task, outperforming both end-to-end and self-supervised baselines. Furthermore, our model also exhibits robust resistance to edge perturbation attacks.},
  archive      = {J_NN},
  author       = {Wenjie Yang and Shengzhong Zhang and Zengfeng Huang},
  doi          = {10.1016/j.neunet.2025.108103},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108103},
  shortjournal = {Neural Netw.},
  title        = {Cross-level graph contrastive learning for community value prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training. <em>NN</em>, <em>194</em>, 108102. (<a href='https://doi.org/10.1016/j.neunet.2025.108102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation, which aims to provide accurate descriptions of both normal and abnormal regions, has been attracting growing research attention. Recently, despite considerable progress, data-driven deep-learning based models still face challenges in capturing and describing the abnormalities, due to the data bias problem. To address this problem, we propose to generate radiology reports via the Visual-Semantic Ambivalence-Aware Network (VSANet) and the Focal Self-Critical Sequence Training (FSCST). In detail, our VSANet follows the encoder-decoder framework. In the encoder part, we first deploy a multi-grained abnormality extractor and a visual extractor to capture both semantic and visual features from given images, and then introduce a Parameter Shared Dual-way Encoder (PSDwE) to delve into the inter- and intra-relationships among these features. In the decoder part, we propose the Visual-Semantic Ambivalence-Aware (VSA) module to generate the abnormality-aware visual features to mitigate the data bias problem. In implementation, our VSA introduces three sub-modules: Dual-way Attention (DwA), introduced to generate both the word-related visual and semantic features; Dual-way Attention on Attention (DwAoA), designed to mitigate redundant information; Score-based Feature Fusion (SFF), constructed to fuse the visual and semantic features in an ambivalence way. We further introduce the FSCST to enhance the overall performance of our VSANet by allocating more attention toward difficult samples. Experimental results demonstrate that our proposal achieves superior performance on various evaluation metrics. Source code have released at https://github.com/SKD-HPC/VSANet .},
  archive      = {J_NN},
  author       = {Xiulong Yi and You Fu and Enxu Bi and Jianguo Liang and Hao Zhang and Jianzhi Yu and Qianqian Li and Rong Hua and Rui Wang},
  doi          = {10.1016/j.neunet.2025.108102},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108102},
  shortjournal = {Neural Netw.},
  title        = {Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative representation learning via attention-enhanced contrastive learning for short text clustering. <em>NN</em>, <em>194</em>, 108101. (<a href='https://doi.org/10.1016/j.neunet.2025.108101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has gained significant attention in short text clustering, yet it has an inherent drawback of mistakenly identifying samples from the same category as negatives and separating them in the feature space (i.e., the false negative separation problem). To generate discriminative representations for short text clustering, we propose a novel clustering method, called Discriminative Representation learning via A ttention- E nhanced C ontrastive L earning for Short Text Clustering ( AECL ). The AECL consists of two modules which are the contrastive learning module and the pseudo-label assisting module. Both modules utilize a sample-level attention mechanism to extract similarities between samples, based on which cross-sample features are aggregated to form a consistent representation for each sample. The contrastive learning module explores the similarity relationships and the consistent representations to form positive samples, effectively addressing the false negative separation issue, and the pseudo-label assisting module utilizes the consistent representations to produce reliable supervision information to assist the clustering task. Experimental results demonstrate that AECL outperforms state-of-the-art methods. The code is available at https://github.com/YZH0905/AECL-STC .},
  archive      = {J_NN},
  author       = {Zhihao Yao and Bo Li and Yufei Liao},
  doi          = {10.1016/j.neunet.2025.108101},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108101},
  shortjournal = {Neural Netw.},
  title        = {Discriminative representation learning via attention-enhanced contrastive learning for short text clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects. <em>NN</em>, <em>194</em>, 108100. (<a href='https://doi.org/10.1016/j.neunet.2025.108100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fixed-time synchronization (FXTS) and prescribed-time synchronization (PSTS) problems of state-dependent switching neural networks (SDSNNs) with stochastic disturbances and impulsive effects. By leveraging the average impulsive interval, comparison principle, and interval matrix methodology, this study advances a novel analytical framework. Departing from conventional approaches, we reformulate stochastic disturbed and impulsive SDSNNs as interval-parameter systems through rigorous interval matrix transformation. Consequently, we derive some sufficient conditions in the form of linear matrix inequalities (LMIs) to ensure the realization of FXTS and PSTS. Since impulsive effects can potentially compromise synchronization stability, careful controller design becomes critical. To address this challenge, we develop a unified proportional integral (PI) control framework. Through proper adjustment of its control parameters, this framework enables the system to achieve both FXTS and PSTS. Moreover, by reasonably configuring the relationship between the impulsive intensity and the prescribed time, the synchronization performance can be balanced. Finally, we demonstrate the effectiveness of the theoretical results through two examples.},
  archive      = {J_NN},
  author       = {Guici Chen and Houxuan Zhang and Shiping Wen and Junhao Hu and Leimin Wang},
  doi          = {10.1016/j.neunet.2025.108100},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108100},
  shortjournal = {Neural Netw.},
  title        = {Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories. <em>NN</em>, <em>194</em>, 108099. (<a href='https://doi.org/10.1016/j.neunet.2025.108099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of long-tail visual recognition, the imbalance in data distribution leads to a significant performance gap between head and tail classes. Improving the tail-class performance and alleviating the decline in head class are two critical questions. Although many methods have proposed solutions for the former, most of them fall short in the latter. Introducing additional knowledge is a novel view to address the problem, however, how to attain useful knowledge and further transfer the knowledge to the target model is the core. This paper proposes a novel method called Expert Knowledge Distillation for Specific Categories (EKDSC). Firstly, we propose a kind of well-trained teacher model ensuring each expert concentrates on its specialized field while being less affected by other interference. Furthermore, the teacher model including three categories of experts: head, mid, and tail classes, is utilized to distill their specialized knowledge to the student model. Experimental results demonstrate that EKDSC effectively improves the accuracy of tail classes, and mitigates the common decreases of head classes’ performance. Our proposed method achieves a high accuracy, exceeding the current state-of-the-art (SOTA) by 1–5 % on benchmark datasets including the small-scale CIFAR-10 LT and CIFAR-100 LT. Furthermore, it demonstrates outstanding performance on large-scale datasets such as ImageNet-LT, iNaturalist 2018, and Places-LT.},
  archive      = {J_NN},
  author       = {Yaping Bai and Jinghua Li and Dehui Kong and Suqiao Yang and Baocai Yin},
  doi          = {10.1016/j.neunet.2025.108099},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108099},
  shortjournal = {Neural Netw.},
  title        = {EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations. <em>NN</em>, <em>194</em>, 108098. (<a href='https://doi.org/10.1016/j.neunet.2025.108098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal imitation learning enables the agent to learn demonstrations of multiple modes at the same time. However, as expert demonstrations in practice tend to have incomplete labels for behavior modes, most methods are inefficient. To address this issue, an approach capable of imitation learning from incompletely labeled expert demonstrations, referred to as Weakly Supervised Multi-modal Imitation Learning (WSMIL), is proposed. WSMIL incorporates weakly supervised learning into multi-modal imitation learning by adding a behavior mode classifier to the adversarial network, thus forming adversaries among three players (generator, classifier and discriminator). Both labeled and unlabeled data are fully utilized in this adversarial process where fake state-action-label pairs generated by the generator and the classifier try to deceive the discriminator that tries to identify them and limited labeled expert demonstrations. Additionally, in order to ensure the data distribution of classifier and generator individually to converge to the expert’s real distribution, three extra losses are employed, where simulated annealing behavioral cloning is also added to the generator network to improve the generalization of policy. Experiments show that WSMIL accurately distinguishes modes with incomplete modal labels in demonstrations, learns close to the expert standard for each mode, and is more stable than other multi-modal methods.},
  archive      = {J_NN},
  author       = {Sijia Gu and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108098},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108098},
  shortjournal = {Neural Netw.},
  title        = {Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection. <em>NN</em>, <em>194</em>, 108097. (<a href='https://doi.org/10.1016/j.neunet.2025.108097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight salient object detection (SOD) is widely used in various downstream applications due to its low resource requirements and fast inference speed. The use of hybrid encoders offers the potential to achieve a better balance between efficiency and accuracy for SOD task. However, the aggregation of features from convolutional neural networks (CNNs) and transformers remains challenging, and most existing lightweight SOD models rarely explore the efficient aggregation of cross-architecture features derived from hybrid encoders. In this paper, we propose a hybrid aggregation strategy network (HASNet) that balances accuracy and efficiency for lightweight SOD by grouping and aggregating features to leverage salient information across different architectures. Specifically, the features obtained after hybrid encoder processing are divided into convolutional and transformer features for shallow and deep aggregation respectively. Deep aggregation uses the global inverted residual block (GIRB) to facilitate the transfer of salient information encoded within transformer features across various levels. Meanwhile, shallow aggregation uses the lightweight inverted residual block (LIRB) to efficiently integrate the spatial information inherent in convolutional features. The GIRB incorporates an efficient global operation to extract channel semantic information from the high-dimensional transformer features. The LIRB fuses low-level features by efficiently exploiting the spatial information in features at extremely low computational cost. Comprehensive experiments conducted across five datasets demonstrate that our HASNet significantly outperform existing methods in a thorough evaluation encompassing parameter sizes, inference speed, and accuracy. The source code will be publicly available at https://github.com/LitterMa-820/HASNet .},
  archive      = {J_NN},
  author       = {Jianhua Ma and Mingfeng Jiang and Xian Fang and Jiatong Chen and Yaming Wang and Guang Yang},
  doi          = {10.1016/j.neunet.2025.108097},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108097},
  shortjournal = {Neural Netw.},
  title        = {Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing image restoration through learning context-rich and detail-accurate features. <em>NN</em>, <em>194</em>, 108096. (<a href='https://doi.org/10.1016/j.neunet.2025.108096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover high-quality images from their degraded counterparts, necessitating a delicate balance between preserving spatial details and capturing contextual information. Although some methods attempt to address this trade-off, they tend to focus primarily on spatial features while overlooking the importance of understanding frequency variations. Moreover, these approaches commonly utilize skip connections–implemented via addition or concatenation–to fuse encoder and decoder features for improved restoration. However, since encoder features may still carry degradation artifacts, such direct fusion strategies risk introducing implicit noise, ultimately hindering restoration performance. In this paper, we present a multi-scale design that optimally balances these competing objectives, seamlessly integrating spatial and frequency domain knowledge to selectively recover the most informative information. Specifically, we develop a hybrid scale frequency selection block (HSFSBlock), which not only captures multi-scale information from the spatial domain, but also selects the most informative components for image restoration in the frequency domain. Furthermore, to mitigate the inherent noise introduced by skip connections employing only addition or concatenation, we introduce a skip connection attention mechanism (SCAM) to selectively determines the information that should propagate through skip connections. The resulting tightly interlinked architecture, named as LCDNet. Extensive experiments conducted across diverse image restoration tasks showcase that our model attains performance levels that are either superior or comparable to those of state-of-the-art algorithms. The code and the pre-trained models are released at https://github.com/Tombs98/LCDNet .},
  archive      = {J_NN},
  author       = {Hu Gao and Xiaoning Lei and Depeng Dang},
  doi          = {10.1016/j.neunet.2025.108096},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108096},
  shortjournal = {Neural Netw.},
  title        = {Enhancing image restoration through learning context-rich and detail-accurate features},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation. <em>NN</em>, <em>194</em>, 108095. (<a href='https://doi.org/10.1016/j.neunet.2025.108095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) has emerged as a critical paradigm for adapting large pre-trained models to downstream tasks, offering a balance between computational efficiency and model performance. Among these methods, Low-Rank Adaptation (LoRA) has gained significant popularity due to its efficiency; it freezes the pre-trained weights and decomposes the incremental matrices into two trainable low-rank matrices. However, a critical limitation of LoRA lies in its uniform rank assignment across all layers, which fails to account for the heterogeneous importance of different layers in contributing to task performance, potentially resulting in suboptimal adaptation. To address this limitation, we propose Layer-wise Adaptive Low-Rank Adaptation (La-LoRA), a novel approach that dynamically allocates rank to each layer based on Dynamic Contribution-Driven Parameter Budget (DCDPB) and Truncated Norm Weighted Dynamic Rank Allocation (TNW-DRA) during training. By treating each layer as an independent unit and progressively adjusting its rank allocation, La-LoRA ensures optimal model performance while maintaining computational efficiency and adapting to the complexity of diverse tasks. We conducted extensive experiments across multiple tasks and models to evaluate the effectiveness of La-LoRA. The results demonstrate that La-LoRA consistently outperforms existing benchmarks, validating its effectiveness in diverse scenarios.},
  archive      = {J_NN},
  author       = {Jiancheng Gu and Jiabin Yuan and Jiyuan Cai and Xianfa Zhou and Lili Fan},
  doi          = {10.1016/j.neunet.2025.108095},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108095},
  shortjournal = {Neural Netw.},
  title        = {La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-level dynamic heterogeneous graph network for video question answering. <em>NN</em>, <em>194</em>, 108094. (<a href='https://doi.org/10.1016/j.neunet.2025.108094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Video Question Answering (VideoQA) has garnered considerable research interest as a pivotal task within the realm of vision-language understanding. However, existing Video Question Answering datasets often lack sufficient entity and event information. Thus, the Vision Language Models (VLMs) struggle to complete intricate grounding and reasoning among multi-modal entities or events and heavily rely on language short-cut or irrelevant visual context. To address these challenges, we make improvements from both data and model perspectives. In terms of VideoQA data, we focus on supplementing the missing specific entities and events with the proposed event and entity augmentation strategies. Based on the augmented data, we propose a Dual-Level Dynamic Heterogeneous Graph Network (DDHG) for Video Question Answering. DDHG incorporates transformer layers to capture the dynamic temporal-spatial changes of visual entities. Then, DDHG establishes multi-modal semantic grounding ability between vision and text with entity-level and event-level heterogeneous graphs. Finally, the Dual-level Cross-modal Interaction Module integrates the dual-level features to predict correct answers. Our method not only significantly outperforms existing VideoQA models on two complex event-based benchmark datasets (Causal-VidQA and NExT-QA) but also demonstrates superior event content prediction ability over several state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Zefan Zhang and Yanhui Li and Weiqi Zhang and Tian Bai},
  doi          = {10.1016/j.neunet.2025.108094},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108094},
  shortjournal = {Neural Netw.},
  title        = {Dual-level dynamic heterogeneous graph network for video question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction. <em>NN</em>, <em>194</em>, 108093. (<a href='https://doi.org/10.1016/j.neunet.2025.108093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction plays a crucial role in drug discovery and repurposing by efficiently and accurately identifying potential therapeutic targets. Existing methods face challenges in capturing high-order semantic relationships in heterogeneous graphs and effectively integrating multi-meta-path information while also suffering from low computational efficiency. To address these challenges, a pre-computation-style hierarchical meta-path learning framework named HMT-DTI is proposed. HMT-DTI can effectively capture rich semantic information about drugs and targets while ensuring high computational efficiency. Specifically, during the pre-collection stage, HMT-DTI employs a Transformer-based message passing mechanism to evaluate neighbors’ importance and adaptively collect meta-path information. The incorporation of even-relation propagation reduces redundant iterations and improves efficiency. During training, HMT-DTI adopts a hierarchical knowledge extraction strategy to evaluate the importance of multi-hop neighbors and different meta-path patterns, capturing fine-grained semantic representations of drugs and targets. HMT-DTI is evaluated on three heterogeneous biological datasets and compared with several state-of-the-art methods. The results demonstrate the superiority of HMT-DTI in DTI prediction.},
  archive      = {J_NN},
  author       = {Dianlei Gao and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108093},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108093},
  shortjournal = {Neural Netw.},
  title        = {HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis. <em>NN</em>, <em>194</em>, 108091. (<a href='https://doi.org/10.1016/j.neunet.2025.108091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal neuroimaging techniques are widely employed for the accurate diagnosis of Alzheimer’s Disease (AD). Existing fusion methods typically focus on capturing semantic correlations between modalities through feature-level interactions. However, they fail to suppress redundant cross-modal information, resulting in sub-optimal multi-modal representation. Moreover, these methods ignore subject-specific differences in modality contributions. To address these challenges, we propose a novel Multi-modal Orthogonal Fusion Network via cross-layer guidance (MOFNet) to effectively fuse multi-modal information for AD diagnosis. We first design a Cross-layer Guidance Interaction module (CGI), leveraging high-level features to guide the learning of low-level features, thereby enhancing the fine-grained representations on disease-relevant regions. Then, we introduce a Multi-modal Orthogonal Compensation module (MOC) to realize bidirectional interaction between modalities. MOC encourages each modality to compensate for its limitations by learning orthogonal components from other modalities. Finally, a Feature Enhancement Fusion module (FEF) is developed to adaptively fuse multi-modal features based on the contributions of different modalities. Extensive experiments on the ADNI dataset demonstrate that MOFNet achieves superior performance in AD classification tasks.},
  archive      = {J_NN},
  author       = {Yumiao Zhao and Bo Jiang and Yuan Chen and Ye Luo and Jin Tang},
  doi          = {10.1016/j.neunet.2025.108091},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108091},
  shortjournal = {Neural Netw.},
  title        = {Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ClickAttention: Click region similarity guided interactive segmentation. <em>NN</em>, <em>194</em>, 108090. (<a href='https://doi.org/10.1016/j.neunet.2025.108090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive segmentation algorithms based on click points have attracted significant attention from researchers in recent years. However, most existing methods rely on sparse click maps as model inputs to segment specific target objects. These clicks primarily affect local regions, limiting the model’s ability to focus on the entire target object and often resulting in a higher number of required clicks. Additionally, many current algorithms struggle to balance performance and efficiency effectively. To address these challenges, we propose a click attention algorithm that expands the influence of positive clicks by leveraging the similarity between positively-clicked regions and the entire input. We further introduce a discriminative affinity loss to reduce attention coupling between positive and negative click regions, minimizing accuracy degradation caused by mutual interference. On the DAVIS dataset, our method achieves a 2 % performance gain (NoC@90) over the state-of-the-art SimpleClick-ViT-L, while using only 15.6 % of its parameters. Extensive experiments demonstrate that our approach outperforms existing methods and achieves state-of-the-art performance with fewer parameters. Data and code are published.},
  archive      = {J_NN},
  author       = {Long Xu and Yongquan Chen and Shanghong Li and Junkang Chen and Ziyuan Tang},
  doi          = {10.1016/j.neunet.2025.108090},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108090},
  shortjournal = {Neural Netw.},
  title        = {ClickAttention: Click region similarity guided interactive segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language model for multitask classification of memes. <em>NN</em>, <em>194</em>, 108089. (<a href='https://doi.org/10.1016/j.neunet.2025.108089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of social media and online memes has led to an increasing demand for automated systems that can analyse and classify multimodal data, particularly in online forums. Memes blend text and graphics to express complicated ideas, sometimes containing emotions, satire, or inappropriate material. Memes often represent cultural prejudices such as objectification, sexism, and bigotry, making it difficult for artificial intelligence to classify these components. Our solution is the vision-language model ViT-BERT CAMT (cross-attention multitask), which is intended for multitask meme categorization. Our model uses a linear self-attentive fusion mechanism to combine vision transformer (ViT) features for image analysis and bidirectional encoder representations from transformers (BERT) for text interpretation. In this way, we can see how text and images relate to space and meaning. We tested the ViT-BERT CAMT on two difficult datasets: the SemEval 2020 Memotion dataset, which contains a multilabel classification of sentiment, sarcasm, and offensiveness in memes, and the MIMIC dataset, which focuses on detecting sexism, objectification, and prejudice. The findings show that the ViT-BERT CAMT achieves good accuracy on both datasets and outperforms many current baselines in multitask settings. These results highlight the importance of combined image-text modelling for correctly deciphering nuanced meanings in memes, particularly when spotting abusive and discriminatory content. By improving multimodal categorization algorithms, this study helps better monitor and comprehend online conversation.},
  archive      = {J_NN},
  author       = {Md. Mithun Hossain and Md. Shakil Hossain and M.F. Mridha and Nilanjan Dey},
  doi          = {10.1016/j.neunet.2025.108089},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108089},
  shortjournal = {Neural Netw.},
  title        = {A vision-language model for multitask classification of memes},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view learning meets state-space model: A dynamical system perspective. <em>NN</em>, <em>194</em>, 108088. (<a href='https://doi.org/10.1016/j.neunet.2025.108088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning exploits the complementary nature of multiple modalities to enhance performance across diverse tasks. While deep learning has significantly advanced these fields by enabling sophisticated modeling of intra-view and cross-view interactions, many existing approaches still rely on heuristic architectures and lack a principled framework to capture the dynamic evolution of feature representations. This limitation hampers interpretability and theoretical understanding. To address these challenges, this paper introduces the Multi-view State-Space Model (MvSSM), which formulates multi-view representation learning as a continuous-time dynamical system inspired by control theory. In this framework, view-specific features are treated as external inputs, and a shared latent representation evolves as the internal system state, driven by learnable dynamics. This formulation unifies feature integration and label prediction within a single interpretable model, enabling theoretical analysis of system stability and representational transitions. Two variants, MvSSM-Lap and MvSSM-iLap, are further developed using Laplace and inverse Laplace transformations to derive system dynamics representations. These solutions exhibit structural similarities to graph convolution operations in deep networks, supporting efficient feature propagation and theoretical interpretability. Experiments on benchmark datasets such as IAPR-TC12, and ESP demonstrate the effectiveness of the proposed method, achieving up to 4.31 % improvement in accuracy and 4.27 % in F1-score over existing state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Weibin Chen and Ying Zou and Zhiyong Xu and Li Xu and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108088},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108088},
  shortjournal = {Neural Netw.},
  title        = {Multi-view learning meets state-space model: A dynamical system perspective},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph convolutional network with adaptive grouping aggregation strategy. <em>NN</em>, <em>194</em>, 108086. (<a href='https://doi.org/10.1016/j.neunet.2025.108086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph convolutional networks (GCNs) with naive aggregation functions on nodes has reached the bottleneck, rendering a gap between practice and theoretical expressity. Some learning-based aggregation strategies have been proposed to improve the performance. However, few of them focus on how these strategies affect the expressity and evaluate their performance in an equal experimental setting. In this paper, we point out that the generated features lack discrimination because naive aggregation functions cannot retain sufficient node information, largely leading to the performance gap. Accordingly, a novel Adaptive Grouping Aggregation (AGA) strategy is proposed to remedy this drawback. Inspired by the label histogram in the Weisfeiler-Lehman (WL) Test, this strategy assigns each node to a unique group to retain more node information, which is proven to have a strictly more powerful expressity. In this work setting, the nodes are grouped according to a modified Student’s t-Distribution between node features and a set of learnable group labels, where the Gumbel Softmax is employed to implement this strategy in an end-to-end trainable pipeline. As a result, such a design can generate more discriminative features and offer a plug-in module in most architectures. Extensive experiments have been conducted on several benchmarks to compare our method with other aggregation strategies. The proposed method improves the performance in all control groups of all benchmarks and achieves the best result in most cases. Additional ablation studies and comparisons with state-of-the-art methods on the large-scale benchmark also indicate the superiority of our method.},
  archive      = {J_NN},
  author       = {Ruixiang Wang and Chunxia Zhang and Chunhong Pan},
  doi          = {10.1016/j.neunet.2025.108086},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108086},
  shortjournal = {Neural Netw.},
  title        = {Graph convolutional network with adaptive grouping aggregation strategy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive behavior with stable synapses. <em>NN</em>, <em>194</em>, 108082. (<a href='https://doi.org/10.1016/j.neunet.2025.108082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral changes in animals and humans, triggered by errors or verbal instructions, can occur extremely rapidly. While learning theories typically attribute improvements in performance to synaptic plasticity, recent findings suggest that such fast adaptations may instead result from dynamic reconfiguration of the networks involved without changes to synaptic weights. Recently, similar capabilities have been observed in transformers, foundational architecture in machine learning widely used in applications such as natural language and image processing. Transformers are capable of in-context learning, the ability to adapt and acquire new information dynamically within the context of the task or environment they are currently engaged in, without changing their parameters. We argue that this property may stem from gain modulation–a feature widely observed in biological networks, such as pyramidal neurons through input segregation and dendritic amplification. We propose a constructive approach to induce in-context learning in an architecture composed of recurrent networks with gain modulation, demonstrating abilities inaccessible to standard networks. In particular, we show that, such architecture can dynamically implement standard gradient-based by encoding weight changes in the activity of another network. We argue that, while these algorithms are traditionally associated with synaptic plasticity, their reliance on non-local terms suggests that they may be more naturally realized in the brain at the level of neural circuits. We demonstrate that we can extend our approach to temporal tasks and reinforcement learning. We further validate our approach in a MuJoCo ant navigation task, showcasing a neuromorphic control paradigm via real-time network reconfiguration.},
  archive      = {J_NN},
  author       = {Cristiano Capone and Luca Falorsi},
  doi          = {10.1016/j.neunet.2025.108082},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108082},
  shortjournal = {Neural Netw.},
  title        = {Adaptive behavior with stable synapses},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disentangled self-supervised video camouflaged object detection and salient object detection. <em>NN</em>, <em>194</em>, 108077. (<a href='https://doi.org/10.1016/j.neunet.2025.108077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video tasks play an important role in multimedia fields. In various video tasks, such as video camouflaged/salient object detection (VCOD/VSOD), motion and context information are two important aspects. Despite the fact that many existing works have already achieved promising results in VCOD and VSOD tasks, they still have limitations when it comes to leveraging motion and context information. In this paper, we propose a new disentangled perspective to treat motion and context information in VCOD and VSOD tasks. Our proposed model can respectively utilize context and motion information in ContextNet and MotionNet, without conflicting with each other as there can be biases between these two types of information in certain circumstances. Moreover, we further explore how to apply disentangled perspective in the self-supervised manner, which can reduce annotation costs. Specifically, we first design a self-supervised adaptive frame routing mechanism to determine whether each video frame belongs to ContextNet or MotionNet. Then we design a cross-supervision for ContextNet and MotionNet to train these two segmentation networks in self-supervised mechanism. In experiments, our proposed self-supervised disentangled model consistently outperforms state-of-the-art unsupervised methods on VCOD and VSOD datasets.},
  archive      = {J_NN},
  author       = {Haoke Xiao and Lv Tang and Bo Li and Zhiming Luo and Shaozi Li},
  doi          = {10.1016/j.neunet.2025.108077},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108077},
  shortjournal = {Neural Netw.},
  title        = {Disentangled self-supervised video camouflaged object detection and salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WPDA: Frequency-based backdoor attack with wavelet packet decomposition. <em>NN</em>, <em>194</em>, 108074. (<a href='https://doi.org/10.1016/j.neunet.2025.108074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores backdoor attack, which is an emerging security threat against deep neural networks (DNNs). The adversary aims to inject a backdoor into the model by manipulating a portion of training samples, such that the backdoor could be activated by a particular trigger to make a target prediction at inference. Currently, existing backdoor attacks often require moderate or high poisoning ratios to achieve the desired attack performance, but making them susceptible to some advanced backdoor defenses ( e . g . , poisoned sample detection). One possible solution to this dilemma is enhancing the attack performance at low poisoning ratios, which has been rarely studied due to its high challenge. To achieve this goal, we propose an innovative frequency-based backdoor attack via wavelet packet decomposition (WPD), which could finely decompose the original image into multiple sub-spectrograms with semantic information. It facilitates us to accurately identify the most critical frequency regions to effectively insert the trigger into the victim image, such that the trigger information could be sufficiently learned to form the backdoor. The proposed attack stands out for its exceptional effectiveness, stealthiness, and resistance at an extremely low poisoning ratio. Notably, it achieves the 98.12 % attack success rate on CIFAR-10 with an extremely low poisoning ratio of 0.004 % ( i.e. , only 2 poisoned samples among 50,000 training samples), and bypasses several advanced backdoor defenses. Besides, we provide more extensive experiments to demonstrate the efficacy of the proposed method, as well as in-depth analyses to explain its underlying mechanism.},
  archive      = {J_NN},
  author       = {Zhengyao Song and Yongqiang Li and Danni Yuan and Li Liu and Shaokui Wei and Baoyuan Wu},
  doi          = {10.1016/j.neunet.2025.108074},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108074},
  shortjournal = {Neural Netw.},
  title        = {WPDA: Frequency-based backdoor attack with wavelet packet decomposition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts. <em>NN</em>, <em>194</em>, 108064. (<a href='https://doi.org/10.1016/j.neunet.2025.108064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are gaining popularity for processing graph data. In real-world scenarios, graph data within the same dataset can vary significantly in scale. This variability leads to depth-sensitivity, where the optimal depth of GNN layers depends on the scale of the graph data. Empirically, fewer layers are sufficient for message passing in smaller graphs, while larger graphs typically require deeper networks to capture long-range dependencies and global features. However, existing methods generally use a fixed number of GNN layers to generate representations for all graphs, overlooking the depth-sensitivity issue in graph data. To address this challenge, we propose the depth adaptive mixture of expert (DA-MoE) method, which incorporates two main improvements to GNN backbone: 1) DA-MoE employs different GNN layers, each considered an expert with its own parameters. Such a design allows the model to flexibly aggregate information at different scales, effectively addressing the depth-sensitivity issue in graph data. 2) DA-MoE utilizes GNN to capture the structural information instead of the linear projections in the gating network. Thus, the gating network enables the model to capture complex patterns and dependencies within the data. By leveraging these improvements, each expert in DA-MoE specifically learns distinct graph patterns at different scales. Furthermore, comprehensive experiments on the TU dataset and open graph benchmark (OGB) have shown that DA-MoE consistently surpasses existing baselines on various tasks, including graph, node, and link-level analyses. The code are available at https://github.com/Celin-Yao/DA-MoE .},
  archive      = {J_NN},
  author       = {Zelin Yao and Mukun Chen and Chuang Liu and Xianke Meng and Yibing Zhan and Jia Wu and Shirui Pan and Huiting Xu and Wenbin Hu},
  doi          = {10.1016/j.neunet.2025.108064},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108064},
  shortjournal = {Neural Netw.},
  title        = {DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph representation learning with disentangled information bottleneck. <em>NN</em>, <em>194</em>, 108056. (<a href='https://doi.org/10.1016/j.neunet.2025.108056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning recently garnered enormous research attention. Despite the notable successes of existing methods, they usually characterize dynamic graphs as a perceptual whole and learn dynamic graph representations within an entangled feature space, which overlook different temporal dependencies inherent in the data. Specifically, the evolution of dynamic graphs is usually decided by a dichotomy in properties: time-invariant properties and time-varying properties. Existing holistic works fail to distinguish these temporal properties and may suffer suboptimal performance in downstream tasks. To tackle this problem, we propose to learn macro-disentangled dynamic graph representations based on the Information Bottleneck theory, leading to a novel dynamic graph representation learning method, Disentangled Dynamic Graph Information Bottleneck (DDGIB). Our DDGIB explicitly embeds the dynamic graphs into a time-invariant representation space and a time-varying representation space. The time-invariant representation space encapsulates stable properties across the temporal span of dynamic graphs, whereas the time-varying representation space encapsulates time-fluctuating properties. The macro disentanglement on the temporal dependencies facilitates the representations’ performance on downstream tasks. Furthermore, we theoretically prove the sufficiency and macro disentanglement of DDGIB. The sufficiency demonstrates that DDGIB can achieve sufficient representations for any possible downstream tasks, while the macro disentanglement certifies that DDGIB can embed the different temporal properties into their corresponding temporal representation space. Extensive experimental results on various datasets and downstream tasks demonstrate the superiority of our method.},
  archive      = {J_NN},
  author       = {Jihong Wang and Yuxin Bai and Chunqiang Zhu and Hao Qian and Ziqi Liu and Minnan Luo},
  doi          = {10.1016/j.neunet.2025.108056},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108056},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph representation learning with disentangled information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning. <em>NN</em>, <em>194</em>, 108023. (<a href='https://doi.org/10.1016/j.neunet.2025.108023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral diversity emerges as a crucial factor for achieving effective collaboration in Multi-Agent Reinforcement Learning (MARL). Current methods often use partial parameter sharing, such as sharing the same representation layer, to balance behavioral diversity and algorithmic scalability. However, this approach ignores that different agents need different decision knowledge, causing training conflicts and knowledge redundancy. To solve these, we propose Tailoring Knowledge for Empowered Cooperative Actions in Multi-Agent Reinforcement Learning (TKCA). Specially, we employ a set of Knowledge Encoders to encode different environment types of knowledge and utilize a Knowledge Selector network to assist each agent in decision-making by selecting the corresponding knowledge. We evaluated TKCA in challenging StarCraftII micromanagement games and Google Research Football games, and the results demonstrate the superior performance of TKCA.},
  archive      = {J_NN},
  author       = {Hu Fu and Yihua Tan and Hao Chen and Pengyi Li},
  doi          = {10.1016/j.neunet.2025.108023},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108023},
  shortjournal = {Neural Netw.},
  title        = {Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="orl">ORL - 1</h2>
<ul>
<li><details>
<summary>
(2026). Monotone convergence of spreading processes on networks. <em>ORL</em>, <em>64</em>, 107363. (<a href='https://doi.org/10.1016/j.orl.2025.107363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the Bass and SI models for the spreading of innovations and epidemics, respectively, on homogeneous complete networks, on one-dimensional networks, and on heterogeneous two-groups complete networks. We allow the network parameters to be time dependent, which is a prerequisite for the analysis of optimal promotional strategies on networks. Using a novel top-down analysis of the master equations, we present a simple proof for the monotone convergence of these models to their respective infinite-population limits. This leads to explicit expressions for the expected adoption or infection level in the Bass and SI models with time-dependent parameters on infinite homogeneous complete and circular networks, and on heterogeneous two-groups complete networks.},
  archive      = {J_ORL},
  author       = {Gadi Fibich and Amit Golan and Steven Schochet},
  doi          = {10.1016/j.orl.2025.107363},
  journal      = {Operations Research Letters},
  month        = {1},
  pages        = {107363},
  shortjournal = {Oper. Res. Lett.},
  title        = {Monotone convergence of spreading processes on networks},
  volume       = {64},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="parco">PARCO - 5</h2>
<ul>
<li><details>
<summary>
(2025). Software acceleration of multi-user MIMO uplink detection on GPU. <em>PARCO</em>, <em>125</em>, 103150. (<a href='https://doi.org/10.1016/j.parco.2025.103150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the exploration of GPU-accelerated block-wise decompositions for zero-forcing (ZF) based QR and Cholesky methods applied to massive multiple-input multiple-output (MIMO) uplink detection algorithms. Three algorithms are evaluated: ZF with block Cholesky decomposition, ZF with block QR decomposition (QRD), and minimum mean square error (MMSE) with block Cholesky decomposition. The latter was the only one previously explored, but it used standard Cholesky decomposition. Our approach achieves an 11% improvement over the previous GPU-accelerated MMSE study. Through performance analysis, we observe a trade-off between precision and execution time. Reducing precision from FP64 to FP32 improves execution time but increases bit error rate (BER), with ZF-based QRD reducing execution time from 2 . 04 μ s to 1 . 24 μ s for a 128 × 8 MIMO size. The study also highlights that larger MIMO sizes, particularly 2048 × 32, require GPUs to fully utilize their computational and memory capabilities, especially under FP64 precision. In contrast, smaller matrices are compute-bound. Our results recommend GPUs for larger MIMO sizes, as they offer the parallelism and memory resources necessary to efficiently handle the computational demands of next-generation networks. This work paves the way for scalable, GPU-based massive MIMO uplink detection systems.},
  archive      = {J_PARCO},
  author       = {Ali Nada and Hazem Ismail Ali and Liang Liu and Yousra Alkabani},
  doi          = {10.1016/j.parco.2025.103150},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103150},
  shortjournal = {Parallel Comput.},
  title        = {Software acceleration of multi-user MIMO uplink detection on GPU},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enable cross-iteration parallelism for PIM-based graph processing with vertex-level synchronization. <em>PARCO</em>, <em>125</em>, 103149. (<a href='https://doi.org/10.1016/j.parco.2025.103149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing-in-memory (PIM) architectures have emerged as a promising solution for accelerating graph processing by enabling computation in memory and minimizing data movement. However, most existing PIM-based graph processing systems rely on the Bulk Synchronous Parallel (BSP) model, which frequently enforces global barriers that limit cross-iteration computational parallelism and introduce significant synchronization and communication overheads. To address these limitations, we propose the Cross Iteration Parallel (CIP) model, a novel vertex-level synchronization approach that eliminates global barriers by independently tracking the synchronization states of vertices. The CIP model enables concurrent execution across iterations, enhancing computational parallelism, overlapping communication and computation, improving core utilization, and increasing resilience to workload imbalance. We implement the CIP model in a PIM-based graph processing system, GraphDF, which features a few specially designed function units to support vertex-level synchronization. Evaluated on a PyMTL3-based cycle-accurate simulator using four real-world graphs and four graph algorithms, CIP running on GraphDF achieves an average speedup of 1.8 × and a maximum of 2.3 × compared to Dalorex, the state-of-the-art PIM-based graph processing system.},
  archive      = {J_PARCO},
  author       = {Xiang Zhao and Haitao Du and Yi Kang},
  doi          = {10.1016/j.parco.2025.103149},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103149},
  shortjournal = {Parallel Comput.},
  title        = {Enable cross-iteration parallelism for PIM-based graph processing with vertex-level synchronization},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-workflow fault-tolerance scheduling strategy considering resources supply delay in WaaS platforms. <em>PARCO</em>, <em>125</em>, 103148. (<a href='https://doi.org/10.1016/j.parco.2025.103148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workflow as a Service (WaaS) platforms rent virtual machines (VMs) from IaaS providers to run scientific workflows for users. However, current researches on workflow scheduling in WaaS platforms did not consider the possibility of VMs downtime leading to task failures or the resources (such as VMs and containers) supply delay affecting scheduling efficiency. To address this issue, this paper proposes a multi-workflow fault-tolerance scheduling strategy for WaaS platforms. Firstly, since WaaS platforms do not manage hardware directly but schedule workflows at the level of VMs and containers, we establish a workflow scheduling model suitable for WaaS platforms, taking into account the impact of resources supply delay on workflow scheduling. Secondly, we propose a multi-workflow fault-tolerance scheduling strategy for WaaS platforms, which includes preprocessing, fault-tolerance selection, task assignment, and resource adjustment. It involves an improved deadline division algorithm to determine the scheduling order, a fault-tolerance selection algorithm combining two fault-tolerance strategies (replication and re-submission), task assignment algorithm considering task attributes and resource supply delay to schedule tasks, and a resource adjustment algorithm to pre-deploy resources for upcoming tasks. Finally, we compare the proposed scheduling strategy with three other algorithms, and the results also demonstrate its effectiveness.},
  archive      = {J_PARCO},
  author       = {Hui Zhao and Wentao Zhi and Xiaoqin Lu and Jing Wang and Nan Luo and Bo Wan and Quan Wang},
  doi          = {10.1016/j.parco.2025.103148},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103148},
  shortjournal = {Parallel Comput.},
  title        = {Multi-workflow fault-tolerance scheduling strategy considering resources supply delay in WaaS platforms},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALBBA: An efficient ALgebraic bypass BFS algorithm on long vector architectures. <em>PARCO</em>, <em>125</em>, 103147. (<a href='https://doi.org/10.1016/j.parco.2025.103147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breadth First Search (BFS) is a fundamental algorithm in scientific computing, databases, and network analysis applications. In the algebraic BFS paradigm, each BFS iteration is expressed as a sparse matrix–vector multiplication, allowing BFS to be accelerated and analyzed through well-established linear algebra primitives. Although much effort has been made to optimize algebraic BFS on parallel platforms such as CPUs, GPUs, and distributed memory systems, vector architectures that exploit Single Instruction Multiple Data (SIMD) parallelism, particularly with their high performance on sparse workloads, remain relatively underexplored for BFS. In this paper, we propose the ALgebraic Bypass BFS Algorithm (ALBBA), a novel and efficient algebraic BFS implementation optimized for long vector architectures. ALBBA utilizes a customized variant of the SELL- C - σ data structure to fully exploit the SIMD capabilities. By integrating a vectorization-friendly search method alongside a two-level bypass strategy, we enhance both sparse matrix-sparse vector multiplication (SpMSpV) and sparse matrix-dense vector multiplication (SpMV) algorithms, which are crucial for algebraic BFS operations. We further incorporate merge primitives and adopt an efficient selection method for each BFS iteration. Our experiments on an NEC VE20B processor demonstrate that ALBBA achieves average speedups of 3.91 × , 2.88 × , and 1.46 × over Enterprise, GraphBLAST, and Gunrock running on an NVIDIA H100 GPU, respectively.},
  archive      = {J_PARCO},
  author       = {Yuyao Niu and Marc Casas},
  doi          = {10.1016/j.parco.2025.103147},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103147},
  shortjournal = {Parallel Comput.},
  title        = {ALBBA: An efficient ALgebraic bypass BFS algorithm on long vector architectures},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using java to create and analyze models of parallel computing systems. <em>PARCO</em>, <em>125</em>, 103146. (<a href='https://doi.org/10.1016/j.parco.2025.103146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the study is to develop optimal solutions for models of parallel computing systems using the Java language. During the study, programs were written for the examined models of parallel computing systems. The result of the parallel sorting code is the output of a sorted array of random numbers. When processing data in parallel, the time spent on processing and the first elements of the list of squared numbers are displayed. When processing requests asynchronously, processing completion messages are displayed for each task with a slight delay. The main results include the development of optimization methods for algorithms and processes, such as the division of tasks into subtasks, the use of non-blocking algorithms, effective memory management, and load balancing, as well as the construction of diagrams and comparison of these methods by characteristics, including descriptions, implementation examples, and advantages. In addition, various specialized libraries were analyzed to improve the performance and scalability of the models. The results of the work performed showed a substantial improvement in response time, bandwidth, and resource efficiency in parallel computing systems. Scalability and load analysis assessments were conducted, demonstrating how the system responds to an increase in data volume or the number of threads. Profiling tools were used to analyze performance in detail and identify bottlenecks in models, which improved the architecture and implementation of parallel computing systems. The obtained results emphasize the importance of choosing the right methods and tools for optimizing parallel computing systems, which can substantially improve their performance and efficiency.},
  archive      = {J_PARCO},
  author       = {Harish Padmanaban and Nurkasym Arkabaev and Maher Ali Rusho and Vladyslav Kozub and Yurii Kozub},
  doi          = {10.1016/j.parco.2025.103146},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103146},
  shortjournal = {Parallel Comput.},
  title        = {Using java to create and analyze models of parallel computing systems},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="pr">PR - 110</h2>
<ul>
<li><details>
<summary>
(2026). Condense loss: Exploiting vector magnitude during person re-identification training process. <em>PR</em>, <em>172</em>, 112443. (<a href='https://doi.org/10.1016/j.patcog.2025.112443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The magnitudes of features and weights significantly affect the gradients during the training process. L2 normalized softmax losses (such as NormFace, CosFace, ArcFace, etc.) and Naive softmax losses both reduce the magnitudes of image features in the training process and achieve good results in face recognition and person re-identification tasks, respectively. In this paper, we fully utilize the feature vector magnitudes and propose Condense loss for Re-ID tasks, which replaces the inner production of Naive softmax loss with the negative Euclidean distance. Condense loss generates negative radial gradients when updating weight parameters to push all features compacter. Because the coefficients of tangential gradients (the tangential component of the gradients) are related to feature magnitudes, it ideally provides monotonically decreasing tangential gradients, resulting in gradually diminishing updates that enhance the stability of the training process. We also introduce a margin parameter into Condense loss to enlarge inter-class distances and thus help the model learn more discriminative features. Mathematical analysis is given in this paper, and we have conducted sufficient experiments focusing on Re-ID tasks to prove the corresponding conclusion. The experimental results demonstrate that the Condense loss achieves competitive results compared to the state-of-the-art methods in the person re-identification task. At the same time, it also has a good performance in face recognition tasks.},
  archive      = {J_PR},
  author       = {Xi Yang and Wenjiao Dong and Yingzhi Tang and Gu Zheng and Nannan Wang and Xinbo Gao},
  doi          = {10.1016/j.patcog.2025.112443},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112443},
  shortjournal = {Pattern Recognition},
  title        = {Condense loss: Exploiting vector magnitude during person re-identification training process},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Buffer-free class-incremental learning with out-of-distribution detection. <em>PR</em>, <em>172</em>, 112441. (<a href='https://doi.org/10.1016/j.patcog.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-incremental learning (CIL) poses significant challenges in open-world scenarios, where models must learn new classes over time without forgetting previous ones and handle inputs from unknown classes that a closed-set model would misclassify. In this paper, we present an in-depth analysis of post-hoc OOD detection methods and investigate their potential to eliminate the need for a memory buffer. When post hoc OOD detection is applied at inference time, we discover that it can effectively replace buffer-based strategies. We examine the performance of these methods in terms of classification accuracy of seen samples and rejection rates of unseen samples. We show that our approach achieves competitive performance compared to recent multi-head and single-head methods that rely on memory buffers and other buffer-free approaches. The results show that the proposed approach outperforms them in a closed-world setting and detects unseen samples while being significantly resource-efficient. Experimental results on CIFAR-10, CIFAR-100, and Tiny ImageNet support our findings and offer new insights into the design of efficient and privacy-preserving CIL systems for open-world settings.},
  archive      = {J_PR},
  author       = {Srishti Gupta and Daniele Angioni and Maura Pintor and Ambra Demontis and Lea Schönherr and Fabio Roli and Battista Biggio},
  doi          = {10.1016/j.patcog.2025.112441},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112441},
  shortjournal = {Pattern Recognition},
  title        = {Buffer-free class-incremental learning with out-of-distribution detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction” [Pattern recognition 172 (2026) 112339]. <em>PR</em>, <em>172</em>, 112440. (<a href='https://doi.org/10.1016/j.patcog.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PR},
  author       = {Chengcheng Li and Luqi Gong and Leiheng Xu and Xin Wang},
  doi          = {10.1016/j.patcog.2025.112440},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112440},
  shortjournal = {Pattern Recognition},
  title        = {Corrigendum to “DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction” [Pattern recognition 172 (2026) 112339]},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A progressive attention network with transformer for multi-label image recognition. <em>PR</em>, <em>172</em>, 112439. (<a href='https://doi.org/10.1016/j.patcog.2025.112439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research typically improves the performance of multi-label image recognition by constructing higher-order pairwise label correlations. However, these methods lack the ability to effectively learn multi-scale features, which makes it difficult to distinguish small-scale objects. Moreover, most current attention-based methods to capture local salient features may ignore many useful non-salient features. To address the aforementioned issues, we propose a Transformer-based Progressive Attention Network (TPANet) for multi-label image recognition. Specifically, we first design a new adaptive multi-scale feature attention (AMSA) module to learn cross-scale features in multi-level features. Then, to excavate various useful object features, we introduce the transformer encoder to construct a semantic spatial attention (ESA) module and also propose a context-aware feature enhanced (CAFE) module. The former ESA module is used to discover complete object regions and capture discriminative features, and the latter CAFE module leverages object-local features to enhance pixel-level global features. The proposed TPANet model can generate more accurate object labels in three popular benchmark datasets (i.e., MS-COCO 2014, Pascal VOC 2007 and Visual Genome), and is competitive to state-of-the-art models (e.g., SST and FL-Tran, etc.).},
  archive      = {J_PR},
  author       = {Sulan Zhang and Zhenwen Liao and Jianeng Li and Lihua Hu and Jifu Zhang},
  doi          = {10.1016/j.patcog.2025.112439},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112439},
  shortjournal = {Pattern Recognition},
  title        = {A progressive attention network with transformer for multi-label image recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Layer-wise correlation and attention discrepancy distillation for semantic segmentation. <em>PR</em>, <em>172</em>, 112438. (<a href='https://doi.org/10.1016/j.patcog.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) has recently garnered increased attention in segmentation tasks due to its effective balance between accuracy and computational efficiency. Nonetheless, existing methods mainly rely on structured knowledge from a single layer, overlooking the valuable discrepant knowledge that captures the diversity and distinctiveness of features across various layers, which is essential for the KD process. We present Layer-wise Correlation and Attention Discrepancy Distillation (LCADD) to tackle this issue, training compact and accurate semantic segmentation networks by considering layer-wise discrepancy knowledge. Specifically, we employ two distillation schemes: (i) correlation discrepancy distillation, which constructs a pixel-wise correlation discrepancy matrix across various layers to seize more detailed spatial dependencies, and (ii) attention discrepancy self-distillation, which aims to guide the shallower layers of the student network to emulate the attention discrepancy maps of the deeper layers, facilitating self-learning of attention discrepancy knowledge within the student network. Each proposed method is designed to work collaboratively in learning discrepancy knowledge, allowing the student network to better imitate the teacher from the perspective of layer-wise discrepancy. Our method has demonstrated superior performance on various semantic segmentation datasets, including Cityscapes, Pascal VOC 2012, and CamVid, compared to the latest knowledge distillation techniques, thereby validating its effectiveness.},
  archive      = {J_PR},
  author       = {Jianping Gou and Kaijie Chen and Cheng Chen and Weihua Ou and Xin Luo and Zhang Yi},
  doi          = {10.1016/j.patcog.2025.112438},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112438},
  shortjournal = {Pattern Recognition},
  title        = {Layer-wise correlation and attention discrepancy distillation for semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gradient semi-masking for improving adversarial robustness. <em>PR</em>, <em>172</em>, 112433. (<a href='https://doi.org/10.1016/j.patcog.2025.112433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In gradient masking, certain complex signal processing and probabilistic optimization strategies exhibit favorable characteristics such as nonlinearity, irreversibility, and feature preservation, thereby providing new solutions for adversarial defense. Inspired by this, this paper proposes a plug-and-play gradient semi-masking module ( GSeM ) to improve the adversarial robustness of neural networks. GSeM primarily contains a feature straight-through pathway that allows for normal gradient propagation and a feature mapping pathway that interrupts gradient flow. The multi-pathway and semi-masking characteristics cause GSeM to exhibit opposing behaviors when processing data and gradients. Specifically, during data processing, GSeM compresses the state space of features while introducing white noise augmentation. However, during gradient processing, it leads to inefficient updates to certain parameters and ineffective generation of training examples. To address this shortcoming, we correct gradient propagation and introduce gradient-corrected adversarial training. Extensive experiments demonstrate that GSeM differs fundamentally from earlier gradient masking methods: it can genuinely enhance the adversarial defense performance of neural networks, surpassing previous state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Xinlei Liu and Tao Hu and Peng Yi and Baolin Li and Jichao Xie and Hailong Ma},
  doi          = {10.1016/j.patcog.2025.112433},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112433},
  shortjournal = {Pattern Recognition},
  title        = {Gradient semi-masking for improving adversarial robustness},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Structural-prior guided bi-generative network for image inpainting. <em>PR</em>, <em>172</em>, 112432. (<a href='https://doi.org/10.1016/j.patcog.2025.112432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting is a great challenge when reconstructed with realistic textures and required to enhance the consistency of semantic structures in large-scale missing regions. However, popular structural prior guidance methods primarily rely on the reconstruction of structural features. Due to the Markovian property inherent in purely feedforward architectures, noise undergoes persistent accumulation and propagation in early network layers. Without intermediate feedback mechanisms, minor artifacts in shallow layers would be nonlinearly amplified through successive convolution operations and cannot be timely corrected, thereby hindering the extraction of valid structural information. To this end, we presents a bi-generative network (Bi-GNet) guided by specific semantic structures, including an auxiliary network N s and an inpainting network N inp . Here N s provides the structural prior information to N inp for reconstructing the texture details of images. Additionally, we provide the spatial coordinate attention (SCA) and the adaptive feature filtering (AFF) module to ensure structural consistency and texture plausibility in the reconstructed content. Experiments demonstrate that Bi-GNet significantly outperforms other state-of-the-art approaches on three datasets and achieves good inpainting results on the Mogao Grottoes mural dataset.},
  archive      = {J_PR},
  author       = {Jiajun Zhang and Jizhao Liu and Huaikun Zhang and Jibao Zhang and Jing Lian},
  doi          = {10.1016/j.patcog.2025.112432},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112432},
  shortjournal = {Pattern Recognition},
  title        = {Structural-prior guided bi-generative network for image inpainting},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning from majority label: A novel problem in multi-class multiple-instance learning. <em>PR</em>, <em>172</em>, 112425. (<a href='https://doi.org/10.1016/j.patcog.2025.112425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a novel multi-class Multiple-Instance Learning (MIL) problem called Learning from Majority Label (LML). In LML, the majority class of instances in a bag is assigned as the bag-level label. The goal of LML is to train a classification model that estimates the class of each instance using the majority label. This problem is valuable in a variety of applications, including pathology image segmentation, political voting prediction, customer sentiment analysis, and environmental monitoring. To solve LML, we propose a Counting Network trained to produce bag-level majority labels, estimated by counting the number of instances in each class. Furthermore, analysis experiments on the characteristics of LML revealed that bags with a high proportion of the majority class facilitate learning. Based on this result, we developed a Majority Proportion Enhancement Module (MPEM) that increases the proportion of the majority class by removing minority class instances within the bags. Experiments demonstrate the superiority of the proposed method on four datasets compared to conventional MIL methods. Moreover, ablation studies confirmed the effectiveness of each module. The code is available at here .},
  archive      = {J_PR},
  author       = {Kaito Shiku and Shinnosuke Matsuo and Daiki Suehiro and Ryoma Bise},
  doi          = {10.1016/j.patcog.2025.112425},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112425},
  shortjournal = {Pattern Recognition},
  title        = {Learning from majority label: A novel problem in multi-class multiple-instance learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Feature subset weighting for distance-based supervised learning. <em>PR</em>, <em>172</em>, 112424. (<a href='https://doi.org/10.1016/j.patcog.2025.112424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces feature subset weighting using monotone measures for distance-based supervised learning. The Choquet integral is used to define a distance function that incorporates these weights. This integration enables the proposed distances to effectively capture non-linear relationships and account for interactions both between conditional and decision attributes and among conditional attributes themselves, resulting in a more flexible distance measure. In particular, we show how this approach ensures that the distances remain unaffected by the addition of duplicate and strongly correlated features. Another key point of this approach is that it makes feature subset weighting computationally feasible, since only m feature subset weights should be calculated each time instead of calculating all feature subset weights ( 2 m ), where m is the number of attributes. Next, we also examine how the use of the Choquet integral for measuring similarity leads to a non-equivalent definition of distance. The relationship between distance and similarity is further explored through dual measures. Additionally, symmetric Choquet distances and similarities are proposed, preserving the classical symmetry between similarity and distance. Finally, we introduce a concrete feature subset weighting distance, evaluate its performance in a k -nearest neighbours (KNN) classification setting, and compare it against Mahalanobis distances and weighted distance methods.},
  archive      = {J_PR},
  author       = {Adnan Theerens and Yvan Saeys and Chris Cornelis},
  doi          = {10.1016/j.patcog.2025.112424},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112424},
  shortjournal = {Pattern Recognition},
  title        = {Feature subset weighting for distance-based supervised learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive integration of textual context and visual embeddings for underrepresented vision classification. <em>PR</em>, <em>172</em>, 112420. (<a href='https://doi.org/10.1016/j.patcog.2025.112420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of deep learning has significantly improved image classification performance; however, handling long-tail distributions remains challenging due to the limited data available for rare classes. Existing approaches predominantly focus on visual features, often neglecting the valuable contextual information provided by textual data, which can be especially beneficial for classes with sparse visual examples. In this work, we introduce a novel method addressing this limitation by integrating textual data generated by advanced language models with visual inputs through our newly proposed Adaptive Integration Block for Vision-Text Synergy (AIB-VTS). Specifically designed for Vision Transformer architectures, AIB-VTS adaptively balances visual and textual information during inference, effectively utilizing textual descriptions generated from large language models. Extensive experiments on benchmark datasets demonstrate substantial performance improvements across all class groups, particularly in underrepresented (tail) classes. These results confirm the effectiveness of our approach in leveraging textual context to mitigate data scarcity issues and enhance model robustness.},
  archive      = {J_PR},
  author       = {Seongyeop Kim and Hyung-Il Kim and Yong Man Ro},
  doi          = {10.1016/j.patcog.2025.112420},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112420},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive integration of textual context and visual embeddings for underrepresented vision classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PCFFusion: Progressive cross-modal feature fusion network for infrared and visible images. <em>PR</em>, <em>172</em>, 112419. (<a href='https://doi.org/10.1016/j.patcog.2025.112419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) aims to fuse thermal target information in infrared images and spatial texture information in visible images, improving the observability and comprehensibility of the fused images. Currently, most IVIF methods suffer from the loss of salient target information and texture details in fused images. To alleviate this problem, a progressive cross-modal feature fusion network (PCFFusion) for IVIF is proposed, which comprises two stages: feature extraction and feature fusion. In the feature extraction stage, to enhance the network’s feature representation capability, a feature decomposition module (FDM) is constructed to extract two modal features of different scales by defining a feature decomposition operation (FDO). In addition, by establishing correlations between the high- frequency and low-frequency components of two modal features, a cross-modal feature enhancement module (CMFEM) is built to realize correction and enhancement of the two features at each scale. The feature fusion stage achieves the fusion of two modal features at each scale and the supplementation of adjacent scale features by constructing three cross-domain fusion module (CDFMs). To constrain the fused results preserve more salient targets and richer texture details, a dual-feature fidelity loss function is defined by constructing a salient weight map to balance the two loss terms. Extensive experiments demonstrate that fusion results of the proposed method highlight prominent targets from infrared images while retaining rich background details from visible images, and the performance of PCFFusion is superior to some advanced methods. Specifically, compared to the optimal results obtained by other comparison methods, the proposed network achieves an average increase of 30.35 % and 10.9 % in metrics Mutual Information (MI) and Standard deviation (SD) on the TNO dataset, respectively.},
  archive      = {J_PR},
  author       = {Shuying Huang and Kai Zhang and Yong Yang and Weiguo Wan},
  doi          = {10.1016/j.patcog.2025.112419},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112419},
  shortjournal = {Pattern Recognition},
  title        = {PCFFusion: Progressive cross-modal feature fusion network for infrared and visible images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time series adaptive mode decomposition (TAMD): Method for improving forecasting accuracy in the apparel industry. <em>PR</em>, <em>172</em>, 112417. (<a href='https://doi.org/10.1016/j.patcog.2025.112417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of apparel sales is critical for inventory management, supply chain optimization, and market strategy planning. However, existing forecasting models often struggle to effectively capture the complex characteristics of apparel sales data, such as distinct seasonality, cyclicality, and strongly nonlinear fluctuations, which significantly hinder prediction accuracy and generalization ability. To address these challenges, this study introduces a novel Time series Adaptive Mode Decomposition (TAMD)-based forecasting algorithm. The proposed method: (1) employs Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and sample entropy-guided Variational Mode Decomposition (VMD) to separate the input time series into noise components and multiple smooth Intrinsic Mode Functions (IMFs), to better capture intrinsic data dynamics; (2) refines the sub-series distribution features via an adaptive module guided by sample entropy, dividing each sub-series into subsequences with maximal distribution difference to improve adaptability to periodic changes and market volatility; (3) predicts each subsequence with adaptive distribution matching based on discontinuous random subsequence combinations, and then linearly superposes the prediction results as a final output, thereby boosting accuracy and generalizability. Comprehensive experiments on both public and self-constructed datasets (including four years of Taobao sales data for dresses, jeans, sweatshirts, and sweaters, totaling over 44.7 million records) demonstrate that TAMD outperforms existing methods significantly, highlighting its effectiveness in revealing the complexity of apparel market data and enhancing prediction performance.},
  archive      = {J_PR},
  author       = {Guangbao Zhou and Pengliang Liu and Quanle Lin and Miao Qian and Zhong Xiang and Zeyu Zheng and Lixian Liu},
  doi          = {10.1016/j.patcog.2025.112417},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112417},
  shortjournal = {Pattern Recognition},
  title        = {Time series adaptive mode decomposition (TAMD): Method for improving forecasting accuracy in the apparel industry},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A framework for bias-aware dataset evaluation in soft facial attribute recognition. <em>PR</em>, <em>172</em>, 112416. (<a href='https://doi.org/10.1016/j.patcog.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft Facial Attribute Recognition (FAR) remains largely unexplored in terms of demographic fairness. To the best of our knowledge, this study presents one of the first comprehensive analyses of demographic bias in FAR, proposing a systematic framework to detect, quantify, and promote awareness of both representational and stereotypical biases, supporting their mitigation. Leveraging established taxonomies, we evaluate state-of-the-art datasets using a rigorous set of interpretable bias metrics to uncover hidden demographic imbalances. To support reliable fairness assessment, we first enrich the datasets with standardized demographic annotations using the FairFace model. We then address label inconsistencies through the integration of predictions from advanced Vision-Language Models (VLMs). Our analysis reveals substantial imbalances across gender, age, and racial categories-specifically White, Black, and Asian- affecting dataset composition. Furthermore, we show that conventional fairness metrics often yield divergent assessments, highlighting the importance of multi-metric evaluation. This study provides a replicable methodology and actionable insights to support bias-aware facial analysis.},
  archive      = {J_PR},
  author       = {Lucia Cascone and Michele Nappi and Chiara Pero and Xinggang Wang},
  doi          = {10.1016/j.patcog.2025.112416},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112416},
  shortjournal = {Pattern Recognition},
  title        = {A framework for bias-aware dataset evaluation in soft facial attribute recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fast multi-view discrete clustering with two solvers. <em>PR</em>, <em>172</em>, 112415. (<a href='https://doi.org/10.1016/j.patcog.2025.112415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view graph clustering follows a three-phase process: constructing view-specific similarity graphs, fusing information from different views, and conducting eigenvalue decomposition followed by post-processing to obtain the clustering indicators. However, it encounters two key challenges: the high computational cost of graph construction and eigenvalue decomposition, and the inevitable information deviation introduced by the last process. To tackle these obstacles, we propose Fast Multi-view Discrete Clustering with two solvers (FMDC), to directly and efficiently solve the multi-view graph clustering problem. FMDC involves: (1) generating a compact set of representative anchors to construct anchor graphs, (2) automatically weighting them into a symmetric and doubly stochastic aggregated similarity matrix, (3) executing clustering on the aggregated form with the discrete indicator matrix directly computed through two efficient solvers that we devised. The linear computational complexity of FMDC w.r.t. data size is a notable improvement over traditional quadratic or cubic complexity. Extensive experiments confirm the superior performance of FMDC both in efficiency and in effectiveness.},
  archive      = {J_PR},
  author       = {Qianyao Qiang and Bin Zhang and Jason Chen Zhang and Feiping Nie},
  doi          = {10.1016/j.patcog.2025.112415},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112415},
  shortjournal = {Pattern Recognition},
  title        = {Fast multi-view discrete clustering with two solvers},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asymmetric simulation-enhanced flow reconstruction for incomplete multimodal learning. <em>PR</em>, <em>172</em>, 112413. (<a href='https://doi.org/10.1016/j.patcog.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multimodal learning addresses the common real-world challenge of missing modalities, which undermines the performance of standard multimodal methods. Existing solutions struggle with distribution mismatches between reconstructed and observed data, asymmetric cross-modal structures, and insufficient cross-modal knowledge sharing. To tackle these issues, we propose an asymmetric simulation-enhanced flow reconstruction (ASE-FR) framework, which contains following contributions: (1) Distribution-consistent flow reconstruction module that align available and missing modality distributions by normalizing flows; (2) Asymmetric simulation module that perturbs and randomly masks features to mimic real-world modality absence and improve robustness; (3) Modal-shared knowledge distillation that transfers shared representations from teacher encoders to a student encoder through contrastive learning. This framework is applicable to a range of real-world scenarios, such as multi-sensor networks in smart manufacturing, medical diagnostic systems combining imaging and electronic health records, and autonomous driving platforms that integrate camera and LiDAR data. The experimental results show that our ASE-FR method achieves 94.71 %, 41.85 % and 81.90 % accuracy on Audiovision-MNIST, MM-IMDb and IEMOCAP datasets, as well as 1.1376 error rate on CMU-MOSI dataset, which exhibits competitive performance.},
  archive      = {J_PR},
  author       = {Jiacheng Yao and Jing Zhang and Yixiao Wang and Li Zhuo},
  doi          = {10.1016/j.patcog.2025.112413},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112413},
  shortjournal = {Pattern Recognition},
  title        = {Asymmetric simulation-enhanced flow reconstruction for incomplete multimodal learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Benchmarking the spatial robustness of DNNs via natural and adversarial localized corruptions. <em>PR</em>, <em>172</em>, 112412. (<a href='https://doi.org/10.1016/j.patcog.2025.112412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robustness of deep neural networks is a crucial factor in safety-critical applications, particularly in complex and dynamic environments (e.g., medical or driving scenarios) where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remained underexplored. This paper fills this gap by introducing novel, region-aware metrics for benchmarking the spatial robustness of segmentation models, along with an evaluation framework to assess the impact of natural localized corruptions. Furthermore, it uncovers the inherent complexity of evaluating worst-case spatial robustness using only a single localized adversarial attack. To address this, the work proposes a region-aware multi-attack adversarial analysis to systematically assess model robustness across specific image regions. The proposed metrics and analysis were exploited to evaluate 14 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones, and vice versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.},
  archive      = {J_PR},
  author       = {Giulia Marchiori Pietrosanti and Giulio Rossolini and Alessandro Biondi and Giorgio Buttazzo},
  doi          = {10.1016/j.patcog.2025.112412},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112412},
  shortjournal = {Pattern Recognition},
  title        = {Benchmarking the spatial robustness of DNNs via natural and adversarial localized corruptions},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preserving privacy without compromising accuracy: Machine unlearning for handwritten text recognition. <em>PR</em>, <em>172</em>, 112411. (<a href='https://doi.org/10.1016/j.patcog.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten Text Recognition (HTR) is crucial for document digitization, but handwritten data can contain user-identifiable features, like unique writing styles, posing privacy risks. Regulations such as the “right to be forgotten” require models to remove these sensitive traces without full retraining. We introduce a practical encoder-only transformer baseline as a robust reference for future HTR research. Building on this, we propose a two-stage unlearning framework for multihead transformer HTR models. Our method combines neural pruning with machine unlearning applied to a writer classification head, ensuring sensitive information is removed while preserving the recognition head. We also present Writer-ID Confusion (WIC), a method that forces the forget set to follow a uniform distribution over writer identities, unlearning user-specific cues while maintaining text recognition performance. We compare WIC to Random Labeling, Fisher Forgetting, Amnesiac Unlearning, and DELETE within our prune-unlearn pipeline and consistently achieve better privacy and accuracy trade-offs. This is the first systematic study of machine unlearning for HTR. Using metrics such as Accuracy, Character Error Rate (CER), Word Error Rate (WER), and Membership Inference Attacks (MIA) on the IAM and CVL datasets, we demonstrate that our method achieves state-of-the-art or superior performance for effective unlearning. These experiments show that our approach effectively safeguards privacy without compromising accuracy, opening new directions for document analysis research. Our code is publicly available at https://github.com/leitro/WIC-WriterIDConfusion-MachineUnlearning .},
  archive      = {J_PR},
  author       = {Lei Kang and Xuanshuo Fu and Lluis Gomez and Alicia Fornés and Ernest Valveny and Dimosthenis Karatzas},
  doi          = {10.1016/j.patcog.2025.112411},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112411},
  shortjournal = {Pattern Recognition},
  title        = {Preserving privacy without compromising accuracy: Machine unlearning for handwritten text recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated automatic latent variable selection in multi-output gaussian processes. <em>PR</em>, <em>172</em>, 112410. (<a href='https://doi.org/10.1016/j.patcog.2025.112410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a federated learning approach that automatically selects the number of latent processes in multi-output Gaussian processes (MGPs). The MGP has seen great success as a transfer learning tool when data is generated from multiple sources/units/entities. A common approach in MGPs to transfer knowledge across units involves gathering all data from each unit to a central server and extracting common independent latent processes to express each unit as a linear combination of the shared latent patterns. However, this approach poses key challenges in (i) determining the adequate number of latent processes and (ii) relying on centralized learning which leads to potential privacy risks and significant computational burdens on the central server. To address these issues, we propose a hierarchical model that places spike-and-slab priors on the coefficients of each latent process. These priors help automatically select only needed latent processes by shrinking the coefficients of unnecessary ones to zero. To estimate the model while avoiding the drawbacks of centralized learning, we propose a variational inference-based approach, that formulates model inference as an optimization problem compatible with federated settings. We then design a federated learning algorithm that allows units to jointly select and infer the common latent processes without sharing their data. We also discuss an efficient learning approach for a new unit within our proposed federated framework. Simulation and case studies on Li-ion battery degradation and air temperature data demonstrate the advantageous features of our proposed approach.},
  archive      = {J_PR},
  author       = {Jingyi Gao and Seokhyun Chung},
  doi          = {10.1016/j.patcog.2025.112410},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112410},
  shortjournal = {Pattern Recognition},
  title        = {Federated automatic latent variable selection in multi-output gaussian processes},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-view consistency clustering via structure-enhanced contrastive learning. <em>PR</em>, <em>172</em>, 112409. (<a href='https://doi.org/10.1016/j.patcog.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current state-of-the-art deep multi-view clustering methods resort to contrastive learning to learn consensus representations with Cross-View Consistency ( CVC ). However, contrastive learning has inherent limitations when being applied to the multi-view clustering. On one hand, contrastive learning suffers from class collision issue, compromising the discriminability of consensus representation. On the other hand, contrastive alignment of two views of different quality could lead to representation degradation for the higher-quality view, weakening the robustness of the consensus representation. To alleviate these issues, this paper presents an Adaptive Multi-view consistency clustering method via structure-enhanced contrastive learning ( A da M ), which learns multi-faceted consensus representation that balances view-consistency, discriminability and robustness, forming an optimal consensus representation. Specifically, we first design a view fusion module and a structural learning module to learn view weights and structural relationships among samples, respectively, to derive the consensus representation. Second, beyond CVC , we propose a novel clustering framework called Adaptive Multi-View Consistency ( AMVC ), which adaptively aligns specific view representation with consensus representation based on the learned view weights. Furthermore, compared to CVC , we theoretically demonstrate the superiority of AMVC in learning robust consensus representation. Third, A da M leverages the structural relationships among samples to refine the conventional contrastive loss, further enhancing the discriminability of the consensus representation. Extensive experimental results on eight datasets demonstrate the superior performance of A da M over eight advanced multi-view clustering baselines.},
  archive      = {J_PR},
  author       = {Xuqian Xue and Qi Cai and Zhanwei Zhang and Yiming Lei and Hongming Shan and Junping Zhang},
  doi          = {10.1016/j.patcog.2025.112409},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112409},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive multi-view consistency clustering via structure-enhanced contrastive learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A text-only weakly supervised learning framework for text spotting via text-to-polygon generator. <em>PR</em>, <em>172</em>, 112408. (<a href='https://doi.org/10.1016/j.patcog.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced text spotting methods typically rely on large-scale, meticulously labeled datasets to achieve satisfactory performance. However, annotating fine-grained positional information of texts in real-world scene images is extremely costly and time-consuming. Although some weakly supervised methods have been developed to reduce annotation costs, they face two major challenges: 1) their performance significantly lags behind the fully supervised counterparts, and 2) They are tightly coupled with specific text spotting models, meaning that switching to a different model would require retraining and incur substantial computational costs. To address these limitations, we propose a novel text-only weakly supervised learning framework for text spotting via text-to-polygon generator. In the first stage, we pretrain a text-to-polygon generator on an auxiliary dataset, e.g., synthetic or public datasets, where full annotations are readily accessible. In the second stage, given real-world target datasets annotated with text-only labels, we employ the pretrained generator to produce pseudo polygon labels, thereby constructing a pseudo-labeled supervised dataset for training text spotting models. To ensure high-quality pseudo polygon labels, the text-to-polygon generator first identifies all candidate text regions, then filters those that are relevant to the target text, and finally predicts their precise spatial locations. Notably, this generator requires only a single pretraining session and can subsequently be applied to any text spotting model and target text-only dataset without incurring additional costs. Extensive experiments on public benchmarks demonstrate that our method can significantly reduce labeling costs while maintaining competitive performance.},
  archive      = {J_PR},
  author       = {Gege Zhang and Zhiyong Gan and Ling Deng and Shuaicheng Niu and Zhenghua Peng and Gang Dai and Shuangping Huang and Xiangmin Xu},
  doi          = {10.1016/j.patcog.2025.112408},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112408},
  shortjournal = {Pattern Recognition},
  title        = {A text-only weakly supervised learning framework for text spotting via text-to-polygon generator},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Leveraging synthetic data for zero–shot and few–shot circle detection in real–world domains. <em>PR</em>, <em>172</em>, 112407. (<a href='https://doi.org/10.1016/j.patcog.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circle detection plays a pivotal role in computer vision, underpinning applications from industrial inspection and bioinformatics to autonomous driving. Traditional methods, however, often struggle with real–world complexities, as they demand extensive parameter tuning and adaptation across different domains. In this paper, we present the Synthetic Circle Dataset (SynCircle), a large synthetic image dataset designed to train a YOLO v10 network for circle detection. The YOLO v10 network, pre–trained solely on synthetic data, demonstrates remarkable off–the–shelf performance that surpasses conventional methods in various practical scenarios. Furthermore, we show that incorporating just a few labeled real images for fine–tuning can significantly boost performance, reducing the need for large annotated datasets. To promote reproducibility and streamline adoption, we publicly release both the trained YOLO v10 weights and the full SynCircle dataset.},
  archive      = {J_PR},
  author       = {Paolo Andreini and Marco Tanfoni and Simone Bonechi and Monica Bianchini},
  doi          = {10.1016/j.patcog.2025.112407},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112407},
  shortjournal = {Pattern Recognition},
  title        = {Leveraging synthetic data for zero–shot and few–shot circle detection in real–world domains},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DURN: Data uncertainty-driven robust network for mural sketch detection. <em>PR</em>, <em>172</em>, 112404. (<a href='https://doi.org/10.1016/j.patcog.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mural sketches reveal both the content and structure of the murals and are crucial for the preservation of murals. However, existing methods lack robustness, making it difficult to suppress noise while preserving sketches on damaged murals and fully capturing details on clear murals. To address this, we propose a Data Uncertainty-Driven Robust Network (DURN) for mural sketch detection. DURN uses uncertainty to quantify noise in the murals, converting prediction into a learnable normal distribution, where the mean represents the sketch and the variance denotes the uncertainty. This enables the model to learn both the sketch and the noise simultaneously, achieving noise suppression while preserving the sketches. To enhance sketches, we design an Adaptive Fusion Feature Enhancement Module (AFFE) to dynamically adjust the fusion strategy according to the contribution of features at different scales and reduce the information loss caused by feature dimensionality reduction to maximize the utility of each feature. We develop a novel Deep-Shallow Supervision (DSS) module to mitigate background noise using deep semantic information to guide shallow features without adding parameters. Additionally, we achieve model lightweighting through pruning techniques, ensuring competitive performance while reducing the number of parameters to only 4.5 % of the original. The experimental results show an improvement of 10. 4 % AP over existing methods, demonstrating the robustness of DURN for complex and damaged murals. The source code is available at https://github.com/TIVEN-Z/DURN .},
  archive      = {J_PR},
  author       = {Shenglin Peng and Xingguo Zhao and Jun Wang and Lin Wang and Shuyi Qu and Jingye Peng and Xianlin Peng},
  doi          = {10.1016/j.patcog.2025.112404},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112404},
  shortjournal = {Pattern Recognition},
  title        = {DURN: Data uncertainty-driven robust network for mural sketch detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learn depth space from light field via a distance-constraint query mechanism. <em>PR</em>, <em>172</em>, 112403. (<a href='https://doi.org/10.1016/j.patcog.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Light Field (LF) captures both spatial and angular information of scenes, enabling precise depth estimation. Recent advancements in deep learning have led to significant success in this field; however, existing methods primarily focus on modeling surface characteristics (e.g., depth maps) while overlooking the depth space, which contains additional valuable information. The depth space consists of numerous space points and provides substantially more geometric data than a single depth map. In this paper, we conceptualize depth prediction as a spatial modeling problem, aiming to learn the entire depth space rather than merely a single depth map. Specifically, we define space points as signed distances relative to the scene surface and propose a novel distance-constraint query mechanism for LF depth estimation. To model the depth space effectively, we first develop a mixed sampling strategy to approximate its data representation. Subsequently, we introduce an encoder-decoder network architecture to query the distances of each point, thereby implicitly embedding the depth space. Finally, to extract the target depth map from this space, we present a generation algorithm that iteratively invokes the decoder network. Through extensive experiments, our approach achieves the highest performance on LF depth estimation benchmarks, and also demonstrates superior performance on various synthetic and real-world scenes.},
  archive      = {J_PR},
  author       = {Hao Sheng and Rongshan Chen and Ruixuan Cong and Da Yang and Zhenglong Cui and Sizhe Wang},
  doi          = {10.1016/j.patcog.2025.112403},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112403},
  shortjournal = {Pattern Recognition},
  title        = {Learn depth space from light field via a distance-constraint query mechanism},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised instance segmentation with superpixels. <em>PR</em>, <em>172</em>, 112402. (<a href='https://doi.org/10.1016/j.patcog.2025.112402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation is essential for numerous computer vision applications, including robotics, human-computer interaction, and autonomous driving. Currently, popular models bring impressive performance in instance segmentation by training with a large number of human annotations, which are costly to collect. For this reason, we present a new framework that efficiently and effectively segments objects without the need for human annotations. Firstly, a MultiCut algorithm is applied to self-supervised features for coarse mask segmentation. Then, a mask filter is employed to obtain high-quality coarse masks. To train the segmentation network, we compute a novel superpixel-guided mask loss, comprising hard loss and soft loss, with high-quality coarse masks and superpixels segmented from low-level image features. Lastly, a self-training process with a new adaptive loss is proposed to improve the quality of predicted masks. We conduct experiments on public datasets in instance segmentation and object detection to demonstrate the effectiveness of the proposed framework. The results show that the proposed framework outperforms previous state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Cuong Manh Hoang},
  doi          = {10.1016/j.patcog.2025.112402},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112402},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised instance segmentation with superpixels},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MIGF-net: Multimodal interaction-guided fusion network for image aesthetics assessment. <em>PR</em>, <em>172</em>, 112401. (<a href='https://doi.org/10.1016/j.patcog.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of social media, people like to post images and comments to share their ideas, which provides rich visual and textural semantic information for image aesthetics assessment (IAA). However, most previous works either extracted the unimodal aesthetic features from image due to the difficulty of obtaining comments, or combined multimodal information together but ignoring the interactive relationship between image and comment, which limits the overall performance. To solve the above problem, we propose a Multimodal Interaction-Guided Fusion Network (MIGF-Net) for image aesthetics assessment based on both image and comment semantic information, which can not only solve the challenge of comment generating, but also provide the multimodal feature interactive information. Specifically, considering the coupling mechanism of the image theme, we construct a visual semantic fusion module to extract the visual semantic feature based on the visual attributes and the theme features. Then, a textural semantic feature extractor is designed to mine the semantic information hidden in comments, which not only addresses the issue of missing comments but also effectively complements the visual semantic features. Furthermore, we establish a Dual-Stream Interaction-Guided Fusion module to fuse the semantic features of images and comments, fully exploring the interactive relationship between images and comments in the human brain’s perception mechanism. Experimental results on two public image aesthetics evaluation datasets demonstrate that our model outperforms the current state-of-the-art methods. Our code will be released at https://github.com/wenzhipeng123/MIGF-Net .},
  archive      = {J_PR},
  author       = {Yun Liu and Zhipeng Wen and Leida Li and Peiguang Jing and Daoxin Fan},
  doi          = {10.1016/j.patcog.2025.112401},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112401},
  shortjournal = {Pattern Recognition},
  title        = {MIGF-net: Multimodal interaction-guided fusion network for image aesthetics assessment},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IRIS: An information path planning method based on reinforcement learning and information-directed sampling. <em>PR</em>, <em>172</em>, 112400. (<a href='https://doi.org/10.1016/j.patcog.2025.112400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information Path Planning (IPP) is a critical aspect of robotics, aimed at intelligently selecting information-rich paths to optimize robot trajectories and significantly enhance the efficiency and quality of data collection. However, in the process of maximizing information acquisition, IPP must also account for energy consumption, time constraints, and physical obstacles, which often lead to inefficiencies. To address these challenges, we propose an Information Path Planning method based on Reinforcement Learning and Information-Directed Sampling (IRIS). This model is the first to integrate Reinforcement Learning (RL) with Information-Directed Sampling (IDS), ensuring both immediate rewards and the potential for greater information gain through exploratory actions. IRIS employs an off-policy deep reinforcement learning framework, effectively overcoming the limitations observed in on-policy methods, thereby enhancing the model’s adaptability and efficiency. Simulation results demonstrate that the IRIS algorithm performs exceptionally well across various IPP scenarios. Once training stabilizes, IDS will dominate decision-making with a probability of approximately 1.3 % to yield better outcomes, highlighting its significant potential in this field. The relevant code is available at https://github.com/SUTLZY/IRIS .},
  archive      = {J_PR},
  author       = {Ziyuan Liu and Yan Zhuang and Peng Wu and Yuanchang Liu},
  doi          = {10.1016/j.patcog.2025.112400},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112400},
  shortjournal = {Pattern Recognition},
  title        = {IRIS: An information path planning method based on reinforcement learning and information-directed sampling},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge tailoring: Bridging the teacher-student gap in semantic segmentation. <em>PR</em>, <em>172</em>, 112399. (<a href='https://doi.org/10.1016/j.patcog.2025.112399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation transfers knowledge from a high-capacity teacher network to a compact student network, but a large capacity gap often limits the student’s ability to fully benefit from the teacher’s guidance. In semantic segmentation, another major challenge is the difficulty in predicting accurate object boundaries, as even strong teacher models can produce ambiguous or imprecise outputs. To address both challenges, we present Knowledge Tailoring, a novel distillation framework that adapts the teacher’s knowledge to better match the student’s representational capacity and learning dynamics. Much like a tailor adjusts an oversized suit to fit the wearer’s shape, our method reshapes the teacher’s abundant but misaligned knowledge into a form more suitable for the student. KT introduces feature tailoring, which restructures intermediate features based on channel-wise correlation to narrow the representation gap, and logit tailoring, which improves boundary prediction by refining class-specific logits. The tailoring strategy evolves throughout training, offering guidance that aligns with the student’s progress. Experiments on Cityscapes, Pascal VOC, and ADE20K confirm that KT consistently enhances performance across a variety of architectures including DeepLabV3, PSPNet, and SegFormer. Our code is available for https://github.com/seok-hwa/KT .},
  archive      = {J_PR},
  author       = {Seokhwa Cheung and Seungbeom Woo and Taehoon Kim and Wonjun Hwang},
  doi          = {10.1016/j.patcog.2025.112399},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112399},
  shortjournal = {Pattern Recognition},
  title        = {Knowledge tailoring: Bridging the teacher-student gap in semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Understanding and tackling the modality imbalance problem in multimodal survival prediction. <em>PR</em>, <em>172</em>, 112398. (<a href='https://doi.org/10.1016/j.patcog.2025.112398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the in-depth integration of multimodal data, survival prediction has emerged as a pivotal task in cancer prognosis by facilitating personalized treatment planning and medical resource allocation. In this study, we report an intriguing phenomenon of inter-modality capability gap (ICG) enlargement during joint survival modelling of genomics data and pathology images. This observation, supported by our dedicated theoretical analysis, uncovers a previously unrecognized modality imbalance problem, where pathology modality suffers from limited gradient propagation and insufficient learning while genomics modality dominates in reducing survival loss. To tackle this problem, we further propose a balanced multimodal learning approach for survival prediction named BMLSurv, which introduces two innovative auxiliary learning strategies: self-enhancement learning (SEL) and peer-assistance learning (PAL). The SEL strategy exploits a real-time imbalance measure to guide extra task-aware supervision, therefore dynamically strengthening pathology-specific gradient propagation in a self-enhanced manner. Meanwhile, the PAL strategy leverages the stronger genomics modality as a “helpful peer” to assist the sufficient learning of pathology modality via a new risk-ranking distillation technique. Extensive experiments on representative cancer datasets demonstrate that by successfully address the modality imbalance problem, BMLSurv remarkably narrows the ICG in joint survival modelling and consistently outperforms state-of-the-art methods by a large margin. These results underscore the potential of BMLSurv to advance multimodal survival prediction and enhance clinical decision-making in cancer prognosis.},
  archive      = {J_PR},
  author       = {Chicheng Zhou and Minghui Wang and Yi Shi and Anli Zhang and Ao Li},
  doi          = {10.1016/j.patcog.2025.112398},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112398},
  shortjournal = {Pattern Recognition},
  title        = {Understanding and tackling the modality imbalance problem in multimodal survival prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hyper-network curvature: A new representation method for high-order brain network analysis. <em>PR</em>, <em>172</em>, 112397. (<a href='https://doi.org/10.1016/j.patcog.2025.112397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human brain is a complex system and contains abundant high-order interactions among multiple brain regions, which can be described by brain hyper-network. In brain hyper-networks, nodes represent brain regions of interest (ROIs), while edges describe the interactions of multiple ROIs, providing important high-order information for brain disease analysis and diagnosis. However, most of the existing hyper-network studies focused on the hyper-connection (i.e. hyper-edge) analysis and ignored the local topological information on nodes. To address this problem, we propose a new representation method (i.e., hyper-network curvature) for brain hyper-network analysis. Compared with the existing hyper-network representation methods, the proposed hyper-network curvature can be used to analyze the local topologies of nodes in brain hyper-networks. Based on hyper-network curvature, we further propose a novel graph kernel called brain hyper-network curvature kernel to measure the similarity of a pair of brain hyper-networks. We have proved that the proposed hyper-network curvature is bounded and brain hyper-network curvature kernel is positive definite. To evaluate the effectiveness of our proposed method, we perform the classification experiments on functional magnetic resonance imaging data of brain diseases. The experimental results demonstrate that our proposed method can significantly improve classification accuracy compared to the state-of-the-art graph kernels and graph neural networks for classifying brain diseases.},
  archive      = {J_PR},
  author       = {Kai Ma and Tianyu Du and Qi Zhu and Xuyun Wen and Jiashuang Huang and Xibei Yang and Daoqiang Zhang},
  doi          = {10.1016/j.patcog.2025.112397},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112397},
  shortjournal = {Pattern Recognition},
  title        = {Hyper-network curvature: A new representation method for high-order brain network analysis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated cross-source learning for lung nodule segmentation with data characteristic-aware weight optimization. <em>PR</em>, <em>172</em>, 112396. (<a href='https://doi.org/10.1016/j.patcog.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning enables multiple medical institutions to undertake distributed training while protecting patient privacy. Nevertheless, the significant variance in data distributions across diverse sites results in imbalanced knowledge acquisition, thereby affecting the performance of the global model. To tackle this challenge, we propose a novel federated algorithm for lung nodule segmentation, incorporating a Cross-source Learning (CSL) method. This method generates pseudo nodules by synthesizing the nodule phase spectrum with the nodule amplitude spectrum from other clients. These pseudo nodules are subsequently embedded into pulmonary regions to augment the data. By incorporating knowledge from various clients, which alleviates the challenges posed by non-IID data. On the server side, a Data Characteristic-aware Weight Optimization (DCWO) method is proposed to incorporate client data quality assessment and the size of lung nodule volume as weights to optimize both model performance and fairness. On the client side, we design a Multi-scale Attention Dynamic Convolution (MADC) lightweight network, which dynamically adapts attention to different spatial regions and extracts features at multiple scales. The performance of our method is superior to the state-of-the-art methods on six public and in-house CT datasets of lung cancer.},
  archive      = {J_PR},
  author       = {Xinjun Bian and Huan Lin and Yumeng Wang and Lingqiao Li and Zhenbing Liu and Huadeng Wang and Zhenwei Shi and Yi Qian and Zaiyi Liu and Rushi Lan and Xipeng Pan},
  doi          = {10.1016/j.patcog.2025.112396},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112396},
  shortjournal = {Pattern Recognition},
  title        = {Federated cross-source learning for lung nodule segmentation with data characteristic-aware weight optimization},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint luminance-chrominance learning for quality assessment of low-light image enhancement. <em>PR</em>, <em>172</em>, 112395. (<a href='https://doi.org/10.1016/j.patcog.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods for low-light enhancement quality assessment (LEQA) often underperform across diverse scenarios. One reason is that most of them rely on shallow feature respresentations, while another is that deep-learning-based counterparts fail to make full use of the unique characteristics of low-light enhanced images (LEIs), such as luminance enhancement and color refinement. In this paper, we propose a novel Joint Luminance-Chrominance Learning Network (JLCLNet) for LEQA to comprehensively assess the effects of low-light image enhancement (LLIE) algorithms. Specifically, we construct a two-branch network architecture consisting of a luminance learning branch and a chrominance learning branch. In the luminance learning branch, the low- and high-frequency subbands of the luminance channel in the CIELAB color space, derived from the dual-tree complex wavelet transform (DTCWT), focus on measuring contrast enhancement and structure preservation. Meanwhile, the chrominance learning branch addresses potential color distortions by integrating perceptual information from the two parallel chrominance channels of the CIELAB color space. Finally, the complementary features from both branches are fused to predict quality scores. Experimental results on four public LEQA databases demonstrate the performance advantages of the proposed method compared to the state-of-the-art approaches. The source code of JLCLNet is available at https://github.com/li181119/JLCLNET .},
  archive      = {J_PR},
  author       = {Tuxin Guan and Qiuping Jiang and Xiongli Chai and Chaofeng Li},
  doi          = {10.1016/j.patcog.2025.112395},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112395},
  shortjournal = {Pattern Recognition},
  title        = {Joint luminance-chrominance learning for quality assessment of low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A graph contrastive learning network for change detection with heterogeneous remote sensing images. <em>PR</em>, <em>172</em>, 112394. (<a href='https://doi.org/10.1016/j.patcog.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land cover change detection (LCCD) with heterogeneous remote sensing images (Hete-RSIs) is an attractive topic in the community of remote sensing applications. Intuitively, Hete-RSIs are acquired with different remote sensors, and they cannot be compared directly for LCCD because of the different imaging modalities. In this paper, a graph contrastive learning network (GCLN) is proposed for LCCD with bitemporal Hete-RSIs. First, with the motivation of smoothing the noise and utilizing contextual information, the k-nearest neighbor algorithm is used to improve the spectral homogeneity of the pixels within a superpixel. Then, a pairwise graph is constructed on the basis of each superpixel from spectral similarity and dissimilarity perspectives, and a graph feature learning network is designed to learn the near-far dependencies of graph features for change detection. Finally, the similarity and dissimilarity loss functions are coupled as a contrastive loss function to expand the difference between similar and dissimilar features. Comparisons with seven advanced methods on five pairs of Hete-RSIs demonstrate the feasibility and superiority of the proposed GCLN for LCCD with Hete-RSIs. For example, the improvements on the five datasets are 3.63 % , 8.47 % , 4.17 % , 8.23 % , and 4.98 % in terms of overall accuracy. The code of the proposed approach can be available at: https://github.com/ImgSciGroup/2024-GCLN .},
  archive      = {J_PR},
  author       = {Zhiyong Lv and Sizhe Cheng and Linfu Xie and Junhuai Li and Minghua Zhao},
  doi          = {10.1016/j.patcog.2025.112394},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112394},
  shortjournal = {Pattern Recognition},
  title        = {A graph contrastive learning network for change detection with heterogeneous remote sensing images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Edge craft odyssey: Navigating guided super-resolution with a fast, precise, and lightweight network. <em>PR</em>, <em>172</em>, 112392. (<a href='https://doi.org/10.1016/j.patcog.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal imaging technology is exceptionally valuable in environments where visibility is limited or nonexistent. However, the high cost and technological limitations of high-resolution thermal imaging sensors restrict their widespread use. Many thermal cameras are now paired with high-resolution visible cameras, which can help improve low-resolution thermal images. However, aligning thermal and visible images is challenging due to differences in their spectral ranges, making pixel-wise alignment difficult. Therefore, we present the Edge Craft Odyssey Network (ECONet), a lightweight transformer-based network designed for Guided Thermal Super-Resolution (GTSR) to address these challenges. Our approach introduces a Progressive Edge Prediction module that extracts edge features from visible images using an adaptive threshold within our innovative Edge-Weighted Gradient Blending technique. This technique provides precise control over the blending intensity between low-resolution thermal and visible images. Additionally, we introduce a lightweight Cascade Deep Feature Extractor that focuses on efficient feature extraction and edge weight highlighting, enhancing the representation of high-frequency details. Experimental results show that ECONet outperforms state-of-the-art methods across various datasets while maintaining a relatively low computational and memory requirements. ECONet improves performance by up to 0.20 to 1.3 dB over existing methods and generates super-resolved images in a fraction of a second, approximately 91 % faster than the other methods. The code is available at https://github.com/Rm1n90/ECONet .},
  archive      = {J_PR},
  author       = {Armin Mehri and Parichehr Behjati and Dario Carpio and Angel D. Sappa},
  doi          = {10.1016/j.patcog.2025.112392},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112392},
  shortjournal = {Pattern Recognition},
  title        = {Edge craft odyssey: Navigating guided super-resolution with a fast, precise, and lightweight network},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models. <em>PR</em>, <em>172</em>, 112391. (<a href='https://doi.org/10.1016/j.patcog.2025.112391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent vulnerabilities of large Vision-Language Models (VLMs), security governance has emerged as a critical concern, particularly given the risks posed by noisy and biased training data as well as adversarial attacks, including data poisoning and prompt injection. These perturbations can significantly degrade model performance and introduce multifaceted societal risks. To verify the safe robustness of VLMs and further inspire the design of defensive AI frameworks, we propose Virtual Scenario Hypnosis (VSH), a multimodal prompt injection jailbreak method that embeds malicious queries into prompts through a deceptive narrative framework. This approach strategically distracts the model while compromising its resistance to jailbreak attempts. Our methodology features two key innovations: 1) Targeted adversarial image prompts that transform textual content into visual layouts through optimized typographic designs, circumventing safety alignment mechanisms to elicit harmful responses; and 2) An information veil encrypted In-Context Learning (ICL) method for text prompts that systematically evades safety detection protocols. To streamline evaluation, we employ Large Language Models (LLMs) to facilitate an efficient assessment of jailbreak success rates, supported by a meticulously designed prompt template incorporating multi-dimensional scoring rules and evaluation metrics. Extensive experiments demonstrate the efficacy of VSH, achieving an overall success rate exceeding 82% on 500 harmful queries spanning multiple domains when tested against LLaVA-v1.5-13B and GPT-4o mini.},
  archive      = {J_PR},
  author       = {Xiayang Shi and Shangfeng Chen and Gang Zhang and Wei Wei and Yinlin Li and Zhaoxin Fan and Jingjing Liu},
  doi          = {10.1016/j.patcog.2025.112391},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112391},
  shortjournal = {Pattern Recognition},
  title        = {Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A locality-sensitive hashing based instance selection method with its application to acceleration of feature selection. <em>PR</em>, <em>172</em>, 112390. (<a href='https://doi.org/10.1016/j.patcog.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of important data preprocessing techniques, feature selection aims to remove redundant and irrelevant features and has been extensively applied to many fields. At present, however, the evaluation of existing feature selection algorithms focuses mainly on the scale of the selected features and the performance of models formulated by the selected features, while the running time of feature selection algorithms is usually neglected. It is noted that the computation complexity of the majority of feature selection algorithms is the square order of the number of instances, resulting in an exponential increase of the running time for large-scale data. In this paper, we propose an algorithm of core instance selection based on the locality-sensitive hashing (CISLSH) to improve the computation efficiency of feature selection algorithms by alleviating the instances used for feature selection. Specifically, all the instances are firstly considered to map them into the one-dimensional integer space using a locality-sensitive hashing (LSH) function. Given a set of hash functions families, a bucket index matrix is constructed to integrate all the mapping results of the set of hash functions families. Then, a voting mechanism is designed according to the bucket index matrix, which motivates to present a novel data partitioning method dividing similar instances into the same bucket (partition) as many as possible. Furthermore, the CISLSH algorithm is developed by selecting a core instance from each non-empty bucket. Finally, numerical experiments are conducted to assess the performance of CISLSH. The experimental results show that the execution of feature selection using the representative instances selected by CISLSH can not only significantly reduce the running time of feature selection but also guarantee the effectiveness of the selected features.},
  archive      = {J_PR},
  author       = {Fan Song and Xiao Zhang and Jinhai Li and Changlin Mei},
  doi          = {10.1016/j.patcog.2025.112390},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112390},
  shortjournal = {Pattern Recognition},
  title        = {A locality-sensitive hashing based instance selection method with its application to acceleration of feature selection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive latent disease state learning for multimodal alzheimer’s disease biomarker detection with missing modalities. <em>PR</em>, <em>172</em>, 112389. (<a href='https://doi.org/10.1016/j.patcog.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal neuroimaging genetics is a crucial approach for identifying biomarkers of Alzheimer’s disease (AD) by leveraging the inherent relationships between genetic and neuroimaging data. However, existing methods are limited by susceptibility to input noises, underutilization of complementary information across neuroimaging modalities, and ineffective handling of samples with incomplete modalities. To address these challenges, we propose an Adaptive Latent Disease State Learning (ALDSL) method, which integrates noise reduction, latent space learning, adaptive regularization, and feature selection into a unified framework for detecting AD biomarkers from incomplete multimodal data. ALDSL introduces a noise reduction strategy based on inter-variable correlations and tailored distance metrics to eliminate noises in the input data, thereby obtaining high-quality representations for each modality. Additionally, latent disease state learning with adaptive regularization is proposed to capture inter-modality correlations by projecting the high-quality representations from multiple modalities into a common latent space. To utilize samples with incomplete modalities, we design a modality-specific weight matrix that accounts for the missing information in the latent disease state learning. Furthermore, an adaptive weighting determination strategy is developed to ensure that the modalities with different data types and varying sample sizes contribute on the same scale. We develop an efficient alternating optimization algorithm to solve the objective function of ALDSL. Experimental results on synthetic datasets and the ADNI GO/2 dataset demonstrate the effectiveness of ALDSL in detecting AD biomarkers.},
  archive      = {J_PR},
  author       = {Zhi Chen and Fengli Zhang and Yun Zhang and Jiajing Zhu and Qiaoqin Li and Yongguo Liu},
  doi          = {10.1016/j.patcog.2025.112389},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112389},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive latent disease state learning for multimodal alzheimer’s disease biomarker detection with missing modalities},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MMP: Enhancing unsupervised graph anomaly detection with multi-view message passing. <em>PR</em>, <em>172</em>, 112388. (<a href='https://doi.org/10.1016/j.patcog.2025.112388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complementary and conflicting relationships between views are two fundamental issues when applying Graph Neural Networks (GNNs) to multi-view attributed graph anomaly detection. Most existing approaches do not address the inherent multi-view properties in the attribute space or leverage complementary information through simple representation fusion, which overlooks the conflicting information among different views. In this paper, we argue that effectively applying GNNs to multi-view anomaly detection necessitates reinforcing complementary information between views and, more importantly, managing conflicting information. Building on this perspective, this paper introduces Multi-View Message Passing (MMP), a novel and effective message passing paradigm specifically designed for multi-view anomaly detection. In the multi-view aggregation phase of MMP, views containing different types of information are integrated using view-specific aggregation functions. This approach enables the model to dynamically adjust the amount of information aggregated from complementary and conflicting views, thereby mitigating issues arising from insufficient complementary information and excessive conflicting information, which can lead to suboptimal representation learning. Furthermore, we propose an innovative aggregation loss mechanism that enhances model performance by optimizing the reconstruction differences between aggregated representations and the original views, thereby improving both detection accuracy and model interpretability. Extensive experiments on synthetic and real-world datasets validate the effectiveness and robustness of our method. The source code is available at https://github.com/weihus/MMP .},
  archive      = {J_PR},
  author       = {Weihu Song and Lei Li and Mengxiao Zhu and Yue Pei and Haogang Zhu},
  doi          = {10.1016/j.patcog.2025.112388},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112388},
  shortjournal = {Pattern Recognition},
  title        = {MMP: Enhancing unsupervised graph anomaly detection with multi-view message passing},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HopGAT: A multi-hop graph attention network with heterophily and degree awareness. <em>PR</em>, <em>172</em>, 112387. (<a href='https://doi.org/10.1016/j.patcog.2025.112387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In highly heterophilic graphs, where nodes frequently connect across categories, the attention learning mechanism by dynamically adjusting neighboring node weights, may struggle to capture intricate node relationships. Furthermore, first-hop neighbor information is usually insufficient to encompass the global structure, but multi-hop increases complexity. To address these challenges, we propose HopGAT, a multi-hop graph attention network with heterophily and degree awareness. Firstly, we design heterophily-based neighbor sampling to sequentially filter high-hop neighbors by degree. Next, to obtain comprehensive global information, we construct a multi-hop recursive learning method with head and tail attention vectors to learn multi-hop neighbor features. Finally, we combine the average node degree of the graph with hop decay modeling to learn importance coefficients at different hops and adaptively aggregate the learned multi-hop features. Experimental results demonstrate that HopGAT significantly improves performance across 9 benchmark datasets with various heterophily and different average degrees.},
  archive      = {J_PR},
  author       = {Han Zhang and Huan Wang and Mingjing Han},
  doi          = {10.1016/j.patcog.2025.112387},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112387},
  shortjournal = {Pattern Recognition},
  title        = {HopGAT: A multi-hop graph attention network with heterophily and degree awareness},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A boundary-enhanced and target-driven deformable convolutional network for abdominal multi-organ segmentation. <em>PR</em>, <em>172</em>, 112386. (<a href='https://doi.org/10.1016/j.patcog.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to accurately segment organs from abdominal CT images for clinical diagnosis, treatment planning, and surgical guidance, which remains an extremely challenging task due to low contrast between organs and surrounding tissues and the difference of organ size and shape. Previous works mainly focused on complex network architectures or task-specific modules but frequently failed to learn irregular boundaries and did not consider that different slices from the same case might contain targets of different numbers of categories. To tackle these issues, this paper proposes UAMSNet for abdominal multi-organ segmentation. In UAMSNet, a hybrid receptive field extraction (HRFE) module is introduced to adaptively learn the features of irregular targets, which has an adaptive dilation factor containing distance information to facilitate spatial and channel attention. The HRFE module can simultaneously learn multiple scales and deformations of different organs. Furthermore, a multi-organ boundary-enhanced attention (MBA) module in the encoder and decoder is designed to provide effective boundary information for feature extraction based on the large peak of the organ edge. Finally, the difference in the number of organ categories between different slices is first considered using a loss function, which can adjust the loss computation based on organ categories in the image. The loss function mitigates the effect of false positives during training to ensure the model can adapt to small organ segmentation. Experimental results on WORD and Synapse datasets demonstrate that our UAMSNet outperforms the existing state-of-the-art methods. Ablation experiments confirm the effectiveness of our designed modules and loss function. Our code is publicly available on https://github.com/HeyJGJu/UAMSNet .},
  archive      = {J_PR},
  author       = {Jianguo Ju and Menghao Liu and Wenhuan Song and Tongtong Zhang and Jindong Liu and Pengfei Xu and Ziyu Guan},
  doi          = {10.1016/j.patcog.2025.112386},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112386},
  shortjournal = {Pattern Recognition},
  title        = {A boundary-enhanced and target-driven deformable convolutional network for abdominal multi-organ segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distantly supervised reinforcement localization for real-world object distribution estimation. <em>PR</em>, <em>172</em>, 112385. (<a href='https://doi.org/10.1016/j.patcog.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the distribution of objects in the real world from monocular images is a challenging task due to the disparity between object distributions in perspective images and reality. Many researchers focus on predicting object distributions by converting perspective images into Bird’s-Eye View (BEV) images. In scenarios where camera parameter information is unavailable, the prediction of vanishing lines becomes critical for performing inverse perspective transformations. However, accurately predicting vanishing lines necessitates accounting for variations in object size, which cannot be effectively captured through simple regression models. Therefore, this paper proposes a size variation-aware method, utilizing expert knowledge from object detection to build a reinforcement learning framework for predicting vanishing lines in traffic scenes. Specifically, this method leverages size information from trained detectors to convert perspective images into BEV images without the need for additional camera intrinsic parameters. First, we design a novel reward mechanism that utilizes prior knowledge of scale differences between similar objects in perspective images, allowing the network to automatically update and learn specific vanishing line positions. Second, we propose a fast inverse perspective transformation method, which accelerates the training speed of the proposed approach. To evaluate the effectiveness of the method, experiments are conducted on two traffic flow datasets. The experimental results demonstrate that the proposed algorithm accurately predicts vanishing line positions and successfully transforms perspective images into BEV images. Furthermore, the proposed algorithm performs competitively with directly supervised methods. The code is available at: https://github.com/HotChieh/DDRL.},
  archive      = {J_PR},
  author       = {Haojie Guo and Junyu Gao and Yuan Yuan},
  doi          = {10.1016/j.patcog.2025.112385},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112385},
  shortjournal = {Pattern Recognition},
  title        = {Distantly supervised reinforcement localization for real-world object distribution estimation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A variable gaussian kernel scale active contour model based on jeffreys divergence for ICT image segmentation. <em>PR</em>, <em>172</em>, 112384. (<a href='https://doi.org/10.1016/j.patcog.2025.112384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial computed tomography (ICT), factors like beam scattering, insufficient beam intensity, and detector dark current often lead to weak edges, scattering artifacts, and severe Gaussian noise in ICT images. These issues pose significant difficulties for accurate segmentation of high-density complex structures using existing active contour models (ACMs). To address these limitations, this paper presents a variable Gaussian kernel scale active contour model based on Jeffreys divergence (VGJD). Firstly, the Jeffreys divergence (JD) is incorporated into the energy function to replace the conventional Euclidean distance, enhancing the contour’s ability to quantify pixel value disparity during evolution. Additionally, a filter weight is introduced to minimize the impact of noise. Moreover, a variable Gaussian kernel scale strategy is adopted to effectively integrate both global and local image information, thereby enhancing the robustness of the initial contour and improving the precision of detail segmentation. Finally, optimized length and regularity terms are employed to enforce constraints on the level set function. Extensive experimental results demonstrate that the VGJD model can effectively segment various complex ICT images, achieving superior precision in comparison to other ACM models. The code is available at https://github.com/LiuZX599/ACM-VGJD.git},
  archive      = {J_PR},
  author       = {Zexin Liu and Qi Li and Junyao Wang and Tingyuan Deng and Rifeng Zhou and Yufang Cai and Fenglin Liu},
  doi          = {10.1016/j.patcog.2025.112384},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112384},
  shortjournal = {Pattern Recognition},
  title        = {A variable gaussian kernel scale active contour model based on jeffreys divergence for ICT image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust spatio-temporal graph neural networks with sparse structure learning. <em>PR</em>, <em>172</em>, 112383. (<a href='https://doi.org/10.1016/j.patcog.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of spatio-temporal graph classification by introducing sparse structure learning to enhance its robustness and explainability. Spatio-temporal graph neural networks (STGNN) integrate spatial structure and temporal sequential features into GNN learning, resulting in promising performance in many applications. However, current STGNN models often fail to capture the discriminative sparse substructure and the smooth distribution of these samples. To this end, this paper introduces RostGNN, robust spatio-temporal graph neural networks, for achieving more discriminative graph representations. Concretely, RostGNN extracts the spatial and temporal features by performing gated recurrent units on the given time series data and calculating adjacent matrixes for graphs. Then, we impose the iterative hard-thresholding approach on the final association matrix to obtain a sparse graph. Meanwhile, we calculate a similarity matrix from the side information of samples to smooth the achieved data representations and use fully connected networks for graph classification. We finally applied RostGNN to brain graph classification in experiments on real-world datasets. The results demonstrate that RostGNN delivers robust and discriminative graph representations and performs better than compared methods, benefiting from the sparsity and manifold regularizers. Furthermore, RostGNN can potentially yield useful findings for data understanding.},
  archive      = {J_PR},
  author       = {Yupei Zhang and Yuxin Li and Shuhui Liu and Xuequn Shang},
  doi          = {10.1016/j.patcog.2025.112383},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112383},
  shortjournal = {Pattern Recognition},
  title        = {Robust spatio-temporal graph neural networks with sparse structure learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiscDC: Unsupervised discriminative deep image clustering via confidence-driven self-labeling. <em>PR</em>, <em>172</em>, 112382. (<a href='https://doi.org/10.1016/j.patcog.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering, as an important research topic in machine learning and data mining, has been widely applied in many real-world scenarios. However, existing deep clustering methods primarily rely on implicit optimization objectives such as contrastive learning or reconstruction, which do not explicitly enforce cluster-level discrimination. This limitation restricts their ability to achieve compact intra-cluster structures and distinct inter-cluster separations. To overcome this limitation, we propose a novel unsupervised discriminative deep clustering (discDC) method, which explicitly integrates cluster-level discrimination into the learning process. The proposed discDC framework projects data into a nonlinear latent space with compact and well-separated cluster representations. It explicitly optimizes clustering objectives by minimizing intra-cluster discrepancy and maximizing inter-cluster discrepancy. Additionally, to tackle the lack of label information in unsupervised scenarios, we introduce a confidence-driven self-labeling mechanism, which iteratively derives reliable pseudo-labels to enhance discriminative analysis. Extensive experiments on five benchmark datasets demonstrate the superiority of discDC over state-of-the-art deep clustering approaches.},
  archive      = {J_PR},
  author       = {Jinyu Cai and Wenzhong Guo and Yunhe Zhang and Jicong Fan},
  doi          = {10.1016/j.patcog.2025.112382},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112382},
  shortjournal = {Pattern Recognition},
  title        = {DiscDC: Unsupervised discriminative deep image clustering via confidence-driven self-labeling},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MCoCa: Towards fine-grained multimodal control in image captioning. <em>PR</em>, <em>172</em>, 112381. (<a href='https://doi.org/10.1016/j.patcog.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controllable image captioning (CIC) models have traditionally focused on generating controlled descriptions using specific text styles. However, these approaches are limited as they rely solely on text control signals, which often fail to align with complex human intentions, such as selecting specific areas in images. To enhance multimodal interactivity, we propose to augment current CIC systems with diverse and joint visual-text controls. To achieve this, we first create a comprehensive Multimodal Controllable Image Captioning Corpus (MCoCa) dataset by leveraging language rewriting ability of GPT-3.5, containing 0.97M image-captions pairs along with 21 visual-text control signals. By training the visual and textual adapters equipped on the multimodal large language model with newly proposed instructional prompts on MCoCa, we observe emergent combinatory multimodal controllability and significant improvement in text controllability. We present exhaustive quantitative and qualitative results, benchmarking our trained model’s state-of-the-art zero-shot captioning performance on SentiCap and FlickrStyle10K in terms of both fidelity and controllability. For regional understanding ability of visual-controlled captioning, our method achieves obvious improvement compared with the baseline models.},
  archive      = {J_PR},
  author       = {Shanshan Zhao and Teng Wang and Jinrui Zhang and Xiangchen Wang and Feng Zheng},
  doi          = {10.1016/j.patcog.2025.112381},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112381},
  shortjournal = {Pattern Recognition},
  title        = {MCoCa: Towards fine-grained multimodal control in image captioning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning interpretable binary codes via semantic alignment for customized image retrieval. <em>PR</em>, <em>172</em>, 112380. (<a href='https://doi.org/10.1016/j.patcog.2025.112380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single modality hashing (SMH) has achieved impressive performance on image retrieval task in recent years. The only fly in the ointment is that most of the methods mainly measure the image similarity based on the high-level class labels. The retrieval needs in the real world are diverse in form of different subsets of the semantics (not only the category labels) presented in the query image. However, existing SMH methods fail to account for such customized image retrieval task that allows users to select visual semantics or their combinations present in the query and retrieve similar images based on such selected semantic descriptions. To address such practical issues, we propose a deep hashing to learn Interpretable Binary Codes (IBC), endowing the hashing bits with semantic interpretability rather than purely entangling the class information in the whole codes, i.e., aligning the criteria of binary space partition of each bit with a particular visual semantic concept. Specifically, binary encoding is a highly non-linear operation of dimension reduction, the semantic and spatial information of which has respectively been abstract and lost heavily. In light of the rich semantic interpretability and binary concept detection ability of convolutional filters, we innovatively transfer the semantic knowledge from filters to hashing bits by align the distributions of the binary codes and filter activations that capture the presence/absence of visual patterns in images. To further improve the semantics of filters/bits, the shared and learnable classification rules are introduced and optimized to disentangle the sparse composition between the category label and encoded semantics in filters/bits. With high interpretability, we can selectively combine bits corresponding to the target semantics during retrieval, thereby enabling flexible and customized similarity searches. Extensive experiments on several large-scale datasets covering general objects and scenes, single and multiple label scenarios, demonstrate the interpretability and functionalities of learned binary codes for the customized image retrieval tasks.},
  archive      = {J_PR},
  author       = {Shishi Qiao and Ruiping Wang and Xilin Chen},
  doi          = {10.1016/j.patcog.2025.112380},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112380},
  shortjournal = {Pattern Recognition},
  title        = {Learning interpretable binary codes via semantic alignment for customized image retrieval},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AFFusion: Atmospheric scattering enhancement and frequency integrated spatial-channel attention for infrared and visible image fusion. <em>PR</em>, <em>172</em>, 112379. (<a href='https://doi.org/10.1016/j.patcog.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) seeks to generate fused images that combine rich texture details with distinct thermal radiation features by integrating and leveraging complementary information from multiple sources. However, existing fusion methods frequently neglect the challenges posed by illumination degradation and inaccurate color contrast, which arise due to light energy loss and light scattering during atmospheric transmission. To address these limitations, this study introduces an innovative IVIF framework, termed AFFusion, which integrates an atmospheric scattering physical model with a frequency-domain feature component. By accurately predicting and estimating two key physical parameters-the transmission map and atmospheric light-within the scattering model, AFFusion harnesses atmospheric scattering principles to produce enhanced visible images, thereby mitigating the adverse effects of energy attenuation and scattering. Furthermore, to resolve artifacts and texture loss caused by traditional atmospheric scattering models, AFFusion incorporates Fourier transform in conjunction with spatial and channel attention mechanisms to selectively amplify amplitude and phase features in the frequency domain, thereby enhancing texture fidelity and detail representation within the fused images. Comprehensive experimental evaluations demonstrate that AFFusion surpasses state-of-the-art methods in both qualitative and quantitative performance metrics, while also providing robust support for high-level visual tasks. The implementation code is publicly accessible at https://github.com/cici0206/AFFusion .},
  archive      = {J_PR},
  author       = {Jiwei Hu and Chengcheng Song and Qiwen Jin and Kin-Man Lam},
  doi          = {10.1016/j.patcog.2025.112379},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112379},
  shortjournal = {Pattern Recognition},
  title        = {AFFusion: Atmospheric scattering enhancement and frequency integrated spatial-channel attention for infrared and visible image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Vision-by-prompt: Context-aware dual prompts for composed video retrieval. <em>PR</em>, <em>172</em>, 112378. (<a href='https://doi.org/10.1016/j.patcog.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composed video retrieval (CoVR) is a challenging task of retrieving relevant videos in a corpus by using a query that integrates both a relative change text and a reference video. Most existing CoVR models simply rely on the late-fusion strategy to combine visual and change text. Furthermore, various methods have been proposed to generate pseudo-word tokens from the reference video, which are then integrated into the relative change text for CoVR. However, these pseudo-word-based techniques exhibit limitations when the target video involves complex changes from the reference video, e.g. , object removal. In this work, we propose a novel CoVR framework that learns context information via context-aware dual prompts for relative change text to achieve effective composed video retrieval. The dual prompts cater to two aspects: 1) Global descriptive prompts generated from the pretrained V-L models, e.g. , BLIP-2, to get concise textual representations of the reference video. 2) Local target prompts to learn the target representations that the change text pays attention to. By connecting these prompts with relative change text, one can easily use existing text-to-video retrieval models to enhance CoVR performance. Our proposed framework can be flexibly used for both composed video retrieval (CoVR) and composed image retrieval (CoIR) tasks. Moreover, we take a pioneering approach by adopting the CoVR model to achieve zero-shot CoIR for remote sensing. Experiments on four datasets show that our approach achieves state-of-the-art performance in both CoVR and zero-shot CoIR tasks, with improvements of as high as around 3.5 % in terms of recall@K=1 score.},
  archive      = {J_PR},
  author       = {Hao Wang and Fang Liu and Licheng Jiao and Jiahao Wang and Shuo Li and Lingling Li and Puhua Chen and Xu Liu},
  doi          = {10.1016/j.patcog.2025.112378},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112378},
  shortjournal = {Pattern Recognition},
  title        = {Vision-by-prompt: Context-aware dual prompts for composed video retrieval},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient and compact tensor wheel decomposition for tensor completion. <em>PR</em>, <em>172</em>, 112377. (<a href='https://doi.org/10.1016/j.patcog.2025.112377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor wheel (TW) decomposition has recently emerged as a powerful technique for achieving state-of-the-art recovery performance in tensor completion tasks. However, its widespread application has been hindered by issues related to rank sensitivity and high computational cost. To address these limitations, we introduce an efficient and compact TW decomposition method for low-rank tensor completion. Specifically, we demonstrate that the model complexity of TW decomposition is controlled simultaneously by two elements, namely, the explicit TW rank and implicit sparsity in the core tensor. Therefore, low-rank and sparsity regularization are introduced to ring factors and core factor, respectively, to achieve a compact TW decomposition. Furthermore, to alleviate the computational bottleneck of TW decomposition, we propose a novel generalized inverse operation, which reduces the computational complexity of vanilla TW decomposition from O ( I N R 2 N ) to O ( I N R N ) . Subsequently, we develop an efficient alternating direction method of multipliers (ADMM) algorithm with theoretical convergence guarantees. Numerical tensor completion experiments on color images, multispectral images, and color videos demonstrate that the proposed method achieves superior performance while significantly reducing runtime compared to state-of-the-art methods. The code is available at: https://github.com/justicbro/TWLRS .},
  archive      = {J_PR},
  author       = {Peilin Yang and Yuning Qiu and Zhenhao Huang and Guoxu Zhou and Qibin Zhao},
  doi          = {10.1016/j.patcog.2025.112377},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112377},
  shortjournal = {Pattern Recognition},
  title        = {Efficient and compact tensor wheel decomposition for tensor completion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning to complement with multiple humans. <em>PR</em>, <em>172</em>, 112376. (<a href='https://doi.org/10.1016/j.patcog.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solution for addressing real-world image classification challenges. Human-AI collaborative classification (HAI-CC) aims to synergise the efficiency of machine learning classifiers and the reliability of human experts to support decision making. Learning to defer (L2D) has been one of the promising HAI-CC approaches, where the system assesses a sample and decides to defer to one of human experts when it is not confident. Despite recent progress, existing L2D methods rely on the strong assumption of ground truth label availability for training, while in practice, most datasets often contain multiple noisy annotations per data sample without well-curated ground truth labels. In addition, current L2D methods either consider the setting of a single human expert or defer the decision to one human expert, even though there may be multiple experts available, resulting in a suboptimal utilisation of available resources. Furthermore, current HAI-CC evaluation frameworks often overlook processing costs, making it difficult to assess the trade-off between computational efficiency and performance when benchmarking different methods. To address these gaps, this paper introduces LECOMH – a new HAI-CC method that learns from noisy labels without depending on clean labels for training, simultaneously maximising collaborative accuracy with either one or multiple human experts, while minimising the cost of human collaboration. The paper also introduces benchmarks featuring multiple noisy labels per data sample for both training and testing to evaluate HAI-CC methods. Through quantitative comparisons on these benchmarks, LECOMH consistently outperforms HAI-CC methods and baselines, including human experts alone, multi-rater learning and noisy-label learning methods across both synthetic and real-world datasets.},
  archive      = {J_PR},
  author       = {Zheng Zhang and Cuong Nguyen and Kevin Wells and Thanh-Toan Do and Gustavo Carneiro},
  doi          = {10.1016/j.patcog.2025.112376},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112376},
  shortjournal = {Pattern Recognition},
  title        = {Learning to complement with multiple humans},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-aware state-space method for underwater object detection. <em>PR</em>, <em>172</em>, 112375. (<a href='https://doi.org/10.1016/j.patcog.2025.112375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater Object Detection (UOD) faces significant challenges due to complex degradation factors, such as color shifts caused by light absorption and scattering, spatially varying noise induced by plankton and sea snow, and motion blur resulting from dynamic water currents. Among existing methods, Convolutional Neural Networks (CNNs) are limited by fixed receptive fields, making it difficult to model long-range noise patterns; while Transformers excel at modeling global dependencies, they suffer from high computational complexity and weak capability in restoring fine-grained local features. Neither can effectively address the demands of detecting underwater-specific noise and small objects. To tackle these issues, we propose UOD-Mamba, a state space model (SSM)-based framework for underwater object detection. At its core is the Noise-Aware Dual-path Mamba (NADM) module, which integrates a global-local dual-path fusion strategy to enable both long-range noise modeling and local feature enhancement. The global path balances noise in input features through the Noise-Balanced Preprocessing Module (NBPM) and leverages Mamba’s long-range modeling capability to extract global noise patterns; the local path fuses the Underwater Enhanced Multi-scale Attention Module (UEMA) with CSP convolution to model edge and detail features at a fine-grained level, thereby compensating for the loss of local information. By explicitly learning the distribution characteristics of underwater noise and capturing the differences between noise and target features, the framework enhances detection robustness in noisy environments. Experimental validation on the DUO and RUOD datasets demonstrates that UOD-Mamba sets a new state-of-the-art in detection performance. It also exhibits advantages in explicit modeling of diverse noises, preservation of local details, and computational efficiency across multi-noise scenarios, enabling effective handling of complex underwater interference environments.},
  archive      = {J_PR},
  author       = {Jingchun Zhou and Xudong Wang and Mingjie Li and Zongxin He and Wentian Xin and Xiuguo Zhang},
  doi          = {10.1016/j.patcog.2025.112375},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112375},
  shortjournal = {Pattern Recognition},
  title        = {Noise-aware state-space method for underwater object detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-domain-aware deep unfolding transformer for hyperspectral image super-resolution. <em>PR</em>, <em>172</em>, 112374. (<a href='https://doi.org/10.1016/j.patcog.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusing low-spatial-resolution hyperspectral images with high-spatial-resolution (HSR) multispectral images is pivotal for generating HSR hyperspectral images (HSR-HSIs). While current deep unrolling-based multi-stage frameworks have shown notable advancements due to their robustness and interpretability, they still exhibit limitations in adequately harnessing the HSI prior knowledge. This deficiency is principally attributed to three factors: (1) prior knowledge learned from training samples often overlooks target-specific characteristics; (2) insufficient feature representation within and across stages; and (3) insufficient modeling of spatial–spectral dependencies. To address these issues, we propose a novel Cross-domain-aware Transformer (CaFormer). Specifically, a cross-domain aware attention mechanism is investigated to capture intrinsic joint spatial–spectral dependencies through unified cross-domain feature representation. The attention mechanism models HSI eigenfeatures to derive spatial and spectral representations while preserving their mutual correlations. Furthermore, we introduce a Fourier Domain Perception Block to enhance structural and semantic representations by exploiting amplitude and phase components in the frequency domain, thereby strengthening feature aggregation across stages. To further improve adaptability while preserving the interpretability of deep unrolling networks, CaFormer employs a dual-stage prior learning strategy, transferring prior knowledge learned from general training data to the specific observed scene. Our experimental evaluations on four public datasets and Worldview-2 satellite images confirm that our proposed method outperformed eleven state-of-the-art methods. The code is available at https://github.com/Caoxuheng/HIFtool .},
  archive      = {J_PR},
  author       = {Xuheng Cao and Xuquan Wang and Xiong Dun and Yusheng Lian and Xinbin Cheng and Xiaopeng Hao},
  doi          = {10.1016/j.patcog.2025.112374},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112374},
  shortjournal = {Pattern Recognition},
  title        = {Cross-domain-aware deep unfolding transformer for hyperspectral image super-resolution},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-teacher self-distillation registration for multi-modality medical image fusion. <em>PR</em>, <em>172</em>, 112373. (<a href='https://doi.org/10.1016/j.patcog.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misaligned multimodal medical images pose challenges to the fusion task, resulting in structural distortions and edge artifacts in the fusion results. Existing registration networks primarily consider single-scale deformation fields at each stage, thereby neglecting long-range connections between non-adjacent stages. Moreover, in the fusion task, due to the quadratic computational complexity faced by Transformers during feature extraction, they are unable to effectively capture long-range correlated features. To address these problems, we propose an image registration and fusion method called DTMFusion. DTMFusion comprises two main networks: a Dual-Teacher Self-Distillation Registration (DTSDR) network and a Mamba-Conv-based Fusion (MCF) network. The registration network employs a pyramid progressive architecture to generate independent deformation fields at each layer. We introduce a dual-teacher self-distillation scheme that leverages past learning history and the current network structure as teacher guidance to constrain the generated deformation fields. For the fusion network, we introduced Mamba to address the quadratic complexity problem of Transformers. Specifically, the fusion network involves two key components: the Shallow Fusion Module (SFM) and the Cross-Modality Fusion Module (CFM). The SFM achieves lightweight cross-modality interaction through channel exchange, while the CFM leverages inherent cross-modality relationships to enhance the representation capability of fusion results. Through the collaborative effort of these components, the network can effectively integrate cross-modality complementary information and maintain appropriate apparent strength from a global perspective. Extensive experimental analysis demonstrates the superiority of this method in fusing misaligned medical images.},
  archive      = {J_PR},
  author       = {Aimei Dong and Jingyuan Xu and Long Wang},
  doi          = {10.1016/j.patcog.2025.112373},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112373},
  shortjournal = {Pattern Recognition},
  title        = {Dual-teacher self-distillation registration for multi-modality medical image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FSF-net: Enhance 4D occupancy forecasting with coarse BEV scene flow for autonomous driving. <em>PR</em>, <em>172</em>, 112372. (<a href='https://doi.org/10.1016/j.patcog.2025.112372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {4D occupancy forecasting is one of the important techniques for autonomous driving, which can avoid potential risk in the complex traffic scenes. Scene flow is a crucial element to describe 4D occupancy map tendency. However, an accurate scene flow is difficult to predict in the real scene. In this paper, we find that BEV scene flow can approximately represent 3D scene flow in most traffic scenes. And coarse BEV scene flow is easy to generate. Under this thought, we propose 4D occupancy forecasting method FSF-Net based on coarse BEV scene flow. At first, we develop a general occupancy forecasting architecture based on coarse BEV scene flow. Then, to further enhance 4D occupancy feature representation ability, we propose a vector quantized based Mamba (VQ-Mamba) network to mine spatial-temporal structural scene feature. After that, to effectively fuse coarse occupancy maps forecasted from BEV scene flow and latent features, we design a U-Net based quality fusion (UQF) network to generate the fine-grained forecasting result. Extensive experiments are conducted on public Occ3D dataset. FSF-Net has achieved IoU and mIoU 9.56 % and 10.87 % higher than state-of-the-art method. Hence, we believe that proposed FSF-Net benefits to the safety of autonomous driving.},
  archive      = {J_PR},
  author       = {Erxin Guo and Pei An and You Yang and Qiong Liu and An-An Liu},
  doi          = {10.1016/j.patcog.2025.112372},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112372},
  shortjournal = {Pattern Recognition},
  title        = {FSF-net: Enhance 4D occupancy forecasting with coarse BEV scene flow for autonomous driving},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel image enhancement method based on image decomposition and deep neural networks. <em>PR</em>, <em>172</em>, 112371. (<a href='https://doi.org/10.1016/j.patcog.2025.112371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image decomposition and deep learning are active research areas in computer vision tasks, such as cartoon texture decomposition, low-light image enhancement, rain streak removal, image recovery, etc. This paper proposes a novel low-light image enhancement method by joining image decomposition and deep neural network techniques. We introduce a new image decomposition-based optimization model by incorporating the Tikhonov regularization and multi-scale convolutional sparse coding (MSCSC) to enhance image visual effects. To enhance robustness performance, we introduce a noise-free image decomposition error term to effectively suppress noise in low-light images. To effectively implement the proposed method, we incorporate a deep-unfolding neural network and an adaptive denoiser into the alternating direction method of multipliers (ADMM) framework. Since the deep unfolding network can effectively simulate the optimization algorithm process, the interpretability of the network model is increased. Moreover, through end-to-end training, we can automatically estimate the two priors and parameter settings from training samples. Finally, qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art image enhancement methods in terms of visual quality and robustness. The source code is available at https://github.com/cassiopeia-yxx/LLIE .},
  archive      = {J_PR},
  author       = {Yao Xiao and Youshen Xia},
  doi          = {10.1016/j.patcog.2025.112371},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112371},
  shortjournal = {Pattern Recognition},
  title        = {A novel image enhancement method based on image decomposition and deep neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonuniform low-light image enhancement via noise-aware decomposition and adaptive correction. <em>PR</em>, <em>172</em>, 112370. (<a href='https://doi.org/10.1016/j.patcog.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-illumination conditions often exhibit low brightness with nonuniform distribution, low contrast, and noise, negatively affecting the human visual experience and the accuracy of image-based computer vision tasks. Enhancing nonuniform low-light images is challenging considering the requirement of simultaneously reducing noise, enhancing low-light regions, and suppressing high-light regions. To address these challenges, we innovatively propose a noise-aware decomposition and adaptive correction method (NDAC) to enhance the nonuniform low-light images without the need for paired high-quality training data. Specifically, a noise-aware image decomposition network (NIDNet) is first presented to decompose the input images into illumination, reflection, and noise components, while suppressing the noise in the reflection component through a variable gradient operator and estimating the noise component. Besides, we devise a novel nonlinear adaptive brightness mapping function (NABM), whose parameters are optimized via a designed automatic light enhancement network (ALENet) to brighten the illumination component. The enhancements are obtained by fusing the noiseless reflection component with the brightened illumination component. Extensive experiments on both public and industrial datasets demonstrate that the proposed NDAC method outperforms state-of-the-art approaches in both qualitative and quantitative evaluations.},
  archive      = {J_PR},
  author       = {Jiancai Huang and Zhaohui Jiang and Xingjian Liu and Yap-Peng Tan and Weihua Gui},
  doi          = {10.1016/j.patcog.2025.112370},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112370},
  shortjournal = {Pattern Recognition},
  title        = {Nonuniform low-light image enhancement via noise-aware decomposition and adaptive correction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fourier-enhanced semi-supervised proxy learning for ultra-fine-grained novel class discovery. <em>PR</em>, <em>172</em>, 112369. (<a href='https://doi.org/10.1016/j.patcog.2025.112369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating in open-world environments requires recognizing known categories and discovering new ones, especially in ultra-fine-grained task, where distinguishing similar categories is challenging. The task of Ultra-Fine-Grained Novel Class Discovery (UFG-NCD) intensifies this challenge by requiring systems to identify previously unseen classes within unlabeled data. However, existing UFG-NCD methods fall short in extracting critical visual cues and efficiently transferring knowledge from known to novel categories. To overcome these limitations, this paper proposes Fourier-Enhanced Semi-supervised Proxy Learning (FESPL), a novel framework for UFG-NCD. FESPL incorporates a Fourier amplitude guided block that leverages frequency domain analysis to capture high-frequency details often missed by traditional approaches, enhancing ultra-fine-grained discrimination. Additionally, the semi-supervised proxy learning strategy maximizes information extraction from limited labeled data and promotes robust generalization across known and unseen categories. Our approach achieves substantial improvements in both novel category discovery and known category classification on seven popular UFG-NCD datasets, with average performance gains of 10.41 % in the accuracy of the old class and 4.27 % in the accuracy of the new class in task-agnostic evaluation, while with average performance gains of 4.40 % in clustering accuracy on the unlabeled training data in task-aware evaluation.},
  archive      = {J_PR},
  author       = {Qiupu Chen and Hongkui Jiang and Lin Jiao and Zhou Li and Taosheng Xu and Xue Wang and Rujing Wang},
  doi          = {10.1016/j.patcog.2025.112369},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112369},
  shortjournal = {Pattern Recognition},
  title        = {Fourier-enhanced semi-supervised proxy learning for ultra-fine-grained novel class discovery},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive weighted active contour based HRNet for underwater image segmentation. <em>PR</em>, <em>172</em>, 112368. (<a href='https://doi.org/10.1016/j.patcog.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acquiring optimal results in underwater environments remains challenging due to light absorption, scattering, and suspended particles. Furthermore, the low-resolution outputs from traditional semantic segmentation often result in spatial information loss and blurred segmentation boundaries. To address these issues, we first propose a low-level image enhancement preprocessing module as an independent preliminary stage to improve underwater image quality, thereby enhancing subsequent high-level semantic segmentation performance. Second, leveraging the region-based active contour model-which is independent of image gradients and adept at handling complex contour topology changes-we design a novel level set function to serve as the level set in the geometric active contour model. While this new level set exhibits formal similarity to classical level sets in representing binary segmentation contours, its formulation is derived from network prediction outputs. Third, we construct an adaptive weighted active contour energy function as a loss function within HRNet for multi-class segmentation. This loss function preserves geometric information while penalizing deviations between network-predicted probabilities and ground truth, effectively mitigating spatial information loss and optimizing boundary. Comparative experiments demonstrate that our model outperforms classical methods on objective metrics including mIoU and mPA.},
  archive      = {J_PR},
  author       = {Bo Chen and Jing Ji and Junwei Li and Xiaoli Sun and Feng Gong},
  doi          = {10.1016/j.patcog.2025.112368},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112368},
  shortjournal = {Pattern Recognition},
  title        = {An adaptive weighted active contour based HRNet for underwater image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BORT2: Bi-level optimization for robust target training in multi-source domain adaptation. <em>PR</em>, <em>172</em>, 112367. (<a href='https://doi.org/10.1016/j.patcog.2025.112367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both conventional and source-free multi-source domain adaptation (MSDA) tasks often face bias toward source domains, because more numerous labeled data in these domains, compared with a single unlabeled target domain, can dominate the training process. To alleviate the bias, target adaptation techniques train a target model on the pseudo-labeled target domain data only, with the source-domain-biased models used as the labeling function for pseudo-label generation. However, the pseudo labels may contain noise and harm performance when directly used for supervision. To tackle label noise, we introduce a novel Bi-level Optimization for Robust Target Training (BORT 2 ) scheme. BORT 2 trains a noise-robust target model on pseudo-labeled target data only and meanwhile updates the labeling function (i.e., the source-domain-biased models) to improve pseudo-label quality. Specifically, the target model is a stochastic network designed to be robust to label noise. Such a stochastic network exploits a Gaussian distribution to model the feature of each target instance and deploys an entropy maximization regularizer to the Gaussian to quantify the uncertainty of each pseudo-label, where the uncertainty is utilized to mitigate the negative effects of label noise. In addition, BORT 2 leverages the entropy to update the labeling function for better pseudo-label quality. Updating both the labeling function and the stochastic network involves a nested bi-level optimization problem, addressed using implicit differentiation. Extensive experiments demonstrate that BORT 2 achieves state-of-the-art performance for both conventional and source-free MSDA, as verified on Office-Home, Office-Caltech, PACS, Digit-Five, and the large-scale DomainNet datasets.},
  archive      = {J_PR},
  author       = {Zhongying Deng and Da Li and Xiaojiang Peng and Yi-Zhe Song and Tao Xiang},
  doi          = {10.1016/j.patcog.2025.112367},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112367},
  shortjournal = {Pattern Recognition},
  title        = {BORT2: Bi-level optimization for robust target training in multi-source domain adaptation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ultra-efficient 3D shape reconstruction: Line-coded absolute phase unwrapping algorithm. <em>PR</em>, <em>172</em>, 112366. (<a href='https://doi.org/10.1016/j.patcog.2025.112366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Absolute phase unwrapping-based fringe projection profilometry (APU-FPP) has the advantages of pixel-wise calculation, high precision, and full-field sensing of 3D shape information. To the best of our knowledge, existing APU-FPP methods have a general contradiction between accuracy and efficiency because of projecting extra auxiliary coded fringes (ACFs). In this paper, a line-coded absolute phase unwrapping (LCAPU) algorithm is presented for absolute 3D shape reconstruction of the scene with non-uniform reflectivity and complex surfaces. Firstly, a sequence of single-pixel lines is successively embedded into two sets of 3-step phase-shifting patterns to mark fringe periods, which can thoroughly avoid extra ACFs to disrupt the coherence of adjacent morphological information. Secondly, two line-coded phase-shifting patterns with the same phase shift are used to recognize the corresponding coded lines containing the fringe order cue, which can be simultaneously used to guide fringe mutual compensation, thereby extracting a high-quality phase. Finally, according to the pixel positions and the fringe indices of the decoded lines, a multi-layer decoding (MLD) algorithm is developed to iteratively generate a fringe order map, which can adapt to the randomness of morphological changes. Compared to other methods, the proposed LCAPU can not only perform a one-shot 3D shape reconstruction with a single image acquisition, but also automatically correct phase errors, balancing ultra-efficiency and high accuracy. Experimental results demonstrate the superior performance and the practical application potential in dynamic complex scenes.},
  archive      = {J_PR},
  author       = {Haihua An and Yiping Cao and Hechen Zhang},
  doi          = {10.1016/j.patcog.2025.112366},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112366},
  shortjournal = {Pattern Recognition},
  title        = {Ultra-efficient 3D shape reconstruction: Line-coded absolute phase unwrapping algorithm},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning label-specific features for multi-dimensional classification. <em>PR</em>, <em>172</em>, 112365. (<a href='https://doi.org/10.1016/j.patcog.2025.112365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-dimensional classification (MDC), instances are associated with multiple class variables that are assumed in the output space, and each class variable corresponds to one heterogeneous class space and characterizes the objects’ semantics from one dimension. Learning from MDC examples poses challenges due to the heterogeneity of class spaces, since the outputs from different class spaces are not directly comparable. Moreover, existing approaches often use identical data representation for all labels in a class, which may lead to suboptimal results as each label might be determined by its own specific characteristics. Critically, the inherent incomparability of raw heterogeneous labels prevents existing methods from effectively capturing label correlations, which are essential for guiding feature learning. In this paper, we propose a novel algorithm named LEAD, i.e., learning Label-spEcific feAtures for multi-Dimensional classification. LEAD first resolves label heterogeneity by transforming the original output space into a unified encoded label space through one-hot label encoding. This critical alignment enables explicit extraction of label correlations from the encoded space. To enhance the reliability of the estimation of label correlations, LEAD then leverages feature-space manifold structures via locally linear embedding, propagating labeling information across similar instances to counteract sparsity. Finally, LEAD jointly learns label-specific feature representations and constructs the classifier through sparse learning while incorporating label correlations. Experimental comparisons on fifteen datasets demonstrate that our proposed method outperforms state-of-the-art multi-dimensional classification methods. The code is available at https://github.com/ZhangZan-source/LEAD .},
  archive      = {J_PR},
  author       = {Zan Zhang and Jialin Zhou and Jialu Yao and Lin Liu and Jiuyong Li and Lei Li and Xindong Wu},
  doi          = {10.1016/j.patcog.2025.112365},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112365},
  shortjournal = {Pattern Recognition},
  title        = {Learning label-specific features for multi-dimensional classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TSAR: A two-stage approach to motion artifact reduction in OCTA images. <em>PR</em>, <em>172</em>, 112364. (<a href='https://doi.org/10.1016/j.patcog.2025.112364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical Coherence Tomography Angiography (OCTA) is an innovative and non-invasive imaging technique that leverages motion contrast imaging to generate angiographic images from high-resolution volumetric blood flow data rapidly. However, OCTA imaging is vulnerable to various artifacts induced by eye movements, including displacement artifacts, duplicated scanning artifacts, and white line artifacts. Previous methods that attempted to mitigate eye motion artifacts necessitated costly hardware upgrades. However, despite the availability of advanced eye-tracking hardware and software correction in commercial machines, motion artifacts persist in real-world usage. Recently developed cost-effective learning-based methods only focus on the removal of white line artifacts while neglecting the displacement artifacts and duplicated scanning artifacts. To address this challenge, we propose a comprehensive framework, TSAR, to remove three types of eye motion artifacts in OCTA images. In the first stage, we leverage the intrinsic axial and directional attributes of these artifacts in the first phase to develop an innovative hierarchical transformer network. This network is designed to capture global-wise, local-wise, and vertical-wise features effectively while also removing displacement and duplicate scanning artifacts. Afterward, we leverage the contextual information and develop a residual conditional diffusion model (RCDM) to remove the white line artifacts. By applying our TSAR to the degraded OCTA images, we aim to eliminate all three types of motion artifacts. We evaluate the superior performance of our proposed methodology in artifact removal and image quality enhancement compared to other methods by conducting experiments on both synthetic and real-world OCTA images. The code is available at https://github.com/btma48/TSAR},
  archive      = {J_PR},
  author       = {Benteng Ma and Xiaomeng Li and Xu Lin and Xiaoyu Bai and Dongping Shao and Chubin Ou and Lin An and Jia Qin and Kwang-Ting Cheng},
  doi          = {10.1016/j.patcog.2025.112364},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112364},
  shortjournal = {Pattern Recognition},
  title        = {TSAR: A two-stage approach to motion artifact reduction in OCTA images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quaternionic reweighted amplitude flow for phase retrieval in image reconstruction. <em>PR</em>, <em>172</em>, 112363. (<a href='https://doi.org/10.1016/j.patcog.2025.112363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternionic signal processing provides powerful tools for efficiently managing color signals by preserving the intrinsic correlations among signal dimensions through quaternion algebra. In this paper, we address the quaternionic phase retrieval problem by systematically developing novel algorithms based on an amplitude-based model. Specifically, we propose the Quaternionic Reweighted Amplitude Flow (QRAF) algorithm, which is further enhanced by three of its variants: incremental, accelerated, and adapted QRAF algorithms. In addition, we introduce the Quaternionic Perturbed Amplitude Flow (QPAF) algorithm, which has linear convergence. Extensive numerical experiments on both synthetic data and real images demonstrate that our proposed methods significantly improve recovery performance and computational efficiency compared to state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Ren Hu and Pan Lian},
  doi          = {10.1016/j.patcog.2025.112363},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112363},
  shortjournal = {Pattern Recognition},
  title        = {Quaternionic reweighted amplitude flow for phase retrieval in image reconstruction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust scene text understanding with OCR token and word alignment for text-VQA and text-caption. <em>PR</em>, <em>172</em>, 112362. (<a href='https://doi.org/10.1016/j.patcog.2025.112362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve vision-language tasks incorporating scene text, such as Text-VQA and Text-Caption, recognizing and understanding scene text within image is the first priority. However, the scene text recognized by Optical Character Recognition (OCR) systems often includes spelling errors, such as “pepsi” being recognized as “peosi”. These OCR errors are one of the major challenges for Text-VQA and Text-Caption systems. To address this, we propose a novel multi-modal OCR Token and Word Alignment (TWA) method to alleviate OCR errors in these tasks. First, we artificially create the misspelled OCR tokens and render them onto the RGB images, which can effectively simulates OCR errors. Second, we propose an OCR token-word contrastive learning task to pre-train OCR token representation, making the system more robust to OCR errors. Finally, we introduce a vocabulary predictor with character-level semantic matching, which enables the model to recover the correct word from the vocabulary even with misspelled OCR tokens. A variety of experimental evaluations demonstrate that our method outperforms the state-of-the-art methods on both Text-VQA and Text-Caption datasets.},
  archive      = {J_PR},
  author       = {Zan-Xia Jin and Pinle Qin and Suzhen Lin and Jia Qin and Shuangjiao Zhai and Jianchao Zeng and Xu-Cheng Yin},
  doi          = {10.1016/j.patcog.2025.112362},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112362},
  shortjournal = {Pattern Recognition},
  title        = {Robust scene text understanding with OCR token and word alignment for text-VQA and text-caption},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prior tokenization-based interactive segmentation with vision transformers. <em>PR</em>, <em>172</em>, 112361. (<a href='https://doi.org/10.1016/j.patcog.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively leveraging the provided priors is crucial for interactive segmentation. Existing approaches typically encode clicks via distance-based maps, which are then concatenated or added to the original image as network input. However, these methods do not fully exploit the semantic information embedded in the provided priors, leading to confusion in the feature distribution of different targets and reducing the segmentation quality. To address this issue, we propose a prior tokenization-based interactive segmentation method that uses simple Vision Transformers. By extending the original image tokens with prior tokens, each token represents the semantic features of the foreground and background related to the priors. These tokens participate in the self-attention operation alongside regular image tokens, gradually extracting semantic features from the image tokens to the prior tokens. In addition, we introduce a discriminative loss function to enforce inter-class separation and intra-class compactness of the prior tokens. Subsequently, we employ a cross-attention mechanism to couple the prior tokens with the regular image block token features, ensuring that the features extracted by the network are aligned with the user’s intent. Finally, we use the register method to suppress artifacts and enhance the segmentation performance further. Extensive experiments demonstrate that our method achieves superior interaction efficiency, robustness, and generalization ability across various medical image segmentation benchmarks. The source codes are available at https://github.com/dzyha2011/PT-SimpleClick},
  archive      = {J_PR},
  author       = {Zongyuan Ding and Boyu Wang and Hongyuan Wang and Tao Wang},
  doi          = {10.1016/j.patcog.2025.112361},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112361},
  shortjournal = {Pattern Recognition},
  title        = {Prior tokenization-based interactive segmentation with vision transformers},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CTNet: Color transformation network for low-light image enhancement. <em>PR</em>, <em>172</em>, 112360. (<a href='https://doi.org/10.1016/j.patcog.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light images are often plagued by low visibility, poor contrast, and high noise levels, which significantly impair both subjective visual quality and the performance of downstream tasks. Existing enhancement methods typically struggle with color-related degradations such as color casting, artifacts, and distortion. To address these challenges, we propose an end-to-end Color Transformation Network for low-light image enhancement, with a specific focus on improving color restoration. By leveraging the complementary strengths of the HSV and RGB color spaces in capturing color attributes, our approach enables effective interaction between these color spaces at the feature level. The HSV branch simultaneously enhances the V component while extracting features from the H and S components, thereby providing a more comprehensive set of cues for color recovery. To facilitate interaction, we design a learnable Color Transformation Block that bridges the HSV and RGB feature domains, effectively simulating the HSV-to-RGB conversion. Furthermore, a Cross-Integration Block, employing an attention-based cross-guidance mechanism, enables bi-directional information flow between the two color spaces. Extensive experiments on both real and synthetic datasets demonstrate that our method achieves superior performance, surpassing existing approaches both qualitatively and quantitatively. The project is available at https://github.com/1013990424/CTNet .},
  archive      = {J_PR},
  author       = {Lidong Xie and Runmin Cong and Ju Dai and Wenhan Yang and Junjun Pan and Hao Wu},
  doi          = {10.1016/j.patcog.2025.112360},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112360},
  shortjournal = {Pattern Recognition},
  title        = {CTNet: Color transformation network for low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint adversarial attack: An effective approach to evaluate robustness of 3D object tracking. <em>PR</em>, <em>172</em>, 112359. (<a href='https://doi.org/10.1016/j.patcog.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have widely been used in 3D object tracking, thanks to its superior capabilities to learn from geometric training samples and locate tracking targets. Although the DNN based trackers show vulnerability to adversarial examples, their robustness in real-world scenarios with potentially complex data defects has rarely been studied. To this end, a joint adversarial attack method against 3D object tracking is proposed, which simulates defects of the point cloud data in the form of point filtration and perturbation simultaneously. Specifically, a voxel-based point filtration module is designed to filter points of the tracking template, which is described by the voxel-wise binary distribution regarding the density of the point cloud. Furthermore, a voxel-based point perturbation module adds voxel-wise perturbations to the filtered template, whose direction is constrained by local geometrical information of the template. Experiments conducted on popular 3D trackers demonstrate that the proposed joint attack have decreased the success and precision of existing 3D trackers by 30.2% and 35.4% respectively in average, which made an improvement of 30.5% over existing attack methods.},
  archive      = {J_PR},
  author       = {Riran Cheng and Xupeng Wang and Ferdous Sohel and Hang Lei},
  doi          = {10.1016/j.patcog.2025.112359},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112359},
  shortjournal = {Pattern Recognition},
  title        = {Joint adversarial attack: An effective approach to evaluate robustness of 3D object tracking},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-channel blur invariants of color and multispectral images. <em>PR</em>, <em>172</em>, 112358. (<a href='https://doi.org/10.1016/j.patcog.2025.112358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with the recognition of blurred color/multispectral images directly without any deblurring. We present a general theory of invariants of multispectral images with respect to blur. The paper is a significant non-trivial extension of the recent theory of blur invariants of graylevel images. The main original contribution of the paper lies in introducing cross-channel blur invariants in Fourier domain. We also developed an algorithm for their stable and fast calculation in the moment domain. Moreover, the cross-channel invariants can be found for blurs for which single-channel invariants do not exist. The experiments on simulated and real data demonstrate that incorporating the new cross-channel invariants significantly improves the recognition power and surpasses other existing approaches. The outlook for a possible implementation of the blur invariants into neural networks is briefly sketched in the conclusion.},
  archive      = {J_PR},
  author       = {Václav Košík and Jan Flusser and Filip Šroubek},
  doi          = {10.1016/j.patcog.2025.112358},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112358},
  shortjournal = {Pattern Recognition},
  title        = {Cross-channel blur invariants of color and multispectral images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniForCE: The unimodality forest method for clustering and estimation of the number of clusters. <em>PR</em>, <em>172</em>, 112357. (<a href='https://doi.org/10.1016/j.patcog.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the number of clusters k while clustering the data is a challenging task. An incorrect cluster assumption indicates that the number of clusters k gets wrongly estimated. Consequently, the model fitting becomes less important. In this work, we focus on the concept of unimodality and propose a flexible cluster definition called locally unimodal cluster . A locally unimodal cluster extends for as long as unimodality is locally preserved across pairs of subclusters of the data. Then, we propose the UniForCE method for locally unimodal clustering. The method starts with an initial overclustering of the data and relies on the unimodality graph that connects subclusters forming unimodal pairs. Such pairs are identified using an appropriate statistical test. UniForCE identifies maximal locally unimodal clusters that are statistically significant by computing a spanning forest in the unimodality graph. Experimental results on both real and synthetic datasets illustrate that the proposed methodology is particularly flexible and robust in discovering regular and highly complex cluster shapes. Most importantly, it automatically provides an adequate estimation of the number of clusters.},
  archive      = {J_PR},
  author       = {Georgios Vardakas and Argyris Kalogeratos and Aristidis Likas},
  doi          = {10.1016/j.patcog.2025.112357},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112357},
  shortjournal = {Pattern Recognition},
  title        = {UniForCE: The unimodality forest method for clustering and estimation of the number of clusters},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SequencePAR: Understanding pedestrian attributes via a sequence generation paradigm. <em>PR</em>, <em>172</em>, 112356. (<a href='https://doi.org/10.1016/j.patcog.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current pedestrian attribute recognition (PAR) algorithms use multi-label or multi-task learning frameworks with specific classification heads. These models often struggle with imbalanced data and noisy samples. Inspired by the success of generative models, we propose Sequence Pedestrian Attribute Recognition (SequencePAR), a novel sequence generation paradigm for PAR. SequencePAR extracts pedestrian features using a language-image pre-trained model and embeds the attribute set into query tokens guided by text prompts. A Transformer decoder generates human attributes by integrating visual features and attribute query tokens. The masked multi-head attention layer in the decoder prevents the model from predicting the next attribute during training. The extensive experiments on multiple PAR datasets validate the effectiveness of SequencePAR. Specifically, we achieve 84.92 %, 90.44 %, 90.73 %, and 90.46 % in accuracy, precision, recall, and F1-score on the PETA dataset.},
  archive      = {J_PR},
  author       = {Jiandong Jin and Xiao Wang and Yin Lin and Chenglong Li and Lili Huang and Aihua Zheng and Jin Tang},
  doi          = {10.1016/j.patcog.2025.112356},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112356},
  shortjournal = {Pattern Recognition},
  title        = {SequencePAR: Understanding pedestrian attributes via a sequence generation paradigm},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SATE: Efficient knowledge distillation with implicit student-aware teacher ensembles. <em>PR</em>, <em>172</em>, 112355. (<a href='https://doi.org/10.1016/j.patcog.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent findings suggest that with the same teacher architecture, a fully converged or “stronger” checkpoint surprisingly leads to a worse student. This can be explained by the Information Bottleneck (IB) principle, as the features of a weaker teacher transfer more “dark” knowledge because they maintain higher mutual information with the inputs. Meanwhile, various works have shown that severe teacher-student structural disparity or capability mismatch often leads to worse student performance. To deal with these issues, we propose a generalizable and efficient Knowledge Distillation (KD) framework with implicit Student-Aware Teacher Ensembles (SATE). The SATE framework simultaneously trains a student network and a student-aware intermediate teacher as a learning companion. With the proposed co-training strategy, the intermediate teacher is trained gradually and forms implicit ensembles of weaker teachers along the learning process. Such a design enables the student model to retain more dark knowledge for better generalization ability. The proposed framework improves the training scheme in a plug-and-play way so that it can be applied to improve various classic and state-of-the-art KD methods on both intra-domain (up to 2.184 % ) and cross-domain (up to 7.358 % ) settings, under a diversified configurations on teacher-student architectures, and achieves a major efficient advantage over other generic frameworks. The code is available at https://github.com/diqichen91/SATE.git .},
  archive      = {J_PR},
  author       = {Diqi Chen and Yang Li and Jiajun Liu and Jun Zhou and Yongsheng Gao},
  doi          = {10.1016/j.patcog.2025.112355},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112355},
  shortjournal = {Pattern Recognition},
  title        = {SATE: Efficient knowledge distillation with implicit student-aware teacher ensembles},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative attention based weighted sparse representation of visual objects in complex scenarios. <em>PR</em>, <em>172</em>, 112354. (<a href='https://doi.org/10.1016/j.patcog.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse subspace representation (SSR) is an attractive technique for subspace segmentation of high-dimensional data through a self-representation manner to reveal its algebraic structure. Numerous generalizations of SSR have been developed to meet different applications. However, a fatal limitation in those extensions is their neglect of feature weights in visual samples, which play crucial roles in segmenting or recognizing specific objects. This paper introduces a discriminative attention based weighted SSR model to tackle visual objects. In the proposed model, the prior information is empirically constructed for intra-cluster features and inter-cluster ones, aided by the sparse representation of samples. An attention mechanism is introduced to learn weights of features of samples. The attention based weights of objects in samples and sparse representation of samples are collaboratively learned from the prior information. A hard version and a soft one of attention based sparse subspace representation, abbreviated as HDAWSSR and SDAWSSR, are specified by assigning attention of features by a Boolean matrix and a fuzzy matrix. Algorithms for solving both models are meticulously developed, respectively. Applications of both algorithms in clustering and moving object detection within high-dimensional image data are investigated. Experimental results show that both models outperform the state-of-the-art subspace based segmentation methods.},
  archive      = {J_PR},
  author       = {Ge Yang and Tingquan Deng and Ming Yang and Changzhong Wang},
  doi          = {10.1016/j.patcog.2025.112354},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112354},
  shortjournal = {Pattern Recognition},
  title        = {Discriminative attention based weighted sparse representation of visual objects in complex scenarios},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale feature sharing and collaborative sampling for unsupervised vehicle re-identification. <em>PR</em>, <em>172</em>, 112353. (<a href='https://doi.org/10.1016/j.patcog.2025.112353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle Re-identification (Re-ID) retrieves target vehicle images from non-overlapping cameras. To address label noise in pseudo-labels, we propose the Multi-scale Feature Sharing and Collaborative Sampling (MFSCS) method. Specifically, the designed multi-scale feature sharing module moves beyond reliance on global features, efficiently promoting the exchange of characteristics between global and local aspects. This shared feature approach collectively mitigates the label noise arising from clustering. Recognizing that clustering methods are highly sensitive to outliers, we introduce a collaborative sampling module that cooperatively combines samples in the clustering process before training the model. This cooperative sampling module is better equipped to handle outliers in the samples and update label information more efficiently. As a result, it asymptotically improves the accuracy and stability of the model. The effectiveness of the proposed method in terms of performance is demonstrated through extensive experiments conducted on both the latest challenging truck Re-ID dataset, Truck-ID and VeRi-776.},
  archive      = {J_PR},
  author       = {Jia-Jia Li and Si-Bao Chen and Chris Ding and Bin Luo},
  doi          = {10.1016/j.patcog.2025.112353},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112353},
  shortjournal = {Pattern Recognition},
  title        = {Multi-scale feature sharing and collaborative sampling for unsupervised vehicle re-identification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). You look from old classes: Towards accurate few shot class-incremental learning. <em>PR</em>, <em>172</em>, 112352. (<a href='https://doi.org/10.1016/j.patcog.2025.112352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) is a common but difficult task that faces two challenges: catastrophic forgetting of old classes and insufficient learning of new classes with limited samples. Recent wisdom focuses on preventing catastrophic forgetting yet overlooks the limited samples issue, resulting in poor new class performance. In this paper, we argue that old class samples contain rich knowledge, which can be exploited to supplement the learning of new classes. To this end, we propose to Look from Old Classes (YLOC) for FSCIL, enhancing both the base and incremental sessions. In the base session, we develop a prototype centered loss (PCL) to obtain a compact distribution of old classes. During incremental sessions, we devise a prototype augmentation learning (PAL) method to aid the learning of new classes by exploiting old classes. Extensive experiments on three FSCIL benchmark datasets demonstrate the superiority of our method.},
  archive      = {J_PR},
  author       = {Yijie Hu and Kaizhu Huang and Wei Wang and Xiaowei Huang and Qiufeng Wang},
  doi          = {10.1016/j.patcog.2025.112352},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112352},
  shortjournal = {Pattern Recognition},
  title        = {You look from old classes: Towards accurate few shot class-incremental learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-decoder collaborative learning with multi-hybrid view augmentation for self-supervised 3D action recognition. <em>PR</em>, <em>172</em>, 112351. (<a href='https://doi.org/10.1016/j.patcog.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised methods, including contrastive learning and masked skeleton modeling, have demonstrated considerable potential in the field of skeleton-based action recognition. While contrastive learning captures fine-grained details at the instance level, masked skeleton modeling emphasizes joint-level features. Recent studies have begun to combine these two approaches. However, existing combination methods primarily focus on integrating the tasks within the skeleton space. Moreover, existing contrastive learning methods often fail to exploit the comprehensive interaction information in skeletal structures, resulting in suboptimal performance when recognizing actions involving multiple individuals. To overcome these limitations, we introduce the Dual-Decoder Collaborative Learning (DDC) with Multi-Hybrid View Augmentation (MHGNA) method, which connects these two tasks across multiple spaces. Specifically, the masked skeleton modeling task provides diverse views for the contrastive learning task in the skeleton space, while the contrastive method aligns the features generated by both tasks within the feature space. We further present an innovative view augmentation method that enhances the model’s capacity to understand human interaction relationships by shuffling and replacing data across temporal, spatial, and personal dimensions. Extensive experiments on four downstream tasks across three large-scale datasets demonstrate that DDC exhibits stronger representational capabilities compared to state-of-the-art methods. Our code is available at https://github.com/Yingfei-Wu/DDC .},
  archive      = {J_PR},
  author       = {Wenming Cao and Yingfei Wu and Xinpeng Yin},
  doi          = {10.1016/j.patcog.2025.112351},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112351},
  shortjournal = {Pattern Recognition},
  title        = {Dual-decoder collaborative learning with multi-hybrid view augmentation for self-supervised 3D action recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). D3PD: Dual distillation and dynamic fusion for camera-radar 3D perception. <em>PR</em>, <em>172</em>, 112350. (<a href='https://doi.org/10.1016/j.patcog.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving perception is driving rapid advancements in Bird’s-Eye-View (BEV) technology. The synergy of surround-view imagery and radar is seen as a cost-friendly approach that enhances the understanding of driving scenarios. However, current methods for fusing radar and camera features lack effective environmental perception guidance and dynamic adjustment capabilities, which restricts their performance in real-world scenarios. In this paper, we introduce the D3PD framework, which combines fusion techniques with knowledge distillation to tackle the dynamic guidance deficit in existing radar-camera fusion methods. Our method includes two key modules: Radar-Camera Feature Enhancement (RCFE) and Dual Distillation Knowledge Transfer. The RCFE module enhances the areas of interest in BEV, addressing the poor object perception performance of single-modal features. The Dual Distillation Knowledge Transfer includes four distinct modules: Camera Radar Sparse Distillation (CRSD) for sparse feature knowledge transfer and teacher-student network feature alignment. Position-guided Sampling Distillation(SamD) for refining the knowledge transfer of fused features through dynamic sampling. Detection Constraint Result Distillation (DcRD) for strengthening the positional correlation between teacher and student network outputs in forward propagation, achieving more precise detection perception. and Self-learning Mask Focused Distillation (SMFD) for focusing perception detection results on knowledge transfer through self-learning, concentrating on the reinforcement of local key areas. The D3PD framework outperforms existing methods on the nuScenes benchmark, achieving 49.6 % mAP and 59.2 % NDS performance. Moreover, in the occupancy prediction task, D3PD-Occ has achieved an advanced performance of 37.94 % mIoU. This provides insights for the design and model training of camera and radar-based 3D object detection and occupancy network prediction methods. The code will be available at https://github.com/no-Name128/D3PD .},
  archive      = {J_PR},
  author       = {Junyin Wang and Chenghu Du and Tongao Ge and Bingyi Liu and Shengwu Xiong},
  doi          = {10.1016/j.patcog.2025.112350},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112350},
  shortjournal = {Pattern Recognition},
  title        = {D3PD: Dual distillation and dynamic fusion for camera-radar 3D perception},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TBiGAN-based parallel networks for remaining useful life prediction of multi-stage degraded bearings. <em>PR</em>, <em>172</em>, 112349. (<a href='https://doi.org/10.1016/j.patcog.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of the remaining useful life (RUL) of rolling bearings is crucial for ensuring the safe and reliable operation of rotating machinery. However, existing methods generally overlook the correlation between different degradation stages and RUL, thereby limiting the accuracy of RUL prediction for rolling bearings. To address this challenge, a novel adaptive RUL prediction method for multi-stage degrading rolling bearings is proposed. Specifically, a new Transformer-based network is designed to classify the degradation stages of bearings. Additionally, a parallel RUL prediction model incorporating attention mechanisms is introduced, which integrates Temporal Convolutional Networks (TCN) and Bidirectional Gated Recurrent Units (BiGRU) to capture degradation features from multiple dimensions automatically and enhance the model’s ability to capture long-term dependencies in sequence tasks. Finally, the RUL prediction results from different stages are adaptively integrated using a smoothing technique to generate the final RUL. The accuracy and superiority of the proposed method are validated on the PHM2012 bearing dataset.},
  archive      = {J_PR},
  author       = {Zheng Jianfei and Chen Dongnan and Hu Changhua and Han Qihui and Pei Hong},
  doi          = {10.1016/j.patcog.2025.112349},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112349},
  shortjournal = {Pattern Recognition},
  title        = {TBiGAN-based parallel networks for remaining useful life prediction of multi-stage degraded bearings},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MChartQA and mChartQABench: A multimodal-only solution for complex chart question-answering. <em>PR</em>, <em>172</em>, 112348. (<a href='https://doi.org/10.1016/j.patcog.2025.112348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal chart question-answering (QA) is essential for applications such as financial report analysis, decision support, and invoice parsing. Current methods typically convert charts to text for processing by large language models (LLMs) or use direct multimodal processing. This raises an important question: under what conditions is a multimodal approach essential for chart question-answering? We observe that these traditional approaches often struggle with complex color patterns, structural intricacies, and implicit numerical data. Yet, limited research addresses these challenges. To bridge this gap, we introduce a new multimodal chart dataset, mChartQABench, constructed by consolidating data from existing open-source datasets to address challenges with color, structure, and textless chart data. To handle these complex multimodal scenarios effectively, we propose mChartQA, a framework integrating the advanced language processing of LLMs with a state-of-the-art table-to-text engine. This framework excels in aligning visual and textual data, enhancing deep reasoning and contextual understanding within charts. Experimental results show that mChartQA achieves superior performance across four datasets, with over 20 % overall accuracy improvement on mChartQABench.},
  archive      = {J_PR},
  author       = {Jingxuan Wei and Nan Xu and Guiyong Chang and Yin Luo and Bihui Yu and Ruifeng Guo},
  doi          = {10.1016/j.patcog.2025.112348},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112348},
  shortjournal = {Pattern Recognition},
  title        = {MChartQA and mChartQABench: A multimodal-only solution for complex chart question-answering},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Copula-based conformal prediction for prioritized heterogeneous multi-task learning. <em>PR</em>, <em>172</em>, 112347. (<a href='https://doi.org/10.1016/j.patcog.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction (CP) has emerged as a standard for finite-sample and distribution-free uncertainty quantification (UQ). Although CP is widely used as a post-processing step (on the outputs of machine learning models) to produce reliable set-valued predictions, it is still challenging to post-process heterogeneous (i.e., categorical & numerical) predictions since the traditional CP procedures are either exclusively designed for classification or only tailored to regression. This article proposes the use of a simple yet novel copula-based CP method that jointly produces (discrete) set-valued predictions and (continuous) interval-valued predictions. This approach offers flexibility by allowing the prioritization of specific outputs’ reliability and applies to general heterogeneous multi-task problems. We demonstrate its effectiveness in the context of autonomous driving, on two popular multi-class object detection benchmarks, where it effectively infers set values for object classes and bounding boxes with the specified confidence levels. Experimental results validate our method’s ability in handling heterogeneous multi-task conformal predictions: we achieve high confidence levels without losing the informativeness of the prediction regions.},
  archive      = {J_PR},
  author       = {Bruce Cyusa Mukama and Soundouss Messoudi and Sébastien Destercke and Sylvain Rousseau},
  doi          = {10.1016/j.patcog.2025.112347},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112347},
  shortjournal = {Pattern Recognition},
  title        = {Copula-based conformal prediction for prioritized heterogeneous multi-task learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep spatio-temporal architecture for dynamic ECN analysis with granger causality based causal discovery. <em>PR</em>, <em>172</em>, 112346. (<a href='https://doi.org/10.1016/j.patcog.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurobrain science provides the motivation for research on causal modeling. The existing causal discovery methods have shown promising results in effective connectivity network analysis, however, they often overlook the dynamics of causality, in addition to the incorporation of spatio-temporal information in data. Dynamic effective connectivity networks (dECNs) reveal the changing directed brain activity and the dynamic causal influences among brain regions, which facilitate the identification of individual differences and enhance the understanding of human brain. To learn dynamic causality, we propose a deep spatio-temporal fusion architecture, which employs a dynamic causal deep encoder to incorporate spatio-temporal information into dynamic causality modeling, and a dynamic causal deep decoder to verify the discovered causality. The effectiveness of the proposed method is first illustrated with simulated data. Then, experimental results from Philadelphia Neurodevelopmental Cohort (PNC) demonstrate the superiority of the proposed method in inferring dECNs, which reveal the dynamic evolution of directed flow between brain regions. The analysis shows the difference of dECNs between young adults and children. Specifically, the directed brain functional networks transit from fluctuating undifferentiated systems to more stable specialized networks as one grows. This observation provides further evidence on the modularization and adaptation of brain networks during development, leading to higher cognitive abilities observed in young adults.},
  archive      = {J_PR},
  author       = {Faming Xu and Yiding Wang and Gang Qu and Vince D. Calhoun and Julia M. Stephen and Tony W. Wilson and Yu-Ping Wang and Chen Qiao},
  doi          = {10.1016/j.patcog.2025.112346},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112346},
  shortjournal = {Pattern Recognition},
  title        = {A deep spatio-temporal architecture for dynamic ECN analysis with granger causality based causal discovery},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised domain adaptation via style-aware self-intermediate domain. <em>PR</em>, <em>172</em>, 112344. (<a href='https://doi.org/10.1016/j.patcog.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) has garnered significant attention for its ability to transfer knowledge from a label-rich source domain to a related but unlabeled target domain, with minimizing inter-domain discrepancies being crucial, especially when a substantial gap exists between the domains. To address this, we introduce the novel Style-aware Self-Intermediate Domain (SSID), which effectively bridges large domain gaps by facilitating knowledge transfer while preserving class-discriminative information. Inspired by human transitive inference and learning capabilities, SSID connects seemingly unrelated concepts through a sequence of intermediate, auxiliary synthesized concepts. Meanwhile, an external memory bank is designed to store and update designated labeled features, ensuring the stability of class-specific and class-wise style features. Additionally, we also proposed a novel intra- and inter-domain loss functions that enhance class recognition and feature compatibility, with their convergence rigorously validated through a novel analytical approach. Comprehensive experiments demonstrate that SSID achieves accuracies of 85.4 % and 85.3 % on two widely recognized UDA benchmarks, outperforming the second-best methods by 0.94 % and 1.17 %, respectively. As a plug-and-play solution, SSID integrates seamlessly with various backbone networks, showcasing its effectiveness and versatility in domain adaptation scenarios.},
  archive      = {J_PR},
  author       = {Lianyu Wang and Meng Wang and Daoqiang Zhang and Huazhu Fu},
  doi          = {10.1016/j.patcog.2025.112344},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112344},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised domain adaptation via style-aware self-intermediate domain},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing visual representation of untrimmed videos by counteracting visuality threatening content. <em>PR</em>, <em>172</em>, 112343. (<a href='https://doi.org/10.1016/j.patcog.2025.112343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the remarkable growth of the video platform industry and the surge in video uploads, Content-Based Video Retrieval (CBVR), which finds videos on desired topics from a collection of untrimmed videos using solely the visual modality, is gaining increased attention. However, the challenge of accurate retrieval persists due to the varied and complex content in untrimmed videos, and there has been a lack of discussion on which types of content compromise visual representations. In this paper, we found that text and blur texture are of this nature, grounded in empirical observations. Indeed, in models focusing on the visual modality, both the visual structure of text (without semantics) and the smoothness of blur texture (with few edges and corners) interfere with decision-making. To address them, we propose two strategies: text-masking learning, which excludes the effect of text in the descriptor for inputs that may contain text content, and blur texture filtering, a re-scaling strategy that mitigates the impact of blur textures by exploiting the neural network’s insensitivity to the smoothed pixel-wise gradients. Furthermore, through empirical observations, we demonstrate that our proposed method effectively handles visuality-threatening content. Additionally, we show that our method can lead to state-of-the-art performance across multiple benchmarks of untrimmed videos.},
  archive      = {J_PR},
  author       = {Gwangjin Lee and Won Jo and Hyunwoo Kim and Yukyung Choi},
  doi          = {10.1016/j.patcog.2025.112343},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112343},
  shortjournal = {Pattern Recognition},
  title        = {Enhancing visual representation of untrimmed videos by counteracting visuality threatening content},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Texture-aware transformer with pose-patch mapping for occluded person re-identification. <em>PR</em>, <em>172</em>, 112341. (<a href='https://doi.org/10.1016/j.patcog.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification (re-ID) aims to retrieve the target person from occluded images captured by different cameras, where the challenges lie in identity loss caused by different types of occlusion. To alleviate the occlusion interference, some methods rely on external clues or generate more occlusion samples. However, these methods fail to address the issues of pose misalignment under extreme occlusion and identity confusion caused by non-target pedestrian occlusion. To solve these problems, we design a novel T exture-Aware T ransformer with P ose-Patch M apping (TTPM), which does not require generating any occlusion samples. Specifically, a Multi-patch Feature Encoder is proposed to encode discriminative features from inter patches and intra patches. Afterwards, the Pose-Patch Mapping is designed to construct a positional mapping between poses and patches, which highlights human patches and weakens the impact of occluded patches. Finally, to mitigate the non-target pedestrian occlusion, a Texture-Aware Decoder is introduced to perceive texture features and leverage their distinctiveness to enhance the representation of important regions. Extensive experiments show that our method achieves state-of-the-art results on Occluded-Duke and Occluded-REID datasets.},
  archive      = {J_PR},
  author       = {Dengwen Wang and Guanyu Xing and Yanli Liu},
  doi          = {10.1016/j.patcog.2025.112341},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112341},
  shortjournal = {Pattern Recognition},
  title        = {Texture-aware transformer with pose-patch mapping for occluded person re-identification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient community-aware pre-training method for graph neural networks. <em>PR</em>, <em>172</em>, 112340. (<a href='https://doi.org/10.1016/j.patcog.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While graph neural networks (GNNs) have demonstrated widespread success in various domains, their pre-training techniques lag behind those in computer vision and natural language processing, typically exhibiting limited performance gains and high computational costs. This paper introduces Community-Aware Pre-training (CAP), a novel approach that leverages the inherent community structures prevalent in real-world networks to enhance GNN pre-training efficiency and effectiveness. CAP employs a self-supervised contrastive learning framework to learn node representations that are highly discriminative of their respective communities. To further optimize the pre-training process, we introduce a Monte Carlo Tree Search-based community sampler that efficiently extracts representative subgraphs, mitigating noise and enhancing sample quality. CAP is versatile and can be applied to a broad range of node classification tasks due to the commonly existing community structures within networks. Extensive evaluations on diverse node classification benchmarks demonstrate that CAP consistently outperforms state-of-the-art methods, achieving accuracy improvements of up to 4.34 % while significantly reducing pre-training time by up to 14.87 times compared to existing techniques. Furthermore, CAP enhances the predictive confidence and visualization distinctiveness of node representations, paving a new path for effective and efficient GNN pre-training.},
  archive      = {J_PR},
  author       = {Zhenhua Huang and Wenhao Zhou and Yihang Jiang and Zhaohong Jia and Linyuan Lü and Yunjie Ma},
  doi          = {10.1016/j.patcog.2025.112340},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112340},
  shortjournal = {Pattern Recognition},
  title        = {An efficient community-aware pre-training method for graph neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction. <em>PR</em>, <em>172</em>, 112339. (<a href='https://doi.org/10.1016/j.patcog.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have made significant progress in trajectory prediction tasks but still face several critical challenges. The ordinary differential equation (ODE) solving methods used in standard diffusion models often suffer from error accumulation during multi-step iterations. Additionally, the denoising process is highly time-consuming due to the large number of computational steps, which significantly hinders inference efficiency and makes real-time applications challenging. To address these issues, we propose a diffusion-based method, DiffTrajectory, which integrates the Runge-Kutta (RK4) method, a Leap Initializer Module (LIM), and an Adaptive Dynamic Step-size Strategy (ADSS) to enhance generation accuracy and greatly optimize inference efficiency. Specifically, to tackle the problem of error accumulation, DiffTrajectory formalizes the denoising process as an ODE-solving problem and adopts the RK4 as a numerical solution. By computing multiple intermediate points at each iteration, this approach significantly reduces error accumulation. To improve the efficiency of the denoising process, DiffTrajectory introduces LIM, which leverages a pre-trained initial model to quickly generate a high-quality starting point for denoising, thereby reducing the computational burden during the initial denoising stages. Furthermore, we design the ADSS that adjusts the step size dynamically based on the results of each denoising stage, ensuring the quality of the generated results while substantially shortening inference time. Extensive experiments on the ETH/UCY and NBA datasets demonstrate that DiffTrajectory achieves substantial improvements in both accuracy and efficiency.},
  archive      = {J_PR},
  author       = {Chengcheng Li and Luqi Gong and Leiheng Xu and Xin Wang},
  doi          = {10.1016/j.patcog.2025.112339},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112339},
  shortjournal = {Pattern Recognition},
  title        = {DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A mondrian conformal predictive system with improved decision trees for uncertainty quantification under heteroscedasticity. <em>PR</em>, <em>172</em>, 112338. (<a href='https://doi.org/10.1016/j.patcog.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing application of machine learning in industrial production, model uncertainty quantification has become a critical tool to evaluate the prediction reliability and guide decision-making. The Conformal Predictive System (CPS), which generates Cumulative Distribution Functions (CDFs), provides valuable support for uncertainty quantification. However, CPS faces limitations when addressing heteroskedasticity. This paper proposes a Mondrian Conformal Predictive System (LWT-MCPS) based on an enhanced Decision Tree. The proposed approach constructs decision trees using splitting criteria derived from Levene’s test and Welch’s t -test, ensuring that the variance and mean within each partition remain as homogeneous as possible. Furthermore, it incorporates predicted values and prediction variances estimated using the k -Nearest Neighbors (KNN) as splitting features, effectively mitigating the impact of high-dimensional data on tree partitioning and enhancing the model’s ability to identify heterogeneous regions. Experiments conducted on simulated data, public datasets, and blast furnace ironmaking data demonstrate that LWT-MCPS generates CDFs with lower Continuous Ranked Probability Scores (CRPS) than traditional CPS. These results validate its significant advantages in addressing heteroskedasticity challenges.},
  archive      = {J_PR},
  author       = {Ruiyao Zhang and Ping Zhou},
  doi          = {10.1016/j.patcog.2025.112338},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112338},
  shortjournal = {Pattern Recognition},
  title        = {A mondrian conformal predictive system with improved decision trees for uncertainty quantification under heteroscedasticity},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial multi-semantic features guided spectral-friendly transformer network for hyperspectral image classification. <em>PR</em>, <em>172</em>, 112337. (<a href='https://doi.org/10.1016/j.patcog.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification (HSIC) is a foundational topic in remote sensing. However, the high correlations between bands and the spectral correlations often result in redundant data. Moreover, traditional convolutional neural networks (CNNs) compress spatial dimensions through pooling layers or strides during spatial information extraction, resulting in the loss of spatial information. To overcome these challenges, we propose a spatial multi-semantic features guided spectral-friendly Transformer network (SFTN), which effectively extracts the spectral and spatial features of HSIs. Specifically, a multi-semantic spatial attention (MsSA) module applies unidirectional spatial compression along the height and width dimensions. Thus, this module maintains spatial structure in one direction while aggregating global spatial information, thereby minimizing information loss during compression. It then employs multi-scale depth-shared 1D convolutions to capture multi-semantic spatial information. Furthermore, the spectral-friendly Transformer replaces the traditional multi-head self-attention (MHSA) with spectral correlation self-attention (ECSa), which effectively captures spectral differences and thus reduces the redundancy of spectral information. Extensive experiments on several HSI datasets show that the proposed SFTN method outperforms other state-of-the-art methods in HSIC applications. The source code for this work will be released later.},
  archive      = {J_PR},
  author       = {Xiaoyan Yu and Mingzhu Tai and Yuyang Wang and Zhenqiu Shu and Liehuang Zhu},
  doi          = {10.1016/j.patcog.2025.112337},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112337},
  shortjournal = {Pattern Recognition},
  title        = {Spatial multi-semantic features guided spectral-friendly transformer network for hyperspectral image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation. <em>PR</em>, <em>172</em>, 112336. (<a href='https://doi.org/10.1016/j.patcog.2025.112336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have become indispensable across various fields; however, their susceptibility to backdoor attacks poses significant security risks. In this paper, we propose a backdoor defense scheme based on adversarial prediction proximity and contrastive knowledge distillation. This scheme not only detects poisoned models and labels but also effectively unlearns backdoors while preserving the model’s benign functionality. Based on the observation that untargeted adversarial examples and poisoned samples exhibit proximity in feature space within poisoned models (i.e., adversarial prediction proximity), we first detect backdoors by analyzing changes in the prediction behavior of untargeted adversarial examples for models before and after fine-tuning. Next, we purify the poisoned model using a triplet loss that incorporates clean samples and untargeted adversarial examples. This process is guided by contrastive knowledge distillation, where a fine-tuned model acts as a “benign teacher”, and a backdoor-retained model serves as a “malicious teacher”, encouraging the poisoned model to align its feature representations with clean behavior. Comprehensive experimental results demonstrate that our scheme achieves high accuracy in detecting poisoned models and labels, even with limited access to clean samples. Furthermore, our scheme provides effective backdoor purification, while preserving the integrity and performance of models.},
  archive      = {J_PR},
  author       = {Lin Huang and Leo Yu Zhang and Ching-Chun Chang and Wei Wang and Chuan Qin},
  doi          = {10.1016/j.patcog.2025.112336},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112336},
  shortjournal = {Pattern Recognition},
  title        = {Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hyperspectral space transformations for texture classification. <em>PR</em>, <em>172</em>, 112335. (<a href='https://doi.org/10.1016/j.patcog.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D color space transformations are widely used in color imaging to enhance the results of various tasks, including image segmentation, object recognition, and texture classification. However, such useful transformations are much more limited in hyperspectral imaging, where images contain hundreds to thousands of spectral bands. To improve the performance of hyperspectral image analysis, we introduce four new hyperspectral space transformations in this paper: the Hyper-Chrominance-Luminance (H-CL), the Hyper-Hue-Chroma-Luminance (H-HCL), the Hyper-Hue-Saturation-Intensity (H-HSI), and the Hyper-Hue-Saturation-Value (H-HSV). These transformations extend the corresponding CL, HCL, HSI, and HSV 3D color spaces to multiple dimensions. To investigate their suitability in the context of texture classification, several well-known texture descriptors, including both theory-driven (handcrafted) and data-driven (deep learning) methods, are used in the experiments. Ten hyperspectral datasets are considered: HyTexila, SpecTex, HyperPlastic, and seven datasets extracted from the Timbers database. Among these datasets, six new ones are introduced in this paper. The proposed H-CL, H-HCL, H-HSI, and H-HSV transformations are also compared with state-of-the-art transformation strategies. The experiments conducted in this paper demonstrate the efficacy of the proposed space transformations with an accuracy improvement that can reach +43.47 %.},
  archive      = {J_PR},
  author       = {Alice Porebski and Souraya Ouaidar Hadir and Thierry Gensane and Nicolas Vandenbroucke},
  doi          = {10.1016/j.patcog.2025.112335},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112335},
  shortjournal = {Pattern Recognition},
  title        = {Hyperspectral space transformations for texture classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-target federated backdoor attack based on feature aggregation. <em>PR</em>, <em>172</em>, 112333. (<a href='https://doi.org/10.1016/j.patcog.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current federated backdoor attacks focus on collaboratively training backdoor triggers, where multiple compromised clients train their local trigger patches and then merge them into a global trigger during the inference phase. However, these methods require careful design of the shape and position of trigger patches and lack the feature interactions between trigger patches during training, resulting in poor backdoor attack success rates. Moreover, the pixels of the patches remain untruncated, thereby making abrupt areas in backdoor examples easily detectable by the detection algorithm. To this end, we propose a novel benchmark for the federated backdoor attack based on feature aggregation. Specifically, we align the dimensions of triggers with images, constrain the trigger’s pixel boundaries so that it is within a small range to avoid being detected, and aggregate trigger features from multiple compromised clients to enhance the global trigger’s ability to capture distributed data patterns. Furthermore, leveraging the intra-class attack strategy to train specific triggers for each class of samples, we propose the simultaneous generation of backdoor triggers for all target classes, significantly reducing the overall production time for triggers across all target classes and increasing the risk of the federated model being attacked. Experiments demonstrate that our method can not only bypass the detection of defense methods while patch-based methods fail, but also achieve a zero-shot backdoor attack with a success rate of 77.39 %. To the best of our knowledge, our work is the first to implement such a zero-shot attack in federated learning. Finally, we evaluate attack performance by varying the trigger’s training factors, including poison location, ratio, pixel bound, and trigger training duration (local epochs and communication rounds).},
  archive      = {J_PR},
  author       = {Lingguag Hao and Kuangrong Hao and Bing Wei and Xue-Song Tang},
  doi          = {10.1016/j.patcog.2025.112333},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112333},
  shortjournal = {Pattern Recognition},
  title        = {Multi-target federated backdoor attack based on feature aggregation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LayerMix: Enhanced data augmentation for robust deep learning. <em>PR</em>, <em>172</em>, 112332. (<a href='https://doi.org/10.1016/j.patcog.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) models have demonstrated remarkable performance across various computer vision tasks, yet their vulnerability to distribution shifts remains a critical challenge. Despite sophisticated neural network architectures, existing models often struggle to maintain consistent performance when confronted with Out-of-Distribution (OOD) samples, including natural corruptions, adversarial perturbations, and anomalous patterns. We introduce LayerMix, an innovative Data Augmentation (DA) approach that systematically enhances model robustness through structured fractal-based image synthesis. By meticulously integrating structural complexity into training datasets, our method generates semantically consistent synthetic samples that significantly improve neural network generalization capabilities. Unlike traditional augmentation techniques that rely on random transformations, LayerMix employs a structured mixing pipeline that preserves original image semantics while introducing controlled variability. Extensive experiments across multiple benchmark datasets, including CIFAR-10, CIFAR-100, ImageNet-200, and ImageNet-1K demonstrate LayerMix’s superior performance in classification accuracy and substantially enhances critical Machine Learning (ML) safety metrics, including resilience to natural image corruptions, robustness against adversarial attacks, improved model calibration and enhanced prediction consistency. LayerMix represents a significant advancement toward developing more reliable and adaptable artificial intelligence systems by addressing the fundamental challenges of DL generalization. The code is available at https://github.com/ahmadmughees/layermix .},
  archive      = {J_PR},
  author       = {Hafiz Mughees Ahmad and Dario Morle and Afshin Rahimi},
  doi          = {10.1016/j.patcog.2025.112332},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112332},
  shortjournal = {Pattern Recognition},
  title        = {LayerMix: Enhanced data augmentation for robust deep learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A query-driven twin network framework with optimization-based meta-learning for few-shot hyperspectral image classification. <em>PR</em>, <em>172</em>, 112331. (<a href='https://doi.org/10.1016/j.patcog.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved remarkable results in hyperspectral image (HSI) classification due to its powerful deep feature extraction and nonlinear relationship processing capabilities. However, the success of deep learning methods is largely dependent on extensive labeled samples, which is both time-consuming and labor-intensive. To address this issue, a novel query-driven meta-learning twin network (QMTN) framework is proposed for HSI few-shot learning. QMTN uses two meta-learning channels, allowing for the comprehensive learning of meta-knowledge across diverse meta-tasks and enhancing learning efficiency. Within the QMTN framework, a lightweight spectral-spatial attention residual network is proposed for extraction of HSI features. The network incorporates a residual mechanism in both spectral and spatial feature extraction processes and includes an attention block to improve network performance by focusing on key locations in the spatial features. To maximize the use of the limited samples for constructing diverse meta-tasks, two meta-task generation approaches are employed, with and without simulated noise. Experiments on three public HSI datasets demonstrate that the QMTN framework effectively reduces the dependence on labeled samples in a single scene and significantly improves the classification performance and convergence of the internal network. The meta-task generation method with simulated noise can improve the classification performance of the QMTN.},
  archive      = {J_PR},
  author       = {Jian Zhu and Pengxin Wang and Jian Hui and Xin Ye},
  doi          = {10.1016/j.patcog.2025.112331},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112331},
  shortjournal = {Pattern Recognition},
  title        = {A query-driven twin network framework with optimization-based meta-learning for few-shot hyperspectral image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reliable classification through rank-based conformal prediction sets. <em>PR</em>, <em>172</em>, 112330. (<a href='https://doi.org/10.1016/j.patcog.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning classification tasks often benefit from predicting a set of possible labels with confidence scores to capture uncertainty. However, existing methods struggle with the high-dimensional nature of the data and the lack of well-calibrated probabilities from modern classification models. We propose a novel conformal prediction method that utilizes a rank-based score function suitable for classification models that predict the order of labels correctly, even if not well-calibrated. Our approach constructs prediction sets that achieve the desired coverage rate while managing their size. We provide a theoretical analysis of the expected size of the conformal prediction sets based on the rank distribution of the underlying classifier. Through extensive experiments, we demonstrate that our method outperforms existing techniques on various datasets, providing reliable uncertainty quantification. Our contributions include a novel conformal prediction method, theoretical analysis, and empirical evaluation. This work advances the practical deployment of machine learning systems by enabling reliable uncertainty quantification.},
  archive      = {J_PR},
  author       = {Rui Luo and Zhixin Zhou},
  doi          = {10.1016/j.patcog.2025.112330},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112330},
  shortjournal = {Pattern Recognition},
  title        = {Reliable classification through rank-based conformal prediction sets},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised domain adaptation for cardiac MRI segmentation via adversarial learning in latent space. <em>PR</em>, <em>172</em>, 112328. (<a href='https://doi.org/10.1016/j.patcog.2025.112328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) imaging is crucial for visualizing myocardial infarction (MI), with accurate segmentation of the ventricles and myocardium being essential for effective MI treatment. However, due to the complex myocardial structure and the limited availability of pixel-level annotations in LGE CMR images, accurate segmentation using supervised deep learning methods remains challenging. To address this, we propose an unsupervised domain adaptation framework for LGE CMR segmentation, utilizing CMR images from other modalities. First, we transform balanced Steady-State Free Precession (bSSFP) CMR images, which have abundant annotations, into LGE-like images using an enhanced CycleGAN. This CycleGAN incorporates an adversarial sample mining technique in the latent space to improve the quality of synthetic images. Next, we modify the nnU-Net architecture by introducing non-local blocks to train on these synthetic images, enabling precise segmentation of the myocardium and ventricular regions. We evaluate our method on the MS-CMRSeg 2019 dataset and MyoPS 2020 dataset, achieving an average Dice score of 88.0 % and 82.6 % respectively. Our experimental results demonstrate superior performance compared to state-of-the-art methods. The code for our approach is available at https://github.com/Lucarqi/Adv-CycleGAN .},
  archive      = {J_PR},
  author       = {Fan Zheng and Hengfei Cui and Yanning Zhang and Yong Xia},
  doi          = {10.1016/j.patcog.2025.112328},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112328},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised domain adaptation for cardiac MRI segmentation via adversarial learning in latent space},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficacy of varying sensing features for enhanced performance of deep-learning-informed multidimensional force platform. <em>PR</em>, <em>172</em>, 112327. (<a href='https://doi.org/10.1016/j.patcog.2025.112327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL)-informed vision-based 3D force platforms have demonstrated significant potential for simultaneous assessment of pressure and shear stresses. However, the enhancement of force decoupling capacity is widely recognized as a difficult challenge in the field. For vision-based designs, the marker-embedded sensing layer serves as the pivotal element of the force platform, unveiling diverse sensing characteristics throughout the learning process. However, none of the previous studies have thoroughly investigated the differences among these sensing features and leveraged them to optimize DL models for enhanced performance in multidimensional force detection. This study addresses this gap by systematically evaluating five distinct features (including optical flow, original images, and their derivatives) using four classic CNN architectures. Our comparative analysis reveals a clear feature-force specialization: gray images are most effective for pressure decoupling, while arrow images are superior in decoupling shear stress. Based on this finding, we proposed and validated a dual-branch DL model that fuses these two specialized features. The model achieves a strong, comprehensive performance on both tasks simultaneously, demonstrating the efficacy of our evidence-based feature-fusion strategy. This study provides new insights into sensing feature selection and evidence-based neural network design for vision-based multidimensional force platforms. These advancements have the potential to expedite the deployment of high-performance multidimensional force platforms in real-life applications.},
  archive      = {J_PR},
  author       = {Hu Luo and Yuxin Ma and Zesheng Wang and Jiewen Li and Xin Ma and Wen-Ming Chen},
  doi          = {10.1016/j.patcog.2025.112327},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112327},
  shortjournal = {Pattern Recognition},
  title        = {Efficacy of varying sensing features for enhanced performance of deep-learning-informed multidimensional force platform},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TP-LReID: Lifelong person re-identification using text prompts. <em>PR</em>, <em>172</em>, 112326. (<a href='https://doi.org/10.1016/j.patcog.2025.112326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong person re-identification (LReID) aims to develop a single model that is capable of continuously learning from new domain (present) while retaining knowledge from previously encountered ones (past) and generalizing to unseen domains (future). However, distribution shifts across these domains pose a significant challenge in maintaining performance across past, present, and future domains, that is, causing the catastrophic forgetting on previously seen domains and limited generalization to unseen ones. To address the above issues, we propose to guide consistent feature extraction to bridge distribution shifts using text prompts designed to remain invariant across domains. First, identity-consistent text prompts capturing high-level image semantics are extracted and aligned with image features throughout the lifelong learning pipeline. Moreover, to enhance generalization to unseen domains, we introduce an adversarial training that text features are contrastively aligned with both original and future-style image features, the latter generated by applying gradient-based perturbations in the feature space. Compared with 21 representative models on 11 benchmark datasets, our proposed model, trained without access to historical data, achieves performance comparable to the model trained using a joint training approach, and it performs well on all of the past, present, and future domains. We further explored the forgetting of the first historical domain and the generalization to all unseen domains under all 24 orders, and the results confirmed the superiority of our model. Codes will be released if this paper is accepted.},
  archive      = {J_PR},
  author       = {Zhaoshuo Liu and Zhiwei Guo and Chaolu Feng and Wei Li and Kun Yu and Jun Hu and Jinzhu Yang},
  doi          = {10.1016/j.patcog.2025.112326},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112326},
  shortjournal = {Pattern Recognition},
  title        = {TP-LReID: Lifelong person re-identification using text prompts},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Zoom-shot: Fast, efficient and unsupervised zero-shot knowledge transfer from CLIP to vision encoders. <em>PR</em>, <em>172</em>, 112323. (<a href='https://doi.org/10.1016/j.patcog.2025.112323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models like CLIP demonstrate exceptional capabilities over a broad domain of knowledge, such as with zero-shot classification; however, they also require significant computational resources, narrowing their real-world utility. Recent studies have shown that mapping features from pre-trained vision encoders into CLIP’s latent space can transfer some of CLIP’s abilities to smaller vision encoders, offering a promising alternative. Yet, the performance of these vision encoders still falls short of CLIP’s native capabilities, particularly in low-data regimes. In this work, we argue that enhancing training data coverage/diversity significantly improves mapping efficacy. We achieve this using tailored loss functions rather than relying on data augmentation or increasing training samples. For instance, we exploit the inherent multimodal nature of CLIP’s latent space, by incorporating cycle-consistency loss as one of our loss functions. Moreover, the mapping is learned using entirely unlabelled and unpaired data, eliminating the need for manual labelling or data pairing in novel domains. From these findings, our resulting method (Zoom-shot) offers a viable path to flexible zero-shot models for resource-limited, data-scarce settings. We test Zoom-shot’s zero-shot performance across various pre-trained vision encoders on coarse- and fine-grained datasets and achieve superior performance compared to recent works. In our ablations, we find Zoom-shot allows for a trade-off between data and compute during training; allowing for a significant reduction in required training data. All code and models are available on GitHub.},
  archive      = {J_PR},
  author       = {Jordan Shipard and Arnold Wiliem and Kien Nguyen Thanh and Wei Xiang and Clinton Fookes},
  doi          = {10.1016/j.patcog.2025.112323},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112323},
  shortjournal = {Pattern Recognition},
  title        = {Zoom-shot: Fast, efficient and unsupervised zero-shot knowledge transfer from CLIP to vision encoders},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging. <em>PR</em>, <em>172</em>, 112322. (<a href='https://doi.org/10.1016/j.patcog.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-pixel imaging provides significant advantages for non-visible wavelength detection and ultra-compressed sensing. However, accurate reconstruction from severely under-sampled measurements remains challenging. To tackle this, we propose a novel wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging (WGDNet), which hierarchically reconstructs images through wavelet component-aware reinforcement. Specifically, we design a sampling-guided model to capture essential textures and produce an initial image decomposed into high- and low-frequency components. The low-frequency part is enhanced with adaptive diffusion to preserve structure, while the high-frequency part is directionally incorporated through a multi-frequency adaptive fusion attention (MAFA) mechanism to refine details. Building on this, we develop a residual spatial adaptive fusion (RSAF) module to effectively combine low-frequency structures and high-frequency details. Extensive experiments on five public datasets demonstrate that our method achieves superior performance in both structural preservation and detail recovery. Successful implementation in the imaging system validates the applicability in real scenarios.},
  archive      = {J_PR},
  author       = {Dawei Song and Qiurong Yan and Hui Wang and Jian Yang and Xiaolong Luo},
  doi          = {10.1016/j.patcog.2025.112322},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112322},
  shortjournal = {Pattern Recognition},
  title        = {Wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical community-based graph generation model for improving structural diversity. <em>PR</em>, <em>172</em>, 112320. (<a href='https://doi.org/10.1016/j.patcog.2025.112320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generation remains a challenging task due to the high dimensionality of graphs and the complex dependencies among their edges. Existing models often struggle to produce structurally diverse graphs. To address this limitation, we propose a novel generative framework specifically designed to capture structural diversity in graph generation. Our approach follows a sequential process: initially, a community detection algorithm partitions the input graph into distinct communities. Each community is then generated independently using deep generative models, while a dedicated module concurrently learns the interconnections between communities. To scale to graphs with a larger number of communities, we extend our approach into a hierarchical generative model. The proposed framework not only improves generation accuracy but also significantly reduces generation time for large-scale graphs. Moreover, it enables the application of prior methods that were previously incapable of handling such graphs. To highlight the shortcomings of existing approaches, we conduct experiments on a synthetic dataset comprising diverse graph structures. The results demonstrate substantial improvements in standard evaluation metrics as well as in the quality of the generated graphs.},
  archive      = {J_PR},
  author       = {Masoomeh Sadat Razavi and Abdolreza Mirzaei and Mehran Safayani},
  doi          = {10.1016/j.patcog.2025.112320},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112320},
  shortjournal = {Pattern Recognition},
  title        = {Hierarchical community-based graph generation model for improving structural diversity},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GLGF-CR: A gated local-global fusion approach for cloud removal in real-world remote sensing. <em>PR</em>, <em>172</em>, 112319. (<a href='https://doi.org/10.1016/j.patcog.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical satellite imagery is a critical data source for Earth observation in remote sensing. However, cloud cover often degrades image quality, hindering its application and analysis. Therefore, effective cloud removal from optical satellite images has become a prominent research direction. In real-world scenarios, thick clouds act as pure noise, completely obscuring underlying information, while thin clouds provide partially beneficial information that can be leveraged for reconstruction. Traditional cloud removal methods often fail to distinguish between these two types of noise, leading to suboptimal performance. To address this limitation, we propose a novel cloud removal model, GLGF-CR, which incorporates a Gated Local-Global Fusion module. This module is designed to effectively separate and process the distinct characteristics of thick and thin clouds. For thick clouds, which contain no recoverable information, the model focuses on robust reconstruction using complementary data sources. For thin clouds, the model extracts and utilizes the beneficial information embedded in the partially obscured regions, enabling more accurate and detailed reconstruction. Additionally, a Dual Cross-Attention mechanism is introduced to establish robust mappings between SAR and optical modalities, further improving fusion accuracy. To handle domain shifts between source and target domains, we incorporate a domain adaptation module, which enhances the model’s ability to generalize across diverse real-world scenarios. The proposed algorithm not only outperforms existing methods on the large-scale real-world dataset SEN12MS-CR but also demonstrates strong cross-domain transferability on the Henan flood dataset. By explicitly addressing the dual nature of cloud noise–pure noise in thick clouds and partially beneficial information in thin clouds–this work advances the field of beneficial noise learning, demonstrating how noise can be systematically analyzed and utilized to improve model performance in complex scenarios.},
  archive      = {J_PR},
  author       = {Ganchao Liu and Jiawei Qiu and Jincheng Huang and Yuan Yuan},
  doi          = {10.1016/j.patcog.2025.112319},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112319},
  shortjournal = {Pattern Recognition},
  title        = {GLGF-CR: A gated local-global fusion approach for cloud removal in real-world remote sensing},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised feature selection with concept factorization and robust label learning. <em>PR</em>, <em>172</em>, 112317. (<a href='https://doi.org/10.1016/j.patcog.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is essential for improving model performance in high-dimensional data by identifying the most relevant features. Concept Factorization (CF), building on Non-negative Matrix Factorization (NMF), is valued for revealing meaningful data structure and producing interpretable concept vectors. However, existing CF-based FS methods are typically unsupervised and do not leverage label information, leading to a bias toward high-variance features. This bias can result in the omission of low-variance features that may be highly discriminative, ultimately reducing the effectiveness of FS and compromising model performance, especially in tasks where subtle or rare patterns are important. To address these limitations, this paper proposes SCFLR, a novel semi-supervised FS method that combines CF with robust label learning. SCFLR establishes the CF framework based on the feature space by expressing each concept vector as a conic combination of the feature vectors, thereby leveraging both the underlying data structure and available label information to select a more informative and balanced set of features. To this end, SCFLR defines a linear regression-based loss function derived from the generated concept vectors to leverage information from labeled data. This loss function is further enhanced through a label learning framework based on the L 2 , 1 -norm to ensure a robust label approximation. SCFLR also utilizes the dual-graph regularization to maintain the local geometric structures in both feature and data spaces. In order to tackle the optimization problem of SCFLR, an efficient algorithm, with proof of its convergence, is introduced. Finally, the experimental validation of the SCFLR method on multiple datasets highlights its effectiveness and superior performance compared to other FS methods.},
  archive      = {J_PR},
  author       = {Razieh Sheikhpour and Farid Saberi-Movahed and Mahdi Jalili and Kamal Berahmand},
  doi          = {10.1016/j.patcog.2025.112317},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112317},
  shortjournal = {Pattern Recognition},
  title        = {Semi-supervised feature selection with concept factorization and robust label learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning for DBT classification with saliency-guided 2D synthesis. <em>PR</em>, <em>172</em>, 112316. (<a href='https://doi.org/10.1016/j.patcog.2025.112316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Breast Tomosynthesis (DBT) is a key imaging modality for breast cancer detection, improving lesion visibility by reducing tissue overlap inherent in conventional mammography. In this work, we propose a novel deep learning framework that classifies DBT volumes as malignant or non-malignant, while simultaneously generating a synthetic 2D image to assist diagnostic interpretation. This image is derived from a 3D saliency map computed by the internal attention mechanisms of the model, which highlights and preserves the most diagnostically relevant regions from the original volume. A surface is defined in this saliency space, enabling sampling and projection into a 2D diagnostic representation. This projection offers a compact summary of the volumetric scan, assisting clinicians in diagnostic interpretation and potentially alleviating the cognitive workload. A standard convolutional neural network trained on these synthetic 2D images achieves classification performance comparable to models operating directly on full 3D volumes. We train and evaluate our method on the OPTIMAM dataset and assess generalization through external validation on the independent BCS-DBT dataset without retraining. Results show that the model performs robustly across different clinical sources and provides an interpretable, computationally efficient tool for DBT-based breast cancer diagnosis.},
  archive      = {J_PR},
  author       = {Marco Cantone and Ciro Russo and Federico~V.~L. Dell’Ascenza and Claudio Marrocco and Alessandro Bria},
  doi          = {10.1016/j.patcog.2025.112316},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112316},
  shortjournal = {Pattern Recognition},
  title        = {Deep learning for DBT classification with saliency-guided 2D synthesis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-tolerant scheme and explicit regularizer for deep active learning with noisy oracles. <em>PR</em>, <em>172</em>, 112313. (<a href='https://doi.org/10.1016/j.patcog.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring the query strategies based on deep learning shows promising results in terms of designing the criteria for active learning. However, the labels provided by the oracles might be noisy (inaccurate) due to similarities across several classes causing ambiguity, leading to unreliable results. To address this issue, we propose a noise-tolerant deep active learning method. Specifically, we design a consistency regularization for deep attention network as explicit regularizer, which is used to measure the uncertainty of examples. Besides, we develop the robust model for dealing with the noisy oracles , which first take the associations that make from embeddings of labeled data to those of unlabeled data and back, then we employ the association probability as a weighting fusion schema into angular margin based loss. Moreover, we design the submodular maximization function for reducing the redundancy of selected batch examples. Finally, the formulation is encapsulated into the multi-task framework that helps to adaptive learning towards more generalizable performance. Experimentally, we conduct extensive experiments on classification and segmentation tasks, and the results clearly demonstrate the superiority of the proposed method to the existing state-of-the-art deep active learning approaches.},
  archive      = {J_PR},
  author       = {Yanchao Li and Ziteng Xie and Hongwu Zhong and Guangwei Gao},
  doi          = {10.1016/j.patcog.2025.112313},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112313},
  shortjournal = {Pattern Recognition},
  title        = {Noise-tolerant scheme and explicit regularizer for deep active learning with noisy oracles},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Linguistic query-guided mask generation for referring image segmentation. <em>PR</em>, <em>172</em>, 112306. (<a href='https://doi.org/10.1016/j.patcog.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation aims to segment the image region of interest according to the given language expression, which is a typical multi-modal task. Existing methods either adopt the pixel classification-based or the learnable query-based framework for mask generation, both of which are insufficient to deal with various text-image pairs with a fix number of parametric prototypes. The motivation of this work is to propose an end-to-end framework built on transformer to perform Linguistic query-Guided mask generation, dubbed LGFormer. It views the linguistic features as query to generate a specialized prototype for arbitrary input image-text pair, thus generating more consistent segmentation results. Moreover, we design several cross-modal interaction modules (e.g. vision-language bidirectional attention module, VLBA) in both encoder and decoder to achieve better cross-modal alignment. Extensive experiments demonstrate that our LGFormer achieves a new state-of-the-art performance on ReferIt, RefCOCO+, and RefCOCOg by large margins. Code is available at https://github.com/mqchen1993/LGFormer .},
  archive      = {J_PR},
  author       = {Zhichao Wei and Xiaohao Chen and Mingqiang Chen and Hao Li and Zilong Dong and Siyu Zhu},
  doi          = {10.1016/j.patcog.2025.112306},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112306},
  shortjournal = {Pattern Recognition},
  title        = {Linguistic query-guided mask generation for referring image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TransSTC: Transformer tracker meets efficient spatial-temporal cues. <em>PR</em>, <em>172</em>, 112303. (<a href='https://doi.org/10.1016/j.patcog.2025.112303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, researchers have started developing trackers using the powerful global modeling capabilities of transformer networks. However, existing transformer trackers usually model all template spatial cues indiscriminately and ignore temporal cues of target state changes. This distracts the tracker’s attention and gradually fails to understand the target’s latest state. Therefore, we propose a new tracker called TransSTC, which explores the effective spatial cues in the template and temporal cues during tracking to improve the tracker’s performance. Specifically, we design the target-aware focused coding network to emphasize the efficient spatial cues in the templates, alleviating the impact of spatial cues with low associations of targets in templates on the tracker’s localization accuracy. Additionally, we employ the multi-temporal template update structure that accurately captures variations in the target’s appearance. Within this structure, the collected samples are assessed for target appearance similarity and environmental interference, followed by a three-level sample selection process to ensure the accurate template update. Finally, we introduce the motion constraint framework to dynamically adjust the classification results based on the target’s historical motion trajectory. Extensive experimental results on seven tracking benchmarks demonstrate that TransSTC achieves competitive tracking performance.},
  archive      = {J_PR},
  author       = {Hong Zhang and Wanli Xing and Yifan Yang and Hanyang Liu and Ding Yuan},
  doi          = {10.1016/j.patcog.2025.112303},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112303},
  shortjournal = {Pattern Recognition},
  title        = {TransSTC: Transformer tracker meets efficient spatial-temporal cues},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MGFNet: Multi-granularity medical pattern fusion network for patient risk prediction. <em>PR</em>, <em>172</em>, 112302. (<a href='https://doi.org/10.1016/j.patcog.2025.112302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of patient risk prediction tasks is to predict a patient’s future disease or mortality risk based on his/her historical electronic health record (EHR). Most prior works focus on learning patient evolution patterns from longitudinal EHR data, while ignoring the differences in temporal granularity in medical data, resulting in insufficient information exploitation. To address these limitations, we propose the M ulti- G ranularity Medical Pattern F usion Net work (MGFNet) for patient risk prediction based on temporal data. It learns the evolutionary patterns of medical data at different temporal granularities (both at the vital sign-level and visit-level), and introduces a gated filtering function and a contrastive learning strategy for multi-granularity fusion, which captures fused information from different temporal granularities and supervises each other to obtain a more effective information representation. In addition, for patients with variable visit lengths, we introduce a soft curriculum learning method to learn these patterns by assigning different weights to medical samples to improve prediction accuracy. The final experimental results demonstrate that MGFNet effectively improves the performance of risk prediction compared with state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Lin Cheng and Yuliang Shi and Xiaojing Yu and Xinyu Li and Xinjun Wang and Zhongmin Yan and Zhiyong Chen},
  doi          = {10.1016/j.patcog.2025.112302},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112302},
  shortjournal = {Pattern Recognition},
  title        = {MGFNet: Multi-granularity medical pattern fusion network for patient risk prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning multi-scale spatial-frequency features for image denoising. <em>PR</em>, <em>172</em>, 112300. (<a href='https://doi.org/10.1016/j.patcog.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.},
  archive      = {J_PR},
  author       = {Xu Zhao and Chen Zhao and Xiantao Hu and Hongliang Zhang and Ying Tai and Jian Yang},
  doi          = {10.1016/j.patcog.2025.112300},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112300},
  shortjournal = {Pattern Recognition},
  title        = {Learning multi-scale spatial-frequency features for image denoising},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep intrinsic image decomposition via physics-aware neural networks. <em>PR</em>, <em>172</em>, 112299. (<a href='https://doi.org/10.1016/j.patcog.2025.112299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrinsic image decomposition (IID) aims to separate an observed image into its underlying reflectance and shading components. This task is challenging due to the complex interplay of lighting, surface geometry, and material reflectance in real-world scenes. To address these challenges, this paper proposes a physics-aware deep neural network with a single-encoder, double-decoder architecture. The encoder incorporates an explicit alternating process inspired by a physics-guided model, enabling iterative decoupling of image features into reflectance and shading. Two asymmetric decoders are designed to reconstruct reflectance and shading maps based on their distinct properties. In addition, we introduce a shading loss function leverages spatial distributions of texture and structure. Unlike standard total variation (TV) losses, it employs a texture-likelihood-weighted TV norm, where weights are derived via a patch-matching scheme to distinguish isotropic textures from anisotropic image edges. This design enhances the model’s ability to suppress texture while preserving structure. Experimental results on three datasets (MIT, MPI-Sintel, and IIW) show the effectiveness of our method: on MIT and MPI-Sintel, it reduces the mean-squared-errors of both reflectance and shading by over 40 % compared to existing works, and on IIW, it achieves a superior WHDR score of 13.2, outperforming all existing methods.},
  archive      = {J_PR},
  author       = {Yan Huang and Kangjie Liu and Tengyue Chen and Yong Xu and Hui Ji},
  doi          = {10.1016/j.patcog.2025.112299},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112299},
  shortjournal = {Pattern Recognition},
  title        = {Deep intrinsic image decomposition via physics-aware neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Domain adapter for visual object tracking based on hyperspectral video. <em>PR</em>, <em>172</em>, 112296. (<a href='https://doi.org/10.1016/j.patcog.2025.112296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking based on hyperspectral video attracts increasing attention due to the rich material and motion information in the hyperspectral videos. The prevailing hyperspectral methods adapt pretrained RGB-based object tracking networks for hyperspectral tasks by converting the hyperspectral images into false-color images and fine-tuning the whole network on hyperspectral datasets, which achieves impressive results in challenging scenarios. However, the performance of hyperspectral trackers is limited by the spectral information loss during the transformation, and fine-tuning the entire pretrained network is inefficient for practical applications. To address the issues, a new hyperspectral object tracking method based on domain adaption, hyperspectral adapter for tracking (HyA-T), is proposed in this work. The hyperspectral adapter for the self-attention (HAS) and the hyperspectral adapter for the multilayer perceptron (HAM) are proposed to generate the adaption information and to transfer the multi-head self-attention (MSA) module and the multilayer perceptron (MLP) in pretrained network for the hyperspectral object tracking task by augmenting the spectral information in the original hyperspectral images into the calculation of the MSA and MLP. Additionally, the hyperspectral enhancement of input (HEI) is proposed to augment the original spectral information into the input of the tracking network. The proposed methods extract spectral information directly from the hyperspectral images, which reduce the negative impact of the spectral information loss caused by the transformation. Moreover, only the parameters in the proposed methods are fine-tuned, which is more efficient than the existing methods. Extensive experiments were conducted on four datasets with various spectral bands, verifying the effectiveness of the proposed methods. The HyA-T achieves state-of-the-art performance on all the datasets.},
  archive      = {J_PR},
  author       = {Long Gao and Yunhe Zhang and Langkun Chen and Yan Jiang and Gang He and Weiying Xie and Yunsong Li},
  doi          = {10.1016/j.patcog.2025.112296},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112296},
  shortjournal = {Pattern Recognition},
  title        = {Domain adapter for visual object tracking based on hyperspectral video},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Few-shot image generation via information transfer from the built geodesic surface. <em>PR</em>, <em>172</em>, 112293. (<a href='https://doi.org/10.1016/j.patcog.2025.112293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models trained with limited data often struggle with poor fidelity and diversity. While adapting large pre-trained models is a common solution, such an approach requires significant resources and suitable source domains, which are often unavailable. To address these limitations, we propose Information Transfer from the Built Geodesic Surface (ITBGS), a framework that generates high-quality images from scratch. The core of ITBGS is our Feature Augmentation on Geodesic Surface (FAGS) module, which constructs a Geodesic surface to create a diverse pseudo-source domain from the initial samples. By transferring structural information from the augmented domain to guide the generator’s training, our method completely removes the need for pre-trained models. To refine the output, a supporting Interpolation and Regularization (I&R) module is also introduced to enhance the smoothness and perceptual quality of generated images. Extensive experiments demonstrate that ITBGS achieves state-of-the-art or comparable performance on various few-shot datasets, successfully balancing image fidelity and diversity.},
  archive      = {J_PR},
  author       = {Yuexing Han and Liheng Ruan and Bing Wang},
  doi          = {10.1016/j.patcog.2025.112293},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112293},
  shortjournal = {Pattern Recognition},
  title        = {Few-shot image generation via information transfer from the built geodesic surface},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FADMB: Fully attention-based dual memory bank network for weakly supervised video anomaly detection. <em>PR</em>, <em>172</em>, 112288. (<a href='https://doi.org/10.1016/j.patcog.2025.112288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection is crucial for analyzing surveillance videos and plays a significant role in maintaining public safety. Recent advances in weakly supervised methods, utilizing video-level labels, have improved performance based on techniques like multi-instance learning and temporal modeling. Furthermore, memory banks demonstrate great potential in unsupervised anomaly detection, prompting their integration into weakly supervised setups. However, these methods depend on the Top- k selection mechanism to update the prototypes within memory banks, which has limitations such as overlooking valuable prototypes, leading to a biased updating process, and requiring hyperparameters. To tackle these challenges, we introduce a novel video anomaly detection model, FADMB ( F ully A ttention-based D ual M emory B ank network), which replaces the Top- k selection mechanism with an innovative attention-based prototype updating paradigm to obtain a more comprehensive and robust memory bank. Additionally, we design a Hybrid Encoder that encodes local and global temporal information to produce superior video representations. Extensive experiments demonstrate the superiority of FADMB, achieving 85.79 % AUC on UCF-Crime dataset and 83.29 % AP on XD-Violence dataset.},
  archive      = {J_PR},
  author       = {Zhiming Luo and Shuheng Huang and Kun Yang and Jianzhe Gao and Shaozi Li},
  doi          = {10.1016/j.patcog.2025.112288},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112288},
  shortjournal = {Pattern Recognition},
  title        = {FADMB: Fully attention-based dual memory bank network for weakly supervised video anomaly detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="ras">RAS - 4</h2>
<ul>
<li><details>
<summary>
(2026). Neuromorphic visuotactile slip perception for robotic manipulation. <em>RAS</em>, <em>195</em>, 105191. (<a href='https://doi.org/10.1016/j.robot.2025.105191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visuotactile sensing technology has received extensive attention in the tactile sensing community due to its stable high-resolution deformation sensing capabilities. However, the existing visuotactile sensing methods are far from humanoid neural information processing mechanism. To address this gap, we propose a neuromorphic visuotactile slip detection method named VT-SNN using Tactile Address-Event Representation (TAER) encoding combined with brain-inspired Spiking Neural Network (SNN) modeling in this paper. Our extensive experimental results demonstrate that the VT-SNN achieves slip detection accuracy of 99.59% and F1 score of 99.28%, which is comparable to Artificial Neural Networks (ANNs) while exhibiting significant advantages in power dissipation and inference time. Furthermore, we deployed the VT-SNN on Intel neuromorphic computing chip–Loihi and performed closed-loop slip-feedback robotic manipulation tasks such as bottle-cap tightening and loosening. Our closed-loop neuromorphic visuotactile sensing system shows significant promise for high accuracy, low latency, and low power dissipation for robotic dexterous manipulation.},
  archive      = {J_RAS},
  author       = {Yiming Qiao and Chaofan Zhang and Shaowei Cui and Lu Cao and Zhigang Wang and Peng Wang and Shuo Wang},
  doi          = {10.1016/j.robot.2025.105191},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105191},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Neuromorphic visuotactile slip perception for robotic manipulation},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm. <em>RAS</em>, <em>195</em>, 105190. (<a href='https://doi.org/10.1016/j.robot.2025.105190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstacle-aware configuration control represents a critical challenge in the deployment of continuum robots for advanced applications such as robotic-assisted laparoscopic surgery and intelligent industrial grasping systems. At present, in order to realize the obstacle avoidance function of flexible robots, inverse kinematic calculations are usually unavoidable. The problems of large amount of computation, long solution time, and non-convergence of results make the configuration control for flexible robots still challenging. Most of the current studies use the inverse kinematics calculation of end tracking, and for flexible robots with multiple degrees of freedom, the success rate of obstacle avoidance is low and the computational cost is large. In this paper, a three-segment continuum configuration planning method based on Rapidly-exploring Random Tree (RRT) algorithm is proposed, in which the rough obstacle avoidance path is obtained by RRT algorithm, then the three-segment fitting is carried out by using the second-order Bézier curve, and the length error is evaluated to meet the planning requirements. Experiments such as obstacle avoidance tests, the arrival of target endpoints at different positions and different obstacle environments show that the proposed method can effectively map the feasible solution to the actual configuration. Compared with the inverse kinematics method, the proposed approach improves the success rate of obtaining feasible solutions by at least 14.8% and reduces the solution time by at least 55%. In addition, no prior curvature information and traditional inverse kinematics calculation are needed for the configuration control.},
  archive      = {J_RAS},
  author       = {Qiqi Pan and Hongbo Wang and Yongfei Feng and Shijie Guo and Jingjing Luo},
  doi          = {10.1016/j.robot.2025.105190},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105190},
  shortjournal = {Robot. Auton. Syst.},
  title        = {RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions. <em>RAS</em>, <em>195</em>, 105185. (<a href='https://doi.org/10.1016/j.robot.2025.105185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the following problem: A robot operating in a 2D environment with a limited vision range finds a path to a goal in an unknown environment containing obstacles. In this paper, we propose a novel algorithm to solve the problem. In some special cases, our algorithm is convergent with respect to ‖ . ‖ . The problem involves discovering the environmental map and blind alley regions, that are bounded by obstacles, and it provides no possible passage for robots except in and out of their path entry occur, the robot has to return back to some positions outside to escape from such regions such that the returned path is not longer than the path entry (Blind Alley Region problem, (BAR) problem, in short). To solve the (BAR) problem, sequences of bundles of line segments during the robot’s traveling are constructed in our algorithm. Some advantages of our algorithm are that (a) It reduces search space in blind alley regions because it only works on the sequences of bundles of the line segments built by the robot’s limited vision range. (b) Our algorithm ensures that the returned path to escape from the regions is not longer than the previous path of the robot. (c) Due to the construction of the sequences of bundles of line segments, our paths are not always “close” obstacles and the number of turns of such paths is smaller ones determined by other shortest path algorithms (e.g., A*, RRT*). Our algorithm is implemented in Python and we experience the algorithm on some autonomous robots with different vision ranges in real environment. We also compare our result with RRTX, a state-of-art local path-planning algorithm, and A ∗ , a basic one. The experimental results show that our algorithm provides better solutions than RRTX and A* results in some specific circumstances.},
  archive      = {J_RAS},
  author       = {Phan Thanh An and Pham Hoang Anh and Tran Thanh Binh and Tran Van Hoai},
  doi          = {10.1016/j.robot.2025.105185},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105185},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances. <em>RAS</em>, <em>195</em>, 105184. (<a href='https://doi.org/10.1016/j.robot.2025.105184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust and enhanced control strategy for a multi-quadrotor suspended payload system, which is characterized by complex nonlinear dynamics and unknown external disturbances. A precise dynamic model of the system is formulated using the Udwadia–Kalaba method. A distributed cooperative planning framework, based on graph theory, is employed to enable effective information exchange and cooperative control among multiple quadrotors. To mitigate the impact of unknown disturbances, such as wind fields and variations in payload mass, a disturbance observer is developed to estimate and compensate for these disturbances, thereby enhancing system robustness. Furthermore, an improved prescribed performance control method is proposed to address the issue of exceeding performance boundaries. The steady-state error of the system is effectively reduced by adaptively adjusting the prescribed performance boundary and combining it with integral backstepping, and real-time constraints on tracking errors and closed-loop stability are achieved. Simulation results validate that the proposed control strategy significantly enhances the control performance and disturbance rejection capability of the multi-quadrotor suspended payload system, demonstrating superior robustness.},
  archive      = {J_RAS},
  author       = {Xinyu Chen and Yunsheng Fan and Guofeng Wang and Dongdong Mu},
  doi          = {10.1016/j.robot.2025.105184},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105184},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="spa">SPA - 3</h2>
<ul>
<li><details>
<summary>
(2026). Convergence of adapted smoothed empirical measures. <em>SPA</em>, <em>191</em>, 104775. (<a href='https://doi.org/10.1016/j.spa.2025.104775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adapted Wasserstein distance ( AW -distance) controls the calibration errors of optimal values in various stochastic optimization problems, pricing and hedging problems, optimal stopping problems, etc. However, statistical aspects of the AW -distance are bottlenecked by the failure of empirical measures ( Emp ) to converge under this distance. Kernel smoothing and adapted projection have been introduced to construct converging substitutes of empirical measures, known respectively as smoothed empirical measures ( S - Emp ) and adapted empirical measures ( A - Emp ). However, both approaches have limitations. Specifically, S - Emp lack comprehensive convergence results, whereas A - Emp in practical applications lead to fewer distinct samples compared to standard empirical measures. In this work, we address both of the aforementioned issues. First, we develop comprehensive convergence results of S - Emp . We then introduce a smoothed version for A - Emp , which provide as many distinct samples as desired. We refer them as AS - Emp and establish their convergence in mean, deviation and almost sure convergence. The convergence estimation incorporates two results: the empirical analysis of the smoothed adapted Wasserstein distance ( AW ( σ ) -distance) and its bandwidth effects. Both results are novel and their proof techniques could be of independent interest.},
  archive      = {J_SPA},
  author       = {Songyan Hou},
  doi          = {10.1016/j.spa.2025.104775},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104775},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Convergence of adapted smoothed empirical measures},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A tamed euler scheme for SDEs with non-locally integrable drift coefficient. <em>SPA</em>, <em>191</em>, 104772. (<a href='https://doi.org/10.1016/j.spa.2025.104772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we show that for SDEs with a drift coefficient that is non-locally integrable, one may define a tamed Euler scheme that converges in L p at rate 1 / 2 to the true solution. The taming is required in this case since one cannot expect the regular Euler scheme to have finite moments in L p . Our proof strategy involves controlling the inverse moments of the distance of scheme and the true solution to the singularity set. We additionally show that our setting applies to the case of two scalar valued particles with singular interaction kernel. To the best of the authors’ knowledge, this is the first work to prove strong convergence of an Euler-type scheme in the case of non-locally integrable drift.},
  archive      = {J_SPA},
  author       = {Tim Johnston and Sotirios Sabanis},
  doi          = {10.1016/j.spa.2025.104772},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104772},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A tamed euler scheme for SDEs with non-locally integrable drift coefficient},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scaling limit and large deviation for 3D globally modified stochastic Navier–Stokes equations with transport noise. <em>SPA</em>, <em>191</em>, 104770. (<a href='https://doi.org/10.1016/j.spa.2025.104770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the globally modified stochastic (hyperviscous) Navier–Stokes equations with transport noise on 3D torus. We first establish the existence and pathwise uniqueness of the weak solutions, and then show their convergence to the solutions of the deterministic 3D globally modified (hyperviscous) Navier–Stokes equations in an appropriate scaling limit. Furthermore, we prove a large deviation principle for the stochastic globally modified hyperviscous system.},
  archive      = {J_SPA},
  author       = {Chang Liu and Dejun Luo},
  doi          = {10.1016/j.spa.2025.104770},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104770},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Scaling limit and large deviation for 3D globally modified stochastic Navier–Stokes equations with transport noise},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="swevo">SWEVO - 22</h2>
<ul>
<li><details>
<summary>
(2025). A preference modified inverted generational distance indicator guided algorithm for evolutionary multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102169. (<a href='https://doi.org/10.1016/j.swevo.2025.102169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference-based evolutionary multi-objective optimization algorithms have attracted much attention in the area of evolutionary computation. However, there are only a few researchers incorporating performance indicators for designing preference-based evolutionary algorithm. In this paper, we propose a preference modified inverted generational distance indicator guided algorithm, named PIGA, for evolutionary multi-objective optimization. The main purpose is that decision-makers provide their preferences, ultimately identifying the portion of Pareto optimal solutions where are located in region of interest. A new preference construction strategy based on coordinate transformation is first proposed. The reference points in the whole objective space can be projected into the preference space, obtaining the preferred reference points. The non-preferred reference points remain in the original objective space, outside the specified preference region. In addition, we define the distance between the candidate solution and preferred reference points as the preference distance and the distance to non-preferred reference points as the penalty distance. Finally, a preference-based modified inverted generational distance indicator is formulated to obtain the preferred optimal solutions according to the preferences and penalty distances. The comparative results are comprehensively analyzed by comparing it with some related preference-based evolutionary algorithms on some test instances. Experimental results have validated the effectiveness and feasibility of the proposed algorithm under different scenarios with the given preference range.},
  archive      = {J_SWEVO},
  author       = {Fei Li and Hao Tian and Hao Shen and Xingyi Zhang and Jianchang Liu and Zaiwu Gong},
  doi          = {10.1016/j.swevo.2025.102169},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102169},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A preference modified inverted generational distance indicator guided algorithm for evolutionary multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Material delivery optimization for make-to-order reconfigurable job shops using an improved chaotic multi-verse algorithm. <em>SWEVO</em>, <em>99</em>, 102167. (<a href='https://doi.org/10.1016/j.swevo.2025.102167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for product customization has highlighted the importance of make-to-order (MTO) material delivery. Although manufacturers have deployed intelligent reconfigurable job shops equipped with flexible workstations and automated guided vehicles (AGVs), challenges remain due to inefficient material scheduling, delayed deliveries, and the complexity arising from diverse material types. This study proposes an active delivery strategy based on a workshop material supermarket, in which both AGV path planning and workstation layout are jointly optimized in response to dynamically changing orders. A multi-objective delivery path model is formulated to support demand splitting while minimizing material delivery costs and maximizing timeliness satisfaction. The model incorporates constraints related to AGV capacity, path feasibility, and demand alignment. To address the nonlinearity and complexity of the problem, an improved chaotic multi-verse optimizer (ICMVO) is proposed. The algorithm employs chaotic encoding to enhance population diversity and mitigate premature convergence. It further integrates gravitational and collision operators to improve global and local search capabilities and adopts adaptive orbital dynamics control to balance exploration and exploitation. A dual-population iterative strategy is employed to enable joint decision-making on workstation coordinates, path direction, and vehicle assignment. Through comprehensive comparisons with state-of-the-art meta-heuristics, the superiority of the ICMVO algorithm and the effectiveness of its components are demonstrated. Moreover, the proposed material delivery optimization method is implemented in a cloud–edge–terminal system and validated in practical MTO reconfigurable job shops through improvements in productivity and cost efficiency.},
  archive      = {J_SWEVO},
  author       = {Qinge Xiao and Kai Wang and Chi Ma and Ye Chen},
  doi          = {10.1016/j.swevo.2025.102167},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102167},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Material delivery optimization for make-to-order reconfigurable job shops using an improved chaotic multi-verse algorithm},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid metaheuristic algorithms for image watermarking: An experimental study. <em>SWEVO</em>, <em>99</em>, 102163. (<a href='https://doi.org/10.1016/j.swevo.2025.102163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invisible image watermarking is a promising method for protecting the copyright of digital images such as photographs, illustrations, and scans. An effective watermarking algorithm embeds a special mark into an image that does not change the image content but can be extracted from it even after some common post-processing operations such as cropping or compression. Many authors use metaheuristic optimization algorithms to achieve a trade-off between imperceptibility and robustness of embedding. In recent years, researchers have been interested in hybrid metaheuristics, which combine operations of individual metaheuristics in some way. However, designs and compositions of hybrid metaheuristic optimization schemes for image watermarking have not been sufficiently studied to date. In this paper, we present an experimental study of various hybrid metaheuristics including sequential, interleaved, and parallel schemes for popular bioinspired optimization algorithms including genetic algorithm, differential evolution algorithm, particle swarm optimization algorithm, firefly algorithm, and artificial bee colony algorithm. We evaluate the effectiveness of hybrid metaheuristics for image watermarking using an algorithm based on changing the ratio between absolute values ​​of sums of discrete cosine transform coefficient groups as an example and perform an experimental comparison of different schemes. The results of the study show that a approach to metaheuristic hybridization and a composition of hybrid scheme significantly affect the imperceptibility and robustness of the image watermarking algorithm. In particular, the interleaved hybridization type provides the best results for the algorithm under consideration.},
  archive      = {J_SWEVO},
  author       = {Anna Melman and Oleg Evsutin},
  doi          = {10.1016/j.swevo.2025.102163},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102163},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Hybrid metaheuristic algorithms for image watermarking: An experimental study},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal financial portfolio selection using a metaheuristic approach with multiple strategies. <em>SWEVO</em>, <em>99</em>, 102162. (<a href='https://doi.org/10.1016/j.swevo.2025.102162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimisation with cardinality constraints has been extensively studied in the realm of financial investment, recognised as an NP-hard quadratic programming problem. As an innovative metaheuristic approach, the dung beetle optimiser leverages its unique optimisation search mechanism to effectively tackle unconstrained optimisation problems. However, the realities of portfolio optimisation involve various constraints; thus, the original dung beetle optimiser may not suffice. Consequently, this study develops an improved dung beetle optimiser to address cardinality constrained portfolio optimisation, incorporating a new decision variable update strategy, a constraint handling strategy, and a local search strategy. These techniques facilitate the efficient selection of assets from among multiple candidate assets. To validate the capabilities of the indicated methodologies, five datasets from OR-Library and six datasets from NGINX are employed for testing. The results from these datasets consistently indicate that the proposed strategies outperform existing alternatives. Furthermore, the comparison results with various methods presented in other works demonstrate that the proposed technology is competitive in the realm of cardinality constrained portfolio optimisation.},
  archive      = {J_SWEVO},
  author       = {Limin Wang and Guosen Lin and Qijun Zhang and Muhammet Deveci and Seifedine Kadry and Mingyang Li},
  doi          = {10.1016/j.swevo.2025.102162},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102162},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Optimal financial portfolio selection using a metaheuristic approach with multiple strategies},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolutionary method with shift pattern learning for real-world multi-skilled personnel scheduling with flexible shifts. <em>SWEVO</em>, <em>99</em>, 102160. (<a href='https://doi.org/10.1016/j.swevo.2025.102160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel scheduling remains a significant organizational challenge with substantial potential for cost and time savings. Despite extensive research in this domain, few studies have been successfully implemented in practice, and even fewer have gained widespread acceptance among end-users. This gap between research and application often arises from oversimplified real-world models, which may result from subjective solution evaluations or a lack of collaboration between modelers and end-users. To bridge this gap, this paper proposes a machine learning-enhanced memetic algorithm (MLMA) that mimics schedules created by experts to solve a highly complex personnel scheduling problem involving multi-skilled workers and flexible shift types (irregular workforce)—a real-world challenge commonly faced in the hospitality sector. By leveraging historical scheduling preferences, the MLMA generates solutions that align with past practices, enhancing their practicality and appeal to end-users. Experiments conducted on real-life instances demonstrate the effectiveness of the proposed approach in addressing real-world problems, where the workforce is predominantly part-time, possesses mixed skills, and requires flexible shifts. Furthermore, the results highlight the MLMA’s ability to identify shift patterns that closely resemble historical schedules, underscoring its potential for practical implementation and its role in bridging the gap between research and real-world application.},
  archive      = {J_SWEVO},
  author       = {Ning Xue and Ruibin Bai and Huan Jin and Tianxiang Cui},
  doi          = {10.1016/j.swevo.2025.102160},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102160},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An evolutionary method with shift pattern learning for real-world multi-skilled personnel scheduling with flexible shifts},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm for integrated design-production-distribution scheduling problems in mass personalized customization. <em>SWEVO</em>, <em>99</em>, 102158. (<a href='https://doi.org/10.1016/j.swevo.2025.102158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, new requirements are proposed for the manufacturing industry transitioning to distributed production models due to emergence of mass personalized customization. Integrated scheduling of design, production and distribution, mixed management of batch and flexible manufacturing are becoming the imminent challenges faced by enterprises. This article proposes an integrated design-production-distribution scheduling problem in distributed mixed shops. It considers distributed flow shops for batch manufacturing and distributed flexible job shops for flexible manufacturing. First, a mixed integer linear programming model is formulized to minimize the maximum completion time, total costs, and total tardiness. Second, a learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm is developed to settle the model. Genetic operators are adopted to improve the global and local search abilities. Three subpopulations with adaptive crossover and mutation probabilities are constructed to enhance the convergence and diversity of population. A Q-learning-assisted cooperative approach is adopted to realize the information communication among subpopulations in the genetic operations. The Q-learning method is used to intelligently choose parent individuals from three subpopulations by utilizing its self-learning strategies. A variable neighborhood search approach considering problem-knowledge neighborhood structures is devised to refine the excellent individuals in population. Finally, the presented algorithm is compared against three well-known intelligent optimization methods on a collection of instances. Comparison outcomes verify the superiority of the developed algorithm in handling the considered problem.},
  archive      = {J_SWEVO},
  author       = {Yanhe Jia and Wei Wang and Jian Zhang},
  doi          = {10.1016/j.swevo.2025.102158},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102158},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm for integrated design-production-distribution scheduling problems in mass personalized customization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster and reinforcement learning-based multi-objective evolutionary algorithm for joint scheduling of virtual machines and prioritize tasks in cloud computing. <em>SWEVO</em>, <em>99</em>, 102156. (<a href='https://doi.org/10.1016/j.swevo.2025.102156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, cloud computing is considered an essential on-demand service that is facing an ongoing problem in Virtual Machine (VM) placement and task scheduling optimization that simultaneously improves server efficiency and user experience. Considering these challenges, this paper aims to reduce the makespan, cost, and total tardiness in Joint Scheduling of Virtual Machines and Prioritize Tasks (JSVPT) by a multi-objective optimization framework. We designed a novel Cluster-Based Multi-Objective Evolutionary Algorithm (MOEA-CD/RLPD) framework, which includes a three-tier encoding scheme with Reinforcement Learning (RL)-guided local search, preselection, and dynamic resource allocation strategy to solve the problem. To guide the search process, we employ K-means clustering to decompose the population into diverse subgroups, promoting balanced exploration. The pre-selection mechanism uses a classifier to identify promising solutions in the decision space, which allows resources to be used effectively. Reinforcement learning adaptively selects intensification operators based on reward feedback, improving exploitation by intensifying promising regions of the search space. An Improved Strength Pareto Evolutionary Algorithm 2 (ISPEA2) is incorporated to maintain a diverse and high-quality Pareto archive. The performance of the proposed algorithm is assessed on multiple test instances covering different scales and benchmarked against five state-of-the-art Multi-Objective Evolutionary Algorithms (MOEAs). Experimental studies demonstrate that the proposed algorithm outperforms most existing algorithms in the literature.},
  archive      = {J_SWEVO},
  author       = {Aanchal Agrawal and Arun Kumar Pal},
  doi          = {10.1016/j.swevo.2025.102156},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102156},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Cluster and reinforcement learning-based multi-objective evolutionary algorithm for joint scheduling of virtual machines and prioritize tasks in cloud computing},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAFSP with limited assembly buffers: A deadlock-free coding-decoding paradigm and hybrid cooperative co-evolutionary approach. <em>SWEVO</em>, <em>99</em>, 102155. (<a href='https://doi.org/10.1016/j.swevo.2025.102155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most prior studies on the Distributed Assembly Flowshop Scheduling Problem (DAFSP) presume infinite buffer capacity for assembly machines. However, in practical DAFSP, assembly buffers are often limited, potentially leading to a deadlock where buffers are full of jobs yet none of them can be assembled into a product. Since the deadlock in DAFSP is caused by incorrect jobs’ sequences in assembly buffers, we formulate a Petri net to model this entry process for the first time. Based on this Petri net model and improved Banker algorithm (IBA), we develop a polynomial-complexity algorithm IDAM to ensure the deadlock-free decoding of a DAFSP solution, which is coded by job and factory permutations. The makespan of such a solution is calculated backward to maintain its deadlock-free property. Furthermore, according to the proposed coding-decoding paradigm for deadlock-free solutions, we propose a hybrid cooperative co-evolution (HCCE) algorithm for DAFSP to minimize the makespan. Notably, our HCCE algorithm incorporates an elite archive (EAR) and two subpopulations. It employs problem-specific operators for heuristic initialization and global-search procedures, and four local-search operators are successively applied to every individual in the EAR. Finally, comprehensive experiments demonstrate the effectiveness and superiority of the proposed HCCE algorithm.},
  archive      = {J_SWEVO},
  author       = {Siyi Wang and Yanxiang Feng and Xiaoling Li and Guanghui Zhang},
  doi          = {10.1016/j.swevo.2025.102155},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102155},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DAFSP with limited assembly buffers: A deadlock-free coding-decoding paradigm and hybrid cooperative co-evolutionary approach},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective combination of mechanisms for particle swarm optimization-based ensemble strategy. <em>SWEVO</em>, <em>99</em>, 102154. (<a href='https://doi.org/10.1016/j.swevo.2025.102154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-quality ensemble strategy can effectively integrate several coefficients, mechanisms, and algorithms into a single framework. The adaptability, timing of intervention, and complementarity are the key factors to consider for the selected coefficients, mechanisms, and algorithms. In this study, two complementary variants based on Particle Swarm Optimization (PSO), namely Modified PSO (MPSO) and Social Learning PSO (SLPSO), were selected, forming IMPSO and ISLPSO after improvements. IMPSO excels at exploration, while ISLPSO excels at exploitation. The Improved Novel Ratio Adaptation Scheme (INRAS) is employed as a selection strategy and provides the ability to abandon less-optimal particles. The Modified Nonlinear Population Size Reduction (MNLPSR) enables the extension of generations, allowing for more sufficient evolution in later stages. Due to the use of MNLPSR, an improved inertia weight and adaptive acceleration coefficients are introduced to ensure compatibility with the proposed algorithm. Additionally, an improved dynamic differential mutation strategy is designed not only to be compatible with the proposed algorithm but also to enhance particle diversity. Both the Improved Sine Cosine Algorithm (ISCA) and Sequential Quadratic Programming (SQP), which focus on searching near the global best particles, are incorporated into the proposed ensemble strategy. This PSO-based variant is named the Effective Combination of Mechanisms for a PSO-based Ensemble Strategy (ECM-PSOES). Ablation experiments demonstrated the effectiveness of the individual coefficients and mechanisms. The novel PSO-based variant was evaluated on the CEC2017 benchmarks and compared with 14 state-of-the-art PSO-based variants and 11 non-PSO algorithms. Additionally, to evaluate the flexible and robust capability of the proposed algorithm, three real-world applications for long-term Transmission Network Expansion Planning (TNEP), Planetary Gear Train Design (PGTD), and Robot Gripper Design (RGD) were tested. The experimental results illustrate that the proposed algorithm displays superior performance compared to recently proposed PSO-based variants and most non-PSO algorithms. However, the proposed algorithm falls short of outperforming Differential Evolution (DE)-based algorithms and still requires time to match the performance of top-tier metaheuristics. The source code of ECM-PSOES is provided at https://github.com/microhard1999/CODES .},
  archive      = {J_SWEVO},
  author       = {Libin Hong and Zhantao Gu and Ruibin Bai and John Woodward and Ender Özcan},
  doi          = {10.1016/j.swevo.2025.102154},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102154},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An effective combination of mechanisms for particle swarm optimization-based ensemble strategy},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive weight optimization algorithm based on decision variable grouping for large-scale multi-objective optimization problems. <em>SWEVO</em>, <em>99</em>, 102149. (<a href='https://doi.org/10.1016/j.swevo.2025.102149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving large-scale multi-objective optimization problems (LSMOPs), the optimization effect of traditional multi-objective optimization algorithms deteriorates as the number of decision variables increases. The weight optimization method based on problem transformation can effectively address LSMOPs, demonstrating superior convergence compared to most evolutionary algorithms. However, existing problem transformation methods often fail to balance convergence and diversity, leading to get trapped in local optima. In order to effectively solve this problem, we propose an adaptive weight optimization algorithm based on variable grouping (GWOEA). The algorithm optimizes weights within groups to accelerate population convergence, while the adaptive control strategy boosts diversity, avoiding local optima and ensuring a balance between convergence and diversity during the optimization process. To reduce the size of solving LSMOPs, weight optimization is performed by grouping decision variables. The weights of variables within each group are first computed, and then these weights are directly optimized instead of the decision variables. The adaptive control strategy is designed to detect whether population evolution has stagnated and to handle stagnant populations, ensuring that the population retains its ability to explore. To evaluate the effectiveness of GWOEA, comprehensive comparative experiments are conducted on benchmark test problems, including variable sizes ranging from 500 to 5000. The results show that the proposed algorithm has relatively better optimization performance.},
  archive      = {J_SWEVO},
  author       = {Hao Wang and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.102149},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102149},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An adaptive weight optimization algorithm based on decision variable grouping for large-scale multi-objective optimization problems},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GTG-ACO: Graph transformer guided ant colony optimization for learning heuristics and pheromone dynamics for combinatorial optimization. <em>SWEVO</em>, <em>99</em>, 102147. (<a href='https://doi.org/10.1016/j.swevo.2025.102147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization (CO) problems are fundamental to numerous real-world applications, ranging from logistics and scheduling to resource allocation. For solving CO problems, Ant Colony Optimization (ACO) is a widely used metaheuristic that simulates cooperative foraging behavior to iteratively construct high-quality solutions. However, traditional ACO suffers from handcrafted heuristic functions that fail to generalize across different instances and uniform pheromone initialization, which results in inefficient exploration and slow convergence. To address these limitations, we introduce G raph T ransformer G uided A nt C olony O ptimization- GTG-ACO , a novel approach that jointly learns both heuristic and initial pheromone matrices, enabling the model to generalize across diverse problem instances without manual tuning. Additionally, GTG-ACO employs Graph Transformer augmented with Squeeze-and-Excitation (SE) network as the backbone for heuristic and pheromone learner. The Graph Transformers enable adaptive representation learning by leveraging attention mechanisms to dynamically capture structural relationships in graph representation of combinatorial optimization problems. Additionally, SE networks enhance the model by recalibrating feature importance, ensuring that critical information is amplified while suppressing less relevant features. Extensive evaluations on four combinatorial optimization problems—Traveling Salesman Problem (TSP), Capacitated Vehicle Routing Problem (CVRP), Single Machine Total Weighted Tardiness Problem (SMTWTP) and Bin Packing Problem (BPP)—demonstrate that GTG-ACO consistently outperforms state-of-the-art baselines achieving improvements ranging from 1% to 56%. Furthermore, we validate its real-world applicability by evaluating it on benchmark datasets TSPLIB and CVRPLIB. Thus, GTG-ACO establishes itself as a powerful and generalizable framework by jointly learning heuristic and pheromone matrices, enabling more informed exploration, which leads to superior solution quality in combinatorial optimization problems. Our code is publicly available at https://github.com/abrarrahmanabir/GTG-ACO .},
  archive      = {J_SWEVO},
  author       = {Abrar Rahman Abir and Muhammad Ali Nayeem and M. Sohel Rahman and Md Adnan Arefeen},
  doi          = {10.1016/j.swevo.2025.102147},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102147},
  shortjournal = {Swarm Evol. Comput.},
  title        = {GTG-ACO: Graph transformer guided ant colony optimization for learning heuristics and pheromone dynamics for combinatorial optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic performance evaluation of evolutionary multi-objective optimization algorithms for gait cycle optimization of a 25-DOFs NAO humanoid robot. <em>SWEVO</em>, <em>99</em>, 102144. (<a href='https://doi.org/10.1016/j.swevo.2025.102144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are increasingly using optimization methods to achieve optimal dynamic performance of humanoid robots, often involving multiple conflicting objectives. Multi-objective optimization algorithms (MOAs) aim to find a Pareto front of optimal solutions, but selecting the best algorithm based on solution quality and computational efficiency remains challenging. This study comprehensively evaluates MOAs from different paradigms: swarm intelligence (CMOPSO), genetic algorithms (NSGA-II, DCNSGA-III), and decomposition-based approaches (CMOEA/D) for optimizing the gait cycle of a 25 DOF NAO humanoid robot during single support phase (SSP) and double support phase (DSP) scenarios. The algorithms’ convergence, diversity, and constraint-handling capabilities are systematically analyzed in solving the gait generation problem. The bi-objective optimization simultaneously minimizes power consumption and maximizes dynamic stability subject to eight functional constraints with 12-13 decision parameters. Through performance evaluation using running inverted generational distance (IGD) and hypervolume (HV) metrics across eleven independent runs of each algorithm, NSGA-II emerges as the most suitable algorithm, demonstrating superior convergence and solution quality, while CMOPSO shows competitive performance with faster initial convergence. DCNSGA-III exhibits moderate performance with constraint-handling difficulties, and CMOEA/D demonstrates poor convergence characteristics requiring significantly more computational resources. Two distinct knee regions emerge during both SSP and DSP, representing optimal trade-off solutions, with a systematic framework provided for practitioners to select appropriate gait parameters based on operational priorities. The running IGD metric combined with HV validation demonstrates effectiveness in providing robust algorithmic insights, enabling practitioners to select suitable algorithms for similar complex real-world optimization problems.},
  archive      = {J_SWEVO},
  author       = {Pushpendra Gupta and Dilip Kumar Pratihar and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.102144},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102144},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Dynamic performance evaluation of evolutionary multi-objective optimization algorithms for gait cycle optimization of a 25-DOFs NAO humanoid robot},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive landscape-aware repelling restart covariance matrix adaptation-evolution strategy for multimodal and global optimization. <em>SWEVO</em>, <em>99</em>, 102143. (<a href='https://doi.org/10.1016/j.swevo.2025.102143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal optimization using Covariance Matrix Adaptation-Evolution Strategy (CMA-ES), redundant restarts are caused by repeated convergence to previously explored local basins, which leads to significant computational resource waste. To address this problem, previous research proposed the concept of Repelling Restart and developed RR-CMA-ES, but issues remain regarding rigid repulsion and gradient information of local basin structures. Building on this foundation, we propose an Adaptive Landscape-aware Repelling Restart CMA-ES (ALR-CMA-ES) that enhances the original RR-CMA-ES through three key improvements: 1) A fitness sensitive dynamic exclusion mechanism that adaptively adjusts tabu region radius based on local optimality and convergence frequency, prioritizing avoidance of high-quality basins; 2) A covariance matrix mechanism preserving convergence history to geometrically align hyper-ellipsoidal exclusion regions with explored local basin landscapes; 3) A Boltzmann-like probabilistic acceptance scheme incorporating exclusion regions, permit- ting controlled exploration near tabu boundaries. Experiments on the BBOB benchmark demonstrate that ALR-CMA-ES outperforms RR-CMA-ES in 90% of tested problems spanning 2D to 50D. This method provides a practical solution for expensive black-box optimization by systematically integrating landscape topology awareness into tabu mechanisms, while proposing a new solution for multimodal optimization problems.},
  archive      = {J_SWEVO},
  author       = {Xikang Wang and Tongxi Wang and Hua Xiang},
  doi          = {10.1016/j.swevo.2025.102143},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102143},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Adaptive landscape-aware repelling restart covariance matrix adaptation-evolution strategy for multimodal and global optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-learning classification-based multi-objective evolutionary algorithm for machine multi-state energy-efficient flexible job shop scheduling under time-of-use pricing. <em>SWEVO</em>, <em>99</em>, 102142. (<a href='https://doi.org/10.1016/j.swevo.2025.102142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the “dual carbon” strategic goals, the coordinated optimization of energy consumption and production efficiency has become a core issue for manufacturing industries. As an important means to promote energy structure transformation, electric substitution has made significant progress in industrial manufacturing, transportation, household electrification, and other fields. Among them, industrial production accounts for over 60% of the total electric energy substitution, becoming the largest electricity consumer. Note that the electricity price is based on time-of-use pricing (TOU), meanwhile, electric consumption is related to the machine multi-state (MM). Regarding these matters, this study focuses on determining sensible machine states and formulating reasonable production scheduling plan, to minimize both production time and power consumption. First, a novel energy-efficient flexible job shop scheduling problem is developed, which considers both the TOU strategy and the MM conditions (EFJSP-MM-TOU). Second, a self-learning classification-based multi-objective evolutionary algorithm (SCMOEA) is proposed to solve the EFJSP-MM-TOU. In specific, the SCMOEA enhances population diversity through a hybrid initialization strategy, adopts a dynamic selection of cross individuals based on the self-learning classification mechanism to improve the search efficiency, and designs four local search operators to increase the potential for approaching better positions. Third, by employing the MK standard dataset in EFJSP-MM-TOU, the proposed SCMOEA is compared with its three variants and five state-of-the-art algorithms to verify its optimization performance. The experimental results suggest that SCMOEA has advantages in terms of Pareto optimal solutions’ diversity and convergence. Finally, by testing in an actual enterprise case, the results further support the effectiveness of the EFJSP-MM-TOU and the significance of SCMOEA.},
  archive      = {J_SWEVO},
  author       = {Da Wang and Lina Qian and Kai Zhang and Dengwang Li and Shicun Zhao and Junqing Li},
  doi          = {10.1016/j.swevo.2025.102142},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102142},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A self-learning classification-based multi-objective evolutionary algorithm for machine multi-state energy-efficient flexible job shop scheduling under time-of-use pricing},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using genetic programming to improve data collection for offline reinforcement learning. <em>SWEVO</em>, <em>99</em>, 102140. (<a href='https://doi.org/10.1016/j.swevo.2025.102140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (RL) learns policies solely from fixed pre-collected datasets, making it applicable to use-cases where data collection is expensive or risky. Consequently, the performance of these offline learners is highly dependent on the dataset used. Still the questions of how this data is collected and what dataset characteristics are needed are not thoroughly investigated. Simultaneously, evolutionary methods have reemerged as a promising alternative to classic RL, leading to the field of evolutionary RL (EvoRL), combining the two learning paradigms to exploit their supplementary attributes. This study aims to join these research directions and examine the effects of Genetic Programming (GP) on dataset characteristics in RL and its potential to enhance the performance of offline RL algorithms. A comparative approach was employed, comparing Deep Q-Networks (DQN) and GP for data collection across multiple environments and collection modes. The exploration and exploitation capabilities of these methods were quantified and a comparative analysis was conducted to determine whether data collected through GP led to superior performance in multiple offline learners. The findings indicate that GP demonstrates strong and stable performance in generating high-quality experiences with competitive exploration. GP exhibited lower uncertainty in experience generation compared to DQN and produced high trajectory quality datasets across all environments. More offline algorithms showed statistically significant performance gains with GP-collected data than trained on DQN-collected trajectories. Furthermore, their performance was less dependent on the environment, as the GP consistently generated high-quality datasets. This study showcases the effective combination of GP's properties with offline learners, suggesting a promising avenue for future research in optimizing data collection for RL.},
  archive      = {J_SWEVO},
  author       = {David Halder and Georgios Douzas and Fernando Bacao},
  doi          = {10.1016/j.swevo.2025.102140},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102140},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Using genetic programming to improve data collection for offline reinforcement learning},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple direction search algorithm for continuous optimization. <em>SWEVO</em>, <em>99</em>, 102138. (<a href='https://doi.org/10.1016/j.swevo.2025.102138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The particle swarm optimization algorithm has been successfully applied to various optimization problems. One of its key features is the combination of particle velocity and search direction towards the optimal position in the history and swarm. Recognizing the limitations of the particle swarm optimization algorithm, this paper proposes a new evolutionary algorithm called the multiple direction search algorithm. The algorithm integrates five different search directions, including a multi-point direction constructed using principal component analysis. The integrated direction is generated by the weighted sum of the search directions. Theoretical analysis shows that under mild conditions, the rate of convergence along the weighted direction is no worse than the rate of convergence along the best of single search directions by a positive constant, or even faster in certain cases. The performance of the proposed algorithm was evaluated on three benchmark test suites by computer simulation. Experimental results demonstrate that the proposed method outperforms seven state-of-the-art particle swarm optimization algorithms.},
  archive      = {J_SWEVO},
  author       = {Wei Huang and Jun He and Liehuang Zhu},
  doi          = {10.1016/j.swevo.2025.102138},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102138},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A multiple direction search algorithm for continuous optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-tightening based adaptive two-stage evolutionary algorithm for constrained multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102137. (<a href='https://doi.org/10.1016/j.swevo.2025.102137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) are prevalent in practical applications, yet existing methods often struggle to handle their diverse characteristics, such as disconnected feasible regions and infeasible solutions near the true constraints Pareto front (CPF). To address these challenges, this paper proposes a constraint-tightening based adaptive two-stage evolutionary algorithm (CT-TSEA) for CMOPs, incorporating a constraint boundary tightening strategy and parameter dynamic adjustment strategy. In the first stage, a constraint boundary tightening strategy based on evaluation counts guides the population toward feasible regions. Initially, constraint boundaries are relaxed to explore the solution space thoroughly, identifying promising solutions. As evaluations increase, the search boundaries shrink, enhancing the feasibility of solutions. Additionally, a step-size adaptive adjustment method improves infeasible solutions using their information, boosting search efficiency and solution diversity. The second stage introduces a dynamic adjustment method for crossover probability and scaling factor, balancing exploration and exploitation. It better balances the exploration and exploitation capabilities of the population. The proposed method is validated via comparing with seven state-of-the-art peer competitors across 59 test instances from four benchmark suites and 21 real-world problems. The corresponding results demonstrate that CT-TSEA has the higher competitiveness in addressing complex CMOPs.},
  archive      = {J_SWEVO},
  author       = {Cunyan Liu and Qingda Chen and Junhua Liu and Wei Zhang and Meng Wang and Can Liu},
  doi          = {10.1016/j.swevo.2025.102137},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102137},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Constraint-tightening based adaptive two-stage evolutionary algorithm for constrained multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploratory landscape analysis on black-box optimization problems via graph neural network. <em>SWEVO</em>, <em>99</em>, 102136. (<a href='https://doi.org/10.1016/j.swevo.2025.102136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most real-world optimization problems are poorly understood, some of which are black-box optimization problems (BBOPs). Exploratory landscape analysis (ELA) paves the way for algorithm design to deal with BBOPs. Existing ELA methods have limitations on unseen problems and lack analysis on the problem itself. To this end, this study introduces a novel ELA framework leveraging Graph Neural Network (GNN) upon BBOP’s surrogate model. Specifically, a neural network surrogate model is constructed whose architecture is utilized to represent BBOP in the form of graph. Then, GNN is responsible for capturing the relationships between the graph-represented BBOP and high-level features. As one of the most notable features in optimization, multimodality of multi-objective problems is to be identified for illustration. More than 99% accuracy on independent test set demonstrates the effectiveness of the proposed framework with simultaneously avoiding the effect of problem dimensions.},
  archive      = {J_SWEVO},
  author       = {Xu Yang and Rui Wang and Kaiwen Li and Wenhua Li and Tao Zhang},
  doi          = {10.1016/j.swevo.2025.102136},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102136},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Exploratory landscape analysis on black-box optimization problems via graph neural network},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention-based joint value estimation strategy for multi-agent coordination optimization. <em>SWEVO</em>, <em>99</em>, 102132. (<a href='https://doi.org/10.1016/j.swevo.2025.102132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordination optimization plays a vital role in complex multi-agent systems, and Multi-Agent Reinforcement Learning (MARL) has emerged as a widely adopted solution. However, MARL still faces significant challenges in this domain, including low coordination efficiency and inaccurate value estimation. To address these issues, we propose MVAPO, a novel Multi-Head Joint Value Attention-based Policy Optimization algorithm that improves policy learning through enhanced value approximation and selective attention to agent contributions. The key innovation of MVAPO lies in the introduction of a joint value network augmented with a multi-head attention mechanism. In this mechanism, context-aware team rewards serve as query inputs, directing attention to the most relevant agents in different situations. This allows the model to dynamically focus on the agents that are most critical at any given time, thus improving coordination efficiency and the accuracy of value estimates. Furthermore, MVAPO incorporates feedforward and residual layers, eliminating linear and monotonic constraints, which significantly enhances its representational capacity. Extensive experiments on a multi-UAV benchmark across a variety of scenarios demonstrate that MVAPO consistently outperforms state-of-the-art methods in both reward acquisition and win rates, highlighting its superior performance and robustness.},
  archive      = {J_SWEVO},
  author       = {Ze Wang and Ni Li and Guanghong Gong and Haitao Yuan},
  doi          = {10.1016/j.swevo.2025.102132},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102132},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An attention-based joint value estimation strategy for multi-agent coordination optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA2MODE: Dynamic archive with adaptive multi-operator differential evolution for numerical optimization. <em>SWEVO</em>, <em>99</em>, 102130. (<a href='https://doi.org/10.1016/j.swevo.2025.102130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Dynamic Archive with Adaptive Multi-Operator Differential Evolution (DA2MODE), a new algorithm that aims to boost the performance of meta-heuristic and evolutionary methods in numerical optimization. DA2MODE introduces a Progressive Adaptive Selector with Exponential Smoothing (PASES), which dynamically updates the selection probabilities of both mutation and crossover operators. Unlike prior approaches that emphasize only mutation operators or rely on short-term success within the current generation, PASES adapts based on cumulative operator performance over time, thus favoring the best-performing operators more reliably. DA2MODE employs an Adaptive Non-Elite Archive Update (ANEAU) mechanism that injects a controlled fraction of non-elite solutions into the archive. ANEAU promotes early exploration, which is gradually reduced to strengthen exploitation. Additionally, the control parameters (crossover probability and mutation factor) are automatically tuned in DA2MODE, allowing full adaptivity of both operator selection and parameter control. Extensive experiments on the CEC2017/2018, CEC2020-2022, and 1000-dimensional CEC2013 benchmarks, along with four real-world engineering design problems, confirm that DA2MODE consistently outperforms 33 competitive algorithms, including CEC winners and recent advanced DE variants. It achieves top performance across all statistical tests, demonstrating superior convergence speed and final accuracy. These results establish DA2MODE as a robust, scalable, and reliable algorithm for solving complex numerical optimization problems. The source code of the DA2MODE algorithm is publicly available at: URL https://github.com/MohamedRedaMu/DA2MODE-Algorithm and URL https://uk.mathworks.com/matlabcentral/fileexchange/182019-da2mode-algorithm .},
  archive      = {J_SWEVO},
  author       = {Mohamed Reda and Ahmed Onsy and Amira Y. Haikal and Ali Ghanbari},
  doi          = {10.1016/j.swevo.2025.102130},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102130},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DA2MODE: Dynamic archive with adaptive multi-operator differential evolution for numerical optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale multi-objective optimization framework based on a dual-space attention mechanism. <em>SWEVO</em>, <em>99</em>, 102089. (<a href='https://doi.org/10.1016/j.swevo.2025.102089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing attention-based methods for large-scale multi-objective optimization (LMOAM) focus only on decision variables, using their variance to guide search behavior. However, single-space strategies ignore critical information in the objective space and the diversity and search efficiency are often degraded for solving multimodal multi-objective optimization problems (MOPs). To address this problem, a novel large-scale optimization framework that integrates a dual-space attention mechanism is proposed in this paper. Different from building attention only with information in decision space, a dual-space Key matrix that quantifies variable importance by combining decision-variable and objective-space distributions is first designed in the framework to refine the precision of the attention. Subsequently, a cross-space clustering method is adopted to select the representative solutions by analyzing the characteristics of individuals in both spaces to construct the Query matrix. The accuracy of attention allocation is improved. Finally, A linear inverse mapping strategy is used to enhance the diversity of the population by translating promising objective-space solutions back to the decision space. Unlike existing approaches, the characteristics of decision and objective space are linked with a new attention mechanism, and the exploration and exploitation of the population are well balanced. Three types of experiments are designed on two benchmark test sets with 500-dimensional and 1000-dimensional decision variables and the voltage transformer optimization problem to demonstrate the efficacy of the AIDF framework, experimental results indicate that AIDF surpasses comparative algorithms in terms of the average performance of IGD and HV.},
  archive      = {J_SWEVO},
  author       = {Xu Li and Debao Chen and Feng Zou and Fangzhen Ge and Zhenghua Xin},
  doi          = {10.1016/j.swevo.2025.102089},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102089},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A large-scale multi-objective optimization framework based on a dual-space attention mechanism},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PheroCom: Decentralised and asynchronous robot swarm coordination framework based on virtual pheromone and vibroacoustic communication. <em>SWEVO</em>, <em>99</em>, 102083. (<a href='https://doi.org/10.1016/j.swevo.2025.102083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing and controlling the dynamics of stigmergic substances used by bio-inspired approaches pose significant challenges when applied to robotics. In order to overcome this challenge, this work proposes a framework based on the virtualisation and control of these substances at a local scope, with the primary goal of coordinating robot swarms. This framework introduces a novel pheromone representation that enables decentralisation and decision asynchronicity, while its lightweight design ensures accessibility to resource-constrained platforms. Each robot maintains an independent virtual pheromone map in its memory, which is continuously updated through its own pheromone deposits and evaporation. Additionally, each robot’s pheromone map is also updated by aggregating information from other robots that are exploring nearby areas. Consequently, individual and independent maps eliminate the need for a centralised agent to manage and distribute pheromone information. This propagation mechanism is inspired by ants’ vibroacoustic communication, which is characterised as a form of indirect communication. The framework was evaluated using an agent-based mass simulation tool and a real-world simulation platform. Experiments were conducted to validate the framework in diverse environments, with variations in shapes, sizes, and the number of robots. Results demonstrated that this proposal can effectively perform the coordination of robot swarms, and the robots have exhibited satisfactory performance while executing the surveillance task.},
  archive      = {J_SWEVO},
  author       = {Claudiney R. Tinoco and Luiz Gustavo A. Martins and Gina M.B. Oliveira},
  doi          = {10.1016/j.swevo.2025.102083},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102083},
  shortjournal = {Swarm Evol. Comput.},
  title        = {PheroCom: Decentralised and asynchronous robot swarm coordination framework based on virtual pheromone and vibroacoustic communication},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tcs">TCS - 3</h2>
<ul>
<li><details>
<summary>
(2025). Optimal gathering of robots in anonymous butterfly networks via leader election. <em>TCS</em>, <em>1057</em>, 115553. (<a href='https://doi.org/10.1016/j.tcs.2025.115553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots with very weak capabilities placed on the vertices of a graph are required to move toward a common vertex from where they do not move anymore. The task is known as the Gathering problem and it has been extensively studied in the last decade with respect to both general graphs and specific topologies. Most of the challenges faced are due to possible isometries observable from the placement of the robots with respect to the underlying topology. Rings, Grids, and Complete graphs are just a few examples of very regular topologies where the placement of the robots and suitable movements are crucial for succeeding in Gathering. Here we are interested in understanding what can be done in Butterfly graphs where really many isometries are present and most importantly unavoidable by any movement. We propose a Gathering algorithm for the so-called leader configurations, i.e., those where the initial placement of the robots admits the detection (and election) of one robot as the leader. We introduce a non-trivial technique to elect the leader which is of its own interest. We also prove that the proposed Gathering algorithm is asymptotically optimal in terms of synchronous rounds required.},
  archive      = {J_TCS},
  author       = {Serafino Cicerone and Alessia Di Fonso and Gabriele Di Stefano and Alfredo Navarra},
  doi          = {10.1016/j.tcs.2025.115553},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115553},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Optimal gathering of robots in anonymous butterfly networks via leader election},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient shape formation by 3D hybrid programmable matter: An algorithm for low diameter intermediate structures. <em>TCS</em>, <em>1057</em>, 115552. (<a href='https://doi.org/10.1016/j.tcs.2025.115552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the shape formation problem within the 3D hybrid model, where a single agent with a strictly limited viewing range and the computational capacity of a deterministic finite automaton manipulates passive tiles through pickup, movement, and placement actions. The goal is to reconfigure a set of tiles into a specific shape termed an icicle . The icicle, identified as a dense, hole-free structure, is strategically chosen to function as an intermediate shape for more intricate shape formation tasks. It is designed for easy exploration by a finite-state agent, enabling the identification of tiles that can be lifted without breaking connectivity. Compared to the line shape, the icicle presents distinct advantages, including a reduced diameter and the presence of multiple removable tiles. We propose an algorithm that transforms an arbitrary initially connected tile structure into an icicle in O ( n 3 ) steps, matching the runtime of the line formation algorithm from prior work. Our theoretical contribution is accompanied by an extensive experimental analysis, indicating that our algorithm decreases the diameter of tile structures on average.},
  archive      = {J_TCS},
  author       = {Kristian Hinnenthal and David Liedtke and Christian Scheideler},
  doi          = {10.1016/j.tcs.2025.115552},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115552},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient shape formation by 3D hybrid programmable matter: An algorithm for low diameter intermediate structures},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On shuffling and splitting automata. <em>TCS</em>, <em>1057</em>, 115539. (<a href='https://doi.org/10.1016/j.tcs.2025.115539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of finite state three-tape transducers which models the operation of shuffling and splitting words. We present them as automata over the so-called Shuffling Monoid. These automata can be seen as either shufflers or splitters interchangeably. We prove that functionality is decidable for splitters, and we also show that the equivalence between functional splitters is decidable. Moreover, in the deterministic case, the algorithm for equivalence is polynomial on the number of states of the splitter.},
  archive      = {J_TCS},
  author       = {Ignacio Mollo Cunningham},
  doi          = {10.1016/j.tcs.2025.115539},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115539},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On shuffling and splitting automata},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
