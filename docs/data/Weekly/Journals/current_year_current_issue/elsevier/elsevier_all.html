<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>elsevier</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij">AIJ - 1</h2>
<ul>
<li><details>
<summary>
(2025). The topology of surprise. <em>AIJ</em>, <em>349</em>, 104423. (<a href='https://doi.org/10.1016/j.artint.2025.104423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a topological epistemic logic, with modalities for knowledge (modelled as the universal modality), knowability (represented by the topological interior operator), and unknowability of the actual world. The last notion has a non-self-referential reading (modelled by Cantor derivative: the set of limit points of a given set) and a self-referential one (modelled by Cantor's perfect core of a given set: its largest subset without isolated points, where x is isolated iff { x } is open). We completely axiomatize this logic, showing that it is decidable and pspace -complete, and we apply it to the analysis of a famous epistemic puzzle: the Surprise Exam Paradox.},
  archive      = {J_AIJ},
  author       = {Alexandru Baltag and Nick Bezhanishvili and David Fernández-Duque},
  doi          = {10.1016/j.artint.2025.104423},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104423},
  shortjournal = {Artif. Intell.},
  title        = {The topology of surprise},
  volume       = {349},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="amc">AMC - 20</h2>
<ul>
<li><details>
<summary>
(2026). Local stabilization of boolean control networks via stochastic sampled-data control. <em>AMC</em>, <em>511</em>, 129746. (<a href='https://doi.org/10.1016/j.amc.2025.129746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a stochastic sampled-data control framework for the local stabilization of Boolean control networks, where the sampling intervals are assumed to be independent and identically distributed random variables. A fundamental equivalence is established between the convergence of the full system state sequence and that of the sampled state subsequence. Based on the equivalence, we propose methods to determine the largest finite-time stabilizable region and the largest asymptotically stabilizable region, respectively. Corresponding control design strategies are provided to achieve stabilization within these regions. Moreover, a unified control scheme is proposed to simultaneously ensure both finite-time and asymptotic stabilization within their respective largest stabilizable regions. Finally, the applicability of the methods is demonstrated using two examples.},
  archive      = {J_AMC},
  author       = {Bingquan Chen and Bowen Li and Tao Wu and Yanling Zheng},
  doi          = {10.1016/j.amc.2025.129746},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129746},
  shortjournal = {Appl. Math. Comput.},
  title        = {Local stabilization of boolean control networks via stochastic sampled-data control},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep neural network-based adaptive supervisory control for strict-feedback nonlinear systems with sensor and actuator faults. <em>AMC</em>, <em>511</em>, 129745. (<a href='https://doi.org/10.1016/j.amc.2025.129745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the adaptive supervisory control problem for strict-feedback nonlinear systems with sensor and actuator faults, where some healthy actuators serve as backups. A deep neural network whose weights are updated in real-time is introduced to approximate the unknown nonlinearities. Based on this deep neural network, an adaptive supervisory control scheme without overparameterization is developed to ensure the prescribed performance of the resulting closed-loop systems by switching from the current faulty actuator to the subsequent healthy one. It is shown that the proposed deep neural network-based adaptive supervisory control scheme can achieve superior tracking performance to the traditional two-layer neural network-based adaptive supervisory control scheme. Finally, a numerical example is provided to validate the effectiveness of the presented control scheme.},
  archive      = {J_AMC},
  author       = {Shanshan Guo and Jinghao Li and Guang-Hong Yang},
  doi          = {10.1016/j.amc.2025.129745},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129745},
  shortjournal = {Appl. Math. Comput.},
  title        = {Deep neural network-based adaptive supervisory control for strict-feedback nonlinear systems with sensor and actuator faults},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The list r-hued coloring of p5-free graph. <em>AMC</em>, <em>511</em>, 129742. (<a href='https://doi.org/10.1016/j.amc.2025.129742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a list L of graph G , an ( L , r ) -coloring of graph G is a proper coloring such that the color of vertex v belongs to its list L ( v ) , and each vertex of degree d G ( v ) is adjcent to vertices with at least min { r , d G ( v ) } different colors. The list r -hued chromatic number, denoted by χ L , r ( G ) , is the smallest integer k such that for any k -list L of G , G has an ( L , r ) -coloring. We prove the following: ( i ) If G = G ( U , V ) is a connected P 5 -free bipartite graph and min { | U | , | V | } = s , then χ L , r ( G ) ≤ max { 2 r , s + 1 } . ( i i ) If G is a connected P 5 -free graph and r ≤ 3 , then χ L , r ( G ) ≤ r χ L ( G ) .},
  archive      = {J_AMC},
  author       = {Xuanhe Jia and Fengxia Liu and Baiyun Ji and Zihang Zhao},
  doi          = {10.1016/j.amc.2025.129742},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129742},
  shortjournal = {Appl. Math. Comput.},
  title        = {The list r-hued coloring of p5-free graph},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finite-time security E2P filter design of fuzzy discrete-time singular system. <em>AMC</em>, <em>511</em>, 129741. (<a href='https://doi.org/10.1016/j.amc.2025.129741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, privacy protection avoids the disclosure of signals during transmission. This article studies the privacy protection of fuzzy singular systems. Initially, the nonlinear discrete-time singular system is represented using the Takagi-Sugeno (T-S) fuzzy modeling approach. Then, through the output mask technology, the eavesdropper is confused to obtain information. Meanwhile, the load problem of the signal passing through the channel is considered, the signal quantization is considered, and the channel fading problem is considered. On this basis, the stability conditions of the system are given, and a singular filter that satisfies the finite-time Energy-to-Peak (E2P) performance is designed. Ultimately, the proposed method’s effectiveness is substantiated.},
  archive      = {J_AMC},
  author       = {Xin-Yue Zhao and Qingkai Kong and Jianping Zhou},
  doi          = {10.1016/j.amc.2025.129741},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129741},
  shortjournal = {Appl. Math. Comput.},
  title        = {Finite-time security E2P filter design of fuzzy discrete-time singular system},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability analysis of stochastic McKean–Vlasov equations with discrete observation. <em>AMC</em>, <em>511</em>, 129740. (<a href='https://doi.org/10.1016/j.amc.2025.129740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the stability issue of stochastic McKean–Vlasov equations (SMVEs) through an innovative method: stabilization via stochastic delay feedback control with discrete observation. Unlike conventional techniques, this approach leverages historical states instead of solely relying on the current state, setting it apart from traditional stochastic feedback controls. The study examines how the diffusion term contributes to enhancing system stability despite the presence of random fluctuations and delays, guaranteeing both p -th moment exponential stability and almost sure exponential stability under a specific delay threshold δ * . The primary contributions of this work include introducing a novel stability analysis framework utilizing stochastic delay feedback control, constructing Lyapunov functions that incorporate both state and distribution, and providing insights into asymptotic and moment exponential stability. Although identifying the optimal delay δ * remains a practical challenge, the theoretical foundation laid in this study offers valuable guidance for real-world applications.},
  archive      = {J_AMC},
  author       = {Yicheng Liu and Quanxin Zhu},
  doi          = {10.1016/j.amc.2025.129740},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129740},
  shortjournal = {Appl. Math. Comput.},
  title        = {Stability analysis of stochastic McKean–Vlasov equations with discrete observation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-triggered control of robotic systems with obstacle avoidance and velocity constraints: A double integral TTCBLF approach. <em>AMC</em>, <em>511</em>, 129739. (<a href='https://doi.org/10.1016/j.amc.2025.129739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a double integral time-to-collision barrier Lyapunov function (TTCBLF) approach for robotic systems with obstacle avoidance and velocity constraints. The existing barrier function assesses collision risk based solely on distance, neglecting the robot’s velocity, which is also highly relevant to collision risk. To comprehensively assess collision risk, a flexible time-to-collision barrier function (TTCBF) is constructed, enabling the robot to dynamically increase or decrease the amplitude of the original barrier function in advance based on its velocity and distances to obstacles. Then, unlike the self-triggered mechanism (STM) that solely depends on control signals, a velocity constraint function-based STM is designed to save communication resources, with the minimum triggering interval decreasing as the velocity constraint function increases. Through the Lyapunov method and boundedness analysis for the barrier function, it is shown that the proposed approach achieves obstacle avoidance for the robotic systems without violating the velocity constraints, while excluding the Zeno behavior. Finally, numerical simulations are provided to demonstrate the effectiveness of the proposed control approach.},
  archive      = {J_AMC},
  author       = {Longbin Fu and Liwei An},
  doi          = {10.1016/j.amc.2025.129739},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129739},
  shortjournal = {Appl. Math. Comput.},
  title        = {Self-triggered control of robotic systems with obstacle avoidance and velocity constraints: A double integral TTCBLF approach},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Collaborated risk perception against multiple epidemics in a multiplayer network. <em>AMC</em>, <em>511</em>, 129738. (<a href='https://doi.org/10.1016/j.amc.2025.129738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concurrent outbreak of epidemics has become a great threat to public health. An important problem is how individuals can protect themselves as the mandated protective measures are relaxed. Previous studies developed various models to investigate the correlated spreading dynamics of concurrent epidemics and the protective measures against them. However, a critical oversight remains that people’s risk perceptions on multiple epidemics are also correlated or even collaborated. In this paper, we build an SS-IS-SI-II coupled model in a multilayer network to describe two concurrent epidemics, integrating collaborated risk perception and spontaneous social distancing as individuals’ self-protection. Moreover, an adjustable coefficient is proposed to describe different levels of inter-epidemic correlations (competition/independence/cooperation). It is found that increasing the levels of inter-epidemic correlation will increase the infected density of both epidemics. Collaborated risk perception is generally more effective in reducing infections across different levels of inter-epidemic correlation, compared with independent risk perception. But its effect is dependent. For one epidemic, when its infectivity is very high or the infectivity of the other epidemic is very low, the effect of collaborated risk perception will be largely reduced. Based on the model, we further investigate the minimum social distancing required to contain epidemics under different conditions, and the priority on different layers is also explored. This research extends existing literature on co-evolutional epidemic dynamics, and lay a foundation to model correlated risk perceptions against epidemics. The results provide implications for individuals to take self-protection against concurrent epidemics.},
  archive      = {J_AMC},
  author       = {Yahong Chen and He Huang},
  doi          = {10.1016/j.amc.2025.129738},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129738},
  shortjournal = {Appl. Math. Comput.},
  title        = {Collaborated risk perception against multiple epidemics in a multiplayer network},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Superconvergent methods for solving two-dimensional hammerstein integral equations. <em>AMC</em>, <em>511</em>, 129737. (<a href='https://doi.org/10.1016/j.amc.2025.129737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the superconvergent degenerate kernel method and the superconvergent Nyström method for the numerical solution of two-dimensional Hammerstein integral equations of the second kind. By employing piecewise polynomial interpolation of degree r , we prove that, under symmetry conditions on both the triangulation and the interpolation nodes, convergence orders of 2 r + 3 and 2 r + 4 are achieved for the approximate solutions and their iterated versions, respectively. Furthermore, we discuss computational aspects related to the construction of the corresponding nonlinear systems, and we present numerical examples to illustrate the theoretical results obtained.},
  archive      = {J_AMC},
  author       = {M. Sennour and D. Sbibih and M. Tahrichi},
  doi          = {10.1016/j.amc.2025.129737},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129737},
  shortjournal = {Appl. Math. Comput.},
  title        = {Superconvergent methods for solving two-dimensional hammerstein integral equations},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrating emotion and expectation improves cooperation. <em>AMC</em>, <em>511</em>, 129736. (<a href='https://doi.org/10.1016/j.amc.2025.129736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperation is a key issue attracting widespread attention across various fields. Emotions and expectations jointly participate in the decision-making process, and are key factors influencing the evolution of cooperation. Therefore, this paper proposes a game evolution model that considers the dual influences of emotions and expectations. In the model, a player’s initial strategy depends on their emotions. Subsequently, expectations influence the decision-making process, altering the player’s initial strategy to the current strategy. Specifically, high expectations lead players to maintain their initial strategy, whereas low expectations prompt them to change strategies. Furthermore, the paper analyzes the evolution of cooperation in the prisoner’s dilemma and the influence of expectations. Simulation results show that under high betrayal temptation, players with loneliness and defection would change their initial strategy to cooperation due to low expectations, while those players who initially gather with cooperation strategies maintain the cooperation strategies due to higher expectations, ultimately increasing the cooperation fraction and payoff of the population. Therefore, expectations effectively enhance the cooperation level and payoff of the population. When the scale of individuals changing their strategies based on expectations (ICSE) is large, the effect of expectations on enhancing cooperation and payoff is more pronounced. Frequent consideration of anticipated initial strategy changes also yields the same effect. Additionally, mechanisms of the influence of emotion on payoff, direct emotion interaction and the influence of strategy on emotion collectively contribute to enhancing the significantly evolutionary advantage of friendly emotions and cooperation strategies. This paper contributes to a deeper understanding of the role of expectations in the evolution of emotions and cooperation, laying the groundwork for enhancing social cooperation through expectation management.},
  archive      = {J_AMC},
  author       = {Wen Lu and Shu Liang},
  doi          = {10.1016/j.amc.2025.129736},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129736},
  shortjournal = {Appl. Math. Comput.},
  title        = {Integrating emotion and expectation improves cooperation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On sketch-and-project methods for solving tensor equations. <em>AMC</em>, <em>511</em>, 129735. (<a href='https://doi.org/10.1016/j.amc.2025.129735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a regular sketch-and-project method for solving linear tensor equations based on the t-product and present its equivalent Fourier domain version, along with several special cases corresponding to existing classical matrix equation methods. Furthermore, we extend this framework via a hierarchical approach to solve generalized Sylvester tensor equations. All the methods are proved to converge linearly in expectation. Finally, numerical experiments demonstrate the efficiency and effectiveness of the proposed approach.},
  archive      = {J_AMC},
  author       = {Ling Tang and Yanjun Zhang and Hanyu Li},
  doi          = {10.1016/j.amc.2025.129735},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129735},
  shortjournal = {Appl. Math. Comput.},
  title        = {On sketch-and-project methods for solving tensor equations},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sampling patterns for zernike-like bases in non-standard geometries. <em>AMC</em>, <em>511</em>, 129727. (<a href='https://doi.org/10.1016/j.amc.2025.129727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zernike polynomials are widely used in optics and ophthalmology due to their direct connection to classical optical aberrations. While orthogonal on the unit disk, their application to discrete data or non-circular domains–such as ellipses, annuli, and hexagons–presents challenges in terms of numerical stability and accuracy. In this work, we extend Zernike-like orthogonal functions to these non-standard geometries using diffeomorphic mappings and construct sampling patterns that preserve favorable numerical conditioning. We provide theoretical bounds for the condition numbers of the resulting collocation matrices and validate them through extensive numerical experiments. As a practical application, we demonstrate accurate wavefront interpolation and reconstruction in segmented mirror telescopes composed of hexagonal facets. Our results show that appropriately transferred sampling configurations, especially Optimal Concentric Sampling and Lebesgue points , allow stable high-order interpolation and effective wavefront modeling in complex optical systems. Moreover, the Optimal Concentric Samplings can be computed with an explicit expression, which is a significant advantage in practice.},
  archive      = {J_AMC},
  author       = {S. Díaz-Elbal and A. Martínez-Finkelshtein and D. Ramos-López},
  doi          = {10.1016/j.amc.2025.129727},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129727},
  shortjournal = {Appl. Math. Comput.},
  title        = {Sampling patterns for zernike-like bases in non-standard geometries},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving linear and nonlinear caputo fractional differential equations with a quantum pseudo-spectral approach. <em>AMC</em>, <em>511</em>, 129726. (<a href='https://doi.org/10.1016/j.amc.2025.129726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear and nonlinear Caputo time-fractional differential equations play a fundamental role in pure and applied mathematics as well as theoretical physics. This article develops a hybrid methodology that combines quantum computing paradigms with spectral methods to solve such equations, employing shifted fractional Chebyshev polynomials as basis functions. The simultaneous treatment of linear and nonlinear fractional equations requires careful selection of both basis functions and collocation points. This choice proves essential for avoiding the chain rule complication inherent in Caputo’s derivative formulation. Crucially, the chosen basis functions generate a triangular operational matrix, thereby improving both the accuracy and computational efficiency of the pseudo-spectral approach. Within our computational framework, the solution at the terminal time is encoded as a final quantum state. We demonstrate the method’s efficacy through numerical experiments and comparative analysis with existing approaches.},
  archive      = {J_AMC},
  author       = {Saeid Abbasbandy},
  doi          = {10.1016/j.amc.2025.129726},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129726},
  shortjournal = {Appl. Math. Comput.},
  title        = {Solving linear and nonlinear caputo fractional differential equations with a quantum pseudo-spectral approach},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal information spreading strategy for containing epidemic spreading on higher-order multiplex networks. <em>AMC</em>, <em>511</em>, 129725. (<a href='https://doi.org/10.1016/j.amc.2025.129725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When an epidemic spreads through a population, related information also spreads concurrently, prompting individuals to adopt protective behaviours (e.g., washing hands). Collective behaviour has been shown to play a critical role in shaping the dynamics of epidemic spreading, and higher-order networks offer a natural framework to describe such group interactions in social contact networks. Yet, the interplay between epidemic and information dynamics on higher-order structures is not fully understood, further limiting our understanding of the optimal information spreading strategy for containing epidemic spreading.In this study, we first construct a higher-order multiplex network framework based on simplicial complexes. Then, a coevolutionary spreading model is proposed, integrating epidemic spreading and information spreading on simplicial complexes. The epidemic spreads through both lower-order (pairwise) and higher-order (group) interactions, while information spreads through lower-order interactions in a degree-preferential manner. Using an extended Microscopic Markov Chain Approach, we analytically derive the dynamical equations of the system and compute the basic reproduction number using the next-generation matrix method. Finally, we conduct extensive numerical simulations of the spreading process across various parameter regimes. Our results demonstrate the role of higher-order infections in promoting epidemics. Although information spreading generally suppresses the spread of most epidemics, it can paradoxically enhance the spread of certain epidemics with a very low spreading capacity. Increases in the recovery probabilities of both the disease and the information can weaken the promoting effect of higher-order infection and enhance the suppressive effect of the information. For certain epidemics with weak spreading capabilities but strong recovery capabilities, the spread of information can completely suppress the outbreak of the disease, while the enhancement of higher-order infections can promote the outbreak of these diseases. By analysing the effects of different information spreading strategies on epidemic spreading, we find that the optimal strategy for containing the epidemic is to allow information to spread without degree preference.},
  archive      = {J_AMC},
  author       = {Jiayi Song and Wenjie Li and Yunzhu Xiao and Ling Chen and Chun Yang and Li Qi and Wei Wang},
  doi          = {10.1016/j.amc.2025.129725},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129725},
  shortjournal = {Appl. Math. Comput.},
  title        = {Optimal information spreading strategy for containing epidemic spreading on higher-order multiplex networks},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the fairness and cooperation among free-riders. <em>AMC</em>, <em>511</em>, 129724. (<a href='https://doi.org/10.1016/j.amc.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the free-rider problem in peer-to-peer (P2P) systems, where agents enjoy the group effort without contributing their share. We introduce the Free-Rider Game (FRG), a non-cooperative game incorporating a fairness-aware profit allocation rule based on the Robin Hood index. We show that FRG admits strong structural properties. First, making a non-zero contribution is a dominant strategy for any player. Second, a player contributes positively whenever at least one other player does so. Third, FRG admits a unique Nash equilibrium in which each player contributes the fullest, eliminating free riding. Fourth, equilibrium outcomes are proportionally fair, ensuring balanced allocation across agents. Finally, FRG guarantees full participation by embedding fairness directly into the payoff structure, differentiating it from classical public goods games, which often yield zero or partial contributions.},
  archive      = {J_AMC},
  author       = {Avadh Kishor},
  doi          = {10.1016/j.amc.2025.129724},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129724},
  shortjournal = {Appl. Math. Comput.},
  title        = {On the fairness and cooperation among free-riders},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Equilibrium analysis of edge-heterogeneous binary network games. <em>AMC</em>, <em>511</em>, 129723. (<a href='https://doi.org/10.1016/j.amc.2025.129723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies on the equilibrium of binary network games have primarily focused on scenarios characterized by agent heterogeneity, where agents exhibit unique attributes but their interactions with different neighbors remain uniform. In this paper, we investigate the edge-heterogeneous binary network game, a more general framework that incorporates heterogeneity into agent interactions. We establish two sufficient equilibrium conditions under asynchronous best-response dynamics from different perspectives. The first condition requires underlying symmetry in interactions between neighboring agents, integrating and generalizing three classical convergence situations in binary network games. The second condition focuses on network balance, positing that equilibrium is achievable if the coordination value network of a game is structurally balanced. Additionally, for games meeting this condition, we develop a method to predict the final state based on initial state information. These results reveal factors that steer edge-heterogeneous binary network games towards equilibrium, providing valuable insights for controlling such highly nonlinear systems. Lastly, we extend the analysis to higher-order network games and propose an equilibrium condition for edge-heterogeneous 2-order network games.},
  archive      = {J_AMC},
  author       = {Jiawen Wang and Yangyang Luan and Xiaoqun Wu},
  doi          = {10.1016/j.amc.2025.129723},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129723},
  shortjournal = {Appl. Math. Comput.},
  title        = {Equilibrium analysis of edge-heterogeneous binary network games},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Theory and numerics of subspace approximation of eigenvalue problems. <em>AMC</em>, <em>511</em>, 129722. (<a href='https://doi.org/10.1016/j.amc.2025.129722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale eigenvalue problems arise in various fields of science and engineering and demand computationally efficient solutions. In this study, we investigate the subspace approximation for parametric linear eigenvalue problems, aiming to mitigate the computational burden associated with high-fidelity systems. We provide general error estimates under non-simple eigenvalue conditions, establishing some theoretical foundations for understanding the convergence behavior of subspace approximations. Numerical examples, including problems with one-dimensional to three-dimensional spatial domain and one-dimensional to two-dimensional parameter domain, are presented to demonstrate the efficacy of reduced basis method in handling parametric variations in boundary conditions and coefficient fields to achieve significant computational savings while maintaining high accuracy, making them promising tools for practical applications in large-scale eigenvalue computations.},
  archive      = {J_AMC},
  author       = {Siu Wun Cheung and Youngsoo Choi and Seung Whan Chung and Jean-Luc Fattebert and Coleman Kendrick and Daniel Osei-Kuffuor},
  doi          = {10.1016/j.amc.2025.129722},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129722},
  shortjournal = {Appl. Math. Comput.},
  title        = {Theory and numerics of subspace approximation of eigenvalue problems},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). H-function-based state bounding results of discrete-time delayed systems. <em>AMC</em>, <em>511</em>, 129721. (<a href='https://doi.org/10.1016/j.amc.2025.129721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the h -function-based state bounding estimation problem for discrete-time nonlinear systems (DTNSs) with time-varying delays and bounded disturbances. First, a direct method based on the system solutions is proposed to provide sufficient conditions, which are composed of simple inequalities and depend on the time delays, to ensure that the state trajectories of the considered system always stay within a polyhedron or converge into it. Second, it is demonstrated that the obtained sufficient conditions are precisely the global h -stability (G h -S) criteria of the considered system when disturbances disappear, and when the initial function is restricted within a certain range, the resulting polyhedron can be considered as h -function-based reachable set estimation of the states. Finally, the applicability of the theoretical results obtained is illustrated through two numerical examples.},
  archive      = {J_AMC},
  author       = {Huan Zhang and Xiaona Yang and Tianqiu Yu},
  doi          = {10.1016/j.amc.2025.129721},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129721},
  shortjournal = {Appl. Math. Comput.},
  title        = {H-function-based state bounding results of discrete-time delayed systems},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Composite sliding mode adaptive tracking control for singularly perturbed semi-markov jump non-linear systems with fault and disturbances. <em>AMC</em>, <em>511</em>, 129717. (<a href='https://doi.org/10.1016/j.amc.2025.129717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work epitomizes the construction of composite sliding mode-oriented adaptive tracking controller for singularly perturbed semi-Markov jump non-linear systems exposed to multiple disturbances and actuator fault. Typically, a model reference adaptive tracking control algorithm composed of baseline control, enhanced error correction term and adaptive laws is embodied with sliding mode control law to attain robust and rapid tracking performance. On top of that, a disturbance observer is embedded with fault estimator configuration to simultaneously deliver precise evaluations of both exogenous disturbances and faults that influence the system state tracking processes and these assessment are assimilated into the established tracking protocol. Collectively, a robust composite sliding mode-oriented adaptive tracking control strategy with disturbance estimation and fault-tolerance strategies is devised to assure adequate tracking objectives as well as the extended dissipativity performance specifications. After then, by deploying relevant Lyapunov function terms, the necessities for confirming the stochastic stability with preset extended dissipativity performance of the adopted system is detailed into linear matrix inequalities. Furthermore, the reliability of the analysed findings is further affirmed by graphical illustrations attained from numerical simulations.},
  archive      = {J_AMC},
  author       = {N. Shobana and R. Sakthivel and O.M. Kwon and M. Sankar and M. Asha Safana},
  doi          = {10.1016/j.amc.2025.129717},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129717},
  shortjournal = {Appl. Math. Comput.},
  title        = {Composite sliding mode adaptive tracking control for singularly perturbed semi-markov jump non-linear systems with fault and disturbances},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-triggered prescribed performance control of the multiplayer game nonlinear system via integral reinforcement learning. <em>AMC</em>, <em>511</em>, 129716. (<a href='https://doi.org/10.1016/j.amc.2025.129716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a view to addressing the optimal control problem of multiplayer game nonlinear systems, an event-triggered prescribed performance control method based on the fusion of integral reinforcement learning (IRL) and adaptive dynamic programming (ADP) is proposed. Firstly, an auxiliary prescribed performance function (PPF) is designed to transform the original system into an unconstrained one. Drawing on the concepts of game theory, the multi-input optimal control problem is reformulated as a mixed zero-sum (MZS) game problem. Subsequently, an IRL-based event-triggered control (ETC) method is designed with a triggering condition. In this event-triggered method, ETC is updated only when the event-triggering condition is met, which reduces unnecessary communication overhead. On the basis of IRL, a critic-only neural network (NN) is established to approximate solutions of the event-triggered Hamilton-Jacobi-Bellman (HJB) equations without using the dynamic knowledge of the system. Additionally, the Lyapunov stability theorem is employed to ensure the uniform ultimate boundedness (UUB) of the system state and neural network weights. And the Zeno behavior can be avoided. Finally, an example is provided to verify the effectiveness of the proposed method in this paper.},
  archive      = {J_AMC},
  author       = {Yuanyang Hu and Jiaqi Chen and Chunbin Qin},
  doi          = {10.1016/j.amc.2025.129716},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129716},
  shortjournal = {Appl. Math. Comput.},
  title        = {Event-triggered prescribed performance control of the multiplayer game nonlinear system via integral reinforcement learning},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Numerical approximation for a stochastic time-fractional cable equation. <em>AMC</em>, <em>511</em>, 129709. (<a href='https://doi.org/10.1016/j.amc.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient numerical method is proposed to address a stochastic time-fractional cable equation driven by fractionally integrated additive noise. Under the reasonable assumptions, we rigorously establish for the first time, the existence, uniqueness, and regularity of the mild solution for this equation. For spatial discretization, a semi-discrete scheme is constructed employing the Galerkin FEM, and the optimal spatial error estimate is derived based on the semigroup approach. In temporal discretization, a piecewise constant function is introduced to approximate the noise, leading to the formulation of a regularized stochastic time-fractional cable equation. A detailed proof of the temporal error estimates is provided via the semigroup approach. Numerical experiments demonstrate that the temporal convergence order attains O ( τ 1 / 2 ) for initial data of either smooth or non-smooth type. The order is independent of the parameters α 1 ∈ ( 0 , 1 ) , α 2 ∈ ( 0 , 1 ) , and β ∈ ( 0 , 1 ) in the equation. These results perfectly align with the theoretical predictions.},
  archive      = {J_AMC},
  author       = {Qimin Li and Yubin Yan and Leijie Qiao and Yu Zhang},
  doi          = {10.1016/j.amc.2025.129709},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129709},
  shortjournal = {Appl. Math. Comput.},
  title        = {Numerical approximation for a stochastic time-fractional cable equation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="artmed">ARTMED - 16</h2>
<ul>
<li><details>
<summary>
(2025). BPINet: Synchronous blood pressure estimation and user authentication based on ECG and PPG signal with multi-task learning. <em>ARTMED</em>, <em>170</em>, 103277. (<a href='https://doi.org/10.1016/j.artmed.2025.103277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a vital indicator of health, blood pressure is particularly important for elderly individuals with chronic illnesses who live alone. Daily monitoring is essential to prevent hypertension and related complications. Nevertheless, most current home blood pressure monitors depend on cuff-based techniques, which can produce inaccurate results through improper use or cuff placement. Moreover, these devices generally cannot identify the specific user being measured, which hinders the development of personalized long-term health monitoring reports. In this paper, we propose BPINet, a multi-task model based on the Multi-gate Mixture-of-Experts (MMoE) framework that utilizes CNN-BiLSTM to extract features from ECG/PPG signals for simultaneous blood pressure estimation and user authentication (identity recognition). We also compile a dataset of ECG/PPG signals from multiple families, along with their blood pressure measurements, and incorporate it with the University of Queensland Vital Signs Dataset (UQVS) to evaluate the performance of BPINet. On the UQVS dataset, BPINet achieves a 97.54% user identity recognition accuracy. For systolic blood pressure (SBP) estimation, BPINet yields an MAE ± STD of 3.317 ± 5.771 mmHg. For diastolic blood pressure (DBP) estimation, the corresponding values are 2.444 ± 4.147 mmHg. On our customized dataset, BPINet achieves a 94.30% user identity recognition accuracy. For SBP estimation, it yields an MAE ± STD of 2.940 ± 4.753 mmHg. These results meet both the British Hypertension Society (BHS) Grade A standard and the Association for the Advancement of Medical Instrumentation (AAMI) standard. BPINet not only performs blood pressure estimation effectively but also enables simultaneous user identity recognition, facilitating the creation of personalized health records. The experimental results demonstrate the clinical feasibility and effectiveness of our proposed scheme.},
  archive      = {J_ARTMED},
  author       = {Xianliang Jiang and Dingxin Yu and Guang Jin and Fei Lei and Weihao Zhang and Xinyan Zhou},
  doi          = {10.1016/j.artmed.2025.103277},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103277},
  shortjournal = {Artif. Intell. Med.},
  title        = {BPINet: Synchronous blood pressure estimation and user authentication based on ECG and PPG signal with multi-task learning},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The interpretable deep learning framework and validation for seizure detection in pediatric electroencephalography: An improved accuracy and performance analysis. <em>ARTMED</em>, <em>170</em>, 103276. (<a href='https://doi.org/10.1016/j.artmed.2025.103276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an interpretable deep learning framework and compares the two novel models. A fully convolutional network with squeeze-and-excitation modules (SE-FCN) is designed to enhance spatial sensitivity and retain temporal resolution. In addition, a transformer-based model (TransNet) is developed to capture temporal and channel-wise dependencies via self-attention. These two models output channel saliency weights to the EEG electrode space and generate heatmaps for inferring potential epileptogenic zones. Deep learning primarily adopts convolutional neural networks (CNNs) or sequence generation networks (SGNs) and faces the limitations. For instance, CNN-based models often lack hierarchical modeling and fail to quantify channel-wise contributions, hindering spatial localization. SGN-based models struggle to capture complex spatiotemporal dependencies and typically lack adaptive attention tailored to electroencephalography (EEG) characters. Epileptic seizure detection is vital for effective clinical intervention and existing methods operated as black boxes, limiting clinical interpretability. This study evaluates the models on the CHB-MIT pediatric EEG dataset using a subject-independent cross-validation protocol. SE-FCN achieves an AUC of 0.89 and accuracy of 86.7 %, while TransNet achieves an AUC of 0.92 and accuracy of 86.4 %. Saliency maps from both models demonstrate high consistency and enable categorization of 22 patients into five groups based on inferred seizure origins.},
  archive      = {J_ARTMED},
  author       = {Yu Zhou and Yuxin Gao and Qiang Li and Ruiheng Wu and Aiping Yang and Ming-Lang Tseng},
  doi          = {10.1016/j.artmed.2025.103276},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103276},
  shortjournal = {Artif. Intell. Med.},
  title        = {The interpretable deep learning framework and validation for seizure detection in pediatric electroencephalography: An improved accuracy and performance analysis},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel memory interaction neural network for multi-label drug–drug interaction prediction with neighbor importance sampling. <em>ARTMED</em>, <em>170</em>, 103275. (<a href='https://doi.org/10.1016/j.artmed.2025.103275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-administration of multiple drugs can frequently cause drug–drug interactions (DDIs), including adverse drug reactions (ADRs) that may increase the likelihood of morbidity and mortality. Identifying potential DDIs presents a significant challenge, due to the complexity of pharmacology. Recent advances in knowledge graphs have contributed to DDI prediction by providing a robust framework for representing various relationships between drugs and other entities, such as proteins, diseases, and drug attributes. However, current network-based models often fail to uncover interaction information among DDI triplets, as they typically encode triplets independently. Additionally, uniform sampling methods may overlook differences in neighboring node properties. In this work, we propose a novel memory interaction neural network for DDI prediction, which integrates drug molecular sequences with semantic information from the drug knowledge graph. Specifically, we introduce a neighbor importance sampling strategy that selectively samples highly connected neighbors, improving computational efficiency and reducing noise. We also design a memory interaction module that utilizes multi-head attention mechanisms and deep neural networks to capture interactions among DDI triplets. Experimental evaluation on KEGG and OGB-biokg datasets demonstrates the superiority of our model compared to classical and state-of-the-art methods in predicting DDIs. Datasets and code for this proposed DDIs prediction model are freely accessible at https://github.com/wj1108114106/Multi-label-DDIs .},
  archive      = {J_ARTMED},
  author       = {Jing Wang and Runzhi Li and Shuo Zhang and YunLi Xing and Siyu Yan and Lihong Ma},
  doi          = {10.1016/j.artmed.2025.103275},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103275},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel memory interaction neural network for multi-label drug–drug interaction prediction with neighbor importance sampling},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Types, functions, and mechanisms of machine learning for personalizing smoking cessation interventions: A systematic scoping review. <em>ARTMED</em>, <em>170</em>, 103274. (<a href='https://doi.org/10.1016/j.artmed.2025.103274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose Artificial intelligence can realize personalization. This systematic scoping review provides the types, functions, and mechanisms of machine learning (ML) for personalizing smoking cessation interventions. Methodology We searched fourteen databases including PubMed, CINAHL, EMBASE, the Cochrane Library, IEEE Xplore, PsycINFO, Scopus, Web of Science, AAAI, ACM Digital Library, ArXIV, Mednar, ProQuest, and Science.gov . We selected 98 articles from 4073 records that met the criteria. Two independent reviewers screened and selected the articles. Two reviewers extracted the data using a self-developed data charting form independently. Results The findings are reported in narrative syntheses, tables, and figures. The types of ML included artificial neural networks, Bayesian algorithms, clustering algorithms, decision tree algorithms, deep learning (DL) algorithms, ensemble algorithms, linear classifiers, others, and unspecified. The most common ML technique used was supervised learning (81 %), and the ML functions included (1) message tailoring (17 %), (2) prediction and detection of smoking events (34 %), (3) social media surveillance (14 %), (4) predictive models (24 %), and (5) biomarker analysis (10 %). The ML mechanisms involved the following sequence: data input, data preprocessing, feature extraction and selection, training and validation, and data output. Conclusion This review is the first to describe the potential use of ML for personalizing smoking cessation interventions. We provide recommendations for future research by identifying the limitations and gaps in the studies. Future studies should refine, validate, and test ML models using robust experimental methods to conclude their effectiveness.},
  archive      = {J_ARTMED},
  author       = {Yu Jie Xavia Ng and Shing Hui Reina Cheong and Wen Wei Ang and Ying Lau and Siew Tiang Lau},
  doi          = {10.1016/j.artmed.2025.103274},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103274},
  shortjournal = {Artif. Intell. Med.},
  title        = {Types, functions, and mechanisms of machine learning for personalizing smoking cessation interventions: A systematic scoping review},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding the cortical responses to mechanical wrist perturbations: A two-step shared structure NARX method. <em>ARTMED</em>, <em>170</em>, 103273. (<a href='https://doi.org/10.1016/j.artmed.2025.103273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared structure nonlinear autoregressive with exogenous input (NARX) model is a promising tool for exploring cortical responses mechanism to external stimuli, essential for advancing our understanding of brain function and developing methods for direct brain information encoding. In this paper, we proposed a two-step method to overcome limitations in existing method, which neglect data relationships and rely on a greedy search for regression terms, leading to less accurate models. In our approach, data from multiple trials are concatenated, and then the orthogonal forward regression (OFR) algorithm identifies model terms in first step, enhancing inter-trial connections and establishing a preliminary model for each subject. Shared model terms across subjects are then used to construct a general target model. Next, non-shared regression terms that best represent population-level information are identified, using adaptive multi-population genetic algorithms, and use to enhance the target models' descriptive power. Simulations results show significant competitiveness in terms of accuracy as compared to other state-of-the-art methods. When applied to real electroencephalography signals under mechanical disturbance, structural and parameter analysis revealed consistent neural response patterns across subjects, with subject-specific responses likely stemming from muscle feedback. Frequency response analysis further suggests that the brain may generate motor inhibition signals based on sensory inputs to maintain a pre-disturbance resting state. These findings provide valuable insights into cortical response mechanisms and have potential implications for future brain information encoding research.},
  archive      = {J_ARTMED},
  author       = {Nan Zheng and Yurong Li and Wuxiang Shi and Jiyu Tan},
  doi          = {10.1016/j.artmed.2025.103273},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103273},
  shortjournal = {Artif. Intell. Med.},
  title        = {Decoding the cortical responses to mechanical wrist perturbations: A two-step shared structure NARX method},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven dynamic grouping for adaptive clinical trials: Rethinking randomization in precision medicine. <em>ARTMED</em>, <em>170</em>, 103272. (<a href='https://doi.org/10.1016/j.artmed.2025.103272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating artificial intelligence into biomedical human subjects research is transforming traditional experimental paradigms. This perspective introduces the concept of “dynamic grouping,” wherein artificial intelligence (AI) systems continuously reassign participants across experimental conditions based on real-time biomarker data and clinical response patterns. Unlike traditional biomedical research designs that rely on fixed treatment and control groups, dynamic grouping allows participant assignments to evolve throughout the study. We examine the ethical implications, methodological challenges, and research opportunities associated with this paradigm, particularly in clinical trials, precision medicine, and digital therapeutics. To support this analysis, we present three computational simulations that quantify its impact: (i) a heterogeneity simulation demonstrating how patient variability affects the advantage of dynamic grouping, (ii) a statistical power analysis showing potential sample size reductions in adaptive designs, and (iii) a clinical outcome distribution analysis highlighting how dynamic grouping reduces negative treatment outcomes and optimizes patient responses. Our findings suggest that dynamic grouping can improve treatment effectiveness, enhance resource allocation, and increase statistical efficiency, although it also raises new challenges for causal inference, informed consent, and regulatory oversight. As AI continues to reshape medical research, adapting ethical and methodological frameworks will be essential for its responsible implementation.},
  archive      = {J_ARTMED},
  author       = {Madhur Mangalam},
  doi          = {10.1016/j.artmed.2025.103272},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103272},
  shortjournal = {Artif. Intell. Med.},
  title        = {AI-driven dynamic grouping for adaptive clinical trials: Rethinking randomization in precision medicine},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H-SynEx: Using synthetic images and ultra-high resolution ex vivo MRI for hypothalamus subregion segmentation. <em>ARTMED</em>, <em>170</em>, 103271. (<a href='https://doi.org/10.1016/j.artmed.2025.103271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hypothalamus is a small structure located in the center of the brain and is involved in significant functions such as sleeping, temperature, and appetite control. Various neurological disorders are also associated with hypothalamic abnormalities. Automated image analysis of this structure from brain MRI is thus highly desirable to study the hypothalamus in vivo . However, most of the automated segmentation tools currently available focus exclusively on T1w images. In this study, we introduce H-SynEx, a machine learning method for automated segmentation of hypothalamic subregions that generalizes across different MRI sequences and resolutions without retraining. H-synEx was trained with synthetic images built from label maps derived from ultra-high resolution ex vivo MRI scans, allowing finer-grained manual segmentation when compared with 1 mm isometric in vivo images. We validated our method using Dice Coefficient (DSC) and Average Hausdorff distance (AVD) across in vivo images from six different datasets with six different MRI sequences (T1, T2, proton density, quantitative T1, fractional anisotropy, and FLAIR). Statistical analysis compared hypothalamic subregion volumes in controls, Alzheimer’s disease (AD), and behavioral variant frontotemporal dementia (bvFTD) subjects using the Area Under the Receiver Operating Characteristic curve (AUROC) and the Wilcoxon rank sum test. Our results show that H-SynEx successfully leverages information from ultra-high resolution scans to segment in vivo from different MRI sequences. Our automated segmentation was able to discriminate controls versus patients with Alzheimer’s disease on FLAIR images with 5 mm spacing. H-SynEx is openly available at https://github.com/liviamarodrigues/hsynex .},
  archive      = {J_ARTMED},
  author       = {Livia Rodrigues and Martina Bocchetta and Oula Puonti and Douglas Greve and Ana Carolina Londe and Marcondes França and Simone Appenzeller and Juan Eugenio Iglesias and Leticia Rittner},
  doi          = {10.1016/j.artmed.2025.103271},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103271},
  shortjournal = {Artif. Intell. Med.},
  title        = {H-SynEx: Using synthetic images and ultra-high resolution ex vivo MRI for hypothalamus subregion segmentation},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining multi-electrode and multi-wave electroencephalogram based time-interval temporal patterns for improved classification capabilities and explainability. <em>ARTMED</em>, <em>170</em>, 103269. (<a href='https://doi.org/10.1016/j.artmed.2025.103269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interface (BCI) systems, and particularly electroencephalogram (EEG) based BCI systems, have become more widely used in recent years and are utilized in various applications and domains ranging from medicine and marketing to games and entertainment. While different algorithms have been used to analyze EEG data and enable its classification, existing algorithms have two main drawbacks; both their classification and explainability capabilities are limited. Lacking in explainability, they cannot indicate which electrodes and waves led to a classification decision or explain how areas and frequencies of the brain's activity correlate to a specific task. In this study, we propose a novel extension for the time-interval temporal patterns mining algorithms aimed at enhancing the data mining process by enabling a richer set of patterns to be learned from the EEG data, thereby contributing to improved classification and explainability capabilities. The extended algorithm is designed to capture and leverage the unique nature of EEG data by decomposing it into different brain waves and modeling the relations among them and between different electrodes. Our evaluation of the proposed extended algorithm on multiple learning tasks and three EEG datasets demonstrated the extended algorithm's ability to mine richer patterns that improve the classification performance by 4–11 % based on the Area-Under the receiver operating characteristic Curve (AUC) metric, compared to the original version of the algorithm. Moreover, the algorithm was shown to shed light on the areas and frequencies of the brain's activity that are correlated with specific tasks.},
  archive      = {J_ARTMED},
  author       = {Ofir Landau and Nir Nissim},
  doi          = {10.1016/j.artmed.2025.103269},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103269},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mining multi-electrode and multi-wave electroencephalogram based time-interval temporal patterns for improved classification capabilities and explainability},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey for large language models in biomedicine. <em>ARTMED</em>, <em>170</em>, 103268. (<a href='https://doi.org/10.1016/j.artmed.2025.103268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent breakthroughs in large language models (LLMs) offer unprecedented natural language understanding and generation capabilities. However, existing surveys on LLMs in biomedicine often focus on specific applications or model architectures, lacking a comprehensive analysis that integrates the latest advancements across various biomedical domains. This review, based on an analysis of 484 publications sourced from databases including PubMed, Web of Science, and arXiv, provides an in-depth examination of the current landscape, applications, challenges, and prospects of LLMs in biomedicine, distinguishing itself by focusing on the practical implications of these models in real-world biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot learning across a broad spectrum of biomedical tasks, including diagnostic assistance, drug discovery, and personalized medicine, among others, with insights drawn from 137 key studies. Then, we discuss adaptation strategies of LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to enhance their performance in specialized biomedical contexts where zero-shot fails to achieve, such as medical question answering and efficient processing of biomedical literature. Finally, we discuss the challenges that LLMs face in the biomedicine domain including data privacy concerns, limited model interpretability, issues with dataset quality, and ethics due to the sensitive nature of biomedical data, the need for highly reliable model outputs, and the ethical implications of deploying AI in healthcare. To address these challenges, we also identify future research directions of LLM in biomedicine including federated learning methods to preserve data privacy and integrating explainable AI methodologies to enhance the transparency of LLMs. As this field of LLM rapidly evolves, continued research and development are essential to fully harness the capabilities of LLMs in biomedicine while ensuring their responsible and effective deployment.},
  archive      = {J_ARTMED},
  author       = {Chong Wang and Mengyao Li and Junjun He and Zhongruo Wang and Erfan Darzi and Zan Chen and Jin Ye and Tianbin Li and Yanzhou Su and Jing Ke and Kaili Qu and Shuxin Li and Yi Yu and Pietro Liò and Tianyun Wang and Yu Guang Wang and Yiqing Shen},
  doi          = {10.1016/j.artmed.2025.103268},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103268},
  shortjournal = {Artif. Intell. Med.},
  title        = {A survey for large language models in biomedicine},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-quality triage and diagnosis of gynecological diseases via artificial intelligence. <em>ARTMED</em>, <em>170</em>, 103267. (<a href='https://doi.org/10.1016/j.artmed.2025.103267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely detection and diagnosis of diseases are key elements of an efficient healthcare system. In recent years, artificial intelligence (AI) has played an increasingly important role in improving the accuracy and efficiency of disease diagnosis in clinical practice. However, most existing AI systems for disease diagnosis have focused on either classifying patients into broad disease categories or diagnosing a specific disease, leaving a gap in the development of a coherent AI system for both triage and diagnosis in a department of a general hospital. In this study, we fill this gap with SmartGyne, an advanced AI system that can achieve high-quality triage and diagnosis for a full spectrum of gynecological diseases. By extracting useful clinical evidence for diagnosis from a large amount of electronic medical records, SmartGyne establishes an effective framework to integrate real-world clinical evidence and knowledge into a coherent AI system that can effectively handle a full spectrum of complex diseases in a department of a general hospital. Validation experiments demonstrated that SmartGyne achieved an overall accuracy of 80.1 % in triage for gynecological diseases, and 99.4 % in diagnosis for a gynecological subspecialty. In comparison with human physicians, SmartGyne showed competitive triage and diagnostic performance, and improved consultation efficiency and accuracy for physicians with limited specialized experience. These results show that SmartGyne achieves high-quality triage and diagnosis, holding the potential to improve the efficiency of the healthcare system in China, as well as other countries lacking professional gynecologists.},
  archive      = {J_ARTMED},
  author       = {Linru Fu and Che Wang and Zhaoyang Liu and Changzai Pan and Zhe Du and Zhijing Sun and Lan Zhu and Ke Deng},
  doi          = {10.1016/j.artmed.2025.103267},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103267},
  shortjournal = {Artif. Intell. Med.},
  title        = {High-quality triage and diagnosis of gynecological diseases via artificial intelligence},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving prototypical parts abstraction for case-based reasoning explanations designed for the kidney stone type recognition. <em>ARTMED</em>, <em>170</em>, 103266. (<a href='https://doi.org/10.1016/j.artmed.2025.103266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The in-vivo identification of the kidney stone types during an ureteroscopy would be a major medical advance in urology, as it could reduce the time of the tedious renal calculi extraction process, while diminishing infection risks. Furthermore, such an automated procedure would make possible to prescribe anti-recurrence treatments immediately. Nowadays, only few experienced urologists are able to recognize the kidney stone types in the images of the videos displayed on a screen during the endoscopy. This visual recognition by urologists is also highly operator dependent. Thus, several deep learning (DL) models have recently been proposed to automatically recognize the kidney stone types using ureteroscopic images. However, these DL models are of black box nature and do not establish the relationship of the visual features they used to take the decision with the color, texture and morphological features visually analyzed in biological laboratories to determine the type of extracted kidney stone fragments using the reference morphoconstitutional analysis (MCA) procedure. This contribution proposes a case-based reasoning DLmodel which uses prototypical parts (PPs) and generates local and global descriptors. The PPs encode for each class (i.e., kidney stone type) visual feature information (hue, saturation, intensity and textures) similar to that used by biologists during MCA. The PPs are optimally generated due a new loss function used during the model training. Moreover, the local and global descriptors of PPs allow to explain the decisions (“what” information, “where in the images”) in an understandable way for biologists and urologists. The proposed DL model has been tested on a database including images of the six most widespread kidney stone types in industrialized countries. The overall average classification accuracy was 90 . 37 ± 0 . 6 % . When comparing this results with that of the eight other DL models of the kidney stone state-of-the-art, it can be seen that the valuable gain in explanability was not reached at the expense of accuracy which was even slightly increased with respect to that ( 88 . 2 ± 2 . 1 % ) of the best method of the literature. These promising and interpretable results also encourage urologists to put their trust in AI-based solutions.},
  archive      = {J_ARTMED},
  author       = {Daniel Flores-Araiza and Francisco Lopez-Tiro and Clément Larose and Salvador Hinojosa and Andres Mendez-Vazquez and Miguel Gonzalez-Mendoza and Gilberto Ochoa-Ruiz and Christian Daul},
  doi          = {10.1016/j.artmed.2025.103266},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103266},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving prototypical parts abstraction for case-based reasoning explanations designed for the kidney stone type recognition},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical multimodal foundation models in clinical diagnosis and treatment: Applications, challenges, and future directions. <em>ARTMED</em>, <em>170</em>, 103265. (<a href='https://doi.org/10.1016/j.artmed.2025.103265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning have significantly revolutionized the field of clinical diagnosis and treatment, offering novel approaches to improve diagnostic precision and treatment efficacy across diverse clinical domains, thus driving the pursuit of precision medicine. The growing availability of multi-organ and multimodal datasets has accelerated the development of large-scale Medical Multimodal Foundation Models (MMFMs). These models, known for their strong generalization capabilities and rich representational power, are increasingly being adapted to address a wide range of clinical tasks, from early diagnosis to personalized treatment strategies. This review offers a comprehensive analysis of recent developments in MMFMs, focusing on three key aspects: datasets, model architectures, and clinical applications. We also explore the challenges and opportunities in optimizing multimodal representations and discuss how these advancements are shaping the future of healthcare by enabling improved patient outcomes and more efficient clinical workflows.},
  archive      = {J_ARTMED},
  author       = {Kai Sun and Siyan Xue and Fuchun Sun and Haoran Sun and Yu Luo and Ling Wang and Siyuan Wang and Na Guo and Lei Liu and Tian Zhao and Xinzhou Wang and Lei Yang and Shuo Jin and Jun Yan and Jiahong Dong},
  doi          = {10.1016/j.artmed.2025.103265},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103265},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical multimodal foundation models in clinical diagnosis and treatment: Applications, challenges, and future directions},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end solution for out-of-hospital emergency medical dispatch triage based on multimodal and continual deep learning. <em>ARTMED</em>, <em>170</em>, 103264. (<a href='https://doi.org/10.1016/j.artmed.2025.103264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study was to build a multimodal, multitask predictive model—named E2eDeepEMC 2 —to improve out-of-hospital emergency incident severity assessments while coping with shifts in data distributions over time. We drew on 2 054 694 independent incidents recorded by the Valencian emergency medical dispatch service between 2009 and 2019 (excluding 2013), combining demographic, temporal, clinical and free-text inputs. To handle temporal drift, our model integrates continual learning strategies and comprises three encoder modules (for context, clinical data and text), whose outputs are merged to predict the life-threatening level, admissible response delay and emergency system jurisdiction. Compared with the Valencian Region’s existing in-house triage protocol, E2eDeepEMC 2 achieved absolute F1-score gains of 18.46% for life-threatening level, 25.96% for response delay and 3.63% for jurisdiction. Compared to non-continual learning baselines, it also outperformed them by 3.04%, 9.66% and 0.58%, respectively. Deployment of E2eDeepEMC 2 is currently underway in the Valencian Region, underscoring its practical impact on real-world emergency dispatch decision-making.},
  archive      = {J_ARTMED},
  author       = {Pablo Ferri and Carlos Sáez and Antonio Félix-De Castro and Purificación Sánchez-Cuesta and Juan M. García-Gómez},
  doi          = {10.1016/j.artmed.2025.103264},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103264},
  shortjournal = {Artif. Intell. Med.},
  title        = {An end-to-end solution for out-of-hospital emergency medical dispatch triage based on multimodal and continual deep learning},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRA-PT: Low-rank adapting UNETR for hippocampus segmentation using principal tensor singular values and vectors. <em>ARTMED</em>, <em>170</em>, 103254. (<a href='https://doi.org/10.1016/j.artmed.2025.103254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hippocampus is an important brain structure involved in various psychiatric disorders, and its automatic and accurate segmentation is vital for studying these diseases. Recently, deep learning-based methods have made significant progress in hippocampus segmentation. However, training deep neural network models requires substantial computational resources, time, and a large amount of labeled training data, which is frequently scarce in medical image segmentation. To address these issues, we propose LoRA-PT, a novel parameter-efficient fine-tuning (PEFT) method that transfers the pre-trained UNETR model from the BraTS2021 dataset to the hippocampus segmentation task. Specifically, LoRA-PT divides the parameter matrix of the transformer structure into three distinct sizes, yielding three third-order tensors. These tensors are decomposed using tensor singular value decomposition to generate low-rank tensors consisting of the principal singular values and vectors, with the remaining singular values and vectors forming the residual tensor. During fine-tuning, only the low-rank tensors (i.e., the principal tensor singular values and vectors) are updated, while the residual tensors remain unchanged. We validated the proposed method on three public hippocampus datasets, and the experimental results show that LoRA-PT outperformed state-of-the-art PEFT methods in segmentation accuracy while significantly reducing the number of parameter updates. Our source code is available at https://github.com/WangangCheng/LoRA-PT/tree/LoRA-PT .},
  archive      = {J_ARTMED},
  author       = {Guanghua He and Wangang Cheng and Hancan Zhu and Gaohang Yu},
  doi          = {10.1016/j.artmed.2025.103254},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103254},
  shortjournal = {Artif. Intell. Med.},
  title        = {LoRA-PT: Low-rank adapting UNETR for hippocampus segmentation using principal tensor singular values and vectors},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMSupcon: An image fusion-based multi-modal supervised contrastive method for brain tumor diagnosis. <em>ARTMED</em>, <em>170</em>, 103253. (<a href='https://doi.org/10.1016/j.artmed.2025.103253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of brain tumors is pivotal for effective treatment, with MRI serving as a commonly used non-invasive diagnostic modality in clinical practices. Fundamentally, brain tumor diagnosis is a type of pattern recognition task that requires the integration of information from multi-modal MRI images. However, existing fusion strategies are hindered by the scarcity of multi-modal imaging samples. In this paper, we propose a new training paradigm tailored for the scenario of multi-modal imaging in brain tumor diagnosis, called multi-modal supervised contrastive learning method (MMSupcon). This method significantly enhances diagnostic accuracy through two key components: multi-modal medical image fusion and multi-modal supervised contrastive loss. First, the fusion component integrates complementary imaging modalities to generate information-rich samples. Second, by introducing fused samples to guide original samples in learning feature consistency or inconsistency among classes, our loss component effectively preserves the integrity of cross-modal information while maintaining the distinctiveness of individual modalities. Finally, MMSupcon is validated on a real-world brain tumor dataset collected from Beijing Tiantan Hospital, achieving state-of-the-art performance. Furthermore, additional experiments on two public BraTS glioma classification datasets also demonstrate our substantial performance improvements. The source code is released at https://github.com/hywang02/MMSupcon .},
  archive      = {J_ARTMED},
  author       = {Haoyu Wang and Jing Zhang and Siying Wu and Haoran Wei and Xun Chen and Yunwei Ou and Xiaoyan Sun},
  doi          = {10.1016/j.artmed.2025.103253},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103253},
  shortjournal = {Artif. Intell. Med.},
  title        = {MMSupcon: An image fusion-based multi-modal supervised contrastive method for brain tumor diagnosis},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathway information on methylation analysis using deep neural network (PROMINENT): An interpretable deep learning method with pathway prior for phenotype prediction using gene-level DNA methylation. <em>ARTMED</em>, <em>170</em>, 103236. (<a href='https://doi.org/10.1016/j.artmed.2025.103236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background DNA methylation is a key epigenetic marker that influences gene expression and phenotype regulation, and is affected by both genetic and environmental factors. Traditional linear regression methods such as elastic nets have been employed to assess the cumulative effects of multiple DNA methylation markers on phenotypes. However, these methods often fail to capture the complex nonlinear nature of the data. Recent deep learning approaches, such as MethylNet, have improved the prediction accuracy but lack interpretability and efficiency. Findings To address these limitations, we introduced P athway Info r mati o n on M ethylat i on Analysis using a Deep Ne ural N e t work (PROMINENT), a novel interpretable deep learning method that integrates gene-level DNA methylation data with biological pathway information for phenotype prediction. PROMINENT enhances interpretability and prediction accuracy by incorporating gene- and pathway-level priors from databases such as Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG). It employs SHapley Additive exPlanations (SHAP) to prioritize significant genes and pathways. Evaluated across various datasets, childhood asthma, idiopathic pulmonary fibrosis (IPF), and first-episode psychosis (FEP)—PROMINENT consistently outperformed existing methods in terms of prediction accuracy and computational efficiency. PROMINENT also identified crucial genes and pathways involved in disease mechanisms. Conclusions PROMINENT represents a significant advancement in leveraging DNA methylation data for phenotype prediction, offering both high accuracy and interpretability within reasonable computational time. This method holds promise for elucidating the epigenetic underpinnings of complex diseases and enhancing the utility of DNA methylation data in biomedical research.},
  archive      = {J_ARTMED},
  author       = {Soyeon Kim and Laizhi Zhang and Yidi Qin and Rebecca I. Caldino Bohn and Hyun Jung Park},
  doi          = {10.1016/j.artmed.2025.103236},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103236},
  shortjournal = {Artif. Intell. Med.},
  title        = {Pathway information on methylation analysis using deep neural network (PROMINENT): An interpretable deep learning method with pathway prior for phenotype prediction using gene-level DNA methylation},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="asoc">ASOC - 102</h2>
<ul>
<li><details>
<summary>
(2025). Intelligent compressive strength prediction of sustainable rubberised concrete using an optimised interpretable deep CNN-LSTM model with attention mechanism. <em>ASOC</em>, <em>185</em>, 113993. (<a href='https://doi.org/10.1016/j.asoc.2025.113993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing environmental concerns associated with waste rubber disposal, particularly from used tyres, have led to the exploration of rubberised concrete as a sustainable construction material. Rubberised concrete provides benefits like enhanced flexibility and energy absorption; however, its reduced compressive strength remains a challenge for structural applications. This study puts forward an advanced deep learning model to accurately evaluate compressive strength of rubberised concrete by combining a hybrid convolutional neural network (CNN) and long short-term memory (LSTM) network enhanced with attention mechanism, and optimised using the enhanced firefly algorithm (EFA), featuring chaotic initialisation and nonlinear learning factor for improved convergence, for hyperparameter tuning. The proposed model introduces computing novelties: attention-guided CNN-LSTM feature fusion and chaos-enhanced firefly optimisation. Then, it is trained on an extensive dataset incorporating key mix parameters, including water, cement, supplementary cementitious materials, superplasticiser, coarse and fine aggregates, crumb and chipped rubber content, and concrete age, with validation supported by experimental tests in the laboratory. The proposed model achieves superior prediction accuracy, achieving R² values of 0.967 for training and 0.943 for testing, outperforming conventional machine learning methods. Evaluation metrics showcase the superior performance of model, with root mean square error of 2.966 MPa and 3.757 MPa for training and test data, respectively. A sensitivity analysis based on SHapley Additive exPlanations (SHAP) highlights coarse aggregate, rubber content, and concrete age as the most influential variables affecting compressive strength. By providing a highly accurate, interpretable, and cost-effective predictive tool, this research facilitates the optimisation of rubberised concrete mix design, supporting its broader adoption in sustainable construction practice.},
  archive      = {J_ASOC},
  author       = {Yang Yu and Roshan Jayathilakage and Yiyang Liu and Ailar Hajimohammadi},
  doi          = {10.1016/j.asoc.2025.113993},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113993},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intelligent compressive strength prediction of sustainable rubberised concrete using an optimised interpretable deep CNN-LSTM model with attention mechanism},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A proximal policy optimization driven hyper-heuristic for workers constrained hybrid flow shop problem. <em>ASOC</em>, <em>185</em>, 113990. (<a href='https://doi.org/10.1016/j.asoc.2025.113990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the production environment becomes increasingly complex, the integration of soft computing techniques becomes essential for addressing resource-constrained scheduling problems. This paper delves into a worker constrained hybrid flow shop scheduling problem (WHFSP) that integrates worker resources at each processing stage. A mixed-integer linear programming (MILP) model is constructed which enables the use of mathematical solvers to obtain optimal solutions for small-scale instances. Additionally, a novel soft computing-based scheduling framework, namely a proximal policy optimization-based hyper-heuristic algorithm (PPO-HH), is proposed. It automatically selects the most suitable low-level heuristic strategies based on the current state and historical data, facilitating efficient exploration and exploitation of the complex decision space. Several low-level heuristics including perturbative and local search operators are developed to explore the solution space. Subsequently, a high-level control strategy based on proximal policy optimization is proposed. A solution quality evaluation function and a reward mechanism based on problem characteristics are formulated. This mechanism provides feedback to PPO-HH based on the degree of alignment between the actions taken by the agent and the objectives, gradually optimizing the selection of low-level heuristic strategies. Eventually, it generates a probability distribution for each low-level heuristic in the given environment. Comprehensive numerical experiments are conducted to evaluate the performance of both the MILP model and the components of the PPO-HH algorithm. The comparison results show that PPO-HH is effective and efficient for solving the WHFSP.},
  archive      = {J_ASOC},
  author       = {Shengnan Ding and Weishi Shao and Zhongshi Shao and ShengTao Peng and Dechang Pi and Jiaquan Gao},
  doi          = {10.1016/j.asoc.2025.113990},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113990},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A proximal policy optimization driven hyper-heuristic for workers constrained hybrid flow shop problem},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond training horizons: A physics-informed U-net transformer for time-dependent CO₂ storage simulation in environmental applications. <em>ASOC</em>, <em>185</em>, 113987. (<a href='https://doi.org/10.1016/j.asoc.2025.113987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CO 2 geological storage is a key strategy for reducing greenhouse gas emissions, requiring accurate modeling of subsurface CO 2 migration is essential for effective storage planning and risk assessment. Conventional numerical simulations, which solve time-dependent nonlinear partial differential equations, provide detailed physical insights but are computationally demanding, especially for large-scale or long-term scenarios. To improve computational efficiency, surrogate models based on machine learning have been increasingly investigated. Methods such as deep learning and physics-Informed neural networks aim to approximate the behavior of physical systems, offering potential reductions in simulation time. However, these approaches often require extensive case-specific datasets and are typically limited to fixed time horizons defined during training, which can restrict their generalizability and practical application. This study presents a time-aware surrogate modeling framework that combines convolutional neural networks with self-attention mechanisms to address these limitations. Drawing inspiration from autoregressive forecasting used in sequential learning models, the proposed approach captures temporal dependencies through iterative prediction of system states.The framework requires only a short-term numerical simulation to initialize the physical system, after which it can generate predictions for arbitrarily extended time horizons without the need for retraining. By enabling long-term forecasting, the method improves efficiency and supports repeated scenario evaluations, such as site screening and well placement optimization. Such predictive capabilities are particularly valuable in addressing environmental sustainability goals, where rapid and scalable simulations are essential for managing long-term subsurface processes under climate-related constraints.},
  archive      = {J_ASOC},
  author       = {Ye Liu and Jiahao Wang and Nan Zhang and Xiaodong Qian and Shaojun Chai},
  doi          = {10.1016/j.asoc.2025.113987},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113987},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Beyond training horizons: A physics-informed U-net transformer for time-dependent CO₂ storage simulation in environmental applications},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating CEO hubris effects on sustainable performance in the IC design industry: An integrated dynamic network DEA framework with machine learning. <em>ASOC</em>, <em>185</em>, 113986. (<a href='https://doi.org/10.1016/j.asoc.2025.113986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces an integrated analytical framework combining dynamic network data envelopment analysis (DNDEA) with machine learning to assess the impact of CEO hubris on sustainable performance in the integrated circuit (IC) design industry. Our two-stage DNDEA model evaluates operational and R&D efficiency separately, incorporating intermediate factors including profit and ESG scores. We develop a novel text-based measure of CEO hubris by analyzing the contrast between confidence and conservatism language in annual shareholder reports. This hubris measure is then incorporated into predictive models, where we compare traditional linear regression against advanced machine learning approaches—support vector regression (SVR) and random forest (RF)—using cross-validation and hyperparameter optimization. The analysis reveals a significant negative correlation between CEO hubris and operational and R&D efficiency. Notably, the non-linear models (SVR and RF) demonstrate superior predictive accuracy compared to linear regression across varying levels of CEO hubris. These findings yield two primary contributions: first, they establish the critical need for monitoring hubristic leadership behavior in innovation-intensive industries, given their detrimental effect on organizational efficiency. Second, they validate the effectiveness of combining text analytics, DNDEA efficiency metrics, and machine learning for evaluating leadership impact on firm performance. This methodology provides a comprehensive framework for analyzing leadership dynamics in the IC design sector and offers an adaptable template for similar analyses across technology-driven industries.},
  archive      = {J_ASOC},
  author       = {Sheng-Wei Lin and Yu-Rou Lin},
  doi          = {10.1016/j.asoc.2025.113986},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113986},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluating CEO hubris effects on sustainable performance in the IC design industry: An integrated dynamic network DEA framework with machine learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FSAMLM: A few-shot adaptation multimodal large model for cross-domain fault diagnosis. <em>ASOC</em>, <em>185</em>, 113985. (<a href='https://doi.org/10.1016/j.asoc.2025.113985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have demonstrated remarkable performance in mechanical fault diagnosis. However, most existing approaches are designed for a single data modality or a single task, limiting their flexibility and generalization ability. Moreover, common knowledge across different tasks remains largely unexploited. Inspired by the success of large-scale models in natural language processing and computer vision, integrating multimodal data with multi-task learning strategies may significantly improve the performance of fault diagnosis models. Nonetheless, a significant gap exists between general pre-trained knowledge and domain-specific expertise, posing considerable challenges for effective integration. To address these issues, we propose a novel few-shot adaptation multimodal large model (FSAMLM) that efficiently captures shared representations through a parameter-efficient fine-tuning strategy, structured in two stages. Specifically, we first design a low-rank adaptation meta-learning (LoRAML) framework, which employs low-rank decomposition on pre-trained parameters to reduce computational complexity and improve robustness. This approach not only accelerates adaptation to new few-shot tasks but also preserves pre-training knowledge effectively. During the second fine-tuning stage, we implement target-domain training with limited samples and introduce a training-free inference option for real-world deployment. Experimental validation using six public datasets demonstrates FSAMLM’s superior domain generalization capability in few-shot fault diagnosis tasks compared to existing methods. The code repository is publicly available at: https://github.com/ohhyeeaah/FSAMLM-for-fault-diagnosis .},
  archive      = {J_ASOC},
  author       = {Xin Zhang and Shixi Liu and Li Jiang and Yibing Li},
  doi          = {10.1016/j.asoc.2025.113985},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113985},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FSAMLM: A few-shot adaptation multimodal large model for cross-domain fault diagnosis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based adaptive large neighborhood search algorithm for the integrated vessel scheduling and speed optimization problem in the compound channel. <em>ASOC</em>, <em>185</em>, 113980. (<a href='https://doi.org/10.1016/j.asoc.2025.113980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The carbon emission from vessel navigating in the channel accounts for about 61 % of the total emissions in port areas. Considering an effective means of reducing emissions, namely, speed adjustment, this study deals with an integrated problem of vessel scheduling and speed optimization (VSSOP) in the channel. This study considers the complex structure of a compound channel, i.e., containing both one-way and two-way lanes with different navigation rules. We also focus on the effects of meteorological conditions (winds, waves and currents) on the vessel stall, and tidal restrictions on the time window for large vessels to pass through the channel. Thus, a mixed integer programming (MIP) model for the VSSOP is proposed to control the carbon emissions in the channel. Then, we develop a machine learning-based adaptive large neighborhood search (ALNS) approach, where the ALNS is used to solve the proposed MIP in real cases and the dynamic machine learning approach helps to evaluate and fit the complex effects of multiple meteorological conditions on the vessel sailing speed. The dynamic parallel mechanism is further introduced to improve the fitting accuracy of the machine learning part without increasing the running time of the ALNS. The experimental results reveal that the machine learning-based ALNS approach can be applied in practice. Additionally, valuable managerial insights for port operators are obtained to aid in vessel traffic management.},
  archive      = {J_ASOC},
  author       = {Jian Du and Shan Lin and Liming Guo and Jianfeng Zheng},
  doi          = {10.1016/j.asoc.2025.113980},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113980},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Machine learning-based adaptive large neighborhood search algorithm for the integrated vessel scheduling and speed optimization problem in the compound channel},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-guided optimization of railway alignments using an adaptive rapidly-exploring random tree algorithm. <em>ASOC</em>, <em>185</em>, 113977. (<a href='https://doi.org/10.1016/j.asoc.2025.113977'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway alignment design is a crucial part of a railway project. Despite the widespread success of computer-aided alignment optimization methods in determining alignments, effectively exploring the objective function’s descent direction (OFDD) remains challenging, particularly when navigating complex alignment search spaces. To address this issue, it is essential to comprehensively consider key factors, including the global and local environment, explored and unexplored search spaces, as well as established alignment search strategies and potential new ones that may emerge during the OFDD optimizing process. Therefore, an alignment-oriented Transformer framework is formulated in this work. In this framework, various real-world railway cases are input into a stacked Transformer framework to learn an optimized OFDD strategy. Specifically, the model handles regular inputs (i.e., global and local contexts, long-term goals) and irregular inputs (i.e., historical paths) using two separate stacked Transformer encoders. Afterward, an adaptive rapidly-exploring random tree star (Ada-RRT-star) method is developed by integrating the Transformer framework’s output to guide RRT’s search direction as well as to enhance the solution quality. Ultimately, the proposed method is applied to a realistic railway case, where the results demonstrate its superiority over the conventional 3D-RRT-star algorithm in terms of solution quality. Besides, the best alignment generated by the Ada-RRT-star also outperforms the manually-designed alignment.},
  archive      = {J_ASOC},
  author       = {Xinjie Wan and Hao Pu and Paul Schonfeld and Yang Ran and Taoran Song and Lihui Peng},
  doi          = {10.1016/j.asoc.2025.113977},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113977},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-guided optimization of railway alignments using an adaptive rapidly-exploring random tree algorithm},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A label enhancement based positive-unlabeled hybrid network for pump bearing intelligent fault diagnosis. <em>ASOC</em>, <em>185</em>, 113976. (<a href='https://doi.org/10.1016/j.asoc.2025.113976'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are important support parts for rotating machinery such as pumps, and the application of machine learning algorithms has brought the fault diagnosis of bearings to a more intelligent stage. However, with the scarcity of target fault data and the lack of accurate labeling for critical data, commonly used data-driven fault diagnosis methods had its limitations. Inspired by semi-supervised learning, hypergraph and knowledge distillation theories, a hybrid PUHGNN network based on label augmentation was proposed in this paper. Firstly, a hypergraph neural network (HGNN) structure based on the multi-resolution signal was proposed to measure the correlation at multiple scales to make difference and connections between different labels. Secondly, the HGNN network is improved by combining HGNN and Positive-Unlabeled (PU) Learning ideas to form a new PUHGNN label enhancing mechanism which will solve the lacking of labels. Lastly, a soft-label-based label selection method is proposed to dynamically judge the similarity of samples to reiterate, which will make the otherwise indistinguishable faults more explicit. In experimental session, the CWRU dataset and the enviormental protection pump bearing datasets were applied to conduct unbalance, mislabel, extreme mislabel and ablation experiments. The result shows that the label enhancement is not only necessary but significant in the unbalanced under-labeled datasets, furthermore, the PUHGNN has more obvious enhancement compared to other methods.},
  archive      = {J_ASOC},
  author       = {Jiaxing zhu and Junlan Hu and Buyun Sheng},
  doi          = {10.1016/j.asoc.2025.113976},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113976},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A label enhancement based positive-unlabeled hybrid network for pump bearing intelligent fault diagnosis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rural road extraction from remote sensing images based on multi-view contextual information and multi-stage features. <em>ASOC</em>, <em>185</em>, 113975. (<a href='https://doi.org/10.1016/j.asoc.2025.113975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate extraction of rural roads from high-resolution optical remote sensing images is of great significance to the development of rural areas, road navigation, rural land resource planning and other applications. Different from urban roads, rural ones with complex terrain backgrounds are often slender and winding, thereby making them more susceptible to vegetation cover. In order to improve the reliability and accuracy of rural road extraction, a Complex Rural Road Extraction Network (CRRENet) is proposed in this work, which consists of five parts: feature encoder, Multi-view Contextual Information Extraction Module (MCIEM), Multi-stage Feature Fusion Module (MFFM), Channel Coordinate Attention Mechanism (CCAM) and feature decoder. The MCIEM extracts the multi-view contextual information by the parallel dilated convolution with different dilation rates. To avoid the loss of image details, the MFFM integrates different feature maps from the downsampling stages. By adjusting the weights of feature maps, the CCAM enables the network to self-adaptively suppress the background noise and focus on the road foreground. Ablation and comparison validate CRRENet's superiority.},
  archive      = {J_ASOC},
  author       = {Langping Li and Jizheng Yi and Pengyu Lei and Hengkai Lou and Xiaoyao Li and Hui Lin},
  doi          = {10.1016/j.asoc.2025.113975},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113975},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Rural road extraction from remote sensing images based on multi-view contextual information and multi-stage features},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint stage features modulation for progressive blind face restoration. <em>ASOC</em>, <em>185</em>, 113974. (<a href='https://doi.org/10.1016/j.asoc.2025.113974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant challenge for Blind Face Restoration (BFR) is to cope with the degraded information of unknown parameters in face images. The BFR method has evolved from non-prior to prior-based methods, but there are still some shortcomings. The quality of priors seriously affects the restoration results, especially in scenarios with severe degradation. Simultaneously encoding or modulating degraded images directly into the restoration process can introduce degraded information, leading to poor visual perception. Therefore, we propose a progressive restoration model with the joint stage features modulation, named JSFM-GAN. JSFM-GAN can be seen as having two stages. In the first stage, the LQ image is modulated with the facial resolution map to provide a rough structure for recovery. In the second stage, Joint Stage Feature Modulation (JSFM) utilizes the LQ images and stage features for joint modulation on multiple scales to balance fidelity and realism by combining clean spatial information of stage features and the tonal structure of LQ images. At the same time, the Up-Sampling Feature Supplement Block (UFSB) is used to reduce information loss due to channel fading and improve the network’s focus on face components and textures. In addition, we use the stage reconstruction loss and adjusted facial parsing maps to enhance the realism and symmetry of the generated results. Experiments with JSFM-GAN on synthetic and real-world datasets achieve good results, demonstrating the superior performance of our method.},
  archive      = {J_ASOC},
  author       = {Xianlun Tang and Xiaodong Qian and Jie Li and Binyu Lu and Wuquan Deng and Weisheng Li},
  doi          = {10.1016/j.asoc.2025.113974},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113974},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Joint stage features modulation for progressive blind face restoration},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilinear hyperspectral unmixing based on autoencoder and recurrent neural network. <em>ASOC</em>, <em>185</em>, 113972. (<a href='https://doi.org/10.1016/j.asoc.2025.113972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral unmixing techniques estimate the endmember spectra and corresponding abundance fractions that constitute the pixels of hyperspectral remote sensing images, revealing the mixing mechanisms of materials within pixels. In recent years, deep learning has shown significant potential in advancing spectral unmixing, particularly in nonlinear scenarios. However, most existing nonlinear models rely on bilinear mixing frameworks, with limited focus on high-order nonlinear models. This restricts their ability to capture complex interactions such as multiple light scattering events. To address this issue, this work proposes an unsupervised unmixing method leveraging an autoencoder network framework and the multilinear mixing model (MLM). It employs a recurrent neural network (RNN) in the decoder to simulate the multiple scattering of light between materials. Unlike conventional multilinear approaches that rely on explicit mathematical formulations, the proposed method leverages the RNN to automatically learn and approximate the nonlinear interactions of light. Moreover, the RNN weights are adaptively updated during training and interpreted as transition probabilities representing further light interactions among materials, endowing the model structure with explicit physical interpretation. Besides, a new stopping criterion is also designed, which ensures better RNN weights are obtained during backpropagation. Experiments conducted on both synthetic and real datasets demonstrate the better performance of the proposed method.},
  archive      = {J_ASOC},
  author       = {Zehui Jin and Xiaorui Yi and Yue Liu and Hongjuan Zhang},
  doi          = {10.1016/j.asoc.2025.113972},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113972},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multilinear hyperspectral unmixing based on autoencoder and recurrent neural network},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets. <em>ASOC</em>, <em>185</em>, 113969. (<a href='https://doi.org/10.1016/j.asoc.2025.113969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors segmentation in Magnetic Resonance Imaging (MRI) images poses significant challenges owing to the uncertain location and size of the tumors, the difficulty in describing their boundaries, and the fuzzy demarcation of diseased tissues. Although U-Net and its recent variants have emerged as leading models for semantic segmentation in medical imaging, they still face structural limitations. These limitations cause the erosion of detail information during downsampling and poor performance in segmenting small lesions when handling targets of varying sizes, indicating a lack of detail handling capability. To counteract these issues, we designed a segmentation model that enhances detail features using frequency information. To reduce the loss of feature information during downsampling, we developed a downsampling module based on lifting wavelets. By lifting wavelets to group and integrate features according to frequency from high to low, we reduce feature resolution while enhancing information transmission and minimizing feature information loss. In our designed multi-frequency directional filtering edge feature extraction module, we extract low-frequency and high-frequency features and construct a dual-channel multi-directional filtering combination. This combination extracts directional information from low-frequency and high-frequency features separately, increasing the multi-angle directional information of the features and enriching the detailed information such as direction and position within the features. On the BraTS2018, BraTS2020, and BraTS2024 brain tumor datasets, our model demonstrated optimal results compared to 14 other advanced models. The average Dice Similarity Coefficients are 78.48 %, 79.80 %, and 74.35 %, while the 95th percentile Hausdorff Distances are 5.75, 6.60, and 7.72. Our code link is https://github.com/Eric-H8/BraTS_Seg_Model .},
  archive      = {J_ASOC},
  author       = {Xin Hua and Zhijiang Du and Hongjian Yu and Zibo Li and Qiaohui Lu and Hui Zhao},
  doi          = {10.1016/j.asoc.2025.113969},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extracting knowledge from limited data: An updated review of data-driven and model-driven few-shot learning for agriculture. <em>ASOC</em>, <em>185</em>, 113968. (<a href='https://doi.org/10.1016/j.asoc.2025.113968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has demonstrated considerable success in agricultural applications. However, its conventional implementations heavily depend on large-scale labelled datasets—a requirement that is often impractical in agriculture due to data scarcity, high annotation costs, or environmental variability. While insufficient training data can significantly limit the performance of standard deep learning models, Few-Shot Learning (FSL) has emerged as a transformative paradigm, enabling robust model training with minimal labelled samples by utilising limited data for training instead. Despite its potential, a critical review assessing how FSL addresses expert system challenges in agriculture remains notably absent. This paper attempts to fill this void by presenting an updated comprehensive review of FSL's applications in agriculture. We categorise FSL methodologies into two primary approaches: data processing-driven and model learning-driven. Data processing–driven approaches address data scarcity by enriching representational diversity through synthetic samples generated with models such as generative adversarial networks, or by transferring knowledge from related domains to improve generalisation. In contrast, model learning–driven strategies confront the same challenge through specialised architectures and optimisation techniques that enable effective generalisation from limited samples. Within this taxonomy, data processing–driven paradigms include transfer learning and generative artificial intelligence, while model learning–driven paradigms cover metric learning methods such as Siamese or prototypical networks, together with model-based and optimisation approaches designed for efficient generalisation. Our analysis pinpoints cutting-edge technologies within each sector, shedding light on overlooked areas and opportunities where FSL can harness limited data to yield promising outcomes when used to solve problems in agriculture.},
  archive      = {J_ASOC},
  author       = {Kam Meng Goh and Usman Ullah Sheikh and Jun Kit Chaw and Weng Kin Lai and Weng Chun Tan and Santhi Krishnamoorthy},
  doi          = {10.1016/j.asoc.2025.113968},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113968},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Extracting knowledge from limited data: An updated review of data-driven and model-driven few-shot learning for agriculture},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coverage exploration of unknown obstacle-cluttered environments using a swarm of ground robots. <em>ASOC</em>, <em>185</em>, 113964. (<a href='https://doi.org/10.1016/j.asoc.2025.113964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a coverage exploration algorithm for unknown obstacle-cluttered environments using a swarm of ground robots. A key contribution of this work is the proposed fitness function, which balances multiple exploration objectives and encourages robots to disperse effectively, avoiding excessive overlapping visits. The robots are assumed to start from a single corner of the environment, reflecting practical situations where pre-distributing them is not feasible. This setup highlights a key feature of the algorithm, as it enables self-organization and effective distribution of the robots throughout the environment. The robustness of the method is demonstrated through experiments in various environmental setups, showing its resilience to different obstacle structures and reliable performance across diverse scenarios. The approach also leverages the benefits of swarm behavior, where an increasing number of robots improves exploration efficiency through enhanced collaboration and coverage. The algorithm is evaluated against a swarm random walk approach and two multi-robot meta-heuristic methods, significantly outperforming them in terms of coverage efficiency and robustness.},
  archive      = {J_ASOC},
  author       = {Khalil Al-rahman Youssefi and Wilfried Elmenreich},
  doi          = {10.1016/j.asoc.2025.113964},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113964},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Coverage exploration of unknown obstacle-cluttered environments using a swarm of ground robots},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated deep embedded clustering under privacy protection. <em>ASOC</em>, <em>185</em>, 113963. (<a href='https://doi.org/10.1016/j.asoc.2025.113963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering, a prominent research focus in data mining, utilizes deeply embedded features to reveal the intrinsic statistical structure of data. However, existing deep clustering models rely on centralized datasets, which are impractical in scenarios with data silos and privacy constraints, leading to degraded clustering performance. Considering the privacy protection characteristics of federated learning, this paper incorporates the idea of federated learning into deep clustering, and proposes a federated deep embedding clustering (FDEC) model under privacy protection. FDEC follows a universal client-server structure, coordinating training between clients through a central server to obtain a unified central model. The server updates the global deep embedding and cluster centers based on a hybrid federated averaging strategy, while each client conducts two-stage deep clustering on local data without sharing raw data. To enhance robustness under non-independent and identically distributed (non-IID) conditions, the hybrid strategy improves parameter aggregation effectiveness. Experimental results on both IID and non-IID datasets demonstrate that FDEC is more robust and consistently outperforms centralized deep clustering methods.},
  archive      = {J_ASOC},
  author       = {Xiao Xu and Hong Liao and Xu Yang},
  doi          = {10.1016/j.asoc.2025.113963},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113963},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Federated deep embedded clustering under privacy protection},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WamGLM: A multimodal large-scale language model for wafer map defect information in-depth query through multi-turn dialogue based on prototypical supervised contrastive learning. <em>ASOC</em>, <em>185</em>, 113962. (<a href='https://doi.org/10.1016/j.asoc.2025.113962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure production efficiency and process stability in semiconductor manufacturing, it is of critical importance to detect wafer map defects and perform information query for tracing and solving problems during the manufacturing process. Numerous vision models based on deep learning have been successfully applied to wafer map defect recognition (WMDR), yielding remarkable results. However, the dynamic and in-depth querying of wafer map defect information remains relatively underexplored. Leveraging the rapid advancements in multimodal large language models (MLLMs), this paper proposes a novel approach for wafer map defect information query (WMDIQ). First, following the paradigm of employing cross-modal alignment model to bridge vision and language models, an end-to-end response MLLM: general language model for wafer map (WamGLM), is constructed for WMDIQ. Concurrently, by designing an interactive dialogue framework between large language models (LLMs), the first large-scale multi-turn dialogue dataset: visual multi-turn question answering dataset for wafer map defects (WaferMapVMQA Dataset), is constructed for wafer map defect analysis. Subsequently, WamGLM is trained using a two-stage fine-tuning strategy. In the first stage, a visual fine-tuning method based on prototypical supervised contrastive learning (PSCL) is introduced to enhance the intra-class compactness and inter-class separability of defect features. In the second stage, language fine-tuning is conducted using the WaferMapVMQA Dataset to infuse specialized knowledge into WamGLM. To validate the effectiveness and superiority of the proposed method, experiments are conducted on a real wafer map dataset. The results demonstrate that the proposed method significantly outperforms other methods in both defect recognition performance and information query response performance. Our code is available at: https://github.com/ZihaoLei/WamGLM .},
  archive      = {J_ASOC},
  author       = {Shulong Gu and Zihao Lei and Guangrui Wen and Quanning Xu and Zhaojun Steven Li and Xuefeng Chen and Chunsheng Yang},
  doi          = {10.1016/j.asoc.2025.113962},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113962},
  shortjournal = {Appl. Soft. Comput.},
  title        = {WamGLM: A multimodal large-scale language model for wafer map defect information in-depth query through multi-turn dialogue based on prototypical supervised contrastive learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representing online reviews using interval type-2 fuzzy Z-numbers for ranking energy-saving appliances. <em>ASOC</em>, <em>185</em>, 113961. (<a href='https://doi.org/10.1016/j.asoc.2025.113961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As e-commerce develops and the green consumption concept gains popularity, consumers are increasingly inclined to purchase energy-saving home appliances through e-commerce platforms. However, they often face technical complexities related to specialized energy-saving attributes and an overwhelming number of online reviews. To address these challenges, we have integrated energy-saving features into our online review analysis, incorporating weight calculations. Notably, we propose and prove a method that transforms online review information into interval type-2 fuzzy Z-numbers (IT2FZNs), which comprehensively represent the information to support product ranking. First, based on the energy-saving attributes of energy-saving appliances and their online review data, we extract energy-saving features and online review features, respectively. We then use a combination of TF-IDF-based text mining and BWM-based expert evaluation to determine the weight of each feature. Next, we convert the energy-saving feature data into IT2FZNs according to specific rules. The online review feature data is converted into interval type-2 fuzzy sets (IT2Fs) by considering the sentiment classification results and the accuracy and robustness of the model, and is further combined with the reliability of online reviews to form IT2FZNs. Finally, the alternative products are ranked based on the constructed decision matrix, and the final ranking results are determined. The method's effectiveness and practicality have been demonstrated using real data from energy-saving refrigerators on the JingDong (JD.com) platform, and its robustness and superiority have been further substantiated through comparative experiments.},
  archive      = {J_ASOC},
  author       = {Yue Xiao and Ming Li and Ying Li and Hongde Liu},
  doi          = {10.1016/j.asoc.2025.113961},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113961},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Representing online reviews using interval type-2 fuzzy Z-numbers for ranking energy-saving appliances},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria linguistic optimization for covert communication in secure LLM-based steganography. <em>ASOC</em>, <em>185</em>, 113960. (<a href='https://doi.org/10.1016/j.asoc.2025.113960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel framework for covert communication through secure steganography using large language models (LLMs). Our approach leverages multi-criteria linguistic optimization to encode secret information directly into stylistic features of auto-regressively generated text. This strategy balances embedding capacity with naturalness and coherence. The secret message is partitioned into fixed-size blocks. Each block is embedded into binary stylistic feature vectors via a surjective linear mapping, which introduces redundancy. This redundancy enables the use of a history-aware cost function that selects stylistic vectors to minimize abrupt transitions and preserve fluency across sentences. Candidate sentences are generated by prompting LLMs with contextual and stylistic constraints. Rejection sampling then ensures exact feature matching and high linguistic quality. Experimental evaluation in multiple LLMs, diverse text contexts, and parameter settings demonstrates effective embedding capacities of up to 0.30 bits per token while maintaining strong linguistic naturalness, validated through perplexity, lexical diversity, readability, and a linguistic acceptability metric. Importantly, decoding recovers the full secret with zero error under ideal conditions. This confirms the reliability of the method. The current work focuses on embedding efficiency and imperceptibility. Robustness against active text alterations and formal undetectability assessments remain open challenges for future research. The proposed multi-criteria linguistic optimization framework offers a promising avenue for advanced covert communication by harmonizing secure information embedding with fluent, human-like language generation.},
  archive      = {J_ASOC},
  author       = {Kamil Woźniak and Marek R. Ogiela and Lidia Ogiela},
  doi          = {10.1016/j.asoc.2025.113960},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113960},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-criteria linguistic optimization for covert communication in secure LLM-based steganography},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative driving route planning based on asymmetric multi-agent path planning problem with limited service area constraints. <em>ASOC</em>, <em>185</em>, 113959. (<a href='https://doi.org/10.1016/j.asoc.2025.113959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobility and logistics service providers operating a vehicle fleet and serving several targets with each vehicle are faced with the challenge of planning efficient and cooperative driving routes while considering all the vehicles. To address this challenge, we present a novel driving route planning method based on an Asymmetric Multi-Agent Path Planning (AMAPP) problem, a variation of the classical Multiple Traveling Salesmen Problem (MTSP). Given a team of m agents (vehicles) that must visit n targets located in a real road network, a set of m optimized open paths (the Plan ) must be found such that each target is visited exactly once. The optimization objective is to minimize the driving distance of the path with the longest driving distance in the Plan (a Min-Max problem) so that this cooperative operation can be completed in the least amount of time. In several cases, the service area for each agent is limited (e.g., certain districts in a city). To simulate this real-world condition, two additional constraints are applied: the maximum geodetic range for each agent, and the maximum spatial range of targets for each agent. An easy-to-apply Genetic Algorithm (GA) with two novel initialization methods is presented to solve this route planning problem. In order to validate the developed route planning method and demonstrate its applicability, the method was tested in a real-world test case where it showed a decent performance. The results show that the applied limited service area constraints not only decrease the average driving distance of the longest route in the route plan, but also reduce the average runtime of the developed solution. Additionally, the performance of the proposed GA was benchmarked using 26 problems based on the TSPLIB instances, where the proposed GA achieved new Best Known Solution (BKS) values for 19 benchmark problems and a result equal to the BKS value for another two problems, demonstrating its superiority and robustness. The developed method can be used for route planning of the mobility and logistics services requiring multiple destinations to be reached by a fleet of vehicles, such as group ride-sharing and last-mile delivery.},
  archive      = {J_ASOC},
  author       = {Ali Maktabifard and Dávid Földes},
  doi          = {10.1016/j.asoc.2025.113959},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113959},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cooperative driving route planning based on asymmetric multi-agent path planning problem with limited service area constraints},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A granularity time series forecasting model combining three-way decision and trend information granule. <em>ASOC</em>, <em>185</em>, 113957. (<a href='https://doi.org/10.1016/j.asoc.2025.113957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term forecasting of time series plays a vital role across diverse applications but is challenged by error accumulation arising from recursive predictions and the insufficient retention of trend information in conventional methods. To tackle these issues, we propose a novel forecasting model based on granular time series (GTS). The model utilizes an improved L 1 -trend filtering technique to achieve optimal segmentation of information granules, preserving essential trend features. Subsequently, we introduce dual evaluation functions based on distance similarity to jointly drive the three-way decision (TWD) process for aggregating information granules, thereby effectively reducing error propagation. Finally, the aggregated granules serve as inputs to a long short-term memory (LSTM) neural network to generate accurate forecasts. In addition, the proposed model is evaluated on several real-world datasets through sensitivity and comparative analyses. The results demonstrate that the model exhibits strong performance in long-term forecasting tasks.},
  archive      = {J_ASOC},
  author       = {Jianuan Qiu and Shuhua Su and Jingjing Qian},
  doi          = {10.1016/j.asoc.2025.113957},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113957},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A granularity time series forecasting model combining three-way decision and trend information granule},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective genetic programming for binary classification with adaptive thresholds and a generalization-optimizing fitness function. <em>ASOC</em>, <em>185</em>, 113956. (<a href='https://doi.org/10.1016/j.asoc.2025.113956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) has been widely applied to classifier construction due to its flexible representation and powerful feature construction capabilities. Existing studies have proposed various fitness functions to improve GP-based classifiers, but most of them rely on a fixed decision threshold. However, when dealing with imbalanced classification problems, a fixed threshold often biases the model toward the majority class, thereby compromising overall performance. To address this issue, in this paper, we propose a novel multi-objective GP framework for constructing binary classifiers with adaptive threshold adjustment. During evolution, the method employs Youden’s Index to dynamically adjust the threshold of each individual, enabling the classifiers to better fit the underlying data distribution. In addition, we introduce a new class separation metric, dist t , to quantify the clarity of class boundaries and enhance the generalization ability of the evolved models. The framework jointly optimizes three objectives: minority class accuracy, majority class accuracy, and the proposed dist t metric. Experiments on 14 imbalanced datasets demonstrate that our method significantly outperforms conventional single-objective GP with fixed thresholds. Further results also confirm the positive impact of the proposed dist t metric on classification performance. Compared to seven existing GP algorithms and five traditional machine learning classifiers, our approach achieves superior overall performance and better generalization ability.},
  archive      = {J_ASOC},
  author       = {Minghui Bai and Yuan Gao and Xiaoying Gao and Jianbin Ma},
  doi          = {10.1016/j.asoc.2025.113956},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113956},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective genetic programming for binary classification with adaptive thresholds and a generalization-optimizing fitness function},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fuzzy entropy optimization with opposition-based archimedes search for robust multilevel image segmentation. <em>ASOC</em>, <em>185</em>, 113943. (<a href='https://doi.org/10.1016/j.asoc.2025.113943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation plays a critical role in diverse computer vision applications. Multilevel thresholding (MLT) remains one of its most widely used unsupervised techniques due to its simplicity and interpretability. However, existing MLT methods often suffer from two major limitations: (1) the inability to adapt to local intensity variations and (2) the computational burden associated with high-dimensional threshold search. To address these challenges, this study proposes a novel segmentation framework that integrates a Proximity-Adaptive Fuzzy Entropy (PAFE) model with an Opposition-Based Learning-enhanced Archimedes Optimization Algorithm (OBL-EAOA). The PAFE model utilizes dynamically adjusted trapezoidal membership functions based on intensity proximity to candidate thresholds, allowing for a more adaptive and smooth entropy surface. Meanwhile, the OBL-EAOA enhances optimization performance through opposition-based learning and adaptive parameter control, improving exploration diversity and convergence speed. The proposed PAFE-EAOA framework is validated on two benchmark datasets, BSD500 and PASCAL VOC 2012, using five standard metrics: PSNR, SSIM, FSIM, SNR, and computation time. Compared with several state-of-the-art methods including Kapur Entropy (KE)-EAOA, Fuzzy Entropy (FE)-EAOA, Patch-Levy-Based Bees Algorithm (PLBA), Marine Predators Algorithm (MPA), Improved Grey Wolf Optimizer (IGWO), and standard Archimedes Optimization Algorithm (AOA), the proposed approach consistently achieves superior segmentation quality. Notably, it reduces computation time by up to 60 % and achieves statistically significant improvements, as confirmed by the Wilcoxon signed-rank test. These results demonstrate the framework’s robustness, scalability, and effectiveness for real-world MLT-based image segmentation.},
  archive      = {J_ASOC},
  author       = {Anusha Ganesan and Sungho Kim and Ganesan Nagabushnam},
  doi          = {10.1016/j.asoc.2025.113943},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113943},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive fuzzy entropy optimization with opposition-based archimedes search for robust multilevel image segmentation},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework. <em>ASOC</em>, <em>185</em>, 113942. (<a href='https://doi.org/10.1016/j.asoc.2025.113942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal additive manufacturing (AM) has revolutionized industries such as aerospace and automotive manufacturing due to its ability to rapidly prototype complex structures. Laser Directed Energy Deposition (L-DED) is a key AM technique, offering high deposition rates and superior mechanical properties. However, the inherent complexity and high cost of L-DED equipment demand reliable maintenance management to minimize downtime. Traditional maintenance approaches struggle to keep pace with escalating production demands and to cope with growing equipment complexity. To address this, we propose a dual-driven intelligent maintenance system for L-DED, integrating Digital Twins (DT) and Large Language Models (LLMs). The system features a comprehensive DT framework that synchronizes the virtual entity with the physical one in real time, it also incorporates an intelligent maintenance Q&A assistant powered by Retrieval-Augmented Generation (RAG), leveraging L-DED maintenance knowledge bases to provide accurate operational support. Additionally, we propose a Directed Acyclic Graphs (DAG)-based framework to assess LLMs’ ability to guide users through complete fault diagnosis. Our work aims to enhance the reliability and efficiency of L-DED maintenance through advanced digital technologies, ultimately improving productivity and reducing downtime in additive manufacturing.},
  archive      = {J_ASOC},
  author       = {Jian Tang and Shitong Peng and Jianan Guo and Danya Song and Dongna Gao and Weiwei Liu and Fengtao Wang},
  doi          = {10.1016/j.asoc.2025.113942},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113942},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model. <em>ASOC</em>, <em>185</em>, 113941. (<a href='https://doi.org/10.1016/j.asoc.2025.113941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large model technology exemplified by large language models has been applied in the field of industrial fault diagnosis. However, existing large models are optimized for specific equipment types and have yet to fully exploit the potential of time-series monitoring data to enable widespread application across diverse mechanical equipment in various industrial scenarios. To address this challenge, a fault diagnosis large model (UniTS-FD) is designed based on unified time series model (UniTS). First, a multi-scale feature fusion backbone network is developed based on UniTS backbone to capture general mechanical fault features. Second, the fault classification head integrates the Pearson correlation coefficient to assess the similarity of class information within linear space for enabling adaptive classification. Third, P-LoRA fine-tuning approach incorporating LoRA and prompt technology is proposed to fine-tune the fault classification head, which enhances the generalization ability of the UniTS-FD model for fault diagnosis tasks of various mechanical equipment. Finally, the UniTS-FD model is pre-trained on 11 fault datasets and fine-tuning experiments were conducted on four different fault datasets to achieve cross-machine fault diagnosis. Experimental results demonstrate the effectiveness of the UniTS-FD in fault diagnosis tasks.},
  archive      = {J_ASOC},
  author       = {Zhiwei Zhang and Chengbin Wei and Weimin Zhang and Long Wen},
  doi          = {10.1016/j.asoc.2025.113941},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113941},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A federated learning-based method for personalized manufacturing service recommendation with collaborative relationships. <em>ASOC</em>, <em>185</em>, 113940. (<a href='https://doi.org/10.1016/j.asoc.2025.113940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the industrial Internet environment, the increasing complexity of manufacturing tasks has rendered them no longer accomplishable by independent manufacturing services. Meanwhile, current recommendation systems predominantly face challenges in maintaining data privacy and security during client parameter exchanges. To address these issues, this paper proposes CoFedSVD+ +, a federated learning-based method for personalized manufacturing service recommendation that integrates an enhanced SVD+ + algorithm with homomorphic encryption. First, we devise an enhanced similarity calculation method to analyze collaborative relationships among manufacturing services. Second, we implement a homomorphic encryption protocol within the federated learning framework to resolve data isolation challenges. Third, the improved SVD+ + algorithm is employed to capture implicit feedback information and predict missing Quality of Service (QoS) metrics. Fourth, a Top-N service composition recommendation list is generated through synergistic analysis of collaborative relationships and QoS predictions. Finally, we validate our approach using real-world case data from an industrial Internet platform. Experimental comparisons with existing recommendation algorithms demonstrate superior recommendation effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Lei Wang and Jun Wang and Feng Xiang and Tongshun Li and Yang Xu and Yibing Li},
  doi          = {10.1016/j.asoc.2025.113940},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113940},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A federated learning-based method for personalized manufacturing service recommendation with collaborative relationships},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Span-level emotion-cause-category triplet extraction with instruction tuning LLMs and data augmentation. <em>ASOC</em>, <em>185</em>, 113938. (<a href='https://doi.org/10.1016/j.asoc.2025.113938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Span-level emotion-cause-category triplet extraction is a fine-grained task in emotion cause analysis that aims to identify emotion spans, cause spans, and their corresponding emotion categories from documents. Existing methods, including clause-level emotion-cause pair extraction and span-level emotion-cause detection, often suffer from redundant information and difficulties in accurately classifying emotion categories, particularly when emotions are expressed implicitly or ambiguously. To overcome these challenges, this study explores a fine-grained approach to span-level emotion-cause-category triplet extraction and introduces an innovative framework that leverages instruction tuning and data augmentation techniques based on large language models. The proposed method employs task-specific triplet extraction instructions and utilizes low-rank adaptation to fine-tune large language models, eliminating the necessity for intricate task-specific architectures. Furthermore, an LLM-based data augmentation strategy is developed to address data scarcity by guiding large language models in generating high-quality synthetic training data. Extensive experimental evaluations demonstrate that the proposed approach significantly outperforms existing baseline methods, achieving at least a 12.8 % improvement in span-level emotion-cause-category triplet extraction metrics. The results demonstrate the method’s effectiveness and robustness, offering a promising avenue for advancing research in emotion cause analysis.},
  archive      = {J_ASOC},
  author       = {Xiangju Li and Dong Yang and Xiaogang Zhu and Faliang Huang and Peng Zhang and Zhongying Zhao},
  doi          = {10.1016/j.asoc.2025.113938},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113938},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Span-level emotion-cause-category triplet extraction with instruction tuning LLMs and data augmentation},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep cross-visual semantic hashing with self-calibrated collaborative attention. <em>ASOC</em>, <em>185</em>, 113937. (<a href='https://doi.org/10.1016/j.asoc.2025.113937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has garnered considerable attention due to its remarkable retrieval efficiency and low storage cost, particularly in visual retrieval scenarios. However, current deep hashing methods generally integrate hash coding into a single-stream architecture, which limits the discriminative power of learned visual features and yields suboptimal hash codes. Additionally, over-reliance on semantic labels shared across samples fails to fully exploit the intrinsic semantic correlations between labels and corresponding visual features. To address these issues, we propose a deep cross-visual semantic hashing (DCvSH) method for image retrieval. First, we develop a visual image feature decoupling encoding network that leverages a self-calibrated collaborative attention mechanism to disentangle common and specific semantics across related images. These decoupled features are fed into a shared decoder for image reconstruction, yielding discriminative visual feature representations. Second, we construct a cross-visual semantic representation learning network with a two-level multi-layer perceptron to capture the underlying relationships between semantic label encodings and visual feature embeddings, while a hypergraph structure is introduced to preserve pairwise similarity relationships. Experimental results on the CIFAR-10, NUS-WIDE, and MIRFLICKR datasets demonstrate consistent improvements, with average mean average precision (mAP) scores reaching 0.895, 0.874, and 0.881 at different code lengths, respectively. Notably, DCvSH outperforms other baselines across all evaluation metrics.},
  archive      = {J_ASOC},
  author       = {Hao Feng and Xiangbo Zhou and Yue Wu and Jian Zhou and Banglei Zhao},
  doi          = {10.1016/j.asoc.2025.113937},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113937},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep cross-visual semantic hashing with self-calibrated collaborative attention},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large model for fault diagnosis of industrial equipment based on a knowledge graph construction. <em>ASOC</em>, <em>185</em>, 113936. (<a href='https://doi.org/10.1016/j.asoc.2025.113936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the significant heterogeneity of multi-modal data and the challenges in capturing fault semantics for industrial equipment, a fault diagnosis framework that integrates a time-frequency knowledge graph with the large model DeepSeek-V3 is proposed. Specifically, an unsupervised knowledge graph construction method is designed based on multi-modal vibration data signals. This method mines temporal evolution relationships using dynamic time warping and quantifies the relevance between features and faults via mutual information, thereby forming a dynamic graph representation. Additionally, DeepSeek-V3 encodes the natural language descriptions of vibration features, integrating graph structure and time-frequency map features to achieve collaborative reasoning and diagnosis among text, graphs, and maps. Experimental results show that the proposed method achieves high accuracy and significantly outperforms benchmark models, surpassing traditional methods. The proposed framework, through the deep integration of data-driven knowledge graphs and large model semantic understanding, demonstrates high precision, strong robustness, and transparent decision-making capabilities, providing new insights for intelligent diagnosis of industrial equipment.},
  archive      = {J_ASOC},
  author       = {Jichao Zhuang and Jiaming Yang and Weigang Li and Jian Chen and Yunjun Zheng and Zhuyun Chen},
  doi          = {10.1016/j.asoc.2025.113936},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113936},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Large model for fault diagnosis of industrial equipment based on a knowledge graph construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval-valued pythagorean fuzzy distance-based extended inferior ratio method for multiattribute decision-making: Application to green supplier selection in manufacturing industry. <em>ASOC</em>, <em>185</em>, 113935. (<a href='https://doi.org/10.1016/j.asoc.2025.113935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued Pythagorean fuzzy sets (IVPFSs) have emerged as a powerful tool for handling uncertainty and vagueness in multiattribute decision-making (MADM). In this paper, we first propose a novel distance measure for IVPFSs based on triangular divergence, which satisfies all core distance axioms and significantly improves discrimination ability compared to existing measures. Building on this, we introduce a maximizing deviation strategy with a new loss function to objectively determine attribute weights. Furthermore, we develop an extended inferior ratio (EIR) method that incorporates a dynamic weight parameter to flexibly balance the influence of positive and negative ideal solutions. The performance of the proposed method is demonstrated through a case study on green supplier selection in the manufacturing industry. The results indicate that, among the seven criteria evaluated, the most suitable suppliers are ranked as follows: β (1.0000), α (0.6471), δ (0.3500), ϵ (0.0690), and θ (0.0000). In addition, sensitivity and comparative analyses confirm the robustness and consistency of the proposed method, reflecting its effectiveness and practical value for sustainable decision-making in real-world scenarios.},
  archive      = {J_ASOC},
  author       = {Zhe Liu and Donglai Wang and Muhammet Deveci and Sukumar Letchmunan},
  doi          = {10.1016/j.asoc.2025.113935},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113935},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval-valued pythagorean fuzzy distance-based extended inferior ratio method for multiattribute decision-making: Application to green supplier selection in manufacturing industry},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multidimensional trade performance assessment for integrating sustainability and economic diversification in OECD countries using a spherical fuzzy SIWEC-SPC-based decision support model. <em>ASOC</em>, <em>185</em>, 113934. (<a href='https://doi.org/10.1016/j.asoc.2025.113934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Countries participate in regional trade blocks to enhance their trade activities and trade performance. This study proposes a novel approach to trade performance assessment, introducing innovations both in terms of performance parameters and methodology. From a performance parameter perspective, the inclusion of sustainable development and economic diversity levels in trade performance evaluation differentiates this study from traditional trade performance measurement approaches. From a methodological perspective, a hybrid model that simultaneously considers both subjective and objective criterion weighting based on expert opinions is introduced. The spherical fuzzy (SF)−simple weight calculation (SIWEC)−symmetry point of criterion (SPC)−opportunity losses-based polar coordinate distance (OPLO-POCOD) model, developed as a decision support system, is proposed for evaluating the trade performance of country blocs. SF-SIWEC is employed as the subjective criterion weighting method, while SPC serves as the objective criterion weighting method. The OPLO-POCOD alternative ranking method is employed to calculate the trade performance of countries. The proposed methodology is applied to the Organization for Economic Cooperation and Development (OECD) countries. According to the subjective weighting method, "sustainable development (0.0978)" emerges as the most important criterion, whereas in the objective weighting method, "number of product types (export) (0.1612)" is identified as the most significant one. In the final criterion weights, "number of product types (export) (0.1232)" is also determined to be the most important criterion. Considering the final criterion weights, the United States (0.9871) has the highest trade performance among the OECD countries. Thus, when both sustainability and economic diversification are considered, it is understood that the most influential criteria in determining multidimensional trade performance are the number of exported product types and sustainable development. From this perspective, the United States stands out as the country with the highest multidimensional trade performance among OECD countries. This study contributes to the literature by integrating sustainability and economic diversification parameters into trade performance measurement as well as proposing a comprehensive methodology for performance evaluation in trade blocs.},
  archive      = {J_ASOC},
  author       = {Galip Cihan Yalçın and Karahan Kara and Emre Kadir Özekenci and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113934},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113934},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multidimensional trade performance assessment for integrating sustainability and economic diversification in OECD countries using a spherical fuzzy SIWEC-SPC-based decision support model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing supply routes in a network interdiction model with dual defense operations. <em>ASOC</em>, <em>185</em>, 113933. (<a href='https://doi.org/10.1016/j.asoc.2025.113933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel bi-level defender–attacker model (BDAM) designed to address real-world homeland defense scenarios. Building on the shortest path network interdiction problem (SPNIP), BDAM incorporates dual defense operations—node interdiction and edge destruction—while explicitly modeling the defender’s supply support. Unlike conventional SPNIP formulations, BDAM jointly considers the attacker’s path disruption and the defender’s logistical requirements, ensuring that all interdicted nodes are supported by available supply nodes without exceeding their capacity. To solve this NP-hard problem, a hybrid metaheuristic algorithm named Improved Simplified Swarm Optimization with Dijkstra (iSSOD) is proposed. The method integrates a population-based SSO framework with a randomized repair mechanism to ensure feasibility and an entropy-guided local search to enhance exploitation. The attacker’s optimal response is computed efficiently using Dijkstra’s algorithm, embedded within the defender’s fitness evaluation. The experimental results on 36 artificial instances demonstrate that iSSOD consistently outperforms several benchmark evolutionary algorithms, providing high-quality solutions through a defense-aware, supply-constrained optimization framework. Furthermore, a real-world case study based on geographic data validates the model’s applicability under realistic defense conditions.},
  archive      = {J_ASOC},
  author       = {Wei-Chang Yeh and Chyh-Ming Lai and Tsung-Hua Wu},
  doi          = {10.1016/j.asoc.2025.113933},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113933},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimizing supply routes in a network interdiction model with dual defense operations},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A continuous encoding-based representation for efficient multi-fidelity multi-objective neural architecture search. <em>ASOC</em>, <em>185</em>, 113932. (<a href='https://doi.org/10.1016/j.asoc.2025.113932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) is a powerful tool for automatically designing optimized deep learning models but is often limited by high computational costs, especially in multi-objective settings. To address this, an adaptive Co-Kriging-assisted multi-fidelity multi-objective NAS algorithm is proposed to reduce the computational cost and accelerate convergence of NAS by incorporating a clustering-based local multi-fidelity infill sampling strategy. Additionally, we introduce a novel continuous encoding method to compactly represent node connections within a generalized U-Net backbone, significantly reducing search dimensionality. Extensive experiments demonstrate that our method consistently outperforms state-of-the-art NAS approaches under limited computational budgets on three benchmarks, a 2D Darcy flow regression task, a CHASE_DB1 biomedical image segmentation task, and an urban wind velocity prediction task. Analysis further shows that our algorithm autonomously identifies design patterns consistent with expert-curated U-Net variants in literature, confirming its efficiency and potential for insight into performant architectures.},
  archive      = {J_ASOC},
  author       = {Zhao Wei and Chin Chun Ooi and Yew-Soon Ong},
  doi          = {10.1016/j.asoc.2025.113932},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113932},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A continuous encoding-based representation for efficient multi-fidelity multi-objective neural architecture search},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fall detection system using tabular GAN for data augmentation with integration of isolation forest model. <em>ASOC</em>, <em>185</em>, 113931. (<a href='https://doi.org/10.1016/j.asoc.2025.113931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective Fall Detection Systems (FDS) are essential to minimize the risk of severe injuries among the elderly. However, the limited availability and imbalanced nature of fall detection data pose significant challenges to developing accurate models. This paper proposes a novel approach to enhance fall detection accuracy by using synthetic data generated through Tabular Generative Adversarial Network (GAN), combined with Isolation Forest and Autoencoder models. The dataset was augmented by factors of 5 and 10, and the models were evaluated using the area under the curve-receiver operating characteristic (AUC-ROC) and area under the curve–precision recall (AUC-PR) metrics. Notably, the Isolation Forest model improved from an AUC-ROC of 0.49 and AUC-PR of 0.43 (without augmentation) to 0.59 and 0.63, respectively, with 5x augmentation. Similarly, the Autoencoder showed an increase from 0.4 (AUC-ROC) and 0.2 (AUC-PR) to 0.5 and 0.54 with the same augmentation. These results demonstrate the effectiveness of synthetic data in improving anomaly detection performance. The findings suggest that advanced data augmentation techniques significantly improve FDS, thereby enhancing safety and quality of life for the vulnerable population.},
  archive      = {J_ASOC},
  author       = {Ali Nawaz and Najah Abu Ali and Amir Ahmad},
  doi          = {10.1016/j.asoc.2025.113931},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113931},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fall detection system using tabular GAN for data augmentation with integration of isolation forest model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning-based adaptive operator selection for traveling salesman problem. <em>ASOC</em>, <em>185</em>, 113930. (<a href='https://doi.org/10.1016/j.asoc.2025.113930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In evolutionary optimization, effectively leveraging knowledge about search operator performance is crucial for enhancing algorithmic results. Traditional operator selection strategies often rely on fixed heuristics or trial-and-error, which struggle to adapt to the nonstationary search dynamics of evolutionary runs—i.e., the stage-dependent, instance-dependent, and population-dependent shifts in operator effectiveness—and typically yield suboptimal performance. To address these challenges, we propose a novel meta-learning-based adaptive operator selection (AOS) framework. It leverages a Long Short-Term Memory (LSTM) neural network to learn temporal patterns of operator performance from historical data and dynamically adjust operator choice on-the-fly. The framework also integrates domain-specific biases to preserve population diversity and promote effective exploration, and it continuously updates its selection policy through dynamic online learning as the evolutionary process unfolds. Experiments on the Traveling Salesman Problem (TSP) benchmark demonstrate that the proposed LSTM-based AOS method significantly outperforms conventional approaches to operator selection. In particular, it achieved a median optimality gap of 9.87 % on a suite of TSP instances—approximately a 20 % improvement over the best fixed-operator configuration—indicating superior solution quality. Moreover, our approach consistently surpassed other state-of-the-art AOS techniques, underscoring the efficacy of the LSTM-driven framework and its significant potential to enhance evolutionary algorithm performance on complex optimization tasks.},
  archive      = {J_ASOC},
  author       = {Ho Young Jeong and Byung Duk Song},
  doi          = {10.1016/j.asoc.2025.113930},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113930},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Meta-learning-based adaptive operator selection for traveling salesman problem},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MACityChat: Integrating remote sensing professional large model with general-purpose large model for multi-domain urban land use analysis. <em>ASOC</em>, <em>185</em>, 113929. (<a href='https://doi.org/10.1016/j.asoc.2025.113929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urbanization remains a global trend, with urban land use being a key component of the process. The effective integration and management of land use are critical for the sustainable development of cities. Traditional urban land use analysis methods can fit dynamic models of land use changes nonlinearly, but they face two challenges: First, the analysis process of existing technologies is often a black-box, with unknown principles, reducing the reliability and authenticity of results. Second, traditional machine learning can only analyze urban land use changes from a single domain, such as remote sensing, overlooking the influence of economic and sociological factors. We propose an interpretable urban land use change analysis task and design MACityChat, a framework that combines remote sensing-specific large models with general-purpose large language models for multidisciplinary generalized analysis, while also visualizing the model’s analytical results. In this framework remote sensing images are input into a remote sensing large model, which transforms the semantic objects in the images into textual descriptions. These descriptions are then fed into a general-purpose large language model. A regional tag-guiding module directs the general-purpose language model to incorporate local economic, policy, and cultural knowledge to perform generalized analysis. Finally, the analysis results are visualized on the remote sensing images, providing a detailed examination of urban land use. Extensive experiments show that MACityChat can provide detailed and effective analyses of urban land use changes and visualize these analyses, offering an interpretable and superior solution to urban land use problems.},
  archive      = {J_ASOC},
  author       = {Tianyi Zhou and Zijie Huang and Hui Lin and Zhaobin Zhou and Jia Hu},
  doi          = {10.1016/j.asoc.2025.113929},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113929},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MACityChat: Integrating remote sensing professional large model with general-purpose large model for multi-domain urban land use analysis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategy allocation for financial trading using competitive reinforcement learning and fuzzy logic. <em>ASOC</em>, <em>185</em>, 113927. (<a href='https://doi.org/10.1016/j.asoc.2025.113927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning has been widely adopted for quantitative trading and portfolio management. Research on reinforcement learning methodologies has simulated how a trading agent interacts with the financial market to realize goals, such as maximizing total profit or minimizing risk to optimize a portfolio within a specific period. Moreover, effective technical indicators have been developed for identifying price trends, but they often rely on a singular trading method, potentially limiting their effectiveness in dynamic, noisy markets. To address this limitation, we propose an intelligent, flexible trading system that employs multiple strategies, reflecting real-world trading practices. Our system, aimed at multistrategy allocation management, includes a global manager at a higher level and several local traders at a lower level. To address inherent noise in financial markets and prevent overfitting of the hyperparameters for each trading strategy, the system incorporates fuzzy logic that enhances its environmental representation. The system is tested in the Taiwan TXF and E-mini Standard and Poor’s 500 Index futures markets using 15-minute frequency data. The results demonstrate the system’s robustness and its effective market timing ability, marking a significant advancement in the field.},
  archive      = {J_ASOC},
  author       = {Ju-Chun Huang and Chiao-Ting Chen and Chih-Chung Chang and Szu-Hao Huang},
  doi          = {10.1016/j.asoc.2025.113927},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113927},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Strategy allocation for financial trading using competitive reinforcement learning and fuzzy logic},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and robust ensemble evolving pixel cloud-based image segmentation approach. <em>ASOC</em>, <em>185</em>, 113926. (<a href='https://doi.org/10.1016/j.asoc.2025.113926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing cluster-based image segmentation algorithms have the burden of iterative computation caused by the change of cluster centers and are sensitive to noise. In this paper, we present a fast and robust ensemble evolving pixel cloud-based image segmentation approach. The concept of pixel clouds by clustering pixels of the same pattern around their focal pixels is proposed. The following attributes distinguish the proposed algorithm: (1) The pixel clouds are evolvable according to the global densities of the incoming pixels and the number of pixel clouds is automatically determined. (2) The focal pixels of pixel clouds are dynamically updated with the highest local densities by using the recursive density estimation, which avoids redundant distance calculations when a new pixel arrives. (3) A multiscale morphological gradient reconstruction operation is employed to merge or filter meaningless pixel clouds, especially in noisy images, which helps to adaptively polish neighboring pixel clouds and compact the pixel clouds. (4) An ensemble structure is introduced to fasten the image segmentation speed by splitting the whole image into multiple independent sub-images, in which the pixel clouds are independently formed and evolved. Comprehensive experiments on natural images, remote sensing images and medical images reveal that the proposed approach surpasses the state-of-the-art algorithms in both segmentation accuracy and computational efficiency. Even for the noisy images, the proposed approach demonstrates more robust performance.},
  archive      = {J_ASOC},
  author       = {Tao Zhang and Hai-Jun Rong and Zhao-Xu Yang and Chi-Man Vong},
  doi          = {10.1016/j.asoc.2025.113926},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113926},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fast and robust ensemble evolving pixel cloud-based image segmentation approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven approach to tackling academic stress-coping and mental health issues in college students using spherical fuzzy MARCOS methodology. <em>ASOC</em>, <em>185</em>, 113925. (<a href='https://doi.org/10.1016/j.asoc.2025.113925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drastically developing nature of the knowledge economy and the rising need for top-notch expertise have placed tremendous pressure on college students. As higher education becomes more accessible, masses of students are enrolling in colleges, which puts additional pressure on colleges and institutions; as a result, they cannot provide adequate resources to the students. As the class size increases, many students require mental health assistance, academic guidance, and financial aid, which then puts pressure on the teachers and the facilities. This flood of students overloads the facilities, resulting in it becoming more challenging to provide attention and concern, leading many students to feel overlooked and affecting their mental health. Due to not getting timely support, students may find it challenging to handle their academic responsibilities. Moreover, the students face a heavy workload, unclear guidance, and limited resource access. The objective of this study is to develop a structured, data-driven decision-making framework for systematically evaluating and improving student mental health and academic stress-coping strategies in a college setting. To address this, a comprehensive decision-making structure, measurement of alternatives, and ranking according to the compromised solution (MARCOS) within the spherical fuzzy (SF) environment, has been applied, which evaluates the key factors causing mental health issues by comparing the ideal and anti-ideal alternatives. The novelty of the proposed approach lies in leveraging the SF framework’s explicit ability to model hesitation (abstinence) alongside truth and falsity degrees, enabling more accurate representation of subjective psychological assessments compared to traditional fuzzy models. Furthermore, the method calculates utility functions corresponding to each alternative (coping technique), prioritizes the strategies, and selects the most effective intervention. The results reveal that personalized mental health plans emerged as the top-ranked coping strategy, highlighting the importance of tailored support in culturally and contextually diverse academic environments.},
  archive      = {J_ASOC},
  author       = {Raiha Imran and Munazza Amin and Kifayat Ullah and Dragan Pamucar and Zeeshan Ali and Oumaima Saidani and Vladimir Simic},
  doi          = {10.1016/j.asoc.2025.113925},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113925},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A data-driven approach to tackling academic stress-coping and mental health issues in college students using spherical fuzzy MARCOS methodology},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure and efficient vehicle control of autonomous vehicles using federated deep reinforcement learning. <em>ASOC</em>, <em>185</em>, 113924. (<a href='https://doi.org/10.1016/j.asoc.2025.113924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving is largely considered a revolutionary technology and the ultimate alternative for smart urban mobility. Artificial Intelligence (AI) has been the main pillar of AV technology. However, despite the significant success achieved through the application of various Deep Reinforcement Learning (DRL) techniques in the field of AVs, numerous challenges remain to be addressed. Particularly, in the case of vehicle control, existing works have shown limited results when extensive action and state spaces are involved, and where the efficacy of agents is often compromised due to the variability of states and actions. In response to these challenges, we introduce a pioneering approach leveraging Federated Deep Reinforcement Learning (FDRL), which fosters the exchange of experiences among participating agents while safeguarding their privacy. FDRL enhances the exploration of all agents’ actions and states in different environments and effectively overcomes the problem of low sample efficiency in action and state spaces for all agents. Our approach is based on three distinct FDRL algorithms: Federated Proximal Policy Optimization (FPPO), Federated Deep Deterministic Policy Gradient (FDDPG), and Federated Deep Q-Network (FDQN), each tailored to control AVs within unique environments. Our results demonstrate the superiority of our approach in terms of average reward, waiting time, and speed, when compared to local models such as PPO, DDPG, and DQN.},
  archive      = {J_ASOC},
  author       = {Badr Ben Elallid and Nabil Benamar and Miloud Bagaa and Nabil Mrani},
  doi          = {10.1016/j.asoc.2025.113924},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113924},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Secure and efficient vehicle control of autonomous vehicles using federated deep reinforcement learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). T5-based anomaly-behavior video captioning using semantic relation mining. <em>ASOC</em>, <em>185</em>, 113923. (<a href='https://doi.org/10.1016/j.asoc.2025.113923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video data consist of a series of images that change over time. The sequence of frames in a video provides important information on the motion and continuity of the video. Therefore, this dynamic information can be used to analyze the movement and behavior patterns of objects. Video captioning, which is used to explain a video, can describe the content of the video data and provide subtitles or descriptions in various languages. It can also explain the main points in a video with complex content, facilitating the information provided to users. In captioning, semantic analysis is used to identify the overall context of the data and generate the correct captions. However, captions are usually generated by focusing on major objects and actions, making it difficult to capture the details. In this paper, we propose text-to-text transfer transformer (T5)-based abnormal behavior video capturing using semantic relation mining. The proposed method generates captions with semantic features from video data based on environmental factors and improves the accuracy of video description by identifying the similarity of each caption for similar video and caption classification. This enables the classification and search of video data and is useful in video analysis systems, such as video monitoring and media analysis.},
  archive      = {J_ASOC},
  author       = {Min-Jeong Kim and Kyungyong Chung},
  doi          = {10.1016/j.asoc.2025.113923},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113923},
  shortjournal = {Appl. Soft. Comput.},
  title        = {T5-based anomaly-behavior video captioning using semantic relation mining},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulating phenomenal consciousness using generative agents based on large language models. <em>ASOC</em>, <em>185</em>, 113922. (<a href='https://doi.org/10.1016/j.asoc.2025.113922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios, LLMs may require multiple attempts to achieve human-level performance, potentially leading to inaccurate responses or inferences in practical environments, affecting their long-term consistency and behavior. This paper introduces the Internal Time-Consciousness Machine (ITCM), a computational consciousness structure to simulate the process of human consciousness. We further propose the ITCM-based Agent (ITCMA), which supports action generation and reasoning in open-world settings, and can independently complete tasks. ITCMA enhances LLMs’ ability to understand implicit instructions and apply common-sense knowledge by considering agents’ interaction and reasoning with the environment. The trained ITCMA performs better than state-of-the-art (SOTA) in the seen set. Even untrained ITCMA can achieve higher task completion rates than SOTA on the seen set, indicating its superiority over traditional intelligent agents in utility and generalization. In real-world tasks with quadruped robots, the task completion rate of untrained ITCMA is close to its performance in the unseen set, demonstrating its comparable utility and universality in real-world settings. CCS Concepts: ∙ Human-centered computing → Interactive systems and tools; ∙ Computing methodologies → Natural language processing.},
  archive      = {J_ASOC},
  author       = {Hanzhong Zhang and Jibin Yin and Haoyang Wang and Ziwei Xiang},
  doi          = {10.1016/j.asoc.2025.113922},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113922},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Simulating phenomenal consciousness using generative agents based on large language models},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymmetrical variable driven simulated binary crossover operator for large scale multi-objective optimization. <em>ASOC</em>, <em>185</em>, 113921. (<a href='https://doi.org/10.1016/j.asoc.2025.113921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the excessive number of decision variables, large scale multi-objective optimization has gradually become a hot research topic over the past few years. Although various reproduction operators have been proposed to effectively generate offspring solutions in the huge decision space, they have a common issue in that most of them are focused on the symmetrical variables and neglect asymmetrical variables. Based on the summary above, it is empirically proved that asymmetrical variables with great similarities play an important role in facilitating each other ′ s effective exploration of the huge decision space. Therefore, to effectively tackle large scale multi-objective optimization problems, the asymmetrical variables are incorporated into the design of a new asymmetrical variable driven simulated binary crossover operator. On the basis of the proposed asymmetrical variable driven simulated binary crossover operator, this paper further constructs a large scale multi-objective evolutionary framework based on asymmetrical variable driven simulated binary crossover operator. Extensive experiments and analyses on typical large scale multi-objective optimization problems with up to 10,000 decision variables and practical engineering problems with 6000 decision variables show its superiority over state-of-the-art optimizers.},
  archive      = {J_ASOC},
  author       = {Maoqing Zhang and Kun Wang},
  doi          = {10.1016/j.asoc.2025.113921},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113921},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Asymmetrical variable driven simulated binary crossover operator for large scale multi-objective optimization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling. <em>ASOC</em>, <em>185</em>, 113920. (<a href='https://doi.org/10.1016/j.asoc.2025.113920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agentic workflows, powered by Industrial Large Models (ILMs), represent a significant development emphasizing collaboration between humans and intelligent systems. This paper presents a structured perspective on the role of agentic workflows for smart design and manufacturing, grounded in integrating ILMs. We define an agentic workflow as a labeled Activity-on-Vertex (AOV) graph, where each node represents a functionally closed subtask and is executed by an ILM-based agent, a human operator, or an automated system. This formalism supports analyzable, modular, and hybrid execution, offering a foundation for modeling complex, mixed-initiative processes in manufacturing environments. To support real-world deployment, we introduce a set of reusable agentic workflow patterns that describe how ILM agents perceive, plan, and act in coordination with other components. Besides, a proof-of-concept case study illustrates the practical application of the human-in-the-loop framework through the agentic generation of CAD models. The study covers task decomposition, workflow implementation, and benchmarking, providing evidence for the feasibility of agentic workflows. Building upon these findings, this work contributes to advancing the development and application of agentic workflows in smart manufacturing contexts.},
  archive      = {J_ASOC},
  author       = {Keyou Zheng and Yuanwei Zhong and Xuyang Su and Jiewu Leng and Qiang Liu and Xin Chen},
  doi          = {10.1016/j.asoc.2025.113920},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fault diagnosis of railway vehicle on-board controller with large language models. <em>ASOC</em>, <em>185</em>, 113919. (<a href='https://doi.org/10.1016/j.asoc.2025.113919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying fault types of the Vehicle On-Board Controller (VOBC) in railway systems is of great significance for ensuring the safe operation of trains. Recently, Large Language Models (LLMs) have demonstrated excellent semantic understanding and natural language interaction capabilities, offering a novel solution for VOBC fault diagnosis. However, LLMs pretrained on general domains lack specific knowledge related to railway VOBC fault diagnosis scenarios, resulting in insufficient adaptability to railway-specific text corpora. This paper conducts an in-depth study on the adaptability of LLMs to VOBC fault diagnosis and proposes Railway Fault Diagnosis Large Language Model (RFD-LLM). First, we adopt railway domain adaptation based on Low-Rank Adaptation (LoRA) to match VOBC fault patterns. Second, instruction tuning is applied to achieve domain knowledge alignment and enhance the model’s ability to follow instructions. The proposed RFD-LLM is the first large language model-based fault diagnosis model for railway VOBC, capable of efficiently and accurately identifying seven types of VOBC fault patterns. RFD-LLM provides a new solution for the development of large models in the railway domain.},
  archive      = {J_ASOC},
  author       = {Cong Peng and Jiali Peng and Zisheng Wang and Zongyao Wang and Junjie Chen and Jianping Xuan and Tielin Shi},
  doi          = {10.1016/j.asoc.2025.113919},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113919},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive fault diagnosis of railway vehicle on-board controller with large language models},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An MADM model using frank operations based power aggregation operator under p,q-quasirung orthopair fuzzy sets for highway selection in war-plane landing. <em>ASOC</em>, <em>185</em>, 113918. (<a href='https://doi.org/10.1016/j.asoc.2025.113918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In military logistics and operational planning, selecting an optimal highway for war-plane landings and take-offs is a critical and strategic decision. This process involves several key factors that directly affect mission success, operational safety, and public security. Among the most important attributes are the highway’s straight and long stretch with sufficient width to accommodate war-plane landing distances, and its surface condition, which must be free from obstacles, debris, and damage. Low traffic density is crucial to avoid the risk of collisions during landing. Additionally, favourable weather conditions, proximity to military camps, availability of emergency services and fuel, and a secure and hazard-free surrounding terrain are essential for safe and efficient operations. These factors collectively form the backbone of a reliable and tactical approach to highway selection for military air operations. Thus, in order to assess and rank various options for the landing and take-off of war planes, a strong and trustworthy procedure for making decisions is required. The purpose of this experiment is to build a comprehensive structure in multi-attribute decision making environment, using suggested p , q -quasirung orthopair fuzzy Frank power averaging as well as p , q -quasirung orthopair fuzzy Frank power geometric operators to capture ambiguity and uncertainty in highway selection. Furthermore, p , q -quasirung orthopair fuzzy Frank power weighted aggregation along with p , q -quasirung orthopair fuzzy Frank power weighted geometric operators are implemented for integrating the distance as well as similarity measures. Finally, sensitivity analysis and a comparison with the present technique are included to further demonstrate the superiority and validity of the technique that is suggested.},
  archive      = {J_ASOC},
  author       = {Sanjita Giri and Sankar Kumar Roy and Muhammet Deveci},
  doi          = {10.1016/j.asoc.2025.113918},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113918},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An MADM model using frank operations based power aggregation operator under p,q-quasirung orthopair fuzzy sets for highway selection in war-plane landing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility. <em>ASOC</em>, <em>185</em>, 113917. (<a href='https://doi.org/10.1016/j.asoc.2025.113917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of metropolitan populations causes transportation network congestion, which increases fuel usage, travel time, and environmental damage. Traditional traffic management systems (TMS) seldom handle these issues in real time. Recently developed Large Language Models (LLMs), especially those using Reinforcement Learning (RL), may enhance urban transportation systems. Traffic management technology's real-time flexibility and shifting congestion patterns provide improved potential. Traditional approaches cannot estimate traffic flow or adapt to urban settings. A strong AI-driven method is needed to improve urban mobility and traffic flow. This paper introduces the LLM-RL Traffic Optimization Framework (LLM-RL-TOF). LLMs analyze real-time traffic data and give predictive insights in this context. Due to these new insights, the RL algorithm can improve traffic flow in real time and reduce congestion via dynamic traffic management. IoT sensors and urban traffic cameras capture real-time traffic data, including traffic volume and incidents. This data helps the LLM estimate bottlenecks, accidents, and traffic congestion. An RL agent uses LLM outputs to adjust traffic signal timing and suggest alternate routes. With real-time alternatives, traffic flow and urban mobility may be optimized. The junction throughput rate rose 17.5 %, the queue length accumulation index fell 22.3 %, and the average vehicle delay fell 18.6 %. The decrease in average vehicle delay enabled all these gains.},
  archive      = {J_ASOC},
  author       = {Arvind R. Singh and Muhammad Wasim Abbas Ashraf and Rajkumar Singh Rathore and Bin Li and M.S. Sujatha},
  doi          = {10.1016/j.asoc.2025.113917},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113917},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive auto-encoding for domain adaptation in evolutionary multi-task optimization. <em>ASOC</em>, <em>185</em>, 113916. (<a href='https://doi.org/10.1016/j.asoc.2025.113916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, evolutionary multi-task optimization (EMTO) has emerged as an effective paradigm for solving multiple optimization tasks simultaneously by leveraging knowledge transfer across tasks. The domain adaptation technique plays an important role in EMTO, as it helps align search spaces to support knowledge transfer among tasks. However, most existing domain adaptation methods rely on static pre-training or periodic re-matched mechanism, which do not adapt well to the dynamic change in evolving populations. In this paper, we propose a progressive auto-encoding (PAE) technique that enables continuous domain adaptation throughout the EMTO process. The PAE incorporates two complementary adaptation strategies: i) segmented PAE, which employs staged training of auto-encoders to achieve effective domain alignment across different optimization phases, and ii) smooth PAE, which utilizes eliminated solutions from the evolutionary process to facilitate more gradual and refined domain adaptation. We integrate the PAE into both single-objective and multi-objective multi-task evolutionary algorithms, yielding MTEA-PAE and MO-MTEA-PAE , respectively. Comprehensive experiments conducted on six benchmark suites and five real-world applications validate the effectiveness of our proposed PAE technique in enhancing domain adaptation capabilities within EMTO.},
  archive      = {J_ASOC},
  author       = {Qiong Gu and Yanchi Li and Wenyin Gong and Zhiyuan Yuan and Bin Ning and Chunyang Hu and Jicheng Wu},
  doi          = {10.1016/j.asoc.2025.113916},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113916},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Progressive auto-encoding for domain adaptation in evolutionary multi-task optimization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving speech emotion recognition using gated cross-modal attention and multimodal homogeneous feature discrepancy learning. <em>ASOC</em>, <em>185</em>, 113915. (<a href='https://doi.org/10.1016/j.asoc.2025.113915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition (SER) remains a significant and crucial challenge due to the complex and multifaceted nature of human emotions. To tackle this challenge, researchers strive to integrate information from diverse modalities through multimodal learning. However, existing multimodal fusion techniques often overlook the intricacies of interactions between different modalities, resulting in suboptimal feature representations. In this paper, we propose WavFusion, a multimodal framework designed for SER that tackles key research challenges, such as effective multimodal fusion, modality heterogeneity, and discriminative representation learning. By utilizing a gated cross-modal attention mechanism and multimodal homogeneous feature discrepancy learning, WavFusion outperforms existing state-of-the-art methods on benchmark datasets. Our research highlights the importance of capturing subtle cross-modal interactions and learning discriminative representations for accurate multimodal SER. Experimental results indicate that the proposed method is highly competitive and better than most of the latest state-of-the-art methods for SER. WavFusion achieves 0.78 % and 1.27 % improvement in accuracy and 0.74 % and 0.44 % improvement in weighted F1 score over the previous methods on the IEMOCAP and MELD datasets, respectively.},
  archive      = {J_ASOC},
  author       = {Feng Li and Jiusong Luo and Wanjun Xia},
  doi          = {10.1016/j.asoc.2025.113915},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113915},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving speech emotion recognition using gated cross-modal attention and multimodal homogeneous feature discrepancy learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind turbine blades defect detection based on global and local attention with multi-feature fusion. <em>ASOC</em>, <em>185</em>, 113914. (<a href='https://doi.org/10.1016/j.asoc.2025.113914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbine blades are prone to small-scale defects—such as cracks, corrosion, and contamination—during long-term operation. Accurate detection of these defects is essential for ensuring the safety and efficiency of wind power systems. However, small-object detection remains challenging due to limited feature representation and weak discriminative cues. To address this, an enhanced YOLOX-s-based framework called Global-Frequency Dual-aware YOLOX (GFD-YOLOX) is proposed. GFD-YOLOX introduces three main improvements. First, the Path Aggregation Feature Pyramid Network (PAFPN) in the neck is replaced with Dual-Frequency Fused Bidirectional Feature Pyramid Network (DFF-BiFPN) to strengthen multi-scale contextual representation. Second, the backbone bottleneck is redesigned with a lightweight structure, improving computational efficiency and convergence speed. Third, a Hierarchical Frequency-Adaptive Fusion (HFAF) module is integrated to enhance cross-scale feature interaction by combining fine-grained and global information. On the self-constructed WTBlade-Defect dataset (3570 annotated images, five defect types: corrosion, hide-craze, surface-eye, thunderstrike, dirt), GFD-YOLOX achieves mAP@0.5 and mAP@0.5:0.95 scores of 94.5 % and 68.9 %, respectively, with 44.3 FPS inference—improving by 13.6 % and 14.4 % over state-of-the-art models. On the public dataset of Ashley Foster et al., it achieves 94.8 % and 69.3 %, with gains of 10.4 % and 10.9 %. These results demonstrate that GFD-YOLOX delivers substantial accuracy gains while maintaining real-time speed and strong cross-dataset generalization, indicating high potential for deployment in operational wind turbine inspection systems.},
  archive      = {J_ASOC},
  author       = {Dandan Liu and Mingjie Liu},
  doi          = {10.1016/j.asoc.2025.113914},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113914},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind turbine blades defect detection based on global and local attention with multi-feature fusion},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous feature selection with group structure mining in fuzzy decision systems for medical diagnosis. <em>ASOC</em>, <em>185</em>, 113913. (<a href='https://doi.org/10.1016/j.asoc.2025.113913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications such as medical diagnosis and group decision making, the potential structural information contained in multi-dimensional features in the form of group domains plays an important role. However, most existing feature selection methods adopt transformed feature spaces for group structure analysis, which lack intrinsic semantic information interpretation. Meanwhile, fuzzy and uncertain heterogeneous data acquired from multiple devices increase the difficulty of task learning. Motivated by these two issues, this work devises a Heterogeneous Feature Selection method with Group Structure Mining in fuzzy decision systems (HFS-GSM), which follows the principle of one “strategy" and one “mechanism". Specifically, a feature group generation strategy based on fuzzy approximation Markov blanket is first designed for mining features with group structure, which introduces the concept of Markov blanket into the fuzzy rough set and utilizes the idea of approximation and fuzzy uncertainty measures. Then, a fuzzy dependency-based overlapping group elimination mechanism is proposed by attribution division, which avoids local redundancy while preserving global discriminative information. Furthermore, the effectiveness of HFS-GSM is verified in comparison with seven representative feature selection methods on publicly available medical datasets. Finally, medical diagnosis data provided by a hospital are obtained to demonstrate the reliability and utility of HFS-GSM in practical applications.},
  archive      = {J_ASOC},
  author       = {Jihong Wan and Hongmei Chen and Li Xiao and Chuangpeng Shen and Wei Huang and Xiaoping Li},
  doi          = {10.1016/j.asoc.2025.113913},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113913},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Heterogeneous feature selection with group structure mining in fuzzy decision systems for medical diagnosis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ahybrid ICEEMDAN-BO-GRU model for real-time grouting parameter prediction. <em>ASOC</em>, <em>185</em>, 113912. (<a href='https://doi.org/10.1016/j.asoc.2025.113912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unit injection volume is one of the core control indicators for evaluating the construction quality of curtain grouting. In actual construction processes, accurate prediction of unit injection volume enables early warning of abnormal conditions during construction. However, geological conditions and construction parameters significantly influence unit injection volume, among other factors, and the data exhibits high nonlinearity. Previous studies have achieved suboptimal prediction accuracy. To address the issue of low prediction accuracy in traditional algorithms when handling highly nonlinear data, this study first applies the Improved Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN) algorithm to decompose the raw data, and the nonlinear features in the curtain grouting data are effectively eliminated. Subsequently, the Gated Recurrent Unit (GRU) and Bayesian Optimization (BO) algorithms are organically integrated, and Bayesian optimization is applied to the hyperparameters of the GRU model to enhance its predictive performance, thereby constructing an intelligent predictive model for the curtain grouting unit injection volume. Finally, an engineering application study was conducted using an actual curtain grouting project at a pumped-storage power station. The results indicate that the model exhibits good computational accuracy and efficiency, providing theoretical and methodological support for constructing intelligent prediction models in curtain grouting.},
  archive      = {J_ASOC},
  author       = {Fei Tong and Dongqing Bai and Xufei Ma and Lin Cheng and Jie Yang and Xiangyu Cao},
  doi          = {10.1016/j.asoc.2025.113912},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113912},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ahybrid ICEEMDAN-BO-GRU model for real-time grouting parameter prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DefGCL: Defence-enhanced graph contrastive learning against attribute inference attacks. <em>ASOC</em>, <em>185</em>, 113911. (<a href='https://doi.org/10.1016/j.asoc.2025.113911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-structured data are prevalent in many real-world applications, such as social networks, drug discovery, and fraud detection. While Graph Neural Networks (GNNs) have shown remarkable performance by capturing rich relational patterns, their success often relies on large labeled datasets and raises growing privacy concerns. Graph Contrastive Learning (GCL) has emerged as a powerful unsupervised alternative by leveraging data augmentations to learn robust representations without labeled data. However, recent studies reveal that GCL models are particularly vulnerable to attribute inference attacks, and existing works prioritize performance improvement over privacy protection. To address this issue, we propose a D e f ense-enhanced G raph C ontrastive L earning, dubbed DefGCL , that integrates four coordinated defense strategies to enhance privacy without degrading utility. Specifically, DefGCL employs edge-based graph augmentations to limit exposure to structural attributes, selects negative samples with low attribute sensitivity scores to reduce leakage, modifies the contrastive loss to decouple graph embeddings from attributes, and injects differential privacy noise during the embedding stage. Extensive experiments on five benchmark datasets demonstrate that DefGCL achieves state-of-the-art (SOTA) performance in both privacy preservation and task accuracy. For instance, on the AIDS dataset, DefGCL reduces attribute inference accuracy by 35 % while incurring only a 0.60 % drop in main task performance. Additionally, DefGCL improves computational efficiency by reducing runtime by nearly 50 % compared to baseline methods. 1},
  archive      = {J_ASOC},
  author       = {Jinyin Chen and Fanyu Ao and Wenbo Mu and Haiyang Xiong},
  doi          = {10.1016/j.asoc.2025.113911},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113911},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DefGCL: Defence-enhanced graph contrastive learning against attribute inference attacks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction. <em>ASOC</em>, <em>185</em>, 113910. (<a href='https://doi.org/10.1016/j.asoc.2025.113910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable wind speed prediction is critical for stabilizing wind power integration. However, current methods are limited by accuracy and stability issues, hindering their large-scale application in wind farms. To overcome these problems, this study innovatively proposes an IMFSformer-CNN model integrating three core components. First, the spatio-temporal and multi-factor feature extraction technology comprehensively captures the spatio-temporal patterns and complex dependencies of wind speed dynamics, incorporating multiple factors such as meteorological variables and spatial correlation. Second, the multi-feature sparse attention mechanism reduces computational complexity by combining sparse attention with multi-feature attention, enhancing representation ability and scalability for precise interval value prediction. Finally, the enhanced interval spatio-temporal prediction fusion model combines the global dependency modeling capabilities of the improved Transformer architecture with the local receptive field advantages of CNN. This hybrid design facilitates the simultaneous capture of both macro-scale atmospheric patterns and micro-scale wind speed fluctuations. The model achieved prediction interval coverage probabilities of 0.921 and 0.899, and coverage width criteria of 1.493 and 3.776, outperforming other models on both datasets. This significantly enhances accuracy and practical value for wind farm cluster forecasting, supporting more reliable and efficient wind energy integration into power grids.},
  archive      = {J_ASOC},
  author       = {Weiyi Jiang and Jujie Wang and Xuecheng He},
  doi          = {10.1016/j.asoc.2025.113910},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction. <em>ASOC</em>, <em>185</em>, 113909. (<a href='https://doi.org/10.1016/j.asoc.2025.113909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction has significant application value in many fields. However, existing methods often fail to fully capture the spatial relationships between joints and the temporal flow of information when modeling complex spatiotemporal dependencies. Additionally, these methods are prone to overfitting dominant features while neglecting other important aspects, and struggle with perceiving contour features effectively. To address these issues, this study introduces a novel encoder-decoder framework. The encoder generates a dual-layer adaptive adjacency matrix using a distance partition strategy to parameterize joint relationships, while incorporating a gating mechanism to control the temporal flow of information. The decoder then employs separate spatiotemporal attention modules to decode temporal and spatial features independently. These features are subsequently reconstructed through a spatiotemporal fusion strategy, effectively decoupling and modeling complex spatiotemporal dependencies. To address the issue of overfitting to dominant features, we introduce a denoising reconstruction strategy that allows the model to learn richer combinations of spatiotemporal features under multiple constraints. Furthermore, a multi-granularity information adaptive fusion module is incorporated to achieve adaptive fusion of both local and contour features. Experimental results across several benchmark datasets demonstrate that our method significantly outperforms the state-of-the-art approaches, showcasing its effectiveness in human motion prediction tasks.},
  archive      = {J_ASOC},
  author       = {Yong Li and Linfeng Zhu and Haofei Xie and Xinchang Yi},
  doi          = {10.1016/j.asoc.2025.113909},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113909},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFNN: Fractional order basis function multi-step neural network method for fractional partial differential equations. <em>ASOC</em>, <em>185</em>, 113907. (<a href='https://doi.org/10.1016/j.asoc.2025.113907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement in artificial intelligence technology, the increasing number of researchers utilize it to address complex equations in ocean engineering. So the technology of artificial intelligence has become a practical area of research. In this paper, we design a novel method to solve the fractional order long water wave equation, which is called the fractional order basis function multi-step neural network. Firstly, a power series is constructed based on a fractional order basis function, which serves as the approximate solution. Secondly, neural networks and the initial conditions of differential equations are integrated into the construction of approximate solutions. Furthermore, the solution is discretized, and a multi-step unfolding strategy is employed on the resulting discrete solution. This approach ensures that each point in the solution is influenced by its predecessor. By means of repeated applications of the optimization algorithm, the residuals are successively diminished, thereby yielding approximate solutions to the equations. Finally, the efficacy and versatility of the proposed strategy were validated through a series of numerical experiments. Compared with the method of fractional physics-informed neural networks, there are up to 18.7 -fold and 22.8 -fold increases in stability of average and maximum residuals. Simultaneously, initial conditions are retained in new solutions.},
  archive      = {J_ASOC},
  author       = {Jianke Zhang and Xudong Tian and Chang Zhou},
  doi          = {10.1016/j.asoc.2025.113907},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113907},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FFNN: Fractional order basis function multi-step neural network method for fractional partial differential equations},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCSMOTE: A transition matrix-driven oversampling technique for class imbalance. <em>ASOC</em>, <em>185</em>, 113906. (<a href='https://doi.org/10.1016/j.asoc.2025.113906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance presents a challenge in machine learning, often skewing predictive performance toward the majority class and undermining the accuracy of minority class predictions. To address this, we introduce MCSMOTE, a novel resampling method that employs a transition matrix-based Monte Carlo mechanism for generating synthetic samples. MCSMOTE differentiates itself by modeling the relationships among features and leveraging probabilistic transitions to generate synthetic data points that effectively capture the underlying data structure. This approach ensures enhanced representativeness of the minority class while approximating the local structure of the minority class and thereby generating samples that reflect the underlying data patterns. Comprehensive experiments across 63 diverse imbalanced datasets demonstrate that MCSMOTE consistently outperforms nine widely used resampling techniques—NORES, ROS, SMOTE, ADASYN, BLSMOTE, RWO, SMOTEWB, DeepSMOTE, RWO, and GQEO—when evaluated using multiple classifiers and six key performance metrics: balanced accuracy, F1-score, G-mean, MCC, ROCAUC, and ROCAUC. Results show that MCSMOTE achieves the highest average performance across all metrics. Friedman and Nemenyi tests confirm that these improvements are statistically significant. An ablation study further highlights the stability and effectiveness of MCSMOTE’s hyperparameter choices across different data characteristics. These findings establish MCSMOTE as a powerful and reliable solution for addressing class imbalance in machine learning applications.},
  archive      = {J_ASOC},
  author       = {Fatih Sağlam and Mehmet Ali Cengiz},
  doi          = {10.1016/j.asoc.2025.113906},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113906},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MCSMOTE: A transition matrix-driven oversampling technique for class imbalance},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limited-budget consensus with maximum consensus level for group decision making. <em>ASOC</em>, <em>185</em>, 113905. (<a href='https://doi.org/10.1016/j.asoc.2025.113905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group decision making usually requires in-depth discussions to form a consensus acceptable to the entire group, which has attracted more and more research in recent years. Despite extensive studies on soft consensus, the relationship between consensus level and consensus cost remains unclear. This study establishes—for the first time—a precise mathematical relationship demonstrating that higher consensus levels require proportionally greater consensus costs. This finding provides critical theoretical grounding for consensus modeling. Recognizing that the cost of achieving consensus cannot be infinite and must be within a certain budget, we develop a model to determine the maximum achievable consensus level under a limited-budget. The consensus model with non-cooperators is also explored and formulated. The proposed models are applied to online lending platforms, providing a practical framework for measuring consensus levels and achieving soft consensus between lenders and borrowers within a limited-budget. This work contributes to understanding the relationship between consensus level and consensus cost, as well as the achievement of the maximum possible consensus level under limited-budget, which is relevant in scenarios where resources are finite.},
  archive      = {J_ASOC},
  author       = {Huanhuan Zhang and Dongjie Guo and Yifeng Ma},
  doi          = {10.1016/j.asoc.2025.113905},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113905},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Limited-budget consensus with maximum consensus level for group decision making},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrimination index based attribute reduction for partially labeled heterogeneous data via a new prediction label strategy and statistical distribution of data. <em>ASOC</em>, <em>185</em>, 113904. (<a href='https://doi.org/10.1016/j.asoc.2025.113904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods often struggle to effectively utilize the statistical distribution of data and unlabeled information when dealing with partially labeled heterogeneous data, leading to limited performance in attribute reduction. To address this issue, this paper presents a novel semi-supervised attribute reduction method that integrates statistical distribution of data, conditional discrimination index and a new prediction label strategy. Initially, the similarity between objects is constructed by analyzing the statistical distribution of data. Subsequently, a new prediction label strategy is introduced, which not only utilizes existing label information but also completes missing information by predicting new labels, thereby enhancing the completeness and usability of data. Finally, conditional discrimination index, a tool for measuring the importance of attributes in classification tasks, is employed to design an attribute reduction algorithm. The experimental results on real-world partially labeled heterogeneous datasets show that the proposed p-CDIAR algorithm exhibits superior performance compared to the existing nine reduction algorithms, with an average increase of 4.67 % in classification accuracy and 6.32 % in outlier detection performance.},
  archive      = {J_ASOC},
  author       = {Qingnian Li and Haixin Huang and Tao Lu and Huaming Wei and Zhaowen Li},
  doi          = {10.1016/j.asoc.2025.113904},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113904},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Discrimination index based attribute reduction for partially labeled heterogeneous data via a new prediction label strategy and statistical distribution of data},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An unsupervised framework for drift-aware anomaly detection in streaming time series. <em>ASOC</em>, <em>185</em>, 113903. (<a href='https://doi.org/10.1016/j.asoc.2025.113903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an unsupervised adaptive drift-aware anomaly detection framework (ADA-ADF) designed to address the challenges of concept drift in time series data streams. ADA-ADF integrates a hybrid drift detection mechanism, combining statistical tests with performance-based metrics to accurately identify and distinguish between sudden and incremental drifts. To ensure effective adaptation, it employs a replay-based model update strategy that adjusts replay ratios in a drift-specific manner and incorporates representative historical data based on reconstruction errors. This approach allows the model to seamlessly adapt to evolving data distributions while maintaining high stability and accuracy. Extensive experiments on four diverse datasets demonstrate ADA-ADF’s superior performance in managing various drift and application scenarios. It consistently outperforms state-of-the-art methods, particularly in environments characterized by incremental or sudden drifts. With robust adaptability to changing data patterns and accurate anomaly detection capabilities, ADA-ADF provides a reliable solution for real-world applications, such as IoT and environmental monitoring.},
  archive      = {J_ASOC},
  author       = {Danlei Li and Nirmal-Kumar C. Nair and Kevin I-Kai Wang},
  doi          = {10.1016/j.asoc.2025.113903},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113903},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An unsupervised framework for drift-aware anomaly detection in streaming time series},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A MADM framework for classifying wireless sensor networks in industrial automation and monitoring using hesitant bipolar complex fuzzy dombi power operators. <em>ASOC</em>, <em>185</em>, 113902. (<a href='https://doi.org/10.1016/j.asoc.2025.113902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) are essential for industrial automation and monitoring because they eliminate the need for wires by enabling real-time data collection, processing, and transmission. They are highly effective for a wide range of applications, from optimizing industrial processes to monitoring machinery and environmental conditions. Using standard methods for evaluating WSNs is insufficient to identify many of the features that are important for making decisions. However, a major flaw in the existing approaches is their inability to simultaneously consider the negative features and extra information associated with attributes. There may be a greater chance of significant information loss as a result. Keeping in mind all those flaws, this manuscript has formulated a new methodology for the evaluation of the best WSNs classification. The hesitant bipolar complex fuzzy (HBCF) Dombi power approach is probably different from all other existing approaches because of its different affordable characteristics of hesitancy nature with dual aspects and saving extra information without any loss. Moreover, this novel approach can easily manage the bipolar nature of any information. Also, in this manuscript, a case study focused on WSNs has been examined. The comparative analysis and results are also discussed, which demonstrate the superiority and effectiveness of the proposed work.},
  archive      = {J_ASOC},
  author       = {Tahir Mahmood and Hafiz Muhammad Waqas and Ubaid ur Rehman},
  doi          = {10.1016/j.asoc.2025.113902},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113902},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A MADM framework for classifying wireless sensor networks in industrial automation and monitoring using hesitant bipolar complex fuzzy dombi power operators},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended belief rule-based system with online joint learning strategy. <em>ASOC</em>, <em>185</em>, 113901. (<a href='https://doi.org/10.1016/j.asoc.2025.113901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of dynamic data streams in the advanced technology environment, it is necessary to solve the evolving classification problems by using adaptable and interpretable artificial intelligence techniques. To meet this challenge, a new extended belief rule-based (EBRB) system incorporating online joint learning strategy is proposed in this paper. The online joint learning strategy comprises two key components: rule update and parameter update schemes. In the rule update scheme, different rule incorporation processes are designed for the labeled or unlabeled input data while overlapping and redundant rules are removed from the rule base. To adapt the updated rule base, the parameter update scheme is designed to retune the parameters within updated rule base. The antecedent attribute weights are optimized using the Bayesian optimization algorithm and the rule weights are updated based on the consistency of rules. To evaluate the performance of the developed system, it is applied to assist radiologists in diagnosing thyroid nodules. Compared with the existing offline EBRB systems and online learning methods, the proposed online joint learning EBRB system could generate higher classification accuracy with fewer rules in the limited running time.},
  archive      = {J_ASOC},
  author       = {Bingbing Hou and Min Xue and Leilei Chang and Zijian Wu},
  doi          = {10.1016/j.asoc.2025.113901},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113901},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Extended belief rule-based system with online joint learning strategy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A collaborative competition multitasking framework for constrained multi-objective optimization. <em>ASOC</em>, <em>185</em>, 113900. (<a href='https://doi.org/10.1016/j.asoc.2025.113900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) are common in the real world. Constrained multi-objective evolutionary algorithms (CMOEAs) based on evolutionary multi-tasking show excellent performance in solving CMOPs. However, not all tasks can find useful information during the process of evolution, which inevitably results in a waste of computing resources. In this paper, a CMOEA based on collaborative competition multitasking (TCCMT) is proposed, in which two auxiliary tasks are constructed to co-evolve with the main task in a collaborative competition manner. During the process of evolution, only the dominant auxiliary task is selected to help the main task evolve, which reduces the resource consumption to evolve the invalid tasks. Meanwhile, the evolutionary process is divided into three stages in order to balance exploration and exploitation. The auxiliary tasks customize the constrained adaptive regression strategy and double angle enhancement strategy respectively to improve the ability to solve different problems. Compared with the nine most advanced CMOEAs on 33 benchmark problems and 7 real-world engineering problems, the Friedman test results show that TCCMT achieves the best rank on all test problems and exhibits a statistically significant difference.},
  archive      = {J_ASOC},
  author       = {Xinyu Feng and Qianlong Dang and Xiaochuan Gao and Yanghui Wu and Lifei Zheng},
  doi          = {10.1016/j.asoc.2025.113900},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113900},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A collaborative competition multitasking framework for constrained multi-objective optimization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A Q-learning based genetic algorithm for collaborative optimization of import container allocation and yard crane deployment in container terminal. <em>ASOC</em>, <em>185</em>, 113899. (<a href='https://doi.org/10.1016/j.asoc.2025.113899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of truck appointment systems in container terminals has led to a greater focus on optimizing terminal operations using appointment information. Container allocation and yard crane deployment problems are the primary issues of yard management that are influenced by truck appointment information. This paper investigates the impact of appointment information on yard operation management, specifically focusing on the container allocation for import tasks and optimizing the deployment of yard cranes based on the workload. A collaborative optimization model is proposed to minimize the workload imbalance across blocks. This model considers the impact of truck appointment information, allocating storage space and storage numbers for import tasks, as well as the minimum number of transfers to arrange yard cranes. Due to the complexity of the model, a self-learning genetic algorithm utilizing Q-learning is designed to solve the proposed model. A comparison was made between the optimization model that takes truck appointments into account and the traditional one which did not. The results indicate that the workload imbalance can be decreased by a minimum of 22.06 % when considering information on the truck appointments. The experimental results demonstrate that the proposed approach successfully reduces workload imbalance among blocks and mitigates the negative effects caused by yard congestion.},
  archive      = {J_ASOC},
  author       = {CuiJie Diao and Ying Huang and KangZhen Peng and ZhiHong Jin},
  doi          = {10.1016/j.asoc.2025.113899},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113899},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A Q-learning based genetic algorithm for collaborative optimization of import container allocation and yard crane deployment in container terminal},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing local density and approximate distance for nonparametric outlier detection. <em>ASOC</em>, <em>185</em>, 113898. (<a href='https://doi.org/10.1016/j.asoc.2025.113898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is an essential yet challenging task in intelligent data analysis, and some density-based unsupervised methods have been introduced to identify outliers in low-density regions. However, these methods still suffer from inaccurate density estimation and limited capability in detecting diverse types of outliers. In this study, we propose a nonparametric outlier detection method with the fusion of density and distance (POD-FDD). The proposed method employs adaptive kernel density estimation based on natural neighborhoods, which reduces the sensitivity to parameters in density estimation. Moreover, the optimistic and pessimistic densities are introduced to enhance the reliability of density estimation in the local neighborhood. In addition, approximate reachability distance information is integrated to improve the capability of identifying cluster outliers. Ultimately, a robust parametric-free outlier detection method is developed to detect different types of outliers. Extensive comparative experiments and statistical significance analysis on synthetic and public datasets demonstrate its superior performance, achieving an average improvement of 1.97 % in the AUC metric.},
  archive      = {J_ASOC},
  author       = {Zhiyu Chen and Can Gao and Jie Zhou and Ying Yu},
  doi          = {10.1016/j.asoc.2025.113898},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113898},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fusing local density and approximate distance for nonparametric outlier detection},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model. <em>ASOC</em>, <em>185</em>, 113897. (<a href='https://doi.org/10.1016/j.asoc.2025.113897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, extreme events caused by global climate change have intensified the phenomenon of saltwater intrusion (SWI) in estuaries. The nonlinear and non-stationary characteristics of estuarine SWI have led to an exponential decline in the timeliness of traditional regression prediction models, making it difficult to meet the operational needs of SWI forecasting. To address this, this study proposed a technical framework for SWI risk level forecasting based on temporal clustering, with its core innovation lying in algorithmic improvements for accurately characterizing complex disaster systems. The key challenges in forecasting SWI risk levels involved capturing the dynamic nonlinear relationships between multidimensional disaster factors (such as runoff, tide level, and wind) and SWI severity, as well as enhancing feature discriminability in label-limited scenarios. Accordingly, this study optimized algorithms through dual-path supervised and unsupervised learning: In the supervised learning framework, LightGBM, RF, XGBoost, and Extra trees were introduced as base learners into the Deep Forest (DF) model. The complementary feature-space partitioning of diverse learners was leveraged to improve the model’s ability to distinguish risk -level boundaries, achieving an average performance gain of 7.8 %. In the unsupervised learning framework, discriminative regularization was incorporated into the Extreme Learning Machine-Autoencoder (ELM-AE) model. By forcing features of samples from the same class to cluster toward the class center, the model’s feature separability for rare events (e.g., severe SWI) was enhanced, leading to an average performance improvement of 11 %. Finally, the optimal model was used to extract dynamic evolution patterns between multidimensional disaster factors and SWI risk levels, with interpretability analysis conducted for real-world forecasting. Notably, upstream flow sequences exhibited high distinguishability between no-SWI and severe-SWI, while mild and moderate SWI showed similar flow patterns, with tidal sequences being the primary differentiator. The algorithmic advancements not only enhanced the accuracy and efficiency of SWI forecasting but also provided a generalizable framework for risk classification in nonlinear hydrological systems.},
  archive      = {J_ASOC},
  author       = {Qingqing Tian and Hongyu Yang and Yu Tian and Peiyao Weng},
  doi          = {10.1016/j.asoc.2025.113897},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113897},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with mirror-task for multimodal sentiment analysis. <em>ASOC</em>, <em>185</em>, 113896. (<a href='https://doi.org/10.1016/j.asoc.2025.113896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning (MTL) in Multimodal Sentiment Analysis (MSA) involves implementing various parameter-sharing strategies among tasks. Currently, MSA primarily focuses on hard parameter-sharing mechanisms based on encoder sharing, while soft parameter-sharing is often neglected. To explore a reasonable combination of soft and hard mechanisms in MSA and optimize multimodal representations, along with multimodal contrastive learning, we propose D 3 MSA. It consists of D ouble network (primaryNet and MirrorNet), D ouble parameter-sharing strategies and D ouble contrastive learning modes for multimodal sentiment analysis. D 3 MSA utilizes hard-sharing to consolidate correlations between positive samples of intra-sample contrastive learning. In soft-sharing, we propose a pre-trained MirrorNet (MN) that generates negative samples by the learned inverse distributions. This optimizes the feature space of negative samples. MN interacts with the MSA task through soft-sharing during inter-sample contrastive learning. Experimental results demonstrate that our proposed method can achieve advanced performance on the CMU-MOSI and CMU-MOSEI datasets with lightweight training that requires only a small number of parameters.},
  archive      = {J_ASOC},
  author       = {Hang Shi and Lianmin Zhou and Yuanyuan Pu and Zhengpeng Zhao and Jinjing Gu and Dan Xu},
  doi          = {10.1016/j.asoc.2025.113896},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113896},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning with mirror-task for multimodal sentiment analysis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems. <em>ASOC</em>, <em>185</em>, 113895. (<a href='https://doi.org/10.1016/j.asoc.2025.113895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multimodal multiobjective problems (CMMOPs) have multiple equivalent constrained Pareto optimal sets in the decision space corresponding to the identical constrained Pareto front in the objective space. The key to solving CMMOPs is how to balance feasibility, convergence, and diversity of solutions in both the decision and objective spaces. In view of this, this paper proposes a Nearest-Best neighbors optimization algorithm with constraint-based fitness (NBNOA) to solve CMMOPs. First, a constraint-based fitness assignment scheme is designed to assign specific fitness values to individuals in the population. Then, the Nearest-better-neighbor clustering method is adopted to identify the nearest-better neighbor and best neighbor of each individual according to the specific fitness values. On this basis, a Nearest-Best neighbors guided strategy is developed to guide the search direction of individuals, striking a better balance between exploration and exploitation capabilities. Moreover, a CDP-density elite selection mechanism is constructed to obtain feasible Pareto optimal solutions with higher precision and better diversity. Extensive experiments on two CMMOPs test suites demonstrated that the proposed NBNOA significantly outperforms nine state-of-the-art algorithms. Notably, NBNOA ranks first among all ten algorithms and achieves the best values for 23 out of 31 benchmark functions regarding the reciprocal of Pareto sets proximity and inverted generational distance. Furthermore, NBNOA is applied to a real-world CMMOP, verifying its effective practical application capability. Additionally, NBNOA is tested on two high-dimensional constrained multiobjective optimization problems test suites, further proving its competitive performance in solving complex problems.},
  archive      = {J_ASOC},
  author       = {Xuming Han and Ting Zhou and Limin Wang and Yali Chu},
  doi          = {10.1016/j.asoc.2025.113895},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113895},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathology characteristics-aware federated learning for weakly supervised nuclei segmentation. <em>ASOC</em>, <em>185</em>, 113894. (<a href='https://doi.org/10.1016/j.asoc.2025.113894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, a key challenge in nuclei segmentation lies in data heterogeneity, primarily resulting from the diverse sources of pathology images. Nuclei in pathological images are typically small and densely distributed, making accurate annotation highly labor-intensive and reliant on specialized expertise. Weakly supervised learning is widely adopted for this task, as it only requires point annotations at the centers of nuclei. However, point annotations lack precise boundary information, thereby exacerbating the difficulties introduced by data heterogeneity. To address this issue, we propose a preprocessing strategy that leverages the unique optical properties of H&E stained images to generate Contrast-Difference Enhanced Images (CDEI). These CDEI highlight nucleus boundaries to varying extents based on the tonal characteristics of H&E stained images. Building on this strategy, we propose a Multi-source Hierarchical Enhancement Network (MHEN) as the client-side architecture. MHEN takes both the H&E stained images and the corresponding CDEI as input, effectively mitigating the limitations of weak labels by incorporating enhanced boundary cues. Furthermore, considering the characteristics of nuclei segmentation, we design a Federated Nuclei-Weighted Aggregation strategy on the server side. This strategy estimates each client’s contribution to the global model by quantifying the number of nuclei present in its local pathology images. To thoroughly assess the effectiveness of our approach, we compare it with both conventional weakly supervised methods and existing federated weak supervision frameworks. The experimental results demonstrate that our proposed federated learning framework for weakly supervised nuclei segmentation significantly outperforms existing methods. Our source code is available on GitHub. 1},
  archive      = {J_ASOC},
  author       = {Yi Qian and Xipeng Pan and Yimin Wen and Xinjun Bian and Shilong Song},
  doi          = {10.1016/j.asoc.2025.113894},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113894},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pathology characteristics-aware federated learning for weakly supervised nuclei segmentation},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency decomposition and patch modeling framework for time-series forecasting. <em>ASOC</em>, <em>185</em>, 113890. (<a href='https://doi.org/10.1016/j.asoc.2025.113890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is widely applied across diverse fields, including finance, transportation, and energy, and has made significant contributions in these areas. However, in real-world applications, time series data can be complex and dynamic. Current methodologies still encounter several challenges in managing high-dimensional data, extracting intricate features, and making long-term forecasts. In this study, we propose a Frequency Decomposition and Patch Modeling Framework (FPF). Our FPF consists of the Frequency Domain Decomposition Block (FDB) and the Dual Patch Modeling Block (DPMB). DPMB consists of Patch Enhancement Block and Patch Mixing Block. First, FDB transforms the input sequence to the frequency domain through the Fast Fourier Transform and designs frequency masks to decompose the data into high-frequency and low-frequency components, to extract fast-changing patterns and trend information respectively. Subsequently, DPMB divides the components into patches, where the high-frequency components are modeled by MLP-based Patch Enhancement Block to capture local features, and the low-frequency components are modeled by Transformer-based Patch Mixing Block to capture global dependencies and cross-patch correlations. We conducted comprehensive experiments using seven real-world time series forecasting datasets, including ETT, Traffic, Electricity, and Weather. The findings indicate that this method demonstrates superior performance in the field of time series forecasting.},
  archive      = {J_ASOC},
  author       = {Denghui Xu and Hua Wang and Fan Zhang},
  doi          = {10.1016/j.asoc.2025.113890},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113890},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Frequency decomposition and patch modeling framework for time-series forecasting},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OdML: An optimization-driven meta-learning framework for multi-task approximate model predictive control. <em>ASOC</em>, <em>185</em>, 113882. (<a href='https://doi.org/10.1016/j.asoc.2025.113882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in approximate model predictive control (MPC) have leveraged deep neural networks (DNNs) to imitate optimal control laws, significantly reducing the computational cost of real-time optimization. However, these methods often struggle to adapt efficiently to previously unseen system dynamics and suffer from poor data efficiency in real time. In this paper, we address these challenges by treating control problems with different system parameters as separate tasks within a meta-learning scope. Under this scope, we propose OdML, an Optimization-driven Meta-Learning approach for approximate MPC that enables rapid online fine-tuning of DNN-based controllers. We introduce an optimization-driven fine-tuning mechanism that allows for fast adaptation to new tasks using limited online data, without requiring full knowledge of the system parameters. Furthermore, to ensure safety during adaptation, we incorporate control barrier functions into the optimization process, allowing the controller to satisfy safety constraints even under previously unseen conditions. We demonstrate the effectiveness of OdML through various simulation scenarios, highlighting its ability to achieve safe and efficient control.},
  archive      = {J_ASOC},
  author       = {Junbo Tong and Shuhan Du and Daming Shi and Wenhui Fan},
  doi          = {10.1016/j.asoc.2025.113882},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113882},
  shortjournal = {Appl. Soft. Comput.},
  title        = {OdML: An optimization-driven meta-learning framework for multi-task approximate model predictive control},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning trader without offline training. <em>ASOC</em>, <em>185</em>, 113881. (<a href='https://doi.org/10.1016/j.asoc.2025.113881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we pursue the question of a fully online trading algorithm (i.e. one that does not need offline training on previously gathered data). For this task we consider Double Deep Q -learning in the episodic setting with Fast Learning Networks approximating the expected reward Q . Additionally, we define the possible terminal states of an episode in such a way as to introduce a mechanism to conserve some of the money in the trading pool when market conditions are seen as unfavourable. Some of these money are taken as profit and some are reused at a later time according to certain criteria. After describing the algorithm, we test it using 1-minute-tick price data for 4 major cryptocurrencies from Binance. We see that the agent performs better than trading with randomly chosen actions on each timestep. And it does so when tested on the whole dataset for a given market as well as on different subsets, representing different market trends.},
  archive      = {J_ASOC},
  author       = {Boian Lazov},
  doi          = {10.1016/j.asoc.2025.113881},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113881},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep reinforcement learning trader without offline training},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering algorithm based on boundary elimination and backbone construction. <em>ASOC</em>, <em>185</em>, 113880. (<a href='https://doi.org/10.1016/j.asoc.2025.113880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) is an effective clustering algorithm, but it still has some problems and faces some challenges. For instance, it cannot identify the variable density datasets, the assignment strategy is easy to produce domino phenomenon, and the clustering results of DPC and its improved algorithms are easily affected by the intersection points between clusters. To solve these problems, in this paper, we propose a novel density peak clustering algorithm based on boundary elimination and backbone construction, called BEBC-DPC. A new local density is defined based on the natural neighbor search, and the boundary degree is defined by the position relationship between each point and its neighbors, which accurately describes the local distribution information of the point. The boundary points of clusters are eliminated by fusing the density and the boundary degree, which reduces the influence of the intersection points on the cluster division. In addition, the cluster backbone construction method based on representative points and representative sets is proposed. The density relationship among non-boundary points is used to form representative sets, and the similarity between representative sets is used to construct the cluster backbones, which can effectively describe the overall distribution structure characteristics of the clusters. Moreover, the adjacency degree of each boundary point is defined by using the neighbor information and distance information, and the boundary points are gradually assigned to the most appropriate cluster backbone based on it to complete the clustering. Finally, sufficient experiments are performed on synthetic, UCI and image datasets, and the proposed BEBC-DPC is compared with DPC and its improved algorithms. Experimental results show the effectiveness of the proposed BEBC-DPC on various types of datasets.},
  archive      = {J_ASOC},
  author       = {Zhizhong Zhao and Sugen Chen and Cong Hu},
  doi          = {10.1016/j.asoc.2025.113880},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Density peak clustering algorithm based on boundary elimination and backbone construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria decision analysis-based framework for supply chain management evaluation with multi-dimensional sensitivity analysis: A green logistics perspective. <em>ASOC</em>, <em>185</em>, 113879. (<a href='https://doi.org/10.1016/j.asoc.2025.113879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transition toward sustainable Supply Chain Management (SCM) presents complex decision-making challenges that require robust and transparent evaluation methods. Effective decision-making in this context requires robust evaluation methods capable of handling complex, multi-dimensional aspects of the decision process. This study proposes a comprehensive decision-support framework that integrates Multi-Criteria Decision Analysis (MCDA) with advanced sensitivity analysis techniques to assess the stability and reliability of alternative rankings under uncertainty. The framework combines established MCDA methods with submodel exclusion analysis and the Comprehensive Sensitivity Analysis Method (COMSAM), which allows for systematic perturbation of the decision matrix and evaluation of robustness across multiple dimensions. Applied to a green logistics case study, the framework demonstrates its capacity to support sustainable decision-making by accounting for varying stakeholder priorities and data uncertainty. The approach offers methodological advances in robustness assessment, practical relevance for sustainability-focused SCM, and open-source implementation to ensure reproducibility. The proposed framework is adaptable to a wide range of decision contexts, contributing to the development of more reliable and explainable MCDA-based evaluations.},
  archive      = {J_ASOC},
  author       = {Jakub Więckowski and Wojciech Sałabun},
  doi          = {10.1016/j.asoc.2025.113879},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113879},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-criteria decision analysis-based framework for supply chain management evaluation with multi-dimensional sensitivity analysis: A green logistics perspective},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical layered multigraph network with scale importance estimation for image classification. <em>ASOC</em>, <em>185</em>, 113877. (<a href='https://doi.org/10.1016/j.asoc.2025.113877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a novel image representation and processing approach using Graph Neural Networks (GNNs). We propose a multigraph representation named H i E rarchical L ayered M ultigraph (HELM), which explicitly encodes spatial and hierarchical relationships as distinct edge types, overcoming the limitations of existing methods that fail to fully exploit relational information in images. A multi-scale representation is generated through hierarchical segmentation of a superpixel base graph, enabling the computation of spatial and hierarchical relationships within and across scales. To effectively process this multi-relational information, we introduce the H i E rarchical L ayered M ultigraph Net work (HELMNet), a novel GNN architecture incorporating specialized mechanisms for selectively aggregating and fusing information from each distinct edge type. Additionally, it includes a Region Graph Readout (RGR) module that employs an attention mechanism to dynamically weight the contribution of each representation scale during the aggregation process for classification. Experimental results demonstrate the greater efficacy of HELMNet for image classification. Compared to hierarchical models that do not distinguish between edge types, HELMNet obtains substantial average accuracy gains of 2.1% (significant at 3% level) and 10% (significant at 0.1% level) on the CIFAR-10 and STL-10 datasets, respectively. On the EUROSAT dataset, HELMNet achieves over 95% accuracy, requiring only 0.73% of the best-performing state-of-the-art model size (in number of parameters). For the more demanding and high-resolution RESISC45 dataset, the proposed model still delivers impressive results, achieving an accuracy of over 85%.},
  archive      = {J_ASOC},
  author       = {João Pedro Oliveira Batisteli and Nicolas Passat and Silvio Jamil Ferzoli Guimarães and Zenilton Kleber Gonçalves do Patrocínio Júnior},
  doi          = {10.1016/j.asoc.2025.113877},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113877},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hierarchical layered multigraph network with scale importance estimation for image classification},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting fuzzy classification rules under footprint of uncertainty of type-2 fuzzy sets. <em>ASOC</em>, <em>185</em>, 113876. (<a href='https://doi.org/10.1016/j.asoc.2025.113876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach to improving classification accuracy in fuzzy rule-based systems by selecting Embedded Type-1 Fuzzy Sets (ET1 FSs) from Footprint of Uncertainty (FOU) areas. The method consists of three stages: (1) learning Type-1 fuzzy rules from predefined linguistic variables, (2) generating FOU areas with Interval Type-2 Fuzzy Sets (IT2 FSs), and (3) using the adaboost ensemble method, where multi-class problems are decomposed into binary classification tasks, and ET1 FSs are iteratively selected via genetic algorithms. By relying on IT2 FSs for the flexible partitioning of classification boundaries, the method enhances accuracy while addressing challenges in high-dimensional and multi-class problems. Experiments were performed on 12 UCI datasets and three image classification tasks using features from pre-trained convolutional neural networks. These datasets were selected to ensure diversity in dimensionality and class distribution. Comparative analyses with several state-of-the-art classification methods demonstrate that IT2 FSs can be effectively used to develop accurate classification systems. Additionally, this work analyzes trade-offs between complexity and interpretability by tuning FOU size (distinguishability) and adjusting the number of rules. The results show that a balanced FOU size and rule count yield better accuracy gains than either alone. Furthermore, several suitable trade-off regions with their parameters are presented.},
  archive      = {J_ASOC},
  author       = {Jidong Li and Jian Cui and Qian Su},
  doi          = {10.1016/j.asoc.2025.113876},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113876},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Boosting fuzzy classification rules under footprint of uncertainty of type-2 fuzzy sets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable type 2 fuzzy Min–Max neural networks for pattern classification. <em>ASOC</em>, <em>185</em>, 113875. (<a href='https://doi.org/10.1016/j.asoc.2025.113875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fuzzy Min–Max (FMM) algorithm is a powerful classification method capable of handling non-linear class boundaries and making both hard and soft decisions while learning from online data. However, it faces significant challenges, including sensitivity to the expansion coefficient, information loss during the contraction stage, and the overlap problem. To address these limitations, we propose a Reliable Type-2 Fuzzy Min–Max (RT2FMM) algorithm, which incorporates type-2 fuzzy logic to consider hyperbox uncertainty and effectively resolve the overlap problem. By assigning distinct certainties to overlapping regions, RT2FMM eliminates the need for the contraction stage and the overlap test. Additionally, we introduce weighted factors for hyperboxes, which enhances the reliability of membership values and models their mutual effects. Our comprehensive experimental evaluation across twenty datasets demonstrates that RT2FMM significantly outperforms existing FMM-based models in terms of robustness and accuracy. The Friedman test further confirms the superior performance of RT2FMM compared to commonly used classifiers, highlighting its potential as a robust solution for complex classification tasks.},
  archive      = {J_ASOC},
  author       = {Ali Nik-Khorasani and Mohammad-R. Akbarzadeh-T.},
  doi          = {10.1016/j.asoc.2025.113875},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113875},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reliable type 2 fuzzy Min–Max neural networks for pattern classification},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fortifying vision models: A comprehensive survey of defences against adversarial examples. <em>ASOC</em>, <em>185</em>, 113874. (<a href='https://doi.org/10.1016/j.asoc.2025.113874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and Machine learning (ML) have seen many advancements in the past two decades. It has led to the creation of several techniques, including Deep Neural Networks (DNN), Convolution Neural Networks (CNN), Autoencoders, Generative Adversarial Networks (GAN) and Diffusion models. These techniques have been applied to various real-world applications, such as self-driving cars, medical diagnosis and voice assistants. Despite these advancements, a carefully crafted input can fool the ML model. Such attacks are known as adversarial examples. It is a serious threat to safety critical systems. This survey provides a comprehensive review of defences against adversarial examples by tracing their evolution from early empirical methods to more principled, theoretically grounded approaches. We systematically categorise defences based on their underlying mechanisms. In addition to surveying state-of-the-art techniques, we spotlight emerging trends such as generative defences and diffusion-based purification. Finally, we identify persistent vulnerabilities and outline promising directions for future research towards building truly resilient vision models. This work aims to equip researchers and practitioners with a deep understanding of current defences and inspire innovation in adversarial robustness for the next generation of vision applications.},
  archive      = {J_ASOC},
  author       = {Siddheshwar Kumar and Shashank Srivastava and Shashwati Banerjea},
  doi          = {10.1016/j.asoc.2025.113874},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113874},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fortifying vision models: A comprehensive survey of defences against adversarial examples},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform. <em>ASOC</em>, <em>185</em>, 113873. (<a href='https://doi.org/10.1016/j.asoc.2025.113873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative image detection faces persistent challenges in terms of generalization and interpretability, limiting its reliability in complex scenarios. To address these issues, we propose AOT-PixelNet, a lightweight and interpretable detection framework that integrates an Adaptive Orthogonal Transform (AOT) module with a streamlined 1 × 1 convolution-based PixelNet architecture. The AOT module leverages diverse orthogonal transforms, such as FFT and DCT, to extract informative frequency-domain features, thereby enhancing sensitivity to medium- and high-frequency artifacts. Meanwhile, PixelNet minimizes parameter count (only 0.98 million) while effectively capturing cross-channel inconsistencies and mitigating overfitting. Experimental evaluations on multiple unseen GAN and diffusion-based datasets demonstrate that AOT-PixelNet achieves superior performance with minimal computational cost. Specifically, it outperforms the NPR method by 0.6% and 11.76% on the ForenSynths and GenImage datasets, respectively, validating the framework’s robustness, effectiveness, and interpretability.},
  archive      = {J_ASOC},
  author       = {Dengtai Tan and Deyi Yang and Boao Tan and Chengyu Niu and Yang Yang and Shichao Li},
  doi          = {10.1016/j.asoc.2025.113873},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113873},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud. <em>ASOC</em>, <em>185</em>, 113872. (<a href='https://doi.org/10.1016/j.asoc.2025.113872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud facilitates the user to complete their work utilizing the cost strategy of pay-as-you-go, which is based on the consumed Virtual Machine (VM) hours. Thus, the scheduler must offer the highest throughput to attain efficient allocation of resources in the cloud paradigm. Cloud services are dependent on characteristics such as fault tolerance, security, scalability, and availability. Hence, an effective scheduler is necessary to arrange the scheduling tasks and adjust the server loads. Typically, a load-balancing task focuses on detecting the overloaded and under-loaded nodes and adjusting the load between them. When considering the significant role of fault-tolerance in load-balancing algorithms, it seems to suffer from poor organization and a lack of in-depth experiments in this sector. This paper proposes a new task for the load-balancing operation. Initially, task scheduling is performed where the fault tolerance and the priority-aided scheduling approach are adopted. Furthermore, resource optimization is carried out in the scheduling task using Randomly Improved Electric Fish Optimization (RIEFO). To validate the load balancing operation, several multi-objective functions such as resource utilization, delay, time, makespan, active servers, throughput, success rate, fault tolerance rate, and energy consumption are derived. Moreover, because of the system’s dynamic environment, the status of the server varies simultaneously. The server status prediction is significant in allocating the tasks to the server or the VM resources. Thus, the Attention-based Cascaded Residual Bidirectional Long Short-Term Memory (ACRes-BiLSTM) is employed to predict the server status before performing the resource allocation. Finally, the tasks are scheduled effectively using the predicted server status. The performance is estimated using numerous performance metrics.},
  archive      = {J_ASOC},
  author       = {Gudivada Lokesh and Kasarapu Ramani and K.K. Baseer},
  doi          = {10.1016/j.asoc.2025.113872},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113872},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +. <em>ASOC</em>, <em>185</em>, 113871. (<a href='https://doi.org/10.1016/j.asoc.2025.113871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape leaf diseases, such as black rot, powdery mildew, and downy mildew, pose a significant threat to global viticulture, leading to substantial yield losses and reduced fruit quality. Early and accurate identification of these diseases is essential for precision agriculture and sustainable crop management. This study presents a comprehensive comparison of traditional and deep learning-based image segmentation methods for detecting grape leaf lesions. A series of classical segmentation techniques, including Mean Shift, Fuzzy C-Means (FCM), Normalized Cut, K-Means, and Fuzzy K-Means (FKM), were evaluated alongside an advanced DeepLabv3 + model. The baseline DeepLabv3 + architecture was further enhanced by integrating a ResNeSt-50 backbone with various attention mechanisms, including Squeeze-and-Excitation (SE) Block, Convolutional Block Attention Module (CBAM), Bottleneck Attention Module (BAM), Self-Attention, and Dual Attention Network (DANet). Among all models, DeepLabv3 + with ResNeSt-50 and CBAM achieved the highest performance, attaining 98.2 % accuracy, 97.1 % precision, 96.7 % recall, 96.6 % mean Intersection over Union (mIoU), and a 96.8 % Dice Score. The results demonstrate that attention-augmented deep networks significantly outperform classical methods, especially in handling complex lesion structures under diverse environmental conditions. While traditional algorithms remain useful in resource-constrained scenarios, deep learning models, particularly those enhanced with spatial and channel-wise attention, offer greater accuracy and robustness, making them ideal for integration into intelligent agricultural platforms such as drones, mobile scanners, and automated disease monitoring systems. Future work will focus on incorporating temporal and multimodal data, expanding dataset diversity, and optimizing lightweight models for real-time deployment on edge devices.},
  archive      = {J_ASOC},
  author       = {Kittipol Wisaeng},
  doi          = {10.1016/j.asoc.2025.113871},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113871},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger. <em>ASOC</em>, <em>185</em>, 113870. (<a href='https://doi.org/10.1016/j.asoc.2025.113870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Teaching-Learning-Based optimization (TLBO) algorithm, which includes teacher phase and learner phase, is a widely used method for global optimization. However, TLBO will experience premature convergence and get stuck in local optimum when faced with complex optimization challenges. Especially when tackling complex problems in practical engineering applications, which involves multiple variables and numerous constraints. To address this issue, a new variant termed Stochastic Proportional–Differential TLBO (SPD-TLBO) has been developed. The SPD phase allows students to learn not only from the current population but also from previous stochastic errors and their generation differences using adaptive random operators. By incorporating an SPD operator into the original TLBO framework, the algorithm’s search diversity is enhanced, reducing the likelihood of premature convergence to local optimum. The experimental results conducted at the IEEE Conference on Evolutionary Computation 2014 (CEC 2014) indicated that the proposed SPD-TLBO algorithm achieved an effective balance between exploration and exploitation capabilities. Specifically, the SPD-TLBO algorithm achieves the highest ranking in 21 out of 30 cases (70%) for 30-dimensional problems and 18 out of 30 cases (60%) for 50-dimensional problems. Statistical tests and convergence analyses show that the SPD-TLBO algorithm outperforms other algorithms in solving global optimization problems. Additionally, when applied to engineering optimization problems, the SPD-TLBO algorithm shows significant advantages over other algorithms. Therefore, the SPD-TLBO algorithm is further applied to optimize the structure of a wafer transfer finger in semiconductor manufacturing.},
  archive      = {J_ASOC},
  author       = {Jinfeng Sun and Yunlang Xu and Haibo Zhou},
  doi          = {10.1016/j.asoc.2025.113870},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113870},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network. <em>ASOC</em>, <em>185</em>, 113867. (<a href='https://doi.org/10.1016/j.asoc.2025.113867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus Disease 2019 (COVID-19) is an infectious illness that affects both humans and animals. Individuals infected with COVID-19 are prone to lung complications during the recovery phase . Radiography and Computed Tomography (CT) are the most commonly used methods for diagnosing lung-related diseases. The primary aim of this paper is to assess the impact of COVID-19 on patients’ lungs, heart, and blood sugar levels using a deep learning-based approach. Initially, data related to the heart, blood sugar levels, and lungs of COVID-19-infected individuals are collected. From this dataset, three types of features are extracted. Deep features are obtained using Iterated Dilated Convolutional Neural Networks (IDCNN). From these deep features, which are obtained from the IDCNN, the optimal weighted features are derived by implementing the Hybrid Dolphin Pod Cuttlefish Optimization (HDPCO) algorithm. Subsequently, the HDPCO algorithm is also employed for optimal feature extraction. In addition, dimensionality reduction is performed using Principal Component Analysis (PCA). These three sets of features from the IDCNN, HDPCO, and PCA, are then fused into a single feature set . This fused feature set is fed into a hybrid classifier composed of a Deep Temporal Convolutional Network (DTCN) and an Attention-based Long Short-Term Memory (ALSTM) network . The classifier parameters are optimized using the HDPCO algorithm. The output from the hybrid classifier provides the final prediction result. Experimental results demonstrate that the proposed COVID-19 impact prediction model significantly outperforms existing models in terms of prediction accuracy and efficiency.},
  archive      = {J_ASOC},
  author       = {Sadanandam Kalvala and B. Baranidharan},
  doi          = {10.1016/j.asoc.2025.113867},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113867},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware. <em>ASOC</em>, <em>185</em>, 113866. (<a href='https://doi.org/10.1016/j.asoc.2025.113866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing offers the potential to enhance computational efficiency beyond classical methods, but practical implementation remains challenging due to the limitations of Noisy Intermediate-Scale Quantum (NISQ) hardware, namely, restricted qubit counts, limited connectivity, and the presence of noise and decoherence. This study presents a novel approach to edge detection by leveraging a recently developed Quantum Fuzzy Inference Engine, implemented on a NISQ device. We introduce an optimized quantum circuit for its implementation, reducing qubit requirements and gate depth to improve execution on NISQ hardware. To overcome constraints related to large-scale image processing, a hybrid quantum–classical lookup table approach is employed. Edge detection performance is evaluated on the Berkeley Segmentation Data Set and Benchmarks 500 dataset under different conditions, including classical execution, ideal quantum simulation, noisy quantum simulation, and NISQ hardware calculation. Results demonstrate that the quantum fuzzy logic-based edge detection achieves outcomes comparable to classical methods by using fewer operations, marking a step toward practical quantum-enhanced image processing.},
  archive      = {J_ASOC},
  author       = {G. Nunziata and S. Crisci and G. De Gregorio and R. Schiattarella and G. Acampora and L. Coraggio and N. Itaco},
  doi          = {10.1016/j.asoc.2025.113866},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113866},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent cooperation-based bi-criteria evolutionary many-objective optimization. <em>ASOC</em>, <em>185</em>, 113865. (<a href='https://doi.org/10.1016/j.asoc.2025.113865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective evolutionary algorithms (MaOEAs) excel in solving many-objective optimization problems (MaOPs), which are mainly classified into two frameworks: the Pareto domination and the non-Pareto domination. The Pareto criterion (PC) obtains a well-converged solution set in multi-objective spaces through the Pareto dominance relationship between solutions. However, insufficient environmental selection pressure in many-objective spaces leads to slow convergence. The non-Pareto criterion (NPC) enhances the selection pressure by evaluating the solution set with a set of sortable scalar values. However, it is difficult to ensure the Pareto-optimal consistency of convergence and distribution when facing highly irregular Pareto fronts (PFs). Therefore, combining the two sets of criteria can satisfy the demand for uniform distribution while bringing significant selection pressure. A multi-agent cooperative strategy is proposed in this study to realize the combination of the two criteria. This strategy controls the evolutionary direction of two populations separately by deploying two agents, and promotes cooperative evolution between these populations through the exchange and flow of large amounts of information. In order to better realize the cooperative effect, we adopt the multi-agent reinforcement learning (MARL) strategy to accurately regulate the variation operator and parameter configurations of the bi-population. In addition, the effectiveness of the proposed method is validated on 74 test problems (DTLZ, WFG, and UF) and 3 real-world problems. The results show that the proposed algorithm is more competitive than 6 state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Jiazheng Li and Yuan Liu and Juan Zou and Shuyi Liu and Shengxiang Yang and Jinhua Zheng},
  doi          = {10.1016/j.asoc.2025.113865},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113865},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent cooperation-based bi-criteria evolutionary many-objective optimization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ORESTE methodology within a circular intuitionistic fuzzy framework for preferential outranking in hybrid cloud service selection. <em>ASOC</em>, <em>185</em>, 113864. (<a href='https://doi.org/10.1016/j.asoc.2025.113864'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper advances the ORESTE (Organísation, Rangement Et Synthèse de Données Relarionnelles) methodology within the Circular Intuitionistic Fuzzy (CIF) framework, highlighting its potential in practical decision analytics. The study first enhances CIF aggregation by employing the generalized mean technique, offering a flexible way to combine evaluative ratings and significance weights. Through modulation of the averaging parameter, decision-makers are able to accentuate either lower or higher values, thereby overcoming the constraints associated with conventional arithmetic means. The framework further improves decision precision through CIF similarity-driven appraisal indices, which utilize refined similarity metrics grounded in axiomatic properties such as symmetry, boundedness, identity, and monotonicity. These indices quantify the similarity between evaluative ratings and anchor references, while also revealing indifference and incomparability—thus equipping decision-makers with a comprehensive toolset for handling uncertainty. The CIF ORESTE framework comprises two methodologies. CIF ORESTE I delivers a global weak ranking using similarity-driven indices and generalized projection-related distances. CIF ORESTE II addresses the limitations of weak rankings by incorporating an Indifference-Preference-Incomparability (I-P-R) structure, which uses mean and net preference intensities to establish thresholds and clarify outranking relations. Applied to the evaluation of hybrid cloud services for a technology corporation, the CIF ORESTE framework demonstrates its effectiveness in resolving group decisions, managing uncertainty, and structuring preferences. Comparative analyses further underscore its robustness in handling CIF-based data and delivering reliable results.},
  archive      = {J_ASOC},
  author       = {Ting-Yu Chen},
  doi          = {10.1016/j.asoc.2025.113864},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113864},
  shortjournal = {Appl. Soft. Comput.},
  title        = {ORESTE methodology within a circular intuitionistic fuzzy framework for preferential outranking in hybrid cloud service selection},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompted complex context generation guided fine-grained ship recognition. <em>ASOC</em>, <em>185</em>, 113856. (<a href='https://doi.org/10.1016/j.asoc.2025.113856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained ship recognition in complex marine environments is challenged by background interference, high inter-class similarity, and limited labeled data. Existing methods often rely on inefficient cascades or holistic feature extraction, which limits both accuracy and efficiency. To address these issues, we propose a Prompted Complex Context Generation Guided Fine-Grained Ship Recognition framework, consisting of two core modules. The Cross-Attention Context Generation Module utilizes a diffusion model to generate diverse background images from prompts, maintaining target consistency and enriching the training data to mitigate data scarcity. It also employs a cross-attention map to highlight target-relevant regions, guiding the Attention Map Guided Fusion Module. The Attention Map Guided Fusion Module adopts a dual-branch transformer architecture: one branch extracts global features from background-enhanced images, and the other captures local features through attention-guided cropping of target-specific regions. By integrating both global and local features, our method effectively identifies key target characteristics. Experimental results demonstrate that our approach achieves 97.04% accuracy on the publicly available MAR-ships dataset and 84.57% accuracy on the challenging GCS dataset, outperforming state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Runtian Wang and Kejun Wu and Renjie Qiao and Chunsheng Yang and Chengtao Cai},
  doi          = {10.1016/j.asoc.2025.113856},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113856},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prompted complex context generation guided fine-grained ship recognition},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label feature selection via asymmetric redundancy and variable precision dependency. <em>ASOC</em>, <em>185</em>, 113852. (<a href='https://doi.org/10.1016/j.asoc.2025.113852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is an effective data preprocessing technique that can significantly mitigate the challenges posed by high-dimensional features in multi-label learning. However, the exploration of feature-label correlations has often been strictly limited to inclusion relationships, while ignoring the fusion of local and global label information. Moreover, most previous work has typically assumed that redundancy between features is fully symmetric, overlooking the valuable insights that asymmetric redundancy provides for designing feature selection. To address these issues, this paper proposes a novel multi-label feature selection via asymmetric redundancy and variable precision dependency. Specifically, it constructs a conditional probability model to reflect the local label semantics, incorporating this into the construction of the variable precision dependency through a fusion indicator. Subsequently, the optimistic and pessimistic information overlap between features is discussed, allowing variable precision granularity to capture asymmetric redundancy between features. Building upon this, an information fusion method is proposed to quantify the pessimistic asymmetric redundancy between features by inducing knowledge granularity in the feature space. Finally, a comprehensive evaluation metric, Maximum Correlation-maximum Discrimination-minimum Redundancy (MCDR), is proposed to evaluate the significance of features. The experimental results on fifteen multi-label benchmark datasets indicate that the proposed method outperforms the other seven state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Wenbin Qian and Xiwen Lu and Shiming Dai and Jintao Huang},
  doi          = {10.1016/j.asoc.2025.113852},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113852},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-label feature selection via asymmetric redundancy and variable precision dependency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy. <em>ASOC</em>, <em>185</em>, 113851. (<a href='https://doi.org/10.1016/j.asoc.2025.113851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing decision tree algorithms often use a single-layer measure to process data, which cannot fully consider the complex interactions and dependencies between different granularity levels. In addition, decision tree algorithms inevitably face the issue of multi-value preference, which may lead to the selection of unreasonable attributes in the process of partition, thereby affecting the performance of the algorithms. Therefore, this paper proposes an improved decision tree algorithm, called Ze-VNDT, which combines variable precision rough sets with Zentropy. First, to avoid the information loss caused by data discretization, this paper introduces variable precision neighborhood rough sets for data processing. Second, by analyzing the granularity level structure within the variable precision neighborhood rough set model, knowledge uncertainty is analyzed from three granularity levels: decision classes, approximate relations, and similarity classes. We describe the uncertain knowledge from the overall to the internal using the idea of going from coarse to fine, and design a Zentropy to measure uncertainty. To address the issue of multi-value preference, an adaptive weighted Zentropy uncertainty measure is designed based on the definition of uncertainty measure based on Zentropy. Third, when constructing the improved decision tree algorithm, the optimal attributes are selected based on the designed uncertainty measure. Finally, numerical experiments on 18 UCI datasets validated the effectiveness and rationality of the proposed algorithm. The experimental results showed that, compared to traditional algorithms and the latest improved algorithms, the proposed algorithm achieved an average accuracy of 94.79%, an average precision of 85.77%, an average recall rate of 84.68%, and an F1-score of 84.97% across the 18 datasets. It ranked first in all five evaluation metrics, demonstrating higher stability and accuracy.},
  archive      = {J_ASOC},
  author       = {Hui Dong and Caihui Liu and Xiying Chen and Duoqian Miao},
  doi          = {10.1016/j.asoc.2025.113851},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113851},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skin lesion classification with mini-batch sampling and deep metric learning. <em>ASOC</em>, <em>185</em>, 113850. (<a href='https://doi.org/10.1016/j.asoc.2025.113850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin lesion image classification based on deep learning has recently garnered significant attention. However, directly applying methods that perform well in general computer vision tasks to skin lesion image classification is not ideal, as skin lesion image datasets possess intrinsic characteristics, such as class imbalance, intra-class variability, and inter-class similarity. To tackle these challenges simultaneously, we propose a novel unified learning framework, named mBSML, which integrates mini-batch sampling and deep metric learning. In this framework, mini-batch sampling re-samples data in real-time during each iteration of learning, while a new loss function combines mini-batch distance metric-based loss with cross-entropy loss. Through the alternating training procedure on both imbalanced training data and balanced re-sampling data, mBSML effectively learns from global distribution information and local similarity information, not only from the original dataset but also from the minority classes. Extensive experiments conducted on two publicly available datasets demonstrate the effectiveness of mBSML for skin lesion image classification.},
  archive      = {J_ASOC},
  author       = {Shengdan Hu and Zhifei Zhang and Li Ying and Guangming Lang},
  doi          = {10.1016/j.asoc.2025.113850},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113850},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Skin lesion classification with mini-batch sampling and deep metric learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes. <em>ASOC</em>, <em>185</em>, 113849. (<a href='https://doi.org/10.1016/j.asoc.2025.113849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in airport surface scenes is crucial for enhancing safety. However, the coexistence of objects with significant scale disparities within the same region complicates feature representation, limiting existing models’ ability to capture fine-grained details, especially for small objects. To address this challenge, we propose AOD-YOLO, an Airport Object Detection (AOD) model incorporating a Self-Modulating Multi-Scale Feature Aggregation Mechanism. This model introduces two key innovations: (1) Enhanced Context Modeling: By leveraging large-kernel convolution, frequency-domain modulation, and statistical feature analysis, our approach effectively adjusts feature contributions across different object scales, improving contextual understanding in complex scenes; (2) Optimized Small Object Representation: A dynamic gradient gain allocation strategy refines small-object features, enhancing detection accuracy and overall feature presentation. AOD-YOLO consistently improves performance across model scales. On our self-constructed Airport dataset and the public VisDrone-DET2019 dataset, it achieves mean Average Precision (mAP 0.5 ) of 87.9% and 44.9%, respectively—outperforming state-of-the-art models like YOLOv11 and Gold-YOLO by substantial margins. Additionally, through optimized network module placement, AOD-YOLO achieves 112 FPS, striking a balance between computational efficiency and accuracy, making it well-suited for real-time airport object detection.},
  archive      = {J_ASOC},
  author       = {Yingqing Wang and Weili Zeng and Ziyu Zhao and Baogeng Li and Zhibin Quan},
  doi          = {10.1016/j.asoc.2025.113849},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113849},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gloss-free sign language translation based on fusion attention. <em>ASOC</em>, <em>185</em>, 113848. (<a href='https://doi.org/10.1016/j.asoc.2025.113848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language translation converts sign language videos into spoken language text. Traditional gloss-based approaches require costly gloss annotations, driving recent interest in gloss-free methods. In this paper, we propose a novel gloss-free sign language translation method based on fusion attention (SLTFA) that uniquely models the intrinsic logical structure of sign language. The key innovation is the development of a dual-attention mechanism that mimics the natural hierarchical structure of sign language: intra-gloss attention captures fine-grained relationships within video frame sequences representing individual semantic units, while inter-gloss attention models the broader contextual connections between these units, similar to how words form coherent sentences. Additionally, we introduce a contrastive loss strategy for cross-modal soft alignment that effectively bridges the gap between visual and textual representations. Extensive experiments on the RWTH-PHOENIX-WEATHER-2014T dataset demonstrate SLTFA’s superior performance, achieving a BLEU-4 score of 16.99 and a ROUGE score of 40.82. On the CSL-Daily dataset, our approach achieves a BLEU-1 score of 25.56 and a ROUGE score of 27.51, demonstrating strong performance across different sign languages.},
  archive      = {J_ASOC},
  author       = {Yingchun Xie and Wei Su and Chongliang Zhong and Chuan Cai and Yongna Yuan},
  doi          = {10.1016/j.asoc.2025.113848},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113848},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Gloss-free sign language translation based on fusion attention},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient mathematical-based optimization method to optimize multi-hydropower operating rules. <em>ASOC</em>, <em>185</em>, 113846. (<a href='https://doi.org/10.1016/j.asoc.2025.113846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing hydropower multi-reservoir systems requires both effective operating rules and efficient optimization techniques. The main contribution of this paper is offering a unique approach that elegantly combines two important parts: creating an efficient optimization method and developing hydropower operating rules. In this regard, a nonlinear rule curve (NLRC) and a linear rule curve (LRC), are tailored for the coordination of a hydropower multi-reservoir system (HMRS) in Iran. To optimize operating rules, the study fabricates a novel algorithm termed the multi-operator weighted mean of vectors (MINFO). The algorithm combines a powerful global search strategy (GSS) that thoroughly searches the solution space with an efficient local search (LS), striking a balance between solution diversity and convergence speed. To fine-tune this balance, an adaptive parameter-tuning strategy is applied. Furthermore, the active-set sequential quadratic programming (ASQP) serves as a localized escaping operator to enhance the algorithm's convergence speed. The effectiveness of the proposed MINFO algorithm is first evaluated through a nonlinear five-reservoir problem. The findings indicate that the MINFO algorithm outperforms a set of 14 distinct optimization methods. Subsequently, the MINFO algorithm is applied to identify optimal NLRC and LRC for a six-reservoir hydropower system. The results underscore the superiority of optimized NLRC, yielding a potential power augmentation of up to 17 % in comparison to the LRC approach. In summation, this study constitutes a seminal contribution by cultivating an efficient rule curve framework for the management of HMRSs.},
  archive      = {J_ASOC},
  author       = {Shuguang Li and Iman Ahmadianfar and Aitazaz A. Farooque and Zaher Mundher Yaseen},
  doi          = {10.1016/j.asoc.2025.113846},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113846},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient mathematical-based optimization method to optimize multi-hydropower operating rules},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach. <em>ASOC</em>, <em>185</em>, 113837. (<a href='https://doi.org/10.1016/j.asoc.2025.113837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting debris and monitoring marine life in sea aquaculture face challenges due to limited visibility and the presence of diverse. Underwater object detection by Autonomous Unmanned Vehicle(AUV) is inherently more challenging than land due to light attenuation and water turbidity, especially for small and dense objects in murky images, where extracting high-quality features is hindered. In this paper, we present an efficient approach for real-time underwater object detection through improvements in image enhancement, data augmentation, and feature aggregation. Initially, U-Shape Transformer is applied to enhance the original images. For data augmentation, it is observable that while Mosaic data augmentation enhances complex images but fails to improve small-object detection due generation of less number of images with small objects. To address this limitation, we propose Underwater-Mosaic (U-Mosaic), a modified Mosaic data augmentation technique designed to enhance small-object detection. Additionally, it was noted that existing YOLOv4 struggles with detecting small and densely populated objects in underwater images as unable to get sufficient features for small objects due to downsampling, image quality and also found difficulty in selecting anchor box size. Therefore, we propose a model called Advanced YOLOv4, tailored for underwater object detection. The proposed Advanced YOLOv4 aims to improve object detection efficiency by altering the neck and prediction layers of YOLOv4. Moreover, we introduce an additional spatial pyramid pooling layer to aggregate features and reduce feature dimensions thereby improving object detection rates. Also, the proposed work concentrates on very large object detection and for this purpose used downsampling during the detection of large objects. The proposed approach is validated through two distinct application areas: (i) detecting and locating debris (ii) detecting fish from underwater images. For validation, the Trash ICRA19 dataset is used for debris detection, while the Brackish dataset is employed for fish detection. UIQM and UCIQE, image enhancement assessment metrics are used to measure quality of enhanced images and found more than 20% better result for both the datasets. The proposed real-time underwater object detection model outperformed single-stage object detectors like YOLOv3, YOLOv4, YOLOv5, YOLOv7, and KPE-YOLOv5 by 5% in terms of mean Average Precision(mAP). Also proposed work compared with two-stage detector RCNN and found 8% better mAP than RCNN.},
  archive      = {J_ASOC},
  author       = {Pratima Sarkar and Sourav De and Prasenjit Dey and Sandeep Gurung},
  doi          = {10.1016/j.asoc.2025.113837},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113837},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-branch and multi-loss learning for fine-grained image retrieval. <em>ASOC</em>, <em>185</em>, 113833. (<a href='https://doi.org/10.1016/j.asoc.2025.113833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively address the problem of low accuracy of fine-grained image retrieval due to significant intra-class differences and small inter-class differences, we propose a novel and highly reliable fine-grained deep hashing learning framework dubbed MBLNet to accurately retrieve fine-grained images. Specifically, we propose (i) a dual-selected significant region erasure method for generating compact binary codes for fine-grained images; (ii) a dual filtering object location method for mining discriminative local features; and (iii) a new multi-stage loss function for optimizing network training. We conducted extensive experiments on three fine-grained datasets, Stanford Cars, FGVC-Aircraft, and CUB-200-2011, and achieved mAP results of 89.3%, 87.2%, and 80.6%, respectively. Additionally, the ablation study demonstrates that both the dual-selected significant region erasure method and the dual filtering object location method contribute to the improved accuracy of fine-grained image retrieval, further validating the effectiveness of the proposed method. Code can be found at https://github.com/luhongchun/MBLNet.git .},
  archive      = {J_ASOC},
  author       = {Hongchun Lu and Min Han and Songlin He and Xue Li and Chase Wu},
  doi          = {10.1016/j.asoc.2025.113833},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113833},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-branch and multi-loss learning for fine-grained image retrieval},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniCon: Unified image-guiding generation with noise consistency. <em>ASOC</em>, <em>185</em>, 113832. (<a href='https://doi.org/10.1016/j.asoc.2025.113832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have demonstrated remarkable capabilities in image-to-image tasks. However, existing methods typically focus either on structural (e.g., layout, content) or stylistic guidance, with few approaches effectively excel at both. On the other hand, many methods require time-consuming fine-tuning or high inference latency, making interactive generation applications challenging to realize. To address these issues, we propose a two-stage framework referred as UniCon ( Uni fied Image-guiding Generation with Noise Con sistency). To improve time efficiency, we follow the paradigm of inversion-based image manipulation and introduce a novel method called Noise Consistency Inversion . Leveraging the nature of Consistency Models, this inversion process is highly efficient, requiring only a single neural function evaluation (NFE) in the inversion process. To achieve high consistency and finer control, we introduce a unified attention-based guidance mechanism that supports structural, stylistic, or joint reference inputs, without any additional fine-tuning. Experiments with structure- and style-specific methods show that our approach performs competitively or better in each individual aspect. In comparison of style transfer tasks that demand both structure and style, our method outperforms state-of-the-art baselines, confirming the effectiveness of our union control strategy. And overall, our approach also achieves the best efficiency in terms of runtime performance.},
  archive      = {J_ASOC},
  author       = {Yuanjun Liao and Yuning Gong and Yanci Zhang},
  doi          = {10.1016/j.asoc.2025.113832},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113832},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UniCon: Unified image-guiding generation with noise consistency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment. <em>ASOC</em>, <em>185</em>, 113830. (<a href='https://doi.org/10.1016/j.asoc.2025.113830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Turkish textile and apparel sector plays a crucial role in the national economy through employment, exports, and investment. The financial performance of companies is a key determinant of their sustainability and competitiveness, especially in global markets. The Turkish textile and apparel sector is one of the essential industries in terms of macro-economic indicators such as net foreign exchange inflow, employment and investment. This sector is also one of the critical actors in world trade. A robust performance evaluation model is essential for stakeholders such as investors, creditors, and managers. However, the assessment of firms is a very critical decision involving uncertainty due to various conflicting criteria based on judgements. In this study, an integrated multi-criteria decision-making (MCDM) model including interval type-2 fuzzy hierarchy process (IT2FAHP) and Compromise Ranking of Alternatives from Distance to Ideal Solution (CRADIS) approaches are proposed to assess the financial performance of Turkish textile and clothing firms that are traded in Borsa İstanbul (BİST) in the period from 2006 to 2020. In line with the determined purpose, the arithmetic average of the determined financial ratios during the analysis period covering 15 years is computed to obtain long-term performance indicators. The importance weights of the selected financial criteria for the performance evaluation model are identified by employing the IT2FAHP approach. Then, the firms are ranked according to their financial performances with the CRADIS method. In addition, the results from the sensitivity analysis validate the proposed approach and prove that it is practical. Moreover, practical and managerial implications are discussed based on the results. The results offer valuable insights for strategic decision-making and can support efforts to enhance financial stability in the textile and apparel sector. According to the results, "LUKSK" had the highest long-term financial performance among the 11 companies discussed. This company is followed by BOSSA, YATAS, and ATEKS companies. The alternatives confirm the robustness of the proposed model in maintaining its place in the ranking in 190 scenarios. In addition, the comparative analysis confirms the consistency of the proposed ranking framework.},
  archive      = {J_ASOC},
  author       = {Ömer Faruk Görçün and Mohsin Shabir and Ahmet Çalık and Özcan Işık},
  doi          = {10.1016/j.asoc.2025.113830},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113830},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks. <em>ASOC</em>, <em>185</em>, 113829. (<a href='https://doi.org/10.1016/j.asoc.2025.113829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty analysis of wind speed forecasting using the Lower Upper Bound Estimation (LUBE) represents an advanced interval prediction method that does not require assumptions about data distribution. Previous studies, however, have exclusively focused on univariate prediction models, neglecting the information from other variables, and have not fully exploited the prediction errors in their loss function during training. To address these issues, an interpretable dual-output multivariate wind speed interval prediction scheme (IMWSIPS) that utilizes a hyper-heuristic optimization algorithm and a deep neural network is proposed, along with a novel loss function for training. The system initially takes multiple inputs such as historical wind speed and other influencing factors including wind direction, density, temperature, and pressure into a deep neural network. The actual wind speeds are then scaled up and down by factors of 1 + θ 1 (0 <θ 1 <1) and 1 + θ 2 (-1 <θ 2 <0), respectively, to produce two outputs from the network. On this basis, an optimization problem to minimize interval width under a given coverage probability is formulated and solved using the developed hyper-heuristic algorithm, yielding optimal values for θ 1 and θ 2 and the prediction intervals for sub-models. Subsequently, the advantages of five deep neural network models are leveraged to construct an ensemble model, with weights optimized by the hyper-heuristic algorithm to derive the final prediction intervals. Ultimately, the system's interpretability is analyzed at both variable and sub-model levels. Experimental and discussion results demonstrate that the introduction of IMWSIPS not only signifies enhancements in forecasting performance but also implies improvements in wind energy utilization efficiency and reductions in operational costs for power systems.},
  archive      = {J_ASOC},
  author       = {Mengzheng Lv and Jianzhou Wang and Shuai Wang and Yang Zhao and Jialu Gao and Yuansheng Qian},
  doi          = {10.1016/j.asoc.2025.113829},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113829},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The fuzzified grey wolf: An improved grey wolf optimizer based on dynamic fuzzy system FGWO. <em>ASOC</em>, <em>185</em>, 113818. (<a href='https://doi.org/10.1016/j.asoc.2025.113818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Grey Wolf Optimizer (GWO) is a leading, powerful, and effective algorithm in swarm optimization techniques, showing competitive performance across various optimization problems. Yet, GWO is burdened by high tendencies toward exploitation and imprecise population diversity. This work introduces an improved GWO called the Fuzzified Grey Wolf Optimizer (FGWO) for solving global optimization problems. FGWO benefits from a dynamic fuzzy inference system (DFIS) to capture the optimal value of a → throughout iterations. DFIS integrates two inputs: the diversity rate and iteration number, and by inferring the optimal value of a → , FGOW determines whether to exploit or explore. Moreover, DFIS employs an adaptive membership function to capture the precise value of population diversity throughout the course of iteration. This optimal a → determination strategy can achieve a balanced exploitation–exploration ratio, mitigating premature convergence and enhancing diversity. FGWO is evaluated on CEC2017 benchmark functions, four engineering designs, and a breast cancer genes feature selection design. FGWO was compared with three other improved GWOs, and across all experiments, the outcomes demonstrate its superiority in terms of efficiency and applicability to real-world designed problems.},
  archive      = {J_ASOC},
  author       = {Mohammed Dheyaa Algubili and Labiba M. Alhelfi and Hana’ M. Ali},
  doi          = {10.1016/j.asoc.2025.113818},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113818},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The fuzzified grey wolf: An improved grey wolf optimizer based on dynamic fuzzy system FGWO},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy lagrange interpolation method from summation of interactive fuzzy numbers. <em>ASOC</em>, <em>185</em>, 113817. (<a href='https://doi.org/10.1016/j.asoc.2025.113817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel approach to extending the sum of interactive fuzzy numbers, which is independent of the order of its operands. Interactive fuzzy numbers are fuzzy quantities in which the values across different α -cuts are not assumed to vary independently, incorporating dependencies that better reflect real-world uncertainty. A characterization of the proposed summation is given in terms of α -cuts, making computational implementation easier. It is shown that this operation preserves essential mathematical properties, including associativity. This is particularly important, as it enables the consistent aggregation of multiple fuzzy quantities without concern for the order in which the operands are grouped. The norm and width behaviors under this new summation are also analyzed. To illustrate the theoretical results, several examples are provided. As a practical application, the classical Lagrange polynomial interpolation method is extended to handle uncertain parameters represented by interactive fuzzy numbers. A fuzzy curve fitting problem is examined using this framework, and a comparative discussion highlights the advantages of the proposed method over existing approaches.},
  archive      = {J_ASOC},
  author       = {Geizane Lima da Silva and Estevão Esmi and Vinícius Francisco Wasques and Laécio Carvalho de Barros},
  doi          = {10.1016/j.asoc.2025.113817},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113817},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy lagrange interpolation method from summation of interactive fuzzy numbers},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision analytics for indian culinary tourism: A holistic group approach considering correlation. <em>ASOC</em>, <em>185</em>, 113812. (<a href='https://doi.org/10.1016/j.asoc.2025.113812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s data-driven world, making informed decisions in dynamic fields like culinary tourism is crucial. An enhanced multi-attribute decision-making (MADM) model is presented in this study to tackle the uncertainty and interdependencies of India’s culinary tourism landscape. The main goals are to (i) address uncertainty and correlations in MADM scenarios, (ii) calculate objective attribute weights, and (iii) resolve conflicts among alternatives based on preference, indifference, and incomparability. To manage uncertainty, the proposed model incorporates r , s -quasirung orthopair fuzzy set ( r , s -QOFS), while to capture relational dynamics among factors Aczel–Alsina operations based geometric Heronian mean operator is developed. Attribute weighting is performed with MEREC (method based on the removal effects of criteria) method, while a modified ORESTE (organísation, rangement et Synthèse dedonnées relarionnelles (in French)) method within the r , s -QOFS is initiated to rank alternatives, introducing a new ranking measure in place of Besson’s traditional rank. Finally, to test the effectiveness and practical value, a case study of culinary tourism destinations across 36 Indian states and union territories is conducted and then ranked using the proposed model. The results highlight southern Indian states as preferred destinations. Thus, this work contributes in two ways: first, by providing a general decision-making model for imprecise and data, and second, by offering valuable insights into the future of Indian culinary tourism.},
  archive      = {J_ASOC},
  author       = {Kaushik Debnath and Sankar Kumar Roy},
  doi          = {10.1016/j.asoc.2025.113812},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113812},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Decision analytics for indian culinary tourism: A holistic group approach considering correlation},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction. <em>ASOC</em>, <em>185</em>, 113776. (<a href='https://doi.org/10.1016/j.asoc.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material properties are illustrated by numerical data and semantic factors. In general, existing methods typically adopt machine learning (ML) algorithms to regress numerical properties or transfer other pre-trained knowledge graphs (KGs) to the material, due to the limitations of small-sample datasets. However, integrating semantic and numerical information from multi-modal data which across diverse experimental conditions remains a significant challenge in materials science. In this paper, a numerical reasoning method for material KGs (NR-KG) 1 was proposed, which constructs a cross-modal KG using semantic nodes and numerical proxy nodes. Both types of information by projecting KG into a canonical KG were captured and a graph neural network to predict material properties was utilized. In process, a novel projection prediction loss is proposed to extract semantic features from numerical information. NR-KG facilitates end-to-end processing of cross-modal data, mining relationships and cross-modal information in small-sample datasets, and fully utilizes effective experimental data to enhance the accuracy of material prediction. We propose two new high-entropy alloys (HEA) property datasets with semantic descriptions. NR-KG outperforms state-of-the-art (SOTA) methods on two material datasets, with MSE values of 3520 and 2.210, and achieving relative improvements of 25.9% and 16.1%, respectively, over the second-best methods, KANO and PCHMLP (semantic). It also achieves RMSE values of 0.584 and 0.521 on the FreeSolv and ESOL public molecular datasets, surpassing SOTA methods by 48.8% and 22.2% over KANO, highlighting its potential application and generalizability.},
  archive      = {J_ASOC},
  author       = {Guangxuan Song and Dongmei Fu and Zhongwei Qiu and Zijiang Yang and Jiaxin Dai and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.asoc.2025.113776},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113776},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing. <em>ASOC</em>, <em>185</em>, 113697. (<a href='https://doi.org/10.1016/j.asoc.2025.113697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading in volatile markets, such as cryptocurrencies, requires portfolio models that can swiftly adapt to regime shifts while controlling risk. We propose a novel approach that frames portfolio management as a dynamic strategy-selection problem. Instead of directly predicting asset weights, our agent selects from a pool of expert strategies based on recent market trends. We introduce a Transformer-based Variational Autoencoder (VAE) to extract disentangled trend representations, and a trend-aware actor–critic model to perform expert selection. Experiments demonstrate that this modular, strategy-level control mechanism outperforms existing methods in risk-sensitive crypto portfolio management.},
  archive      = {J_ASOC},
  author       = {Ahmad Asadi and Reza Safabakhsh},
  doi          = {10.1016/j.asoc.2025.113697},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113697},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="autom">AUTOM - 67</h2>
<ul>
<li><details>
<summary>
(2026). Congealed neural network design for uncertain nonlinear spatiotemporal control systems. <em>AUTOM</em>, <em>183</em>, 112636. (<a href='https://doi.org/10.1016/j.automatica.2025.112636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note is concerned with the approximation-based adaptive control problem for a class of uncertain nonlinear spatiotemporal systems. A congealed neural network (ConNN) is first proposed to approximate nonlinear spatiotemporal uncertainties arising from system states and time-varying parameters. Unlike conventional NN approximation structures, the ConNN explicitly decomposes the time-varying coupling weight into a congealed weight and a time-dependent perturbation. The congealed weight is estimated using a standard adaptive law for constant parameters, while the residual perturbation is handled within the network structure. To enhance robustness, smooth sliding-mode-like functions are then embedded into the control architecture, effectively attenuating bias terms, particularly in reference tracking scenarios. It is shown that the resulting ConNN-based adaptive controller guarantees adjustable, bounded-error tracking performance, thereby extending the applicability of robust adaptive control to complex spatiotemporal systems and outperforming existing NN-based approaches.},
  archive      = {J_AUTOM},
  author       = {Tianrun Liu and Yang-Yang Chen and Xiaohua Ge},
  doi          = {10.1016/j.automatica.2025.112636},
  journal      = {Automatica},
  month        = {1},
  pages        = {112636},
  shortjournal = {Automatica},
  title        = {Congealed neural network design for uncertain nonlinear spatiotemporal control systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stabilization of feedforward nonlinear time-delay systems with vanishing actuator effectiveness by linear time-varying feedback. <em>AUTOM</em>, <em>183</em>, 112635. (<a href='https://doi.org/10.1016/j.automatica.2025.112635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of global stabilization for a class of feedforward nonlinear systems in the presence of state delay, uncertain parameters, and vanishing actuator effectiveness. By assuming that the time-delay nonlinear function is unknown but satisfies a linear growth condition with unknown parameters, a state feedback controller incorporating two time-varying parameters is designed. One parameter focuses on compensating for the vanishing actuator effectiveness, while the other addresses uncertain nonlinear terms. The feature of the approach is that the designed controller is linear, and its implementation do not necessitate online computation, thereby significantly conserving computational resources. An example is included to verify the effectiveness of the proposed approaches.},
  archive      = {J_AUTOM},
  author       = {Kai Zhang and Bin Zhou},
  doi          = {10.1016/j.automatica.2025.112635},
  journal      = {Automatica},
  month        = {1},
  pages        = {112635},
  shortjournal = {Automatica},
  title        = {Stabilization of feedforward nonlinear time-delay systems with vanishing actuator effectiveness by linear time-varying feedback},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed safety-critical control of nonlinear multi-agent systems. <em>AUTOM</em>, <em>183</em>, 112634. (<a href='https://doi.org/10.1016/j.automatica.2025.112634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the safety-critical control problem for nonlinear second-order multi-agent systems with constraints of each agent and inter-agent ones. We overcome the challenge of the time-varying and position-dependent communication network with limited sensing range by introducing a truncated function for the smooth addition and deletion of links in the edge set, and design a distributed and locally Lipschitz-continuous safety-critical control law, composed of a nominal controller for the objectives such as consensus, formation, and position swapping, etc., and a safety controller, which only takes effect when some neighboring agent enters the custom-designed boundary set. Meanwhile, to rigorously verify the safety of the whole multi-agent system, a continuously differentiable control barrier function is proposed under a relaxed feasibility condition in the sense that it is imposed on each subsystem and only needed in the boundary area.},
  archive      = {J_AUTOM},
  author       = {Xiaoyu Wang and Yi Dong and Yiguang Hong and Karl Henrik Johansson},
  doi          = {10.1016/j.automatica.2025.112634},
  journal      = {Automatica},
  month        = {1},
  pages        = {112634},
  shortjournal = {Automatica},
  title        = {Distributed safety-critical control of nonlinear multi-agent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integral version of Lyapunov–Razumikhin conditions. <em>AUTOM</em>, <em>183</em>, 112633. (<a href='https://doi.org/10.1016/j.automatica.2025.112633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a retarded nonlinear system, this paper proposes a modification of the Lyapunov–Razumikhin method introducing a distributed integral of Lyapunov function for comparison with its current value instead of the maximum over delayed interval. The developed conditions are illustrated on different analysis problems presenting integral Halanay-type inequalities.},
  archive      = {J_AUTOM},
  author       = {Jian Wang and Denis Efimov and Alexander Aleksandrov},
  doi          = {10.1016/j.automatica.2025.112633},
  journal      = {Automatica},
  month        = {1},
  pages        = {112633},
  shortjournal = {Automatica},
  title        = {Integral version of Lyapunov–Razumikhin conditions},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed adaptive fixed-time formation tracking for heterogeneous multi-agent systems. <em>AUTOM</em>, <em>183</em>, 112632. (<a href='https://doi.org/10.1016/j.automatica.2025.112632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the problem of fixed-time time-varying formation tracking control (FTC) for heterogeneous linear multiagent systems (MASs) under the directed communication graph. It is assumed that the Laplacian matrix associated with the communication graph is unavailable and that the system matrices of the leader are only available to its neighboring followers. This differs from many existing works on fixed-time FTC problems where the communication graphs are typically undirected and protocol designs often rely on certain global information. A novel distributed observer is first put forward to estimate both the state and system matrices of the leader in fixed time. Then, an adaptive scheme is developed to solve the time-varying regulator equations resulting from the estimated leader system matrices in fixed time. Based on the proposed observer and the adaptive solutions to the regulator equations, a distributed adaptive fixed-time FTC protocol is further proposed via coordinate transformation techniques. It is shown that our proposed controllers do not require the input matrices of the followers to be of full row rank. It is also shown that the concerned fixed-time FTC problem can be solved with the proposed fixed-time FTC strategy in a distributed manner. Our results can be directly applied to solve both the adaptive fixed-time cooperative output regulation problem and the leader-following consensus problems of MASs under the directed graph. Finally, the effectiveness of the proposed fixed-time FTC strategy is demonstrated through a numerical example.},
  archive      = {J_AUTOM},
  author       = {Shiyu Zhou and Dong Sun and Gang Feng},
  doi          = {10.1016/j.automatica.2025.112632},
  journal      = {Automatica},
  month        = {1},
  pages        = {112632},
  shortjournal = {Automatica},
  title        = {Distributed adaptive fixed-time formation tracking for heterogeneous multi-agent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Estimation of the minimum and maximum states of charge of lithium-ion battery packs: A hybrid approach. <em>AUTOM</em>, <em>183</em>, 112630. (<a href='https://doi.org/10.1016/j.automatica.2025.112630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring the minimum and maximum states of charge (SOC) in lithium-ion battery packs is key to ensuring safe and reliable long-term operation. The challenge is that these SOCs cannot be directly measured and their corresponding cells within the pack may change with time. This paper proposes a novel hybrid scheme that estimates the minimum and maximum SOCs within a battery pack given by the series interconnection of equivalent circuit models. The estimation scheme relies on a mechanism that determines online two cells, which are candidates for having the minimum and maximum SOCs. The dimension of the hybrid estimator is independent of the number of cells, which makes it particularly attractive for large battery packs. Moreover, the estimator is endowed with robust, global convergence guarantees despite disturbances and measurement noise. Furthermore, Zeno behavior is ruled out as any solution to the considered system is shown to exhibit an average dwell-time. Numerical simulations illustrate the efficiency in terms of accuracy and computational time of the proposed estimator.},
  archive      = {J_AUTOM},
  author       = {Mira Khalil and Romain Postoyan and Stéphane Raël and Dragan Nešić},
  doi          = {10.1016/j.automatica.2025.112630},
  journal      = {Automatica},
  month        = {1},
  pages        = {112630},
  shortjournal = {Automatica},
  title        = {Estimation of the minimum and maximum states of charge of lithium-ion battery packs: A hybrid approach},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nature-inspired dynamic control for pursuit-evasion of robots. <em>AUTOM</em>, <em>183</em>, 112629. (<a href='https://doi.org/10.1016/j.automatica.2025.112629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pursuit-evasion problem is widespread in nature, engineering, and societal applications. It is commonly observed in nature that predators often exhibit faster speeds than their prey but have less agile maneuverability. Over millions of years of evolution, animals have developed effective and efficient strategies for pursuit and evasion. In this paper, we provide a dynamic framework for the pursuit-evasion problem of unicycle systems, drawing inspiration from nature. First, we address the scenario with one pursuer and one evader by proposing an Alert-Turn control strategy, which consists of two efficient ingredients: a sudden turning maneuver and an alert condition for starting and maintaining the maneuver. We present and analyze the escape and capture results at two levels: a lower level of a single run and a higher level with respect to parameters’ changes. In addition, we provide a theorem with sufficient conditions for capture. The Alert-Turn strategy is then extended to more complex scenarios involving multiple pursuers and evaders by integrating aggregation control laws and a target-changing mechanism. By adjusting a ‘selfish parameter’, the aggregation control commands produce various escape patterns of evaders: cooperative mode, selfish mode, and their combinations. The influence of the selfish parameter is quantified, and the target-changing mechanism is explored from a statistical perspective. Our findings align closely with observations in nature. Finally, the proposed strategies are validated through numerical simulations that replicate some chasing behaviors of animals in nature.},
  archive      = {J_AUTOM},
  author       = {Panpan Zhou and Sirui Li and Benyun Zhao and Bo Wahlberg and Xiaoming Hu},
  doi          = {10.1016/j.automatica.2025.112629},
  journal      = {Automatica},
  month        = {1},
  pages        = {112629},
  shortjournal = {Automatica},
  title        = {Nature-inspired dynamic control for pursuit-evasion of robots},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event/self-triggered cooperative control via reinforcement learning for a quadrotor team under multiple faults and denial-of-service attacks. <em>AUTOM</em>, <em>183</em>, 112628. (<a href='https://doi.org/10.1016/j.automatica.2025.112628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cooperative fault-tolerant control problem of a quadrotor team, subject to multiple faults and denial-of-service (DoS) attacks, is addressed via event/self-triggered strategies and reinforcement learning. Multiple under-actuated quadrotors with nonlinearities, couplings, and unknown dynamical parameters are introduced to achieve distributed cooperation. Event-triggered observers are developed to estimate position references under uncertain cyber faults and DoS attacks. Observer-based optimal controllers for the nominal position and attitude subsystems are learned by off-policy reinforcement learning without dynamical information. Fault-tolerant controllers are constructed by integrating the learned controllers and adaptive actuator fault compensators. A self-triggered strategy is further proposed to avoid continuous communication. The relationship among the time-varying topology coupled with cyber faults, the features of DoS attacks, and the closed-loop control system stability is analyzed, and the exclusion of Zeno behavior is proved. Simulation results illustrate the effectiveness of the proposed methods.},
  archive      = {J_AUTOM},
  author       = {Ziming Ren and Hao Liu and Hongwei Zhang and Ci Chen and Frank L. Lewis},
  doi          = {10.1016/j.automatica.2025.112628},
  journal      = {Automatica},
  month        = {1},
  pages        = {112628},
  shortjournal = {Automatica},
  title        = {Event/self-triggered cooperative control via reinforcement learning for a quadrotor team under multiple faults and denial-of-service attacks},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Convergence behaviors of nonlinear polar opinion dynamics in cooperative-antagonistic social networks. <em>AUTOM</em>, <em>183</em>, 112627. (<a href='https://doi.org/10.1016/j.automatica.2025.112627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates two kinds of convergence behaviors of nonlinear polar opinion dynamics over cooperative-antagonistic social networks determined by signed graphs. The first problem studies the neutralization of opinions over strongly connected and structurally unbalanced signed graphs, while the second problem focuses on the containment convergence to external stubborn agents over signed graphs under a variety of connectivity constraints. It is observed that various connectivity conditions induce the common intrinsic property that the involved generalized opposing Laplacian matrix is nonsingular. A stability framework is proposed that addresses both the existence of potential limiting behaviors as well as their convergence properties. This involves an analysis of the positiveness of the (opinion) susceptibility functions. The domains of attraction associated with the convergent behaviors are characterized. The solvability of both problems is provided, and the attracting domains are characterized precisely. The results are applied to blended social networks composed of three specialized opinion models. Simulations and comparisons are provided to illustrate the effectiveness of the paper’s results.},
  archive      = {J_AUTOM},
  author       = {Ti-Chung Lee and Ying Zhang and Youfeng Su and Iven Mareels},
  doi          = {10.1016/j.automatica.2025.112627},
  journal      = {Automatica},
  month        = {1},
  pages        = {112627},
  shortjournal = {Automatica},
  title        = {Convergence behaviors of nonlinear polar opinion dynamics in cooperative-antagonistic social networks},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Linear system analysis and optimal control of natural gas dynamics in pipeline networks. <em>AUTOM</em>, <em>183</em>, 112626. (<a href='https://doi.org/10.1016/j.automatica.2025.112626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design nonlinear and adaptive linear model-predictive control (MPC) techniques to minimize operational costs of compressor-actuated dynamics in natural gas pipeline networks. We establish stability of the local linear system and derive rigorous bounds on error between the nonlinear and linear system solutions. These bounds are used to quantify conditions under which the linear MPC can substitute the nonlinear MPC without significant loss of predictive accuracy. Furthermore, we prove and numerically verify that the computational cost of the linear MPC is orders of magnitude lower than that of solving the baseline optimal control problem. Numerical simulations are performed on nontrivial networks to demonstrate that the proposed MPC can effectively adapt to varying load conditions while maintaining nearly 95% optimality.},
  archive      = {J_AUTOM},
  author       = {Luke S. Baker and Sachin Shivakumar and Dieter Armbruster and Rodrigo B. Platte and Anatoly Zlotnik},
  doi          = {10.1016/j.automatica.2025.112626},
  journal      = {Automatica},
  month        = {1},
  pages        = {112626},
  shortjournal = {Automatica},
  title        = {Linear system analysis and optimal control of natural gas dynamics in pipeline networks},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive distributed observer design for nonlinear multiagent systems. <em>AUTOM</em>, <em>183</em>, 112625. (<a href='https://doi.org/10.1016/j.automatica.2025.112625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed state estimation is crucial for the leader-following control problem of multiagent systems (MASs). In this paper, adaptive distributed observers (DOs) are designed for a nonlinear autonomous leader system using only its output. Via system transformation, the DO design problem of the origin system is converted to that of a canonical system with lumped dynamics. When the lumped dynamics is parametric, an adaptive DO is developed to reconstruct the state and the unknown parameters under an undirected topology, which also addresses the distributed state/parameter estimation problem of an uncertain autonomous system with its dynamics in a parametric form. Then, the DO framework is extended to the case of non-parametric uncertainties, and a neural network (NN) DO is designed for reconstructing the state/lumped dynamics over a strongly connected digraph Finally, the effectiveness of the proposed DOs is demonstrated via numerical simulations.},
  archive      = {J_AUTOM},
  author       = {Jixing Lv and Changhong Wang and Lihua Xie},
  doi          = {10.1016/j.automatica.2025.112625},
  journal      = {Automatica},
  month        = {1},
  pages        = {112625},
  shortjournal = {Automatica},
  title        = {Adaptive distributed observer design for nonlinear multiagent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Simple sufficient conditions for integer stabilizability of discrete-time systems with relative degree one. <em>AUTOM</em>, <em>183</em>, 112624. (<a href='https://doi.org/10.1016/j.automatica.2025.112624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, firstly the concept of integer stabilizability is defined. It is discussed that the main motivation for introducing this concept is its helpfulness in achieving homomorphic encrypted control systems involving no computational overflow. Then, some simple sufficient conditions to ensure integer stabilizability of discrete-time systems described by transfer functions with relative degree one are derived. The usefulness of achievements of the paper is verified by a numerical example.},
  archive      = {J_AUTOM},
  author       = {Mohammad Saleh Tavazoei},
  doi          = {10.1016/j.automatica.2025.112624},
  journal      = {Automatica},
  month        = {1},
  pages        = {112624},
  shortjournal = {Automatica},
  title        = {Simple sufficient conditions for integer stabilizability of discrete-time systems with relative degree one},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel switching rule to observer-based control for switched systems. <em>AUTOM</em>, <em>183</em>, 112622. (<a href='https://doi.org/10.1016/j.automatica.2025.112622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores observer-based control for switched systems subject to partially unknown sojourn probability information. To more accurately capture the dynamic nature of switched systems, a novel switching rule related to duration time is devised, in which the system switching is governed by a joint distribution function. This function uniquely integrates both the current system mode and its duration, effectively addressing the challenges of incompleteness in probability information. Distinct from the conventional semi-Markov kernel technique, the sojourn probabilities involve fewer parameters and can be more readily measured using statistical techniques, thereby lessening computational burden. Additionally, a non-monotonic Lyapunov function is constructed, leading to less conservative conditions that ensure the mean-square stability of the switched systems. Eventually, the effectiveness and superiority of the devised methodology are verified through a practical example.},
  archive      = {J_AUTOM},
  author       = {Jun Cheng and Tianfeng Tang and Huaicheng Yan and Zheng-Guang Wu and Dan Zhang},
  doi          = {10.1016/j.automatica.2025.112622},
  journal      = {Automatica},
  month        = {1},
  pages        = {112622},
  shortjournal = {Automatica},
  title        = {A novel switching rule to observer-based control for switched systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sampled-data primal–dual gradient dynamics in model predictive control. <em>AUTOM</em>, <em>183</em>, 112621. (<a href='https://doi.org/10.1016/j.automatica.2025.112621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model predictive control (MPC) can incur computational burden that exceeds what the application warrants, sometimes even for linear systems. Recently, a rapid computation method that guides the input toward convergence with the optimal control problem solution by employing primal–dual gradient (PDG) dynamics has been proposed for linear MPCs. However, stability has been ensured under the assumption that the controller is a continuous-time system, leading to potential instability when the controller undergoes discretization and is implemented as a sampled-data system. In this paper, we propose a discrete-time dynamical controller incorporating specific modifications to the PDG approach and present stability conditions. Additionally, we introduce an extension to enhance control performance that was traded off in the original. Numerical examples substantiate that our proposed method, which can be executed in only 1 μ s on a commodity laptop, not only ensures stability considering sampled-data implementation but also substantially enhances the control performance.},
  archive      = {J_AUTOM},
  author       = {Ryuta Moriyasu and Sho Kawaguchi and Kenji Kashima},
  doi          = {10.1016/j.automatica.2025.112621},
  journal      = {Automatica},
  month        = {1},
  pages        = {112621},
  shortjournal = {Automatica},
  title        = {Sampled-data primal–dual gradient dynamics in model predictive control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cooperative dynamic surrounding coverage control for multi-autonomous surface vehicle fleets with limited sensing ranges. <em>AUTOM</em>, <em>183</em>, 112620. (<a href='https://doi.org/10.1016/j.automatica.2025.112620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative surrounding coverage by a multi-autonomous surface vehicle (ASV) fleet involves dynamic coverage with concentric moving trajectories. This low-cost form of coverage, which operates with limited perceptual ranges, has long presented a significant challenge in real-world collective marine detection applications. To this end, the paper establishes a surrounding coverage control framework that minimizes the required number of ASVs by covering a designated region across multiple consecutive periods. A distributed randomized gradient-free (DRGF) protocol is thereby proposed to identify the optimal central point of the coverage region. Accordingly, a distributed control law is designed to regulate the ASV dynamic surrounding coverage operation around the optimal concentric point. Significantly, sufficient conditions are derived to guarantee the asymptotical convergence of the closed-loop multi-ASV fleet governed by the present DGRF. Finally, experiments are conducted on a self-established lake-based multi-ASV fleet platform to verify the effectiveness of the present surrounding coverage scheme.},
  archive      = {J_AUTOM},
  author       = {Jiayu Zou and Hai-Tao Zhang and Bin Liu and Xiaohua Liu and Jianing Ding and Ning Xing and Shiqi Fu and Lijun Zhu},
  doi          = {10.1016/j.automatica.2025.112620},
  journal      = {Automatica},
  month        = {1},
  pages        = {112620},
  shortjournal = {Automatica},
  title        = {Cooperative dynamic surrounding coverage control for multi-autonomous surface vehicle fleets with limited sensing ranges},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asynchronous resilient collision-free formation control for nonlinear MASs under DoS attacks. <em>AUTOM</em>, <em>183</em>, 112619. (<a href='https://doi.org/10.1016/j.automatica.2025.112619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-agent systems (MASs) exchange the communication information by the communication network, which is vulnerable to denial-of-service (DoS) attacks. DoS attacks can disrupt the communication channels and result in the collisions between agents, thus it is an important and challenging topic to study the collision avoidance formation control issue under DoS attacks. This paper investigates the asynchronous resilient collision-free formation control issue for nonlinear MASs with DoS attacks. An asynchronous resilient distributed observer is proposed to estimate the output information of leader under DoS attacks. Based on the designed distributed observer and by constructing two high-order filters, an asynchronous resilient collision-free formation control method is presented by backstepping control design theory. The presented formation control method can ensure that the formation tracking errors asymptotically converge to zero, and the collision avoidance objective is realized. Moreover, the non-differentiable problem of virtual controllers is solved. Finally, we apply the developed formation control method to multiple Euler-Lagrangian (EL) systems, the simulation and comparison results verify its effectiveness.},
  archive      = {J_AUTOM},
  author       = {Jun Zhang and Jun Ning and Shaocheng Tong},
  doi          = {10.1016/j.automatica.2025.112619},
  journal      = {Automatica},
  month        = {1},
  pages        = {112619},
  shortjournal = {Automatica},
  title        = {Asynchronous resilient collision-free formation control for nonlinear MASs under DoS attacks},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sector stabilization criterion of a novel nonlinear flexible marine riser coupled system. <em>AUTOM</em>, <em>183</em>, 112618. (<a href='https://doi.org/10.1016/j.automatica.2025.112618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes a sector stabilization criterion for a nonlinear flexible marine riser system that incorporates lateral and transverse coupling vibrations, derived from Hamilton’s principle. This criterion, grounded in the sector-bounded condition, encompasses a wide range of linear and nonlinear feedback control laws applied to the transverse and lateral directions at the top boundary of the flexible marine riser, respectively. In the analysis, the nonlinear semigroup theory is utilized to establish the well-posedness of the resulting closed-loop coupled system. Notably, the solution demonstrates continuous dependence on the initial conditions. Furthermore, the exponential stability of the closed-loop coupled system is achieved by employing a generalized Gronwall-type integral inequality and the integral multiplier method, which involves the innovative development of an energy-like functional. To demonstrate the effectiveness of the proposed controls, numerical simulations utilizing the finite element method are presented.},
  archive      = {J_AUTOM},
  author       = {Yi Cheng and Xin Wang and Yuhu Wu and Bao-Zhu Guo},
  doi          = {10.1016/j.automatica.2025.112618},
  journal      = {Automatica},
  month        = {1},
  pages        = {112618},
  shortjournal = {Automatica},
  title        = {Sector stabilization criterion of a novel nonlinear flexible marine riser coupled system},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global exponential stabilization of 2 × 2 linear hyperbolic PDEs via dynamic event-triggered backstepping control. <em>AUTOM</em>, <em>183</em>, 112617. (<a href='https://doi.org/10.1016/j.automatica.2025.112617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces novel dynamic event-triggered control (ETC) mechanisms for 2 × 2 linear hyperbolic PDEs in three configurations: continuous-time event-triggered control (CETC), periodic event-triggered control (PETC), and self-triggered control (STC). These mechanisms ensure global exponential stability (GES) under ETC using PDE backstepping, with stability estimates provided in the spatial L 2 norm of the states. The proposed CETC and PETC designs are observer-based and require continuous boundary measurements collocated with the actuation. In contrast, the STC design requires full-state measurements; however, unlike CETC and PETC, it does not require continuous measurements for the triggering mechanism—only measurements taken at event times. In the CETC design, a lower bound on the time between two consecutive events is enforced, and a dynamic variable with appropriately designed switching dynamics is introduced. By employing a novel Lyapunov functional, GES of the closed-loop system is established under zero-order hold implementation of the backstepping control between events. Events are triggered when the dynamic variable crosses zero from the positive side, after which it is immediately reset to an appropriate nonnegative value. Detecting events, therefore, necessitates continuous monitoring of this dynamic variable. To address this limitation, PETC and STC strategies are proposed. The PETC design identifies a suitable triggering condition that requires only periodic checks and derives an upper bound on the allowable sampling period. This PETC approach preserves the GES guaranteed by CETC without requiring continuous monitoring of a triggering condition, although it still relies on continuous measurements. Unlike CETC and PETC, STC requires neither continuous measurements nor monitoring of a triggering condition. Instead, at each event, STC computes the time to the next event — beyond a suitably enforced minimal dwell-time — using only measurements taken at events. Despite relying solely on event-triggered measurements, STC is capable of guaranteeing GES of the closed-loop system. The well-posedness of the closed-loop systems under all three strategies is established. A simulation study is provided to illustrate the theoretical results.},
  archive      = {J_AUTOM},
  author       = {Bhathiya Rathnayake and Mamadou Diagne},
  doi          = {10.1016/j.automatica.2025.112617},
  journal      = {Automatica},
  month        = {1},
  pages        = {112617},
  shortjournal = {Automatica},
  title        = {Global exponential stabilization of 2 × 2 linear hyperbolic PDEs via dynamic event-triggered backstepping control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Signal temporal logic control synthesis among uncontrollable dynamic agents with conformal prediction. <em>AUTOM</em>, <em>183</em>, 112616. (<a href='https://doi.org/10.1016/j.automatica.2025.112616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of dynamical systems under temporal logic specifications among uncontrollable dynamic agents is challenging due to the agents’ a-priori unknown behavior. Existing works have considered the problem where either all agents are controllable, the agent models are deterministic and known, or no safety guarantees are provided. We propose a predictive control synthesis framework that guarantees, with high probability, the satisfaction of signal temporal logic (STL) tasks that are defined over a controllable system in the presence of uncontrollable stochastic agents. We use trajectory predictors and conformal prediction to construct probabilistic prediction regions for each uncontrollable agent that are valid over multiple future time steps. Specifically, we construct a normalized prediction region over all agents and time steps to reduce conservatism and increase data efficiency. We then formulate a worst-case bilevel mixed integer program (MIP) that accounts for all agent realizations within the prediction region to obtain an open-loop controller that provably guarantee task satisfaction with high probability. To efficiently solve this bilevel MIP, we propose an equivalent MIP program based on KKT conditions of the original bilevel formulation. Building upon this, we design a closed-loop controller, where both recursive feasibility and task satisfaction can be guaranteed with high probability. We illustrate our control synthesis framework on two case studies.},
  archive      = {J_AUTOM},
  author       = {Xinyi Yu and Yiqi Zhao and Xiang Yin and Lars Lindemann},
  doi          = {10.1016/j.automatica.2025.112616},
  journal      = {Automatica},
  month        = {1},
  pages        = {112616},
  shortjournal = {Automatica},
  title        = {Signal temporal logic control synthesis among uncontrollable dynamic agents with conformal prediction},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-triggered boundary estimation for 2 × 2 hyperbolic PDEs with disturbance. <em>AUTOM</em>, <em>183</em>, 112615. (<a href='https://doi.org/10.1016/j.automatica.2025.112615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the event-triggered boundary estimation problem for 2 × 2 linear hyperbolic partial differential equations (PDEs) subject to disturbances. These disturbances enter the PDEs through the boundary and are represented as an ordinary differential equation (ODE). The scenario considered involves transmitting boundary measurements to the observer only when necessary, as determined by a dynamic event-triggering condition. This approach aims to conserve communication and computational resources. The event-triggered observer is designed using the backstepping method, and an event-triggering condition is proposed to determine the time instants when sampled measurements should be transmitted. Under this event-triggered estimation mechanism, a minimal dwell-time between consecutive triggering time instants is guaranteed. Furthermore, the well-posedness of the solutions and the exponential convergence of the estimation error are ensured. Finally, the obtained results are applied to the Saint-Venant equations to demonstrate the effectiveness of the event-triggered estimation method.},
  archive      = {J_AUTOM},
  author       = {Yan Zhao and Rafael Vazquez},
  doi          = {10.1016/j.automatica.2025.112615},
  journal      = {Automatica},
  month        = {1},
  pages        = {112615},
  shortjournal = {Automatica},
  title        = {Event-triggered boundary estimation for 2 × 2 hyperbolic PDEs with disturbance},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven unknown-input observers. <em>AUTOM</em>, <em>183</em>, 112614. (<a href='https://doi.org/10.1016/j.automatica.2025.112614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown inputs related to, e.g., sensor aging, modeling errors, or device bias, represent a major concern in wireless sensor networks, as they degrade the state estimation performance. To improve the performance, unknown-input observers (UIOs) have been proposed. Most of the results available to design UIOs are based on explicit system models, which can be difficult or impossible to obtain in real-world applications. Data-driven techniques, on the other hand, have become a viable alternative for the design and analysis of unknown systems using only data. In this context, a novel data-driven distributed unknown-input observer (D-DUIO) for unknown continuous-time linear time-invariant (LTI) systems is developed, which requires solely some data collected offline, without any prior knowledge of the system matrices. In the paper, first, a model-based approach to the design of a DUIO is presented. A sufficient condition for the existence of such a DUIO is recalled, and a new one is proposed, that is prone to a data-driven adaptation. Moving to a data-driven approach, it is shown that under suitable assumptions on the input/output/state data collected from the continuous-time system, it is possible to both claim the existence of a D-DUIO and to derive its matrices in terms of the matrices of pre-collected data. Finally, the efficacy of the D-DUIO is illustrated by means of numerical examples.},
  archive      = {J_AUTOM},
  author       = {Yuzhou Wei and Giorgia Disarò and Wenjie Liu and Jian Sun and Maria Elena Valcher and Gang Wang},
  doi          = {10.1016/j.automatica.2025.112614},
  journal      = {Automatica},
  month        = {1},
  pages        = {112614},
  shortjournal = {Automatica},
  title        = {Distributed data-driven unknown-input observers},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robustness of supervisory controllers subject to measurement disturbances. <em>AUTOM</em>, <em>183</em>, 112613. (<a href='https://doi.org/10.1016/j.automatica.2025.112613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the supervisory control problem for a class of uncertain nonlinearly parameterized systems in the presence of measurement disturbance. Based on the well-established estimator-based supervisory control structure, a robustification of supervisory controller dealing with measurement disturbance is developed taking advantage of the monitoring signals redesign, such that the plant state asymptotically converges to a given set-point or its neighborhood, subject to the vanishing or the persistent measurement disturbance, respectively. Moreover, a constructive design of the multi-estimator using measurement feedback is proposed for the supervisory control of a class of uncertain nonlinearly parameterized systems in the strict-feedback form. A numerical simulation based on an uncertain mass–spring system is given to show the efficacy of our proposed algorithm, in which we use an event-trigger to be a measurement disturbance generator.},
  archive      = {J_AUTOM},
  author       = {Yutian Wang and Qingkai Meng and Yi Jiang},
  doi          = {10.1016/j.automatica.2025.112613},
  journal      = {Automatica},
  month        = {1},
  pages        = {112613},
  shortjournal = {Automatica},
  title        = {Robustness of supervisory controllers subject to measurement disturbances},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-driven min–max MPC for linear systems: Robustness and adaptation. <em>AUTOM</em>, <em>183</em>, 112612. (<a href='https://doi.org/10.1016/j.automatica.2025.112612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven controllers design is an important research problem, in particular when data is corrupted by the noise. In this paper, we propose a data-driven min–max model predictive control (MPC) scheme using noisy input-state data for unknown linear time-invariant (LTI) system. The unknown system matrices are characterized by a set-membership representation using the noisy input-state data. Leveraging this representation, we derive an upper bound on the worst-case cost and determine the corresponding optimal state-feedback control law through a semidefinite program (SDP). We prove that the resulting closed-loop system is robustly stabilized and satisfies the input and state constraints. Further, we propose an adaptive data-driven min–max MPC scheme which exploits additional online input-state data to improve closed-loop performance. Numerical examples show the effectiveness of the proposed methods.},
  archive      = {J_AUTOM},
  author       = {Yifan Xie and Julian Berberich and Frank Allgöwer},
  doi          = {10.1016/j.automatica.2025.112612},
  journal      = {Automatica},
  month        = {1},
  pages        = {112612},
  shortjournal = {Automatica},
  title        = {Data-driven min–max MPC for linear systems: Robustness and adaptation},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Local practically safe extremum seeking with assignable rate of attractivity to the safe set. <em>AUTOM</em>, <em>183</em>, 112611. (<a href='https://doi.org/10.1016/j.automatica.2025.112611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Assignably Safe Extremum Seeking (ASfES), an algorithm designed to minimize a measured, static objective function while maintaining a measured, static metric of safety (a control barrier function or CBF) to be positive in a practical sense. We ensure that for trajectories with safe initial conditions, the violation of safety can be made arbitrarily small through appropriately chosen design constants. We also guarantee an assignable “attractivity” rate: from unsafe initial conditions, the trajectories approach the safe set, in the sense of the measured CBF, at a rate no slower than a user-assigned rate. Similarly, from safe initial conditions, the trajectories approach the unsafe set, in the sense of the CBF, no faster than the assigned attractivity rate. The feature of assignable attractivity is not present in the semiglobal version of safe extremum seeking, where the semiglobality of convergence is achieved by slowing the adaptation. We also demonstrate local convergence of the parameter to a neighborhood of the minimum of a quadratic objective function constrained to the safe set with a linear CBF. The ASfES algorithm and analysis are multivariable, but we also extend the algorithm to a Newton-Based ASfES scheme which we show is only useful in the scalar case. The proven properties of the designs are illustrated through simulation examples.},
  archive      = {J_AUTOM},
  author       = {Alan Williams and Miroslav Krstic and Alexander Scheinker},
  doi          = {10.1016/j.automatica.2025.112611},
  journal      = {Automatica},
  month        = {1},
  pages        = {112611},
  shortjournal = {Automatica},
  title        = {Local practically safe extremum seeking with assignable rate of attractivity to the safe set},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Secondary safety control for systems with sector bounded nonlinearities. <em>AUTOM</em>, <em>183</em>, 112610. (<a href='https://doi.org/10.1016/j.automatica.2025.112610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of safety verification and safety-aware controller synthesis for systems with sector bounded nonlinearities. We aim to keep the states of the system within a given safe set under potential actuator and sensor attacks. Specifically, we adopt the setup that a controller has already been designed to stabilize the plant. Using invariant sets and barrier certificate theory, we first give sufficient conditions to verify the safety of the closed-loop system under attacks. Furthermore, by using a subset of sensors that are assumed to be free of attacks, we provide a synthesis method for a secondary controller that enhances the safety of the system. The sufficient conditions to verify safety are derived using Lyapunov-based tools and the S -procedure. Using the projection lemma, the conditions are then formulated as linear matrix inequality (LMI) problems which can be solved efficiently. Lastly, our theoretical results are illustrated through numerical simulations.},
  archive      = {J_AUTOM},
  author       = {Yankai Lin and Michelle S. Chong and Carlos Murguia},
  doi          = {10.1016/j.automatica.2025.112610},
  journal      = {Automatica},
  month        = {1},
  pages        = {112610},
  shortjournal = {Automatica},
  title        = {Secondary safety control for systems with sector bounded nonlinearities},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Non-parametric IQC multipliers in data-driven robust controller synthesis. <em>AUTOM</em>, <em>183</em>, 112608. (<a href='https://doi.org/10.1016/j.automatica.2025.112608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a robust data-driven controller synthesis method for generalised multi-input multi-output (MIMO) systems. Using the frequency response of a linear time-invariant (LTI) MIMO system and characterising perturbations through Integral Quadratic Constraint (IQC), the method provides a convex set of controllers robust to perturbations. This facilitates the design of controllers with either robust stability or robust performance criteria. Notably, the proposed method is versatile, as it is also applicable for non-parametric IQC multipliers. An example of a non-parametric IQC multiplier for elliptical uncertainty quantification is demonstrated and subsequently employed in designing a robust controller for a hybrid active-passive micro-vibration platform. Experimental results show that the synthesised controller effectively achieves the desired levels of both robustness and performance.},
  archive      = {J_AUTOM},
  author       = {Vaibhav Gupta and Elias Klauser and Alireza Karimi},
  doi          = {10.1016/j.automatica.2025.112608},
  journal      = {Automatica},
  month        = {1},
  pages        = {112608},
  shortjournal = {Automatica},
  title        = {Non-parametric IQC multipliers in data-driven robust controller synthesis},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Iterative learning control for performance-driven switched systems under all unknown channel gains. <em>AUTOM</em>, <em>183</em>, 112607. (<a href='https://doi.org/10.1016/j.automatica.2025.112607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fading channels introduce random and unknown gains into signal transmission, which has a great impact on the accuracy of the transmitted data, thus affecting system stability. However, there are few studies on this regard in the control field. In this paper, the transmission of both feedback and switching signals is affected by the unknown channel gains, which induces severe mode asynchronization in the switched systems under iterative learning control (ILC). For the faded switching signals, by designing a calibration-rounding mechanism (CRM) to recover it, the asynchronous time can gradually decrease with the iteration, and finally the system achieves synchronization, that is calibration-rounding-based iterative synchronization (CRIS). For the faded feedback signals, an improved gain estimation mechanism (IGEM) is given to correct the signal faster with fewer iterations. Moreover, a novel tracking performance-driven switching law (TPD-SL) is proposed to reasonably schedule subsystems for obtaining optimal performance. A set of new average dwell time (ADT) conditions with the minimum synchronization time is obtained. Finally, the effectiveness of the method is verified by numerical simulations.},
  archive      = {J_AUTOM},
  author       = {Yiwen Qi and Ziyu Qu and Dong Shen},
  doi          = {10.1016/j.automatica.2025.112607},
  journal      = {Automatica},
  month        = {1},
  pages        = {112607},
  shortjournal = {Automatica},
  title        = {Iterative learning control for performance-driven switched systems under all unknown channel gains},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Induced norm analysis of linear systems for nonnegative input signals. <em>AUTOM</em>, <em>183</em>, 112606. (<a href='https://doi.org/10.1016/j.automatica.2025.112606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the analysis of the L p ( p ∈ [ 1 , ∞ ) , p = ∞ ) induced norms of continuous-time linear systems where input signals are restricted to be nonnegative. This norm is referred to as the L p + induced norm in this paper. It has been shown recently that the L 2 + induced norm is effective for the stability analysis of nonlinear feedback systems where the nonlinearity returns only nonnegative signals. However, the exact computation of the L 2 + induced norm is essentially difficult. To get around this difficulty, in the first part of this paper, we provide a copositive-programming-based method for the upper bound computation by capturing the nonnegativity of the input signals by copositive multipliers. In the second part, we consider how far the L 2 + induced norm can be smaller than the standard L 2 induced norm, and derive the uniform infimum on the ratio of the L 2 + induced norm to the L 2 induced norm over all linear systems including infinite-dimensional ones. Then, for each linear system, we finally derive a computation method of the lower bounds of the L 2 + induced norm that are larger than (or equal to) the value determined by the uniform infimum. The effectiveness of the upper/lower bound computation methods is illustrated by numerical examples.},
  archive      = {J_AUTOM},
  author       = {Yoshio Ebihara and Noboru Sebe and Hayato Waki and Dimitri Peaucelle and Sophie Tarbouriech and Victor Magron and Tomomichi Hagiwara},
  doi          = {10.1016/j.automatica.2025.112606},
  journal      = {Automatica},
  month        = {1},
  pages        = {112606},
  shortjournal = {Automatica},
  title        = {Induced norm analysis of linear systems for nonnegative input signals},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed fault-tolerant control for a class of uncertain cascaded ODE-PDE multi-agent systems. <em>AUTOM</em>, <em>183</em>, 112605. (<a href='https://doi.org/10.1016/j.automatica.2025.112605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed fault-tolerant control is proposed for a class of uncertain cascaded ordinary differential equation (ODE)-partial differential equation (PDE) multi-agents. For the cascaded system under consideration, the output of ODEs serves as the input signal of PDEs such that a distributed control involving states of the ODE as well as the PDE system is expected to be designed for consensus tracking. Based on the designed distributed control, where the actuator is assumed to be healthy, a distributed fault-tolerant control is designed to guarantee the performance of the system, and it is further improved to deal with actuator failures. To enhance the robustness of the cascaded system, the system uncertainties and the external disturbances of both followers and leader are compensated using adaptive laws and an adaptive distributed observer, based on which the stabilization of the cascaded ODE-PDE multi-agent system can be achieved with partially known agents’ information. Simulation results are carried out to prove the effectiveness of the proposed method.},
  archive      = {J_AUTOM},
  author       = {Xueyan Xing and Guoqiang Hu},
  doi          = {10.1016/j.automatica.2025.112605},
  journal      = {Automatica},
  month        = {1},
  pages        = {112605},
  shortjournal = {Automatica},
  title        = {Distributed fault-tolerant control for a class of uncertain cascaded ODE-PDE multi-agent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A compensation-oriented algorithm for difference-driven identification under binary-valued observations and data packet dropout. <em>AUTOM</em>, <em>183</em>, 112604. (<a href='https://doi.org/10.1016/j.automatica.2025.112604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the identification problem for finite impulse response (FIR) systems with binary-valued observations under event-triggered communication mechanism and data packet dropout. The challenge lies in the inability to distinguish between untriggered events and packet loss when no information is received, which prevents us from obtaining the statistical properties of the binary-valued sequence. A compensation-oriented difference-driven identification (CODD) algorithm is proposed to estimate the parameter by recovering the mean of the original binary-valued sequence, where different values for the observation estimates are assigned when receiving 0, 1 or nothing. Even though, the convergence analysis of the parameter estimate is still challenging since the assigned values are dependent. To tackle this difficulty, the estimate error is divided into two parts: an initial assigned value related part, which is demonstrated to be convergent through the construction of an auxiliary set, and the remaining component, which happens to be a convergent martingale-difference sequence. As a result, the almost sure convergence and the asymptotic normality of the CODD algorithm are established when data packet loss probability is less than 1 2 . By calculating the communication rate, it is proven that the difference-driven mechanism can save 50% of the communication cost compared to original binary-valued systems. Furthermore, when data packet loss probability is high, an m -channel compensation-oriented identification ( m -CODD) algorithm is constructed by utilizing retransmission of the each observation for m times, which is designed based on the packet loss probability. The properties of m -CODD algorithm including convergence, asymptotic normality and communication rate are established. Numerical simulations are illustrated to show the theoretical results.},
  archive      = {J_AUTOM},
  author       = {Tianning Han and Ying Wang and Jin Guo and Yanlong Zhao},
  doi          = {10.1016/j.automatica.2025.112604},
  journal      = {Automatica},
  month        = {1},
  pages        = {112604},
  shortjournal = {Automatica},
  title        = {A compensation-oriented algorithm for difference-driven identification under binary-valued observations and data packet dropout},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed nash equilibrium seeking for aggregative games of linear systems subject to unknown disturbances. <em>AUTOM</em>, <em>183</em>, 112603. (<a href='https://doi.org/10.1016/j.automatica.2025.112603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the distributed Nash equilibrium seeking problem for aggregative games of N players subject to unknown disturbances over strongly connected networks. Compared with existing works, the general linear dynamics, general directed and strongly connected networks, as well as unknown disturbances are tackled simultaneously in the aggregative games. First, by introducing certain coordinate transformation and feedback linearization method, we develop a distributed gradient-based Nash equilibrium seeking law. A dynamic average consensus dynamics is designed to deal with the challenge by unbalance of general strongly connected networks. By the graph-related property and converse Lyapunov theorem, we establish the global exponential stability of a linear system and a class of nonlinear systems, respectively. Then, we propose a gain design method to obtain the stability of the nonlinear closed-loop system, which is not in the lower triangular form. Inspired by the output regulation theory, we design an internal model and an adaptive dynamics to tackle the unknown disturbances. Resorting to the perturbation theory and the internal model principle, we demonstrate that distributed Nash equilibrium seeking for aggregative games of N players with general linear systems subject to unknown disturbances over strongly connected networks can be achieved. Finally, the effectiveness of the proposed distributed Nash equilibrium seeking approaches are verified by their applications to some simulation examples.},
  archive      = {J_AUTOM},
  author       = {Lupeng Liu and Fang Deng and Jie Chen and Maobin Lu},
  doi          = {10.1016/j.automatica.2025.112603},
  journal      = {Automatica},
  month        = {1},
  pages        = {112603},
  shortjournal = {Automatica},
  title        = {Distributed nash equilibrium seeking for aggregative games of linear systems subject to unknown disturbances},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive fault-tolerant control of nonlinear systems: A self-regulating spatiotemporal performance approach. <em>AUTOM</em>, <em>183</em>, 112602. (<a href='https://doi.org/10.1016/j.automatica.2025.112602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of performance constraints of uncertain nonlinear systems with actuator faults. Particularly, by developing the boundary threshold triggering strategy, the performance boundaries would be updated adaptively once the distance between the tracking error and the performance boundaries is smaller than the given threshold. Moreover, compared with the existing works, the transient behaviors are improved, and the limitation imposed on the initial conditions is removed attributed to the construction of novel performance functions and error transformation. Then, an adaptive fault-tolerant control scheme with self-regulating spatiotemporal performance is designed for a class of nonlinear systems with non-parametric uncertainties. It is shown that both the boundedness of the closed-loop signals and the satisfactory performance constraints are guaranteed in the presence of unpredictable actuator failure. The effectiveness of the proposed method is verified by theoretical analysis and numerical simulation.},
  archive      = {J_AUTOM},
  author       = {Zeqiang Li and Jason J.R. Liu and Yongduan Song},
  doi          = {10.1016/j.automatica.2025.112602},
  journal      = {Automatica},
  month        = {1},
  pages        = {112602},
  shortjournal = {Automatica},
  title        = {Adaptive fault-tolerant control of nonlinear systems: A self-regulating spatiotemporal performance approach},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fully coupled nonlinear FBS△Es: Solvability and LQ control insights. <em>AUTOM</em>, <em>183</em>, 112601. (<a href='https://doi.org/10.1016/j.automatica.2025.112601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a class of fully coupled nonlinear forward–backward stochastic difference equations (FBS △ Es) is proposed and the existence of solutions is proved based on a linear-quadratic (LQ) optimal control problem. Inspired from the solvability studies of various forward–backward stochastic differential equations (FBSDEs), the dominant-monotone framework is discretized and a continuum approach is used to prove the unique solvability of the fully coupled FBS △ Es and to obtain a pair of estimates on the solutions, and finally, the conclusions are applied to the related LQ problem.},
  archive      = {J_AUTOM},
  author       = {Zhipeng Niu and Qingxin Meng and Xun Li and Maoning Tang},
  doi          = {10.1016/j.automatica.2025.112601},
  journal      = {Automatica},
  month        = {1},
  pages        = {112601},
  shortjournal = {Automatica},
  title        = {Fully coupled nonlinear FBS△Es: Solvability and LQ control insights},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Aerial target encirclement and interception with noisy range observations. <em>AUTOM</em>, <em>183</em>, 112600. (<a href='https://doi.org/10.1016/j.automatica.2025.112600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a strategy to encircle and intercept a non-cooperative aerial point-mass moving target by leveraging noisy range measurements for state estimation. In this approach, the guardians actively ensure the observability of the target by using an anti-synchronization (AS), 3D “vibrating string” trajectory, which enables rapid position and velocity estimation based on the Kalman filter. Additionally, a novel anti-target controller is designed for the guardians to enable adaptive transitions from encircling a protected target to encircling, intercepting, and neutralizing a hostile target, taking into consideration the input constraints of the guardians. Based on the guaranteed uniform observability, the exponentially bounded stability of the state estimation error and the convergence of the encirclement error are rigorously analyzed. Simulation results and real-world UAV experiments are presented to further validate the effectiveness of the system design.},
  archive      = {J_AUTOM},
  author       = {Fen Liu and Shenghai Yuan and Thien-Minh Nguyen and Wei Meng and Lihua Xie},
  doi          = {10.1016/j.automatica.2025.112600},
  journal      = {Automatica},
  month        = {1},
  pages        = {112600},
  shortjournal = {Automatica},
  title        = {Aerial target encirclement and interception with noisy range observations},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stochastic gradient hamiltonian sequential monte carlo filter with earth mover’s distance sampling for target tracking. <em>AUTOM</em>, <em>183</em>, 112599. (<a href='https://doi.org/10.1016/j.automatica.2025.112599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed missile tracking requires advanced filtering algorithms to overcome the limitations of traditional nonlinear methods. This study presents the stochastic gradient Hamiltonian sequential Monte Carlo filter, combining stochastic gradient Hamilton Monte Carlo with sequential Monte Carlo (SMC) for enhanced sampling performance and reduced computational burden. The method incorporates Earth Mover’s Distance based adaptive resampling with theoretical bounds for optimal particle count. Validation through univariate nonstationary growth model simulation and bearing-only tracking experiments demonstrates superior performance over conventional methods, achieving 15 % root mean square error improvement compared to conventional SMC and 30 % over extended Kalman filter/unscented Kalman filter approaches.},
  archive      = {J_AUTOM},
  author       = {Chang Ho Kang and Sun Young Kim},
  doi          = {10.1016/j.automatica.2025.112599},
  journal      = {Automatica},
  month        = {1},
  pages        = {112599},
  shortjournal = {Automatica},
  title        = {Stochastic gradient hamiltonian sequential monte carlo filter with earth mover’s distance sampling for target tracking},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed nash equilibrium seeking with a dynamic set of players. <em>AUTOM</em>, <em>183</em>, 112598. (<a href='https://doi.org/10.1016/j.automatica.2025.112598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formulates a new distributed Nash equilibrium seeking problem with a dynamic set of players in which players are allowed to join and leave the network in a free manner during the decision-making process. To accommodate the dynamic joining and leaving behaviors of the players, a status estimation mechanism, which is capable of estimating in a finite time whether the players are active or inactive, is introduced. Based on the status estimation mechanism, a gradient play based algorithm is developed for distributed Nash equilibrium seeking in the dynamic environment. It is shown that under strongly connected communication graphs, players’ actions are convergent to a small neighborhood of the new Nash equilibrium linearly every time the player set changes. Moreover, the convergence accuracy and convergence rate can be adjusted by suitably tuning the step-size. To cover more general communication scenarios, strongly connected graphs are further relaxed to be B-jointly connected graphs, under which the convergence properties of the proposed algorithm are analytically studied. Furthermore, the upper bound of the average tracking error is quantified to evaluate the dynamic performance of the proposed algorithm. In the last, a simulation study on energy consumption games is given to verify the effectiveness of the proposed algorithm.},
  archive      = {J_AUTOM},
  author       = {Yuxuan Liu and Maojiao Ye and Lei Ding and Lihua Xie and Qing-Long Han},
  doi          = {10.1016/j.automatica.2025.112598},
  journal      = {Automatica},
  month        = {1},
  pages        = {112598},
  shortjournal = {Automatica},
  title        = {Distributed nash equilibrium seeking with a dynamic set of players},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Constrained finite-time and fixed-time stabilization for linear systems: Adaptive implicit lyapunov function-based control. <em>AUTOM</em>, <em>183</em>, 112597. (<a href='https://doi.org/10.1016/j.automatica.2025.112597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, finite-time and fixed-time stabilization problems are investigated for single-input single-output (SISO) linear system under the control input constraint. The achievement of finite-time or fixed-time convergence rates is facilitated through the utilization of adaptive implicit Lyapunov function (ILF)-based control. For ease of practical implementation, the dynamics of Approximated-ILF (AILF) guarantees the precise estimation of ILF, while the stability of AILF-based control holds established. Furthermore, from both performance and input-constrained safety considerations, the anti-windup (AW) AILF endows the system with tolerance to saturation and maintains the non-asymptotic convergence properties. Numerical simulations support the obtained theoretical results and verify their effectiveness.},
  archive      = {J_AUTOM},
  author       = {Peng Wang and Mou Chen and Shuzhi Sam Ge and Xiaobing Zhang},
  doi          = {10.1016/j.automatica.2025.112597},
  journal      = {Automatica},
  month        = {1},
  pages        = {112597},
  shortjournal = {Automatica},
  title        = {Constrained finite-time and fixed-time stabilization for linear systems: Adaptive implicit lyapunov function-based control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Input-to-state stability of self-triggered impulsive control systems. <em>AUTOM</em>, <em>183</em>, 112596. (<a href='https://doi.org/10.1016/j.automatica.2025.112596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the local input-to-state stability ( LISS ) of nonlinear systems under the self-triggered impulsive control ( STIC ) method. A novel LISS -type comparison principle is proposed, by which the LISS property of addressed system can be derived by the LISS property of its comparison system. On the basis of it, some Lyapunov-based sufficient conditions for non-Zeno behavior and LISS of nonlinear systems are provided in the framework of STIC . Moreover, the designed self-triggering mechanism ( STM ) is in the form of an explicit relationship with simple structure and east implementation. Finally, two numerical examples are given to illustrate the effectiveness of the proposed results.},
  archive      = {J_AUTOM},
  author       = {Xiaodi Li and Mingzhu Wang},
  doi          = {10.1016/j.automatica.2025.112596},
  journal      = {Automatica},
  month        = {1},
  pages        = {112596},
  shortjournal = {Automatica},
  title        = {Input-to-state stability of self-triggered impulsive control systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-triggered global and group consensus for linear multiagent systems with multiplicative noises. <em>AUTOM</em>, <em>183</em>, 112595. (<a href='https://doi.org/10.1016/j.automatica.2025.112595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the event-triggered global and group consensus problems for linear multiagent systems (MASs) with multiplicative noises and directed topology. First, for the global consensus of MASs under a balanced directed graph, a stochastic input-to-state stability property is proved to show that the piecewise constant control input has sufficient feedback capability; based on the relative state measurement, two novel static and dynamic event-triggered mechanisms (ETMs) are established to reduce the number of controller updates, where the Zeno phenomenon is effectively eliminated by imposing a uniformly strictly fixed positive time for all the inter-event times. Especially, new stochastic stability analysis techniques are developed to give sufficient conditions of mean square and almost sure consensus in both static and dynamic ETMs. Moreover, the obtained results on global consensus are extended to the setting of group consensus in order to cope with some grouping tasks in practical applications. Finally, some examples are presented to show the validity of theoretical results.},
  archive      = {J_AUTOM},
  author       = {Ruru Jia and Yuan-Hua Ni and Guangchen Wang},
  doi          = {10.1016/j.automatica.2025.112595},
  journal      = {Automatica},
  month        = {1},
  pages        = {112595},
  shortjournal = {Automatica},
  title        = {Event-triggered global and group consensus for linear multiagent systems with multiplicative noises},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-model-hybrid-driven near-optimal operational control of two-time-scale industrial systems with unknown operational model. <em>AUTOM</em>, <em>183</em>, 112594. (<a href='https://doi.org/10.1016/j.automatica.2025.112594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the optimal operational control (OOC) problem of two-time-scale (TTS) industrial systems with unknown operation model. Based on the singular perturbation theory (SPT), the OOC problem of TTS industrial systems is decomposed into an optimal regulation problem in fast time-scale and an optimal set-point tracking problem in slow time-scale. Then, by convex duality, the obtained optimization problems are equivalently transformed into convex optimization (CO) problems, and a data-model-hybrid-driven composite controller is designed. The design method of this composite controller avoids the potential numerical stiffness problems, and does not need complete system dynamics information while ensuring the steady-state output tracking error converges to zero. Finally, an example of mixed separation thickening process (MSTP) of hematite beneficiation is given to show the effectiveness of the proposed scheme.},
  archive      = {J_AUTOM},
  author       = {Yao Xu and Linna Zhou and Jianguo Zhao and Lei Ma and Chunyu Yang},
  doi          = {10.1016/j.automatica.2025.112594},
  journal      = {Automatica},
  month        = {1},
  pages        = {112594},
  shortjournal = {Automatica},
  title        = {Data-model-hybrid-driven near-optimal operational control of two-time-scale industrial systems with unknown operational model},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-triggered distributed optimal coordination of heterogeneous linear MASs over weight-unbalanced digraphs. <em>AUTOM</em>, <em>183</em>, 112593. (<a href='https://doi.org/10.1016/j.automatica.2025.112593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the distributed optimal coordination problem of heterogeneous linear multi-agent systems is studied, in which the actual information of the left eigenvector and out-degree cannot be obtained in advance. The underlying communication network among agents is assumed to be a weight-unbalanced and strongly connected digraph. The global objective function of the whole system is the sum of privately-known local objective functions, which are assumed to be strongly convex with Lipschitz continuous gradients. To achieve the distributed optimal coordination with low communication and computational resource consumption, and to efficiently reduce the frequency of control signal updates, a new distributed event-triggered control scheme is proposed. In this scheme, an auxiliary system with adaptive edge weights is established to generate the optimal trajectories and the tracking control inputs are designed for agents to track the given optimal trajectories. It is privacy-preserving to some extent as no actual state or output information of agents is communicated with neighbors. Sufficient conditions are derived, under which the distributed optimal coordination under consideration can be exponentially achieved. Moreover, the Zeno-behavior is shown to be excluded. Additionally, for cases where agent states are unmeasurable, a new distributed event-triggered observer-based control input is designed for each agent to achieve optimal coordination. Finally, numerical simulations are carried out to show the good performance of the proposed control scheme.},
  archive      = {J_AUTOM},
  author       = {Dandan Wang and Jialing Zhou and Guanghui Wen},
  doi          = {10.1016/j.automatica.2025.112593},
  journal      = {Automatica},
  month        = {1},
  pages        = {112593},
  shortjournal = {Automatica},
  title        = {Event-triggered distributed optimal coordination of heterogeneous linear MASs over weight-unbalanced digraphs},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reducing real-time complexity via sub-control lyapunov functions: From theory to experiments. <em>AUTOM</em>, <em>183</em>, 112592. (<a href='https://doi.org/10.1016/j.automatica.2025.112592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The techniques to design control Lyapunov functions (CLF), along with a proper stabilizing feedback, possibly in the presence of constraints, often provide control laws that are too complex for proper implementation online, especially when an optimization problem is involved. In this work, we show how to acquire an alternative, computationally attractive feedback. Given a nominal CLF and a nominal state feedback, we say that a different positive definite function is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative is negative-definite and bounded above by the Lyapunov derivative of the nominal function with the nominal control. It turns out that if we consider a family of basis functions, then an SCLF can be computed by linear programming, with an infinite number of constraints. The idea is that although the offline computational burden to achieve the new controller and solve the linear program is considerable, the online computational burden is drastically reduced. Comprehensive simulations and experiments on drone control are conducted to demonstrate the effectiveness of the study.},
  archive      = {J_AUTOM},
  author       = {Huu-Thinh Do and Franco Blanchini and Stefano Miani and Ionela Prodan},
  doi          = {10.1016/j.automatica.2025.112592},
  journal      = {Automatica},
  month        = {1},
  pages        = {112592},
  shortjournal = {Automatica},
  title        = {Reducing real-time complexity via sub-control lyapunov functions: From theory to experiments},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adversarial dynamic games for markov jump systems: A policy iteration Q-learning method. <em>AUTOM</em>, <em>183</em>, 112591. (<a href='https://doi.org/10.1016/j.automatica.2025.112591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reinforcement Q-learning approach for solving adversarial dynamic games in Markov jump systems. The H ∞ control problem is first formulated as a two-player zero-sum dynamic game, where the control policy and the disturbance policy act as adversarial players. To derive the Nash equilibrium control strategies for such games, a set of coupled algebraic Riccati equations is established, with the disturbance attenuation level properly prescribed. On this basis, two novel data-driven parallel Q-learning algorithms are proposed. The advantages of the proposed method are threefold: (i) it does not require precise knowledge of the system dynamics; (ii) it learns the optimal disturbance attenuation level; (iii) it yields Nash equilibrium control strategies. Finally, two simulation examples validate the effectiveness of the proposed method.},
  archive      = {J_AUTOM},
  author       = {Hao Shen and Jiacheng Wu and Jing Wang and Zhengguang Wu},
  doi          = {10.1016/j.automatica.2025.112591},
  journal      = {Automatica},
  month        = {1},
  pages        = {112591},
  shortjournal = {Automatica},
  title        = {Adversarial dynamic games for markov jump systems: A policy iteration Q-learning method},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). H2/H∞ state and output feedback control with sparse actuation. <em>AUTOM</em>, <em>183</em>, 112581. (<a href='https://doi.org/10.1016/j.automatica.2025.112581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present novel convex optimization formulations for designing full-state and output-feedback controllers with sparse actuation that achieve user-specified H 2 and H ∞ performance criteria. The sparsity is induced through the ℓ 1 -minimization over channel-wise H 2 norms from disturbances to the individual actuator signals, while simultaneously constraining H 2 or H ∞ norm from disturbances to the output variables The proposed approach is applied to a structural dynamics problem, demonstrating the advantages of simultaneous optimization of the control law and the actuation architecture in realizing an efficient closed-loop system, as well as highlighting the trade-offs between maximum allowable actuator magnitudes and the controller sparsity.},
  archive      = {J_AUTOM},
  author       = {Vedang M. Deshpande and Raktim Bhattacharya},
  doi          = {10.1016/j.automatica.2025.112581},
  journal      = {Automatica},
  month        = {1},
  pages        = {112581},
  shortjournal = {Automatica},
  title        = {H2/H∞ state and output feedback control with sparse actuation},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive dynamic event–triggered distributed optimal coordination of heterogeneous uncertain nonlinear multiagent systems. <em>AUTOM</em>, <em>183</em>, 112580. (<a href='https://doi.org/10.1016/j.automatica.2025.112580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed optimal coordination problem for a class of heterogeneous uncertain nonlinear multiagent systems. Instead of relying on the analytical forms of gradient functions, we use the measured gradient values depending on agents’ real-time outputs and propose a novel adaptive distributed control scheme. This scheme integrates event-triggered optimal coordinators, high-order filters, and tracking controllers. To handle the interaction between optimal coordinators and filters, we incorporate a new compensation term into the updating law for the coupling weight of each edge. Moreover, we design a novel adaptive distributed dynamic event-triggering mechanism that ensures that the inter-event times of each agent are lower bounded by a positive constant. Asymptotic convergence of agents’ outputs to the optimal point is proved by constructing a composite Lyapunov function. The proposed control scheme does not depend on global topology information. A numerical example is given to demonstrate the effectiveness of the proposed control scheme.},
  archive      = {J_AUTOM},
  author       = {Tianyu Liu and Lu Liu},
  doi          = {10.1016/j.automatica.2025.112580},
  journal      = {Automatica},
  month        = {1},
  pages        = {112580},
  shortjournal = {Automatica},
  title        = {Adaptive dynamic event–triggered distributed optimal coordination of heterogeneous uncertain nonlinear multiagent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accelerated primal–dual methods for strongly convex objective functions in continuous and discrete time. <em>AUTOM</em>, <em>183</em>, 112579. (<a href='https://doi.org/10.1016/j.automatica.2025.112579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a “second-order primal” + “first-order dual” continuous-time dynamic for linearly constrained optimization problems, where the objective function is μ -strongly convex. We consider a constant damping 2 μ for the second-order ordinary differential equation in the primal variable, following Nesterov’s acceleration for strongly convex optimization. A positive constant scaling is applied to the primal variable, while a positive increasing scaling function is applied to the dual variable. We prove that the proposed dynamic achieves a fast convergence rate for both the objective residual and the feasibility violation, with the decay rate potentially reaching O ( e − μ t ) . Additionally, we show that the dynamic is robust under small perturbations. By discretizing the proposed continuous-time dynamic, we develop an accelerated linearized augmented Lagrangian method for strongly convex composite optimization with linear constraints, where the objective function has a nonsmooth + smooth composite structure. The proposed algorithm achieves a fast convergence rate that matches the one of the continuous-time dynamic. We also consider an inexact version of the proposed algorithm, which can be viewed as a discrete version of the perturbed continuous-time dynamic. Numerical results are provided to verify the practical performances.},
  archive      = {J_AUTOM},
  author       = {Xin He and Dong He and Ya-Ping Fang},
  doi          = {10.1016/j.automatica.2025.112579},
  journal      = {Automatica},
  month        = {1},
  pages        = {112579},
  shortjournal = {Automatica},
  title        = {Accelerated primal–dual methods for strongly convex objective functions in continuous and discrete time},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical supervisory control of networked and cyber-attacked discrete-event systems. <em>AUTOM</em>, <em>183</em>, 112578. (<a href='https://doi.org/10.1016/j.automatica.2025.112578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In standard supervisory control of discrete-event systems, partial (incomplete) observations are given by deterministic functions such as natural projections, which erase unobservable events, or masks, which can represent indistinguishable events, where two or more different events yield the same observation. However, communication channels in modern technological systems are not always reliable and can be attacked by malicious external agents. In that case, the plant observations obtained by the supervisor may not be deterministic, e.g., due to delays and losses, or external attacks. This paper considers a unified supervisory control framework with set-valued (nondeterministic) observations and proposes a simplified version of nondeterministic observability, together with a generalized normality. It shows how the results of hierarchical control can be extended to the networked and cyber-attacked discrete-event systems at the same time.},
  archive      = {J_AUTOM},
  author       = {Shaowen Miao and Jan Komenda and Feng Lin},
  doi          = {10.1016/j.automatica.2025.112578},
  journal      = {Automatica},
  month        = {1},
  pages        = {112578},
  shortjournal = {Automatica},
  title        = {Hierarchical supervisory control of networked and cyber-attacked discrete-event systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the design of linear time varying model predictive control for trajectory stabilization. <em>AUTOM</em>, <em>183</em>, 112577. (<a href='https://doi.org/10.1016/j.automatica.2025.112577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilizing a reference trajectory of a nonlinear system is a recurrent, non-trivial task in control engineering. A common approach is to linearize the dynamics along the trajectory, thus deriving a linear-time-varying (LTV) model, and to design a model predictive controller (MPC), which results to be computationally efficient, since only convex programs need to be solved in real time, while retaining constraint handling capabilities. Building on recent developments in gain-scheduling control design, where linearization errors and tracking error bounds are considered, a new approach to derive such LTV-MPC controllers is presented. The method addresses the systematic derivation of a suitable terminal cost. The resulting MPC law is tube-based, exploiting the co-designed auxiliary gain-scheduled controller. Computational and implementation aspects are discussed as well, and the resulting hierarchical method is demonstrated both in simulation and in experiments with a small drone with fast dynamics and limited embedded computational capacity.},
  archive      = {J_AUTOM},
  author       = {Nicolas Kessler and Lorenzo Fagiano},
  doi          = {10.1016/j.automatica.2025.112577},
  journal      = {Automatica},
  month        = {1},
  pages        = {112577},
  shortjournal = {Automatica},
  title        = {On the design of linear time varying model predictive control for trajectory stabilization},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intersection-based architectures for decentralized diagnosis of discrete event systems. <em>AUTOM</em>, <em>183</em>, 112576. (<a href='https://doi.org/10.1016/j.automatica.2025.112576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two intersection-based architectures, named the normal-state-estimator-intersection-based architecture (N-SEI architecture) and the failure-state-estimator-intersection-based architecture (F-SEI architecture), are examined for decentralized diagnosis of discrete event systems. For each of these architectures, the corresponding notion of codiagnosability is defined. These defined notions of codiagnosability are incomparable with inference diagnosability for the inference-based architecture. In addition, codiagnosability for the N-SEI architecture is weaker than the existing notion of intersection-based codiagnosability, while codiagnosability for the F-SEI architecture is incomparable with it. For each of the N-SEI and F-SEI architectures, a method for verifying the corresponding notion of codiagnosability is developed.},
  archive      = {J_AUTOM},
  author       = {Shigemasa Takai and Takashi Yamamoto},
  doi          = {10.1016/j.automatica.2025.112576},
  journal      = {Automatica},
  month        = {1},
  pages        = {112576},
  shortjournal = {Automatica},
  title        = {Intersection-based architectures for decentralized diagnosis of discrete event systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed stochastic constrained optimization with constant step-sizes via saddle-point dynamics. <em>AUTOM</em>, <em>183</em>, 112575. (<a href='https://doi.org/10.1016/j.automatica.2025.112575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers distributed stochastic optimization problems over a multi-agent network, where each agent collaboratively minimizes the sum of individual expectation-valued cost functions subject to nonidentical set constraints. We first recast the distributed constrained optimization as a constrained saddle-point problem. Subsequently, two distributed stochastic algorithms via optimistic gradient descent ascent (SOGDA) and extragradient (SEG) methods are developed with constant step sizes, in which the variable sample-size technique is incorporated to reduce the variance of the sampled gradients. We present the explicit selection criteria of the constant step size, under which the developed algorithms achieve almost sure convergence to an optimal solution. Moreover, the convergence rate is O ( 1 / k ) for merely convex cost functions, which matches the optimal rate of its deterministic counterpart. Finally, a numerical example is provided to reflect the theoretical findings.},
  archive      = {J_AUTOM},
  author       = {Yi Huang and Shisheng Cui and Xianlin Zeng and Ziyang Meng},
  doi          = {10.1016/j.automatica.2025.112575},
  journal      = {Automatica},
  month        = {1},
  pages        = {112575},
  shortjournal = {Automatica},
  title        = {Distributed stochastic constrained optimization with constant step-sizes via saddle-point dynamics},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A characterization method of terminal ingredients for nonlinear MPC using value-based reinforcement learning. <em>AUTOM</em>, <em>183</em>, 112574. (<a href='https://doi.org/10.1016/j.automatica.2025.112574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability of nonlinear model predictive control (MPC) relies significantly on stabilizing factors such as the terminal region and cost. A larger terminal region not only expands the region of attraction for the closed-loop system but also contributes to reducing online computation costs. However, existing methods in the literature often impose limitations on the degrees of freedom available for characterizing terminal ingredients. This limitation arises from the reliance on either a predetermined linear local controller or a preset control Lyapunov function. This paper introduces an innovative approach to terminal ingredient characterization leveraging value-based reinforcement learning (RL). This method provides ample degrees of freedom for expanding the terminal region. To achieve this, a deep neural network is employed to learn the parametric state value function, serving as the terminal cost for MPC. The local controller adopts a one-step MPC instead of a predetermined linear or nonlinear feedback controller. Subsequently, a terminal set sequence is constructed iteratively through the one-step set expansion. The proposed approach’s effectiveness is validated through simulations.},
  archive      = {J_AUTOM},
  author       = {Jinghan Cui and Jinwu Gao and Xiangjie Liu and Yuqi Liu and Shuyou Yu},
  doi          = {10.1016/j.automatica.2025.112574},
  journal      = {Automatica},
  month        = {1},
  pages        = {112574},
  shortjournal = {Automatica},
  title        = {A characterization method of terminal ingredients for nonlinear MPC using value-based reinforcement learning},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Aperiodic-sampled neural network controllers with closed-loop stability verifications. <em>AUTOM</em>, <em>183</em>, 112573. (<a href='https://doi.org/10.1016/j.automatica.2025.112573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we synthesize two aperiodic-sampled deep neural network (DNN) control schemes, based on the closed-loop tracking stability guarantees. By means of the integral quadratic constraint coping with the input–output behavior of system uncertainties/nonlinearities and the convex relaxations of nonlinear DNN activations leveraging their local sector-bounded attributes, we establish conditions to design the event- and self-triggered logics and to compute the ellipsoidal inner approximations of region of attraction, respectively. Finally, we perform a numerical example of an inverted pendulum to illustrate the effectiveness of the proposed aperiodic-sampled DNN control schemes.},
  archive      = {J_AUTOM},
  author       = {Renjie Ma and Zhijian Hu and Rongni Yang and Ligang Wu},
  doi          = {10.1016/j.automatica.2025.112573},
  journal      = {Automatica},
  month        = {1},
  pages        = {112573},
  shortjournal = {Automatica},
  title        = {Aperiodic-sampled neural network controllers with closed-loop stability verifications},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backstepping for partial differential equations: A survey. <em>AUTOM</em>, <em>183</em>, 112572. (<a href='https://doi.org/10.1016/j.automatica.2025.112572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems modeled by partial differential equations (PDEs) are at least as ubiquitous as those by nature finite-dimensional and modeled by ordinary differential equations (ODEs). And yet, systematic and readily usable methodologies, for such a significant portion of real systems, have been historically scarce. Around the year 2000, the backstepping approach to PDE control began to offer not only a less abstract alternative to PDE control techniques replicating optimal and spectrum assignment techniques of the 1960s, but also enabled the methodologies of adaptive and nonlinear control, matured in the 1980s and 1990s, to be extended from ODEs to PDEs, allowing feedback synthesis for systems that are uncertain, nonlinear, and infinite-dimensional. The PDE backstepping literature has since grown to hundreds of papers and nearly a dozen books. This survey aims to facilitate the entry into this thriving area of overwhelming size and topical diversity. Designs of controllers and observers, for parabolic, hyperbolic, and other classes of PDEs, in one or more dimensions, with nonlinear, adaptive, sampled-data, and event-triggered extensions, are covered in the survey. The lifeblood of control are technology and physics. The survey places a particular emphasis on applications that have motivated the development of the theory and which have benefited from the theory and designs: flows, flexible structures, materials, thermal and chemically reacting dynamics, energy (from oil drilling to batteries and magnetic confinement fusion), and vehicles.},
  archive      = {J_AUTOM},
  author       = {Rafael Vazquez and Jean Auriol and Federico Bribiesca-Argomedo and Miroslav Krstic},
  doi          = {10.1016/j.automatica.2025.112572},
  journal      = {Automatica},
  month        = {1},
  pages        = {112572},
  shortjournal = {Automatica},
  title        = {Backstepping for partial differential equations: A survey},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Maximum principle for partial information non-zero sum stochastic differential games with mixed delays. <em>AUTOM</em>, <em>183</em>, 112570. (<a href='https://doi.org/10.1016/j.automatica.2025.112570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with one kind of partial information non-zero sum stochastic differential game with mixed delays. Both the state and control processes contain delays, where the former contains moving-average delay, discrete delay and noisy memory. We establish a necessary as well as two sufficient stochastic maximum principles for the game. As one of the main features of this research, a new kind of sufficient maximum principle is given, where the diffusion term can be controlled with non-convex control domains, and no second-order adjoint equation is needed. The theoretical results are applied to study two examples where the adjoint processes can be derived by two approaches and then the equilibrium points are obtained. This research generalizes those of stochastic optimal control problems.},
  archive      = {J_AUTOM},
  author       = {Pan Chen and Feng Zhang},
  doi          = {10.1016/j.automatica.2025.112570},
  journal      = {Automatica},
  month        = {1},
  pages        = {112570},
  shortjournal = {Automatica},
  title        = {Maximum principle for partial information non-zero sum stochastic differential games with mixed delays},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finite and fixed-time feedback-based continuous-time optimization. <em>AUTOM</em>, <em>183</em>, 112569. (<a href='https://doi.org/10.1016/j.automatica.2025.112569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a framework for finite and fixed-time control, using feedback-based optimization to drive a system toward its optimal operating point. Unlike traditional methods that rely on predefined set points, this approach employs endogenous control inputs derived through numerical optimization while adhering to system constraints. The controller’s dynamics are modeled as a convergent gradient flow, allowing the system to autonomously achieve its optimum without external references. The proposed control architecture guarantees finite- and fixed-time stability, with a Lyapunov-based analysis determining permissible perturbation bounds to ensure robust performance. The effectiveness of the proposed control strategy is demonstrated through simulations on a coupled-tank and a buck converter systems, successfully achieving the desired steady-state operation with the designed control approach.},
  archive      = {J_AUTOM},
  author       = {Baby Diana and Sunidhi Pandey and Shyam Kamal and Thach Ngoc Dinh},
  doi          = {10.1016/j.automatica.2025.112569},
  journal      = {Automatica},
  month        = {1},
  pages        = {112569},
  shortjournal = {Automatica},
  title        = {Finite and fixed-time feedback-based continuous-time optimization},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State estimation for lithium-ion batteries based on electrolyte–electrode PDE observers. <em>AUTOM</em>, <em>183</em>, 112568. (<a href='https://doi.org/10.1016/j.automatica.2025.112568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate information about the states of an electrochemical battery model facilitates a deeper understanding of battery behavior and enables performance enhancement. This paper first proposes backstepping Partial Differential Equation (PDE) observers for lithium concentration in the electrolyte phase within the negative electrode, positive electrode, and separator. Reverse sensitivity analysis is conducted to identify the most suitable measurable parameter for obtaining the electrolyte lithium concentration at the boundaries, which is used in the design of the electrolyte-phase observer. Subsequently, enhanced observers for the solid-phase lithium concentration in the negative and positive electrodes are developed. The proposed solid-phase observer enables more accurate State-of-Charge (SoC) estimation by leveraging the closed-loop electrolyte-phase observer. Simulations of the reverse sensitivity analysis and state observers are performed on a commercial cylindrical lithium iron phosphate ( LiFePO 4 ) cell to validate the effectiveness of the proposed approach.},
  archive      = {J_AUTOM},
  author       = {Sara Sepasiahooyi and Shu-Xia Tang},
  doi          = {10.1016/j.automatica.2025.112568},
  journal      = {Automatica},
  month        = {1},
  pages        = {112568},
  shortjournal = {Automatica},
  title        = {State estimation for lithium-ion batteries based on electrolyte–electrode PDE observers},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interval-constraint multiagent systems: Global attractivity and structural stability of equilibria. <em>AUTOM</em>, <em>183</em>, 112566. (<a href='https://doi.org/10.1016/j.automatica.2025.112566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the dynamic behavior of an interval-constraint multiagent system. Each agent has a constraint interval that limits its potential consensus values, achieved by encoding a nonsmooth piecewise function into the agent. In addition, the underlying graphs considered are strongly connected. First, a dichotomy of equilibria is identified: either a unique non-consensus equilibrium point or multiple consensus points, depending on whether the intersection of the constraint intervals is empty or not. Then, the set of equilibria is proven to be a global attractor. Structural stability of such a system is also proven based on real-analysis methods, showing that the equilibria have continuous dependence on changes of the constraint intervals. Three running examples are used to illustrate the proposed results.},
  archive      = {J_AUTOM},
  author       = {Fengqiu Liu and Kuize Zhang and Yuhu Wu and Xiaoping Xue},
  doi          = {10.1016/j.automatica.2025.112566},
  journal      = {Automatica},
  month        = {1},
  pages        = {112566},
  shortjournal = {Automatica},
  title        = {Interval-constraint multiagent systems: Global attractivity and structural stability of equilibria},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Closed-loop data-enabled predictive control and its equivalence with closed-loop subspace predictive control. <em>AUTOM</em>, <em>183</em>, 112556. (<a href='https://doi.org/10.1016/j.automatica.2025.112556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factors like growing data availability and increasing system complexity have sparked interest in data-driven predictive control (DDPC) methods like Data-enabled Predictive Control (DeePC). However, closed-loop identification bias arises in the presence of noise, which reduces the effectiveness of obtained control policies. In this paper we propose Closed-loop Data-enabled Predictive Control (CL-DeePC), a framework that unifies different approaches to address this challenge. To this end, CL-DeePC incorporates instrumental variables (IVs) to synthesize and sequentially apply consistent single or multi-step-ahead predictors. Furthermore, a computationally efficient CL-DeePC implementation is developed that reveals an equivalence with Closed-loop Subspace Predictive Control (CL-SPC). Time marching simulations of DeePC and CL-DeePC are conducted using Hankel matrices of past data that are updated at every time step to induce potentially troublesome closed-loop correlations between inputs and noise. Compared to DeePC, CL-DeePC simulations demonstrate superior reference tracking, with a sensitivity study finding a 48% lower susceptibility to noise-induced reference tracking performance degradation.},
  archive      = {J_AUTOM},
  author       = {Rogier Dinkla and Tom Oomen and Sebastiaan Paul Mulders and Jan-Willem van Wingerden},
  doi          = {10.1016/j.automatica.2025.112556},
  journal      = {Automatica},
  month        = {1},
  pages        = {112556},
  shortjournal = {Automatica},
  title        = {Closed-loop data-enabled predictive control and its equivalence with closed-loop subspace predictive control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated online learning for gaussian process regression. <em>AUTOM</em>, <em>183</em>, 112554. (<a href='https://doi.org/10.1016/j.automatica.2025.112554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Byzantine-resilient federated online learning for Gaussian process regression (GPR). We develop a Byzantine-resilient federated GPR algorithm that allows a cloud and a group of agents to collaboratively learn a latent function and improve the learning performances where some agents exhibit Byzantine failures, i.e., arbitrary and potentially adversarial behavior. Each agent-based local GPR sends potentially compromised local predictions to the cloud, and the cloud-based aggregated GPR computes a global model by a Byzantine-resilient product of experts aggregation rule. Then the cloud broadcasts the current global model to all the agents. Agent-based fused GPR refines local predictions by fusing the received global model with that of the agent-based local GPR. Moreover, we quantify the learning accuracy improvements of the agent-based fused GPR over the agent-based local GPR. Experiments on a toy example and two medium-scale real-world datasets are conducted to demonstrate the performances of the proposed algorithm.},
  archive      = {J_AUTOM},
  author       = {Xu Zhang and Zhenyuan Yuan and Minghui Zhu},
  doi          = {10.1016/j.automatica.2025.112554},
  journal      = {Automatica},
  month        = {1},
  pages        = {112554},
  shortjournal = {Automatica},
  title        = {Byzantine-resilient federated online learning for gaussian process regression},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Observer-based asymptotic active fault diagnosis: Separate and joint design of observer gain and input. <em>AUTOM</em>, <em>183</em>, 112548. (<a href='https://doi.org/10.1016/j.automatica.2025.112548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes observer gain and input design methods for observer-based asymptotic active fault diagnosis, which are based on a newly-defined notion named the excluding degree of the origin from a zonotope. Using the excluding degree, a quantitative specification is obtained to characterize the performance of set-based robust fault diagnosis. Furthermore, a separate gain design method and a joint gain and input design method are proposed, respectively. This is the first work to achieve a joint observer gain and input design for set-based active fault diagnosis. Compared with the existing methods that design gains and input separately, the proposed joint gain and input design method has advantages to exploit the fault diagnosis potential of observer-based schemes. Finally, several examples are used to illustrate the effectiveness of the proposed methods.},
  archive      = {J_AUTOM},
  author       = {Feng Xu and Yiming Wan and Ye Wang and Vicenç Puig},
  doi          = {10.1016/j.automatica.2025.112548},
  journal      = {Automatica},
  month        = {1},
  pages        = {112548},
  shortjournal = {Automatica},
  title        = {Observer-based asymptotic active fault diagnosis: Separate and joint design of observer gain and input},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Controller synthesis from noisy-input noisy-output data. <em>AUTOM</em>, <em>183</em>, 112545. (<a href='https://doi.org/10.1016/j.automatica.2025.112545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of synthesizing a dynamic output-feedback controller for a linear system, using solely input–output data corrupted by measurement noise. To handle input–output data, an auxiliary representation of the original system is utilized. By exploiting the structure of the auxiliary system, we design a controller that robustly stabilizes all possible systems consistent with data. Notably, we also provide a novel solution to extend the results to generic multi-input multi-output systems. The findings are illustrated by numerical examples.},
  archive      = {J_AUTOM},
  author       = {Lidong Li and Andrea Bisoffi and Claudio De Persis and Nima Monshizadeh},
  doi          = {10.1016/j.automatica.2025.112545},
  journal      = {Automatica},
  month        = {1},
  pages        = {112545},
  shortjournal = {Automatica},
  title        = {Controller synthesis from noisy-input noisy-output data},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accuracy bounds for the simulation of a class of continuous-time nonlinear models. <em>AUTOM</em>, <em>183</em>, 112543. (<a href='https://doi.org/10.1016/j.automatica.2025.112543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world dynamic systems evolve in the continuous-time world, while their models are simulated in the digital world using discrete-time numerical simulation algorithms. Such simulation is essential for a variety of system and control problems such as system identification and performance analysis of (control) systems. Ideally, the simulated model response should be identical to the system response. However, this is typically not the case in practice, even when the effects of unmodelled dynamics and parametric uncertainty are excluded. Even in that scenario, a mismatch exists between the response of the system and the model due to the interface between the physical world and the digital computer, unknown disturbances, and simulation inaccuracies. For the class of continuous-time, nonlinear Lur’e-type systems, this paper analyses the mismatch between the steady-state system response and the steady-state model response computed using the so-called mixed time–frequency algorithm. Firstly, a bound on the mismatch between the steady-state system response and the computed steady-state model response based on continuous-time signals is derived. Secondly, a bound for the same mismatch is derived for a sampled version of the signals. The bounds are further decomposed into several components, each given an interpretation that can be used to reduce the bounds on the mismatch. In a numerical case study, we show that reducing the bounds also reduces the actual mismatch.},
  archive      = {J_AUTOM},
  author       = {Fahim Shakib and Johan Schoukens and Alexander Yu. Pogromsky and Alexey Pavlov and Nathan van de Wouw},
  doi          = {10.1016/j.automatica.2025.112543},
  journal      = {Automatica},
  month        = {1},
  pages        = {112543},
  shortjournal = {Automatica},
  title        = {Accuracy bounds for the simulation of a class of continuous-time nonlinear models},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revisiting lossless convexification: Theoretical guarantees for discrete-time optimal control problems. <em>AUTOM</em>, <em>183</em>, 112537. (<a href='https://doi.org/10.1016/j.automatica.2025.112537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lossless Convexification (LCvx) is a modeling approach that transforms a class of nonconvex optimal control problems, where nonconvexity primarily arises from control constraints, into convex problems through convex relaxations. These convex problems can be solved using polynomial-time numerical methods after discretization, which converts the original infinite-dimensional problem into a finite-dimensional one. However, existing LCvx theory is limited to continuous-time optimal control problems, as the equivalence between the relaxed convex problem and the original nonconvex problem holds only in continuous-time. This paper extends LCvx theory to discrete-time optimal control problems by classifying them into normal and long-horizon cases. For normal cases, after an arbitrarily small perturbation to the system dynamics (recursive equality constraints), applying the existing LCvx method to discrete-time problems results in optimal controls that meet the original nonconvex constraints at all but no more than n x − 1 temporal grid points, where n x is the state dimension. For long-horizon cases, the existing LCvx method fails, but we resolve this issue by integrating it with a bisection search, leveraging the continuity of the value function from the relaxed convex problem to achieve similar results as in normal cases. This paper strengthens the theoretical foundation of LCvx, extending the applicability of LCvx theory to discrete-time optimal control problems.},
  archive      = {J_AUTOM},
  author       = {Dayou Luo and Kazuya Echigo and Behçet Açıkmeşe},
  doi          = {10.1016/j.automatica.2025.112537},
  journal      = {Automatica},
  month        = {1},
  pages        = {112537},
  shortjournal = {Automatica},
  title        = {Revisiting lossless convexification: Theoretical guarantees for discrete-time optimal control problems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated cubic regularized newton learning with sparsification-amplified differential privacy. <em>AUTOM</em>, <em>183</em>, 112531. (<a href='https://doi.org/10.1016/j.automatica.2025.112531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the cubic-regularized Newton method within a federated learning framework while addressing two major concerns: privacy leakage and communication bottlenecks. We propose the Differentially Private Federated Cubic Regularized Newton (DP-FCRN) algorithm, which leverages second-order techniques to achieve lower iteration complexity than first-order methods. We incorporate noise perturbation during local computations to ensure privacy. Furthermore, we employ sparsification in uplink transmission, which not only reduces the communication costs but also amplifies the privacy guarantee. Specifically, this approach reduces the necessary noise intensity without compromising privacy protection. We analyze the convergence properties of our algorithm and establish the privacy guarantee. Finally, we validate the effectiveness of the proposed algorithm through experiments on a benchmark dataset.},
  archive      = {J_AUTOM},
  author       = {Wei Huo and Changxin Liu and Kemi Ding and Karl Henrik Johansson and Ling Shi},
  doi          = {10.1016/j.automatica.2025.112531},
  journal      = {Automatica},
  month        = {1},
  pages        = {112531},
  shortjournal = {Automatica},
  title        = {Federated cubic regularized newton learning with sparsification-amplified differential privacy},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A consensus kalman filter on l2 spaces. <em>AUTOM</em>, <em>183</em>, 112530. (<a href='https://doi.org/10.1016/j.automatica.2025.112530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the estimation problem of infinite dimensional discrete-time stochastic linear systems with finite dimensional measurements on sensor networks modeled by connected undirected graphs. The framework encompasses discretized PDEs with sampled measurements. A new scheme of distributed consensus on measurements is extended to systems evolving in L 2 spaces in order to limit the information exchange to finite-dimensional vectors. We show that, in analogy to the finite-dimensional case, at each node the variance of the estimation error tends to the one of the centralized Kalman filter for systems is L 2 when the number of consensus steps increases.},
  archive      = {J_AUTOM},
  author       = {Stefano Battilotti and Alessandro Borri and Filippo Cacace and Massimiliano d’Angelo and Alfredo Germani},
  doi          = {10.1016/j.automatica.2025.112530},
  journal      = {Automatica},
  month        = {1},
  pages        = {112530},
  shortjournal = {Automatica},
  title        = {A consensus kalman filter on l2 spaces},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning for safe time-critical verification using reachability analysis. <em>AUTOM</em>, <em>183</em>, 112528. (<a href='https://doi.org/10.1016/j.automatica.2025.112528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a safe time-critical control problem using reachability analysis and design a reinforcement learning-based mechanism for learning online and in fixed-time the solution to the safe time-critical control problem. Safety is ensured by determining a set of states for which there exists an admissible control law generating a system trajectory that does not reach a set of forbidden states at a user-prescribed time instant. Specifically, we cast our safe time-critical problem as a Mayer optimal feedback control problem whose solution satisfies the Hamilton–Jacobi–Bellman (HJB) equation and characterizes the set of safe states. Since the HJB equation is generally difficult to solve, we develop an online critic-only reinforcement learning-based algorithm for simultaneously learning the solution to the HJB equation and the safe set in a fixed time. In particular, we introduce a non-Lipschitz experience replay-based learning law utilizing recorded and current data for updating the critic weights to learn the value function and the safe set. The non-Lipschitz property of the dynamics gives rise to fixed-time convergence, whereas the experience replay-based approach eliminates the need to satisfy the persistence of excitation condition provided that a recorded data set is sufficiently rich. Simulation results illustrate the efficacy of the proposed approach to the problem of fixed-wing unmanned aerial vehicle collision avoidance.},
  archive      = {J_AUTOM},
  author       = {Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis and Wassim M. Haddad},
  doi          = {10.1016/j.automatica.2025.112528},
  journal      = {Automatica},
  month        = {1},
  pages        = {112528},
  shortjournal = {Automatica},
  title        = {Fixed-time learning for safe time-critical verification using reachability analysis},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Orchestrating on-board sensors for global hybrid robust stabilization of unicycles. <em>AUTOM</em>, <em>183</em>, 112502. (<a href='https://doi.org/10.1016/j.automatica.2025.112502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider mobile robots described through unicycle dynamics equipped with on-board range sensors and cameras, one facing forward and one facing backward, providing measurements of the distance and misalignment to a target. We propose a hybrid control law combining the two on-board measurements and discuss stability results for the closed-loop expressed in the on-board camera-based coordinates, using Lyapunov-based arguments. We prove robustness of the stability properties to uncertainties affecting the sensors and external perturbations acting on the robot. The results are illustrated via simulations.},
  archive      = {J_AUTOM},
  author       = {Riccardo Ballaben and Alessandro Astolfi and Philipp Braun and Luca Zaccarian},
  doi          = {10.1016/j.automatica.2025.112502},
  journal      = {Automatica},
  month        = {1},
  pages        = {112502},
  shortjournal = {Automatica},
  title        = {Orchestrating on-board sensors for global hybrid robust stabilization of unicycles},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cma">CMA - 3</h2>
<ul>
<li><details>
<summary>
(2026). A second-order time-accurate, linear fully decoupled unconditional energy stabilization finite element method for tumor growth model. <em>CMA</em>, <em>201</em>, 35-52. (<a href='https://doi.org/10.1016/j.camwa.2025.09.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By using the L 2 gradient flow method, we derive a phase-field model for tumor growth from the free energy. The scalar auxiliary variable (SAV) method is employed to handle the nonlinear energy potential. Based on the second-order backward differentiation formula (BDF2) and the finite element method, we construct an unconditionally stable, linear, and decoupled fully discrete numerical scheme. We rigorously prove the unconditional energy stability of the proposed scheme and the optimal L 2 -norm error estimates for ϕ and c . Numerical examples are presented to validate the theoretical results and to demonstrate the effectiveness of the model and the scheme.},
  archive      = {J_CMA},
  author       = {Mingle Sun and Bo Wang and Guang-an Zou and Yuxing Zhang},
  doi          = {10.1016/j.camwa.2025.09.028},
  journal      = {Computers & Mathematics with Applications},
  month        = {1},
  pages        = {35-52},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A second-order time-accurate, linear fully decoupled unconditional energy stabilization finite element method for tumor growth model},
  volume       = {201},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High order energy invariant fast algorithm for space two dimensional klein-gordon-zakharov equations. <em>CMA</em>, <em>201</em>, 18-34. (<a href='https://doi.org/10.1016/j.camwa.2025.09.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space two dimensional Klein-Gordon-Zakharov equations are directly changed into the Hamiltonian system with infinite dimensional space by the variational formula, which can be discretized into finite dimensional Hamiltonian system by Fourier pseudo-spectral method. The average vector field formulas with second and fourth order accuracy in time are utilized to compute the finite dimensional Hamiltonian system. In order to improve computation velocity of these formulas, the fast computation algorithm of these formulas is proposed by decomposing the spectral matrix. Solitary wave evolution of the equations is analyzed with different initial conditions by these new computational formulas. Energy invariant property, accuracy and computation efficiently of these new formulas are also investigated.},
  archive      = {J_CMA},
  author       = {Jie Chen and Jianqiang Sun},
  doi          = {10.1016/j.camwa.2025.09.026},
  journal      = {Computers & Mathematics with Applications},
  month        = {1},
  pages        = {18-34},
  shortjournal = {Comput. Meth. Appl.},
  title        = {High order energy invariant fast algorithm for space two dimensional klein-gordon-zakharov equations},
  volume       = {201},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fundamental solution neural networks for solving inverse cauchy problems for the laplace and biharmonic equations. <em>CMA</em>, <em>201</em>, 1-17. (<a href='https://doi.org/10.1016/j.camwa.2025.09.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel fundamental solution neural networks method (FSNNs) to solve inverse Cauchy problems, which combines the method of fundamental solutions (MFS) with the physics-informed neural networks (PINNs). To optimize the distribution of source points, the method starts by partitioning the interval into equal segments, determined by the number of the source points. The coordinate system is situated at the center of the computational domain. The resulting angles as network inputs for the FSNNs and the intermediate variable as outputs, which is subsequently substituted into a length function to obtain the final length. The coordinates of the source points are then determined, and the MFS is employed to approximate the numerical solutions. The loss function is formulated based on the boundary conditions on the accessible boundary, and the training is employed to optimize the network parameters in the FSNNs and source point intensities in the MFS. The introduction of the PINNs overcomes the challenge of source point selection in the MFS and effectively addresses the ill-posedness of inverse problems. In summary, the proposed scheme is a machine learning-based semi-analytical meshless method which is simple, accurate and easily implemented, making it highly suitable for the numerical solution of inverse problems. Four numerical experiments, including the Laplace and biharmonic equations, validate the effectiveness and accuracy of the proposed FSNNs.},
  archive      = {J_CMA},
  author       = {Xin Li and Fajie Wang and Renhao Wang and Shengdong Zhao and Daigeng Yang},
  doi          = {10.1016/j.camwa.2025.09.032},
  journal      = {Computers & Mathematics with Applications},
  month        = {1},
  pages        = {1-17},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Fundamental solution neural networks for solving inverse cauchy problems for the laplace and biharmonic equations},
  volume       = {201},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cmame">CMAME - 29</h2>
<ul>
<li><details>
<summary>
(2026). Physics- and data-driven active learning of neural network representations for free energy density functions of materials from statistical mechanics. <em>CMAME</em>, <em>448</em>, 118434. (<a href='https://doi.org/10.1016/j.cma.2025.118434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate free energy density representations are crucial for understanding phase dynamics in materials. We employ a scale-bridging approach to incorporate atomistic information into our free energy density model by training a neural network on DFT-informed Monte Carlo data. To optimize sampling in the high-dimensional Monte Carlo space, we present an active learning framework that integrates space-filling sampling, uncertainty-based sampling, and physics-informed sampling. Additionally, our approach includes methods such as hyperparameter tuning, dynamic sampling, and novelty enforcement. These strategies can be combined to reduce the mean squared error-either globally or in targeted regions of interest-while minimizing the number of required data points. The framework introduced here is broadly applicable to Monte Carlo sampling of a range of materials systems.},
  archive      = {J_CMAME},
  author       = {J. Holber and K. Garikipati},
  doi          = {10.1016/j.cma.2025.118434},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118434},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Physics- and data-driven active learning of neural network representations for free energy density functions of materials from statistical mechanics},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dimension-reduced chapman-kolmogorov equation for high-dimensional stochastic dynamical systems. <em>CMAME</em>, <em>448</em>, 118433. (<a href='https://doi.org/10.1016/j.cma.2025.118433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random vibration analysis of high-dimensional dynamical systems is a fundamental problem in science and engineering, yet it remains challenging due to the curse of dimensionality. While dimension-reduced formulations have been developed for differential-type equations governing time-variant probability density, such as the Fokker-Planck equation, no equivalent formulation has been established for the integral-type Chapman-Kolmogorov (CK) equation, despite its theoretical importance and computational advantages. In this paper, a novel dimension-reduced Chapman-Kolmogorov (DRCK) equation is established governing the transient probability density function (PDF) of any quantity of interest in high-dimensional Markov systems. The derivation is conducted based on the projection of the full Chapman-Kolmogorov equation onto the dimension-reduced space. It is established that the intrinsic transition probability density (TPD) of the DRCK equation is the conditional expectation of the original TPD. Further, the short-time approximate intrinsic TPDs under both Gaussian and Poisson white noise excitations are derived analytically, enabling practical numerical implementation. The proposed DRCK equation provides a mathematically rigorous and computationally efficient framework for high-dimensional stochastic systems. Numerical examples are developed to demonstrate its accuracy and effectiveness. The DRCK equation thus provides a new tool for reliability assessment and uncertainty quantification in complex engineering applications.},
  archive      = {J_CMAME},
  author       = {Jianbing Chen and Meng-Ze Lyu and Shenghan Zhang},
  doi          = {10.1016/j.cma.2025.118433},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118433},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Dimension-reduced chapman-kolmogorov equation for high-dimensional stochastic dynamical systems},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Second order three-dimensional serendipity virtual elements for hyperelasticity: Static and dynamic analysis. <em>CMAME</em>, <em>448</em>, 118432. (<a href='https://doi.org/10.1016/j.cma.2025.118432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a three-dimensional (3D) second-order serendipity virtual element method (S-VEM) is developed for the static and dynamic analysis of hyperelastic materials. The VEM framework is based on the projection of unknown basis functions onto polynomial spaces, allowing for flexible discretization with arbitrary polyhedral meshes. While most existing VEM formulations for 3D mechanical problems are discretized using first-order formulations, higher-order schemes offer improved precision, especially for nonlinear problems. However, conventional second-order VEM formulations introduce additional degrees of freedom (DOFs), such as body and surface moments, which complicate the implementation and reduce computation efficiency. To address this challenge, we propose a novel 3D second-order serendipity VEM that avoids any extra moment-related DOFs. This is the first application of a serendipity VEM to 3D static and dynamic problems in hyperelasticity. Furthermore, by integrating advanced mesh generation techniques, the proposed method enables hybrid simulations that combine second-order serendipity VEM and FEM to efficiently handle complex geometries.},
  archive      = {J_CMAME},
  author       = {Bing-Bing Xu and Lourenco Beirao da Veiga and Yongjie Jessica Zhang and Peter Wriggers},
  doi          = {10.1016/j.cma.2025.118432},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118432},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Second order three-dimensional serendipity virtual elements for hyperelasticity: Static and dynamic analysis},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stabilized explicit material point method for fluid flow and fluid-structure interaction simulations using dual high-order B-spline volume averaging. <em>CMAME</em>, <em>448</em>, 118428. (<a href='https://doi.org/10.1016/j.cma.2025.118428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional explicit Material Point Methods (MPM) for weakly compressible fluids often suffer from volumetric locking, cell-crossing instability, and excessive energy dissipation, particularly in fluid-structure interaction (FSI) scenarios. This study presents a stabilized explicit MPM framework that integrates dual high-order B-spline volume averaging to address these challenges. The proposed dual averaging technique simultaneously smooths deformation gradients and pressure fields using cubic B-spline basis functions to eliminate cell-crossing errors and reduce volumetric locking. A blended APIC/FLIP mapping scheme is developed to enhance energy conservation and stability at coarse grid resolutions. The framework is further enhanced by seamlessly integrating various complementary techniques such as δ -correction, pressure smoothing, and specialized boundary handling for more robust and effective modeling of free-surface and FSI problems. The framework is rigorously validated through benchmark cases, including 1D elastic wave propagation, Poiseuille flow, lid-driven cavity flow, water sloshing, dam break, and water impact on elastic obstacles. The simulation results demonstrate a remarkable reduction in pressure oscillations and improved particle distribution uniformity compared to prior MPM approaches. The proposed method establishes a robust and efficient tool for large-deformation FSI problems and bridges gaps in accuracy and stability for industrial-scale applications.},
  archive      = {J_CMAME},
  author       = {Zhang Cheng and Shiwei Zhao and Hao Chen and Jidong Zhao},
  doi          = {10.1016/j.cma.2025.118428},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118428},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Stabilized explicit material point method for fluid flow and fluid-structure interaction simulations using dual high-order B-spline volume averaging},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Personalized multiscale modeling of coronary plaque progression: The interaction between low-density-lipoprotein transport and cellular dynamics. <em>CMAME</em>, <em>448</em>, 118427. (<a href='https://doi.org/10.1016/j.cma.2025.118427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiscale agent-based modeling has shown promise in elucidating the mechanobiological mechanisms underlying atherosclerotic plaque formation and progression. However, the integration of advanced models of low-density lipoprotein (LDL) transport in the lumen and across the endothelium with agent-based models (ABMs) of plaque growth remains underexplored. Furthermore, patient-specific applications are lacking. This study introduces a novel agent-based modeling framework for atherosclerosis, integrating hemodynamics and LDL transport in the lumen through computational fluid dynamics simulations, a three-pore model of trans-endothelial LDL migration, and an ABM of lipid and cellular dynamics. For the first time, the framework was applied to a patient-specific coronary artery and validated against 1-year follow-up data. Furthermore, it was used to explore potential plaque evolution over 5 years and under elevated LDL concentration. The calibrated model predicted the 1-year variation in wall area in two patient-specific coronary cross-sections with an error of less than 10%. Simulated scenarios indicated that variations in blood LDL concentrations can result in distinct plaque morphologies, from localized to diffuse patterns. This study provided an innovative, advanced multiscale model of atherosclerotic plaque formation and progression. As the first patient-specific application of a multiscale agent-based modeling framework for atherosclerosis with initial validation, this study underscored the potential of the approach for deciphering the mechanobiological pathways driving coronary plaque progression. The developed model provided valuable insights into how the interplay between LDL transport and hemodynamics influences arterial wall cellular dynamics in a patient-specific context.},
  archive      = {J_CMAME},
  author       = {Anna Corti and Giuseppe De Nisco and Jolanda J. Wentzel and Francesco Migliavacca and Umberto Morbiducci and Claudio Chiastra},
  doi          = {10.1016/j.cma.2025.118427},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118427},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Personalized multiscale modeling of coronary plaque progression: The interaction between low-density-lipoprotein transport and cellular dynamics},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Linearized localized orthogonal decomposition for quasilinear nonmonotone elliptic PDE. <em>CMAME</em>, <em>448</em>, 118426. (<a href='https://doi.org/10.1016/j.cma.2025.118426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and analyze a multiscale method for a class of quasilinear elliptic problems of nonmonotone type with spatially multiscale coefficient. The numerical approach is inspired by the Localized Orthogonal Decomposition (LOD), so that we do not require structural assumptions such as periodicity or scale separation and only need minimal regularity assumptions on the coefficient. To construct the multiscale space, we solve linear fine-scale problems on small local subdomains, for which we consider two different linearization techniques. For both, we present a rigorous well-posedness analysis and convergence estimates in the H 1 -semi norm. We compare and discuss theoretically and numerically the performance of our strategies for different linearization points. Both numerical experiments and theoretical analysis demonstrate the validity and applicability of the method.},
  archive      = {J_CMAME},
  author       = {Maher Khrais and Barbara Verfürth},
  doi          = {10.1016/j.cma.2025.118426},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118426},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Linearized localized orthogonal decomposition for quasilinear nonmonotone elliptic PDE},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The isogeometric MITC shell in geometric nonlinear analysis. <em>CMAME</em>, <em>448</em>, 118425. (<a href='https://doi.org/10.1016/j.cma.2025.118425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends the isogeometric MITC shell formulation proposed by Mi and Yu (2021) for linear analysis to address geometric nonlinear shell problems. Built on the Reissner-Mindlin shell theory, the original linear formulation employs the Mixed Interpolation of Tensorial Components (MITC) technique to alleviate shear and membrane locking. The present nonlinear extension retains the MITC framework while incorporating a mixed Non-Uniform Rational B-Spline (NURBS)-Lagrange interpolation strategy to address the additional complexities induced by geometric nonlinearity. The interpolatory nature of the Lagrange basis functions is leveraged to simplify the construction of director vectors and assumed strain fields. The nonlinear problem is formulated in a total Lagrangian setting and solved using Newton-Raphson iterations. The effectiveness of the proposed method is demonstrated through a comprehensive set of numerical examples, including both standard benchmarks and a collection of geometric nonlinear shell problems, which features challenging behaviors such as large rotations and the development of local creases. Through Bézier extraction, the method is further evaluated using T-spline and U-spline basis functions. The numerical results confirm that the MITC technique effectively suppresses shear and membrane locking, and the proposed shell formulation exhibits high accuracy and robust convergence, even for coarse and severely distorted meshes. However, it is also observed that the high inter-element continuity inherent in splines-based discretization can inhibit large deformations, introducing a new form of locking. This issue is successfully mitigated using Bézier extraction to reduce the inter-element continuity. Overall, the proposed formulation offers a general and reliable isogeometric framework for geometrically nonlinear analysis, applicable across a wide range of shell geometries, loading conditions, and boundary constraints.},
  archive      = {J_CMAME},
  author       = {Yongzhen Mi},
  doi          = {10.1016/j.cma.2025.118425},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118425},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {The isogeometric MITC shell in geometric nonlinear analysis},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new pre-stressing algorithm for patient-specific simulations of growth and remodeling using the homogenized constrained mixture theory. <em>CMAME</em>, <em>448</em>, 118424. (<a href='https://doi.org/10.1016/j.cma.2025.118424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The homogenized constrained mixture theory has been implemented in different Finite-Element software packages for almost ten years to simulate growth and remodeling in soft biological tissues. In these models, it is essential to determine the pre-stresses of each constituent of the mixture in the reference configuration. However, no efficient numerical solution has been proposed so far to solve this problem. We propose to address this lack with a new algorithm based on the concept of anisotropic thermal contraction. In this algorithm, the pre-stretch tensor is incrementally updated by applying a series of anisotropic thermal contractions to each representative volume element of the model to restore its reference configuration. These contractions are proportional to the inverse of the local right stretch tensor, obtained through the polar decomposition of the deformation gradient. We implemented the algorithm in the Abaqus Finite-Element package through a UMAT subroutine and verified it on examples including growth and remodeling of a patient-specific aorta. We demonstrate that the model captures the residual stresses in good agreement with experimental results. To highlight the potential clinical relevance of the proposed algorithm, we expanded our model predictions to investigate the influence of the aortic axial pre-stretch on morphological and microstructural evolutions of the aorta under hypertensive conditions. Our simulations show that loss of axial tension, induced by hypertension, increases aortic length and may lead to pathological deformations such as aortic tortuosity. These findings highlight the importance of efficiently determining pre-stresses for simulating long-term vascular growth and remodeling.},
  archive      = {J_CMAME},
  author       = {Ali Akbar Karkhaneh Yousefi and Stéphane Avril},
  doi          = {10.1016/j.cma.2025.118424},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118424},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A new pre-stressing algorithm for patient-specific simulations of growth and remodeling using the homogenized constrained mixture theory},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GPU-accelerated multi-phase, multi-resolution SPH method with ray tracing for laser powder bed fusion. <em>CMAME</em>, <em>448</em>, 118423. (<a href='https://doi.org/10.1016/j.cma.2025.118423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powder-scale simulation of laser powder bed fusion (LPBF) is increasingly vital for understanding, predicting, and controlling metallurgical defects. However, the complex multi-physics and multi-material interactions involved, along with high computational demands, pose significant challenges. This study presents the first multiphase smoothed particle hydrodynamics (SPH) simulation framework for LPBF under both low and high evaporation regimes, incorporating a multi-resolution particle strategy and ray tracing (RT). An adaptive particle refinement (APR) method, compatible with multiphase SPH and optimized for GPU acceleration, is developed to enhance computational efficiency of the multiphase model. The RT model is also optimized and integrated with the APR-GPU architecture, further improving performance. A physics-based wetting force model is introduced, along with a novel method for improving normal vector accuracy near the contact line. The proposed framework is validated through three benchmark cases and applied to simulate LPBF processes. The results demonstrate that the framework achieves high accuracy and efficiency in resolving key LPBF phenomena, including melt pool dynamics and keyhole formation.},
  archive      = {J_CMAME},
  author       = {Yibo Ma and Zhilang Zhang and Christian Weißenfels and Minli Zhou and Lingxiao Ma and Xiaofei Tang and Moubin Liu},
  doi          = {10.1016/j.cma.2025.118423},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118423},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {GPU-accelerated multi-phase, multi-resolution SPH method with ray tracing for laser powder bed fusion},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-guided hybrid network for predicting nonlinear dynamic response of structures under bi-directional ground motions. <em>CMAME</em>, <em>448</em>, 118422. (<a href='https://doi.org/10.1016/j.cma.2025.118422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seismic structural response is a critical indicator for assessing collapse resistance and ensuring post-earthquake functionality. Therefore, accurate and rapid prediction of these responses is essential, with Deep Learning (DL) models offering a robust alternative to finite element methods due to their computational efficiency and capability to model nonlinear dynamic responses of structures. However, prevailing DL approaches predominantly focus on unidirectional seismic excitations, often neglecting the complex effects of bidirectional seismic excitations on real-world structures. Furthermore, while the development of the physics-informed neural network effectively enhances interpretability under limited data, most existing approaches incorporate physical constraints solely into the loss function, potentially leading to optimization conflicts and slow convergence rates. To bridge these gaps, this study introduces a novel physics-guided hybrid deep learning framework, the Physical Residual Long Short-term Memory network-Kolmogorov–Arnold network model (Phy-RLK), for real-time bidirectional seismic structural response prediction. The proposed DL architecture embeds the Newmark- β numerical integration scheme as a physical residual within LSTM cells. Simultaneously, the adaptive basis functions of the KAN enhance the feature extraction capability from bidirectional seismic inputs, enabling real-time correction of acceleration, velocity, and displacement predictions at each time step, thereby ensuring improved accuracy and physical consistency. The effectiveness of the proposed model is initially verified on a six-story Reinforced Concrete (RC) frame structure, determining optimal hyperparameters in the process. An ablation study further confirms the necessity of both the physics-residual LSTM cell and KAN layer. The model is subsequently implemented on a five-story RC frame structure to verify accuracy and applicability. The experimental results demonstrate that the Phy-RLK provides superior predictive accuracy and robustness, and significantly higher computational efficiency compared to finite element simulations.},
  archive      = {J_CMAME},
  author       = {Zheyi Guo and Jun Xu},
  doi          = {10.1016/j.cma.2025.118422},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118422},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Physics-guided hybrid network for predicting nonlinear dynamic response of structures under bi-directional ground motions},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sparse data assimilation for under-resolved large-eddy simulations. <em>CMAME</em>, <em>448</em>, 118421. (<a href='https://doi.org/10.1016/j.cma.2025.118421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for accurate and fast scale-resolving simulations of fluid flows, where turbulent dispersion is a crucial physical feature, is evident. Large-eddy simulations (LES) are computationally more affordable than direct numerical simulations, but their accuracy depends on sub-grid scale models and the quality of the computational mesh. In order to compensate related errors, a data assimilation approach for LES is devised in this work. The presented method is based on variational assimilation of sparse time-averaged velocity reference data. Working with the time-averaged LES momentum equation allows to employ a stationary discrete adjoint method. Therefore, a stationary corrective force in the unsteady LES momentum equation is iteratively updated within the gradient-based optimization framework in conjunction with the adjoint gradient. After data assimilation, corrected anisotropic Reynolds stresses are inferred from the stationary corrective force. Ultimately, this corrective force that acts on the mean velocity is replaced by a term that scales the velocity fluctuations through nudging of the corrected anisotropic Reynolds stresses. Efficacy of the proposed framework is demonstrated for turbulent flow over periodic hills and around a square cylinder. Coarse meshes are leveraged to further enhance the speed of the optimization procedure. Time- and spanwise-averaged velocity reference data from high-fidelity simulations is taken from the literature. Our results demonstrate that adjoint-based assimilation of averaged velocity enables the optimization of the mean flow, vortex shedding frequency (i. e., Strouhal number), and anisotropic Reynolds stresses. This highlights the superiority of scale-resolving simulations such as LES over simulations based on the (unsteady) Reynolds-averaged equations.},
  archive      = {J_CMAME},
  author       = {Justin Plogmann and Oliver Brenner and Patrick Jenny},
  doi          = {10.1016/j.cma.2025.118421},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118421},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Sparse data assimilation for under-resolved large-eddy simulations},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DGTO: Derivable geodesics-coupled topology optimization for multi-axis 3D printing of continuous fiber-reinforced spatial structures. <em>CMAME</em>, <em>448</em>, 118419. (<a href='https://doi.org/10.1016/j.cma.2025.118419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous fiber reinforced composites (CFRCs) are composite materials with exceptional mechanical properties to enhance structural mechanical performance. In comparison with traditional three-axis 3D printing (also referred to as 2.5D printing), multi-axis 3D printing simultaneously moves the nozzle and rotates the build platform during the printing process, making it particularly suited for fabricating spatial structures made of CFRCs due to better alignment between the fiber depositions and principal stress directions. In this research, we propose a Derivable Geodesics-coupled Topology Optimization (DGTO) method for design of CFRCs given the manufacturing scheme of multi-axis 3D printing. A prominent feature of DGTO is the introduction of two geodesic fields to achieve curved layer generation and continuous fiber path planning. The heat diffusion equation and Poisson equation are solved to produce the geodesic fields, and hence, all objective functions and constraints related to the slices and paths are derivable, making them perfectly suitable to be integrated with topology optimization. Hence, the proposed method concurrently optimizes the density field and the auxiliary geodesic fields, simultaneously tuning the material distribution and spatial fiber distribution, thereby attaining optimal performance while fulfilling the manufacturing constraints of multi-axis printing, i.e., self-support of structure and overlap/gap-free of continuous fibers. Four numerical examples are presented to demonstrate the effectiveness of the algorithm, especially showing outstanding performances than designs for traditional three-axis 3D printing.},
  archive      = {J_CMAME},
  author       = {Kaixian Liang and Jikai Liu and Shuzhi Xu and Yifan Guo},
  doi          = {10.1016/j.cma.2025.118419},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118419},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {DGTO: Derivable geodesics-coupled topology optimization for multi-axis 3D printing of continuous fiber-reinforced spatial structures},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Active evolutionary gaussian process for structural large-scale full-field reliability analysis and critical domain prognosis with only few initial samples. <em>CMAME</em>, <em>448</em>, 118418. (<a href='https://doi.org/10.1016/j.cma.2025.118418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability analysis is crucial for ensuring structural integrity, yet it requires repeated, time-consuming evaluations of responses and multivariate limit state functions, while struggling to provide full-field estimations efficiently. Therefore, we propose an active evolutionary reduced Gaussian Process framework ( AER-GP ) for fast and large-scale full-field reliability analysis and critical domain prognosis, utilizing only a few initial samples. In which we first define a novel probability indicator of erroneously evaluating the sign of the minimum of the full-field limit state function. Based on this, we then develop an efficient convergence criterion that relies on the expected error in failure probability estimates. Furthermore, we advance the dual order-reduced Gaussian process coupled Monte Carlo methods to accurately predict the large-scale full-field stochastic response under material and load uncertainty. Where the preliminary design of experiments starts from a significantly small number of sets (e.g.,5), and is progressively added by those samples containing the most information to distinguish the failure boundary. More importantly, we propose a novel mechanism for structural critical domain prognosis mechanism based on the failure probability of each single material point within the entire field, and make accurate critical domain prognosis. Real-world examples, including a car wheel hub and a single-tower cable-stayed bridge, demonstrate that the proposed algorithm achieves high prediction accuracy, computational efficiency, and robustness in large-scale structural reliability analysis and critical domain prognosis. It consistently outperforms widely used methods such as AK-MCS, EFF-MCS, ERF-MCS, and H-MCS. Notably, the proposed AER-GP method requires only a small number of initial DoE samples (fewer than 40), and through adaptive learning, it can reliably produce results with very low errors (typically less than 2%).},
  archive      = {J_CMAME},
  author       = {Xinlong Li and Chensen Ding},
  doi          = {10.1016/j.cma.2025.118418},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118418},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Active evolutionary gaussian process for structural large-scale full-field reliability analysis and critical domain prognosis with only few initial samples},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mixed-dimensional analysis for coupling 2D elastodynamics and timoshenko beam. <em>CMAME</em>, <em>448</em>, 118416. (<a href='https://doi.org/10.1016/j.cma.2025.118416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wave propagation is considered in a two-dimensional (2D) elastic structure, which includes a relatively small region whose behavior is fully 2D and a long and slender region whose bending behavior is like that of a Timoshenko beam. To save in computational effort, the latter region is reduced to a genuinely one-dimensional (1D) Timoshenko beam. The mathematical and computational problem posed then involves the coupling of the two regions, such that a well-posed, accurate, numerically stable and efficient hybrid 2D-elastic-Timoshenko-beam model is formed. The appropriate interface conditions are derived, and the well-posedness of the time-dependent problem is proved. A new computational coupling method is proposed, where the shape functions associated with the axial degrees of freedom on the interface of the elastic solid are modified in a special manner, to allow for the rotation continuity. The method results in a symmetric, positive and stable finite element formulation. Numerical examples are presented which demonstrate the performance of the scheme.},
  archive      = {J_CMAME},
  author       = {Daniel Rabinovich and Abimael F.D. Loula and Dan Givoli},
  doi          = {10.1016/j.cma.2025.118416},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118416},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Mixed-dimensional analysis for coupling 2D elastodynamics and timoshenko beam},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Variable stiffness boundary condition to determine effective toughness of heterogeneous materials. <em>CMAME</em>, <em>448</em>, 118414. (<a href='https://doi.org/10.1016/j.cma.2025.118414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a computational framework that combines a variable stiffness boundary condition (VSBC) with a phase-field model to evaluate the effective fracture toughness of heterogeneous materials. It is built on the so-called surfing boundary condition (SBC) that applies nonuniform displacement at the remote boundary to stabilize crack-propagation in a heterogeneous medium. Unlike SBC, VSBC is easily implementable in traditional universal testing machines and commercial software packages. The VSBC passively translates a simple, uniform remote displacement into a non-uniform load via an engineered stiffness gradient, enabling the stable, natural propagation of cracks along energetically favorable paths. The framework is validated on homogeneous materials, where the calculated J -integral precisely matches the prescribed fracture toughness. When applied to heterogeneous domains, the VSBC method successfully quantifies the increase in effective toughness due to stiffness and toughness contrasts and captures the critical transition from crack penetration to deflection. Experimental validation using 3D-printed samples confirms the model’s predictive capability. The VSBC framework provides a robust easily accessible tool for investigating fracture in complex materials and guide the design of advanced, fracture-resistant composites.},
  archive      = {J_CMAME},
  author       = {Tengyuan Hao and Adrian Piel and Zubaer Hossain},
  doi          = {10.1016/j.cma.2025.118414},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118414},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Variable stiffness boundary condition to determine effective toughness of heterogeneous materials},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph neural network surrogates for contacting deformable bodies with necessary and sufficient contact detection. <em>CMAME</em>, <em>448</em>, 118413. (<a href='https://doi.org/10.1016/j.cma.2025.118413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate models for the rapid inference of nonlinear boundary value problems in mechanics are helpful in a broad range of engineering applications. However, effective surrogate modeling of applications involving the contact of deformable bodies, especially in the context of varying geometries, is still an open issue. In particular, existing methods are confined to rigid body contact or, at best, contact between rigid and soft objects with well-defined contact planes. Furthermore, they employ contact or collision detection filters that serve as a rapid test but use only the necessary and not sufficient conditions for detection. In this work, we present a graph neural network architecture that utilizes continuous collision detection and, for the first time, incorporates sufficient conditions designed for contact between soft deformable bodies. We test its performance on two benchmarks, including a problem in soft tissue mechanics of predicting the closed state of a bioprosthetic aortic valve. We find a regularizing effect on adding additional contact terms to the loss function, leading to better generalization of the network. These benefits hold for simple contact at similar planes and element normal angles, and complex contact at differing planes and element normal angles. We also demonstrate that the framework can handle varying reference geometries. However, such benefits come with high computational costs during training, resulting in a trade-off that may not always be favorable. We quantify the training cost and the resulting inference speedups on various hardware architectures. Importantly, our graph neural network implementation results in up to a hundred- to thousand-fold speedup on GPU, and twenty- to two hundred-fold speedup on CPU for our benchmark problems at inference.},
  archive      = {J_CMAME},
  author       = {Vijay K. Dubey and Collin E. Haese and Osman Gültekin and David Dalton and Manuel K. Rausch and Jan Fuhg},
  doi          = {10.1016/j.cma.2025.118413},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118413},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Graph neural network surrogates for contacting deformable bodies with necessary and sufficient contact detection},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Personalized multiscale modeling of left atrial mechanics and blood flow. <em>CMAME</em>, <em>448</em>, 118412. (<a href='https://doi.org/10.1016/j.cma.2025.118412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a personalized multiscale mechanics model of the left atrium (LA) to simulate its deformation throughout the cardiac cycle and drive blood flow. Our patient data-driven model tightly integrates 3D structural mechanics of the LA myocardium, incorporating both passive and active components, with a 0D closed-loop lumped parameter network (LPN)-based circulatory system model. A finite element (FE) model of LA tissue is constructed from the patient’s images, assuming uniform thickness and employing rule-based fiber directions. We then adopted a multi-step personalization approach, in which the LPN parameters with a surrogate LA model are first optimized to match cuff-based blood pressures and cardiac lumen volumes derived from time-resolved 3D gated computed tomography angiography (CTA) images. The surrogate LA pressure during passive expansion is used to estimate myocardial passive mechanics parameters and the reference unloaded configuration using an inverse finite element analysis (iFEA) framework. Finally, a robust multiscale coupling is applied between the iFEA-optimized FE model and the tuned 0D LPN model to characterize LA contraction. This effectively captures the physiological LA pressure-volume curve and reasonably aligns with the image-based cavity volumes and deformation. We then imposed the resulting simulation-predicted deformation as a moving-wall boundary condition to model atrial hemodynamics. We analyzed the model sensitivities to various simplifications to demonstrate its robustness and versatility and discussed potential future improvements. Overall, this comprehensive digital twinning platform could be applied to study LA biomechanics in health and disease and assist in devising personalized treatment plans.},
  archive      = {J_CMAME},
  author       = {Lei Shi and Boyang Gan and Ian Y. Chen and Vijay Vedula},
  doi          = {10.1016/j.cma.2025.118412},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118412},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Personalized multiscale modeling of left atrial mechanics and blood flow},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum neural network-assisted topology optimization: Concept and implementation with parameterized quantum circuits. <em>CMAME</em>, <em>448</em>, 118411. (<a href='https://doi.org/10.1016/j.cma.2025.118411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a quantum machine learning-assisted approach to accelerating density-based topology optimization using quantum neural network (QNN), a class of trainable models based on parameterized quantum circuits (PQCs). The proposed framework extracts key features from classical data, starting by encoding the corresponding finite element analysis results, i.e., strain energy, sensitivity, and design variables from early design iterations obtained using the standard optimizer. Then, the PQCs are fine-tuned using minimization of the binary cross-entropy loss function, enabling the model to learn the mapping between input features and optimal design. Specifically, the framework consists of two main stages. First, an offline training stage where the QNN is calibrated using precomputed iterative results from a relatively coarse mesh obtained through the standard optimizer, establishing pattern recognition between input features and the final design variables. The second is an online stage where the trained QNN model is integrated with the standard optimizer to accelerate the final design. Numerical results show that QNN requires only a small number of qubits, and once trained on coarse meshes with several different boundary conditions, can effectively integrate with standard optimizers to predict target designs across various configurations, including different resolutions, volume constraints, and loading conditions. Furthermore, the proposed QNN-assisted framework significantly reduces computational time compared to standard iterative approaches, laying the groundwork for solving large-scale problems with near-term quantum computers.},
  archive      = {J_CMAME},
  author       = {Naruethep Sukulthanasorn and Kenjiro Terada},
  doi          = {10.1016/j.cma.2025.118411},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118411},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Quantum neural network-assisted topology optimization: Concept and implementation with parameterized quantum circuits},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generative emulation of chaotic dynamics with coherent prior. <em>CMAME</em>, <em>448</em>, 118410. (<a href='https://doi.org/10.1016/j.cma.2025.118410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven emulation of nonlinear dynamics is challenging due to long-range skill decay that often produces physically unrealistic outputs. Recent advances in generative modeling aim to address these issues by providing uncertainty quantification and correction. However, the quality of generated simulation remains heavily dependent on the choice of conditioning prior. In this work, we present an efficient generative framework for nonlinear dynamics emulation, connecting principles of turbulence with diffusion-based modeling: Cohesion. Our method estimates large-scale coherent structure of the underlying dynamics as guidance during the denoising process, where small-scale fluctuation in the flow is then resolved. These coherent prior are efficiently approximated using reduced-order models, such as deep Koopman operators, that allow for rapid generation of long prior sequences while maintaining stability over extended forecasting horizon. With this gain, we can reframe forecasting as trajectory planning, a common task in reinforcement learning, where conditional denoising is performed once over entire sequences, minimizing the computational cost of autoregressive-based generative methods. Numerical evaluations on chaotic systems of increasing complexity, including Kolmogorov flow, shallow water equations, and subseasonal-to-seasonal climate dynamics, demonstrate Cohesion superior long-range forecasting skill that can efficiently generate physically-consistent simulations, even in the presence of partially-observed guidance.},
  archive      = {J_CMAME},
  author       = {Juan Nathaniel and Pierre Gentine},
  doi          = {10.1016/j.cma.2025.118410},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118410},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Generative emulation of chaotic dynamics with coherent prior},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Concurrent 3D topology optimization method for hierarchical hybrid structures under static and dynamic loads with CPU-GPU heterogeneous parallelism. <em>CMAME</em>, <em>448</em>, 118408. (<a href='https://doi.org/10.1016/j.cma.2025.118408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology optimization of 3D hierarchical hybrid structures (HHS) is constrained by the coupling of high-dimensional design spaces and multiscale computational complexity, often addressed by restricting certain designable components, which limits the full exploration of the design space and realization of performance potential. This paper proposes a novel concurrent topology optimization method for 3D-HHS, achieving concurrent optimization of all designable components, including macroscopic topology, substructural topology, and their spatial distribution, under static and dynamic loads. This approach significantly expands the design space, enhancing the mechanical performance of hierarchical structures. To address the computational challenges of large-scale 3D problems, we employ CPU-GPU heterogeneous parallel computing to improve the efficiency of structural response and sensitivity analysis. Numerical examples demonstrate that this method delivers superior 3D-HHS designs with markedly improved optimization efficiency, providing an innovative solution for efficient 3D structural optimization.},
  archive      = {J_CMAME},
  author       = {Yunfei Liu and Ruxin Gao and Ying Li and Daining Fang},
  doi          = {10.1016/j.cma.2025.118408},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118408},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Concurrent 3D topology optimization method for hierarchical hybrid structures under static and dynamic loads with CPU-GPU heterogeneous parallelism},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tensegrity structures and data-driven analysis for 3D cell mechanics. <em>CMAME</em>, <em>448</em>, 118406. (<a href='https://doi.org/10.1016/j.cma.2025.118406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cytoskeleton (CSK) plays an important role in many cell functions. Given the similarities between the mechanical behavior of tensegrity structures and the CSK, many studies have proposed different tensegrity-based models for simulating cell mechanics. However, the low symmetry of most tensegrity units has hindered the analysis of realistic 3D structures. As a result, tensegrity-based modeling in cell mechanics has been mainly focused on single cells or monolayers. In this paper, we propose a 3D tensegrity model based on the finite element method for simulating 3D cell mechanics. We show that the proposed model not only captures the nonlinearity of a single cell in an indentation test and a monolayer in stretch test but also the non-uniform stress distribution in multicellular spheroids upon non-uniform prestress design. Furthermore, we introduce a multiscale data-driven framework for cellular mechanics to optimize the computation, thus paving the way for modeling the mechanobiology of large cellular assemblies such as organs.},
  archive      = {J_CMAME},
  author       = {Ziran Zhou and Jacinto Ulloa and Guruswami Ravichandran and José E. Andrade},
  doi          = {10.1016/j.cma.2025.118406},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118406},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Tensegrity structures and data-driven analysis for 3D cell mechanics},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Configuration-decoupled concurrent topology optimization of heterogeneous lattice structures. <em>CMAME</em>, <em>448</em>, 118405. (<a href='https://doi.org/10.1016/j.cma.2025.118405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-configuration lattice structures have recently been introduced into structural optimization due to their broadly tunable physical properties. Traditional methods for multi-configuration lattice optimization employ extreme strategies of complete fusion or separation, leading to a trade-off between optimality and scalability that has not been fully addressed in the existing literature. The paper suggests decomposing the lattice library into pairs of lattices, through which multi-configuration lattice optimization is decoupled into the concurrent optimization of iso-value, combination category, and ratio within combination. A novel hybrid interpolation scheme is proposed to describe the effective mechanical behavior of the configuration-decoupled lattices. In this approach, polynomial models are employed to characterize the performance of individual lattice combinations, while the Uniform Multiphase Materials Interpolation model is used to integrate the contributions of all combinations. Benchmark experiments, including full-scale simulations, are conducted to validate the effectiveness of the framework. The proposed method enables rapid convergence to configuration layouts that align with the principal stress orientations. Compared to single- and dual-configuration designs, it achieves compliance reductions of 61.0 % and 26.2 %, respectively, approaching the performance of density-based topology optimization. Extended numerical experiments reveal the joint influence of resolution and configuration count on the overall performance. This method achieves a better trade-off between optimality and extensibility, enabling more flexible utilization of large lattice databases in practical engineering fields.},
  archive      = {J_CMAME},
  author       = {Xinze Shen and Changdong Zhang and Wenhe Liao and Dawei Li and Tingting Liu},
  doi          = {10.1016/j.cma.2025.118405},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118405},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Configuration-decoupled concurrent topology optimization of heterogeneous lattice structures},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intrepid MCMC: Metropolis-hastings with exploration. <em>CMAME</em>, <em>448</em>, 118402. (<a href='https://doi.org/10.1016/j.cma.2025.118402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In engineering examples, one often encounters the need to sample from unnormalized distributions with complex shapes that may also be implicitly defined through a physical or numerical simulation model, making it computationally expensive to evaluate the associated density function. For such cases, MCMC has proven to be an invaluable tool. Random-walk Metropolis Methods (also known as Metropolis-Hastings (MH)), in particular, are highly popular for their simplicity, flexibility, and ease of implementation. However, most MH algorithms suffer from significant limitations when attempting to sample from distributions with multiple modes (particularly disconnected ones). In this paper, we present Intrepid MCMC - a novel MH scheme that utilizes a simple coordinate transformation to significantly improve the mode-finding ability and convergence rate to the target distribution of random-walk Markov chains while retaining most of the simplicity of the vanilla MH paradigm. Through multiple examples, we showcase the improvement in the performance of Intrepid MCMC over vanilla MH for a wide variety of target distribution shapes. We also provide an analysis of the mixing behavior of the Intrepid Markov chain, as well as the efficiency of our algorithm for increasing dimensions. A thorough discussion is presented on the practical implementation of the Intrepid MCMC algorithm. Finally, its utility is highlighted through a Bayesian parameter inference problem for a two-degree-of-freedom oscillator under free vibration.},
  archive      = {J_CMAME},
  author       = {Promit Chakroborty and Michael D. Shields},
  doi          = {10.1016/j.cma.2025.118402},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118402},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Intrepid MCMC: Metropolis-hastings with exploration},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-level overlapping additive schwarz preconditioner for training scientific machine learning applications. <em>CMAME</em>, <em>448</em>, 118400. (<a href='https://doi.org/10.1016/j.cma.2025.118400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel two-level overlapping additive Schwarz preconditioner for accelerating the training of scientific machine learning applications. The design of the proposed preconditioner is motivated by the nonlinear two-level overlapping additive Schwarz preconditioner. The neural network parameters are decomposed into groups (subdomains) with overlapping regions. In addition, the network’s feed-forward structure is indirectly imposed through a novel subdomain-wise synchronization strategy and a coarse-level training step. Through a series of numerical experiments, which consider physics-informed neural networks and operator learning approaches, we demonstrate that the proposed two-level preconditioner significantly speeds up the convergence of the standard (LBFGS) optimizer while also yielding more accurate machine learning models. Moreover, the devised preconditioner is designed to take advantage of model-parallel computations, which can further reduce the training time.},
  archive      = {J_CMAME},
  author       = {Youngkyu Lee and Alena Kopaničáková and George Em Karniadakis},
  doi          = {10.1016/j.cma.2025.118400},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118400},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Two-level overlapping additive schwarz preconditioner for training scientific machine learning applications},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cohesive zone treatment for the material point method involving problems of large deformation and damage. <em>CMAME</em>, <em>448</em>, 118399. (<a href='https://doi.org/10.1016/j.cma.2025.118399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new algorithm is described that permits the use of cohesive zones in the material point method for problems involving large deformation and fracture. In contrast to previous cohesive zone implementations, this method does not utilize massless surface-element particles. Instead, cohesive tractions are computed using the shape function mappings from a reference grid configuration in combination with explicitly defined particle surface normals and surface positions. These normals and relative surface positions are updated each time step according to particle deformation. The tractions are converted to cohesive forces using the nodal areas and mapped back to particles using the same reference shape function mappings. These forces are then remapped by conventional particle-to-grid interpolation as external forces using the current-configuration shape-function mappings. This allows highly compliant cohesive zones to function over jump displacements larger than a grid cell. Upon damage, these interfaces can revert to conventional multi-field contact surfaces. This approach is general and readily applies to two and three dimensions as well as being compatible with damage-field gradient partitioning offering exceptional computational flexibility. The framework for this method enables other capabilities, such as improved contact precision using explicitly defined surface normals and positions, and a method to mitigate spurious material damage at weak discontinuities between stiff brittle materials and soft or compliant materials.},
  archive      = {J_CMAME},
  author       = {Cameron M. Crook and Michael A. Homel},
  doi          = {10.1016/j.cma.2025.118399},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118399},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A cohesive zone treatment for the material point method involving problems of large deformation and damage},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overlapping schwarz preconditioners for isogeometric discretizations of acoustic wave problems. <em>CMAME</em>, <em>448</em>, 118397. (<a href='https://doi.org/10.1016/j.cma.2025.118397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this work is to construct and analyze two-level overlapping additive Schwarz (OAS) preconditioners for isogeometric discretizations of the acoustic wave equation with absorbing boundary conditions. Both Collocation and Galerkin isogeometric methods are employed for space discretization, while time advancing is performed by means of a Newmark implicit scheme. The linear systems to be solved at each time step are ill conditioned, especially in case of highly regular splines, thus their solution requires the use of effective preconditioners. Two-level OAS solvers consist of partitioning the domain into overlapping subdomains, solving independent local problems on each subdomain and an additional coarse problem associated with the subdomain mesh. Several two-dimensional numerical results validate our theoretical estimates, showing the scalability and quasi-optimality of the algorithms proposed. We also investigate numerically the robustness of the OAS preconditioners with respect to the spline polynomial degree, the spline regularity and the overlap parameter.},
  archive      = {J_CMAME},
  author       = {Elena Zampieri and Simone Scacchi and Luca F. Pavarino},
  doi          = {10.1016/j.cma.2025.118397},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118397},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Overlapping schwarz preconditioners for isogeometric discretizations of acoustic wave problems},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Latent space modeling of parametric and time-dependent PDEs using neural ODEs. <em>CMAME</em>, <em>448</em>, 118394. (<a href='https://doi.org/10.1016/j.cma.2025.118394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Differential Equations (PDEs) are central to science and engineering. Since solving them is computationally expensive, a lot of effort has been put into approximating their solution operator via both traditional and recently increasingly Deep Learning (DL) techniques. In this paper, we propose an autoregressive and data-driven method using the analogy with classical numerical solvers for time-dependent, parametric and (typically) nonlinear PDEs. We present how Dimensionality Reduction (DR) can be coupled with Neural Ordinary Differential Equations (NODEs) in order to learn the solution operator of arbitrary PDEs accounting both for (continuous) time and parameter dependency. The idea of our work is that it is possible to map the high-fidelity (i.e., high-dimensional) PDE solution space into a reduced (low-dimensional) space, which subsequently exhibits dynamics governed by a (latent) Ordinary Differential Equation (ODE). Solving this (easier) ODE in the reduced space allows avoiding solving the PDE in the high-dimensional solution space, thus decreasing the computational burden for repeated calculations for e.g., uncertainty quantification or design optimization purposes. The main outcome of this work is the importance of exploiting DR as opposed to the recent trend of building large and complex architectures: we show that by leveraging DR we can deliver not only more accurate predictions, but also a considerably lighter and faster DL model compared to existing methodologies.},
  archive      = {J_CMAME},
  author       = {Alessandro Longhi and Danny Lathouwers and Zoltán Perkó},
  doi          = {10.1016/j.cma.2025.118394},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118394},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Latent space modeling of parametric and time-dependent PDEs using neural ODEs},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Geometry-agnostic model reduction with GNN-generated reduced POD bases and boosted PGD enrichment for (non)linear structural elastodynamics. <em>CMAME</em>, <em>448</em>, 118357. (<a href='https://doi.org/10.1016/j.cma.2025.118357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This contribution proposes a new and significantly enhanced extension of a recently-introduced hybrid Graph Neural Network (GNN)-based reduced-order modeling approach for the numerical solution of time-dependent partial differential equations on non-parametric finite element meshes. Building upon previous proof-of-concept work, this more generalized framework presents a number of key novelties: tight integration of graph-based learning with physical information via direct imposition of finite element operators as node and edge level features; introduction of a Grassmannian subspace distance measure as a dedicated training objective; incorporation of a Gated Recurrent Unit (GRU) for a more efficient and lightweight architecture; hybridization with other Galerkin-based reduced-order methods such as the Proper Orthogonal Decomposition (POD); and a first treatment of nonlinear problems. A novel, on-the-fly enrichment mechanism, modified from a classical Proper General Decomposition (PGD) and dubbed ”Boosted PGD”, is additionally introduced to improve prediction accuracy at low computational cost via additional greedy corrective modes. The efficacy of the overall methodology is assessed on two challenging datasets featuring significant geometric and topological variations that include highly heterogeneous spatial discretizations. A variety of performance studies demonstrate very competitive accuracy and computational cost in simulating highly-dynamic behavior when compared to conventional full-order finite element models, including a remarkable capacity to generalize to configurations well outside of the topological scope of the original training and validation sets. Results imply that solvers constructed from such an approach may enable more scalable and robust mechanical simulations for complex, real-world engineering applications related to iterative design.},
  archive      = {J_CMAME},
  author       = {Victor Matray and David Néron and Frédéric Feyel and Faisal Amlani},
  doi          = {10.1016/j.cma.2025.118357},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118357},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Geometry-agnostic model reduction with GNN-generated reduced POD bases and boosted PGD enrichment for (non)linear structural elastodynamics},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weighted eigenseparation-based residual approach for model reduction of interface failure in heterogeneous materials. <em>CMAME</em>, <em>448</em>, 118352. (<a href='https://doi.org/10.1016/j.cma.2025.118352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interface failure plays a critical role in the degradation of heterogeneous materials, often governing structural integrity across a range of applications from fiber-reinforced composites to polycrystalline rocks. This paper introduces a novel model reduction framework—the Weighted Eigenseparation-based Residual (WER) approach—for efficiently simulating interface failure using cohesive zone models. Two variants of the WER are developed: a force-based formulation that weakly enforces equilibrium equations at the interface at the modal level and a separation-based formulation that weakly enforces contact conditions at the modal level. These formulations are supported by precomputed influence functions within representative volume elements (RVEs), significantly reducing computational cost while preserving accuracy. The separation-based variant, in particular, demonstrates broad applicability across microstructures with interface junctions. Numerical examples in two and three dimensions—including fiber composites and geological microstructures—demonstrate the effectiveness, convergence behavior, and computational advantages of the WER over direct numerical simulations. The results show that high-fidelity predictions can be obtained even with coarsely discretized interface modes, confirming the robustness and versatility of the WER methodology.},
  archive      = {J_CMAME},
  author       = {Jacob Fish and Junhe Cui},
  doi          = {10.1016/j.cma.2025.118352},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118352},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Weighted eigenseparation-based residual approach for model reduction of interface failure in heterogeneous materials},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="comcom">COMCOM - 10</h2>
<ul>
<li><details>
<summary>
(2025). META: Multi-classified encrypted traffic anomaly detection with fine-grained flow and interaction analysis. <em>COMCOM</em>, <em>243</em>, 108333. (<a href='https://doi.org/10.1016/j.comcom.2025.108333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasive implementation of encryption mechanisms has introduced considerable obstacles to anomalous traffic detection, rendering conventional attack detection methodologies that rely on packet payload characteristics ineffectual. In the absence of plaintext information, current anomaly encrypted traffic detection mainly relies on traffic data analysis to identify and characterize anomalous attack patterns in encrypted traffic, employing machine learning or deep learning models. However, the existing methods still suffer from limited detection capabilities, especially the ability to classify multi-class attacks due to insufficient internal and external features. In this paper, we propose a Multi-classified Encrypted Traffic Anomaly Detection (META) method. META refines and extends the available feature dimensions in encrypted traffic by leveraging two key aspects: the internal interaction behavior information within the traffic and the external interaction behavior information in network topology. Specifically, an in-depth examination of the internal packet interaction features is undertaken, resulting in a novel feature set, designated as META-Features, encompassing 278 fine-grained statistical features. Furthermore, a Graph Neural Network (GNN) is employed to learn the external interaction behavior in the network topology from the embedding of the IP node graph and flow edge graph. The results of the experiments demonstrate that the refined feature set META-Features significantly enhances the model’s detection capabilities. Thereby, the META-GNN model exhibits superior performance compared to the traditional approaches, with an accuracy of 91.90% and an F1-score of 87.41%.},
  archive      = {J_COMCOM},
  author       = {Boyu Kuang and Yuchi Chen and Yansong Gao and Yaqian Xu and Anmin Fu and Willy Susilo},
  doi          = {10.1016/j.comcom.2025.108333},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108333},
  shortjournal = {Comput. Commun.},
  title        = {META: Multi-classified encrypted traffic anomaly detection with fine-grained flow and interaction analysis},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating scalability of median-based ADR under different mobility conditions. <em>COMCOM</em>, <em>243</em>, 108322. (<a href='https://doi.org/10.1016/j.comcom.2025.108322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The LoRaWAN protocol is widely used in Internet of Things (IoT) applications due to its ability to provide long-range, low-power communication. The Adaptive Data Rate (ADR) mechanism dynamically adjusts transmission parameters to optimize energy consumption. However, ADR is primarily designed for static devices, which limits its effectiveness in mobile environments, where fluctuating signal conditions can degrade performance. To address this limitation, the Median-Based ADR (MB-ADR) scheme was introduced, leveraging statistical measures to improve ADR adaptability to changing channel conditions. This study evaluates the scalability of MB-ADR in networks with up to 1,000 end devices and node speeds of up to 20 m/s, considering mobility models such as Random Walk and Gauss–Markov. The results show that MB-ADR demonstrates superior performance in scenarios with realistic mobility patterns, particularly under the Steady-State Random Waypoint model, resulting in improvements of up to 15% in Packet Delivery Ratio (PDR) and 55% in energy efficiency compared to a Kalman filter-based scheme under the same mobility model. Additionally, the analysis demonstrates the effectiveness of MB-ADR in improving throughput and reducing collisions by promoting an efficient distribution of spreading factors. Overall, the study confirms the potential of MB-ADR to enhance communication reliability and energy efficiency in mobile IoT networks, making it a viable solution for large-scale, high-density IoT deployments with variable mobility.},
  archive      = {J_COMCOM},
  author       = {Geraldo A. Sarmento Neto and Thiago A.R. da Silva and Artur F. da S. Veloso and Pedro Felipe de Abreu and Luis H. de O. Mendes and J. Valdemir dos Reis Jr},
  doi          = {10.1016/j.comcom.2025.108322},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108322},
  shortjournal = {Comput. Commun.},
  title        = {Evaluating scalability of median-based ADR under different mobility conditions},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting the problem of optimizing spreading factor allocations in LoRaWAN: From theory to practice. <em>COMCOM</em>, <em>243</em>, 108321. (<a href='https://doi.org/10.1016/j.comcom.2025.108321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper revisits the problem of optimizing LoRa network success probability by proposing an optimized allocation strategy for Spreading Factors (SFs) under both uniform and Gaussian network deployments with a single or multiple gateways. More specifically, we solve the problem of finding the best SF allocations in dense network deployments whose EDs are first assigned with the minimum SF. Theoretical models are developed to quantify the success probability of transmissions, considering the capture effect as well as intra- and inter-SF interference. A mathematical optimization framework is introduced to determine the optimal SF distribution that maximizes the average probability of packet reception. The problem is solved using Mixed Integer Linear Programming (MILP), and then evaluated using simulations. Even though optimal SF allocation strategies have been proposed in the literature, no practical insights have been discovered and no real-world deployments have been considered. To this extent, the practical benefits of using improved or optimal SF settings are discovered in this paper. Simulation results confirm the theoretical findings while they demonstrate an up to 10 percentage points improvements in Packet Reception Ratio (PRR) in the real-world use-case.},
  archive      = {J_COMCOM},
  author       = {Dimitrios Zorbas and Aruzhan Sabyrbek and Luigi Di Puglia Pugliese},
  doi          = {10.1016/j.comcom.2025.108321},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108321},
  shortjournal = {Comput. Commun.},
  title        = {Revisiting the problem of optimizing spreading factor allocations in LoRaWAN: From theory to practice},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy consumption optimization in UAV-assisted multi-layer mobile edge computing with active transmissive RIS. <em>COMCOM</em>, <em>243</em>, 108320. (<a href='https://doi.org/10.1016/j.comcom.2025.108320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV)-assisted edge computing provides low-latency and low-energy consumption computing capabilities for sparsely distributed Internet of Things (IoT) networks. In addition, the assisted UAVs provide line-of-sight links to further improve communication quality. However, the existing offloading strategies have low efficiency and high costs. Motivated by this, we propose a novel UAV-assisted multi-layer mobile edge computing network with active transmissive reconfigurable intelligent surface (RIS). The introduced an active transmissive RIS not only receives data from UAVs but also performs computing functionality. We establish an optimization to minimize the total system energy consumption under delay constraints by jointly planning UAV positions and allocating computing bits, sub-carriers, time slots, transmission power, and RIS transmission coefficient. To tackle this problem, we first use the block coordinate descent (BCD) algorithm to decouple it into four sub-problems. Then, we solve them by adopting successive convex approximation (SCA), difference-convex (DC) programming, and introducing slack variables. Experimental results demonstrate that the proposed network is superior to the other five baselines concerning energy consumption reduction. Also, the influences of system parameters are verified, including the number of IoT devices, the number of RIS elements, and the delay threshold.},
  archive      = {J_COMCOM},
  author       = {Kexin Yang and Yaxi Liu and Boxin He and Jiahao Huo and Wei Huangfu},
  doi          = {10.1016/j.comcom.2025.108320},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108320},
  shortjournal = {Comput. Commun.},
  title        = {Energy consumption optimization in UAV-assisted multi-layer mobile edge computing with active transmissive RIS},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RIS-assisted LoRa networks with diversity: Impact of hardware impairments and phase noise. <em>COMCOM</em>, <em>243</em>, 108319. (<a href='https://doi.org/10.1016/j.comcom.2025.108319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the performance of downlink LoRa networks assisted by reconfigurable intelligent surfaces (RIS) and diversity techniques. We derive closed-form expressions for the coverage probability (Pcov) under four scenarios: phase noise at the RIS only, hardware impairments at both the gateway and end devices (EDs), the combined effect of both impairments, and an ideal benchmark case. The analysis is carried out within a unified framework that is valid for any number of RIS elements, providing key insights into the influence of hardware impairment levels, gateway transmit power, and the diversity order as the number of RIS elements grows large. The results reveal that coverage probability improves with transmit power but deteriorates under more severe hardware impairments, while the diversity order scales directly with the number of RIS elements. Monte Carlo simulations validate the analytical findings and confirm that the ideal scenario achieves the best performance, followed in order by the phase noise, hardware impairment, and combined impairment cases.},
  archive      = {J_COMCOM},
  author       = {Thi-Phuong-Anh Hoang and Thien Huynh-The and Tien Hoa Nguyen and Trong-Thua Huynh and Nguyen-Son Vo and Lam-Thanh Tu},
  doi          = {10.1016/j.comcom.2025.108319},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108319},
  shortjournal = {Comput. Commun.},
  title        = {RIS-assisted LoRa networks with diversity: Impact of hardware impairments and phase noise},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channel-hopping sequence generation for blind rendezvous in cognitive radio-enabled internet of vehicles: A multi-agent twin delayed deep deterministic policy gradient-based method. <em>COMCOM</em>, <em>243</em>, 108318. (<a href='https://doi.org/10.1016/j.comcom.2025.108318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient spectrum utilization is a major challenge in highly dynamic vehicular environments due to the scarcity of spectrum resources. Cognitive Radio (CR) has emerged as a solution to improve spectrum utilization by enabling opportunistic access in IoV. In this context, channel-hopping based blind rendezvous offers a practical approach for decentralized spectrum access in CR-enabled IoV (CR-IoV). This paper presents a novel Multi-Agent Twin Delayed Deep Deterministic Policy Gradient (MATD3PG)-based strategy for generating channel sequences in channel-hopping-based blind rendezvous. Unlike existing methods that overlook the quality of licensed spectrum, our approach ensures spectrum efficiency and QoS awareness in dynamic channel sequence generation. We formulate the channel sequence selection problem as a multi-objective optimization, aiming to maximize spectrum efficiency and minimize Time-To-Rendezvous (TTR) while meeting stringent latency and reliability requirements for vehicular communications. Each vehicle independently generates a channel-hopping sequence using a learning agent, which considers key channel quality metrics such as availability, reliability, and capacity. The generated sequences are employed in an asynchronous and asymmetric blind rendezvous process, enhancing adaptability to dynamic network conditions. Simulation results demonstrate that the proposed method significantly outperforms existing approaches, including Enhanced Jump-Stay (EJS), Single-radio Sunflower Set (SSS), Zero-type, One-type, and S-type (ZOS), Multi-Agent Q-Learning based Rendezvous (MAQLR), Exponential-weight algorithm for Exploration and Exploitation (Exp3), and Reinforcement Learning-based Channel-Hopping Rendezvous (RLCH) in terms of Expected TTR (ETTR), Maximum TTR (MTTR), delay, capacity, and reliability.},
  archive      = {J_COMCOM},
  author       = {Mehri Asadi Vasfi and Behrouz Shahgholi Ghahfarokhi},
  doi          = {10.1016/j.comcom.2025.108318},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108318},
  shortjournal = {Comput. Commun.},
  title        = {Channel-hopping sequence generation for blind rendezvous in cognitive radio-enabled internet of vehicles: A multi-agent twin delayed deep deterministic policy gradient-based method},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor-based task allocation using multi-objective optimization in GECC environment. <em>COMCOM</em>, <em>243</em>, 108316. (<a href='https://doi.org/10.1016/j.comcom.2025.108316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green Edge-Cloud Computing (GECC) has emerged as a promising paradigm to meet the diverse requirements of modern applications by integrating edge and cloud resources. Existing task allocation strategies in GECC environment often fail to adequately address the problems of low resource utilization and high economic cost in multi-objective conflicts. Therefore, this paper proposes a tensor-based task allocation scheme using multi-objective optimization in GECC environment. We first extend the task allocation problem in GECC environment to a multi-objective optimization problem and construct five optimization models, i.e., energy, system reliability, quality of experience, economic cost, and latency. Then, to address the complex relationship among these objectives, we develop a tensor-based representation and calculation model for task allocation across cloud, edge service, and edge device platforms. Furthermore, we propose a tensor-based multi-objective beetle swarm optimization algorithm combined speed limiting and dynamic step strategies (TMOBSO-SLDS) that dynamically adjusts the step size and limit speed to improve the global search efficiency and the diversity of solution set. Extensive experimental results in various task allocation scenarios demonstrate that our proposed TMOBSO-SLDS algorithm outperforms existing approaches, as measured by the HV value. It can significantly enhance the diversity of the solution set and improve resource utilization.},
  archive      = {J_COMCOM},
  author       = {Huazhong Liu and Longtao Huang and Yuan Tian and Jihong Ding and Xiaoxue Yin and Guangshun Zhang},
  doi          = {10.1016/j.comcom.2025.108316},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108316},
  shortjournal = {Comput. Commun.},
  title        = {Tensor-based task allocation using multi-objective optimization in GECC environment},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A preemptive task unloading scheme based on second optional unloading in cloud-fog collaborative networks. <em>COMCOM</em>, <em>243</em>, 108315. (<a href='https://doi.org/10.1016/j.comcom.2025.108315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-distance data transmission between Internet of Things (IoT) devices and remote cloud center often leads to unacceptable latency for certain tasks. Fog computing has emerged as a promising solution for low-latency tasks. Consequently, the concept of cloud-fog collaborative networks has garnered significant attention. However, existing research primarily focuses on heterogeneous tasks, overlooking the crucial aspect of considering both task priority and second unloading. To address this gap, this paper proposes a novel task unloading scheme that concurrently takes preemptive priority and second optional unloading into account. In this scheme, delay-sensitive tasks (DSTs) are given preemptive priority over delay-tolerant tasks (DTTs). Furthermore, some DTTs may undergo preprocessing in the fog layer to optimize resource utilization. Moreover, tasks encountering blocking or preemption in the fog layer can also be secondarily unloaded to the cloud layer. In this framework, we devise a four-dimensional Markov chain (4DMC) to model and analyze this process. Through numerical experiments, we assess performance indicators under various parameters. Ultimately, our proposed strategy is compared with the unloading scheme that does not incorporate second unloading through both numerical analysis and simulation validation. The results indicate that our scheme notably enhances the throughput of DTTs, albeit at a marginal performance trade-off.},
  archive      = {J_COMCOM},
  author       = {Yuan Zhao and Hongmin Gao and Shuaihua Liu},
  doi          = {10.1016/j.comcom.2025.108315},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108315},
  shortjournal = {Comput. Commun.},
  title        = {A preemptive task unloading scheme based on second optional unloading in cloud-fog collaborative networks},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ScaleIP: A hybrid autoscaling of VoIP services based on deep reinforcement learning. <em>COMCOM</em>, <em>243</em>, 108314. (<a href='https://doi.org/10.1016/j.comcom.2025.108314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive resource provisioning has become crucial for cloud-based applications, especially those managing real-time traffic like Voice over IP (VoIP), which experience rapidly fluctuating workloads. Traditional static provisioning methods often fall short in these dynamic environments, leading to inefficiencies and potential service disruptions. Existing solutions struggle to maintain performance under varying traffic conditions, particularly for time-sensitive applications. This paper introduces ScaleIP, a hybrid autoscaling solution for containerized VoIP services that offers real-time adaptability and efficient resource management. ScaleIP leverages Deep Reinforcement Learning to make dynamic and efficient scaling decisions, improving call latency, increasing the number of successfully routed calls, and maximizing resource utilization. We evaluated ScaleIP through extensive experiments conducted on a real testbed utilizing the customer Call Detail Record (CDR) from 2023 provided by World Direct, encompassing over 89 million calls. The results show that ScaleIP consistently maintains call latency below 2 s, increases the number of successfully routed calls by 3.26 ×, and increases the resource utilization up to 60 % compared to state-of-the-art autoscaling methods.},
  archive      = {J_COMCOM},
  author       = {Zahra Najafabadi Samani and Juan Aznar Poveda and Dominik Gratz and Rene Hueber and Philipp Kalb and Thomas Fahringer},
  doi          = {10.1016/j.comcom.2025.108314},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108314},
  shortjournal = {Comput. Commun.},
  title        = {ScaleIP: A hybrid autoscaling of VoIP services based on deep reinforcement learning},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond performance comparing the costs of applying deep and shallow learning. <em>COMCOM</em>, <em>243</em>, 108312. (<a href='https://doi.org/10.1016/j.comcom.2025.108312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of mobile network traffic and the emergence of complex applications, such as self-driving cars and augmented reality, demand ultra-low latency, high throughput, and massive device connectivity, which traditional network design approaches struggle to meet. These issues were initially addressed in Fifth-Generation (5G) and Beyond-5G (B5G) networks, where Artificial Intelligence (AI), particularly Deep Learning (DL), is proposed to optimize the network and to meet these demanding requirements. However, the resource constraints and time limitations inherent in telecommunication networks raise questions about the practicality of deploying large Deep Neural Networks (DNNs) in these contexts. This paper analyzes the costs of implementing DNNs by comparing them with shallow ML models across multiple datasets and evaluating factors such as execution time and model interpretability. Our findings demonstrate that shallow ML models offer comparable performance to DNNs, with significantly reduced training and inference times, achieving up to 90% acceleration. Moreover, shallow models are more interpretable, as explainability metrics struggle to agree on feature importance values even for high-performing DNNs.},
  archive      = {J_COMCOM},
  author       = {Rafael Teixeira and Leonardo Almeida and Pedro Rodrigues and Mário Antunes and Diogo Gomes and Rui L. Aguiar},
  doi          = {10.1016/j.comcom.2025.108312},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108312},
  shortjournal = {Comput. Commun.},
  title        = {Beyond performance comparing the costs of applying deep and shallow learning},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cor">COR - 31</h2>
<ul>
<li><details>
<summary>
(2026). Optimal placement of electric vehicle slow-charging stations: A continuous facility location problem under uncertainty. <em>COR</em>, <em>185</em>, 107289. (<a href='https://doi.org/10.1016/j.cor.2025.107289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicles (EVs) are becoming a key mechanism to reduce emissions in the transportation industry, and hence contribute to the green transition. In this paper, we present a mathematical programming model which determines the optimal placement of EV charging stations such that chargers are placed in the most cost-efficient way possible for all stakeholders, assuming additionally that EV charging demand is inherently stochastic in nature. The model is formulated as a two-stage, continuous location–allocation model in the form of a generalised Weber problem in two dimensions. However, this formulation is non-convex and notoriously difficult to solve. We therefore propose a suitable discretisation procedure to find high quality solutions in suitable time. The discretisation procedure shows strong performance across a variety of computational experiments using randomly generated scenarios, maintaining robustness in terms of the objective value and overall solution quality. A part of this solution procedure was entered into the 15th AIMMS-MOPTA Optimisation Modelling Competition.},
  archive      = {J_COR},
  author       = {H.W. Ljósheim and S. Jenkins and K.D. Searle and J.K. Wolff},
  doi          = {10.1016/j.cor.2025.107289},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107289},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal placement of electric vehicle slow-charging stations: A continuous facility location problem under uncertainty},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modeling and algorithm for job shop scheduling with batch operations in semiconductor fabs. <em>COR</em>, <em>185</em>, 107287. (<a href='https://doi.org/10.1016/j.cor.2025.107287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semiconductor manufacturing presents a highly complex Job Shop Scheduling Problem (JSP) due to the diversity and large number of processing machines, as well as the intricate manufacturing processes including batch and non-batch operations. Existing studies often either overlook batching problems or address them in oversimplified ways, failing to provide effective solutions for large-scale scheduling challenges with batch operations. For this problem, a model for the JSP involving both batching and non-batching processes in semiconductor fabs is first developed. Then, the First Come First Served (FCFS) approach, as an effective rule-based method, is employed to generate high-quality initial solutions. A tailored Constrained Genetic Algorithm (CGA) by embedding constraints to the stages of genetic algorithms is proposed to further optimize the solution. The CGA incorporates batch grouping, constrained encoding, constrained crossover and constrained mutation to effectively handle the sequential constraints of batch and non-batch processes, ensuring the generation of valid solutions. The CGA is validated using the SMT2020 and SMAT2022 datasets across various scales and scenarios. Experimental results demonstrate that the CGA outperforms FCFS, backward simulation and reinforcement learning. These results highlight the CGA’s effectiveness and robustness in solving complex scheduling problems in semiconductor manufacturing.},
  archive      = {J_COR},
  author       = {Wen Ma and Gedong Jiang and Nuogang Sun and Chaoqing Min and Xuesong Mei},
  doi          = {10.1016/j.cor.2025.107287},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107287},
  shortjournal = {Comput. Oper. Res.},
  title        = {Modeling and algorithm for job shop scheduling with batch operations in semiconductor fabs},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Maximum capture location problem with random utilities and overflow penalties. <em>COR</em>, <em>185</em>, 107285. (<a href='https://doi.org/10.1016/j.cor.2025.107285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends the maximum capture location problem with random utilities by incorporating the facility capacity and introducing penalties for overflows into the objective function. We propose a method that combines the key features of two state-of-the-art approaches for the uncapacitated case, which are adapted to solve the problem at hand. The first approach is a linear reformulation that extends the best-known linearization in the literature, which is based on variable substitution. The second approach is a reformulation that incorporates outer-approximation cuts and enhanced submodular cuts, solving the problem via a branch-and-cut approach. We tested the performance of the three approaches on several instances and show that the combined method outperforms each of the preceding techniques. The optimal location patterns of the model are also analysed, and it is found that considering the overflow and overflow penalties in the objective function affects the location decisions. The resulting optimal locations align more closely with practical scenarios.},
  archive      = {J_COR},
  author       = {Gonzalo Méndez-Vogel and Sebastián Dávila-Gálvez and Pedro Jara-Moroni and Jorge Zamorano and Vladimir Marianov},
  doi          = {10.1016/j.cor.2025.107285},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107285},
  shortjournal = {Comput. Oper. Res.},
  title        = {Maximum capture location problem with random utilities and overflow penalties},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel mathematical model for the scheduling of a zero inventory production: An application of process scheduling in fog computing. <em>COR</em>, <em>185</em>, 107284. (<a href='https://doi.org/10.1016/j.cor.2025.107284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main production-related costs in manufacturing is inventory cost since manufacturing firms allocate a vast area to raw material, semi-processed, and final products in production lines and warehouses. Reducing the volume of these inventories leads to lower production-related costs. This paper presents a novel mathematical model for zero-inventory production scheduling. In this model, the jobs arrive at fixed times and are scheduled on a set of unrelated machines. The jobs have different operations that need to be processed one by one. Since the system has zero inventory, the jobs must be processed immediately upon arrival. Also, whenever a job’s operation is complete, the following operation must instantly start (no wait time). That operation is outsourced if no machines are available to process any of the job’s operations. The jobs’ operations are dispatched to the machines from a dispatching center, and there is a latency between the dispatching center, the machines, and the outsourcing center. We present a mixed-integer non-linear programming (MINLP) model to formulate this problem. Then, the MINLP model is turned into a mixed-integer linear programming (MILP) model by linearizing its constraints. Since many production scheduling problems are known to be NP-hard, particularly those involving unrelated parallel machines, precedence constraints, and time-dependent decisions like ours, we adopt two metaheuristics to solve the problem for large-scale cases where exact methods are computationally inefficient. The first is a Genetic Algorithm (GA), and the second is a Teaching-Learning-Based Optimization (TLBO) algorithm. The performance of these algorithms is tested against the optimal solutions obtained from CPLEX for a set of small-scale problems. We consider a real case study, an image processing system, to validate the proposed developments (the MILP model and the GA). The results show that the presented model and algorithm can reduce the system’s total cost by about 12.57% compared to the existing online dispatching rules.},
  archive      = {J_COR},
  author       = {Mani Sharifi and Sharareh Taghipour and Abdolreza Abhari and Maciej Rysz},
  doi          = {10.1016/j.cor.2025.107284},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107284},
  shortjournal = {Comput. Oper. Res.},
  title        = {A novel mathematical model for the scheduling of a zero inventory production: An application of process scheduling in fog computing},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified approach to extract interpretable rules from tree ensembles via integer programming. <em>COR</em>, <em>185</em>, 107283. (<a href='https://doi.org/10.1016/j.cor.2025.107283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree ensembles are widely used machine learning models, known for their effectiveness in supervised classification and regression tasks. Their performance derives from aggregating predictions of multiple decision trees, which are renowned for their interpretability properties. However, tree ensemble models do not reliably exhibit interpretable output. Our work aims to extract an optimized list of rules from a trained tree ensemble, providing the user with a condensed, interpretable model that retains most of the predictive power of the full model. Our approach consists of solving a set partitioning problem formulated through Integer Programming. The extracted list of rules is unweighted and defines a partition of the training data, assigning each instance to exactly one rule, and thereby simplifying the explanation process. The proposed method works with tabular or time series data, for both classification and regression tasks, and its flexible formulation can include any arbitrary loss or regularization functions. Our computational experiments offer statistically significant evidence that our method performs comparably to several rule extraction methods in terms of predictive performance and fidelity towards the tree ensemble. Moreover, we empirically show that the proposed method effectively extracts interpretable rules from tree ensembles that are designed for time series data.},
  archive      = {J_COR},
  author       = {Lorenzo Bonasera and Emilio Carrizosa},
  doi          = {10.1016/j.cor.2025.107283},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107283},
  shortjournal = {Comput. Oper. Res.},
  title        = {A unified approach to extract interpretable rules from tree ensembles via integer programming},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing high-tech product take-back schemes in a closed-loop supply chain. <em>COR</em>, <em>185</em>, 107282. (<a href='https://doi.org/10.1016/j.cor.2025.107282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent product development is a solution to the shortened product lifecycles in the consumer electronics industry. It enables companies to maintain competitiveness and strengthen their market share. However, environmental concerns bring reverse logistics practices into focus. A take-back policy is a strategic reverse logistics activity known to foster market share; however, it poses various challenges and uncertainties. Considering uncertain demand, we introduced an innovative adoption model with two distinct take-back policies, trade-in and credit, to address challenges in multi-generation production planning. Inspired by real-world practices of companies like Apple and Samsung, our model first examines how trade-in programs drive repeat purchases and enhance market share, with credit-based programs to attract new customers. It then captures changes in demand, production planning, recovery decisions, and internal competition among multiple product generations. Distinct from previous conclusions, this study explores how producers can strategically manage demand for new generations to slow diffusion, thereby increasing refurbishment and recycling volumes over time. Our findings highlight the pivotal role of adaptive pricing strategies and production scalability in maximizing profitability and promoting sustainability in competitive high-tech industries.},
  archive      = {J_COR},
  author       = {Fatemeh Keshavarz-Ghorbani and Mohamad Y. Jaber and Seyed Hamid Reza Pasandideh},
  doi          = {10.1016/j.cor.2025.107282},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107282},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing high-tech product take-back schemes in a closed-loop supply chain},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Minimizing the weighted number of tardy jobs: Data-driven heuristic for single-machine scheduling. <em>COR</em>, <em>185</em>, 107281. (<a href='https://doi.org/10.1016/j.cor.2025.107281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research on single-machine scheduling is largely focused on exact algorithms, which perform well on typical instances but can significantly deteriorate on certain regions of the problem space. In contrast, data-driven approaches provide strong and scalable performance when tailored to the structure of specific datasets. Leveraging this idea, we focus on a single-machine scheduling problem where each job is defined by its weight, duration, due date, and deadline, aiming to minimize the total weight of tardy jobs. We introduce a novel data-driven scheduling heuristic that combines machine learning with problem-specific characteristics, ensuring feasible solutions, which is a common challenge for ML-based algorithms. Experimental results demonstrate that our approach significantly outperforms the state-of-the-art in terms of optimality gap, number of optimal solutions, and adaptability across varied data scenarios, highlighting its flexibility for practical applications. In addition, we conduct a systematic exploration of ML models, addressing a common gap in similar studies by offering a detailed model selection process and demonstrating why the chosen model is the best fit.},
  archive      = {J_COR},
  author       = {Nikolai Antonov and Přemysl Šůcha and Mikoláš Janota and Jan Hůla},
  doi          = {10.1016/j.cor.2025.107281},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107281},
  shortjournal = {Comput. Oper. Res.},
  title        = {Minimizing the weighted number of tardy jobs: Data-driven heuristic for single-machine scheduling},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the periodic service scheduling problem with non-uniform demands. <em>COR</em>, <em>185</em>, 107280. (<a href='https://doi.org/10.1016/j.cor.2025.107280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Periodic Service Scheduling Problem with Non-uniform Demands, in which the best service policy for a set of customers with periodically recurring demand through a given finite planning horizon has to be determined. Service to customers is provided at every time period by a set of potential service providers, each of them with an activation cost and a capacity. The decisions to be made include the servers to be activated at each time period together with a service schedule and server allocation for every customer that respect the periodicity of customer demand and the capacity of the activated servers, which minimize the total cost of the activated servers. We give a first Integer Linear Programming formulation with one set of decision variables associated with each of the decisions of the problem. Afterwards, we develop a logic-based Benders reformulation where one set of variables is projected out and constraints that guarantee the feasibility of the solutions are introduced. The separation problem for the new set of constraints is studied, and an exact Branch & Logic-Benders-Cut algorithm for the reformulation is proposed together with several variations and enhancements. The particular cases in which all servers are identical and in which all parameters are time-invariant are also studied. Extensive computational experiments assess the superiority of the logic-based Benders reformulation over the first formulation.},
  archive      = {J_COR},
  author       = {Elena Fernández and Jörg Kalcsics},
  doi          = {10.1016/j.cor.2025.107280},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107280},
  shortjournal = {Comput. Oper. Res.},
  title        = {On the periodic service scheduling problem with non-uniform demands},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Q-learning-based hyper-heuristic algorithm for open dimension irregular packing problems. <em>COR</em>, <em>185</em>, 107279. (<a href='https://doi.org/10.1016/j.cor.2025.107279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic methods provide a computationally efficient framework for addressing two-dimensional irregular packing problems, particularly in resource-constrained industrial settings. As a typical combinatorial optimization problem, irregular packing exhibits exponential growth in computational complexity with increasing workpiece counts, while the solution space dynamically reconfigures due to geometric variability among workpieces. Although heuristic algorithms can generate feasible layouts within acceptable timeframes, their reliance on fixed search rule limits adaptability to diverse scenarios, necessitating more flexible approaches. In this paper, a hyper-heuristic algorithm based on Q-Learning is proposed to solve open dimension packing problems, including one-open and two-open dimension problems. Q-Learning is adopted as the high-level strategy for its ability to optimize low-level heuristic selection through reward-driven experience accumulation. The method incorporates a mixed encoding method for solution representation, four specialized low-level heuristic operators, a linear population decline mechanism, and an elite preservation strategy to balance exploration–exploitation. The Q-Learning controller dynamically selects operators by updating the Q-table based on Bellman’s equation. The proposed algorithm is compared to some advanced algorithms in general datasets. The results show that our method has better performance and applicability.},
  archive      = {J_COR},
  author       = {Yongchun Wang and Qingjin Peng and Zhen Wang and Shuiquan Huang and Zhengkai Xu and Chuanzhen Huang and Baosu Guo},
  doi          = {10.1016/j.cor.2025.107279},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107279},
  shortjournal = {Comput. Oper. Res.},
  title        = {Q-learning-based hyper-heuristic algorithm for open dimension irregular packing problems},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid modelling using simulation and machine learning in healthcare. <em>COR</em>, <em>185</em>, 107278. (<a href='https://doi.org/10.1016/j.cor.2025.107278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling & Simulation (M&S) and Machine Learning (ML) methodologies have undergone significant advancements, enabling transformative applications across various industries. The integration of M&S and ML into a Hybrid M&S-ML approach leverages the unique strengths of both fields, offering enhanced model precision, improved efficiency, and more effective decision support. This review explores the increasing convergence of ML algorithms with traditional M&S methods- namely Agent-Based Modelling & Simulation, Discrete Event Simulation, and System Dynamics- in healthcare applications. Through a systematic review of 90 relevant studies, this article provides a comprehensive synthesis of the current state-of-the-art Hybrid M&S-ML in healthcare. Specifically, it examines the M&S and ML methodologies employed, associated software tools and programming languages, analyses integration patterns and data exchange mechanisms, and explores application domains, as well as the types and motivations for hybridisation. Key findings highlight prominent methodological and technical trends, as well as opportunities for combining M&S with ML to address healthcare challenges. These insights provide direction for modellers and data scientists in developing hybrid M&S–ML approaches that more effectively combine simulation capabilities with data-driven learning. The review also demonstrates the potential of such approaches to advance methodological innovation and support evidence-based decision-making in diverse healthcare contexts.},
  archive      = {J_COR},
  author       = {Ali Ahmadi and Masoud Fakhimi and Carin Magnusson},
  doi          = {10.1016/j.cor.2025.107278},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107278},
  shortjournal = {Comput. Oper. Res.},
  title        = {Hybrid modelling using simulation and machine learning in healthcare},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A note on battery swapping policies in the electric vehicle routing problem with time windows and battery swapping vehicles. <em>COR</em>, <em>185</em>, 107277. (<a href='https://doi.org/10.1016/j.cor.2025.107277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Çatay and Sadati [An improved matheuristic for solving the electric vehicle routing problem with time windows and synchronized mobile charging/battery swapping. Computers & Operations Research 159, 106310, 2023] explores a variant of the Electric Vehicle Routing Problem with Time Windows that incorporates mobile chargers for recharging electric vehicles (EVs) at selected locations while serving customers. The authors propose a matheuristic method to address this problem and its special case, where EV batteries are swapped in constant time instead of being recharged over variable durations. While comparing their results with those in the literature, the authors overlook a critical assumption regarding the swapping policy, potentially causing confusion in interpreting the findings. This note addresses the issue, clarifies the overlooked assumption, and updates the results that do not align with the actual scenario in the literature. Furthermore, it introduces two new battery swapping policies and presents an extensive computational study to offer new insights on synchronized mobile battery swapping.},
  archive      = {J_COR},
  author       = {Bülent Çatay and İhsan Sadati},
  doi          = {10.1016/j.cor.2025.107277},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107277},
  shortjournal = {Comput. Oper. Res.},
  title        = {A note on battery swapping policies in the electric vehicle routing problem with time windows and battery swapping vehicles},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive K-means and reinforcement learning (RL) algorithm to effective vaccine distribution. <em>COR</em>, <em>185</em>, 107275. (<a href='https://doi.org/10.1016/j.cor.2025.107275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new adaptive reinforcement learning (RL) approach, integrated with a K-means clustering algorithm and guided by simulated annealing, to address the capacitated vehicle routing for vaccine distribution (CVRVD) problem. This integrated method provides an efficient and scalable solution for optimizing vaccine distribution logistics. By incorporating cost factors related to travel distance, inventory levels, and penalty terms – while adhering to delivery time windows – our approach improves both operational efficiency and vaccine allocation effectiveness. Experimental results demonstrate that our K-means supported RL algorithm significantly outperforms traditional solvers in tackling this NP-hard problem, particularly in large-scale scenarios. Specifically, our approach can efficiently solve CVRVD instances with up to 1,000 facilities—scenarios that are computationally intractable for exact methods. We demonstrate the effectiveness of the adaptive K-means supported RL algorithm using data from New Jersey, USA, where facility-level vaccination data were available through the state’s Immunization Information System. Beyond vaccine distribution, our method has broad applicability in logistics and transportation, enabling more efficient and cost-effective allocation of critical resources such as vaccines and medical supplies.},
  archive      = {J_COR},
  author       = {Elson Cibaku and İ. Esra Büyüktahtakın},
  doi          = {10.1016/j.cor.2025.107275},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107275},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive K-means and reinforcement learning (RL) algorithm to effective vaccine distribution},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A Q-learning-based multi-objective hyper-heuristic algorithm for energy-efficient integrated distributed hybrid flow-shop scheduling with preventive maintenance. <em>COR</em>, <em>185</em>, 107267. (<a href='https://doi.org/10.1016/j.cor.2025.107267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the dual engines of supply chain integration and low-carbon transformation in industrial Internet of Things (IIoT) manufacturing systems, energy-efficient integrated distributed scheduling has emerged as a pivotal component of industrial intelligence-driven smart manufacturing. This article investigates the energy-efficient integrated distributed hybrid flow shop scheduling problem with preventive maintenance (EE-IDHFSP-PM), which aims to minimize the dual objectives of makespan and total carbon emissions. In this study, a mixed-integer linear programming (MILP) model is established for the EE-IDHFSP-PM, making the first attempt to solve such NP-hard problem by using a Q -learning-based multi-objective hyper-heuristic algorithm (QLMHHA). First, a modified NEH-based initialization method is introduced to produce high-quality solutions that balance multiple optimization objectives, ensuring both the quality and diversity of initial populations. Second, a novel multi-stage collaborative energy-efficient strategy (MSC_EES) is developed to dynamically adjust the processing speeds of machines on non-critical paths, which reduces energy consumption across stages. Third, a new Q -learning-based high-level strategy (HLS) is devised to dynamically coordinate twelve low-level heuristics (LLHs) according to specific states, improving adaptive search efficiency through superior exploration–exploitation trade-offs. Fourth, a dual-criterion reward mechanism is proposed to evaluate population quality in terms of both convergence and diversity, which can deliver immediate feedback and effectively guide evolutionary processes. Fifth, comprehensive convergence and computational complexity analyses of critical components are conducted to confirm the stability, reliability, and efficiency of QLMHHA. Extensive experiments are carried out on 54 small-scale and 24 large-scale instances, which demonstrate that QLMHHA achieves promising performance in both effectiveness and efficacy against state-of-the-art multi-objective algorithms for addressing the EE-IDHFSP-PM. These findings validate the efficacy and superiority of QLMHHA in tackling complex scheduling challenges, providing valuable theoretical implications and practical insights for energy-efficient distributed manufacturing systems.},
  archive      = {J_COR},
  author       = {Zi-Qi Zhang and Xin-Yun Wu and Bin Qian and Rong Hu and Jian-Bo Yang},
  doi          = {10.1016/j.cor.2025.107267},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107267},
  shortjournal = {Comput. Oper. Res.},
  title        = {A Q-learning-based multi-objective hyper-heuristic algorithm for energy-efficient integrated distributed hybrid flow-shop scheduling with preventive maintenance},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A Q-learning-based evolutionary algorithm for solving the low-carbon multi-objective flexible job shop scheduling problem. <em>COR</em>, <em>185</em>, 107266. (<a href='https://doi.org/10.1016/j.cor.2025.107266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, how to reduce energy consumption at the manufacturing system level in the low-carbon multi-objective flexible job shop scheduling problem (LCM-FJSP) has received significant attention. In this research, a model with the maximum completion time, total machine workload and total carbon emissions is built. Moreover, a Q-learning-based adaptive weight-adjusted decomposition evolutionary algorithm (QMOEA/D-AWA) is proposed. In the QMOEA/D-AWA, an initialization strategy with four heuristic initial rules for obtaining high-quality population, a variable neighborhood search strategy with four problem-specific local search methods for enhancing exploration and a Q-learning-based parameter adaptive strategy for automatically determining the number of neighborhood solutions are designed. To validate the effectiveness of the proposed QMOEA/D-AWA, it is compared with five state-of-the-art algorithms on 15 instances. In the statistical analysis, the QMOEA/D-AWA obtains the overwhelming metric results in 10 instances. In the visual analysis, the completion time is reduced by 3.74%, the total workload is reduced by 3.94%, and the carbon emissions are reduced by 5.94%.},
  archive      = {J_COR},
  author       = {Zhixue Wang and Maowei He and Hanning Chen and Yabao Hu and Yelin Xia},
  doi          = {10.1016/j.cor.2025.107266},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107266},
  shortjournal = {Comput. Oper. Res.},
  title        = {A Q-learning-based evolutionary algorithm for solving the low-carbon multi-objective flexible job shop scheduling problem},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A benders-branch-and-cut methodology for global cargo vessel traffic prediction given declining arctic sea ice and changing risks. <em>COR</em>, <em>185</em>, 107265. (<a href='https://doi.org/10.1016/j.cor.2025.107265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global warming has led to declining sea-ice in the Arctic Ocean, making it easier for ice-class vessels to navigate Arctic waters for greater portions of the year. As sailing conditions in these waters improve over coming decades, these passageways are expected to open for larger portions of the year and to become increasingly viable options for unsupported transit and even open-water vessels. This paper proposes a Benders-branch-and-cut methodology for estimating changes in global maritime cargo flow patterns under future climate scenarios with declining Arctic sea ice. The model accounts for changing incident risk along Arctic passageways and corresponding ice-class vessel and icebreaker escort requirements, lower speeds, increased insurance premiums, higher accident probabilities, and constraints on path-based maximum risk exposure. The resulting mixed-integer program involves path-based, continuous decision variables. The solution technique is applied on a model of the global maritime container network including 80 ports, 76 routes, 426 links and 4,303 legs associated with the world’s largest carrier alliance. Embedded acceleration techniques and a label-correcting algorithm that employs specialized fathoming rules for a non-additive, constrained path subproblem enable solution at this global scale. The outcome is an estimate of seasonal future global maritime trade flows along key global routes and through ports predicted under six climate-related scenarios. Results illustrate that the developed model can provide support to companies, nations and regions as they prepare for a changing global landscape and climate.},
  archive      = {J_COR},
  author       = {Wenjie Li and Elise Miller-Hooks},
  doi          = {10.1016/j.cor.2025.107265},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107265},
  shortjournal = {Comput. Oper. Res.},
  title        = {A benders-branch-and-cut methodology for global cargo vessel traffic prediction given declining arctic sea ice and changing risks},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning approach for dynamic job-shop scheduling problem considering time variable and new job arrivals. <em>COR</em>, <em>185</em>, 107263. (<a href='https://doi.org/10.1016/j.cor.2025.107263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the complexity of the production process due to increased demand for customization has greatly increased the difficulty of dynamic job-shop scheduling problem (DJSP). This paper proposes a deep reinforcement learning (DRL) approach to tackle the DJSP based on proximal policy optimization (PPO) algorithm. A novel state representation method that expresses state features as multi-channel images is proposed to simplify the state characterization process. Various heuristic-based priority dispatching rules (PDRs)are used to construct action space. By converting scheduling instances into images and leveraging the spatial pyramid pooling fast (SPPF) module for feature extraction, this model can handle scheduling instances of varying scales and map size-independent processing information matrix to fixed action space. Additionally, a dense reward based on a predefined scheduling region is developed to offer detailed guidance to the agent, enabling more precise and comprehensive policy assessment. Static tests are conducted on well-known benchmarks, and the experimental results indicate that our scheduling model surpasses the performance of the three latest DRL approaches on average. Compared with PDR methods, dynamic experiments demonstrate that the proposed DRL model excels in adaptability and robustness when new tasks arrive and the processing time fluctuates with uncertainty.},
  archive      = {J_COR},
  author       = {Haoyang Yu and Wenbin Gu and Na Tang and Zhenyang Guo},
  doi          = {10.1016/j.cor.2025.107263},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107263},
  shortjournal = {Comput. Oper. Res.},
  title        = {A deep reinforcement learning approach for dynamic job-shop scheduling problem considering time variable and new job arrivals},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient resource utilization and scheduling strategy for in-service aircraft maintenance and operations. <em>COR</em>, <em>185</em>, 107262. (<a href='https://doi.org/10.1016/j.cor.2025.107262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal scheduling of maintenance activities requires the solution of combinatorial optimization problems that need to be efficiently modeled and solved with optimization techniques. Maintenance scheduling and operations-associated problems in the aviation industry can efficiently enhance competitiveness. In the maintenance and scheduling problem, aircrafts need to undergo tasks for both line (A check) and base (C check) maintenance at various hangers at MRO (Maintenance, Repair and Operations) based on resource availability (both human and material). The determination of the optimal maintenance plan, in terms of allocating the resources to the aircraft, and resource movement from one aircraft to another based on availability and licensed skills in the presence of multiple tasks and capacity constraints so as to obtain maximum utilization of resources at maintenance site and minimize the turnaround time is a complex combinatorial optimization problem. To the best of our knowledge, this work is the first CP (Constraint Programming) based mathematical solution that jointly integrates zone, task precedence, technician-pool sharing, and multi-shift continuity for large-scale aircraft maintenance scheduling. In this article, we proposed an efficient optimization strategy that overcomes many of the drawbacks of the formulation/strategies available in literature and helps in determining efficient execution of maintenance work packages. The proposed strategy is generic, encompassing multi-aircraft, multi-skill and multi-shift scheduling capabilities and is validated on two real scenario business case studies, one each for line maintenance (A check) tasks and base maintenance (C check) tasks, as well as six large-scale synthetic scenarios with up to 20,000 tasks, demonstrating feasibility and scalable performance. The proposed strategy is demonstrated on MRO scheduling and it shows an improvement of up to 30.68% in the turn-around time by incorporating the proposed optimization strategy.},
  archive      = {J_COR},
  author       = {Sandeep Singh Chauhan and Likhith Maadhav and Abhijit Dake and Gauthier Brillaud},
  doi          = {10.1016/j.cor.2025.107262},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107262},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient resource utilization and scheduling strategy for in-service aircraft maintenance and operations},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven optimization approach for the integrated train scheduling and maintenance planning in high-speed railways. <em>COR</em>, <em>185</em>, 107261. (<a href='https://doi.org/10.1016/j.cor.2025.107261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In railway systems, preventive maintenance plans are essential for ensuring the safety of train operations. However, these tasks are often subject to various disturbances (e.g., bad weather), leading to unpredictable deviations between planned and actual maintenance durations, which can further disrupt train schedules. Unlike most studies that assume constant maintenance durations, this paper introduces a data-driven, two-stage distributionally robust optimization (DRO) model for jointly optimizing train scheduling and maintenance planning. In the first stage, we determine the initial train schedule and maintenance plan. In the second stage, we allow for slight adjustments to train departure and arrival times at each station to accommodate disturbances affecting maintenance tasks. Our objective is to minimize both the expected travel time of trains and the deviation from the planned schedule under worst-case scenarios for maintenance disturbances. To capture the uncertainty of maintenance disturbances, we construct an ambiguity set using historical data and the Wasserstein metric. We show that the proposed two-stage DRO model, formulated over the Wasserstein ambiguity set, can be reformulated into an efficiently solvable equivalent form. Finally, we apply our model to a real-world case study of the Beijing–Guangzhou high-speed railway and compare it with traditional stochastic programming methods, including sample average approximation and robust optimization. The results highlight the efficiency of our approach and provide valuable insights for railway management.},
  archive      = {J_COR},
  author       = {Hangyu Ji and Chuntian Zhang and Jiateng Yin and Lixing Yang},
  doi          = {10.1016/j.cor.2025.107261},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107261},
  shortjournal = {Comput. Oper. Res.},
  title        = {A data-driven optimization approach for the integrated train scheduling and maintenance planning in high-speed railways},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ROBIST: Robust optimization by iterative scenario sampling and statistical testing. <em>COR</em>, <em>185</em>, 107260. (<a href='https://doi.org/10.1016/j.cor.2025.107260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose ROBIST , a simple, yet effective, data-driven algorithm for optimization under parametric uncertainty. The algorithm first generates solutions in an iterative manner by sampling and optimizing over a relatively small set of scenarios. Then, using statistical testing, the robustness of the solutions is evaluated, which can be done with a much larger set of scenarios. ROBIST offers a number of practical advantages over existing methods as it is: (i) easy to implement, (ii) able to deal with a wide range of problems and (iii) capable of providing sharp probability guarantees that are easily computable and independent of the dimensions of the problem. Numerical experiments demonstrate the effectiveness of ROBIST in comparison to alternative methods.},
  archive      = {J_COR},
  author       = {Justin Starreveld and Guanyu Jin and Dick den Hertog and Roger J.A. Laeven},
  doi          = {10.1016/j.cor.2025.107260},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107260},
  shortjournal = {Comput. Oper. Res.},
  title        = {ROBIST: Robust optimization by iterative scenario sampling and statistical testing},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A branch-and-price algorithm for energy aware task scheduling of constellations of nanosatellites. <em>COR</em>, <em>185</em>, 107259. (<a href='https://doi.org/10.1016/j.cor.2025.107259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-price algorithm for solving the Optimal Network Task Scheduling (ONTS) problem in satellite constellations. The algorithm efficiently manages both constellation tasks that can be performed by any satellite and satellite-specific tasks that must be executed by designated satellites, while considering critical energy constraints. We formulate the problem as a Mixed-Integer Linear Programming (MILP) model and develop a Dantzig–Wolfe decomposition that handles battery management constraints for the satellites at the master level, while addressing constellation-wide coordination requirements in the subproblems. A novel dynamic programming algorithm is proposed to solve the pricing subproblem for constellation tasks, augmented with dual stabilization techniques to improve convergence. Comprehensive computational experiments on realistic instances derived from nanosatellite operations demonstrate the effectiveness of the algorithm. Results show that our structured formulation significantly outperforms a naive approach, particularly for large instances, while effectively balancing workload distribution and energy management across the constellation. This work provides a practical framework for optimizing task scheduling in modern satellite constellations, with direct applications in Earth observation, telecommunications, and scientific missions.},
  archive      = {J_COR},
  author       = {Pedro Marcolin Antunes and Laio Oriel Seman and Eduardo Camponogara},
  doi          = {10.1016/j.cor.2025.107259},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107259},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-price algorithm for energy aware task scheduling of constellations of nanosatellites},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A branch-and-cut algorithm for the pallet-loading vehicle routing problem considering load balance of semi-trailer trucks. <em>COR</em>, <em>185</em>, 107258. (<a href='https://doi.org/10.1016/j.cor.2025.107258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work presented in this paper is motivated by some practical applications, introducing and solving a new problem called the split delivery vehicle routing problem with time windows and two-dimensional loading constraints considering load balance (2L-SDVRPTW-LB). This problem expands the integrated routing and loading problem, in which the required pallet orders are delivered to customers by a fleet of homogeneous semi-trailer trucks. Firstly, with the goal to minimize the total transportation cost, a mixed-integer linear programming model for the 2L-SDVRPTW-LB is proposed. Secondly, an exact algorithm framework based on the branch-and-cut algorithm is designed to solve the problem. In the algorithm framework, a metaheuristic algorithm is designed to obtain the upper bound. Subsequently, various classes of valid inequalities are introduced to strengthen the formulation, while the constraints ensuring load balance are applied in a lazy manner to optimize computational efficiency. Numerical experiments based on modified benchmark instances demonstrate that the proposed branch-and-cut algorithm effectively solves the 2L-SDVRPTW-LB and its variant of excluding split delivery. This study provides valuable insights for addressing the pallet-loading vehicle routing problem considering load balance of semi-trailer trucks.},
  archive      = {J_COR},
  author       = {Xiangbin Xu and Haoxing Ouyang},
  doi          = {10.1016/j.cor.2025.107258},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107258},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-cut algorithm for the pallet-loading vehicle routing problem considering load balance of semi-trailer trucks},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid memetic metaheuristic for medical staff assignment in major public health emergencies. <em>COR</em>, <em>185</em>, 107256. (<a href='https://doi.org/10.1016/j.cor.2025.107256'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During major public health emergencies, effective assignment of medical staff is crucial for saving lives and controlling the spread of epidemics. This work focuses on the assignment of doctors and nurses to hospitals to form treatment groups that carry out patient treatment tasks. We consider the practical constraints of skill types of medical staff and the severity of patients’ conditions and propose a mixed integer programming model with the objective of maximizing demand satisfaction and personnel skill matching. To solve this problem, we introduce a hybrid memetic search algorithm that combines a specialized crossover operator for generating promising offspring solutions and a variable neighborhood search procedure to improve their quality. Computational results demonstrate that our algorithm outperforms the general mixed integer programming solver GUROBI . The key components of the proposed algorithm are experimentally analyzed and managerial insights are derived.},
  archive      = {J_COR},
  author       = {Yang Wang and He Zheng and Zequn Wei and Christophe Wilbaut and Saïd Hanafi},
  doi          = {10.1016/j.cor.2025.107256},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107256},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid memetic metaheuristic for medical staff assignment in major public health emergencies},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-guided iterated local search for the minmax multiple traveling salesman problem. <em>COR</em>, <em>185</em>, 107255. (<a href='https://doi.org/10.1016/j.cor.2025.107255'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minmax multiple traveling salesman problem involves minimizing the costs of a longest tour among a set of tours. The problem is of great practical interest because it can be used to formulate several real-life applications. To solve this computationally challenging problem, we propose a learning-driven iterated local search approach that combines an effective local search procedure to find high-quality local optimal solutions and a multi-armed bandit algorithm to select removal and insertion operators to escape local optimal traps. Extensive experiments on 77 commonly used benchmark instances show that the algorithm achieves excellent results in terms of solution quality and running time. In particular, it achieves 32 new best results (improved upper bounds) and matches the best-known results for 35 other instances. Additional experiments shed light on the understanding of the algorithm’s constituent elements. Multi-armed bandit selection can be used advantageously in other multi-operator local search algorithms.},
  archive      = {J_COR},
  author       = {Pengfei He and Jin-Kao Hao and Jinhui Xia},
  doi          = {10.1016/j.cor.2025.107255},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107255},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning-guided iterated local search for the minmax multiple traveling salesman problem},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Grouping strategies on two-phase methods for bi-objective combinatorial optimization. <em>COR</em>, <em>185</em>, 107254. (<a href='https://doi.org/10.1016/j.cor.2025.107254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-phase methods are commonly used to solve bi-objective combinatorial optimization problems. In the first phase, all extreme supported nondominated points are generated through a dichotomic search. This phase also allows the identification of search zones that may contain other nondominated points. The second phase focuses on exploring these search zones to locate the remaining points, which typically accounts for most of the computational cost. Ranking algorithms are frequently employed to explore each zone individually, but this approach leads to redundancies, causing multiple visits to the same solutions. To mitigate these redundancies, we propose several strategies that group adjacent zones, allowing a single run of the ranking algorithm for the entire group. Additionally, we explore an implicit grouping approach based on a new concept of coverage. Our experiments on the Bi-Objective Spanning Tree Problem demonstrate the beneficial impact of these grouping strategies when combined with coverage.},
  archive      = {J_COR},
  author       = {Felipe O. Mota and Luís Paquete and Daniel Vanderpooten},
  doi          = {10.1016/j.cor.2025.107254},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107254},
  shortjournal = {Comput. Oper. Res.},
  title        = {Grouping strategies on two-phase methods for bi-objective combinatorial optimization},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Drone-aided mobile blood collection problem: A rolling-horizon-based matheuristic. <em>COR</em>, <em>185</em>, 107253. (<a href='https://doi.org/10.1016/j.cor.2025.107253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the drone-aided mobile blood collection problem, which integrates mobile blood donation vehicles with drones to improve operations related to the blood collection in urban areas. Each vehicle, carrying multiple drones, travels to several collection sites to conduct blood collection operations within a working day. Drones fly between vehicles to pick up collected blood bags and deliver them to the blood center. This collaborative framework enhances the performances of the collection system and ensures the freshness of collected blood upon arrival to the blood center. We develop a novel mixed-integer linear programming model to optimally synchronize the routes and collection schedules of mobile units and drones to ensure the timely delivery of collected blood to the blood center. We also develop a rolling-horizon-based matheuristic to solve large-scale instances of the problem. This algorithm combines a rolling horizon approach, which divides the problem into manageable subproblems solved sequentially, with a local branching technique that enhances solutions by exploring promising neighborhoods. To evaluate the algorithm’s performance, we conduct a comprehensive computational study. Our results show that the proposed algorithm not only finds better solutions than those obtained by Gurobi but also outperforms other matheuristics, including the rolling horizon, relax-and-fix, and fix-and-optimize algorithms. Finally, we demonstrate the real-life applicability of the problem through a case study in Quebec City, Canada.},
  archive      = {J_COR},
  author       = {Amirhossein Abbaszadeh and Hossein Hashemi Doulabi},
  doi          = {10.1016/j.cor.2025.107253},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107253},
  shortjournal = {Comput. Oper. Res.},
  title        = {Drone-aided mobile blood collection problem: A rolling-horizon-based matheuristic},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fair and efficient multi-agent routing for cooperative and autonomous agricultural fleets with implements. <em>COR</em>, <em>185</em>, 107252. (<a href='https://doi.org/10.1016/j.cor.2025.107252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing use of autonomous tractor fleets with detachable implements presents complex logistical challenges in agriculture. Current systems often rely on simple heuristics and avoid implement swapping, limiting efficiency. A central challenge is to dynamically coordinate vehicle routing and implement exchanges to enable efficient, low-intervention task execution. Due to high costs, such fleets are owned mainly by large enterprises or cooperatives, where fair task allocation and profit sharing are critical. Addressing both coordination and fairness, in this paper, we introduce the Agricultural Fleet Vehicle Routing Problem with Implements (AFVRPI). We propose a distributed model derived from a centralized formulation also presented in this paper. This model is embedded within a Distributed Multi-Agent System Architecture (DIMASA), where autonomous vehicle agents manage routing and implement use under limited fuel autonomy, while implement agents ensure compatibility and sufficient capacity to meet task demands. Our solution applies systematic egalitarian social welfare optimization to iteratively maximize the profit of the worst-off vehicle, balancing fairness with system efficiency. To enhance scalability, we use column generation in the distributed model, achieving solution quality comparable to the centralized model while significantly reducing computing time. Simulation results on new benchmark instances demonstrate that our distributed multi-agent AFVRPI approach is scalable, efficient, and fair.},
  archive      = {J_COR},
  author       = {Aitor López-Sánchez and Marin Lujak and Frédéric Semet and Holger Billhardt},
  doi          = {10.1016/j.cor.2025.107252},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107252},
  shortjournal = {Comput. Oper. Res.},
  title        = {Fair and efficient multi-agent routing for cooperative and autonomous agricultural fleets with implements},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flexible scheduling of customized bus for green mega-events: A distributionally robust optimization approach. <em>COR</em>, <em>185</em>, 107249. (<a href='https://doi.org/10.1016/j.cor.2025.107249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mega-events such as the Olympics and the World Championships face significant challenges in evacuating large numbers of attendees after the events conclude, which consume substantial transportation resources. Under the global pressure to reduce carbon emissions, energy conservation and emission reduction are increasingly becoming top priorities. This paper focuses on the efficient scheduling of customized buses (CB) after green mega-events, incorporating skip-stop operations and coordinated bus services to minimize energy consumption, fixed and transportation costs, and facilitate the evacuation of attendees, while accounting for practical constraints such as the availability of customized buses, vehicle capacity, time windows, and flow balance. A distributionally robust optimization (DRO) model is developed, using a novel ambiguity set to model uncertain demand via parametric interval-valued fuzzy variables. To ensure computational tractability, the model is reformulated as an integer linear programming model. To address the computational challenges of large-scale instances, an improved variable neighborhood search heuristic is designed by incorporating the reinforcement learning techniques, including the KL-UCB algorithm and a sliding window mechanism. Extensive numerical experiments are conducted to verify the performance of the proposed heuristic. Computational results demonstrate that the proposed DRO model effectively handles uncertainty, offering robust and adaptable solutions. Compared to existing heuristics, the proposed heuristic improves performance by 6.51% on average, and incorporating reinforcement learning into VNS enhances computational efficiency by 4.88% on average. A real-life case study further validates the model, demonstrating that the skip-stop strategy significantly reduces vehicle travel time and enhances overall operational efficiency.},
  archive      = {J_COR},
  author       = {Xiaojie An and Xiang Li and Bowen Zhang},
  doi          = {10.1016/j.cor.2025.107249},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107249},
  shortjournal = {Comput. Oper. Res.},
  title        = {Flexible scheduling of customized bus for green mega-events: A distributionally robust optimization approach},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal planning of power distribution networks with fault-tolerant configuration. <em>COR</em>, <em>185</em>, 107248. (<a href='https://doi.org/10.1016/j.cor.2025.107248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power Distribution networks are essential infrastructures that should be designed by satisfying two conflicting requests: cost minimization and reliability. While traditional network planning aimed at radial configurations, which are more similar to the typical working configuration of a network but are not fault-tolerant, modern techniques seek for meshed configurations, since these architectures are more fault-tolerant. Due to the complexity of the problem and the large size of nowadays instances, most of the techniques used for planning are based on heuristic approaches. Thus, they are usually unable to guarantee optimality and not even able to provide an assessment of the distance from the optimal solution. In this work, we address the challenge of planning a fault tolerant network through an exact approach, by introducing innovative Mixed-Integer Linear Programming models designed for the planning of meshed distribution networks with loop-feeder or open-loop topology. Differently from other techniques, our approach simplifies the formulation by avoiding the need for fault scenarios, significantly reducing the computational burden of the optimization problem. The outcomes of our approach are the generation of optimal meshed network, which effectively balance cost and reliability of the electric distribution system. Comprehensive studies on realistic test instances show the advantages of the proposed formulations.},
  archive      = {J_COR},
  author       = {Renato Bruni and Alberto Geri and Marco Maccioni and Ludovico Nati},
  doi          = {10.1016/j.cor.2025.107248},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107248},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal planning of power distribution networks with fault-tolerant configuration},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Centrality measures and opinion dynamics in two-layer networks with replica nodes. <em>COR</em>, <em>185</em>, 107245. (<a href='https://doi.org/10.1016/j.cor.2025.107245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two fast and accurate algorithms to approximate game-theoretic centrality measures and examine connection between centrality measures, network properties, and key performance indicators (consensus time and winning rate) of opinion dynamic processes on such networks. As an example, we consider a Zachary’s karate club as a social network and extend it by adding the second (internal) layer of communication. The internal layer represents the network where individuals can share their real opinions with the close friends. The structures of the external and internal layers may be different. The significant positive correlation between internal graph density and consensus time, and significant negative correlation between centrality of authoritative nodes and consensus time are found. The proposed algorithms are verified by a series of experiments from two aspects: the accuracy and the efficiency. The algorithms are novel and can be considered as a contribution to the network theory independently of opinion dynamics as they can be used to calculate node centrality in any weighted graph.},
  archive      = {J_COR},
  author       = {Chi Zhao and Elena Parilina},
  doi          = {10.1016/j.cor.2025.107245},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107245},
  shortjournal = {Comput. Oper. Res.},
  title        = {Centrality measures and opinion dynamics in two-layer networks with replica nodes},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI automatic decision in newsvendor model with nash bargaining fairness concern. <em>COR</em>, <em>185</em>, 107227. (<a href='https://doi.org/10.1016/j.cor.2025.107227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of artificial intelligence (AI) automatic ordering and producing decisions on fairness-concerned supply chains under the newsvendor model. We develop a dyadic supply chain model in which the manufacturer acts as the Stackelberg leader while the retailer serves as the follower in a push supply chain. In contrast, their roles are switched in a pull supply chain. We assume that only human decision-making leads to decision regret behavior, whereas AI-automated decision-making does not. Without adopting AI, our results show that fairness concern does not necessarily lead to a decreasing quantity in ordering or producing, which is different from most previous studies. Different from the prior findings, our work reveals that in binding equilibrium, if fairness concerns are considered, the order quantity will decrease, while in non-binding equilibrium, the order quantity may not necessarily be less than the previous results. Interestingly, when decision regret bias is considered for fairness-concerned decision-makers, we can obtain quantity coordination solutions for supply chains under specific conditions. With adopting AI, our results show that increasing fairness concerns are beneficial for improving the follower’s profit while at the expense of sacrificing the leader’s profit margins, while the leader can only benefit from AI adoption when the decision regret bias of the follower is relatively high. It is noteworthy that under certain conditions, AI automation may negatively impact the profits of both push and pull decentralized supply chains. For instance, in low-margin profit scenarios where decision-makers exhibit moderate regret bias and fairness concerns, such effects can emerge. This indicates that under specific circumstances, the human behavioral factors — regret bias and fairness concerns — may sometimes enhance the performance of decentralized supply chain members. Our research findings provide significant practical implications for the adoption of AI-automated decision-making in real-world supply chains.},
  archive      = {J_COR},
  author       = {Rui Hou and Yishen Cen and Jianxin Chen},
  doi          = {10.1016/j.cor.2025.107227},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107227},
  shortjournal = {Comput. Oper. Res.},
  title        = {AI automatic decision in newsvendor model with nash bargaining fairness concern},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Green horizons: Sustainable global logistics in dynamic supply chain management. <em>COR</em>, <em>185</em>, 107226. (<a href='https://doi.org/10.1016/j.cor.2025.107226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain management in a global scale involves addressing numerous uncertainties, from demand fluctuations to unforeseen disruptions. Developing advanced solution approaches is critical to manage such complexities and ensure resilience. This study presents a multi-stage stochastic–dynamic model for the global supply chain, incorporating hedging policies. The aim is to identify optimal order scheduling for bill of materials, production planning, and inventory management across warehouses (i.e., materials and finished products). Due to the dynamic nature of the global supply chain (e.g., demand fluctuations, disruptions, and lead time), a multi-stage stochastic model is developed for the stochastic–dynamic supply chain network. To address dynamic factors of real-world global supply chain, an accelerated parallel stochastic dual dynamic integer programming (SDDiP) approach is proposed to deal with disruptions (e.g., political unrest, natural disasters, and pandemics), enhancing supply chain resiliency. To validate the proposed parallel SDDiP , various scenarios with different sizes are generated using the case study and compared to the SDDiP with Benders cuts and integrated stage-wise Lagrangian dual cut ( SWLDC ) (i.e., SDDiP-SWLDC ). According to the obtained results, the proposed parallel node strategy for accelerated SDDiP consistently outperforms the basic stochastic dual dynamic programming (SDDP) and demonstrated robust CPU scalability. Evaluation across various scenario sizes shows stochastic dual dynamic integer programming-mixed integer rounding cuts ( SDDiP-MIR ) achieving faster computation and a smaller 7% optimality gap compared to SDDiP-SWLDC and SDDiP in large-size instances, highlighting its superior performance in complex supply chain settings.},
  archive      = {J_COR},
  author       = {Mahsa Mohammadi and Babak Mohamadpour Tosarkani},
  doi          = {10.1016/j.cor.2025.107226},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107226},
  shortjournal = {Comput. Oper. Res.},
  title        = {Green horizons: Sustainable global logistics in dynamic supply chain management},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="csda">CSDA - 10</h2>
<ul>
<li><details>
<summary>
(2026). Fast and efficient causal inference in large-scale data via subsampling and projection calibration. <em>CSDA</em>, <em>214</em>, 108281. (<a href='https://doi.org/10.1016/j.csda.2025.108281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the average treatment effect in large-scale datasets faces significant computational and storage challenges. Subsampling has emerged as a critical strategy to mitigate these issues. This paper proposes a novel subsampling method that builds on the G-estimation method offering the double robustness property. The proposed method uses a small subset of data to estimate computationally complex nuisance parameters, while leveraging the full dataset for the computationally simple final estimation. To ensure that the resulting estimator remains first-order insensitive to variations in nuisance parameters, a projection approach is introduced to optimize the estimation of the outcome regression function and treatment regression function such that the Neyman orthogonality conditions are satisfied. It is shown that the resulting estimator is asymptotically normal and achieves the same convergence rate as the full data-based estimator when either the treatment or the outcome models is correctly specified. Additionally, when both models are correctly specified, the proposed estimator achieves the same asymptotic variance as the full data-based estimator. The finite sample performance of the proposed method is demonstrated through simulation studies and an application to birth data, comprising over 30 million observations collected over the past eight years. Numerical results indicate that the proposed estimator is nearly as computationally efficient as the uniform subsampling estimator, while achieving similar estimation efficiency to the full data-based G-estimator.},
  archive      = {J_CSDA},
  author       = {Miaomiao Su},
  doi          = {10.1016/j.csda.2025.108281},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108281},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Fast and efficient causal inference in large-scale data via subsampling and projection calibration},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generalized composite multi-sample tests for high-dimensional data. <em>CSDA</em>, <em>214</em>, 108279. (<a href='https://doi.org/10.1016/j.csda.2025.108279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional data is ubiquitous in studies involving omics, human movement, and imaging. A multivariate comparison method is proposed for such types of data when either the dimension or the replication size substantially exceeds the other. A testing procedure is introduced that centers and scales a composite measure of distance statistic among the samples to appropriately account for high dimensions and/or large sample sizes. The properties of the test statistic are examined both theoretically and empirically. The proposed procedure demonstrates superior performance in simulation studies and an application to confirm the involvement of previously identified genes in the stages of invasive breast cancer.},
  archive      = {J_CSDA},
  author       = {Xiaoli Kong and Alejandro Villasante-Tezanos and David W. Fardo and Solomon W. Harrar},
  doi          = {10.1016/j.csda.2025.108279},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108279},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Generalized composite multi-sample tests for high-dimensional data},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gamma approximation of stratified truncated exact test (GASTE-test) & application. <em>CSDA</em>, <em>214</em>, 108277. (<a href='https://doi.org/10.1016/j.csda.2025.108277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of binary outcomes and features, such as the effect of vaccination on health, often rely on 2 × 2 contingency tables. However, confounding factors such as age or gender call for stratified analysis, by creating sub-tables, which is common in bioscience, epidemiological, and social research, as well as in meta-analyses. Traditional methods for testing associations across strata, such as the Cochran-Mantel-Haenszel (CMH) test, struggle with small sample sizes and heterogeneity of effects between strata. Exact tests can address these issues, but are computationally expensive. To address these challenges, the Gamma Approximation of Stratified Truncated Exact (GASTE) test is proposed. It approximates the exact statistic of the combination of p-values with discrete support, leveraging the gamma distribution to approximate the distribution of the test statistic under stratification, providing fast and accurate p-value calculations, even when effects vary between strata. The GASTE method maintains high statistical power and low type I error rates, outperforming traditional methods by offering more sensitive and reliable detection. It is computationally efficient and broadens the applicability of exact tests in research fields with stratified binary data. The GASTE method is demonstrated through two applications: an ecological study of Alpine plant associations and a 1973 case study on admissions at the University of California, Berkeley. The GASTE method offers substantial improvements over traditional approaches. The GASTE method is available as an open-source package at https://github.com/AlexandreWen/gaste . A Python package is available on PyPI at https://pypi.org/project/gaste-test/},
  archive      = {J_CSDA},
  author       = {Alexandre Wendling and Clovis Galiez},
  doi          = {10.1016/j.csda.2025.108277},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108277},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Gamma approximation of stratified truncated exact test (GASTE-test) & application},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An algorithm for estimating threshold boundary regression models. <em>CSDA</em>, <em>214</em>, 108274. (<a href='https://doi.org/10.1016/j.csda.2025.108274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an innovative iterative two-stage algorithm designed for estimating threshold boundary regression (TBR) models. By transforming the non-differentiable least-squares (LS) problem inherent in fitting TBR models into an optimization framework, our algorithm combines the optimization of a weighted classification error function for the threshold model with obtaining LS estimators for regression models. To improve the efficiency and flexibility of TBR model estimation, we integrate the weighted support vector machine (WSVM) as a surrogate method for solving the weighted classification problem. The TBR-WSVM algorithm offers several key advantages over recently developed methods: it eliminates pre-specification requirements for threshold parameters, accommodates flexible estimation of nonlinear threshold boundaries, and streamlines the estimation process. We conducted several simulation studies to illustrate the finite-sample performance of TBR-WSVM. Finally, we demonstrate the practical applicability of the TBR model through a real data analysis.},
  archive      = {J_CSDA},
  author       = {Chih-Hao Chang and Takeshi Emura and Shih-Feng Huang},
  doi          = {10.1016/j.csda.2025.108274},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108274},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {An algorithm for estimating threshold boundary regression models},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rate accelerated inference for integrals of multivariate random functions. <em>CSDA</em>, <em>214</em>, 108273. (<a href='https://doi.org/10.1016/j.csda.2025.108273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of integrals is a fundamental task in the analysis of functional data, where the data are typically considered as random elements in a space of squared integrable functions. Effective unbiased estimation and inference procedures are proposed for integrals of uni- and multivariate random functions. Applications to key problems in functional data analysis involving random design points are examined and illustrated. In the absence of noise, the proposed estimates converge faster than the sample mean and standard numerical integration algorithms. The estimator also supports effective inference by generally providing better coverage with shorter confidence and prediction intervals in both noisy and noiseless settings.},
  archive      = {J_CSDA},
  author       = {Valentin Patilea and Sunny G․ W․ Wang},
  doi          = {10.1016/j.csda.2025.108273},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108273},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Rate accelerated inference for integrals of multivariate random functions},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust selection of the number of change-points via FDR control. <em>CSDA</em>, <em>214</em>, 108272. (<a href='https://doi.org/10.1016/j.csda.2025.108272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust quantification of uncertainty regarding the number of change-points presents a significant challenge in data analysis, particularly when employing false discovery rate (FDR) control techniques. Emphasizing the detection of genuine signals while controlling false positives is crucial, especially for identifying shifts in location parameters within flexible distributions. Traditional parametric methods often exhibit sensitivity to outliers and heavy-tailed data. Addressing this limitation, a robust method accommodating diverse data structures is proposed. The approach constructs component-wise sign-based statistics. Leveraging the global symmetry inherent in these statistics enables the derivation of data-driven thresholds suitable for multiple testing scenarios. Method development occurs within the framework of U-statistics, which naturally encompasses existing cumulative sum-based procedures. Theoretical guarantees establish FDR control for the component-wise sign-based method under mild assumptions. Demonstrations of effectiveness utilize simulations with synthetic data and analyses of real data.},
  archive      = {J_CSDA},
  author       = {Hui Chen and Chengde Qian and Qin Zhou},
  doi          = {10.1016/j.csda.2025.108272},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108272},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Robust selection of the number of change-points via FDR control},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Kernel density estimation with a markov chain monte carlo sample. <em>CSDA</em>, <em>214</em>, 108271. (<a href='https://doi.org/10.1016/j.csda.2025.108271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference relies on the posterior distribution, which is often estimated with a Markov chain Monte Carlo sampler. The sampler produces a dependent stream of variates from the limiting distribution of the Markov chain, the posterior distribution. When one wishes to display the estimated posterior density, a natural choice is the histogram. However, abundant literature has shown that the kernel density estimator is more accurate than the histogram in terms of mean integrated squared error for an i.i.d. sample. With this as motivation, a kernel density estimation method is proposed that is appropriate for the dependence in the Markov chain Monte Carlo output. To account for the dependence, the cross-validation criterion is modified to select the bandwidth in standard kernel density estimation approaches. A data-driven adjustment to the biased cross-validation method is suggested with introducing the integrated autocorrelation time of the kernel. The convergence of the modified bandwidth to the optimal bandwidth is shown by adapting theorems from the time series literature. Simulation studies show that the proposed method finds the bandwidth close to the optimal value, while standard methods lead to smaller bandwidths under Markov chain samples and hence to undersmoothed density estimates. A study with real data shows that the proposed method has a considerably smaller integrated mean squared error than standard methods. The R package KDEmcmc to implement the suggested algorithm is available on the Comprehensive R Archive Network.},
  archive      = {J_CSDA},
  author       = {Hang J. Kim and Steven N. MacEachern and Young Min Kim and Yoonsuh Jung},
  doi          = {10.1016/j.csda.2025.108271},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108271},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Kernel density estimation with a markov chain monte carlo sample},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Measure selection for functional linear model. <em>CSDA</em>, <em>214</em>, 108270. (<a href='https://doi.org/10.1016/j.csda.2025.108270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in modern science have led to an increased prevalence of functional data, which are usually viewed as elements of the space of square-integrable functions L 2 . Core methods in functional data analysis, such as functional principal component analysis, are typically grounded in the Hilbert structure of L 2 and rely on inner products based on integrals with respect to the Lebesgue measure over a fixed domain. A more flexible framework is proposed, where the measure can be arbitrary, allowing natural extensions to unbounded domains and prompting the question of optimal measure choice. Specifically, a novel functional linear model is introduced that incorporates a data-adaptive choice of the measure that defines the space, alongside an enhanced function principal component analysis. Selecting a good measure can improve the model’s predictive performance, especially when the underlying processes are not well-represented when adopting the default Lebesgue measure. Simulations, as well as applications to COVID-19 data and the National Health and Nutrition Examination Survey data, show that the proposed approach consistently outperforms the conventional functional linear model.},
  archive      = {J_CSDA},
  author       = {Su I Iao and Hans-Georg Müller},
  doi          = {10.1016/j.csda.2025.108270},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108270},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Measure selection for functional linear model},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of normal-reference tests for high-dimensional means with implementation in the r package ‘HDNRA’. <em>CSDA</em>, <em>214</em>, 108269. (<a href='https://doi.org/10.1016/j.csda.2025.108269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of testing for equal mean vectors in high-dimensional data poses significant difficulties in statistical inference. Much of the existing literature introduces methods that often rely on stringent regularity conditions for the underlying covariance matrices, enabling asymptotic normality of test statistics. However, this can lead to complications in controlling test size. To address these issues, a new set of tests has emerged, leveraging the normal-reference approach to improve reliability. The latest normal-reference methods for testing equality of mean vectors in high-dimensional samples, potentially with differing covariance structures, are reviewed. The theoretical underpinnings of these tests are revisited, providing a new unified justification for the validity of centralized L 2 -norm-based normal-reference tests (NRTs) by deriving the convergence rate of the distance between the null distribution of the test statistic and its corresponding normal-reference distribution. To facilitate practical application, an R package, HDNRA , is introduced, implementing these NRTs and extending beyond the two-sample problem to accommodate general linear hypothesis testing (GLHT). The package, designed with user-friendliness in mind, achieves efficient computation through a core implemented in C++ using Rcpp , OpenMP , and RcppArmadillo . Examples with real datasets are included, showcasing the application of various tests and providing insights into their practical utility.},
  archive      = {J_CSDA},
  author       = {Pengfei Wang and Tianming Zhu and Jin-Ting Zhang},
  doi          = {10.1016/j.csda.2025.108269},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108269},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Overview of normal-reference tests for high-dimensional means with implementation in the r package ‘HDNRA’},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional subgroup functional quantile regression with panel and dependent data. <em>CSDA</em>, <em>214</em>, 108268. (<a href='https://doi.org/10.1016/j.csda.2025.108268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional additive functional partial linear single-index quantile regression with high-dimensional parameters under subgroup panel data is investigated. Based on spline-based approach, we construct oracle estimators of the unknown parameter and functions, and discuss their consistency with rates and asymptotic normality under α -mixing assumptions. A penalized estimation method by using the SCAD technique is introduced to estimate the additive functions and parameter, enabling variable selection and automatic identification of the number of groups. Hypothesis testing for the parameter is also considered, and the asymptotic distributions of the restricted estimators and the test statistic are derived under both the null and local alternative hypotheses. Simulation studies and real data analysis are conducted to verify the validity of the proposed methods and applications.},
  archive      = {J_CSDA},
  author       = {Xiao-Ge Yu and Han-Ying Liang},
  doi          = {10.1016/j.csda.2025.108268},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108268},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {High-dimensional subgroup functional quantile regression with panel and dependent data},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cviu">CVIU - 14</h2>
<ul>
<li><details>
<summary>
(2025). Generalization-preserving adaptation of vision-language models for open-vocabulary segmentation. <em>CVIU</em>, <em>261</em>, 104518. (<a href='https://doi.org/10.1016/j.cviu.2025.104518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in large-scale Vision-Language Models (VLMs) has significantly advanced open-vocabulary segmentation. Previous works typically either generate class-agnostic masks and classify them with frozen VLMs, or align the mask generator features with VLM text features. These approaches face challenges of weak spatial discrimination ability of frozen VLMs and poor generalization due to unreliable vision-language alignment. This paper introduces a novel Generalization-Preserving Adaptation (GPA) of VLMs for open-vocabulary segmentation. GPA enhances the spatial discrimination capability of pre-trained VLMs through an efficient fine-tuning scheme, which incorporates a spatial adaptation module comprising spatial dependency modeling and low-rank feature modulation for preserving the feature space. Additionally, GPA proposes a context-aware feature aggregation module to extract mask features better aligned with the VLM features for mask classification. It performs decoupled context modeling that generates object-agnostic contextualized feature map and object-specific classification maps for accentuating discriminative and contextual clues. By maintaining the original VLM feature distribution for vision-language alignment, GPA effectively preserves the generalization capabilities of VLMs while enhancing segmentation performance. Extensive experiments on multiple open-vocabulary panoptic and semantic segmentation benchmarks demonstrate both superior effectiveness and generalization capabilities compared to previous works.},
  archive      = {J_CVIU},
  author       = {Zhen Chen and Hao Tang and Shiliang Zhang},
  doi          = {10.1016/j.cviu.2025.104518},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104518},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Generalization-preserving adaptation of vision-language models for open-vocabulary segmentation},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond geometry: The power of texture in interpretable 3D person ReID. <em>CVIU</em>, <em>261</em>, 104517. (<a href='https://doi.org/10.1016/j.cviu.2025.104517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents FusionTexReIDNet, a robust framework for 3D person re-identification that uniquely leverages UVTexture to enhance both performance and explainability. Unlike existing 3D person ReID approaches that simply overlay textures on point clouds, our method exploits the full potential of UVTexture through its high resolution and normalized coordinate properties. The framework consists of two main streams: a UVTexture stream that processes appearance features and a 3D stream that handles geometric information. These streams are fused through an effective combination of KNN, attribute-based, and explainable re-ranking strategies. Our approach introduces explainability to 3D person ReID through the visualization of activation maps on UVTextures, providing insights into the model’s decision-making process by highlighting discriminative regions. By incorporating the Intersection-Alignment Score derived from activation maps and visible clothing masks, we further improve the ReID accuracy. Extensive experiments demonstrate that FusionTexReIDNet achieves state-of-the-art performance across various scenarios, with Rank-1 accuracies of 98.5% and 89.7% Rank-1 on benchmark datasets, while providing interpretable results through its explainable component.},
  archive      = {J_CVIU},
  author       = {Huy Nguyen and Kien Nguyen and Akila Pemasiri and Sridha Sridharan and Clinton Fookes},
  doi          = {10.1016/j.cviu.2025.104517},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104517},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Beyond geometry: The power of texture in interpretable 3D person ReID},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic dual and efficient additive attention network for no-reference image quality assessment. <em>CVIU</em>, <em>261</em>, 104516. (<a href='https://doi.org/10.1016/j.cviu.2025.104516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No-Reference Image Quality Assessment (NR-IQA) aims to evaluate the perceptual quality of images in alignment with human subjective judgments. However, most existing NR-IQA methods, while striving for high accuracy, often neglect computational complexity. To address this challenge, we propose a Synergistic Spatial and Channel and Efficient Additive Attention Network for NR-IQA. In our approach, we first employ a feature extraction module to derive features rich in both distortion and semantic information. Subsequently, we introduce a spatial-channel synergistic attention mechanism to enhance feature representations across spatial and channel dimensions. This attention module focuses on the most salient regions of the image and modulates feature responses accordingly, enabling the network to emphasize critical distortions and semantic features pertinent to perceptual quality assessment. Specifically, the spatial attention mechanism identifies significant regions that substantially contribute to quality perception, while the channel attention mechanism adjusts the importance of each feature channel, ensuring effective utilization of spatial and channel-specific information. Furthermore, to enhance the model’s robustness, we incorporate an Efficient Additive Attention mechanism alongside a Multi-scale Feed-forward Network, designed to reduce computational costs without compromising performance. Finally, a dual-branch structure for patch-weighted quality prediction is employed to derive the final quality score based on the weighted scores of individual patches. Extensive experimental evaluations on four widely used benchmark datasets demonstrate that the proposed method surpasses several state-of-the-art NR-IQA approaches in both performance and computational efficiency.},
  archive      = {J_CVIU},
  author       = {Zhou Fang and Baiming Feng and Ning Li},
  doi          = {10.1016/j.cviu.2025.104516},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104516},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Synergistic dual and efficient additive attention network for no-reference image quality assessment},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative caption generation with heuristic guidance for enhancing knowledge-based visual question answering. <em>CVIU</em>, <em>261</em>, 104515. (<a href='https://doi.org/10.1016/j.cviu.2025.104515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of large language models (LLMs) has significantly advanced Knowledge-based Visual Question Answering (KBVQA) by reducing the reliance on external knowledge bases. Traditional methods often generate captions in a single pass, which can struggle with complex questions due to difficulty in precisely identifying key visual components. This challenge undermines the reasoning capabilities of LLMs, which require accurate, semantically aligned captions to answer complex questions effectively. To address this limitation, we propose ICGHG I terative C aption G eneration with H euristic G uidance, a novel framework that refines captions iteratively. Our approach incorporates a dynamic loop where captions are continuously refined based on heuristic feedback from a set of candidate answers and the question itself, ensuring that the final caption provides accurate semantic alignment with both the visual content and the question. By leveraging this iterative process, ICGHG mitigates common issues such as hallucinations and improves the quality of the generated captions. Extensive experiments on OK-VQA, A-OKVQA, and FVQA datasets demonstrate that ICGHG significantly outperforms existing methods, achieving 57.5%, 60.2%, and 69.4% accuracy on their respective test sets, setting new benchmarks in KBVQA accuracy.},
  archive      = {J_CVIU},
  author       = {Fengyuan Liu and Zhongjian Hu and Peng Yang and Xingyu Liu},
  doi          = {10.1016/j.cviu.2025.104515},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104515},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Iterative caption generation with heuristic guidance for enhancing knowledge-based visual question answering},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KD-mamba: Selective state space models with knowledge distillation for trajectory prediction. <em>CVIU</em>, <em>261</em>, 104499. (<a href='https://doi.org/10.1016/j.cviu.2025.104499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction is a key component of intelligent mobility systems and human–robot interaction. The inherently stochastic nature of human behavior, coupled with external environmental influences, poses significant challenges for long-term prediction. However, existing approaches struggle to effectively model spatial interactions and accurately predict long-term destinations, while their high computational demands limit real-world applicability. To address these limitations, this paper presents KD-Mamba, the Selective State Space Models with Knowledge Distillation for trajectory prediction. The model incorporates the U-CMamba module, which features a U-shaped encoder–decoder architecture. By integrating convolutional neural networks (CNN) with the Mamba mechanism, this module effectively captures local spatial interactions and global contextual information of human motion patterns. Subsequently, we introduce a Bi-Mamba module, which captures long-term dependencies in human movement, ensuring a more accurate representation of trajectory dynamics. Knowledge distillation strengthens both modules by facilitating knowledge transfer across diverse scenarios. Compared to transformer-based approaches, KD-Mamba reduces computational complexity from quadratic to linear. Extensive experimental results from two real-world trajectory datasets indicate that KD-Mamba outperforms the existing mainstream baselines. The proposed method provides insights into the application of trajectory prediction in human-in-the-loop assistive systems.},
  archive      = {J_CVIU},
  author       = {Shaokang Cheng and Sourav Das and Shiru Qu and Lamberto Ballan},
  doi          = {10.1016/j.cviu.2025.104499},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104499},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {KD-mamba: Selective state space models with knowledge distillation for trajectory prediction},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage attribute-guided dual attention network for fine-grained fashion retrieval. <em>CVIU</em>, <em>261</em>, 104497. (<a href='https://doi.org/10.1016/j.cviu.2025.104497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained clothing retrieval is essential for intelligent shopping and personalized recommendation systems. However, conventional methods often fail to capture subtle attribute variations. This paper proposes a novel two-stage attribute-guided dual attention network. The network combines global and local feature extraction with Attribute-aware Multi-Scale Spatial Attention (AMSA) and Attribute-guided Dynamic Channel Attention (ADCA). AMSA captures attribute-specific spatial details at multiple scales, while ADCA dynamically adjusts channel importance based on attribute embeddings, enabling precise attribute-level similarity modeling. A multi-level joint loss function further optimizes both global and local representations and enhances feature alignment. Experiments on FashionAI and the self-built FGDress dataset show that the proposed method achieves mAP scores of 66.01% and 73.98%, respectively, outperforming baseline approaches. Attribute-level analysis confirms robust recognition of both well-defined and challenging attributes. These results validate the practicality and generalizability of the proposed framework, with promising applications in personalized recommendation, fashion trend analysis, and design evaluation.},
  archive      = {J_CVIU},
  author       = {Bo Pan and Jun Xiang and Ning Zhang and Ruru Pan},
  doi          = {10.1016/j.cviu.2025.104497},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104497},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Two-stage attribute-guided dual attention network for fine-grained fashion retrieval},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JSF: A joint spatial-frequency domain network for low-light image enhancement. <em>CVIU</em>, <em>261</em>, 104496. (<a href='https://doi.org/10.1016/j.cviu.2025.104496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enhancement of low-light images remains a prominent focus in the field of image processing. The degree of lightness significantly influences vision-based intelligent recognition and analysis. Departing from conventional methods, this paper proposes an innovative joint spatial-frequency domain network for low-light image enhancement, referred to as JSF. In the spatial domain, brightness is optimized through the amalgamation of global and local information. In the frequency domain, noise is reduced and details are amplified using Fourier Transformation to carry out amplitude and phase enhancement. Additionally, the enhanced results from the aforementioned domains are fused by linear and nonlinear stretching. To validate the effectiveness of JSF, this paper presents both qualitative and quantitative comparison results, demonstrating its superiority over several existing state-of-the-art methods.},
  archive      = {J_CVIU},
  author       = {Yahong Wu and Feng Liu and Rong Wang},
  doi          = {10.1016/j.cviu.2025.104496},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104496},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {JSF: A joint spatial-frequency domain network for low-light image enhancement},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCNet: A feature complementary network for nighttime flare removal. <em>CVIU</em>, <em>261</em>, 104495. (<a href='https://doi.org/10.1016/j.cviu.2025.104495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nighttime image flare removal is a very challenging task due to the presence of various types of unfavorable degrading effects, including glare, shimmer, streak and saturated blobs. Most of the existing methods focus on the spatial domain and limited perception field, resulting in incomplete flare removal and severe artifacts. To address these challenges, we propose a two-stage feature complementary network for nighttime flare removal, which is used for flare perception and removal, respectively. In the first stage, a Spatial-Frequency Complementary Module (SFCM) is designed to perceive the flare region from different domains to get a mask of the flare. In the second stage, the flare mask and image are fed into the Spatial-Frequency Complementary Gating Module (SFCGM) to preserve the background information, while removing the flares from different angles and restoring the detailed features. Finally the flare and non-flare regions are modeled by the Flare Interactive Module (FIM) to refine the flare regions at a fine-grained level to suppress the artifact problem. Extensive experiments on Flare 7K++ validate the superiority of the proposed approach over state-of-the-arts, both qualitatively and quantitatively.},
  archive      = {J_CVIU},
  author       = {Kejing Qi and Bo Wang and Chongyi Li},
  doi          = {10.1016/j.cviu.2025.104495},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104495},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {FCNet: A feature complementary network for nighttime flare removal},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRE-net: A forgery image detection framework based on gradient feature and reconstruction error. <em>CVIU</em>, <em>261</em>, 104494. (<a href='https://doi.org/10.1016/j.cviu.2025.104494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous technological breakthroughs in Generative Adversarial Networks (GANs) and diffusion models, remarkable progress has been achieved in the field of image generation. These technologies enable the creation of highly realistic images, thereby intensifying the risk of spreading fake information. However, traditional image detectors face a growing challenge of inadequate generalization capabilities when confronted with images generated by models that were not included during the training phase. To tackle this challenge, we introduce a novel detection framework, named GRE-Net (Network integrating Gradient and Reconstruction Error), which extracts gradient feature through the DPG module and calculates the reconstruction error utilizing the DIRE method. By integrating these two aspects into a comprehensive feature representation, GRE-Net effectively detects the authenticity of images. Specifically, we devise a dual-branch model that leverages the proposed DPG (Discriminator of ProjectedGAN to extract Gradient) module to extract gradient feature from images and concurrently employs the DIRE (DIffusion Reconstruction Error) method to obtain the diffusion reconstruction error of images. By fusing the features extracted from these two modules as a universal representation, we describe the artifacts produced by generative models, crafting a comprehensive detector capable of identifying both GAN-generated and diffusion model-generated images. Notably, the DPG approach utilizes the discriminator of ProjectedGAN as an intermediary bridge, mapping all data into the gradient domain. This transformation process effectively captures the intrinsic feature differences during the image generation process. Subsequently, the gradient feature are fed into a classifier to achieve efficient discrimination between authentic and fake images. To validate the efficacy of our proposed detector, we conducted evaluations on a dataset comprising images generated by ten diverse diffusion models and GANs. Extensive experiments demonstrate that our detector exhibits stronger generalization capabilities and higher robustness, rendering it suitable for real-world generated image detection tasks.},
  archive      = {J_CVIU},
  author       = {Wenqing Wu and Xinyi Shi and Jinghai Ai and Xiaodong Wang},
  doi          = {10.1016/j.cviu.2025.104494},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104494},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {GRE-net: A forgery image detection framework based on gradient feature and reconstruction error},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating forgetting in the adaptation of CLIP for few-shot classification. <em>CVIU</em>, <em>261</em>, 104493. (<a href='https://doi.org/10.1016/j.cviu.2025.104493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adapter-style efficient transfer learning has demonstrated outstanding performance in fine-tuning vision-language models, especially in scenarios with limited data. However, existing methods fail to effectively balance the prior knowledge acquired during the pre-training process and the training samples. To address this problem, we propose a method called Mitigating Forgetting in the Adaptation (MiFA) of CLIP. MiFA first employs class prototypes to represent the most prominent features of a class, and these prototypes provide a robust initialization for the classifier. To overcome the forgetting of prior knowledge, MiFA then leverages a memory module that retains the initial parameters and the parameters of training history by creating a memory weight through momentum. The weight is used to initialize a new classification layer, which, along with the original layer, guides each other to balance prior knowledge and feature adaptation. Similarly, in the text processing branch, a parallel initialization strategy is adopted to ensure that the model’s performance is improved. Text features are employed to initialize a text classification layer, and CLIP logits help prevent excessive forgetting of useful text information. Extensive experiments have demonstrated the effectiveness of our method.},
  archive      = {J_CVIU},
  author       = {Jiale Cao and Yuanheng Liu and Zhong Ji and Jingren Liu and Aiping Yang and Yanwei Pang},
  doi          = {10.1016/j.cviu.2025.104493},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104493},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Mitigating forgetting in the adaptation of CLIP for few-shot classification},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint multi-dimensional dynamic attention and transformer for general image restoration. <em>CVIU</em>, <em>261</em>, 104491. (<a href='https://doi.org/10.1016/j.cviu.2025.104491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outdoor images often suffer from severe degradation due to rain, haze, and noise, impairing image quality and challenging high-level tasks. Current image restoration methods struggle to handle complex degradation while maintaining efficiency. This paper introduces a novel image restoration architecture that combines multi-dimensional dynamic attention and self-attention within a U-Net framework. To leverage the global modeling capabilities of transformers and the local modeling capabilities of convolutions, we integrate sole CNNs in the encoder–decoder and sole transformers in the latent layer. Additionally, we design convolutional kernels with selected multi-dimensional dynamic attention to capture diverse degraded inputs efficiently. A transformer block with transposed self-attention further enhances global feature extraction while maintaining efficiency. Extensive experiments demonstrate that our method achieves a better balance between performance and computational complexity across five image restoration tasks: deraining, deblurring, denoising, dehazing, and enhancement, as well as superior performance for high-level vision tasks. The source code will be available at https://github.com/House-yuyu/MDDA-former .},
  archive      = {J_CVIU},
  author       = {Huan Zhang and Xu Zhang and Nian Cai and Jianglei Di and Yun Zhang},
  doi          = {10.1016/j.cviu.2025.104491},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104491},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Joint multi-dimensional dynamic attention and transformer for general image restoration},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO. <em>CVIU</em>, <em>261</em>, 104489. (<a href='https://doi.org/10.1016/j.cviu.2025.104489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone-based target detection presents inherent challenges, including the high density and overlap of targets in drone images, as well as the blurriness of targets under varying lighting conditions, which complicates accurate identification. Traditional methods often struggle to detect numerous small, densely packed targets against complex backgrounds. To address these challenges, we propose LAM-YOLO, an object detection model specifically designed for drone-based applications. First, we introduce a light-occlusion attention mechanism to enhance the visibility of small targets under diverse lighting conditions. Additionally, we incorporate Involution modules to improve feature layer interactions. Second, we employ an improved SIB-IoU as the regression loss function to accelerate model convergence and enhance localization accuracy. Finally, we implement a novel detection strategy by introducing two auxiliary detection heads to better identify smaller-scale targets. Our quantitative results demonstrate that LAM-YOLO outperforms methods such as Faster R-CNN, YOLOv11, and YOLOv12 in terms of mAP@0.5 and mAP@0.5:0.95 on the VisDrone2019 public dataset. Compared to the original YOLOv8, the average precision increases by 7.1%. Additionally, the proposed SIB-IoU loss function not only accelerates convergence speed during training but also improves average precision compared to the traditional loss function.},
  archive      = {J_CVIU},
  author       = {Yuchen Zheng and Yuxin Jing and Jufeng Zhao and Guangmang Cui},
  doi          = {10.1016/j.cviu.2025.104489},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104489},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camera pose in SfT and NRSfM under isometric and weaker deformation models. <em>CVIU</em>, <em>261</em>, 104488. (<a href='https://doi.org/10.1016/j.cviu.2025.104488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camera pose is a very natural concept in 3D vision in the rigid setting. It is however much more difficult to work with in deformable settings. Consequently, numerous deformable reconstruction methods simply ignore camera pose. We analyse the concept of pose in deformable settings and prove that it is unconstrained with the existing formulations, properly justifying the existing pose-less methods reconstructing structure only. We explain this result intuitively by the impossibility to define an intrinsic coordinate frame to a general deforming object. The proposed analysis uses the isometric deformation model and extends to the weaker models including conformality and equiareality We propose a novel prior to rescue camera pose estimation in deformable settings, which attributes the deforming object’s dominant rigid-body motion to the camera. We show that adding this prior to any existing formulation fully constrains camera pose and leads to elegant two-step solution methods, involving deformable structure reconstruction using a base method in the first step, and absolute orientation or Procrustes analysis in the second step. We derive the proposed approach for the template-based and template-less settings, respectively implemented using Shape-from-Template (SfT) and Non-Rigid Structure-from-Motion (NRSfM) as base methods and validate them experimentally, showing that the computed pose is qualitatively and quantitatively plausible.},
  archive      = {J_CVIU},
  author       = {Adrien Bartoli and Agniva Sengupta},
  doi          = {10.1016/j.cviu.2025.104488},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104488},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Camera pose in SfT and NRSfM under isometric and weaker deformation models},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-granularity balance learning for long-tailed image classification. <em>CVIU</em>, <em>261</em>, 104469. (<a href='https://doi.org/10.1016/j.cviu.2025.104469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In long-tailed datasets, the training of deep neural network-based models faces challenges, where the model may become biased towards the head classes with abundant training data, resulting in poor performance on tail classes with limited samples. Most current methods employ contrastive learning to learn more balanced representations by finding the class center. However, these methods use class centers to address local imbalance within a mini-batch, they overlook the global imbalance between batches throughout an epoch, caused by the long-tailed distribution of the dataset. In this paper, we propose bi-granularity balance learning to address the two-layer imbalance. We decouple the attraction–repulsion term in contrastive loss into two independent components: global and local balance. The global balance component focuses on capturing semantic information from different perspectives of the image and shifting learning attention from the head classes to the tail classes in the global perspective. The local balance component aims to learn inter-class separability from the local perspective. The proposed method efficiently learns the intra-class compactness and inter-class separability in long-tailed model training and improves the performance of the long-tailed model. Experimental results show that the proposed method achieves competitive performance on long-tailed benchmarks such as CIFAR-10/100-LT, TinyImageNet-LT, and iNaturalist 2018.},
  archive      = {J_CVIU},
  author       = {Ning Ren and Xiaosong Li and Yanxia Wu and Yan Fu},
  doi          = {10.1016/j.cviu.2025.104469},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104469},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Bi-granularity balance learning for long-tailed image classification},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="disopt">DISOPT - 4</h2>
<ul>
<li><details>
<summary>
(2025). Minimizing maximum dissatisfaction in the allocation of indivisible items under a common preference graph. <em>DISOPT</em>, <em>58</em>, 100913. (<a href='https://doi.org/10.1016/j.disopt.2025.100913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the task of allocating indivisible items to agents, when the agents’ preferences over the items are identical. The preferences are captured by means of a directed acyclic graph, with vertices representing items and an edge ( a , b ) , meaning that each of the agents prefers item a over item b . The dissatisfaction of an agent is measured by the number of items that the agent does not receive and for which it also does not receive any more preferred item. The aim is to allocate the items to the agents in a fair way, i.e., to minimize the maximum dissatisfaction among the agents. We study the status of computational complexity of that problem and establish the following dichotomy: the problem is NP -hard for the case of at least three agents, even on fairly restricted graphs, but polynomially solvable for two agents. We also provide several polynomial-time results with respect to different underlying graph structures, such as graphs of width at most two and tree-like structures such as stars and matchings. These findings are complemented with fixed parameter tractability results related to path modules and independent set modules. Techniques employed in the paper include bottleneck assignment problem, greedy algorithm, dynamic programming, maximum network flow, and integer linear programming.},
  archive      = {J_DISOPT},
  author       = {Nina Chiarelli and Clément Dallard and Andreas Darmann and Stefan Lendl and Martin Milanič and Peter Muršič and Ulrich Pferschy},
  doi          = {10.1016/j.disopt.2025.100913},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100913},
  shortjournal = {Discret. Optim.},
  title        = {Minimizing maximum dissatisfaction in the allocation of indivisible items under a common preference graph},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computational aspects of lifted cover inequalities for knapsacks with few different weights. <em>DISOPT</em>, <em>58</em>, 100912. (<a href='https://doi.org/10.1016/j.disopt.2025.100912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cutting planes are frequently used for solving integer programs. A common strategy is to derive cutting planes from building blocks or a substructure of the integer program. In this paper, we focus on knapsack constraints that arise from single row relaxations. Among the most popular classes derived from knapsack constraints are lifted minimal cover inequalities. The separation problem for these inequalities is NP-hard though, and one usually separates them heuristically, therefore not fully exploiting their potential. For many benchmarking instances however, it turns out that many knapsack constraints only have few different coefficients. This motivates the concept of sparse knapsacks where the number of different coefficients is a small constant, independent of the number of variables present. For such knapsacks, we observe that there are only polynomially many different classes of structurally equivalent minimal covers. This opens the door to specialized techniques for using lifted minimal cover inequalities. In this article we will discuss two such techniques, which are based on specialized sorting methods. On the one hand, we present new separation routines that separate equivalence classes of inequalities rather than individual inequalities. On the other hand, we derive compact extended formulations that express all lifted minimal cover inequalities by means of a polynomial number of constraints. These extended formulations are based on tailored sorting networks that express our separation algorithm by linear inequalities. We conclude the article by a numerical investigation of the different techniques for popular benchmarking instances.},
  archive      = {J_DISOPT},
  author       = {Christopher Hojny and Cédric Roy},
  doi          = {10.1016/j.disopt.2025.100912},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100912},
  shortjournal = {Discret. Optim.},
  title        = {Computational aspects of lifted cover inequalities for knapsacks with few different weights},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved bound for the price of anarchy for related machine scheduling. <em>DISOPT</em>, <em>58</em>, 100911. (<a href='https://doi.org/10.1016/j.disopt.2025.100911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce an improved upper bound for the efficiency of Nash equilibria in utilitarian scheduling games on related machines. The machines have varying speeds and adhere to the shortest processing time first policy. The goal of each job is to minimize its completion time, while the social objective is to minimize the sum of completion times. Our main finding establishes an upper bound of 2 − 1 / ( 4 m − 2 ) on the price of anarchy for the general case of m machines. We improve this bound to 3/2 for the case of two machines, and to 2 − 1 / ( 2 m ) for the general case of m machines when the machines have divisible speeds, i.e., if the speed of each machine is divisible by the speed of any slower machine.},
  archive      = {J_DISOPT},
  author       = {André Berger and Arman Rouhani and Marc Schröder},
  doi          = {10.1016/j.disopt.2025.100911},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100911},
  shortjournal = {Discret. Optim.},
  title        = {An improved bound for the price of anarchy for related machine scheduling},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the circuit diameter conjecture for counterexamples to the hirsch conjecture. <em>DISOPT</em>, <em>58</em>, 100910. (<a href='https://doi.org/10.1016/j.disopt.2025.100910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circuit diameters of polyhedra are a fundamental tool for studying the complexity of circuit augmentation schemes for linear programming and for finding lower bounds on combinatorial diameters. The main open problem in this area is the circuit diameter conjecture, the analogue of the Hirsch conjecture in the circuit setting. A natural question is whether the well-known counterexamples to the Hirsch conjecture carry over. Previously, Stephen and Yusun showed that the Klee-Walkup counterexample to the unbounded Hirsch conjecture does not transfer to the circuit setting. Our main contribution is to show that the original counterexamples for other variants, using monotone walks or for bounded polytopes, also do not transfer. A challenge lies in the dependence of circuit diameters on the specific realization of a polyhedron. We discuss for which realizations, in addition to the original ones from the literature, our tools resolve this question. Our results rely on new observations on structural properties of these counterexamples. To analyze the bounded case, we exploit the geometry of certain 2-faces of the polytopes underlying all known bounded Hirsch counterexamples in Santos’ work. For Todd’s monotone Hirsch counterexample, we study linear programs on spindles and prove sufficient conditions for short monotone circuit walks to exist. We then enumerate all linear programs over Todd’s polytope and find four new orientations that contradict the monotone Hirsch conjecture, while the remaining 7107 satisfy the bound. The conclusion then follows by applying these sufficient conditions to Todd’s counterexample.},
  archive      = {J_DISOPT},
  author       = {Alexander E. Black and Steffen Borgwardt and Matthias Brugger},
  doi          = {10.1016/j.disopt.2025.100910},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100910},
  shortjournal = {Discret. Optim.},
  title        = {On the circuit diameter conjecture for counterexamples to the hirsch conjecture},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="dke">DKE - 15</h2>
<ul>
<li><details>
<summary>
(2026). Secure data storage in multi-cloud environments using lattice-based saber with diffie-hellman cryptography and authenticate based on PUF-ECC. <em>DKE</em>, <em>161</em>, 102512. (<a href='https://doi.org/10.1016/j.datak.2025.102512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human life has become highly dependent on data in recent decades almost every facet of daily activities, leading to its storage in multi-cloud environments. To ensure data integrity, confidentiality, and privacy, it is essential to protect data from unauthorized access. This paper proposes a novel approach for securing data in multi-cloud environments for user authentication and data storage using Lattice-Based Saber Cryptography combined with PUF-ECC and the Enhanced Goose Optimization Algorithm (EGOA). The initial user authentication is achieved through the PUF-ECC digital signature algorithm, which verifies both the user's and the device's identity. Once authenticated, user data is securely transmitted to the cloud server based on Lattice-Based Saber post-quantum cryptography combined with the Diffie-Hellman key exchange protocol. The encrypted data is then stored across multiple cloud storage through a cloud controller using RAM-based chunking. For efficient data retrieval, the Enhanced Goose Optimization Algorithm (EGOA) is employed to extract encrypted data from clouds. Finally, the data is decrypted using the Lattice-Based Saber decryption algorithm and securely retrieved by the authenticated user. This method enhances both the security and efficiency of cloud data management and retrieval. The experiment is carried out with the proposed methodologies and also compared with the existing technologies. The proposed approach achieves encryption times of 9.68 ms, key generation times of 4.84 ms, and block creation times of 1.59 ms, while maintaining a 93.7 % confidentiality rate, a 98 % packet delivery ratio, a transmission delay of 0.026 ms, throughput of 407.33 MB/s, jitter of 3.26 ms, and an RTT of 0.17 ms, demonstrating its effectiveness in secure data storage and retrieval in multi-cloud environments.},
  archive      = {J_DKE},
  author       = {R. Iyswarya and R. Anitha},
  doi          = {10.1016/j.datak.2025.102512},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102512},
  shortjournal = {Data Knowl. Eng.},
  title        = {Secure data storage in multi-cloud environments using lattice-based saber with diffie-hellman cryptography and authenticate based on PUF-ECC},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ASF: A novel associative scoring function for embedded knowledge graph reasoning. <em>DKE</em>, <em>161</em>, 102511. (<a href='https://doi.org/10.1016/j.datak.2025.102511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important tools for knowledge management is the Knowledge Graph (KG), a multi-relational graph that depicts rich factual information across entities. A KG represents entities as nodes and relations as edges, with each edge represented by a triplet: (head entity, relation, tail entity). The Scoring Function (SF) in a KG quantifies the plausibility of these triplets and is often derived from KG embeddings. However, due to the distinct relational patterns across KGs, an SF that performs well on one KG might fail on another, making the design of optimal SFs a challenging task. This study introduces the concept of an Associative Scoring Function (ASF), which leverages Association Rule Mining (ARM) to discover and incorporate patterns and characteristics of symmetric, asymmetric, inverse, and other relational types within embedded KGs. The ARM technique in ASF uses the FP-Growth algorithm to extract meaningful associations, which is enhanced further through hyperparameter tuning. Extensive experiments on benchmark datasets demonstrate that ASF is KG-independent and performs better than state-of-the-art SFs. These results highlight ASF's potential to generalize across diverse KGs, offering a significant advancement in the KG link prediction task.},
  archive      = {J_DKE},
  author       = {MVPT Lakshika and HA Caldera},
  doi          = {10.1016/j.datak.2025.102511},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102511},
  shortjournal = {Data Knowl. Eng.},
  title        = {ASF: A novel associative scoring function for embedded knowledge graph reasoning},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A graph-based model for semantic textual similarity measurement. <em>DKE</em>, <em>161</em>, 102509. (<a href='https://doi.org/10.1016/j.datak.2025.102509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring semantic similarity between sentence pairs is a fundamental problem in Natural Language Processing with applications in various domains, including machine translation, speech recognition, automatic question answering, and text summarization. Despite its significance, accurately assessing semantic similarity remains a challenging task, particularly for underrepresented languages such as Vietnamese. Existing methods have yet to fully leverage the unique linguistic characteristics of Vietnamese for semantic similarity measurement. To address this limitation, we propose GBNet-STS (Graph-Based Network for Semantic Textual Similarity), a novel framework for measuring the semantic similarity of Vietnamese sentence pairs. GBNet-STS integrates lexical-grammatical similarity scores and distributional semantic similarity scores within a multi-layered graph-based model. By capturing different semantic perspectives through multiple interconnected layers, our approach provides a more comprehensive and robust similarity estimation. Experimental results demonstrate that GBNet-STS outperforms traditional methods, achieving state-of-the-art performance in Vietnamese semantic similarity tasks.},
  archive      = {J_DKE},
  author       = {Van-Tan Bui and Quang-Minh Nguyen and Van-Vinh Nguyen and Duc-Toan Nguyen},
  doi          = {10.1016/j.datak.2025.102509},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102509},
  shortjournal = {Data Knowl. Eng.},
  title        = {A graph-based model for semantic textual similarity measurement},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rule-guided process discovery. <em>DKE</em>, <em>161</em>, 102508. (<a href='https://doi.org/10.1016/j.datak.2025.102508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event data extracted from information systems serves as the foundation for process mining, enabling the extraction of insights and identification of improvements. Process discovery focuses on deriving descriptive process models from event logs, which form the basis for conformance checking, performance analysis, and other applications. Traditional process discovery techniques predominantly rely on event logs, often overlooking supplementary information such as domain knowledge and process rules. These rules, which define relationships between activities, can be obtained through automated techniques like declarative process discovery or provided by domain experts based on process specifications. When used as an additional input alongside event logs, such rules have significant potential to guide process discovery. However, leveraging rules to discover high-quality imperative process models, such as BPMN models and Petri nets, remains an underexplored area in the literature. To address this gap, we propose an enhanced framework, IMr, which integrates discovered or user-defined rules into the process discovery workflow via a novel recursive approach. The IMr framework employs a divide-and-conquer strategy, using rules to guide the selection of process structures at each recursion step in combination with the input event log. We evaluate our approach on several real-world event logs and demonstrate that the discovered models better align with the provided rules without compromising their conformance to the event log. Additionally, we show that high-quality rules can improve model quality across well-known conformance metrics. This work highlights the importance of integrating domain knowledge into process discovery, enhancing the quality, interpretability, and applicability of the resulting process models.},
  archive      = {J_DKE},
  author       = {Ali Norouzifar and Marcus Dees and Wil van der Aalst},
  doi          = {10.1016/j.datak.2025.102508},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102508},
  shortjournal = {Data Knowl. Eng.},
  title        = {Rule-guided process discovery},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LQ-FJS: A logical query-digging fake-news judgment system with structured video-summarization engine using LLM. <em>DKE</em>, <em>161</em>, 102507. (<a href='https://doi.org/10.1016/j.datak.2025.102507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of online social platforms can greatly benefit people by fostering remote relationships, but it also inevitably amplifies the impact of multimodal fake news on societal trust and ethics. Existing fake-news detection AI systems are still vulnerable to the inconspicuous and indiscernible multimodal misinformation, and often lacking interpretability and accuracy in cross-platform settings. Hence, we propose a new innovative logical query-digging fake-news judgment system (LQ-FJS) to tackle the above problem based on multimodal approach. The LQ-FJS verifies the truthfulness of claims made within multimedia news by converting video content into structured textual summaries. It then acts as an interpretable agent, explaining the reasons for identified fake news by the structured video-summarization engine (SVSE) to act as an interpretable detection intermediary agent. The SVSE generates condensed captions for raw video content, converting it into structured textual narratives. Then, LQ-FJS exploits these condensed captions to retrieve reliable information related to the video content from LLM. Thus, LQ-FJS cross-verifies external knowledge sources and internal LLM responses to determine whether contradictions exist with factual information through a multimodal inconsistency verification procedure. Our experiments demonstrate that the subtle summarization produced by SVSE can facilitate the generation of explanatory reports that mitigate large-scale trust deficits caused by opaque “black-box” models. Our experiments show that LQ-FJS improves F1 scores by 4.5% and 7.2% compared to state-of-the-art models (FactLLaMA 2023 and HiSS 2023), and increases 14% user trusts through interpretable conclusions.},
  archive      = {J_DKE},
  author       = {Jhing-Fa Wang and Din-Yuen Chan and Hsin-Chun Tsai and Bo-Xuan Fang},
  doi          = {10.1016/j.datak.2025.102507},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102507},
  shortjournal = {Data Knowl. Eng.},
  title        = {LQ-FJS: A logical query-digging fake-news judgment system with structured video-summarization engine using LLM},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ABBA: Index structure for sequential pattern-based aggregate queries. <em>DKE</em>, <em>161</em>, 102506. (<a href='https://doi.org/10.1016/j.datak.2025.102506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern-based aggregate (PBA) queries constitute an important and widely used type of analytical queries in sequence OLAP (S-OLAP) systems. Unfortunately, finding accurate answers to PBA queries in the S-OLAP system is often very expensive both in terms of time and memory consumption. In this paper we propose an efficient and easily maintainable index structure called the ABBA Index, which addresses the problem of PBA query processing. Experiments conducted using the KDD Cup data and public transport passengers’ travel behavior data show that our index outperforms state-of-the art solutions while requiring much less memory. The ABBA Index can be easily extended to support pattern-based aggregate queries over hierarchy (PBA-H), a novel class of analytical queries which we introduce as the second main contribution of the paper. Sensitivity, scalability and complexity analysis of the ABBA Index is also provided.},
  archive      = {J_DKE},
  author       = {Witold Andrzejewski and Tadeusz Morzy and Maciej Zakrzewicz},
  doi          = {10.1016/j.datak.2025.102506},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102506},
  shortjournal = {Data Knowl. Eng.},
  title        = {ABBA: Index structure for sequential pattern-based aggregate queries},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Elevating human-machine collaboration in NLP for enhanced content creation and decision support. <em>DKE</em>, <em>161</em>, 102505. (<a href='https://doi.org/10.1016/j.datak.2025.102505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-machine collaboration in Natural Language Processing (NLP) is revolutionizing content creation and decision support by seamlessly combining the strengths of both entities for enhanced efficiency and quality. The lack of seamless integration between human creativity and machine efficiency in NLP hinders optimal content creation and decision support. The objective of this study is to explore and promote the integration of human-machine collaboration in NLP to enhance both content creation and decision support processes. Data Acquisition for NLP requests involves defining the task and target audience, identifying relevant data sources like text documents and web data, and incorporating human expertise for data curation through validation and annotation. Machine processing techniques like tokenization, stemming/lemmatization, and removal of stop words, as well as human input for tasks like data annotation and error correction, to improve data quality and relevance for NLP applications. The combination of automated processing and human feedback leads to more precise and dependable effects. Techniques such as sentiment analysis, topic modelling, and entity recognition are utilized to excerpt valued perceptions from the data and enhance collaboration between humans and machines. These techniques help to streamline the NLP process and ensure that the system is providing accurate and relevant information to users. The analysis of NLP models in machine processing involves training the models to perform specific tasks, such as summarization, sentiment analysis, information extraction, trend identification, and creative content generation. The results show that social media leads with 90% usage, pivotal for audience engagement, while blogs at 78% highlight their depth in content creation implementation using Python software. These trained models are then used to improve decision-making processes, generate creative content, and enhance the accuracy of search results. The future scope involves leveraging advanced NLP techniques to deepen the collaboration between humans and machines for more effective content creation and decision support.},
  archive      = {J_DKE},
  author       = {Priyanka V. Deshmukh and Aniket K. Shahade},
  doi          = {10.1016/j.datak.2025.102505},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102505},
  shortjournal = {Data Knowl. Eng.},
  title        = {Elevating human-machine collaboration in NLP for enhanced content creation and decision support},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ELEVATE-ID: Extending large language models for end-to-end entity linking evaluation in indonesian. <em>DKE</em>, <em>161</em>, 102504. (<a href='https://doi.org/10.1016/j.datak.2025.102504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their effectiveness in low-resource languages remains underexplored, particularly in complex tasks such as end-to-end Entity Linking (EL), which requires both mention detection and disambiguation against a knowledge base (KB). In earlier work, we introduced IndEL — the first end-to-end EL benchmark dataset for the Indonesian language — covering both a general domain (news) and a specific domain (religious text from the Indonesian translation of the Quran), and evaluated four traditional end-to-end EL systems on this dataset. In this study, we propose ELEVATE-ID, a comprehensive evaluation framework for assessing LLM performance on end-to-end EL in Indonesian. The framework evaluates LLMs under both zero-shot and fine-tuned conditions, using multilingual and Indonesian monolingual models, with Wikidata as the target KB. Our experiments include performance benchmarking, generalization analysis across domains, and systematic error analysis. Results show that GPT-4 and GPT-3.5 achieve the highest accuracy in zero-shot and fine-tuned settings, respectively. However, even fine-tuned GPT-3.5 underperforms compared to DBpedia Spotlight — the weakest of the traditional model baselines — in the general domain. Interestingly, GPT-3.5 outperforms Babelfy in the specific domain. Generalization analysis indicates that fine-tuned GPT-3.5 adapts more effectively to cross-domain and mixed-domain scenarios. Error analysis uncovers persistent challenges that hinder LLM performance: difficulties with non-complete mentions, acronym disambiguation, and full-name recognition in formal contexts. These issues point to limitations in mention boundary detection and contextual grounding. Indonesian-pretrained LLMs, Komodo and Merak, reveal core weaknesses: template leakage and entity hallucination, respectively—underscoring architectural and training limitations in low-resource end-to-end EL. 1},
  archive      = {J_DKE},
  author       = {Ria Hari Gusmita and Asep Fajar Firmansyah and Hamada M. Zahera and Axel-Cyrille Ngonga Ngomo},
  doi          = {10.1016/j.datak.2025.102504},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102504},
  shortjournal = {Data Knowl. Eng.},
  title        = {ELEVATE-ID: Extending large language models for end-to-end entity linking evaluation in indonesian},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-aware complex question answering over temporal knowledge graph. <em>DKE</em>, <em>161</em>, 102503. (<a href='https://doi.org/10.1016/j.datak.2025.102503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Question Answering (KGQA) is a crucial topic in Knowledge Graphs (KGs), with the objective of retrieving the corresponding facts from KGs to answer given questions. In practical applications, facts in KGs usually have time constraints, thus, question answering on Temporal Knowledge Graphs (TKGs) has attracted extensive attention. Existing Temporal Knowledge Graph Question Answering (TKGQA) methods focus on dealing with complex questions involving multiple facts, and mainly face two challenges. First, these methods only consider matching questions with facts in TKGs to identify the answer, ignoring the temporal order between different facts, which makes it challenging to solve the questions involving temporal order. Second, they usually focus on the representation of the question text while neglecting the rich semantic information within the questions, which leads to certain limitations in understanding question. To address the above challenges, this research proposes a model named Time-Aware Complex Question Answering (TA-CQA). Specifically, we extend the Temporal Knowledge Graph Embedding (TKGE) model by incorporating temporal order information into the embedding vectors, ensuring that the model can distinguish the temporal order of different facts. To enhance the semantic representation of the question, we integrate question information using attention mechanism and learnable encoder. Different from the previous TKGQA methods, we propose time relevance measurement to further enhance the accuracy of answer prediction by better capturing the correlation between question information and time information. Multiple sets of experiments on CronQuestions and TimeQuestions demonstrate our model’s superior performance across all question types. In particular, for complex questions involving multiple facts, the hit@1 values are increased by 3.2% and 3.5% respectively.},
  archive      = {J_DKE},
  author       = {Luyi Bai and Tongyue Zhang and Guangchen Feng},
  doi          = {10.1016/j.datak.2025.102503},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102503},
  shortjournal = {Data Knowl. Eng.},
  title        = {Time-aware complex question answering over temporal knowledge graph},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conceptual modeling of user perspectives — From data warehouses to alliance-driven data ecosystems. <em>DKE</em>, <em>161</em>, 102502. (<a href='https://doi.org/10.1016/j.datak.2025.102502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of modern information systems has highlighted the need for advanced conceptual modeling techniques that incorporate multi-perspective and view-based approaches. This paper explores the role of multi-perspective modeling and view modeling in designing distributed, heterogeneous systems while addressing diverse user requirements and ensuring semantic consistency. These methods enable the representation of multiple viewpoints, traceability, and dynamic integration across different levels of abstraction. Key advancements in schema mapping, view maintenance, and semantic metadata management are examined, illustrating how they support query optimization, data quality, and interoperability. We discuss how data management architectures, such as data ecosystems, data warehouses, and data lakes, leverage these innovations to enable flexible and sustainable data sharing. By integrating user-centric and goal-oriented modeling frameworks, the alignment of technical design with organizational and social requirements is emphasized. Future challenges include the need for enhanced reasoning capabilities and collaborative tools to manage the growing complexity of interconnected systems while maintaining adaptability and trust.},
  archive      = {J_DKE},
  author       = {Sandra Geisler and Christoph Quix and István Koren and Matthias Jarke},
  doi          = {10.1016/j.datak.2025.102502},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102502},
  shortjournal = {Data Knowl. Eng.},
  title        = {Conceptual modeling of user perspectives — From data warehouses to alliance-driven data ecosystems},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Source-free domain adaptation with complex distribution considerations for time series data. <em>DKE</em>, <em>161</em>, 102501. (<a href='https://doi.org/10.1016/j.datak.2025.102501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained model from a labeled source domain to an unlabeled target domain without accessing source domain data, thereby protecting source domain privacy. Although SFDA has recently been applied to time series data, the inherent complex distribution characteristics including temporal variability and distributional diversity of such data remain underexplored. Time series data exhibit significant dynamic variability influenced by collection environments, leading to discrepancies between sequences. Additionally, multidimensional time series data face distributional diversity across dimensions. These complex characteristics increase the learning difficulty for source models and widen the adaptation gap between the source and target domains. To address these challenges, this paper proposes a novel SFDA method for time series data, named Adaptive Latent Subdomain feature extraction and joint Prediction (ALSP). The method divides the source domain, which has a complex distribution, into multiple latent subdomains with relatively simple distributions, thereby effectively capturing the features of different subdistributions. It extracts latent domain-specific and domain-invariant features to identify subdomain-specific characteristics. Furthermore, it combines domain-specific classifiers and a domain-invariant classifier to enhance model performance through multi-classifier joint prediction. During target domain adaptation, ALSP reduces domain dependence by extracting invariant features, thereby narrowing the distributional gap between the source and target domains. Simultaneously, it leverages prior knowledge from the source domain distribution to support the hypothesis space and dynamically adapt to the target domain. Experiments on three real-world datasets demonstrate that ALSP achieves superior performance in cross-domain time series classification tasks, significantly outperforming existing methods.},
  archive      = {J_DKE},
  author       = {Jing Shang and Zunming Chen and Zhiwen Xiao and Zhihui Wu and Yifei Zhang and Jibing Wang},
  doi          = {10.1016/j.datak.2025.102501},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102501},
  shortjournal = {Data Knowl. Eng.},
  title        = {Source-free domain adaptation with complex distribution considerations for time series data},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conceptual modeling: A large language model assistant for characterizing research contributions. <em>DKE</em>, <em>161</em>, 102497. (<a href='https://doi.org/10.1016/j.datak.2025.102497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The body of conceptual modeling research publications is vast and diverse, making it challenging for a single researcher or research group to fully comprehend the field’s overall development. Although some approaches have been proposed to help organize these research contributions, it is still unrealistic to expect human experts to manually comprehend and characterize all of this research. However, as generative AI tools based on large language models, such as ChatGPT, become increasingly sophisticated, it may be possible to replace or augment tedious, manual work with semi-automated approaches. In this research, we present a customized version of ChatGPT that is tuned to the task of characterizing conceptual modeling research. Experiments with this AI tool demonstrate that it is feasible to create a usable knowledge survey for the continually evolving body of conceptual modeling research contributions.},
  archive      = {J_DKE},
  author       = {Stephen W. Liddle and Heinrich C. Mayr and Oscar Pastor and Veda C. Storey and Bernhard Thalheim},
  doi          = {10.1016/j.datak.2025.102497},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102497},
  shortjournal = {Data Knowl. Eng.},
  title        = {Conceptual modeling: A large language model assistant for characterizing research contributions},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic time warping for classifying long-term trends in time series. <em>DKE</em>, <em>161</em>, 102495. (<a href='https://doi.org/10.1016/j.datak.2025.102495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the potential of dynamic time warping (DTW) for recognizing different segments in time series data characterized by their long-term trends and curvature. To perform classification, a set of reference data for each class is required, where each time series in the reference set represents a typical shape of that class. The classification process involves computing the DTW distance between a given time series and each reference time series, then assigning the time series to the class with the minimum distance. Experiments on both simulated and real-world time series data from two different use cases demonstrate that DTW can correctly classify the different segments. Additionally, the paper investigates whether incorrectly classified phases could indicate data security issues. Additional experiments are performed to assess the number of data points required to reliably classify a segment correctly. These experiments highlight the limitations and emphasize the importance of selecting good reference data.},
  archive      = {J_DKE},
  author       = {Anna-Christina Glock and Klaus Chmelina and Johannes Fürnkranz and Thomas Hütter},
  doi          = {10.1016/j.datak.2025.102495},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102495},
  shortjournal = {Data Knowl. Eng.},
  title        = {Dynamic time warping for classifying long-term trends in time series},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semantic-aware query answering with large language models. <em>DKE</em>, <em>161</em>, 102494. (<a href='https://doi.org/10.1016/j.datak.2025.102494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern data-driven world, answering queries over heterogeneous and semantically inconsistent data remains a significant challenge. Modern datasets originate from diverse sources, such as relational databases, semi-structured repositories, and unstructured documents, leading to substantial variability in schemas, terminologies, and data formats. Traditional systems, constrained by rigid syntactic matching and strict data binding, struggle to capture critical semantic connections and schema ambiguities, failing to meet the growing demand among data scientists for advanced forms of flexibility and context-awareness in query answering. In parallel, the advent of Large Language Models (LLMs) has introduced new capabilities in natural language interpretation, making them highly promising for addressing such challenges. However, LLMs alone lack the systematic rigor and explainability required for robust query processing and decision-making in high-stakes domains. In this paper, we propose Soft Query Answering (Soft QA), a novel hybrid approach that integrates LLMs as an intermediate semantic layer within the query processing pipeline. Soft QA enhances query answering adaptability and flexibility by injecting semantic understanding through context-aware, schema-informed prompts, and leverages LLMs to semantically link entities, resolve ambiguities, and deliver accurate query results in complex settings. We demonstrate its practical effectiveness through real-world examples, highlighting its ability to resolve semantic mismatches and improve query outcomes without requiring extensive data cleaning or restructuring.},
  archive      = {J_DKE},
  author       = {Paolo Atzeni and Teodoro Baldazzi and Luigi Bellomarini and Eleonora Laurenza and Emanuel Sallinger},
  doi          = {10.1016/j.datak.2025.102494},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102494},
  shortjournal = {Data Knowl. Eng.},
  title        = {Semantic-aware query answering with large language models},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated requirements framework for analytical and AI projects. <em>DKE</em>, <em>161</em>, 102493. (<a href='https://doi.org/10.1016/j.datak.2025.102493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To this day, the requirements of data warehouses, user visualizations and ML projects have been tackled in an independent manner, ignoring the possible cross-requirements, collective constraints and dependencies between the outputs of the different systems that should be taken into account to ensure a successful analytical project. In this work, we take a holistic approach and propose a methodology that supports modeling and subsequent analysis while taking into account these three aspects. This methodology has several advantages, mainly that (i) it enables us to identify possible conflicts between actors on different tasks that are overlooked if the systems are treated in an isolated manner and (ii) this holistic view enables modeling multi-company systems, where the information or even the analytical results can be provided by third-parties, identifying key participants in federated environments. After presenting the required formalism to carry out this kind of analysis, we showcase it on a real-world running example of the tourism sector.},
  archive      = {J_DKE},
  author       = {Juan Trujillo and Ana Lavalle and Alejandro Reina-Reina and Jorge García-Carrasco and Alejandro Maté and Wolfgang Maaß},
  doi          = {10.1016/j.datak.2025.102493},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102493},
  shortjournal = {Data Knowl. Eng.},
  title        = {An integrated requirements framework for analytical and AI projects},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="dss">DSS - 10</h2>
<ul>
<li><details>
<summary>
(2025). Corporate credit scoring method based on unlabeled data and multi-source data. <em>DSS</em>, <em>198</em>, 114543. (<a href='https://doi.org/10.1016/j.dss.2025.114543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlabeled data and multi-source data provide unprecedented opportunities for the financial industry to improve credit scoring accuracy. When utilizing unlabeled data, existing credit scoring methods often suffer from unreliability issues due to improper clustering or the introduction of noise when predicting labels. When utilizing multi-source data, existing credit scoring methods based on federated learning frameworks fail to tailor models for different data distributions of different data sources due to the limitations of relying on a single global model. Moreover, recent studies have explored the individual value of unlabeled data and multi-source data, but they often fail to utilize both. To address these issues, we propose UMDCS (Unlabeled and Multi-Source data Driven Credit Scoring), a self-supervised credit scoring method that utilizes both unlabeled and multi-source data simultaneously. To utilize unlabeled data, we propose a novel sample masking function to generate pseudo-labels for unlabeled data and pre-train the encoder using the pretext tasks. To utilize multi-source data, we employ a horizontal federated learning framework to aggregate local encoders into a global model while preserving data privacy. The global encoder is concatenated with personalized predictors to form personalized credit scoring models for each data source. Five experiments and statistical significance tests show that UMDCS outperforms other baseline methods.},
  archive      = {J_DSS},
  author       = {Yunhong Xu and Yitong Chen and Li Sun and Yu Chen},
  doi          = {10.1016/j.dss.2025.114543},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114543},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Corporate credit scoring method based on unlabeled data and multi-source data},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Being responsible or affable: Investigating the effects of AI error correction behaviors on user engagement. <em>DSS</em>, <em>198</em>, 114542. (<a href='https://doi.org/10.1016/j.dss.2025.114542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affable design is increasingly employed in AI conversational agents to foster smoother interaction and enhance user experience. However, a growing concern is that this overemphasis on social appeal often overlooks corrective interventions, particularly when users hold false or biased beliefs. Such omissions carry the risk of reinforcing user misconceptions and ultimately undermining the effectiveness of human–AI collaboration. Drawing upon the attribution theory, this study investigates whether the error-correction behavior of AI agents offset these risks and improve user engagement. Empirical evidence from three experimental studies verifies that AI agents' error-correction behavior indeed enhances users' perceived responsibility of AI agents and strengthens their engagement intentions. This effect does not appear to compromise social comfort, especially in the context where responsibility takes precedence, such as healthcare. This study further finds that the high expertise of AI agents amplifies the positive effects of error-correction behavior, while high entitativity diminishes these effects by blurring AI agents' responsibility. These findings offer important guidance for designing responsible AI agents and highlight the value of AI error-correction behaviors in human-AI interaction.},
  archive      = {J_DSS},
  author       = {Yunchang Zhu and Xianghua Lu},
  doi          = {10.1016/j.dss.2025.114542},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114542},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Being responsible or affable: Investigating the effects of AI error correction behaviors on user engagement},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-robo-advisor collaboration in decision-making: Evidence from a multiphase mixed methods experimental study. <em>DSS</em>, <em>198</em>, 114541. (<a href='https://doi.org/10.1016/j.dss.2025.114541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robo-advisors (RAs) are cost-effective, bias-resistant alternatives to human financial advisors, yet adoption remains limited. While prior research has examined user interactions with RAs, less is known about how individuals interpret RA roles and integrate their advice into decision-making. To address this gap, this study employs a multiphase mixed methods design integrating a behavioral experiment ( N = 334), thematic analysis, and follow-up quantitative testing. Findings suggest that people tend to rely on RAs, with reliance shaped by information about RA performance and the framing of advice as gains or losses. Thematic analysis reveals three RA roles in decision-making and four user types, each reflecting distinct patterns of advice integration. In addition, a 2 × 2 typology categorizes antecedents of acceptance into enablers and inhibitors at both the individual and algorithmic levels. By combining behavioral, interpretive, and confirmatory evidence, this study advances understanding of human–RA collaboration and provides actionable insights for designing more trustworthy and adaptive RA systems.},
  archive      = {J_DSS},
  author       = {Hasan Mahmud and Najmul Islam and Satish Krishnan},
  doi          = {10.1016/j.dss.2025.114541},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114541},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Human-robo-advisor collaboration in decision-making: Evidence from a multiphase mixed methods experimental study},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emotion aware session based news recommender systems. <em>DSS</em>, <em>198</em>, 114540. (<a href='https://doi.org/10.1016/j.dss.2025.114540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News recommender systems are decision support systems that exploit user-article interactions over a short duration of time to discover users’ interests and predict unseen news articles to generate a ranking of news articles that are relevant and interesting. In the news recommendation scenario, the relevance of articles decays quickly, and fresh articles are generated daily. Session based models are proposed using time-aware approaches to exploit interactions sequentially. Prior news recommender systems do not consider emotional information expressed in news articles within sessions for recommendations. Emotions play a key role in supporting decision-making and emotionally charged headlines can evoke curiosity or urgency, prompting users to click on certain articles. This paper presents an innovative decision support system for session based news recommendation, using expressed emotions from news articles, such as expressed in the title, abstract, and text, to improve user decision-making. We introduce a novel methodology that incorporates expressed emotions into three session based news recommendation models. Our results demonstrate that expressed emotion carries valuable information to improve session based news recommenders on various ranking metrics significantly and proved especially beneficial in scenarios with limited user interaction history, addressing the cold-start problem. The results show significant improvements in ranking metrics, emphasizing the utility of emotional features for dynamic decision-making support.},
  archive      = {J_DSS},
  author       = {Benjamin Gundersen and Saikishore Kalloori and Abhishek Srivastava},
  doi          = {10.1016/j.dss.2025.114540},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114540},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Emotion aware session based news recommender systems},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision support for integrated trade agent's procurement and sales planning under uncertainty. <em>DSS</em>, <em>198</em>, 114537. (<a href='https://doi.org/10.1016/j.dss.2025.114537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a trade agent decision optimization problem (TADOP), in which a trade agent (TA) selects a subset of retailers and suppliers to maximize its profit under uncertain demand and spot price. The TA operates between suppliers and retailers as a third-party platform and decide which subset of retailers to serve, taking into account capacity reservations with option suppliers in advance. Once demand and spot price are realized, the TA decides how much to procure from each channel to fulfill retailers' demand. The problem is formulated as a two-stage stochastic program. Due to the high complexity and large number of scenarios, we reformulate the problem as a set-partition model, where the master problem (MP) selects the combination of retailers to serve, and the subproblem (SP) identifies the optimal procurement plans, thus reducing the number of variables and constraints. To further enhance tractability, the SP is transformed into an equivalent shortest-path problem (SPP) to address issues of non-linearity and non-convexity. Experimental results demonstrate the effectiveness of the decomposition approach, providing TAs with a practical decision-making tool for procurement and sales. Furthermore, the insights gained into TAs' procurement and sales strategies across various scenarios offer valuable guidance for decision-making in uncertain supply chain environments.},
  archive      = {J_DSS},
  author       = {An Liu and Xinyu Wang and Jiafu Tang},
  doi          = {10.1016/j.dss.2025.114537},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114537},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Decision support for integrated trade agent's procurement and sales planning under uncertainty},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling hybrid firm relationships with graph neural networks for stock investment decisions. <em>DSS</em>, <em>198</em>, 114528. (<a href='https://doi.org/10.1016/j.dss.2025.114528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The highly volatile nature of the stock market makes predicting data patterns challenging. Significant efforts have been dedicated to modeling complex stock correlations to improve stock return forecasting and support better investor decision-making. Although various predefined intrinsic associations and learned implicit graph structures have been discovered, they have limitations in fully exploring and leveraging both types of graph information. In this paper, we proposed a Hybrid Structure-aware Graph Neural Network (HSGNN) framework. Unlike models that rely solely on predefined or learned graphs, HSGNN utilizes money-flow graphs to complementarily learn implicit graph structures and applies sparse supply-chain graphs to jointly enhance stock return forecasting. Extensive experiments on real stock benchmarks demonstrate our proposed HSGNN outperforms various state-of-the-art forecasting methods, offering a robust decision-support system for financial stakeholders.},
  archive      = {J_DSS},
  author       = {Yang Du and Biao Li and Zhichen Lu and Gang Kou},
  doi          = {10.1016/j.dss.2025.114528},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114528},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Modeling hybrid firm relationships with graph neural networks for stock investment decisions},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social capital matters: Towards comprehensive user preference for product recommendation with deep learning. <em>DSS</em>, <em>198</em>, 114527. (<a href='https://doi.org/10.1016/j.dss.2025.114527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommender systems help address data sparsity in user–product interactions by leveraging social relationships to infer user preferences. However, existing models often overlook the role of social capital that influence decision-making in social commerce. Social capital consists of structural, relational, and cognitive dimensions, all of which shape user preferences. To better understand these influences, we propose a multi-task learning framework named DeepSC that integrates social capital theory into preference modeling. Its user preference learning module extracts structural features through graph-based pre-training, learns relational features from dynamic user embeddings, and models cognitive features using a hypergraph attention network. Additionally, the dual graph-based product feature learning module enhances cognitive feature extraction by incorporating product co-interactions. DeepSC is optimized through a joint learning objective, combining point-wise and pair-wise learning with an auxiliary social link prediction task to refine user representations. Experiments on three e-commerce datasets demonstrate that DeepSC significantly outperforms the state-of-the-art recommendation models, highlighting the effectiveness of integrating social capital into social preference learning. Our research advances social recommendation by providing a social capital theory-driven approach to modeling user behavior in digital commerce.},
  archive      = {J_DSS},
  author       = {Weiyue Li and Ming Gao and Bowei Chen and Jingmin An and Yeming Gong},
  doi          = {10.1016/j.dss.2025.114527},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114527},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Social capital matters: Towards comprehensive user preference for product recommendation with deep learning},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cybersecurity risk assessment using temporal knowledge graph-based explainable decision support system. <em>DSS</em>, <em>198</em>, 114526. (<a href='https://doi.org/10.1016/j.dss.2025.114526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing cybersecurity policies is crucial for any organization to combat evolving cyber threats. The absence of a comprehensive dataset has prevented previous studies from analyzing the risk of organizations’ cybersecurity policies. Past studies have not considered temporal information in the policies. Analysis of cybersecurity policies using attention mechanism requires automated determination of optimal number of attention units which remains unaddressed. Moreover, absence of interpretation in cybersecurity studies creates a barrier to understanding policy vulnerabilities and developing targeted solutions. To address these challenges, we develop a decision support system which (i) enhances risk classification of organization’s cybersecurity policies, (ii) develops a comprehensive cybersecurity policy dataset from the websites of 190 companies, transformed into a knowledge graph to capture entity relationships among various policies, (iii) integrates temporal information into the knowledge graph by incorporating time stamps from event sequences in cyberattack information, (iv) develops Explainable Factor Analysis based Multi-Head Attention mechanism, which automates the determination of the optimal number of attention units and optimizes data allocation across attention units using factor analysis, and (v) utilizes attention heatmaps and shapley values for interpretability. Our cybersecurity policy dataset is used as a case study with four benchmark datasets for further validation. Results reveal that our model outperforms the other state-of-the-art, achieving an 87.78% F 1 score, followed by robustness checking and statistical significance testing. Finally, Shapley values are used to interpret the model’s output to identify vulnerabilities within the organizational policies, providing crucial insights enabling decision-makers to enhance their cybersecurity policies and mitigate potential threats.},
  archive      = {J_DSS},
  author       = {Subhajit Bag and Sobhan Sarkar and Indranil Bose},
  doi          = {10.1016/j.dss.2025.114526},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114526},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Enhancing cybersecurity risk assessment using temporal knowledge graph-based explainable decision support system},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A field study on the impact of the counter ad-blocking wall strategy on user engagement. <em>DSS</em>, <em>198</em>, 114525. (<a href='https://doi.org/10.1016/j.dss.2025.114525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ad-blocking tools prevent ads from being shown to web users. Their increasingly widespread usage poses an existential risk to online publishers who provide free content and rely on display ads for revenue. Studies on counter ad-blocking strategies taken by publishers are limited, especially with regard to how these strategies affect user engagement, thus posing additional uncertainties to the selection of a suitable counter ad-blocking strategy. Through a randomized field experiment with a large global publisher, our study seeks to understand how the two most common counter ad-blocking strategies, (i) Wall and (ii) Acceptable Ads Exchange (AAX), affect user engagement differently. Our results show that the Wall strategy causes a lower overall engagement compared to AAX, mainly due to users who refuse to whitelist and leave the website. Over time, the negative impact increases, albeit at a slower speed. Furthermore, heavier users, identified based on the amount of engagement in the pre-treatment period, are less affected by the Wall strategy than lighter users; instrumental users, who read for practical purposes, are less affected than entertainment users. Finally, the Wall strategy has a bigger negative impact on the engagement of popular and new articles, compared to niche and old articles, respectively, as observed by a longer tail in engagement distribution with respect to content. These results on the heterogeneous effects of counter ad-blocking strategies on engagement offer novel and important managerial implications on a publisher’s choice of counter ad-blocking strategy and editorial decisions.},
  archive      = {J_DSS},
  author       = {Michael K. Chen and Shuai Zhao and Cristian Borcea and Yi Chen},
  doi          = {10.1016/j.dss.2025.114525},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114525},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A field study on the impact of the counter ad-blocking wall strategy on user engagement},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-platform rumor detection framework considering data privacy protection and different detection capabilities of online social platforms. <em>DSS</em>, <em>198</em>, 114524. (<a href='https://doi.org/10.1016/j.dss.2025.114524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anonymity and widespread popularity of online social platforms (OSPs) allow users to share uncertain posts freely, leading to numerous rumors. Similar rumors spread widely across OSPs, resulting in frequent cross-platform rumors (CPRs). Owing to the unique nature of the cross-platform spread, the dual challenges of data privacy protection constraints and differences in the data and detection capabilities of OSPs exacerbate the difficulty of CPR detection. Thus, to detect CPRs effectively, we designed and implemented a novel deep learning framework named Cross Platform Rumor Detection based on Improved Federated Learning (CPRDIFL), which integrates and improves federated learning and the pre-trained Masked and Contextualized BERT (MacBERT). Our framework uses FL to analyze data from OSPs independently, thus avoiding the need for data integration and ensuring the data privacy protection of OSPs. Moreover, MacBERT is deployed on the clients of CPRDIFL to extract contextual features from posts and dynamically update local weights based on the data and detection performance. Weight parameters are dynamically shared between clients and servers and between clients to achieve complementary advantages across OSPs. Our framework was used in six comprehensive experiments in different scenarios, and the experimental results showed that it achieved the best results in CPR detection. This study not only provides an effective solution for CPR detection but also marks a significant step toward the automated detection of cross-OSP information pollution.},
  archive      = {J_DSS},
  author       = {Xuelong Chen and Jinchao Pan},
  doi          = {10.1016/j.dss.2025.114524},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114524},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A cross-platform rumor detection framework considering data privacy protection and different detection capabilities of online social platforms},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="eaai">EAAI - 200</h2>
<ul>
<li><details>
<summary>
(2025). Driver risk classification for transportation safety: A machine learning approach using psychological, physiological, and demographic factors with driving simulator. <em>EAAI</em>, <em>162</em>, 112585. (<a href='https://doi.org/10.1016/j.engappai.2025.112585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving behavior is a critical factor in ensuring road safety, particularly in commercial transportation sectors where hiring safe and reliable drivers is a priority. This study presents a machine learning-based framework for predicting driver behavior using multimodal assessments, including psychological, physiological, and demographic factors. We utilized a driving simulator equipped with biometric sensors to capture the physiological data of the driver, including heart rate, eye blink rate, pupil diameter, and point of gaze (POG), during driving sessions. The psychological attributes are collected through a self-report questionnaire. The questionnaire is structured to obtain information about nine psychological characteristics of the driver, including instrumental attitude, social anxiety, sensation seeking, premeditation, urgency, selfishness, aggressive mode, life satisfaction, and conscientiousness. In addition, some demographic attributes, such as age and gender, are also adopted to study their effect on driving behavior. Experiments were conducted on 80 participants, each driving for 10 min. Various machine learning models, along with a feature selection strategy, were used to find the relationship between the driver's modalities and his driving behavior. Results demonstrate that the k-nearest neighbors (KNN) model achieved the best performance, yielding an accuracy of 93.75 % and a False Negative Rate (FNR) of 0. Feature importance analysis revealed that gaze distraction, sensation seeking, conscientiousness, and gender are the best predictors of driving behavior. The findings suggest that our model can serve as a valuable decision-support tool for taxi companies and transportation agencies aiming to enhance driver selection processes by identifying drivers with lower accident risks.},
  archive      = {J_EAAI},
  author       = {Malek Masmoudi and Yasmin Shakrouf and Omar Hassan Omar and Amir Shikhli and Fatima Abdalla and Wadad Alketbi and Imad Alsyouf and Ali Cheaitou and Anwar Jarndal and Ali I. Siam},
  doi          = {10.1016/j.engappai.2025.112585},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112585},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Driver risk classification for transportation safety: A machine learning approach using psychological, physiological, and demographic factors with driving simulator},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based pre-compensator design for piezoelectric actuators based on physics guided neural network and physics-precision balanced training. <em>EAAI</em>, <em>162</em>, 112576. (<a href='https://doi.org/10.1016/j.engappai.2025.112576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing model-based pre-compensators is crucial for achieving high-precision motion control in piezoelectric actuators (PEAs), which exhibit complex nonlinear behaviors. While data-based modeling methods offer a straightforward approach, they face challenges with poor extrapolation and high complexity. Incorporating the known physics of PEAs, which is more consistent with physical principles and computationally efficient, can help overcome these limitations. Based on the above knowledge, this paper embeds physical knowledge within a neural network, forming a novel Physics Guided Neural Network (PGNN) structure as a model-based PEA pre-compensator to achieve high motion precision. Training the PGNN is challenging due to potential competition between the physics component and the neural network. The flexible nature of the neural network can easily overshadow the physical information, leading to overfitting and rendering the PGNN model ineffective. To address this, a Physics-Precision Balanced Training (PPBT) method is proposed. In the PPBT method, the physical correctness and model precision of the PGNN are mathematically defined, and these two components are balanced through a nonlinear function within the training algorithm. Experimental results show that the proposed pre-compensator based on PGNN and PPBT outperforms physics-based approaches in precision and offers greater robustness than purely data-based methods. The peak-to-peak displacement error is reduced to less than 35 nm in open-loop control. Measured by Mean Absolute Error (MAE), this method reduces displacement errors by 89 % compared to no compensation, by 77 % compared to purely neural network-based compensation, and by 73 % compared to rate-dependent Prandtl-Ishlinskii operator-based compensation.},
  archive      = {J_EAAI},
  author       = {Qin Li and Zhiwei Ruan and Chenyang Ding},
  doi          = {10.1016/j.engappai.2025.112576},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112576},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model-based pre-compensator design for piezoelectric actuators based on physics guided neural network and physics-precision balanced training},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end burst signal demodulation via adaptive masked deep learning framework. <em>EAAI</em>, <em>162</em>, 112569. (<a href='https://doi.org/10.1016/j.engappai.2025.112569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bit error rate (BER) directly determines the quality of wireless communication transmission. Traditional demodulators are limited in operating on burst signals and exhibit poor BER performance in low signal-to-noise ratio (SNR) conditions. For real-world burst signals, symbol-by-symbol approaches fail to capture inter-symbol dependencies, and existing end-to-end frameworks cannot handle the variable output lengths required for burst signals. To address this issue, we propose an end-to-end demodulation framework based on deep learning (DL), in which detection, recognition, channel compensation, and demodulation stages were trained as a unified system, enabling the entire signal burst to be demodulated in a single operation during inference. The framework's generalization and robustness are enhanced by a proposed masking mechanism and a denoising autoencoder (DAE), respectively. The former dynamically adjusts the output bitstream length while preventing gradient flow from redundant components, and the latter compensates for channel fading effects. We further introduce a dedicated end-to-end training strategy to optimize the adaptation between these modules. Experimental results on real-world Frequency Shift Keying (FSK), Minimum Shift Keying (MSK), Phase-Shift Keying (PSK), and Quadrature Amplitude Modulation (QAM) signals demonstrate that the proposed framework achieves superior demodulation accuracy for long-sequence burst signals. Compared to existing methods, the proposed framework enables parallel demodulation, and dynamically adapts the output bit stream in terms of varying message types and lengths.},
  archive      = {J_EAAI},
  author       = {Mingdi Li and Wenzhe Fan and Yanbin Li and Chunlei Xie and Yanan Duan},
  doi          = {10.1016/j.engappai.2025.112569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {End-to-end burst signal demodulation via adaptive masked deep learning framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties prediction of bi-metal foam sandwiches using machine learning methods and elastic deformation behaviour. <em>EAAI</em>, <em>162</em>, 112560. (<a href='https://doi.org/10.1016/j.engappai.2025.112560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal foam sandwiches are a kind of ultra-lightweight material made from a porous metal core bonded to two face sheets. Friction stir welding (FSW) is utilised in welding bimetal foam sandwiches. It is worth mentioning that the exact relation between mechanical properties and process parameters is challenging to determine. The innovation lies in the non-destructive estimation of mechanical properties (Young's modulus, ultimate tensile strength and fracture strain) through elastic deformation data and the novel application of artificial intelligence techniques optimised by genetic algorithms, eliminating dependency on input process parameters. After proper network training, three methods are employed to estimate these mechanical properties: a decision tree, a feedforward neural network and long-short term memory. These are chosen to investigate the influence of both machine/deep learning methods in predicting the mechanical properties of the FSW final product. Moreover, a genetic algorithm is employed to find the optimal hyperparameters of the three investigated prediction models to reach the highest accuracy. The results prove the efficiency of the proposed feedforward neural network in the estimation of Young's modulus and ultimate tensile strength for the bi-metal foam sandwiches with lower mean absolute error (MAE) and higher correlation coefficient compared to the decision tree (63.9 % lower MAE and 25.50 % higher correlation coefficient) and long-short term memory (77.50 % lower MAE and 25.05 % higher correlation coefficient). In addition, the proposed decision tree model accurately predicts the fracture strain with R-square and root mean square error as 0.61429 and 1.3862 × 10 −5 , respectively.},
  archive      = {J_EAAI},
  author       = {Mohammad Reza Chalak Qazani and Mohsen Dorudgar and Mehdi Moayyedian and Abdel-Hamid I. Mourad and Moosa Sajed and S.M. Hossein Seyedkashi and Siamak Pedrammehr},
  doi          = {10.1016/j.engappai.2025.112560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mechanical properties prediction of bi-metal foam sandwiches using machine learning methods and elastic deformation behaviour},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal unified generalization and translation network for intelligent fault diagnosis under dynamic environments. <em>EAAI</em>, <em>162</em>, 112559. (<a href='https://doi.org/10.1016/j.engappai.2025.112559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal data fusion can generate reliable fault representations for intelligent fault diagnosis. However, simple data fusion strategies often introduce fault-irrelevant information, thereby reducing robustness against unknown domain shifts. Moreover, traditional methods generally lack adaptive mechanisms to address missing modalities, leading to considerable performance degradation under sensor failure conditions. To address these problems, this paper proposes a multimodal unified generalization and translation network. To learn invariant unified representations for resisting unknown data distribution shifts, information-enhanced concatenation first generates intra-domain and cross-domain representations. Subsequently, mutual information maximization is applied to remove fault-unrelated information from these representations. Finally, A hybrid ensemble diagnosis strategy fully leverages the interaction of multimodal information across different levels. In addition, semantic supervision investigates the relationships among different modalities and enables intermodal translation in the event of a sensor failure within the monitoring system. Extensive experimental results based on a public bearing dataset and a self-collected motor dataset indicate that the proposed method improves accuracy by 10.53 % and 8.47 % compared to the state-of-the-art methods, respectively. The code and datasets are available at https://github.com/CHAOZHAO-1/MUGTN .},
  archive      = {J_EAAI},
  author       = {Chao Zhao and Weiming Shen and Enrico Zio and Hui Ma},
  doi          = {10.1016/j.engappai.2025.112559},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112559},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal unified generalization and translation network for intelligent fault diagnosis under dynamic environments},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FabricMamba: A fabric surface defect detection system based on large kernel attention and visual state space. <em>EAAI</em>, <em>162</em>, 112558. (<a href='https://doi.org/10.1016/j.engappai.2025.112558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the textile manufacturing industry, fabric defect detection is essential for ensuring product quality. Traditional approaches based on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) often encounter scalability issues, particularly due to the high computational complexity of the self-attention mechanism in ViTs. To address these limitations, this study introduces FabricMamba, a real-time defect detection framework built on the You Only Look Once version 8 (YOLOv8) CNN architecture. The model enhances detection precision and efficiency for complex fabric defects in high-resolution images while minimizing computational cost. YOLOv8 was selected as the base model due to its strong balance between accuracy and inference speed, which is critical in fast-paced textile production settings. FabricMamba extends YOLOv8 with several innovations: the Parallel Large Separable Kernel Attention (P-LSKA) mechanism for multi-scale perception, the Visual State Space Module (MVSS) for long-range dependency modeling, the lightweight DySample module for reduced resource usage, and Programmable Gradient Information (PGI) to optimize training without increasing inference complexity. Extensive evaluations were conducted using a proprietary industrial fabric defect dataset and two public benchmarks, TILDA Textile Texture Database and FDDS Object Detection Dataset. FabricMamba achieved a mean Average Precision (mAP) of 90.0 %, 97.7 %, and 39.1 % on the respective datasets, outperforming the YOLOv8 baseline by 1.8 %, 2.3 %, and 2.0 %. Compared to Mamba-YOLO, FabricMamba reduced model size and computational requirements by 36.7 % and 33.1 %, respectively, with recall improving by 2.9 %, 1.4 %, and 4.0 %. These results confirm the model effectiveness and practical potential for industrial fabric inspection tasks.},
  archive      = {J_EAAI},
  author       = {Nengsheng Bao and Jiajun Lin and Yuchen Fan and Runxuan Bao and Alessandro Simeone},
  doi          = {10.1016/j.engappai.2025.112558},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112558},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FabricMamba: A fabric surface defect detection system based on large kernel attention and visual state space},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing performance metrics with new distance and similarity measures using control parameters of linear diophantine fuzzy sets. <em>EAAI</em>, <em>162</em>, 112557. (<a href='https://doi.org/10.1016/j.engappai.2025.112557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control parameters (CPs) of linear Diophantine fuzzy sets (LDFSs) provide an innovative approach for information analysis in the multi-criteria decision making (MCDM), machine learning (ML), and computational intelligence (CI). The CPs give freedom to the decision-makers in evaluating feasible alternatives in measuring performance metrics. Previous fuzzy MCDM methods often meet strict limitations in handling real-world uncertainty and dynamic MCDM. To overcome these limitations, this study extends the Preference Ranking Organization Method for Enrichment of Evaluations (PROMETHEE-II) method to linear Diophantine fuzzy sets (LDFSs) for more flexible and robust MCDM approach. The proposed MCDM approach primarily evaluates performance metrics criterion, utilizing LDFSs which are robust extension of fuzzy sets (FSs), intuitionistic fuzzy sets (IFSs) as well as interval-valued intuitionistic fuzzy sets (IVIFSs). It helps decision makers to address uncertain information with membership degree (MD), non-membership degree (NMD), and CPs. For this objective, new LDFS based distance measures (DMs) and similarity measures (SMs) are developed for the construction of LDFS PROMETHEE-II technique. The proposed MCDM approach provides a structured and comprehensive framework for optimizing investment performance metrics. Its robustness is validated through sensitivity and comparative analyses.},
  archive      = {J_EAAI},
  author       = {Masooma Raza Hashmi and Muhammad Riaz and Arshid Mahmood and Muhammad Ajmaeen and Muhammad Aslam},
  doi          = {10.1016/j.engappai.2025.112557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing performance metrics with new distance and similarity measures using control parameters of linear diophantine fuzzy sets},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic capsule network-based physical alert monitoring system for elderly people with disabilities. <em>EAAI</em>, <em>162</em>, 112556. (<a href='https://doi.org/10.1016/j.engappai.2025.112556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elderly disabled people have higher health risks due to reduced mobility, delayed emergency response, and poor real-time monitoring. Existing Internet of Things (IoT) based monitoring systems frequently have static thresholds, lack personalization, and struggle to capture complex physical and physiological fluctuations, resulting in false alerts and reduced reliability. We propose a Dynamic Capsule Network-Based Physical Alert Monitoring System (DyCN-PAM) for intelligent, real-time monitoring of elderly disabled people to overcome these constraints. Compiling accelerometer, gyroscope, and heart rate readings, and utilizing capsule routing to preserve spatiotemporal hierarchies, enables the system to detect falls, seizures, and fainting. Context-aware alerts utilize capsule confidence and heart rate baselines to distinguish between typical changes and catastrophic emergencies. The DyCN-PAM system outperforms benchmark models in terms of accuracy and robustness, achieving a 5.13 % increase in F1-score, a 28.6 % increase in precision, a 45.1 % reduction in false alarms, and a 26.3 % improvement in computational efficiency. The DyCN-PAM system enhances accuracy, precision, and efficiency, making it feasible to improve safety, independence, and quality of life for older individuals with disabilities. More real-world experiments are needed to prove its use.},
  archive      = {J_EAAI},
  author       = {Shujuan Feng and Hongying Zhu and Yangkai Wu and Ziheng Zeng and Ezzeddine Touti and Jinming Wang and Amar Jain},
  doi          = {10.1016/j.engappai.2025.112556},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112556},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic capsule network-based physical alert monitoring system for elderly people with disabilities},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning driven prediction of dynamic stress-strain response in limestone: Insights into transient mechanical behavior under complex loadings for shield tunneling. <em>EAAI</em>, <em>162</em>, 112554. (<a href='https://doi.org/10.1016/j.engappai.2025.112554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex geological conditions pose a serious challenge to improving the rock-breaking efficiency of shield cutter machines in subway tunnel constructions. This study develops a three-axis thermal-hydraulic-mechanical (THM) coupled dynamic impact system, which is integrated with a scaled shield cutter model to generate a unique dataset of stress wave propagation under multi-field coupling. A bidirectional long short-term memory (LSTM) neural network with an attention mechanism is proposed to establish a nonlinear time mapping relationship between stress waves. The determination coefficient ( R 2 ) exceeds 0.97, the symmetric mean absolute percentage error ( sMAPE ) is less than 10 %, and the average relative uncertainty ( ARU ) is less than 4 %, confirming its high accuracy and reliability. Based on predictions and test results, the new quantitative laws for the transient dynamics of limestone are further revealed. The results reveal that loading conditions do not alter the correlation trend between loading rate and dynamic parameters but significantly influence the degree of the loading rate's effect. Axial pressure dominates energy absorption with an energy contribution rate of 60 %. Confining pressure amplified the sensitivity of loading rate by 170 %, while THM coupling suppressed the dynamic deformation modulus by over 30 %. The accurate prediction of the nonlinear response of stress waves in limestone by the LSTM neural network establishes the connection between transient dynamic observation and rock fragmentation physics mechanism, providing support for quantifying energy absorption and conversion in the rock fragmentation process, and providing key strategies for optimizing shield machine performance in extreme environments.},
  archive      = {J_EAAI},
  author       = {Baoping Zou and Kejian Xia and Jingyuan Ma and Xu Long},
  doi          = {10.1016/j.engappai.2025.112554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning driven prediction of dynamic stress-strain response in limestone: Insights into transient mechanical behavior under complex loadings for shield tunneling},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-tuning hierarchical vehicle trajectory tracking framework based on improved kinematic model predictive control. <em>EAAI</em>, <em>162</em>, 112551. (<a href='https://doi.org/10.1016/j.engappai.2025.112551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory tracking is crucial in vehicle control, as it ensures stable driving along a predefined path. This paper proposes a deep reinforcement learning (DRL)-tuning hierarchical trajectory tracking framework, aiming to improve the tracking accuracy of traditional kinematic model predictive control (MPC) methods in uncertain environments. The proposed hierarchical vehicle trajectory tracking framework consists of two layers: the upper layer serves as a compensation layer for the vehicle side-slip angle (VSA), designed using bidirectional long short-term memory (BiLSTM); while the lower layer is the trajectory tracking layer, in which the improved kinematic MPC is enhanced by integrating the twin delayed deep deterministic policy gradient (TD3) algorithm with an external attention (EA) mechanism. The contribution in artificial intelligence is improving the TD3 algorithm with the EA mechanism, enhancing its ability to capture contextual information and improve adaptability. The contribution in engineering applications is implementing the EA-TD3-tuned hierarchical kinematic MPC framework in the field of vehicle trajectory tracking. With 95 % confidence, compared to traditional kinematic MPC controller, the proposed hierarchical vehicle trajectory tracking framework reduces the average lateral error by 33 % (confidence interval, CI: [0.0616, 0.0850]), the average heading angle error by 34 % (CI: [0.01173, 0.0157]), the average yaw rate variation by 31 % (CI: [0.0244, 0.0346]), and the average front wheel steering angle variation by 28 % (CI: [0.0244, 0.0346]).},
  archive      = {J_EAAI},
  author       = {Jiankun Peng and Xingyan Liu and Changcheng Wu and Dawei Pi and Jiaxuan Zhou},
  doi          = {10.1016/j.engappai.2025.112551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-tuning hierarchical vehicle trajectory tracking framework based on improved kinematic model predictive control},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel decomposition-prediction hybrid model improved by dual-channel cross-attention mechanism for short-term wind speed prediction. <em>EAAI</em>, <em>162</em>, 112550. (<a href='https://doi.org/10.1016/j.engappai.2025.112550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of wind energy is crucial for ensuring the safe operation and stability of power systems. To improve the accuracy and robustness of wind speed (WS) forecasting, a novel hybrid method based on mixture of experts (MoE), Transformer, temporal convolution network (TCN), multi-head attention (MA) mechanism, and improved by dual-channel cross-attention mechanism (DCCAM) is proposed. The wind speed data is decomposed by MoE into seasonal and trend components. The trend features are directly captured through a multi-head attention mechanism. An innovative Transformer-TCN framework associated with DCCAM is designed to handle the seasonal component, wherein the Transformer-TCN can make full use of long dependency modeling of Transformer and the local feature extraction of TCN, and DCCAM enables the information interchange and feature fusion, therefore realizing complementary advantages. Based on the proposed model, a series of experiments are conducted on multiple datasets. Ablation experiments confirm the effectiveness of the model and the role of each module in performance improvement. Experiments on seasonal datasets, including spring, summer, autumn, and winter, show that the proposed model can effectively adapt to variations in amplitude and volatility of wind speed sequences under different climatic conditions. Comparative experiments with six advanced hybrid models including decomposition and prediction modules, further demonstrate the superiority and stability of the proposed model.},
  archive      = {J_EAAI},
  author       = {Donghan Geng and Haiteng Cui and Leisen Lv and Jiamin Guo},
  doi          = {10.1016/j.engappai.2025.112550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel decomposition-prediction hybrid model improved by dual-channel cross-attention mechanism for short-term wind speed prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A digital twin-assisted algorithm for diagnosis of permanent magnet synchronous generator interturn short circuit fault and converter open circuit fault in wind power systems using pearson correlation coefficient. <em>EAAI</em>, <em>162</em>, 112547. (<a href='https://doi.org/10.1016/j.engappai.2025.112547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interturn short-circuit faults (ISCFs) in permanent magnet synchronous generators (PMSGs) and open-circuit faults (OCFs) in the machine-side converters represent two critical reliability challenges in wind power systems. Conventional fault diagnosis approaches typically rely on dedicated models for each fault type for each fault type, leading to excessive system complexity and suboptimal computational efficiency. To overcome these limitations, this paper proposes a novel unified digital twin-assisted framework capable of simultaneous diagnosis of both PMSG ISCFs and converter OCFs within a single integrated architecture. The high-fidelity digital twin model based on one-dimensional convolutional neural networks is established to generate real-time reference value of current space vector (SV) for online fault detection, while Pearson correlation coefficient analysis enables accurate differentiation between ISCF and OCF. For ISCFs, the fault severity assessment is performed based on the deviation between reference and measured current SV, with the faulty phase identified using phase current root mean square (RMS) values. In the case of converter OCFs, the proposed method introduces a dual-stage identification process: single and dual insulated-gate bipolar transistor (IGBT) open faults are differentiated through severity estimation analysis, and the faulty IGBT is identified by evaluating the effective current interval ratio (ECIR) and normalized current average (NCA). The experimental results validate the effectiveness of the proposed method, and comparative analysis further demonstrates its superior performance in terms of parameter dependency and diagnostic efficacy.},
  archive      = {J_EAAI},
  author       = {Bin Sun and Ying Zhu and Zhinong Wei},
  doi          = {10.1016/j.engappai.2025.112547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A digital twin-assisted algorithm for diagnosis of permanent magnet synchronous generator interturn short circuit fault and converter open circuit fault in wind power systems using pearson correlation coefficient},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal multi-scale fusion network for leak detection in marine piping systems. <em>EAAI</em>, <em>162</em>, 112545. (<a href='https://doi.org/10.1016/j.engappai.2025.112545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine system monitoring data inherently exhibit multimodal characteristics, making artificial intelligence-driven correlation and fusion essential for improving fault feature recognition. However, existing intelligent diagnosis methods mostly focus on feature fusion within homogeneous data types, such as fusing multiple time-series signals or multiple image sets, while systematic exploration of joint representation learning across heterogeneous dimensions remains under-explored. This limitation constrains the recognition capability for complex failure modes. Meanwhile, the inherent differences in physical meanings and representations of multimodal data pose significant challenges in constructing effective correlations, often limiting the performance of mainstream machine learning based fault diagnosis approaches. The proposed method enhances the fault diagnosis capability of mainstream approaches through the fusion of multi-sensor data and visual data, with its core innovation residing in a multimodal fusion framework leveraging attention mechanisms to effectively integrate cross-dimensional representations of multivariate time-series data and imaging data. Compared to existing multimodal transformer techniques, this dual-strategy architecture enables the model to simultaneously capture shared systemic behaviors and modality-unique signatures, substantially elevating diagnosis precision. Experimental validation on real-world leak detection datasets demonstrates that the proposed model achieves F1-scores consistently surpassing 90 % across diverse marine monitoring scenarios, with quantitative evaluations further confirming its superior performance over conventional multivariate time-series diagnosis methods in establishing multimodal correlations, conclusively validating both technical excellence and engineering practicability.},
  archive      = {J_EAAI},
  author       = {Peng Zhang and Chaozhe Li and Shitao Peng and Bomu Tian and Si Luo and Yuewen Zhang and Taili Du},
  doi          = {10.1016/j.engappai.2025.112545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multimodal multi-scale fusion network for leak detection in marine piping systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified rotating machinery health management framework leveraging large language models for diverse components, conditions, and tasks. <em>EAAI</em>, <em>162</em>, 112544. (<a href='https://doi.org/10.1016/j.engappai.2025.112544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Rotating Machinery Large Language Model (RotLLM), a unified framework for rotating machinery health management that integrates deep learning with large language models (LLMs) to address diverse operational conditions, components, and health management tasks. RotLLM employs a novel Spectral Folding Network (SFN) to transform vibration spectrum into a unified feature space that preserves essential health state information. A dedicated projection layer then maps these features into the semantic domain of an LLM. The framework is trained using a three-stage strategy: first, pre-training the encoder on the Large-scale Multimodal Rotating Machinery (LMR) dataset, which comprises 237,298 vibration samples collected under hundreds of operating conditions; second, initializing the projection layer with textual health state labels; and finally, fine-tuning using parameter-efficient Low-Rank Adaptation (LoRA) with high-quality corpus for various health management tasks. Experimental evaluations demonstrate that RotLLM achieves state-of-the-art performance in fault classification, maintains strong robustness under noisy conditions, and delivers rapid multi-task inference with minimal computational overhead. The framework consistently outperforms conventional methods, enabling efficient, accurate, and context-aware health management for rotating machinery across diverse conditions and tasks. The dataset and source code are open-sourced ( https://github.com/SIA-IDE/RotLLM ), fostering collaboration, reproducibility, and broader adoption in industrial prognostics research.},
  archive      = {J_EAAI},
  author       = {Haotian Peng and Jie Gao and Jiawei Liu and Jinsong Du and Wei Wang},
  doi          = {10.1016/j.engappai.2025.112544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A unified rotating machinery health management framework leveraging large language models for diverse components, conditions, and tasks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-source heterogeneous data fusion based fault diagnosis framework for manufacturing processes. <em>EAAI</em>, <em>162</em>, 112542. (<a href='https://doi.org/10.1016/j.engappai.2025.112542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis technologies are important means to ensure the production operation safety and product quality stability for manufacturing processes. After a fault occurs in the manufacturing processes, it may be characterized by high-frequency and high-dimensional structured time series data anomalies such as sensor data, or by unstructured data anomalies such as images. Traditionally, single structured sensor data is often used for constructing diagnosis models, the fault characteristics may not be adequately characterized, thus affecting the diagnosis performance. Therefore, in this paper, in order to make full use of multi-source data and obtain more comprehensive and accurate diagnosis results, a new multi-source heterogeneous data fusion based fault diagnosis framework is designed for manufacturing processes. Specifically, to solve the problem that the important information is ignored during data level fusion of multi-source data, an adaptive weight multi-source data fusion method is proposed. Furthermore, in response to the problem of feature redundancy in feature level fusion of heterogeneous data, a feature differentiation extraction and heterogeneous feature fusion method is proposed, of which a feature source discriminator is constructed for enhancing the complementarity of the extracted heterogeneous features, and feature concatenation is performed to improve the feature expression ability. Finally, the effectiveness and feasibility of the proposed framework is verified on actual datasets from the hot rolling process and the Tennessee Eastman process. Experimental results show that the proposed framework is both effective and feasible in fault diagnosis with multi-source heterogeneous data.},
  archive      = {J_EAAI},
  author       = {Liang Ma and Qikai Yang and Orestes Llanes-Santiago and Kaixiang Peng},
  doi          = {10.1016/j.engappai.2025.112542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multi-source heterogeneous data fusion based fault diagnosis framework for manufacturing processes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing modal differences in zero-shot anomaly detection based on vision-language generation model. <em>EAAI</em>, <em>162</em>, 112541. (<a href='https://doi.org/10.1016/j.engappai.2025.112541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot anomaly detection methods based on vision-language model rely on alignment between image and text. These methods ignore the inherent differences between different modalities, which is unfavorable for improving the alignment between modalities. This paper reduces modal differences between image and text by using guiding vision feature and text feature from the pre-trained vision-language generation model. The vision perception text embedding is constructed by adding guiding vision feature to the weight shared text prompt. The text perception vision embedding is extracted by a vision text fusion module. The fusion module is designed to promote the visual modality to perceive the textual information locally. Anomaly regions are detected by cosine similarity between cross-modal perception embeddings. Zero-shot anomaly detection performance is evaluated on five publicly available industrial anomaly detection datasets, and a real-world dataset about automotive plastic parts. Experimental results show that the proposed method achieves highly competitive anomaly detection performance on multiple evaluation metrics.},
  archive      = {J_EAAI},
  author       = {Yanan Song and Weiming Shen and Baisong Pan and Quanhui Wu and Dawei Gu},
  doi          = {10.1016/j.engappai.2025.112541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reducing modal differences in zero-shot anomaly detection based on vision-language generation model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel short-term prediction method for distributed photovoltaic power generation considering extreme weather. <em>EAAI</em>, <em>162</em>, 112540. (<a href='https://doi.org/10.1016/j.engappai.2025.112540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed photovoltaic power plants are often impacted by various factors such as weather conditions and geographical locations, making it challenging to fully capture the spatial correlation characteristics among multiple photovoltaic plants. Furthermore, the failure to consider meteorological factors that influence photovoltaic output results in larger prediction errors during extreme weather events. To reduce prediction errors, this paper proposes a short-term photovoltaic forecasting method that considers meteorological factors, explores spatial correlations among photovoltaic plants, and captures temporal characteristics. Firstly, a Graph Attention Network is established to obtain spatial correlations between different plants while a Convolutional Neural Network is employed to extract feature information of meteorological factors. Then, the feature information from these two sources is integrated and input into a Long Short-Term Memory network, which is enhanced based on Spiking Neural P Systems to extract temporal characteristics of photovoltaic output and complete the prediction task. Finally, real-world power station datasets are utilized for validation and comparison with several typical photovoltaic prediction models. The results clearly show that the application of artificial intelligence in this proposed method can effectively improve the accuracy of distributed photovoltaic power forecasting, demonstrating the great potential of AI in the field of photovoltaic power prediction.},
  archive      = {J_EAAI},
  author       = {Xin Guan and Xiao Han and Jun Wang and Tao Wang},
  doi          = {10.1016/j.engappai.2025.112540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel short-term prediction method for distributed photovoltaic power generation considering extreme weather},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative method of multi-view face frontalization based on receptive field-enhanced conditional generative adversarial network. <em>EAAI</em>, <em>162</em>, 112539. (<a href='https://doi.org/10.1016/j.engappai.2025.112539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A series of theoretical and experimental investigations based on deep learning were conducted to enhance the accuracy and generalizability of face frontalization models. A series of theoretical investigations and experimental verifications based on deep learning are conducted to further enhance the face frontalization model's accuracy and generalizability. To address inadequate local feature extraction and the low realism in synthesized images, a receptive field-enhanced conditional generative adversarial network (RFC-GAN) is proposed to achieve multi-view face frontalization. RFC-GAN model integrates a novel configuration of multi-scale dilated convolutions in a multi-branch generator architecture to significantly expand the receptive field and improve feature extraction. The unique integration enhances the realism and detail of the generated images. Unlike conventional approaches that focus primarily on pixel-level accuracy, RFC-GAN introduces a perceptual loss component to enhance semantic content and structural integrity at the feature level. RFC-GAN has been experimentally validated on the Karolinska Directed Emotional Faces (KDEF) and Carnegie Mellon University Multiple Pose, Illumination, and Expression Face Database (CMU Multi-PIE). The generated facial expression images from RFC-GAN exhibit a higher degree of detailed texture reproduction in critical facial features such as the eyes, nose, and mouth. On the two datasets, the Peak Signal-to-Noise Ratio (PSNR) reaches 31.5185 for KDEF and 26.1851 for Multi-PIE, the Structural Similarity Index (SSIM) reaches 0.3604 for KDEF and 0.3965 for Multi-PIE, and the Learned Perceptual Image Patch Similarity (LPIPS) reaches 0.117 for KDEF and 0.408 for Multi-PIE, respectively. Compared to existing state-of-the-art methods, RFC-GAN exhibits marked improvements in these metrics, especially in detailed texture reproduction of critical facial features such as the eyes, nose, and mouth, establishing new benchmarks in face frontalization.},
  archive      = {J_EAAI},
  author       = {Yancong Zhou and Dongdong Wang},
  doi          = {10.1016/j.engappai.2025.112539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An innovative method of multi-view face frontalization based on receptive field-enhanced conditional generative adversarial network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced air pollution spatiotemporal forecast model using frequency domain convolution and attention mechanism. <em>EAAI</em>, <em>162</em>, 112538. (<a href='https://doi.org/10.1016/j.engappai.2025.112538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of air pollution, which is crucial for public health and environmental management, often faces challenges in effectively capturing the complex and intertwined spatiotemporal dynamics of pollutants. Existing models frequently struggle to simultaneously account for broad periodic spatiotemporal dependencies as well as fine-grained local temporal patterns. This paper presents a novel deep learning architecture, the Fourier Convolutional Graph Transformer (FCGformer), specifically designed to overcome these limitations. FCGformer distinctively features a dual-module approach: a Global Module that constructs an integrated spatiotemporal graph and leverages Fourier transforms with frequency domain convolution to extract long-range dependencies and crucial periodicities; and a Local Module that employs inverse temporal embedding and self-attention to meticulously capture nuanced, short-term temporal variations. The key contribution of this work lies in the synergistic integration that enables FCGformer to effectively model complex pollutant behaviors, providing a more comprehensive understanding of both global contexts and local details. Extensive experiments demonstrate that FCGformer significantly outperforms state-of-the-art benchmark models in prediction accuracy, offering a promising advancement for improved air quality management.},
  archive      = {J_EAAI},
  author       = {Haiwei Yang and Ru Yang and Ling Ding and Shiqiang Du and Maozhen Li and Bo Zhang},
  doi          = {10.1016/j.engappai.2025.112538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced air pollution spatiotemporal forecast model using frequency domain convolution and attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gate-guided spatial-channel reconstruction network: An efficient lightweight framework for steel surface defect detection. <em>EAAI</em>, <em>162</em>, 112537. (<a href='https://doi.org/10.1016/j.engappai.2025.112537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations in You Only Look Once version 8 (YOLOv8) for steel surface defect detection, including insufficient generalization of image enhancement, constrained feature representation capability in core modules, and poor adaptability of the loss function to scale variations and sample imbalance, this paper proposes the Gate-guided Spatial-channel Reconstruction Network, an efficient and lightweight improved network. Contrast-Limited Adaptive Histogram Equalization (CLAHE) is introduced to enhance local image details and contrast while reducing noise impact. The Gating Block and the Spatial-channel Reconstruction Block are designed to replace the original C2f (cross-stage partial bottleneck with two convolutions) module in YOLOv8, thereby enhancing feature representation capability and efficiency. The loss function is optimized using Wise-IoU (WIoU) and Slide Loss (SlideLoss) to improve convergence and robustness. The proposed network was evaluated on the Northeastern University Surface Defect Detection (NEU-DET) dataset (200 × 200 pixels) and the Chinese Academy of Sciences Defect Detection (GC10-DET) dataset (2048 × 1000 pixels). It demonstrated high detection accuracy, achieving the mean Average Precision at 50 % (mAP50) of 84.7 % and 79.4 %, respectively. Furthermore, the network maintains low complexity with only 3.6 million parameters and achieves a high detection speed of up to 154 frames per second (FPS). The Gate-guided Spatial-channel Reconstruction Network effectively detects surface defects on hot-rolled steel, achieving state-of-the-art detection accuracy. It successfully meets the requirements for precise and real-time steel surface defect detection under resource-constrained industrial conditions.},
  archive      = {J_EAAI},
  author       = {Wei Zhang},
  doi          = {10.1016/j.engappai.2025.112537},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112537},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gate-guided spatial-channel reconstruction network: An efficient lightweight framework for steel surface defect detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor product-fault diagnosis-transformer based wind turbine blade fault prediction method. <em>EAAI</em>, <em>162</em>, 112535. (<a href='https://doi.org/10.1016/j.engappai.2025.112535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous iterative updating of wind turbine (WT) blade fault diagnosis (FD) technology, intelligent prediction methods based on supervisory control and data acquisition (SCADA) systems have gradually become advanced mainstream technology in the industry. However, despite the many advantages of SCADA data in fault prediction, its high-dimensional characteristics and highly unstable nature still pose significant challenges for practical applications. Accordingly, this study proposes an innovative WT blade fault prediction method based on tensor product dimensionality reduction and FD-Transformer (TP-FD-Transformer) methodology, which aims to effectively solve the problem of timely and accurate prediction of WT blade faults. The TP-FD-Transformer method combines the quantum dimensionality reduction technique with the FD-Transformer model to form a new framework for data processing and analysis. The TP-FD-Transformer method adopts the tensor product-relative position matrix composite dimensionality reduction technique, which effectively reduces the dimensionality and complexity of SCADA data while preserving its features. After data processing is completed, the TP-FD-Transformer method utilizes the FD-Transformer model for deep learning training. The FD-Transformer model has been improved for complex time series data and can effectively capture potential features in the data. The experiments under the open dataset show that the TP-FD-Transformer method demonstrates excellent prediction ability in the field of WT blade FD, with an accuracy rate of 93.65 %. The research findings verify that TP-FD-Transformer method provides a feasible solution for the intelligent diagnosis of WT blade faults, with broad application prospects and significant practical significance.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Yuhan Liu and Nannan Wang},
  doi          = {10.1016/j.engappai.2025.112535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tensor product-fault diagnosis-transformer based wind turbine blade fault prediction method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid physics-based and data-driven method for the rotor angle prediction. <em>EAAI</em>, <em>162</em>, 112533. (<a href='https://doi.org/10.1016/j.engappai.2025.112533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are widely employed for transient stability analysis in power systems. However, the prediction performance can be adversely affected by undesirable factors in the measured data. To alleviate the effect of the undesirable factors, a hybrid physics-based and data-driven prediction network of the rotor angle trajectory is proposed in this paper. The prediction model embeds the rotor equation to form a dynamic learning model that conforms to the actual physical law. The physical consistency of the prediction results is guaranteed. Meanwhile, a dynamic error derivative integral network incorporating the Runge–Kutta method is proposed to correct the final results. The accuracy of the prediction can be improved. Finally, it is tested in the IEEE 39-bus system and the East China Power Grid system. The test results show that the model significantly outperforms other comparative models. And the dependence on the quality of measured data can be alleviated effectively.},
  archive      = {J_EAAI},
  author       = {Lingzhe Zhang and Dong Huang and Huaiyuan Wang},
  doi          = {10.1016/j.engappai.2025.112533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid physics-based and data-driven method for the rotor angle prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed machine learning for near real-time stress prediction on a structural component: Application for landing gears. <em>EAAI</em>, <em>162</em>, 112532. (<a href='https://doi.org/10.1016/j.engappai.2025.112532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight design constitutes a pivotal research and development objective for next-generation landing gear systems. Nevertheless, achieving reduced weight while maintaining structural safety and reliability presents considerable challenges. The establishment of a digital twin (DT) for structural health monitoring (SHM) offers a promising approach to address these concerns across the design, testing, and operational lifecycle of landing gears. In this study, we develop a physics-informed neural network (PINN) model for near real-time stress prediction on the drag strut of a nose landing gear (NLG), specifically for an A320-type aircraft, serving as a foundational component of a DT system. The proposed PINN framework directly outputs displacement fields while deriving stresses as secondary quantities, effectively incorporating the fundamental equations of linear elasticity into the loss function. Displacement boundary conditions, informed by finite element method (FEM) simulations, are integrated as penalty terms to enhance trainability and physical consistency. The training dataset is constructed using load cases statistically representative of actual landing gear operations, with high-fidelity FEM providing corresponding displacement and stress references. The model demonstrates strong predictive accuracy, with relative errors between 5% and 7% compared to FEM results, and significantly outperforms both pure stress-output PINNs and conventional deep neural networks (DNNs). Moreover, the trained PINN achieves inference times within seconds under time-varying loads, highlighting its capability for near real-time stress monitoring. This work underscores the potential of physics-informed machine learning for enhancing DT-enabled SHM systems in safety-critical aerospace structures.},
  archive      = {J_EAAI},
  author       = {Zixuan Zhu and Yifan Zhao and Agusmian Partogi Ompusunggu},
  doi          = {10.1016/j.engappai.2025.112532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed machine learning for near real-time stress prediction on a structural component: Application for landing gears},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free safe deep reinforcement learning for grid-to-vehicle management considering grid constraints and transformer thermal stress. <em>EAAI</em>, <em>162</em>, 112529. (<a href='https://doi.org/10.1016/j.engappai.2025.112529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing penetration of Electric Vehicles (EVs) presents challenges to the distribution grid, due to more volatile power profiles and higher peak demand. One key research question is how to accommodate EVs with limited-capacity grid equipment, such as transformers and lines. However, uncertainties from the EV side and the complexity of grid equipment models challenge the performance of the control strategies implemented. Moreover, the thermal loading of the transformer is often neglected. In this work, we propose a fully model-free, safe Deep Reinforcement Learning (DRL)- based grid-to-vehicle management strategy to avoid electric and thermal overloading of the transformer and power grid constraint violation. The management strategy is based on Projection-based Constraint Policy Optimization (PCPO) and takes only the observable information from the grid and vehicles. The target is to maximize energy delivery to the EV fleet while considering safe constraints, such as transformer thermal loading, voltage magnitude limits, and line loading limits. We compared the proposed strategy with conventional DRL and other safe DRL methods and investigated its robustness against higher ambient temperatures. The results show that the proposed strategy can deliver 92 % energy and reduce violations of the grid and transformers, while the other benchmarks deliver less than 80 %. The robustness test demonstrates that the proposed strategy is effective in various temperature. Moreover, the proposed strategy can effectively reduce at most 90 % of the transformer aging incurred by the thermal stress, compared with the uncontrolled charging.},
  archive      = {J_EAAI},
  author       = {Zhewei Zhang and Rémy Rigo-Mariani and Nouredine Hadjsaid and Yan Xu},
  doi          = {10.1016/j.engappai.2025.112529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model-free safe deep reinforcement learning for grid-to-vehicle management considering grid constraints and transformer thermal stress},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probability forecasting for multivariate urban water demand using temporal convolutional network based on quantile regression and parzen window. <em>EAAI</em>, <em>162</em>, 112528. (<a href='https://doi.org/10.1016/j.engappai.2025.112528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability prediction can provide more abundant information about uncertainties in future water demand, which is gaining increasing attention in building economical and reliable water resource management plans. However, most existing literature on water demand prediction focus on provide deterministic point prediction results. To overcome this problem, a novel hybrid probability forecasting model based on quantile regression temporal convolutional network and Parzen window is proposed for the probability density forecast of multivariate urban water demand. Firstly, to address the complex coupling relationship between water demand and multiple influencing factors, a random forest-based feature selection method is employed to eliminate the redundant variables. Then, a discrete wavelet transform is deployed to decompose the original series into a variety of characteristic subseries to reduce fluctuations of the original water demand series. Secondly, a quantile regression-based temporal convolutional neural network is employed to obtain the conditional quantiles of future water demand. Moreover, a probability density prediction method based on Parzen window estimation is developed to further obtain the distribution information of prediction uncertainty. Finally, a real-world multivariate dataset from a water plant in Suzhou, China, is used for comparison experiments with state-of-the-art models. The comparison results show that the proposed model has achieved an average improvement of 15.4 % and 53.3 % in interval prediction and probability density prediction, respectively. It shows that the proposed model is a reliable prediction model that can assist policymakers to optimize the management of urban water demand.},
  archive      = {J_EAAI},
  author       = {Jun Guo and Qingya Meng and Baigang Du and Hui Sun},
  doi          = {10.1016/j.engappai.2025.112528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probability forecasting for multivariate urban water demand using temporal convolutional network based on quantile regression and parzen window},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Critical nodes detection for complex networks via knowledge-guided evolutionary framework. <em>EAAI</em>, <em>162</em>, 112526. (<a href='https://doi.org/10.1016/j.engappai.2025.112526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Critical Node Problem (CNP) focuses on identifying critical nodes within complex networks. These nodes play a crucial role in maintaining connectivity, and their removal impacts network performance. Among CNP variants, CNP-1a — which minimizes pairwise connectivity after removing a limited number of nodes — has attracted significant research attention due to its NP-hard nature and applications in diverse fields like epidemic control and infrastructure resilience. While state-of-the-art methods leverage memetic algorithms and variable populations, they fundamentally rely on random initialization that often converges to local optima. This limitation arises because traditional methods fail to capture higher-order topological dependencies. To address this gap, we propose K2GA, a knowledge-guided genetic algorithm initialized by a graph attention network (GAT). The GAT embeds networks into low-dimensional spaces, assigning topology-aware attention weights to nodes that guide population initialization. K2GA then employs a hybrid genetic algorithm with a local search process to identify an optimal set of critical nodes. The local search process utilizes a cut node-based greedy strategy. Experiments on 26 real-world networks demonstrate that K2GA outperforms state-of-the-art methods in terms of the best, median, and average objective values, establishing new upper bounds for minimization in eight cases. This work pioneers a GAT-guided evolutionary search framework, offering a novel paradigm for solving CNP.},
  archive      = {J_EAAI},
  author       = {Chanjuan Liu and Shike Ge and Zhihan Chen and Wenbin Pei and Enqiang Zhu and Hisao Ishibuchi},
  doi          = {10.1016/j.engappai.2025.112526},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112526},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Critical nodes detection for complex networks via knowledge-guided evolutionary framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient framework for general long-horizon time series forecasting with mamba and diffusion probabilistic models. <em>EAAI</em>, <em>162</em>, 112525. (<a href='https://doi.org/10.1016/j.engappai.2025.112525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting plays an essential role in supporting critical decision-making processes in risk management and resource allocation in various fields, including finance, transportation, industrial systems, etc. Conventional models can effectively capture volatility and, are proficient in handling specific patterns, such as the AutoRegressive Integrated Moving Average model (ARIMA) and the Generalized AutoRegressive Conditional Heteroskedasticity model (GARCH). Nonetheless, these models meet many challenges, such as high dimensionality, non-stationarity, and nonlinearity inherent in real-world data. Although deep learning methodologies can provide better performance, they may still suffer from long-term errors and heightened computational expenses. A novel framework named Mamba Diffusion Probabilistic Models (MambaDiffTS) is proposed, which integrates Mamba’s state space model with a frequency-aware diffusion process grounded in Denoising Diffusion Probabilistic Models (DDPM). Mamba’s selective state transitions enable linear-time modeling of long-range dependencies; at the same time, frequency-aware spectral decomposition isolates trends and seasonality through Fourier regularization. Furthermore, the implementation of spectral energy-guided noise scheduling preserves temporal fidelity. Extensive experiments on diverse benchmarks-financial volatility, industrial IoT sensor data, and climate modeling-demonstrate MambaDiffTS’s superiority. Notably, on stock forecasting tasks, MambaDiffTS reduces Mean Squared Error (MSE) by approximately 18.6% compared to the best-performing baseline, and substantially outperforms diffusion models, all while maintaining linear computational complexity. The proposed MambaDiffTS facilitates scalable forecasting over extended horizons.},
  archive      = {J_EAAI},
  author       = {Wenjing Wang and Qilei Li and Ziwu Jiang and Deqian Fu and David Camacho},
  doi          = {10.1016/j.engappai.2025.112525},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112525},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient framework for general long-horizon time series forecasting with mamba and diffusion probabilistic models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selecting after sales provider of complex product based on game and matching framework. <em>EAAI</em>, <em>162</em>, 112524. (<a href='https://doi.org/10.1016/j.engappai.2025.112524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a strategic enabler of high-end manufacturing, the high-quality evolution of complex equipment is indispensable for any nation aspiring to industrial leadership. After sales service (AS) long relegated to a support function, which has emerged as a decisive determinant of product life-cycle value and, consequently, of this transformative journey. This study therefore investigates the technological innovation of AS for complex products through a Stackelberg game that captures the collaborative dynamics between an original equipment manufacturer (OEM) and an after-sales service provider (ASP). We derive the necessary and sufficient conditions under which an ASP finds participation economically viable, then embed these conditions into a multi-criteria matching framework that links ASP capabilities with spare-part requirements. Leveraging an entropy weighted DEMATEL (Decision-making Trial and Evaluation Laboratory) hybrid and we first quantify the causal salience of matching attributes and build a parsimonious evaluation index system. Next, by explicitly encoding bilateral attribute preferences, we formulate a two-sided matching model that identifies the Pareto-optimal ASP portfolio for any given product architecture. Finally, backward induction over the integrated game-matching structure yields a prescriptive tool that not only screens ASPs but also prescribes contractual levers to sustain long-term co-innovation. The proposed framework thus unifies strategic participation incentives with operational compatibility, offering OEMs a rigorous, implementable roadmap for selecting and governing after-sales partners in the era of servitized, high-stakes manufacturing.},
  archive      = {J_EAAI},
  author       = {Xin Huang and Xiaoyan Qi and Xiaojuan Xu},
  doi          = {10.1016/j.engappai.2025.112524},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112524},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Selecting after sales provider of complex product based on game and matching framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable interval prediction of dam displacement based on variational autoencoder and improved temporal fusion transformer considering solar radiation effects. <em>EAAI</em>, <em>162</em>, 112520. (<a href='https://doi.org/10.1016/j.engappai.2025.112520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the safety of dams is critical to maintaining national economic development and social stability, requiring the implementation of accurate displacement prediction methods for early detection of structural anomalies and effective risk mitigation. However, existing statistical models primarily focus on point predictions, failing to quantify the uncertainty in displacement variations, and often neglect the critical environmental factor of solar radiation. To address these limitations, this study proposes a novel interpretable interval prediction framework that integrates solar radiation factors into an advanced hydrostatic-temperature-time (AHTT) model. A variational autoencoder (VAE) is employed to extract robust latent features from a large volume of measured temperature data, effectively reducing temperature-related noise. Subsequently, an improved temporal fusion transformer method is introduced to probabilistic dam displacement prediction. This method uses an enhanced quantile loss function based on the Huber loss to generate both point and interval predictions that dynamically reflect the prediction uncertainty. In addition, an interpretable multi-head attention module is incorporated to quantify the contribution of each environmental factor. Hyperparameter tuning of the improved temporal fusion transformer is further optimized using Bayesian optimization based on the tree-structured Parzen estimator (TPE), which improves prediction accuracy. Engineering case studies validate that the proposed model not only achieves the highest point prediction accuracy, but also provides narrower prediction intervals with the best coverage width criterion. Ablation experiments and interpretability analyses further confirm the significant impact of solar radiation on dam displacement, providing valuable insights for the development of dam displacement prediction models and risk-informed decision making.},
  archive      = {J_EAAI},
  author       = {Taiqi Lu and Hao Gu and Chongshi Gu and Chenfei Shao and Yiming Wang and Dongyang Yuan},
  doi          = {10.1016/j.engappai.2025.112520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable interval prediction of dam displacement based on variational autoencoder and improved temporal fusion transformer considering solar radiation effects},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An undersampling method for software defect prediction based on hilbert curve mapping distance. <em>EAAI</em>, <em>162</em>, 112519. (<a href='https://doi.org/10.1016/j.engappai.2025.112519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem presents a significant challenge in software defect prediction. The undersampling method enhances prediction performance by eliminating non-defective instances, thereby enabling the model to focus more on defective instances. However, the effective selection of representative non-defective instances while preserving the overall data distribution remains a critical challenge. Inspired by the space-filling property of Hilbert curves, we propose the H ilbert C urve M apping D istance U ndersampling (HCMDU) method for software defect prediction. This method first maps instances to Hamming space to ensure that similar instances are positioned closer together in the space. Instance circular domains are then partitioned based on the Hamming distance between them, which facilitates the exploration of instance variability within a localized region. Finally, the Hilbert curve mapping distance is employed to further uncover the data distribution pattern within the instance circular domains. The experimental results demonstrate that HCMDU delivers outstanding performance across 16 randomly selected software defect datasets in both Random Forest (RF) and Classification and Regression Trees (CART). Moreover, the results are further corroborated by the Friedman ranking and Nemenyi post-hoc test, which indicate that HCMDU significantly improves the performance of software defect prediction.},
  archive      = {J_EAAI},
  author       = {Yu Tang and Ye Du and Ang Li and Ming-song Yang and Yan Xia},
  doi          = {10.1016/j.engappai.2025.112519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An undersampling method for software defect prediction based on hilbert curve mapping distance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised fault diagnosis method for rolling bearings based on federated universal domain adaptation. <em>EAAI</em>, <em>162</em>, 112518. (<a href='https://doi.org/10.1016/j.engappai.2025.112518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues of low diagnostic model accuracy caused by non-sharing of rolling bearing private data, distribution differences, and label space discrepancies across multiple clients, as well as the challenges that certain clients face in obtaining labeled data, an unsupervised fault diagnosis method is proposed for rolling bearings based on federated universal domain adaptation (FUDA). First, privacy protection during the transmission process in federated learning is ensured by implementing random mapping at local clients. Second, the central server employs the proposed mixed radial basis kernel-maximum mean discrepancy (MR-MMD) method to further mitigate distributional disparities between the feature spaces of source and target clients. This achieves unsupervised features alignment between these features. Third, margin vectors are introduced to tackle label space disparities between source and target clients, enabling effective separation of unknown class samples in the dataset of the target client. Finally, a dynamic weighted loss fusion strategy is designed to adaptively optimize the weight ratios of different losses. This enhancement facilitates the learning efficiency of the model. Experimental validation on two datasets demonstrates that the proposed approach can achieve average accuracies of 95.6 % and 87.7 % for the respective datasets. Compared with other methods, it represents improvements of 6.5 % and 8.1 %, while training time is reduced by at least 27 %. These results validate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shouqiang Kang and Yulin Sun and Xinrui Li and Yujing Wang and Qingyan Wang and Xintao Liang},
  doi          = {10.1016/j.engappai.2025.112518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised fault diagnosis method for rolling bearings based on federated universal domain adaptation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting. <em>EAAI</em>, <em>162</em>, 112517. (<a href='https://doi.org/10.1016/j.engappai.2025.112517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electric load forecasting remains challenged by the dual requirements of accuracy and robustness due to the combined effects of strong seasonality, multi-scale spikes, and stochastic disturbances. To address this, we propose a novel multi-scale forecasting framework, NP-WavKAN-Fusion, which integrates Neural Prophet for data decomposition and a Wavelet-based Kolmogorov–Arnold Network (WavKAN) with learnable wavelet kernels for multi-scale encoding. This fusion model utilizes a Bi-directional Gated Recurrent Unit (BiGRU) to capture long-term temporal dependencies and an adaptive feature fusion gate (AFF) to dynamically re-weight static and dynamic features for final load predictions. Extensive experiments on two public datasets from Australia and Morocco show that NP-WavKAN-Fusion consistently outperforms traditional models, reducing the mean absolute error by at least 30 %. For multi-step forecasting tasks, NP-WavKAN-Fusion maintains error inflation within 15 %, demonstrating superior performance compared to state-of-the-art long-sequence models such as Informer and PatchTST. The Diebold–Mariano test confirms that NP-WavKAN-Fusion yields statistically significant improvements, with 19 out of 20 comparisons showing lower errors. Ablation studies show that removing either the Neural Prophet component or the AFF significantly increases the forecasting error, validating the necessity of our layered denoising and fusion strategies. The proposed NP-WavKAN-Fusion framework demonstrates strong potential for real-world applications in electric load forecasting, offering robust performance under various temporal and non-stationary conditions.},
  archive      = {J_EAAI},
  author       = {Chunliang Mai and Lixin Zhang and Xuewei Chao and Xue Hu and Omar Behar},
  doi          = {10.1016/j.engappai.2025.112517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient kernel-based unsupervised multi-view feature selection via compact binary hashing. <em>EAAI</em>, <em>162</em>, 112515. (<a href='https://doi.org/10.1016/j.engappai.2025.112515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view feature selection across diverse views identifying a compact subset of the most informative feature across various data views without relying on labeled information. While most of the solutions are limited to linear multi-view data or utilize weakly-supervised single-label learning to assist in feature selection, leading to the loss of valuable semantic information, especially when dealing with complex real-world multi-view datasets. To overcome these limitations, we introduce a novel Resilient Kernel-based Unsupervised Multi-view Feature Selection via compact Binary Hashing (RKUMBH), which aims to search a robust and consistent graph representation across views, leveraging binary hashing codes to guide feature selection. Specifically, we first standardize the dimensionality of multi-view data by using non-linear kernel mapping. Then, we explore consistent graph structures across different views by fusing individual similarity graph of each view under a self-representation guidance. Moreover, the low-rank constraints are used to preserve the primary structures and patterns embedding within the data, and an unsupervised hashing feature selection framework is conducted to generate reliable hashing codes across views. Additionally, we design a customized iterative optimization method to solve the unified model. Extensive experiments on six public multi-view datasets demonstrate that our proposed method obtains state-of-the-art results compared to existing works for both clustering and feature selection tasks.},
  archive      = {J_EAAI},
  author       = {Rongyao Hu and Mengmeng Zhan and Jiangzhang Gan and Li Li and Fei Ye and Tong Liu},
  doi          = {10.1016/j.engappai.2025.112515},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112515},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resilient kernel-based unsupervised multi-view feature selection via compact binary hashing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering the geometry-dependent optical asymmetry of gold nanorods helical assemblies using artificial neural networks. <em>EAAI</em>, <em>162</em>, 112513. (<a href='https://doi.org/10.1016/j.engappai.2025.112513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optical asymmetry of gold nanorods (Au-NRs) helical assemblies is well-documented with a wide range of applications. Nevertheless, the geometry-dependent optical asymmetry within these assemblies has not been adequately explored and quantified. The present study proposes a novel approach to predict the optical asymmetry of Au-NRs helical assemblies based on geometric characteristics using artificial neural networks (ANN). The performance of the ANN termed 3 N H L 50 N N was significantly enhanced through the optimization of the hidden layer and node, resulting in an R 2 of the outcomes exceeding 0.998 and a reduction in computational time exceeding 99.99 %. In instances where the specific geometric characteristics are needed to attain a desired optical asymmetry, a retrieval of geometric characteristics of Au-NRs helical assemblies was additionally investigated using a traversing mechanism featured particle swarm optimization (PSO) algorithm. The results of the retrieval were obtained within 6 s and demonstrate a high degree of accuracy and reliability. The combination of the 3 N H L 50 N N and the PSO algorithm is capable of accurately predicting the optical asymmetry of Au-NRs helical assemblies and the retrieval of the geometry characteristics, thereby enabling the quantitative understanding of their overall geometry-dependent optical asymmetry.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Yongguang Chen and Xiyang Wei and Jianhua Shang and Lina Zhao},
  doi          = {10.1016/j.engappai.2025.112513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncovering the geometry-dependent optical asymmetry of gold nanorods helical assemblies using artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting worker loss of balance events from point cloud sequence using unsupervised motion-pose learning. <em>EAAI</em>, <em>162</em>, 112512. (<a href='https://doi.org/10.1016/j.engappai.2025.112512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workers' loss of balance (LB), such as slip and trip, may lead to severe injuries and even fatalities. Existing methods for detecting LB typically rely on wearable sensors and focus on specific body parts. This study introduces a novel, non-contact approach utilizing light detection and ranging (LiDAR) technology to detect LB events. By capturing full-body point cloud data, the proposed method extracts both static pose and dynamic motion features across multiple body sections and detects LB events through unsupervised learning. The high-dimensional point cloud sequence is transformed into interpretable gait features, enabling effective unsupervised learning through sequence reconstruction. A two-stream network and fusion strategy are also developed to combine pose and motion features for final LB detection. Experiments with various LB events demonstrate the method's effectiveness, achieving an F1 score of 0.98 and a recall of 0.98. Our analysis reveals that integrating features from multiple body parts and the fusion of pose and motion information significantly enhances detection performance. This study offers a promising alternative to traditional methods, providing effective, non-intrusive monitoring of worker safety in dynamic construction environments.},
  archive      = {J_EAAI},
  author       = {Mingyu Zhang and Lei Wang and Yinong Hu and Shuai Han and Jiawen Zhang and Heng Li},
  doi          = {10.1016/j.engappai.2025.112512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting worker loss of balance events from point cloud sequence using unsupervised motion-pose learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human motion prediction using mixture-of-branch graph convolutional network. <em>EAAI</em>, <em>162</em>, 112511. (<a href='https://doi.org/10.1016/j.engappai.2025.112511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the same spatio-temporal feature extraction network to predict multiple types of human motions pose a challenge for the prediction model to achieve optimal performance. To address this issue and achieve differentiated training, we propose a novel Mixture-of-Branch Graph Convolutional Network model which simultaneously inserts human motion sequences into a multi-branch human motion prediction module and a branch weight allocation module. When generating the final prediction sequence, weights are assigned to the prediction results of each branch. Mixture-of-Branch Graph Convolutional Network employs loss values to control competition rather than cooperation among branches, effectively addressing the issue of mutual influence between sequences during network training. To the best of our knowledge, this marks the inaugural utilization of a Mixture-of-Branch network in the realm of human motion prediction. To optimize the efficiency of the multi-branch model and reduce prediction complexity, we introduce a spatio-temporal feature extraction method for the human skeleton that accommodates Euclidean geometric transformations. This method liberates the Mixture-of-Branch Graph Convolutional Network from the constraints of additional branches, allowing it to handle similar motion sequences under varying degrees of translation or rotation, where feature matrices may exhibit significant differences. The proposal of Mixture-of-Branch Graph Convolutional Network and its related experiments represent our contribution to the Artificial Intelligence field, with significant potential value in engineering applications as well. Mixture-of-Branch Graph Convolutional Network is tested on the Human3.6M, Carnegie Mellon University Motion Capture, and Three-Dimensional Human Pose in the Wild datasets, achieving high performance. Particularly noteworthy is the 7% overall performance improvement in Mean Per Joints Position Error prediction on the Carnegie Mellon University Motion Capture dataset.},
  archive      = {J_EAAI},
  author       = {Xianshan Li and Ang Gao and Xingxing Ning and Fengda Zhao},
  doi          = {10.1016/j.engappai.2025.112511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human motion prediction using mixture-of-branch graph convolutional network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse design of particle shapes with target sphericity and packing fraction using variational autoencoders. <em>EAAI</em>, <em>162</em>, 112509. (<a href='https://doi.org/10.1016/j.engappai.2025.112509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sphericity and packing fraction are fundamental properties governing the behavior of granular materials in many engineering applications. Conventional methods for designing particles with these target properties usually suffer from limited accuracy, diversity, and interpretability due to complex relationships between particle shape and properties. To address this, we propose an inverse design framework based on deep learning. First, a rotation- and reflection-invariant variational autoencoder (VAE) parameterizes two-dimensional convex particle shapes into a low-dimensional latent space, enabling accurate reconstruction and capturing geometric interpretations such as sphericity and symmetry. Second, a conditional variational autoencoder (CVAE) facilitates inverse design by generating particle shapes corresponding to target sphericity or packing fraction, and also enables the coupling control of both properties. Trained on a dataset of over 1600 convex shapes, the framework demonstrates robustness and universality. The rotation- and reflection-invariant architecture consistently maps different orientations of the same shape to a unified representation, which enhances interpretability. The main contribution in artificial intelligence lies in developing invariant generative models that learn shape representations and enable property-driven shape generation. The engineering contribution is providing a precise and efficient tool for the inverse design of particle shapes with target properties, supporting the optimization of granular materials in engineering applications.},
  archive      = {J_EAAI},
  author       = {Yutong Qian and Shuixiang Li},
  doi          = {10.1016/j.engappai.2025.112509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse design of particle shapes with target sphericity and packing fraction using variational autoencoders},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way dynamic clustering algorithms based on generalized neighborhood relations in incomplete hybrid information systems with applications in medical decision-making. <em>EAAI</em>, <em>162</em>, 112508. (<a href='https://doi.org/10.1016/j.engappai.2025.112508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing clinical challenges related to chronic diseases, the effective use of medical data in decision-making is often hindered by issues such as incompleteness, heterogeneity, and the need for continuous updates. To cope with these challenges, this study introduces a three-way dynamic clustering strategy built upon generalized neighborhood relations, aiming to enhance clustering robustness, strengthen the model’s ability to manage uncertainty, and support adaptability to dynamically evolving data. First, generalized neighborhood relations are constructed in incomplete hybrid information systems. An evaluation function is defined from two perspectives: the number of similar attributes between objects and the distance between objects, thereby optimizing similarity measurement and accurately characterizing the data structure. Second, three-way decision rules are introduced to effectively handle uncertainty in objects while maintaining classification accuracy, thereby improving the interpretability and adaptability of the clustering model. Furthermore, to accommodate the dynamic nature of medical data, a dynamic incremental clustering method based on neighborhood information is proposed to ensure that newly added patient data can be efficiently integrated into existing clusters, enhancing model real-time performance and computational efficiency. Experiments conducted on real clinical data from Chronic kidney disease (CKD) patients validate the proposed method. The results demonstrate that, compared to existing clustering algorithms, the proposed method outperforms in terms of F1-score and Rand Index evaluation metrics. It also exhibits higher applicability in patient classification, core and boundary domain partitioning, and dynamic data processing, providing effective support for precision stratified management of chronic disease patients and intelligent medical decision-making.},
  archive      = {J_EAAI},
  author       = {Haoran Sun and Bingzhen Sun and Xixuan Zhao and Qiang Bao and Xiaoli Chu},
  doi          = {10.1016/j.engappai.2025.112508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-way dynamic clustering algorithms based on generalized neighborhood relations in incomplete hybrid information systems with applications in medical decision-making},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-stage segmentation framework for lung cancer lesion isolation in three-dimensional positron emission tomography images. <em>EAAI</em>, <em>162</em>, 112507. (<a href='https://doi.org/10.1016/j.engappai.2025.112507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background Positron emission tomography (PET) is a critical functional medical imaging modality for the early detection and diagnosis of cancers. PET imaging faces several challenges that hinder accurate interpretation including its inherently low spatial resolution, substantial variability in cancer lesions’ appearance, and difficulties distinguishing between the image background and benign lesions. Methods We propose a novel three-stage image segmentation framework to enhance the accuracy of lung cancer lesion identification and extraction from three-dimensional (3D) PET images. The first stage conducts a coarse segmentation using an encoder-decoder structure network to roughly position lesions. The second stage employs a multi-layer feature extraction network to learn the detailed characteristics of coarse segmentation results, mitigating false positives caused by localization inaccuracy. The last stage further refines the extracted features via dividing a sub-region of the lesion into foreground and background branches, reducing false positives caused by over-segmentation of edges. A novel lesion count loss function is introduced to guide the model to generate predictions during the training, ensuring that the predicted lesion counts align with the ground truth labels. Results The proposed method was evaluated on clinical 3D PET image datasets. Experimental results demonstrated a Dice Similarity Coefficient (DSC) of 85.35 %, Accuracy of 83.97 %, and Recall of 86.83 %. Compared to existing models applied to the same datasets, our method consistently achieved superior performance. Conclusion The proposed method significantly improves the segmentation performance of lung cancer lesions, implying that our method holds substantial potential for broader clinical application, even in low-resolution images.},
  archive      = {J_EAAI},
  author       = {Yusheng Wu and Qiang Lin and Jingjun Wei and Yongchun Cao and Zhengxing Man and Xiaodi Huang},
  doi          = {10.1016/j.engappai.2025.112507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A three-stage segmentation framework for lung cancer lesion isolation in three-dimensional positron emission tomography images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised visual assessment of railway track curvature via homography learning based on projective curvilinear geometry model. <em>EAAI</em>, <em>162</em>, 112506. (<a href='https://doi.org/10.1016/j.engappai.2025.112506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway track curvature monitoring is crucial for ensuring operational safety and passenger comfort. As a robust complement to the single-point physical sensor approaches, vision-based methods have recently gained increasing adoption. However, existing approaches frequently neglect the systematic exploitation of railway ego-vision geometry in two critical aspects: (1) the rail-camera kinematic coupling that relates the rail appearance in camera’s view and the track curvature during curvilinear motion, and (2) the potential of self-supervised learning to overcome annotation scarcity in this domain. This geometric oversight limits their accuracy in real-world dynamic scenarios. To address these gaps, this study proposes a novel vision-based framework that systematically exploits the railway ego vision geometry. Our methodology comprises two key innovations: First, a projective curvilinear geometry model that mathematically relates the ground-planes-induced homography to actual track curvature, thereby establishing a mapping from curvature and its variation to rail imaging curves. Second, a self-supervised curvature prediction network trained using automatically generated labels from our geometric model, eliminating the need for manual curve annotations. The self-supervision is achieved through a cyclic consistency mechanism between predicted curvatures and reprojected image features. Experimental validation using real-world railway footage demonstrates significant improvements: Our method reduces the average root mean squared error by 23.31% compared to state-of-the-art vision-based curvature estimation methods. These results underscore the effectiveness of geometry-aware computer vision for railway geometry monitoring},
  archive      = {J_EAAI},
  author       = {Peng Tang and Zhibin Yu},
  doi          = {10.1016/j.engappai.2025.112506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised visual assessment of railway track curvature via homography learning based on projective curvilinear geometry model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Saliency and correlation learning for co-salient object detection. <em>EAAI</em>, <em>162</em>, 112504. (<a href='https://doi.org/10.1016/j.engappai.2025.112504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-Salient object detection aims to identify common salient objects across a given group of images. However, accurately locating co-salient objects remains challenging due to the complexity of capturing the correlation representation of each group of images. To tackle this problem, we propose a saliency and correlation learning method for co-salient object detection. This method employs a saliency learning network and a correlation learning network to generate precise co-saliency maps of a group of images. Within the saliency learning network, a saliency feature grafting module is designed to refine object edges and achieve accurate detection of salient objects. Furthermore, the correlation learning network incorporates two modules, which are designed for extracting saliency correlation representation and deriving consensus correlation representation within a group of images, respectively. Guided by prior information obtained from saliency learning of images, our method significantly improves performance in co-salient object detection through correlation representation learning. Extensive experiments on all the latest benchmarks demonstrate that our method outperforms 11 state-of-the-art models, achieving a new level of technical excellence, with an average Structural Similarity Measure score of 0.845.},
  archive      = {J_EAAI},
  author       = {Ying Tong and Xiangfeng Luo and Liyan Ma and Shaorong Xie},
  doi          = {10.1016/j.engappai.2025.112504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Saliency and correlation learning for co-salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAVREN: A multilayered adaptive framework for deploying vision-language models on resource-constrained unmanned aerial vehicles for autonomous search and rescue. <em>EAAI</em>, <em>162</em>, 112498. (<a href='https://doi.org/10.1016/j.engappai.2025.112498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) have become indispensable in autonomous search and rescue (SAR) missions, where the ability to interpret complex visual scenes in real time is critical. When equipped with artificial intelligence (AI)-empowered Vision-Language Models (VLMs), UAVs can provide rich contextual insights, interpret their findings, and even suggest next steps, but their deployment on resource-constrained UAV platforms is vastly limited by high computational demands, energy constraints, and strict latency requirements. This paper introduces MAVREN, a m ultilayered a daptive scheduler for V LM execution in re source-constrained UAV n etworks for autonomous SAR operations. Evaluations conducted on NVIDIA Jetson Orin NX using state-of-the-art VLMs such as Large Language and Vision Assistant (LLaVA) 1.6 and Vision-Language Alignment (VILA) 7B demonstrate that MAVREN achieves up to 26.11% higher throughput , 23% lower energy consumption , 13.51% reduced latency , and a 7% gain in detection accuracy compared to baseline schedulers across indoor, outdoor, and multi-UAV SAR scenarios. This is achieved through the integration of a visual encoder for lightweight feature extraction, a block floating-point quantizer for precision-efficient representation, a bit-wise computation engine for fast arithmetic execution, and a branch-and-bound optimizer for dynamic central processing unit (CPU) scheduling. These tightly coupled components allow MAVREN to optimize the energy–latency–accuracy trade-off, making it a deployable solution for vision-language reasoning in real-world SAR missions. Our findings demonstrate MAVREN’s capability to deliver rapid, energy-efficient inference, advancing the deployment of computationally intensive VLMs on resource-constrained UAV platforms.},
  archive      = {J_EAAI},
  author       = {Md Tahmid Rashid and Md Jawad Siddique and Abdus Shaqur},
  doi          = {10.1016/j.engappai.2025.112498},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112498},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAVREN: A multilayered adaptive framework for deploying vision-language models on resource-constrained unmanned aerial vehicles for autonomous search and rescue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rapid prediction of structural deflection based on explainable machine learning. <em>EAAI</em>, <em>162</em>, 112497. (<a href='https://doi.org/10.1016/j.engappai.2025.112497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-pressure arched air-rib membrane structures (HP-ARMS) exhibit lightweight portability and modular installation. This study proposes an explainable machine learning (ML) framework for the prediction of blast-induced HP-ARMS deflection. Firstly, compare the simulation results with the experimental data to verify the numerical method accuracy. Subsequently, a database containing 500 samples was established through numerical modeling. The input features include 6 structural parameters (air-rib pressure (X1), air-rib diameter (X2), air-rib thickness (X3), air-rib width (X4), air-rib height (X5), and air-rib bottom consolidation method (X6)) and 4 external load parameters (soil cover depth (X7), lateral explosion distance (X8), explosion equivalent (X9), and charge burial depth (X10)). Use Six ML algorithms—Light Gradient Boosting Machine (LightGBM), Random Forest (RF), Adaptive Boosting (AdaBoost), K-Nearest Neighbors (KNN), Convolutional Neural Network (CNN), and Gradient Boosting (GB)— and use four evaluation metrics to assess the accuracy of the ML model. Finally, the SHapley Additive exPlans (SHAP) method was used for interpretable analysis. The results showed that the LightGBM model had the best prediction performance. Compared with LightGBM, the Random-LightGBM (R-LightGBM) model significantly improved performance after hyperparameter optimization, with Root Mean Square Error (RMSE) reduced by 2.75 %, Mean Absolute Percentage Error (MAPE) reduced by 8.16 %, Mean Absolute Error (MAE) reduced by 5.88 %, and R-Squared (R 2 ) increased by 0.01. The SHAP method indicates that the explosion equivalent (X9) and charge burial depth (X10) are the most important parameters.},
  archive      = {J_EAAI},
  author       = {Yongtao Mi and Yushuai Zhang and Yicun Chen and Chenxi Sun and Huiqi Ren},
  doi          = {10.1016/j.engappai.2025.112497},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112497},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rapid prediction of structural deflection based on explainable machine learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A latent-coupled neural network for multiphysics long-term forecasting in reactor transients using sparse observations. <em>EAAI</em>, <em>162</em>, 112496. (<a href='https://doi.org/10.1016/j.engappai.2025.112496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex dynamical systems in safety-critical applications like nuclear reactors involve strongly coupled physical fields evolving over space and time. Accurate prediction of these fields is vital for safety monitoring but is challenged by limited sensor placement and unobservable variables ( e.g. , xenon and iodine concentrations). This paper proposes the S parse observation to H igh-dimensional coupled physical field P rediction Network (SHPNet), a deep learning framework that predicts and reconstructs multiple physical fields directly from sparse observations.SHPNet combines a three-branch autoencoder to extract shared latent representations with a neural operator that models temporal dynamics in latent space, enabling efficient long-term forecasting. Evaluated on H ua-long P ressurized R eactor (HPR1000) under varying power and burnup conditions, SHPNet outperforms traditional frameworks and end-to-end model , achieving higher accuracy, robustness to observation sparsity, and effective reconstruction of unobservable fields. These results demonstrate SHPNet’s potential as a practical tool for real-time monitoring of complex coupled systems.},
  archive      = {J_EAAI},
  author       = {Yu-Yan Xu and Jun Luo and Deng Pan and Wei Lu and Ting Liu and Guanghui Yuan and Minxiao Zhong and Qing Li and Helin Gong},
  doi          = {10.1016/j.engappai.2025.112496},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112496},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A latent-coupled neural network for multiphysics long-term forecasting in reactor transients using sparse observations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESIGCF: Extremely simplified but intent-enhanced graph collaborative filtering for recommendation. <em>EAAI</em>, <em>162</em>, 112495. (<a href='https://doi.org/10.1016/j.engappai.2025.112495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) and graph contrastive learning (GCL) have substantially advanced recommender systems by modeling high-order user–item interactions and leveraging self-supervised signals. However, many existing methods overemphasize user–user or item–item similarities and rely on complex intent modeling, leading to increased complexity and limited exposure to diverse items. To address these challenges, we propose ESIGCF ( E xtremely S implified but I ntent-enhanced G raph C ollaborative F iltering) — a lightweight yet effective recommendation framework. ESIGCF explicitly defines user intent as the inner product between user and item embedding vectors and comprises two primary modules: (i) an intent-enhanced GCN that uses hybrid normalization (combining mean- and symmetric-normalization) to capture fine-grained user–item preferences without additional intent parameters, and (ii) an intent-aware GCL that aligns user–item pairs and positive and generated negative items. Negative samples are generated via a non-linear activation of item embedding interactions, promoting exposure to varied candidates without data augmentation. Experiments on three public datasets (Alibaba-iFashion, Yelp2018, Amazon-Book) show that ESIGCF consistently outperforms state-of-the-art baselines. For instance, on Alibaba-iFashion, ESIGCF achieves Recall@20 of 0.1273 versus 0.1059 for the best intent-enhanced baseline (a 20.2% relative improvement). Comprehensive experiments confirm that ESIGCF effectively captures latent user intent, mitigates popularity bias, and enhances recommendation performance with reduced complexity. Our code is available at https://github.com/Yangzhi22/ESIGCF .},
  archive      = {J_EAAI},
  author       = {Zhi Yang and Ruizhang Huang and Yanping Chen and Chuan Lin and Yongbin Qin},
  doi          = {10.1016/j.engappai.2025.112495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ESIGCF: Extremely simplified but intent-enhanced graph collaborative filtering for recommendation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatial–temporal information into deep learning via wind propagation theory to enhance wind power prediction. <em>EAAI</em>, <em>162</em>, 112494. (<a href='https://doi.org/10.1016/j.engappai.2025.112494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting wind power poses significant challenges because of the inherent randomness and intermittency of wind speed, thereby impeding effective wind power scheduling. This study proposes an improved deep learning model which leverages wind propagation theory to uncover spatial–temporal relationships among wind turbines to enhance the performance of wind power prediction. In addition, comprehensive theoretical and empirical analyses are conducted to justify the effectiveness of leveraging wind propagation theory for capturing spatio-temporal relationships among wind turbines. Moreover, spatio-temporal dependencies are modeled through a dual mechanism: multi-channel independent modeling for per-turbine temporal dynamics and wind propagation-based matrix computations for inter-turbine spatial relationships, which together significantly reduce computational complexity while preserving predictive performance. Data from 134 wind turbines and six comparison models were employed to validate the robustness and effectiveness of the proposed model. Empirical results indicate that the proposed model outperforms the baseline models, achieving an average improvement of 6.19% in Root Mean Square Error and 7.05% in Mean Absolute Error.},
  archive      = {J_EAAI},
  author       = {Maolin He and Jujie Wang},
  doi          = {10.1016/j.engappai.2025.112494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fusing spatial–temporal information into deep learning via wind propagation theory to enhance wind power prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed dynamic bayesian networks for time-dependent reliability prediction of subsea wellhead sealing system with multi-states. <em>EAAI</em>, <em>162</em>, 112492. (<a href='https://doi.org/10.1016/j.engappai.2025.112492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Subsea Wellhead Sealing System (SWSS) is crucial for the safety of deepwater operating, yet its reliability assessment faces challenges from harsh environments and multi-factor interactions. This study developed a data-driven, physics-informed reliability assessment method combining Finite Element Analysis (FEA) and Dynamic Bayesian Networks (DBN). An FEA model is established based on metal sealing theory, and a data-driven reliability model is subsequently constructed through sampling analysis, with a numerical-to-state conversion method bridging FEA and DBN. The FEA-DBN approach offers two key advantages: eliminating expert scoring subjectivity through physics-based modeling and effectively capturing multi-factor interactions and time-dependent behaviors. Results show this method can precisely quantify the evolution of SWSS reliability throughout its service lifecycle, with the probability of failure increasing from 0.64 % to 3.38 % over a 30-year service life. Case studies demonstrate its effectiveness for deep-sea equipment assessment, particularly in operating environments where real-time monitoring proves challenging, thereby demonstrating significant engineering application value.},
  archive      = {J_EAAI},
  author       = {Shengnan Wu and Han Gong and Long Yu and Aibo Zhang and Laibin Zhang and Yiliu Liu},
  doi          = {10.1016/j.engappai.2025.112492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed dynamic bayesian networks for time-dependent reliability prediction of subsea wellhead sealing system with multi-states},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing a robust short-text clustering model for contrastive learning based on optimized adaptive optimal transport for pseudo-label generation. <em>EAAI</em>, <em>162</em>, 112491. (<a href='https://doi.org/10.1016/j.engappai.2025.112491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-text data often suffers from noise and class imbalances, posing challenges for effective clustering. To address these issues, we propose a Short-Text Clustering Model based on Pseudo-Labels and Contrastive Learning (SCPCL). The model comprises two key components: (1) a pseudo-label acquisition module, which introduces the optimal transport theory into short-text clustering and adopts a dynamically adjusted prior distribution to enhance the clustering of minority classes; and (2) a contrastive learning module combining a supervised clustering network, an instance contrastive head, and an anchor network. These components ensure intraclass compactness, interclass separability, and robustness to noise. Experiments on six benchmark datasets showed that SCPCL achieves an average clustering accuracy improvement of 2.61%, with a maximum gain of 6.47% for long-tailed distributions. This model provides an effective solution for clustering complex short text data.},
  archive      = {J_EAAI},
  author       = {Jiahui Liu and Chun Yan and Wei Liu and Yi Ding},
  doi          = {10.1016/j.engappai.2025.112491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Constructing a robust short-text clustering model for contrastive learning based on optimized adaptive optimal transport for pseudo-label generation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid semantic-structural graph neural network for fault knowledge graph completion in railway operational equipment. <em>EAAI</em>, <em>162</em>, 112490. (<a href='https://doi.org/10.1016/j.engappai.2025.112490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete fault knowledge graphs in railway operational equipment hinder effective fault diagnosis, prediction, and maintenance planning. This study addresses the challenge of completing fault knowledge graph by proposing a hybrid semantic-structural graph neural network (Hybrid S-GNN) that integrates both semantic and structural information for knowledge graph completion (KGC) in railway fault scenarios. The Hybrid S-GNN comprises four key modules: a semantic encoding module that enhances textual fault data representations through contextual enhancement and dynamic weight allocation; a structural encoding module that captures graph topology using multi-view structure encoding combining local aggregation, global path encoding, and relation-aware adjustment; a semantic-structural fusion module leveraging attention mechanisms to balance semantic and structural signals; and an optimization-prediction module employing margin-based ranking loss and context-aware negative sampling for accurate triple prediction. Experiments on real-world railway fault knowledge graphs demonstrate that Hybrid S-GNN achieves a Hits@10 of 80.5 % and mean reciprocal rank (MRR) of 0.640, outperforming state-of-the-art baselines by 5.8 % and 6.1 %, respectively. Ablation studies confirm the critical contributions of each module, validating the necessity of jointly modeling semantic and structural features. This work provides an effective solution to enhance railway fault knowledge graphs and paves the way for advanced fault management applications in railway operations.},
  archive      = {J_EAAI},
  author       = {Xiaorui Yang and Honghui Li and Yi Xu and Yunhao Deng and Yanhui Bai and Shufang Liu},
  doi          = {10.1016/j.engappai.2025.112490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid semantic-structural graph neural network for fault knowledge graph completion in railway operational equipment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive detection method for driver fatigue using facial multisource dynamic behavior fusion. <em>EAAI</em>, <em>162</em>, 112482. (<a href='https://doi.org/10.1016/j.engappai.2025.112482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving while fatigued is a leading cause of traffic accidents. This study proposed an adaptive detection model to recognize driver fatigue based on the dynamic facial behavior information of drivers. First, drivers’ facial fatigue features were extracted to establish a general feature space, including pupil movement, eye state, and fatigue expression parameters. A differentiated feature space was then built based on individual drivers, taking into account the homogeneity, regularity, and individual variances in drivers' facial behavior at various states. A complete adaptive fatigue feature space was built by integrating the general feature space and differentiated feature space. Finally, a driver adaptive fatigue discrimination model was constructed to classify the general and adaptive fatigue feature space to detect driver fatigue states adaptively. A driver fatigue detection dataset from real scenarios had been established to validate the performance of the proposed model. Experimental results demonstrated that the proposed method significantly improved the detection accuracy of driver fatigue. In terms of artificial intelligence, this study contributes a novel adaptive feature space construction method based on multimodal dynamic feature fusion for facial fatigue recognition; in engineering application, it develops an adaptive driver fatigue detection system grounded in multimodal dynamic behaviors, which provides real-time alerts upon detecting driver fatigue and ensures driving safety.},
  archive      = {J_EAAI},
  author       = {Guoxin Zhang and Fei Yang and Xin Fang and Lili Wang and Lei Zhao and Chaoning Yu},
  doi          = {10.1016/j.engappai.2025.112482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive detection method for driver fatigue using facial multisource dynamic behavior fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermoeconomic optimization of climate-adaptive solar and wind multi-generation systems using artificial intelligence and thermal energy recovery. <em>EAAI</em>, <em>162</em>, 112481. (<a href='https://doi.org/10.1016/j.engappai.2025.112481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a hybrid multi-generation energy system designed to overcome solar intermittency while meeting the global demand for integrated delivery of electricity, water, cooling, and sustainable fuels in the transition to decarbonization. The engineering application integrates solar thermal and wind energy with a modified Brayton cycle, a Steam Rankine Cycle (SRC), and a Thermoelectric Generator (TEG) to simultaneously produce electricity, fresh water via Reverse Osmosis (RO), hydrogen and oxygen via Proton Exchange Membrane Electrolyzer (PEME), and cooling (via absorption chiller) within a unified optimization framework. The system was modeled using Engineering Equation Solver (EES) and optimized via Response Surface Methodology (RSM) based on 11 decision variables. To address the complexity of optimization, a second phase applied Artificial Intelligence (AI) techniques: Adaptive Boosting (AdaBoost) for predictive modelling and Particle Swarm Optimization (PSO) for global optimization. Under optimal conditions, the Response Surface Methodology yielded an exergy efficiency of 45.8 % with a cost rate of 576.76 United States Dollars per hour (USD/h), while AI reduced costs to 211.2 USD/h with a moderate efficiency trade-off. Simulation of the optimized configuration across eight diverse climates identified Quebec as most viable, generating 22,629.6 Megawatt-hours per year (MWh/year) of electricity and avoiding 4616.4 tons of Carbon Dioxide (CO 2 ) emissions annually. Integration of wind energy stabilizes solar variability, enhancing performance. AI contributes to optimizing complex interactions, nonlinear constraints, and multiple conflicting objectives. The methodology offers a scalable, generalizable framework for designing intelligent, climate-resilient infrastructures. Future research includes AI-enabled real-time control, experimental validation, and broader deployment strategies.},
  archive      = {J_EAAI},
  author       = {Ehsanolah Assareh and Nima Izadyar and Emad Tandis and Mehdi Khiadani and Amir shahavand and Neha Agarwal and Arian Gerami and Ahmed Rezk and Minkyu Kim and Reza Kord and Tahereh Pirhoushyaran and Mehdi Hosseinzadeh and Saleh Mobayen},
  doi          = {10.1016/j.engappai.2025.112481},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112481},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermoeconomic optimization of climate-adaptive solar and wind multi-generation systems using artificial intelligence and thermal energy recovery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-driven prior learning-based deep unrolling for underwater image enhancement. <em>EAAI</em>, <em>162</em>, 112472. (<a href='https://doi.org/10.1016/j.engappai.2025.112472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a physics-driven prior learning-based algorithm unrolling approach for underwater image enhancement that leverages the advantages of both model- and learning-based approaches while overcoming their limitations. Model-based algorithms are theoretically robust because of prior knowledge of the underlying physics but may degrade image quality due to modeling inaccuracies. On the other hand, learning-based algorithms exhibit better adaptivity but inferior interpretability due to their black-box models and neglect of domain knowledge. In this work, we first formulate underwater image enhancement as a joint optimization problem with physics-based underwater-related priors and two learnable regularizers to compensate for modeling inaccuracies. Then, we solve the problem by reformulating it as a set of subproblems, which are then solved iteratively. Finally, we unroll the iterative algorithm into a deep neural network comprising a series of blocks, in which the optimization variables and regularizers are updated using closed-form solutions and learned deep neural networks, respectively. Experimental results on several datasets demonstrate that the proposed algorithm outperforms state-of-the-art underwater image enhancement algorithms on both quantitative and qualitative comparisons. The source code and pretrained models will be available at https://github.com/thithuypham/BLUE-Net .},
  archive      = {J_EAAI},
  author       = {Thuy Thi Pham and Hansung Yu and Truong Thanh Nhat Mai and Chul Lee},
  doi          = {10.1016/j.engappai.2025.112472},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112472},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-driven prior learning-based deep unrolling for underwater image enhancement},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explore unicin milvus optimization-based scale invariant signal interference noise loss enabled cycle generative adversarial network for audio source separation. <em>EAAI</em>, <em>162</em>, 112470. (<a href='https://doi.org/10.1016/j.engappai.2025.112470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio Source Separation remains the major research area as noisy audio signals lack information connectivity among users. Despite the numerous important efforts for audio source separation, there are still some challenges limiting the overall performance. Specifically, the existing methods face difficulty in working with multiple input sources and ignore the spectrum information of the signals, resulting in subpar performance. Hence, the research proposes the Explore Unicin Milvus Optimization-based Scale Invariant Signal interference Noise loss enabled Cycle Generative Adversarial Network (ExUnMO-S2NC-GAN) for addressing the challenges in the existing methods. The proposed approach utilizes the Cycle Generative Adversarial Network (C-GAN) architecture to carry out the transformation and restoration while preserving the significant details, resulting in achieving the most relevant audio source as the outcome. Specifically, the proposed model exploits the Scale Invariant Signal interference noise (S2N) loss function, improving the robustness against invariant to the signal scale and deformations of the signal. Besides, the Explore Unicin Milvus Optimization (ExUnMO) algorithm, harnessing the unique traits of Red Kite and Harris Hawk, is used for fine-tuning the hyperparameters of C-GAN, leading to improved performance. Moreover, the feature extraction with the spectral parameters added more advantages to the research model to work on more specific inputs. Extensive experiments demonstrates that theproposed model obtained high-efficiency outcomes in comparison with the state-of-the-art methods, which is evaluated with the error metrics attaining the Mean Absolute Error (MAE) of 1.79, and Mean Absolute Percentage Error (MAPE) of 3.22, whereas the signal quality metrics such as Peak Signal-to-Noise Ratio (PSNR), Signal-to-Interference Ratio (SIR) and Signal-to-Artifacts Ratio (SAR) achieved the high values of 54.81 dB (dB), 39.33 dB, and 40.56 dB respectively.},
  archive      = {J_EAAI},
  author       = {Baishakhi Dutta and Chandrakant J Gaikwad},
  doi          = {10.1016/j.engappai.2025.112470},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112470},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explore unicin milvus optimization-based scale invariant signal interference noise loss enabled cycle generative adversarial network for audio source separation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vessel behavior recognition method for preventing vessel-bridge collisions via adaptive video analytics. <em>EAAI</em>, <em>162</em>, 112467. (<a href='https://doi.org/10.1016/j.engappai.2025.112467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive end-to-end framework for recognizing vessel behaviors aimed at preventing vessel-bridge collisions in complex maritime environments. Current monitoring approaches that rely on Automatic Identification Systems or external tracking mechanisms often suffer from class imbalance, cross-domain variability, and limited capability to detect previously unseen high-risk behaviors. To address these challenges, the proposed framework directly analyzes video streams and introduces a standardized behavioral taxonomy, classifying vessel activities into eleven categories while incorporating temporal continuity and behavior transition modeling. A robust dataset construction pipeline is established, consisting of fixed-length frame sequences and mechanisms for cross-domain generalization. The framework integrates a spatio-temporal feature extraction module based on deformable convolution and multi-scale attention, coupled with a cross-instance mutual enhancement mechanism to capture domain-invariant representations. An open-set recognition strategy, grounded in class anchor clustering, enables accurate identification of previously unobserved high-risk behaviors. Furthermore, an adaptive frame sampling strategy dynamically adjusts sampling density around behavior transitions, enhancing recall and capturing infrequent events while minimizing computational cost. Extensive evaluations on both single-domain and multi-domain benchmark datasets, as well as real-world bridge video streams, demonstrate superior performance in terms of overall accuracy, F1-score, detection of rare behaviors, and recall compared with baseline methods. Ablation studies confirm the contribution of each component, and comparisons with open-set recognition methods underscore the practical utility of the proposed approach for anomaly detection. This framework provides a scalable, artificial intelligence-driven solution for vessel behavior recognition, anomaly detection, and cross-domain generalization, supporting intelligent monitoring and early warning in safety-critical maritime operations.},
  archive      = {J_EAAI},
  author       = {Woqin Luo and Daoxin Chen and Ye Xia and Dongming Feng},
  doi          = {10.1016/j.engappai.2025.112467},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112467},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vessel behavior recognition method for preventing vessel-bridge collisions via adaptive video analytics},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks. <em>EAAI</em>, <em>162</em>, 112465. (<a href='https://doi.org/10.1016/j.engappai.2025.112465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-isothermal plastic deformation creates modeling challenges for constitutive model development. Current constitutive models challenge to capture the coupled microstructural changes that occur when temperature varies during processing. The Micro-Mechanism Informed Artificial Neural Network (MMIANN) framework was developed to address these limitations using artificial intelligence (AI) and machine learning (ML) techniques. The MMIANN framework combines physics-based evolution equations for key metallurgical processes—dislocation density, grain boundary migration, and precipitation kinetics—with neural network predictions. These micro-mechanisms operate as internal state variables that guide the network's material behavior predictions. The architecture uses parallel physics-based and neural pathways, blended through adaptive coefficients. Thermodynamic constraints maintain consistency through penalty-based enforcement of the Clausius-Duhem inequality. The model was trained and validated using experimental data from simultaneous cooling and tensile deformation of AA7075 aluminum alloy. The tests replicated industrial hot forming conditions with cooling rates from 25 to 75 °C per second (°C/s). This experimental approach captures the thermal-mechanical coupling that drives microstructural evolution in practice. MMIANN achieved correlation coefficients exceeding 0.96 for stress, temperature, and grain size predictions. The framework captures thermomechanical regimes. Processing maps generated by the AI model link process parameters to microstructural outcomes. The analysis reveals an optimal processing window (40–55 °C/s cooling, 0.15–0.25 strain ( ε )) and identifies three regimes where different strengthening mechanisms dominate. By integrating metallurgical science with machine learning, this framework provides a practical tool for non-isothermal manufacturing processes. The approach bridges microstructural understanding with process control for thermal-mechanical operations through the application of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Yo-Lun Yang and Tsai-Fu Chung and Chia-Hung Liao and Liang-Yu Chen and Hsing-Yu Wu and Uthayakumar Marimuthu and Arumugaprabu Veerasimman and Sundarakannan Rajendran and Vigneshwaran Shanmugam},
  doi          = {10.1016/j.engappai.2025.112465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learnable patchmatch and self-teaching for multi-frame depth estimation in monocular endoscopy. <em>EAAI</em>, <em>162</em>, 112463. (<a href='https://doi.org/10.1016/j.engappai.2025.112463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work delves into unsupervised monocular depth estimation in endoscopy, which leverages adjacent frames to establish supervisory signals during the training phase. For many clinical applications, e.g. , surgical navigation, temporally correlated frames are also available at test time. However, most existing monocular methods struggle to make effective use of temporal information during both training and inference, primarily due to the inherent challenges of endoscopic imagery, including low- or homogeneous-texture regions and brightness fluctuations between frames. To fully exploit the temporal information in endoscopic scenes, we propose a novel unsupervised multi-frame monocular depth estimation model. The proposed model integrates a learnable patchmatch module to adaptively increase the discriminative ability in regions with low or homogeneous textures, and enforces cross-teaching and self-teaching consistencies to provide efficacious regularizations towards brightness fluctuations. Furthermore, as a byproduct of the self-teaching paradigm, the proposed model is able to improve the depth predictions when more frames are input at test time. We conduct detailed experiments on multiple datasets, and the experimental results indicate that the proposed method exceeds prior state-of-the-art competitors. The source code and trained models will be publicly available at https://github.com/ShuweiShao/FrameDepth .},
  archive      = {J_EAAI},
  author       = {Shuwei Shao and Zhongcai Pei and Weihai Chen and Xingming Wu and Zhong Liu},
  doi          = {10.1016/j.engappai.2025.112463},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112463},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learnable patchmatch and self-teaching for multi-frame depth estimation in monocular endoscopy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph induced semi-supervised orthogonal nonnegative matrix factorization with label and constraint propagation. <em>EAAI</em>, <em>162</em>, 112462. (<a href='https://doi.org/10.1016/j.engappai.2025.112462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a popular technology of artificial intelligence, nonnegative matrix factorization (NMF) aims at clustering and finding the differentially expressed features of each cluster. However, for complex high-dimensional sample data, it is still a challenge to design more appropriate NMF optimization models and develop more efficient algorithms to solve this model in view of enhanced theoretical properties and numerical performance. In this paper, a novel NMF optimization model with regularization is proposed such that the NMF is performed by a semi-supervised approach, as well as incorporating the strategies of hypergraph induced label propagation and constraint propagation. Specifically, different from existing NMF methods, the hypergraph structure underlying the data, together with the simple graph information, is employed to guide the pairwise constraint propagation in our built model. In recognition of sample similarity, a dataset-adaptive strategy is proposed to update the weight matrix of the graphs. By adding dual orthogonality on the factor matrices in the objective function, interpretability and feature independence of the built model are enhanced. Then, an algorithm is developed to efficiently solve this complicated model. Theoretically, it is proved that the developed algorithms are well defined and convergent. Numerically, extensive tests on the proposed model and algorithm are performed, which validate that they outperform the state-of-the-art ones in terms of different metrics of evaluating clustering performance when they are applied into solution of the problems from eight public datasets.},
  archive      = {J_EAAI},
  author       = {Jie Guo and Ting Li and Jialu Liu and Zhong Wan},
  doi          = {10.1016/j.engappai.2025.112462},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112462},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hypergraph induced semi-supervised orthogonal nonnegative matrix factorization with label and constraint propagation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery. <em>EAAI</em>, <em>162</em>, 112461. (<a href='https://doi.org/10.1016/j.engappai.2025.112461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring of complex industrial systems is critical for ensuring operational reliability. Data-driven methods using artificial intelligence have advanced anomaly detection (AD) and fault diagnosis (FD), but existing approaches often treat them separately, focus on known faults, and struggle with previously unseen or rare conditions in multi-modal scenarios. This study proposes a novel condition monitoring framework that integrates AD and FD within a distributed architecture. Lightweight models—including kernel principal component analysis, support vector machines, and one-dimensional convolutional neural networks—enable efficient and scalable processing. A multilevel information fusion strategy ensures consistent detection and diagnosis while facilitating the isolation of previously unknown faults. Module test results demonstrate the effectiveness and robustness of the proposed feature extraction and adaptive modeling approaches. The overall test results for previously unknown faults vary across channels and modules. For samples with misalignment and inner blade wear, channel-level detection accuracy ranges from 0.007 to 0.989, with unknown recognition rates up to 0.933 and diagnosis probabilities from 0.508 to 0.933. For strong misalignment and fan-end inner race faults, nearly all channels achieve 100 % detection accuracy, with some diagnosis probabilities above 0.9, while unknown recognition remains minimal (mostly below 0.05). Importantly, the proposed framework integrates detection and diagnostic outputs across channels, effectively mapping previously unseen faults to similar known categories or to an unknown category. Overall, the proposed framework offers a referenced solution for condition monitoring of industrial systems like pumps, turbines, and compressors, and lays the foundation for future improvements incorporating domain knowledge and model-driven interpretability.},
  archive      = {J_EAAI},
  author       = {Yingqian Liu and Rongyong Zhang and Luigi Grossi and Zhipin Ye and Huairui Li and Rongsheng Zhu and Qiang Fu},
  doi          = {10.1016/j.engappai.2025.112461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and stable framework for generative adversarial imitation learning. <em>EAAI</em>, <em>162</em>, 112460. (<a href='https://doi.org/10.1016/j.engappai.2025.112460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying reinforcement learning to complex and high-dimensional tasks encounters challenges, including the formulation of suitable reward functions, achieving sample efficiency, and developing effective exploration strategies. Adversarial imitation learning techniques address these issues by employing generative adversarial networks (GANs) to capture temporal dependencies and mitigate compounding errors. These methods exhibit enhanced efficiency relative to behavioral cloning and require fewer expert samples. Nonetheless, their complex min-max problem results in sample inefficiency and struggles with challenges such as mode collapse and training instability. This paper provides a comprehensive approach that adeptly addresses these challenges. The proposed method's design comprises three main steps. First, it uses the off-policy Twin Delayed Deep Deterministic (TD3) algorithm to enhance sample efficiency and accelerate learning. In the second step, a novel reward function based on energy-based GANs and deep regret analytic GANs is developed, which alleviates mode collapse and enhances training stability. Finally, we suggest several improvements, including the use of a pre-trained discriminator and mixed batches, to achieve a faster and more stable algorithm. The evaluation findings on continuous control tasks demonstrate that our method not only matches state-of-the-art performance but also surpasses it in both sample efficiency and stability. It achieves convergence with far fewer iterations than the compared methods.},
  archive      = {J_EAAI},
  author       = {Fateme Shahabi-Nejad and Mohammad Mehdi Ebadzadeh},
  doi          = {10.1016/j.engappai.2025.112460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast and stable framework for generative adversarial imitation learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transfer learning method of collaborating random walk and adaptive instance normalization for inscription image denoising. <em>EAAI</em>, <em>162</em>, 112458. (<a href='https://doi.org/10.1016/j.engappai.2025.112458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mess noise hinders reading and understanding of inscriptions in images. For image restoration from noise-corrupted images, existing network-learning-based methods can construct an excellent model to generate noise patterns. However, the performance of such models is degraded owing to the lack of high-quality training data and the complex noise pattern in inscription images, e.g., mixed noise with multiple levels. Herein, we first propose a novel noise generation model that can produce more realistic synthetic noise images using the random walk algorithm. Then, we propose an explainable inscription image denoising network using a variational inference model, where the joint distribution of clean-noise image pairs is approximated in a dual adversarial manner. The proposed network exhibits improved generalizability and adaptability to different noise characteristics using an estimated noise map and adaptive instance normalization. Finally, we introduce a transfer learning scheme to migrate the network learned from the synthetic noise image domain to a real-inscription image domain with a limited number of real-inscription images. The proposed method outperforms state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Erhu Zhang and Yunjing Liu and Guangfeng Lin and Jinghong Duan},
  doi          = {10.1016/j.engappai.2025.112458},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112458},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A transfer learning method of collaborating random walk and adaptive instance normalization for inscription image denoising},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite element-integrated neural network framework for spatial modal prediction in machine tool structures. <em>EAAI</em>, <em>162</em>, 112456. (<a href='https://doi.org/10.1016/j.engappai.2025.112456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of position-dependent structural dynamics in (CNC) machine tools is critical for ensuring machining precision, avoiding resonance, and enabling real-time health monitoring. This study proposes an integrated framework combining finite element analysis (FEA), experimental modal testing, and artificial neural networks (ANNs) to model and predict position-dependent dynamics across the machine workspace. A validated FEA model of a high-rigidity vertical machining centre is developed and correlated with experimental modal analysis using a PCB 086D20 impact hammer and tri-axial accelerometer. Natural frequencies and mode shapes are extracted and compared, showing deviation under 10 %, confirming model fidelity. To capture position-dependent dynamics, modal analysis was performed at 27 spatial locations, revealing significant frequency variation across planes, indicating localized compliance zones. A multilayer ANN is trained on the modal dataset to predict frequencies based on spatial coordinates, achieving R 2 values above 0.99. The proposed hybrid approach enables real-time estimation of structural dynamics, reducing the need for repeated testing and supporting intelligent control strategies in large-format CNC systems. This work contributes a predictive foundation for dynamic stability optimization, resonance avoidance, and digital twin development in precision machining applications.},
  archive      = {J_EAAI},
  author       = {Aman Ullah and Tzu-Chi Chan and Jun-Fa Huang and Shinn-Liang Chang},
  doi          = {10.1016/j.engappai.2025.112456},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112456},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite element-integrated neural network framework for spatial modal prediction in machine tool structures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end go (Weiqi) game record reconstruction from live broadcast videos. <em>EAAI</em>, <em>162</em>, 112455. (<a href='https://doi.org/10.1016/j.engappai.2025.112455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual transcription of Go (Weiqi) game records from broadcast videos creates a major bottleneck for building training data in artificial intelligence (AI). We present an end-to-end system that reconstructs complete smart game format (SGF) records from professional tournament broadcasts. The pipeline integrates four modules: (i) video-to-frame sampling; (ii) a board detector based on a detection transformer (DETR), optimized with a size-aware loss to reliably localize both main and commentary boards; (iii) a stone classifier that uses knowledge distillation from a vision transformer (ViT) teacher to an efficient grid-based student for full-board inference; and (iv) a temporal reconstruction algorithm for occlusion recovery and move-sequence consistency. When evaluated under a zero-error-tolerance video-level protocol – where a video is counted correctly only if all sampled frames match the reference – the system achieves 82.56% accuracy on 86 real tournament videos (356 h). Component analyses reveal high board localization quality with mean average precision (mAP50-95) reaching 0.99; near-teacher board-state recognition with a 67 × speedup (377.5 frames per second, FPS) and F1 score 0.988; and a 70.23% reduction of occlusion-related misdetections. Compared with you only look once (YOLO) and faster region-based convolutional neural network (Faster R-CNN) baselines, our design improves small-board recall and end-to-end robustness in dual-board and occluded settings. The system outputs SGF records suitable for large-scale dataset construction, AI-assisted analysis, education, and digital preservation, and the approach can be generalized to other grid-structured board games with minor adaptations.},
  archive      = {J_EAAI},
  author       = {Chih-Lin Lin and Hsia-Hung Ou and Lung Hung Chen and Chih-En Kuo},
  doi          = {10.1016/j.engappai.2025.112455},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112455},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {End-to-end go (Weiqi) game record reconstruction from live broadcast videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting code paraphrased by large language models using coding style features. <em>EAAI</em>, <em>162</em>, 112454. (<a href='https://doi.org/10.1016/j.engappai.2025.112454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in large language models (LLMs) for code generation has raised serious concerns about intellectual property protection. Malicious users can exploit LLMs to produce paraphrased versions of proprietary code that closely resemble the original. While the potential for LLM-assisted code paraphrasing continues to grow, research on detecting it remains limited, underscoring an urgent need for a detection system. We respond to this need by proposing two tasks. The first task is to detect whether code generated by an LLM is a paraphrased version of original human-written code. The second task is to identify which LLM is used to paraphrase the original code. For these tasks, we construct a dataset consisting of pairs of human-written code and LLM-paraphrased code using various LLMs. We statistically confirm significant differences in the coding styles of human-written and LLM-paraphrased code, particularly in terms of naming consistency, code structure, and readability. Based on these findings, we develop a detection method that identifies paraphrase relationships between human-written and LLM-generated code, and discover which LLM is used for the paraphrasing. Our detection method outperforms the best baselines in two tasks, improving F1 scores by 2.64% and 15.17% while achieving speedups of 1,343x and 213x, respectively.},
  archive      = {J_EAAI},
  author       = {Shinwoo Park and Hyundong Jin and Jeong-won Cha and Yo-Sub Han},
  doi          = {10.1016/j.engappai.2025.112454},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112454},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting code paraphrased by large language models using coding style features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative neural networks for inverse design: Integrating denoising autoencoder and surrogate model for partial design variable imputation. <em>EAAI</em>, <em>162</em>, 112453. (<a href='https://doi.org/10.1016/j.engappai.2025.112453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven inverse design is an engineering approach where target performance criteria are specified upfront, leading to the derivation of design solutions that meet these criteria. While recent research focuses on generating complete design solutions using generative models, these approaches struggle with partial design variables and constraints that predetermine certain variables. Additionally, generative models are data-intensive and prone to overfitting with limited datasets. To address these limitations, this paper proposes a Cooperative Neural Network architecture comprising two key components: the Imputation Model and the Surrogate Model. These components collaborate to optimize design solutions while adhering to predefined performance criteria. The framework’s effectiveness is demonstrated through a case study on Glass Run Channel (GRC) designs from a Korean automotive manufacturer. Results show the architecture proficiently imputes undetermined variables and ensures the designs meet desired performance metrics, achieving Mean Squared Error (MSE) reductions of up to 98 % and R-squared values of 0.997–0.999 in initial tests. It remains robust in diverse scenarios, achieving up to 95.65 % MSE reduction and R-squared values of 0.995–0.999 for cases with the most undetermined variables, and up to 94.68 % MSE reduction with R-squared values of 0.983–0.995 for the smallest training datasets. This framework reduces design cycle times and enhances engineering design efficiency, offering a robust solution to limitations in traditional methods reliant on physical prototyping and iterative testing.},
  archive      = {J_EAAI},
  author       = {Agung Nugraha and Hyerin Kwon and Gyeongho Park and Jihwan Lee},
  doi          = {10.1016/j.engappai.2025.112453},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112453},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cooperative neural networks for inverse design: Integrating denoising autoencoder and surrogate model for partial design variable imputation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Region-based weighting-and-enhancement network with adaptive class weighting loss for postoperative inguinal hernia prediction. <em>EAAI</em>, <em>162</em>, 112451. (<a href='https://doi.org/10.1016/j.engappai.2025.112451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Postoperative inguinal hernia (PIH) is a common complication after radical prostatectomy, subsequently leading to multiple potential risks (e.g., cardiovascular and cerebrovascular accidents) and increased surgical costs due to re-surgical reparation. Magnetic resonance imaging (MRI) examination is a widely used procedure before radical prostatectomy, which can investigate the muscle structures of the abdominal wall (MSAW). Recently, clinical studies have indicated that clinical parameters (e.g., thickness and width of the external oblique muscle) of MSAW are strongly related to PIH. However, automated MRI-based PIH prediction based on deep neural networks has not been studied previously. Motivated by these observations, we propose a novel region-based weighting-and-enhancement network to predict PIH before radical prostatectomy based on MRI images automatically. Specifically, we employ the well-designed Region Weighting-and-Enhancement module to capture informative context representations through region weighting and regional context enhancement, by fully leveraging the potential of clinical MSAW priori. Additionally, this paper designs an effective adaptive class weighting loss to emphasize or suppress the samples with varying levels of significance to further boost the PIH prediction performance. The extensive experiments on a clinical MRI-PIH dataset and one publicly available MRI dataset manifest the superiority of our proposed methods over state-of-the-art deep neural networks and advanced loss methods.},
  archive      = {J_EAAI},
  author       = {Jiawei Zhang and Lisheng Wu and Qiang Fang and Weidong Yu and Zhengyu Hu and Fengyun Zhang and Cheng Yang and Xiaoqing Zhang},
  doi          = {10.1016/j.engappai.2025.112451},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112451},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Region-based weighting-and-enhancement network with adaptive class weighting loss for postoperative inguinal hernia prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach. <em>EAAI</em>, <em>162</em>, 112450. (<a href='https://doi.org/10.1016/j.engappai.2025.112450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanofluids have garnered significant research interest due to their enhanced heat transfer and thermal characteristics. A novel hybrid nanofluid has exhibited exceptional thermal properties, combining five nanoparticles of uniform shapes with a base fluid, such as blood. This study investigates the influence of fin thickness, varying with length, considering the implications of internal heat production, convection, and thermal radiation processes in rectangular, convex, and triangular fin descriptions. Wet scenarios are interpreted to evaluate differences in thermal energy dynamics for fin shapes like Rectangular, Convex and Triangular. Darcy's model is employed to account for the material's porous nature. A finite difference scheme, implemented using Partial Differential Equation solver (PDSolve) in Maple (2024), provides graphical insights into fin effectiveness and thermal steady-state responses across various parameters. Incorporating Penta hybrid nanofluids enhances fin performance, with rectangular fins' Nusselt numbers (up to 1.936) proving more efficient, delivering faster thermal responses than triangular fins and convex fins. Further, using the Adam Optimisation algorithm, Convolutional Neural Networks were used to validate the current model. It was observed that these networks could accurately forecast the truth values, and the two findings matched, as indicated in Table 3 As a potential biological application, this research offers insight into optimising cooling systems for biomedical devices, such as heat exchangers in artificial organs.},
  archive      = {J_EAAI},
  author       = {Maddina Dinesh Kumar and Nehad Ali Shah and Dharmaiah Gurram and Se-Jin Yook},
  doi          = {10.1016/j.engappai.2025.112450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the application of attention mechanism based multi-model fusion in food recommendation platforms. <em>EAAI</em>, <em>162</em>, 112449. (<a href='https://doi.org/10.1016/j.engappai.2025.112449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphone-based food ordering has greatly enhanced convenience in daily life, and the rise of recommendation systems has transformed the functionality and user experience of food delivery applications. Innovations in recommendation algorithms and models have significantly improved the efficiency of food, merchant, and advertisement recommendations on food platforms, leading to higher transaction rates and greater user satisfaction. To further enhance recommendation efficiency, this study introduces a novel multi-model fusion recommendation architecture based on the multi-head self-attention mechanism, utilizing a two-tier structure. The first-tier model (the attention-based homogeneous AutoInt model) acts as a teacher to guide the training of the second-tier Transformer model. This hierarchical approach integrates multiple models through knowledge distillation, significantly improving the accuracy of the recommendation system. The complexity and performance of the proposed architecture were analyzed and applied in a production environment. Testing on a private dataset reveals that the proposed multi-model fusion recommendation architecture significantly enhances recommendation performance across various food platform scenarios, achieving an accuracy of 0.7643, recall of 0.8262, and an F1 score of 0.7936. These results surpass the performance of current state-of-the-art models. Therefore, the proposed architecture is not only highly applicable to food recommendation systems but also has broad applicability in other fields such as retail and entertainment.},
  archive      = {J_EAAI},
  author       = {Linchao Zhang and Lei Hang},
  doi          = {10.1016/j.engappai.2025.112449},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112449},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on the application of attention mechanism based multi-model fusion in food recommendation platforms},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced multi-modal emotion recognition using the feature level fusion. <em>EAAI</em>, <em>162</em>, 112447. (<a href='https://doi.org/10.1016/j.engappai.2025.112447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal human emotion recognition is a complex process of synthesizing information from various modalities to calculate emotion states. This field faces several challenges: (1) Acoustic is an essential component of emotion expression, but it often underperforms compared to visual and text in emotion recognition. (2) Capturing the feature interaction among different modalities is usually complex. (3) Processing high-definition videos can significantly reduce the efficiency of visual analysis. In this study, we presented a learning architecture designed to recognize human emotions effectively. For the first challenge, we implemented a multi-level acoustic encoder (MLAE) that enhances the extraction of acoustic information to improve the acoustic contribution in multi-modal emotion recognition. Facing the second challenge, we introduced the cross-attention block module, which adeptly captures the inter-modal interactions. To address the third challenge, we adopted the re-parameterized visual geometry group network (RepVGG) as the visual feature encoder, employing its multi-branch learning and single-branch reasoning structure to maintain high reasoning efficiency. Our model has demonstrated the state-of-the-art performance of the interactive emotional dyadic motion capture (IEMOCAP) dataset and the multi-modal opinion sentiment and emotion intensity of the Carnegie Mellon University (CMU-MOSEI) dataset.},
  archive      = {J_EAAI},
  author       = {Aziguli Wulamu and Yuheng Wu and Xin Liu and Yao Zhang and Jinghan Xu and Yang Zhang},
  doi          = {10.1016/j.engappai.2025.112447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced multi-modal emotion recognition using the feature level fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection. <em>EAAI</em>, <em>162</em>, 112446. (<a href='https://doi.org/10.1016/j.engappai.2025.112446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—Permanent magnet synchronous motors (PMSMs) are widely used in industrial applications but remain vulnerable to stator faults, such as inter-coil and inter-turn short circuits. Although recent deep learning-based fault detection methods have shown promise, they typically rely on large volumes of labelled fault data for training. To address this limitation, this paper proposes a novel unsupervised fault detection framework, termed Deep Adaptive Wavelet Autoencoder (DAWA) with Mutually Independent Empirical Cumulative Distribution (MIECD), specifically designed for PMSM fault detection. DAWA utilizes convolutional neural networks to learn adaptive wavelet filters through fast discrete wavelet transform, allowing for fully learnable, threshold-free extraction of fine-grained signal patterns. The resulting latent features are then mapped by MIECD into a mutually independent space via independent component analysis (ICA). Without assuming any prior data distribution, MIECD estimates empirical cumulative distributions (ECDs), computes tail probabilities across dimensions, and aggregates them into a unified anomaly score. Experimental results on motor vibration datasets demonstrate the effectiveness of the proposed method, showing average accuracy improvements of 15.85 % for Interturn and 15.16 % for Intercoil fault detection compared to conventional data-driven baselines across various operating conditions.},
  archive      = {J_EAAI},
  author       = {Pinze Ren and Ning Zhu and Dandan Peng and Liyuan Ren and Huan Wang},
  doi          = {10.1016/j.engappai.2025.112446},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112446},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic vision-based machine vibration sensing and fault diagnosis with signal alignment and feature clustering. <em>EAAI</em>, <em>162</em>, 112445. (<a href='https://doi.org/10.1016/j.engappai.2025.112445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, intelligent fault diagnosis methods for machines have been widely developed. The contact accelerometer has been popularly used with high measurement accuracy. However, in many industrial applications, non-contact sensors are often preferred due to practical constraints. The event camera is a novel bio-visual sensing technology for asynchronously capturing pixel-wise changes in brightness. It has various advantages including high measurement rate, exceptional resolution, wide dynamic range, etc., which thus has promising prospects in non-contact monitoring and fault diagnostic tasks. Despite these advantages, the high complexity of the dynamic vision data from the event cameras poses significant processing challenges, and the extraction of machine vibration information is of great difficulties. To address these challenges, this paper proposes a novel dynamic vision-based machine vibration sensing and fault diagnosis method. First, the dynamic vision data is reconstructed into event frame sequences. Next, a deep neural network is proposed to extract the micro-vibration information with feature clustering for enhancing model robustness. A signal alignment method is further proposed where the contact sensing data are used as a reference for optimizing model performance. Finally, the intelligent fault diagnosis is implemented with the estimated vibration data. Experimental validations are conducted with real rotating machine data, which demonstrate the promising applicability of the proposed method in non-contact machine vibration sensing and fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Ruiyi Guang and Xiang Li and Yaguo Lei and Bin Yang and Naipeng Li},
  doi          = {10.1016/j.engappai.2025.112445},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112445},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic vision-based machine vibration sensing and fault diagnosis with signal alignment and feature clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention. <em>EAAI</em>, <em>162</em>, 112444. (<a href='https://doi.org/10.1016/j.engappai.2025.112444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health state prediction of Proton Exchange Membrane Fuel Cells (PEMFCs) is a critical technology to ensure their long-term reliable operation. Prediction accuracy directly influences the effectiveness of maintenance strategies and risk management. However, existing PEMFC degradation prediction methods based on Recurrent Neural Networks (RNNs) or Transformer architectures mostly focus on point estimation while neglecting uncertainty quantification. This limitation makes it difficult to assess the confidence level of predictions in practical engineering applications, reducing the models' reliability in decision support. To address this issue, this paper proposes a novel Bayesian Patch Time Series Transformer (B-PatchTST) method. By deeply integrating Bayesian variational inference with time series patch modeling, the method enables probabilistic prediction of PEMFC degradation trajectories and disentangled analysis of uncertainty sources. Unlike traditional Bayesian Neural Networks (BNNs) that primarily apply Bayesian modeling to fully connected layers, B-PatchTST introduces a Bayesian Self-Attention Mechanism, which models epistemic uncertainty in three stages: patch embedding, uncertainty-aware self-attention computation, and adaptive regularization. This design significantly enhances the credibility of the model. Extensive experiments on the fuel cell datasets demonstrate the proposed method's outstanding performance. It achieves an average reduction of 36.31 % in root mean square error and an average compression of 83.39 % in the 95 % confidence interval, significantly outperforming existing methods. This approach offers a trustworthy basis for predictive maintenance in PEMFC systems, promoting a shift from “experience-based maintenance” to “reliable prognostics” in hydrogen energy applications.},
  archive      = {J_EAAI},
  author       = {Mengyu Liu and Zhe Cheng and Yu Yang and Niaoqing Hu and Guoji Shen and Yi Yang},
  doi          = {10.1016/j.engappai.2025.112444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge computing and server-based high-precision flood level classification system. <em>EAAI</em>, <em>162</em>, 112442. (<a href='https://doi.org/10.1016/j.engappai.2025.112442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban flooding and the resulting road water accumulation have become a significant threat to public transportation safety and the stability of municipal infrastructure. Traditional monitoring networks based on physical water level sensors suffer from low deployment density, high maintenance costs, and lagging response times. To address these shortcomings of traditional water accumulation monitoring systems, this study proposes an edge-computing intelligent monitoring system based on collaborative inference between the edge end (You Only Look Once version 5, YOLOv5) and the server end (Transform Vision Detection, TrVDet). A dual-modal perception architecture of “edge-end triggering and server-end precise analysis” has been constructed. At the edge end, the YOLOv5 model is deployed on embedded devices to achieve efficient preliminary screening of water accumulation, reducing dependence on the central server, lowering latency, and enhancing real-time response capabilities. On the server end, multi-object segmentation is performed on the detected water accumulation images, including roads, cars, motorcycles, and bicycles. Finally, a series of logical judgments is applied to determine the water accumulation level based on reference objects within the water. Since there is no publicly available dataset for target object recognition in flooded areas, we employed professional annotators to perform pixel-level labeling on the collected and organized flood data and constructed a multi-class target flood dataset (City Flood Segmentation, CityFloodSeg). Given the scarcity of moderate and severe water accumulation samples, we optimized the instance segmentation model TrVDet under the (A Visual Representation for Neon Genesis, EVA-02) framework and applied five data augmentation methods, including Mosaic and Flip, to expand the diversity of the dataset. Moreover, based on domain expert standards, we designed a logical judgment rule algorithm for model inference of water accumulation levels to classify the levels of water accumulation. Experimental results show that the server-end processing delay is stable within 0.4 s, capable of accurately judging different water accumulation risk levels. This provides centimeter-level real-time situational awareness for urban flood control decision-making and promotes the development of intelligent municipal infrastructure towards higher reliability and universality.},
  archive      = {J_EAAI},
  author       = {Ankang Lu and Runlong Cao and Yuanbin Wang and Wenjun Hu and Yuncan Gao and Zhifeng Hu and Ying Zang},
  doi          = {10.1016/j.engappai.2025.112442},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112442},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Edge computing and server-based high-precision flood level classification system},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WeedNet-X: A lightweight field weed detection algorithm. <em>EAAI</em>, <em>162</em>, 112441. (<a href='https://doi.org/10.1016/j.engappai.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately distinguishing field weeds from crops and locating weed positions are critical prerequisites in automated weed control operations. However, weed detection and localization in unstructured field environments with complex lighting remains challenging. Firstly, data-driven deep learning based algorithms usually have a high dependence on a large number of training samples, and there are huge differences between field weeds and crops in different regions, growth cycles, and types. In addition, the conflict between hardware performance and computation cost makes it difficult for existing weed detection algorithms to maintain both detection accuracy and speed on low-performance platforms. All these problems increase the difficulty of detection. To solve the above problems, we first construct a medium-to-large weed dataset using an open-source agricultural image dataset and collect field data. Subsequently, we have proposed a lightweight weed detection algorithm using the ShuffleNetv2 network as the backbone network, with a multi-scale pyramid network, and the overall network algorithm is named WeedNet-X. The number of model parameters and the computational volume of the algorithm are only 0.57 million and 0.48 Giga floating point operations (GFLOPs), respectively. On the two constructed datasets, the mean Average Precision (mAP) of the algorithm can reach 86.31 % and 80.98 %, respectively, which are improved by 0.61 % and 3.10 % compared to the baseline model. Finally, the hardware and software systems for weed detection verify the excellence of the proposed algorithm in terms of practical performance.},
  archive      = {J_EAAI},
  author       = {Yong Li and Ao Ke and Zhiqiang Guo and Qingji Tan and Jingchao Yang},
  doi          = {10.1016/j.engappai.2025.112441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WeedNet-X: A lightweight field weed detection algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts. <em>EAAI</em>, <em>162</em>, 112440. (<a href='https://doi.org/10.1016/j.engappai.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent human-made conflict in 2022 severely damaged Ukraine's infrastructure, causing significant instability in the food supply chain. This crisis was further exacerbated by trade bans imposed on another major global wheat exporter. Since wheat production and export are intrinsically linked, particularly in times of crisis, it is essential to adopt the concept of an intertwined supply chain. Accordingly, this study proposes an intertwined supply chain framework for the production and export of wheat during long-term disruptions. To enhance the viability of this intertwined system, the study introduces three key strategies. First, it addresses long-term disruptions and operational risks by employing redundancies and data-driven robust optimization techniques, where uncertainty sets are generated using a support vector clustering model. Second, the proposed supply chain accounts for freshwater resource limitations by integrating water resilience measures. Third, as the framework operates within a global context, it incorporates a comprehensive model that considers exchange rates, taxation, foreign demand points, and international trade responsibilities. To optimize these strategies, two multi-objective optimization models are developed and solved using an epsilon-constraint method. A cardinality-based measure is introduced to efficiently represent the Pareto front, offering decision-makers valuable insights into non-dominated solutions. The results are divided into analyses of wheat production, export, and their combined network. Individual analyses assess network setup, viability, and uncertainty control, while the integrated analysis examines sensitivity and interdependence. Overall, improving water use, managing risks, and designing a resilient, interconnected system can greatly strengthen the wheat supply chain during long-term crises.},
  archive      = {J_EAAI},
  author       = {Hani Gilani and Mehrdad Mohammadi and Tom Van Woensel and Hadi Sahebi},
  doi          = {10.1016/j.engappai.2025.112440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multitask learning-based fault detection approach for high impedance fault in resonant distribution networks. <em>EAAI</em>, <em>162</em>, 112439. (<a href='https://doi.org/10.1016/j.engappai.2025.112439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing high impedance faults (HIF) in resonant distribution networks remains a formidable challenge. This paper introduces a multitask learning-based approach integrated with a multitask fault detection network (MTFD-Net), employing three task-specific heads—classification, segmentation, and regression—to enable precise fault detection. MTFD-Net utilizes zero-sequence voltage data and a sliding time window to perform initial coarse classification, which allows the classification head to determine whether a permanent HIF has occurred. Upon detection, MTFD-Net proceeds to pinpoint potential fault moments through the outputs of the segmentation head. The regression head further refines these moments by predicting a reference moment and calculating the distance to each potential fault, effectively isolating the exact fault moment. An industrial prototype was developed and rigorously tested on a 10 kV system, where MTFD-Net demonstrated superior performance, achieving an accuracy of 0.976, an intersection over union of 0.984, and an absolute detection deviation of 5.20 ms. Operating efficiently with inference times ranging from 9.69 to 15.45 miliseconds on a Raspberry Pi 4B, MTFD-Net surpasses existing methods in accuracy, F1-score, sensitivity, specificity, and detection accuracy, providing a robust solution for HIF detection in resonant distribution networks.},
  archive      = {J_EAAI},
  author       = {Jian-Hong Gao and Mou-Fa Guo and Shuyue Lin and Duan-Yu Chen},
  doi          = {10.1016/j.engappai.2025.112439},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112439},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multitask learning-based fault detection approach for high impedance fault in resonant distribution networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network. <em>EAAI</em>, <em>162</em>, 112438. (<a href='https://doi.org/10.1016/j.engappai.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of carbon trading prices (CTPs) with spikes is crucial for developing carbon emission reduction policies and planning corporate investments. However, most existing CTP approaches usually focus on designing a cutting-edge model without considering spike prediction. Therefore, this paper presents a novel heuristic optimization-based hybrid model framework for CTP prediction with spikes. First, random forest is exploited to identify the relevant features of spikes and non-spikes for CTPs, and categorical boosting is employed to predict the spike occurrences of CTPs. Then, a novel hybrid model based on multiple linear regression, categorical boosting, and two dimensions convolutional neural network and bidirectional gated recurrent unit with multi-head regularized attention mechanism (2DCNN-BiGRU-MRA) is proposed to predict spikes and non-spikes for CTPs. In this model, multiple linear regression and categorical boosting are respectively applied to capture the linear and complex nonlinear features of the CTPs, in which their prediction results and deviations are integrated into the 2DCNN-BiGRU-MRA model as relevant features. The proposed 2DCNN-BiGRU-MRA can learn the spatiotemporal features and enhance representation capabilities by introducing 2DCNN, BiGRU, and MRA, thereby improving the accuracy of CTP prediction. In addition, to construct appropriate model hyperparameters of 2DCNN-BiGRU-MRA, the strength honey badger algorithm based on the adaptive momentum estimation is proposed to optimize the hyperparameters of 2DCNN-BiGRU-MRA. Finally, the proposed framework is tested on the actual data of European Union emissions trading and the carbon market in Hubei, China, and case studies have confirmed the superiority and achievable local interpretability of the proposed hybrid model framework.},
  archive      = {J_EAAI},
  author       = {Rongquan Zhang and Siqi Bu and Gangqiang Li and Min Zhou},
  doi          = {10.1016/j.engappai.2025.112438},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112438},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-graph and intra-graph: Utilizing global financial markets and constituent stocks for stock index prediction. <em>EAAI</em>, <em>162</em>, 112437. (<a href='https://doi.org/10.1016/j.engappai.2025.112437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock index prediction is a significant yet difficult undertaking due to its incorporation of complex and diverse information. Following the implementation of Graph Neural Networks in financial data analysis, numerous researchers have focused on the node-level task of forecasting individual stock movements by analyzing the relationships between stocks. However, two key challenges remain: first, realizing different speeds of feature propagation among nodes in graph representation learning; second, predicting stock indices by extracting and aggregating fluctuations from constituent stocks through graph-level tasks remains unaddressed. To tackle these challenges, this paper proposes a novel spatio-temporal prediction framework combining both node-level and graph-level tasks. The framework includes two types of graphs: inter-graph and intra-graph, which combine information from the micro, meso, and macro dimensions. For the inter-graph at the node level, we introduce the Granger causality test as an innovative node filtering method, which realizes the propagation of features between nodes with different strengths and speeds in the process of graph representation learning. For the intra-graph at the graph level, we examine various graph pooling methods and pooling proportions of stock index constituents to enhance the interpretability of the results and to provide new theoretical insights for stock index prediction. In conclusion, we develop the Graph Representation Learning-based Long Short-Term Memory (GRL-LSTM) model for forecasting stock index movements, and demonstrate the superiority of our approach on four major Chinese stock markets.},
  archive      = {J_EAAI},
  author       = {Yong Shi and Yunong Wang and Jie Wu},
  doi          = {10.1016/j.engappai.2025.112437},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112437},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inter-graph and intra-graph: Utilizing global financial markets and constituent stocks for stock index prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-efficient double deep Q-network framework for intelligent financial portfolio management. <em>EAAI</em>, <em>162</em>, 112436. (<a href='https://doi.org/10.1016/j.engappai.2025.112436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigating the complexities of dynamic and uncertain financial markets demands intelligent systems capable of learning profitable strategies amidst risk and volatility. While Deep Q-Networks (DQN) offer a foundation for such systems, they often suffer from overestimation bias, training instability, and poor generalization in noisy financial environments. To address these challenges, this work introduces Portfolio Double Deep Q-Network (PDQN), a novel architecture inspired by recent advancements in reinforcement learning. PDQN enhances portfolio management by integrating Double Q-Learning to reduce overestimation, alongside Leaky ReLU activation, Xavier initialization, Huber loss, and dropout regularization to improve learning stability and generalization. Unlike prior methods that rely on large datasets and heavy computational infrastructure, PDQN achieves competitive—and often superior—performance using substantially less training data and lightweight infrastructure, making it well-suited for real-world, resource-constrained financial applications. Distinct from conventional approaches, PDQN uses separate networks to adapt portfolio decisions across varying market conditions. Empirical results across multiple market years show that PDQN often outperforms baseline strategies, including classic DQN and Buy-and-Hold, across key metrics such as Sharpe ratio, Sterling ratio, and cumulative return. PDQN—like all data-driven models—exhibits room for improvement under highly irregular or extreme financial scenarios. These observations suggest promising directions for future refinement and increased robustness, without detracting from the model's practical effectiveness and competitive edge.},
  archive      = {J_EAAI},
  author       = {Mahshad Alidousti and Morteza Khakzar Bafruei and Amir Hosein Afshar Sedigh},
  doi          = {10.1016/j.engappai.2025.112436},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112436},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel data-efficient double deep Q-network framework for intelligent financial portfolio management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking few-shot wind speed prediction through a novel end-to-end transfer learning paradigm based on decomposition and gating information fusion. <em>EAAI</em>, <em>162</em>, 112435. (<a href='https://doi.org/10.1016/j.engappai.2025.112435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind speed prediction is one of the key technologies for achieving intelligent and sustainable development in the engineering field. In the field of wind speed prediction, we are confronted with a challenging few-shot prediction problem. Specifically, due to the fact that some wind turbines in wind farms are newly established or there is data loss during the data collection process, these turbines only contain a small amount of wind speed data. This scarcity of data poses great difficulties for the prediction work, and traditional prediction methods often fail to achieve the desired prediction accuracy. In order to overcome the above difficulties, we propose an novel prediction paradigm of end-to-end transfer learning based on data decomposition and gated information fusion. We use the Fourier transform to find the source domain similar to the target domain to achieve feature alignment. Then, we pre-train the model on the source domain and transfer this model to the target domain, thus solving the problem of low prediction accuracy when directly predicting the target domain. In the first step, the data is decomposed and denoised by using the Variational Mode Decomposition. According to the sample entropy, the decomposed data is reorganized into three frequency components. Each component is input as an independent channel into the end-to-end prediction model. Firstly, the features of each channel are expanded to a high-dimensional space through the Multilayer Perceptron. Then, the gating mechanism is utilized to mix the features of the three channels into the features of one channel, thus achieving information fusion. Finally, the prediction result of the end-to-end model is output through the Gated Recurrent Unit. In the second step, the model pre-trained on the source domain is transferred to the small-sample target domain. The Dynamic Time Warping and cosine similarity are used to quantify the similarity of each channel between the two domains. The parameters of the channels with high similarity are locked, and at the same time, the parameters of other channels are fine-tuned to output the final prediction result. In addition, multiple sets of comparative experiments conducted using the wind speed data from wind farms in Queensland, Australia, have demonstrated the superiority of this prediction paradigm. Our strategy outperforms various baseline models in all three sets of data. Moreover, ablation experiments have proven the effectiveness of each component in this framework in improving prediction accuracy, opening up a new path for solving the difficult problem of few-shot prediction in practical engineering.},
  archive      = {J_EAAI},
  author       = {Xiaoyue Dong and Zhirui Tian},
  doi          = {10.1016/j.engappai.2025.112435},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112435},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unlocking few-shot wind speed prediction through a novel end-to-end transfer learning paradigm based on decomposition and gating information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hyperparameter-fusion neural networks for deposition prediction. <em>EAAI</em>, <em>162</em>, 112434. (<a href='https://doi.org/10.1016/j.engappai.2025.112434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As integrated circuit manufacturing processes develop into the nanometer scale, precise control and prediction of the deposition process have become crucial. Nanoscale manufacturing imposes unprecedentedly high demands on film quality, uniformity, and consistency, presenting significant challenges to traditional control and prediction methodologies. This study proposes a novel approach that, for the first time, formulates the thin-film deposition process as a video prediction task, enabling the use of deep learning for morphological forecasting under varying process conditions, and introduces a novel hyperparameter-fusion neural network, referred to as DepositionNet (DepoNet). Unlike conventional video prediction models, DepoNet specifically accounts for the influence of deposition parameters on the entire simulation process. We have incorporated a novel Hyper Projector that allows the model to flexibly adapt to varying deposition conditions and material characteristics. Through comprehensive comparative experimental analyses, we demonstrate that DepoNet significantly outperforms existing deep-learning models and achieves a mean squared error of 17.34, representing a 3.67% improvement over the second best model and a 1,435 × speedup over physics-based methods, thereby validating its exceptional generalization capability. Extensive experiments reveal that the model maintains high performance even under conditions of limited training data, for instance, achieving a peak signal-to-noise ratio (PSNR) of 41.516 decibels (dB) when trained with only 20% of the available data.},
  archive      = {J_EAAI},
  author       = {Li Ding and Kun Pang and Junjie Li and Hua Shao and Nan Liu and Rui Chen and Zhiqiang Li and Zhenjie Yao and Ling Li},
  doi          = {10.1016/j.engappai.2025.112434},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112434},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hyperparameter-fusion neural networks for deposition prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming challenges in leveraging blockchain technology: Entropy-based q-rung orthopair fuzzy model for benchmarking application barriers. <em>EAAI</em>, <em>162</em>, 112433. (<a href='https://doi.org/10.1016/j.engappai.2025.112433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has emerged as a transformative solution across industries, delivering enhanced transparency, security, and operational efficiency. Nevertheless, its adoption remains hindered by significant challenges, especially in complex, data-intensive domains such as logistics. This study introduces a novel integration of the entropy-based q-rung orthopair fuzzy compromise ranking of alternatives from distance to ideal solution (CRADIS) approach to systematically evaluate and prioritize key barriers to blockchain adoption. The innovation of this work lies in applying q-rung orthopair fuzzy sets which are particularly capable of handling higher degrees of uncertainty and hesitancy, and then integrated with entropy for objective criterion weighting and CRADIS for robust decision-making. A real-world case study is presented, involving five critical barriers, lack of legal and regulatory frameworks, high implementation costs, technological scalability issues, data privacy and security concerns, and cultural resistance to change evaluated against eight decision criteria. The entropy weighting revealed regulatory clarity (0.168) and security (0.154) as the most influential factors, while the CRADIS ranking identified a lack of legal frameworks as the top barrier. This framework provides a transparent, data-driven method for decision-makers to identify and prioritize adoption challenges, particularly in uncertain and multi-faceted environments. By demonstrating the model’s applicability and precision, the study contributes to the emerging body of literature on blockchain integration and supports organizations in navigating the transition towards decentralized technologies.},
  archive      = {J_EAAI},
  author       = {Sana Shahab and Naoufel Kraiem and Ashit Kumar Dutta and Mohd Anjum and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112433},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112433},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Overcoming challenges in leveraging blockchain technology: Entropy-based q-rung orthopair fuzzy model for benchmarking application barriers},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual angle magnetic arc blow estimation in keyhole tungsten inert gas welding using high dynamic range imaging and a lightweight vision transformer network with coordinate attention and multiple auxiliary branches. <em>EAAI</em>, <em>162</em>, 112432. (<a href='https://doi.org/10.1016/j.engappai.2025.112432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high current Keyhole Tungsten Inert Gas (K-TIG) welding, magnetic arc blow frequently causes severe defects such as lack of fusion and undercut, which seriously affect weld formation quality. Conventional visual sensing systems are limited by dynamic range, making it difficult to capture arc morphology, while single angle descriptors fail to represent nonlinear deflection and lightweight convolutional models struggle with long range dependencies. To address these challenges, this study employs a High Dynamic Range (HDR, 120 decibel [dB]) imaging system to capture detailed arc variations and proposes a lightweight Vision Transformer (ViT) network with embedded Coordinate Attention (CA) and multiple auxiliary branches for real time angle estimation. A custom magnetic excitation system enables controllable arc blow simulation and consistent data acquisition. The method introduces a dual angle representation, namely the maximum curvature angle ( θ curv ) and the equivalent deviation angle ( θ eq ), to comprehensively describe arc geometry. The Artificial Intelligence (AI) framework integrates segmentation, keypoint localization, and regression tasks to improve accuracy and robustness. Trained on a self constructed HDR dataset containing 3,191 annotated images, model achieves a mean absolute error (MAE) of 1 . 12 ° , a root mean square error (RMSE) of 2 . 84 ° , a determination coefficient ( R 2 ) of 0.96, and a per frame inference latency of 12.96 ms (ms) on an NVIDIA RTX 2080Ti graphics processing unit (GPU). These results demonstrate that AI based methods combined with HDR imaging cannot only achieve accurate monitoring of welding arc states, but also provide potential support for closed loop control in all position welding applications.},
  archive      = {J_EAAI},
  author       = {Xiyin Chen and Xiaohu Zhang and Yonghua Shi and Yuxiang Huang and Junjie Pang},
  doi          = {10.1016/j.engappai.2025.112432},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112432},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual angle magnetic arc blow estimation in keyhole tungsten inert gas welding using high dynamic range imaging and a lightweight vision transformer network with coordinate attention and multiple auxiliary branches},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A diffusion model using semantic and sketch information for anomaly detection. <em>EAAI</em>, <em>162</em>, 112430. (<a href='https://doi.org/10.1016/j.engappai.2025.112430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In anomaly detection, methods that employ diffusion models for anomaly localization and reconstruction have demonstrated significant achievements. However, these methods face challenges such as the misclassification of multiple types of anomalies and the inability to effectively reconstruct large-scale anomalies due to the absence of semantic and sketch information from the original images. To tackle these challenges, we propose a framework, A Diffusion Model using Semantic and Sketch Information for Anomaly Detection (DSAD), which includes a semantic and sketch-guided network (SSG), a pre-trained autoencoder, and Stable Diffusion (SD). Initially, within SSG, we introduce a Semantic & Sketch Feature Fusion Module to enhance the model’s comprehension of the original images and present a Multi-scale Feature Fusion Module to maximize reconstruction accuracy. Subsequently, we connect SSG with the denoising network in SD in order to guide the network in reconstructing anomalous regions. Experiments on MVTec-AD dataset demonstrate the effectiveness of our approach which surpasses the state-of-the-art methods. The dataset and code are available at https://github.com/QinLi-STUDY/DSAD/tree/master .},
  archive      = {J_EAAI},
  author       = {Li Qin and Zhenyu Yin and Feiqing Zhang and Chunhe Song and Xiaoqiang Shi},
  doi          = {10.1016/j.engappai.2025.112430},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112430},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A diffusion model using semantic and sketch information for anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time spatiotemporal error compensation framework for face gear grinding. <em>EAAI</em>, <em>162</em>, 112429. (<a href='https://doi.org/10.1016/j.engappai.2025.112429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric and thermal errors critically affect the precision of face gear grinding, yet current modeling approaches are computationally intensive and lack real-time adaptability. This study proposes a real-time spatiotemporal error compensation framework for face gear grinding. A closed-loop feedback mechanism is introduced to adaptively update compensation intensity based on residual error feedback, ensuring robustness and efficiency under fluctuating machining conditions. Moreover, a novel spatial-temporal thermal error model is developed by integrating Taylor-graph convolutional network and modified-long short term memory network to capture both node-level spatial fusion and long-term temporal dependencies. High-order terms in geometric error modeling are eliminated using a vector decomposition and truncation-based approach, significantly reducing computational complexity. Furthermore, a high-efficiency multi-source error-tooth flank mapping model is developed based on vector decomposition and truncation function methods, enabling accurate prediction with reduced computational cost. To identify dominant error contributors, an improved Morris-based sensitivity analysis method is integrated, distinguishing geometric and thermal errors affecting tooth flank deviation. Experimental results demonstrate sub-65 ms real-time response, 24.2 μm maximum error reduction, and robust adaptability under fluctuating machining conditions. Compared with recent gear-flank compensation studies, the proposed closed-loop framework achieves a 63.4 % reduction in maximum normal flank error under real machining and <65 ms response latency. This level is comparable to reported reductions based on grid-aggregated metrics in spiral bevel gears (76.82 % reduction of the sum of absolute grid errors), while additionally ensuring real-time, delay-aware execution. These findings validate the proposed system's potential for precision, real-time compensation in multi-axis manufacturing environments.},
  archive      = {J_EAAI},
  author       = {Jialan Liu and Chi Ma and Mingming Li and Jialong He and Giovanni Totis and Chunlei Hua and Gangwei Cui and Liang Wang and Ruijun Xue and Zhi Tan and Jun Yang and Kuo Liu and Yuansheng Zhou and Jianqiang Zhou and Xiaolei Deng and Shengbin Weng},
  doi          = {10.1016/j.engappai.2025.112429},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112429},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time spatiotemporal error compensation framework for face gear grinding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilayer perceptron-based offspring prediction model for constrained multi-objective optimization. <em>EAAI</em>, <em>162</em>, 112428. (<a href='https://doi.org/10.1016/j.engappai.2025.112428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems generally have both multiple constraint violations and conflicting objective functions. Some of them not only have sparse feasible regions, but also are difficult to converge. For these problems, the evolutionary operators used in traditional constrained multi-objective evolutionary algorithms (CMOEAs) are difficult to generate solutions with ideal quality. Therefore, this paper proposes a multilayer perceptron-based offspring prediction model for constrained multi-objective optimization (MOPCMO). Specifically, an evolutionary direction guidance strategy is designed that utilizes historical populations as training data to train a multilayer perceptron, which guides the evolution of the population by predicting and generating offspring, thereby improving the overall evolutionary efficiency of the algorithm. In addition, as the population iterates, evolutionary direction guidance strategy adaptively transforms the training data of multilayer perceptron. Finally, the multilayer perceptron is intermittently updated and uses an evolutionary direction guidance strategy to generate promising offspring, guiding the algorithm to achieve efficient search. Compared with seven state-of-the-art CMOEAs on 33 benchmark test problems and 8 engineering application problems, MOPCMO achieves excellent performance.},
  archive      = {J_EAAI},
  author       = {Qianlong Dang and Ruihuan Luo and Linlin Xie and Xiaochuan Gao and Weiting Bai},
  doi          = {10.1016/j.engappai.2025.112428},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112428},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multilayer perceptron-based offspring prediction model for constrained multi-objective optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis via multi-sensor fusion with auxiliary contrastive learning and phased fine-tuning. <em>EAAI</em>, <em>162</em>, 112427. (<a href='https://doi.org/10.1016/j.engappai.2025.112427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, deep learning-based fault diagnosis models fail to fully utilize the potential information in large amounts of normal state data and encounter difficulties when learning from limited fault samples. To address these challenges, this study proposes an auxiliary contrastive learning framework designed for multi-sensor data. The framework incorporates auxiliary classifiers after each sensor-specific branch to enhance feature representation, and enables model pretraining using only normal condition data. In addition, a phased fine-tuning strategy is developed, which combines full-model fine-tuning with lightweight adapter tuning to improve the adaptability of the fine-tuning process. A novel multi-sensor data augmentation technique is also introduced to enrich the contrastive learning tasks by generating structurally diverse negative samples. By enabling the effective utilization of normal condition data in model training, the proposed framework offers a new perspective for fault diagnosis applications. Experimental results on three benchmark datasets demonstrate that the proposed method significantly improves the generalization capability of the pre-trained model. Furthermore, the phased fine-tuning strategy exhibits high adaptability to the target tasks. Compared to other data fusion methods, the proposed auxiliary contrastive learning framework achieves notable performance advantages.},
  archive      = {J_EAAI},
  author       = {Yulin Jin and Xiaochuan Luo and Xiangwei Kong and Yulin Zhang},
  doi          = {10.1016/j.engappai.2025.112427},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112427},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis via multi-sensor fusion with auxiliary contrastive learning and phased fine-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting. <em>EAAI</em>, <em>162</em>, 112426. (<a href='https://doi.org/10.1016/j.engappai.2025.112426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To optimize joint performance, a finite element (FE) model is developed based on low-cycle reciprocating load tests of latticed concrete-filled steel tubular (CFST) column-composite box girder joints. The FE-predicted hysteresis curves are compared with test results to verify model accuracy, and a data set is established accordingly. Extreme Gradient Boosting (XGBoost) algorithm is used for training and prediction, and compared with the traditional machine learning (ML) algorithm, the superiority of the XGBoost algorithm is manifested. The XGBoost algorithm is then used to predict the damage and energy values of the joint under more different parameter combinations, with the largest ratio of damage value to energy dissipation value selected as the optimal combination of the joints within the variation range of the six parameters. The results show that the FE model correlates well with the test results and can therefore be used to generate a data set. The prediction accuracy of XGBoost algorithm has high accuracy of more than 99 % in predicting damage and energy dissipation values and can thus be used for joint prediction research. Compared with other ML algorithms, XGBoost has the best prediction performance and superiority. Within the variation range of the six parameters, the ratio of damage value to energy dissipation value is the largest when the concrete strength, longitudinal bar diameter, concrete slab thickness, box girder strength, axial compression ratio, and transverse stiffener strength are respectively 30 Mega Pascal (MPa), 12 mm (mm), 90 mm, 390 MPa, 0.3, and 455 MPa.},
  archive      = {J_EAAI},
  author       = {Zhi Huang and Xin Deng and Juan Chen and Xiang Li and Lizhong Jiang and Yohchia Frank Chen and Yuner Huang and Lin Chen},
  doi          = {10.1016/j.engappai.2025.112426},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112426},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional feature fusion network design and performance optimisation for small target detection. <em>EAAI</em>, <em>162</em>, 112425. (<a href='https://doi.org/10.1016/j.engappai.2025.112425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the long distance of image acquisition, high imaging resolution, complex feature background, shooting angle, etc. The result is that there are few features available for small targets and they are easily interfered by background noise, which poses a challenge to the detection of small targets. To address the above problems, this paper proposes a target detection network (Convolution-based Small Target Detection Network, CSTDNet) with enhanced feature information, which integrates a multi-dimensional information fusion strategy for small target features. An all-round efficient feature fusion mudule (AeFusion) is introduced, which emphasises the fusion of multi-dimensional feature information, enhances the model's ability to focus on key information and suppress redundant information, and strengthens the ability to characterise local features and details, improving the effectiveness of the information and computational efficiency. In order to further enhance the location-awareness capability in cross-layer interaction, this paper introduces a novel decoupling head (Self-aware task decomposition for fine-grained feature sharing, STFS), which improves the accuracy of the small-target classification and localisation tasks through efficient detail sharing and task auto-alignment functions. And localisation tasks through efficient detail sharing and task auto-alignment. This study evaluates the effectiveness of the algorithm on five different scenarios containing small target datasets. Experimental results show that CSTDNet achieved improvements of 6.6 %, 5.8 %, 5.8 %, 5.5 %, and 5.6 % over the baseline model in terms of the mean average precision (mAP@0.5) metric on the Visdrone 2019, BDD100K, WiderPerson, SODA10M, and AppleDatas datasets, respectively, demonstrating stronger detection performance.},
  archive      = {J_EAAI},
  author       = {Xiaoyao Yang and Wenyang Zhao and Pengchao Sun and Wenda Zhao and Wenlong Yang},
  doi          = {10.1016/j.engappai.2025.112425},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112425},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-dimensional feature fusion network design and performance optimisation for small target detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions. <em>EAAI</em>, <em>162</em>, 112423. (<a href='https://doi.org/10.1016/j.engappai.2025.112423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is a critical technique for enhancing the reliability and security of rotating machinery. Existing diagnosis methods still have restricted generalization performance under speed variations owing to inadequate utilization of multisensor information. To address this problem, a novel feature-decision dual fusion network is proposed for fault diagnosis of rotating machinery under varying speed conditions. First, for each sensor, the frequency information learner is built to simultaneously extract global and local frequency domain features using global and local feature encoders. These features are then fused through a cross-attention mechanism to generate a sensor-specific initial classification decision. Subsequently, these individual sensor-wise decisions are fed into the decision dynamic ensemble to yield final fault diagnosis result. Moreover, an adaptive optimization strategy is designed to guide model learning generalizable features by flexibly adjusting the sensor loss weights during training. Finally, the effectiveness of the proposed method is validated on bearing and gearbox datasets. Experimental results demonstrate that the proposed method exhibits superior generalization and robustness for fault diagnosis under varying speed conditions.},
  archive      = {J_EAAI},
  author       = {Qi Deng and Zuoxiu Zhang and Xuyuan Tu and Zimuzhi Wang and Jun Wu},
  doi          = {10.1016/j.engappai.2025.112423},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112423},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource-efficient cross-subject emotion recognition from electroencephalogram via spiking domain discriminators. <em>EAAI</em>, <em>162</em>, 112422. (<a href='https://doi.org/10.1016/j.engappai.2025.112422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time emotion recognition poses a significant challenge in electroencephalogram (EEG) based emotion recognition, as it requires the immediate processing of EEG data. This necessity imposes substantial demands on the model’s resource consumption. To address this issue, this paper introduces a novel approach to EEG emotion recognition using a Cross Domain Spiking Convolutional Network (CDSCN), focusing on developments in the design of the spiking convolutional block. To address individual differences, the CDSCN incorporates Z-Score normalization at the feature level and introduces a spiking domain discriminator at the model level. These innovations aim to mitigate variations in data distribution across individuals and domains, thereby enhancing the model’s robustness and generalizability. Additionally, the CDSCN introduces a novel pooling fusion layer within the spiking convolutional block to optimize computational efficiency while preserving discriminative performance. Experimental evaluations on two publicly available datasets validate the effectiveness of the proposed CDSCN in achieving both accurate and generalized emotion recognition.},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Shengyao Huang and Yujun Shen and Zhe Wang},
  doi          = {10.1016/j.engappai.2025.112422},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112422},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resource-efficient cross-subject emotion recognition from electroencephalogram via spiking domain discriminators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning based solar cells defect detection using electroluminescence images. <em>EAAI</em>, <em>162</em>, 112421. (<a href='https://doi.org/10.1016/j.engappai.2025.112421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar cells are the fundamental core energy harvesting components in photovoltaic (PV) power generation stations. In view of the capability of detecting the invisible defects, the electroluminescence (EL) imaging is broadly used in the production lines of solar cells, based on which the deep learning technique is introduced to implement automatic defect detection and classification. However, the current deep learning models feature high complexity and require much computation resources, which are difficult to deploy in edge devices for real time applications. To tackle this issue, we proposed a novel lightweight and high-precision deep learning model named Cross Stage Partial Photovoltaic-You Only Look Once (CSPV-YOLO) based on the deep learning framework You Only Look Once v5 (YOLOv5) to enable the real-time solar cell defect detection. Firstly, a new module Cross Stage Partial C5 (CSPC5) is proposed to replace the initial C3 module in the YOLOv5 network to enhance the network accuracy in recognizing different types of defects. Secondly, a novel Spatial Pyramid Pooling with Cross Stage Partial (SPPFCSP) module is designed to replace the original Spatial Pyramid Pooling Fast (SPPF), which boosts the network feature extraction capabilities from defect targets at multiple scales and facilitates a more efficient integration of multiscale features. Finally, the original loss function of YOLOv5 is replaced by the Scylla intersection over union (SIoU) function to optimize the training model. The proposed models have been validated and intensively compared with many other state-of-the-art models on two public datasets. Firstly, results of experiments on the public Pascal Visual Object Classes (PASCAL VOC) 2007 datasets demonstrate that the proposed SPPFCSP block is obviously superior to other Spatial Pyramid Pooling blocks for the most state-of-the-art YOLO detectors, which can significantly improve the detection accuracy. The comparison results of experiments on the public Photovoltaic Electroluminescence Anomaly Detection Dataset (PVEL-AD) that includes 12-class defects obviously indicate that the proposed CSPV-YOLO model is better than many state-of-the-art models and achieves 91.5 % average precision (AP) and frames per second (FPS) of 177.8 on with only 2.2 million (M) parameters. Hence, it is suitable for the deployment on edge devices for real-time applications.},
  archive      = {J_EAAI},
  author       = {Zhicong Chen and Tianxiang Chen and Haoxin Zheng and Lijun Wu and Shuying Cheng and Peijie Lin},
  doi          = {10.1016/j.engappai.2025.112421},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112421},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight deep learning based solar cells defect detection using electroluminescence images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A streaming variable neural speech codec. <em>EAAI</em>, <em>162</em>, 112418. (<a href='https://doi.org/10.1016/j.engappai.2025.112418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a variable bit rate streaming neural speech codec designed for ultra-low bit rate scenarios, based on the SoundStream network framework. The codec employs the vector quantized variational auto-encoder (VQ-VAE) algorithm to capture the temporal structure and spectral characteristics of the speech signal, and constructs a latent space codebook to facilitate the effective mapping of feature vectors to discrete vectors. Based on the harmonic characteristics of speech signals and the inherent defects of single-scale discriminators, we introduce multi-period discriminators and multi-scale discriminators. The training process uses a balanced training strategy to ensure the balance between codebook utilization and training weights, and utilizes the Short-Time Fourier Transform (STFT) spectrum that can provide more accurate time–frequency resolution to compute the reconstruction loss. We introduce codebook loss to improve the utilization rate of the codebook and accelerate the convergence of the model. In the inference process, we use a quantizer selection strategy to achieve adaptive adjustment of variable bitrate. Objective and subjective experiments demonstrate that our proposed new neural speech codec outperforms traditional classical speech codecs and existing neural speech codecs in terms of reconstructed speech naturalness and quality while maintaining the low latency characteristic of neural speech codecs. With a multi-stimulus test with hidden reference and anchor (MUSHRA) score of 87, it is highly suitable for ultra-low bit rate speech compression applications such as satellite speech communication and narrowband instant messaging. The demo has been publicly released at https://svcodec.github.io/ .},
  archive      = {J_EAAI},
  author       = {Huaifeng Zhang and Pengfei Wu and Guigeng Li and Yuan An and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112418},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112418},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A streaming variable neural speech codec},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates. <em>EAAI</em>, <em>162</em>, 112416. (<a href='https://doi.org/10.1016/j.engappai.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Light Guide Plate-DETR (LGP-DETR), an end-to-end object detection model tailored for identifying surface defects in light guide plates (LGPs). To address challenges such as low contrast, small target size, and complex backgrounds in industrial settings, LGP-DETR integrates three key components: Deformable Transformer Fusion Layer (DtransFusion), a deformable attention-based fusion module for capturing multi-scale features; Upsampling by Dynamic Sampling (DySample), a dynamic upsampling strategy for edge detail preservation; and OrthoC3, a channel attention module that suppresses background noise through orthogonal feature enhancement. We adopt FasterNet as a lightweight convolutional backbone to achieve a balance between accuracy and efficiency. Experimental results on a real-world LGP defect dataset demonstrate that LGP-DETR achieves a mean Average Precision (mAP) of 97.9 % and inference speed of 60 frames per second (FPS), significantly outperforming existing models. Furthermore, generalization tests on a fiberglass fabric defect dataset confirm the model's adaptability to different industrial domains. These findings validate the practical applicability and robustness of the proposed deep learning framework for industrial visual inspection.},
  archive      = {J_EAAI},
  author       = {Shuangning Liu and Cunling Liu and Junfeng Li},
  doi          = {10.1016/j.engappai.2025.112416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient stream monitoring: A systematic approach for model selection and continuous improvement in tiny machine learning applications. <em>EAAI</em>, <em>162</em>, 112415. (<a href='https://doi.org/10.1016/j.engappai.2025.112415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring ephemeral stream flows is essential for ecological and hydrological studies. However, their intermittent nature and remote locations pose challenges for conventional monitoring methods, which often consume excessive energy to capture rare events. We address this with BODOQUE (Bimodal Observational Device for Optimizing Quantification of Ephemeral streams), a dual-mode system that leverages Tiny Machine Learning (TinyML) on low-power microcontrollers. The system remains in an energy-saving sensing state and activates high-precision measurements only when water flow is detected. We present a model selection methodology that balances detection accuracy with inference cost, enabling reliable operation within hardware constraints. To enhance adaptability in diverse environments, we developed a specialized component that facilitates dataset expansion through new field samples. This supports ongoing retraining to maintain model performance under changing conditions. A comprehensive evaluation using real-world data demonstrates that our system can achieve up to 97% annual energy savings compared to traditional continuous monitoring approaches.},
  archive      = {J_EAAI},
  author       = {Benjamín Arratia and Erika Rosas and Javier Prades and Salvador Peña-Haro and José M. Cecilia and Pietro Manzoni},
  doi          = {10.1016/j.engappai.2025.112415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards efficient stream monitoring: A systematic approach for model selection and continuous improvement in tiny machine learning applications},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer architecture with illumination aware mechanisms for low-light image enhancement via retinex decomposition. <em>EAAI</em>, <em>162</em>, 112414. (<a href='https://doi.org/10.1016/j.engappai.2025.112414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing low-light images is a complex task that involves not only restoring brightness but also preserving color fidelity and reducing noise interference. In this paper, we propose a novel Retinex-based Transformer Model with Illumination Aware Mechanisms (TIMRetinex-Net), which achieves physically interpretable modeling through a decomposition network guided by Retinex theory. To adapt to light variations in different regions, we randomly apply gamma transformations to several subregions of the illumination component and use a Color Estimation Module to capture the color global distribution of the natural scene in the reflection component. By modeling the color global distribution and repairing the degraded regions collaboratively, we alleviate the issue of being highly sensitive to data usage during training and improve the model’s ability to handle unknown scenes. The Illumination and Reflection Adjustment Transformer Network (IRAT-Net) produces enhanced images, achieving a balanced enhancement of detail and color. In addition, IRAT-Net incorporates an attention mechanism into the feature extraction layer and introduces the Illumination-Guided Information Aggregation Module to adaptively estimate lighting conditions. In the field of image processing, our method based on artificial intelligence was evaluated on five datasets and compared with twelve state-of-the-art methods. The results demonstrated strong alignment with the ground truth, with our method achieving superior performance in both subjective and objective assessments.},
  archive      = {J_EAAI},
  author       = {Zixuan Wang and Gang Liu and Hanlin Xu and Yao Qian and Rui Chang and Durga Prasad Bavirisetti},
  doi          = {10.1016/j.engappai.2025.112414},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112414},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer architecture with illumination aware mechanisms for low-light image enhancement via retinex decomposition},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient interactive segmentation of three-dimensional gaussians with optimal view selection. <em>EAAI</em>, <em>162</em>, 112413. (<a href='https://doi.org/10.1016/j.engappai.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) scene representation has advanced rapidly in recent years, drawing the focus of more researchers. One of the main challenges for researchers is quickly and accurately segmenting 3D objects. Previous work has achieved excellent segmentation accuracy, but retraining requires a significant amount of time. Additionally, most methods fail to provide users with an efficient and convenient segmentation experience. To address these issues, we present Efficient Interactive Segmentation of 3D Gaussians (EISG), an efficient interactive segmentation method that eliminates the need for lengthy retraining. We first design an optimal view selection (OVS) method. This method uses 3D Gaussian entropy and image uncertainty to evaluate the quantity of view information. OVS helps users quickly select the optimal segmentation view, thereby enhancing interaction efficiency. Secondly, we use projection to find the target foreground rapidly and then segment the approximate objects using a clustering algorithm. Thirdly, we design a spatial-color background filter (SCBF) using the depth and color of 3D Gaussians. SCBF enables precise segmentation without needing retraining. Our method has been systematically tested on multiple datasets. Compared to other methods, the results demonstrate that EISG achieves ideal accuracy while significantly reducing processing time.},
  archive      = {J_EAAI},
  author       = {Yongtang Bao and Chengjie Tang and Yuze Wang and Yutong Qi and Ruijun Liu},
  doi          = {10.1016/j.engappai.2025.112413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient interactive segmentation of three-dimensional gaussians with optimal view selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification. <em>EAAI</em>, <em>162</em>, 112411. (<a href='https://doi.org/10.1016/j.engappai.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correctly identifying power quality disturbance (PQD) is crucial for the proper functioning of power systems. Deep learning (DL) techniques have been widely used for PQD classification due to their excellent performance. However, DL models are susceptible to adversarial attacks, posing a serious security threat to DL-based PQD classification systems. This issue has received limited attention in current research. In this study, we first utilize a convolutional neural network (CNN) to recognize various types of PQD signals. To evaluate model robustness, we introduce a black-box attack method for PQD classification based on the variance-tuning momentum iterative fast gradient sign method (VMI-FGSM). VMI-FGSM integrates a variance tuning method into the iterative process of the momentum iterative fast gradient sign method (MI-FGSM) , thereby producing more transferable adversarial PQD signals. To defend against such attacks, we propose a perturbation removal defense based on a generative adversarial network (PRD-GAN). This approach is capable of removing perturbations from adversarial PQD signals before they are recognized by the target classification model. Experiments demonstrate that VMI-FGSM produces adversarial perturbations that are nearly identical to those of the advanced MI-FGSM, but its adversarial examples are significantly more effective at misleading the target CNN model. Furthermore, the proposed PRD-GAN effectively reconstructs adversarial PQD signals into clean forms under various black-box attack intensities and outperforms the multi-level denoising autoencoder (ML-DAE) in defense performance due to its superior reconstruction capability.},
  archive      = {J_EAAI},
  author       = {Xiudong Zhang and Congmei Jiang and Mingbiao Yu and Xiankui Wen and Jing Zhang and Na Rong and Song Han},
  doi          = {10.1016/j.engappai.2025.112411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intrusion detection system for critical infrastructures: Modbus approach. <em>EAAI</em>, <em>162</em>, 112410. (<a href='https://doi.org/10.1016/j.engappai.2025.112410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop an Intrusion Detection System (IDS) using deep learning and machine learning algorithms to detect cyber attacks in the network traffic of critical infrastructures using an artificial intelligence-based approach. The research investigates various machine learning algorithms, datasets, and performance evaluations to detect the security vulnerabilities commonly found in industrial networks. Implemented in Python, the system has been tested on hybrid dataset, demonstrating the performance of different algorithms in terms of accuracy, precision, and other metrics. From artificial intelligence perspective, this study contributes machine learning and deep learning in cybersecurity, showing how normal and ensemble models can effectively detect complex threats, with fewer features but more relevant. The research employs supervised learning techniques, leveraging labeled datasets to train models that can accurately classify network traffic as either normal or attack, ensuring high detection accuracy. From an engineering standpoint, the system’s Python implementation addresses the practical challenges of real-world deployment in industrial control systems (ICS) and facilitates integration with existing infrastructures. Additionally, the custom dataset and post-dissector code contribute to the field of industrial cybersecurity, providing engineers with tools for testing, validating, and optimizing IDS solutions. As cyber–physical systems are increasingly integrated into ICS, the proposed IDS provides a crucial layer of defense against cyber threats, safeguarding both the digital and physical components of critical infrastructure. The findings reveal that the proposed system exhibits high performance in terms of detection accuracy. The results show that the system provides an effective and reliable detection mechanism using artificial intelligence techniques.},
  archive      = {J_EAAI},
  author       = {Murat Varol and Murat İskefiyeli},
  doi          = {10.1016/j.engappai.2025.112410},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112410},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intrusion detection system for critical infrastructures: Modbus approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence. <em>EAAI</em>, <em>162</em>, 112409. (<a href='https://doi.org/10.1016/j.engappai.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective resource management is crucial for the operation of dynamic Cyber–Physical Systems (CPS), yet traditional static or rule-based approaches often fail to handle their inherent complexity. This paper presents a novel Artificial Intelligence (AI)-driven framework for adaptive resource management, defined as the capability to autonomously adjust resource allocation by proactively forecasting future demands and dynamically optimizing decisions in real-time. The framework integrates a suite of AI techniques, including time-series models like Long Short-Term Memory (LSTM), chosen for their ability to capture complex temporal dependencies, for demand prediction. For resource allocation, it employs advanced actor–critic reinforcement learning (RL) algorithms like Proximal Policy Optimization (PPO) and Deep Deterministic Policy Gradient (DDPG), selected for their stability and efficiency in complex decision-making tasks. Performance was rigorously evaluated in a simulated dynamic environment. Experimental results demonstrate that combinations leveraging LSTM’s predictive accuracy with the robust optimization of PPO and DDPG achieve superior performance and stability. Specifically, the LSTM+DDPG and LSTM+PPO configurations yielded the highest average rewards (0.964 and 0.942, respectively), significantly outperforming the fixed-strategy baseline (0.497) and other AI pairings. Furthermore, the feasibility of training prediction models in a distributed manner via Federated Learning (FL) is successfully demonstrated. This research highlights that a synergistic integration of suitable AI predictors and advanced RL agents provides a powerful and resilient solution for resource management in dynamic CPS.},
  archive      = {J_EAAI},
  author       = {Xiaofei Zhao and Fangling Guo and Amin Huang and Jieqiong Ding and Chi Yan and Wei Yuan and Yunqi Su and Quanzhou Li and Qianggang Zhang},
  doi          = {10.1016/j.engappai.2025.112409},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112409},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation. <em>EAAI</em>, <em>162</em>, 112408. (<a href='https://doi.org/10.1016/j.engappai.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based segmentation techniques have demonstrated significant potential in defect detection, which is vital for product quality. However, the existing models tend to specialize in detecting specific defect types, reducing their adaptability to a wider range of product defects, most existing methods rely on multi-scale or prototype learning to extract defect features, but still struggle with complex backgrounds, various interferences, and large intra-class variations. Additionally, the rarity of certain defects limits the availability of training samples. Herein, an innovative segmentation network, the Prior Knowledge-based and Texture-Enhanced Network (PTNet), is designed for few-shot industrial segmentation. The model is mainly composed of a self-guidance branch, a cross-guidance branch, and a texture enhancement module, enabling generalization across defect types with minimal labeled samples. Self-guidance extracts prior knowledge from the query image, while the cross-guidance branch extracts prior and prototype features from the masked support image. The texture information in the low-level features of the backbone is then enhanced by proposed texture enhancement module (TEM). Finally, the enhanced low-level texture information are fused with high-level semantic features, allowing the network to fully exploit both local details and global context before being decoded to restore the original image size. This enables the model to handle complex textures and generalize to unseen defect types. Extensive experimental results validate the effectiveness of the proposed modules. State-of-the-art performance is achieved in few-shot defect segmentation, with notable improvements in mean Intersection over Union (mIoU) of 46.05 % and 46.98 % under 1-shot and 5-shot conditions, respectively.},
  archive      = {J_EAAI},
  author       = {Xingyue Liu and Qian Wu and Yahui Cheng and Guojun Wen},
  doi          = {10.1016/j.engappai.2025.112408},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112408},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems. <em>EAAI</em>, <em>162</em>, 112407. (<a href='https://doi.org/10.1016/j.engappai.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of control actions is a critical challenge in industrial systems, especially when dealing with complex and unknown dynamics. Data collected from the environment enables the application of reinforcement learning techniques, which let the controller learn a policy based on data. This work proposes a novel model-free reinforcement learning approach that consists of a value iteration algorithm based on separate policy evaluation and policy improvement phases to provide an accurate control policy estimation. The proposed approach addresses tracking control for quadruple-tank water systems while obtaining minor tracking errors and faster transient responses. The results from the case study reveal better accurate estimation of the value function, up to 86.13% mean improvement in tracking accuracy and faster responses compared to existing methods. Therefore, the proposed approach demonstrates advantages in optimizing control performance and stands as a promising control method for industrial applications.},
  archive      = {J_EAAI},
  author       = {Eva Masero and Giacomo Mussita and Alessio La Bella and Riccardo Scattolini},
  doi          = {10.1016/j.engappai.2025.112407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion. <em>EAAI</em>, <em>162</em>, 112406. (<a href='https://doi.org/10.1016/j.engappai.2025.112406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health management of transmission parameters for railway signal equipment is a key link between intelligent operation and maintenance. As a core parameter of track circuits, ballast resistance significantly affects signal transmission. To accurately and reliably assess its health state, an ensemble learning algorithm (ELA) is introduced, tackling deviations of appraisal decision boundaries. Focusing on issues of complex weight calculation, model homogenization, and severe overfitting in ELA, an integration model based on an automatic weight allocation strategy (AWAS) is innovatively proposed, constructing a method for resistance estimations driven by information fusion, while maximizing its generalization ability. Firstly, for deterioration mechanism analysis of ballast resistance, a transmission state model for vehicle-ground collaboration is established, completing extractions of evolutionary rules. Secondly, the improved ELA leverages heterogeneous classifier optimization and automatic weighted soft voting, with its core ensemble strategy employing a secondary learner to map the fused datasets. Then, by means of data mining techniques, interpolation and denoising algorithms are applied to implement data preprocessing, facilitating the effective fusion of heterogeneous vehicle-ground information. Finally, based on occurrence of adverse conditions, an appropriate particle size is set to achieve state warning. The results indicate that the proposed AWAS for ballast resistance calculations can achieve 98.52 % testing accuracy and outperforms others.},
  archive      = {J_EAAI},
  author       = {Conghui Wang and Shiwu Yang and Chang Liu},
  doi          = {10.1016/j.engappai.2025.112406},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112406},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Future of humanity in an artificial intelligence centric world. <em>EAAI</em>, <em>162</em>, 112405. (<a href='https://doi.org/10.1016/j.engappai.2025.112405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This scholarly article rigorously investigates the transformative and disruptive roles of artificial intelligence (AI) in influencing the trajectory of human society. By concentrating on three fundamental sectors—healthcare, finance, and education—it evaluates the ways in which AI augments operational efficiency, facilitates intricate decision-making processes, and introduces innovative capabilities such as personalized medicine and automated financial systems. Concurrently, the analysis underscores urgent ethical dilemmas, encompassing algorithmic bias, accountability deficiencies, data privacy vulnerabilities, and workforce displacement. Employing real-world examples such as Deepfakes, and Neuralink, the article contextualizes emerging challenges within a dynamic socio-technical framework. The research offers a cohesive conceptual model that amalgamates technical, ethical, and governance aspects of AI, while presenting policy recommendations designed to promote transparency, equity, and human-centered AI development. The study emphasizes the necessity for reliable AI systems that humans can trust. The conclusions accentuate the immediate necessity for robust regulatory frameworks and sector-specific ethical supervision to ensure that advancements in AI are harmonized with the well-being of society.},
  archive      = {J_EAAI},
  author       = {Sunil Baloda and Monika Sharma and Mukesh Kumar},
  doi          = {10.1016/j.engappai.2025.112405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Future of humanity in an artificial intelligence centric world},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel federated deep learning for intrusion detection in smart grid cyber-physical systems. <em>EAAI</em>, <em>162</em>, 112404. (<a href='https://doi.org/10.1016/j.engappai.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of sophisticated computational, communicative, and physical elements in Smart Grid Cyber-Physical Systems (SGCPS) has greatly improved the efficiency and reliability of power grids. However, this complexity introduces enhanced cybersecurity risks, evidenced by significant cyberattacks on the Ukrainian power grid during 2015 and 2016. Despite progress in Artificial Intelligence (AI)-driven security solutions for SGCPS, practical deployment of these technologies is often limited due to a lack of high-quality attack data and owners’ hesitance to distribute sensitive details. This paper introduces an innovative strategy to fortify SGCPS against diverse network threats via a comprehensive intrusion detection system. We present a deep learning model leveraging a temporal convolutional network with multi-feature integration, aimed at robust threat identification. We also propose a federated learning framework enabling various SGCPS to jointly develop an extensive intrusion detection model, ensuring data privacy. Moreover, we incorporate a gradient compression technique utilizing the Long Short Term Memory- β -Total Correlation Variational Autoencoder (LSTM- β -TCVAE) model to enhance and secure model parameters throughout the training phase. Thorough experimental validations confirm the efficacy of our method in recognizing multiple cyber threat types to SGCPS and its advantages over current methods.},
  archive      = {J_EAAI},
  author       = {Rong Xie and Bin Wang and Xin Xu},
  doi          = {10.1016/j.engappai.2025.112404},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112404},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel federated deep learning for intrusion detection in smart grid cyber-physical systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection. <em>EAAI</em>, <em>162</em>, 112403. (<a href='https://doi.org/10.1016/j.engappai.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting crack leakages in shield tunnels is crucial for ensuring structural safety and extending service life, as traditional detection methods are limited by high subjectivity and low accuracy. To address these limitations, this paper proposes Tunnel-YOLO, an improved object detection algorithm based on You Only Look Once version 8 (YOLOv8). This algorithm replaces standard convolutional blocks with a novel Receptive Field Channel Attention Convolution (RFCAConv) module, which leverages dynamic receptive fields to enhance feature capture at different scales. We also introduce a C2f_SGE module, integrating the Spatial Group-wise Enhance (SGE) attention mechanism into the C2f (CSPNet with 2 convolutions) block to significantly improve feature extraction while suppressing background interference. Furthermore, an Edge Feature Enhancement Detection Head (EFE-Head) incorporates deconvolution layers to enhance fine-grained details for more precise boundary localization. To better accommodate the shape-sensitive detection task, our LeShape-IoU (Intersection over Union) loss function is designed to focus on the shape and scale characteristics of target bounding boxes. Experimental results on a public, real-world dataset demonstrate that Tunnel-YOLO significantly outperforms the baseline, increasing Recall, Precision, and mean Average Precision at 0.5 IoU (mAP50) by 15.7%, 10.3%, and 14.8%, respectively. Comparative analysis with other mainstream algorithms further validates the effectiveness and superiority of the proposed Tunnel-YOLO.},
  archive      = {J_EAAI},
  author       = {Ruijun Yang and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112403},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112403},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of data-driven predictive model and enhanced multiobjective optimization to improve the excavation performance of large-diameter slurry shields. <em>EAAI</em>, <em>162</em>, 112402. (<a href='https://doi.org/10.1016/j.engappai.2025.112402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety, efficiency and energy consumption are important aspects for evaluating the performance of large-diameter slurry shield, and improving the performance of shield is crucial for safe and efficient excavation. To this end, a data-driven hybrid method is developed to improve the excavation performance of large-diameter slurry shields by intelligence regulating shield parameters. This method combines Bayesian Optimization with categorical boosting (BO-CatBoost) and enhanced multiobjective evolutionary algorithm based on decomposition (EMOEA/D). The method uses surface settlement, penetration and specific energy as output targets and employs the expert knowledge to select the input parameters. Subsequently, the trained BO-CatBoost model is employed to fit the input-output relationship. On this basis, the multiobjective optimization process was performed using EMOEA/D, with the important parameters determined by Shapley Additive exPlanations as decision variables and the nonlinear relationship fitted by BO-CatBoost as the objective function. Finally, the technique for order preference similarity to ideal solution is applied to obtain optimal operational parameters, thereby enhancing the excavation performance of large-diameter slurry shield. The proposed method is applied to a Wuhan rail transit line to verify the effectiveness, and the result shows that: (1) Our method can accurately predict the three targets with goodness of fit ranging from 0.938 to 0.988, respectively. (2) The proposed method can effectively improve the excavation performance of the large-diameter slurry shield, and reaches 13.88 %, 5.21 %, and 10.88 %, respectively. (3) An adaptive decision-making system for setting operational parameters is constructed, which is valuable for formulating of operational control strategies for large-diameter slurry shields.},
  archive      = {J_EAAI},
  author       = {Feiming Su and Xianguo Wu and Tiejun Li and Yang Liu},
  doi          = {10.1016/j.engappai.2025.112402},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112402},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of data-driven predictive model and enhanced multiobjective optimization to improve the excavation performance of large-diameter slurry shields},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive active adaptive partial label learning under class distribution mismatch. <em>EAAI</em>, <em>162</em>, 112401. (<a href='https://doi.org/10.1016/j.engappai.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning is an important learning framework where each training sample is associated with a candidate label set and its ground-truth label is included in the candidate label set. Active partial label learning is a variation where training data consists of both labeled and unlabeled samples. However, there exists the problem of class distribution mismatch, wherein the unlabeled sample set contains many instances out of the target categories. In this paper, a contrastive active adaptive partial label learning method under class distribution mismatch which combines active partial label learning with contrastive coding is proposed. A novel active sample selection strategy is first established to use label propagation ability to measure the optimization ability of unlabeled samples to partially labeled samples. Furthermore, to solve the problem of class distribution mismatch, a joint query score based on contrastive coding is utilized to reduce the queries of unlabeled samples out of target categories. Finally, the above two indicators are combined adaptively to select the most valuable unlabeled samples in target categories for manual labeling and the selected samples will be added to the training sample set to train the new classifier. The effectiveness and efficiency of the method are evaluated by performing experiments on the datasets CIFAR10 and CIFAR100.},
  archive      = {J_EAAI},
  author       = {Aohan Zhang and Kezhen Dong and Hongying Zhang},
  doi          = {10.1016/j.engappai.2025.112401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive active adaptive partial label learning under class distribution mismatch},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for photovoltaic power forecasting based on hybrid data reconstruction, neural network models fusion, and multi-objective optimization. <em>EAAI</em>, <em>162</em>, 112400. (<a href='https://doi.org/10.1016/j.engappai.2025.112400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intermittency of photovoltaic power seriously affects the safety and operation of the power grid. Accurate photovoltaic power forecasting is critical for a safe connection of large-scale solar energy to the grid. Despite the efforts of many researchers, current forecasting methodologies remain inadequate. To bridge this gap, leveraging the recent advancements in artificial intelligence algorithms, this work combines cutting-edge deep learning techniques and data preprocessing strategies to develop a forecasting system that comprehensively considers various influencing factors and integrates multiple deep learning neural networks. The framework enables deterministic forecasting and uncertainty analysis, providing reliable supporting information for accurate forecasting through hybrid decomposition data preprocessing and feature selection modules. Then, closed-form continuous-time (Cfc) neural networks are introduced as one of the core forecasting components. Theoretically, the validity of the combined model and the Pareto optimization process are proved. Practically, the multi-objective African vultures optimization (MoAvo) is employed to identify the Pareto optimal solution, integrate four models, and improve the model's adaptability to external environmental changes. The experimental results show that the average mean absolute percentage error (MAPE) of the designed combined system for 1–3 steps forecasting on the Yulara are 6.09 %, 8.15 %, and 10.03 %, respectively. The results demonstrate that the framework fully considers the influence of candidate variables on forecasting, offering significant advantages over comparison models.},
  archive      = {J_EAAI},
  author       = {Menggang Kou and Jianzhou Wang and Jingrui Li and Runze Li and Zhiwu Li},
  doi          = {10.1016/j.engappai.2025.112400},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112400},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A framework for photovoltaic power forecasting based on hybrid data reconstruction, neural network models fusion, and multi-objective optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A binary particle swarm optimization with dual encoding mechanism for feature selection. <em>EAAI</em>, <em>162</em>, 112397. (<a href='https://doi.org/10.1016/j.engappai.2025.112397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a crucial machine learning preprocessing stage with numerous practical uses. Numerous algorithms are created to tackle the task. However, these algorithms still suffer from several challenges. This study introduces a novel binary particle swarm optimization with dual encoding mechanism, named DEBPSO, to solve feature selection problems. A new transfer function, called an inverse S-shaped function, and a Boolean encoding mechanism are employed to enhance the exploration performance of DEBPSO. In addition, to better balance exploration and exploitation, a new game mechanism is proposed to find the best solution. In order to verify the performance of DEBPSO, a comprehensive experimental is designed. The experimental results on 27 well-known datasets show that DEBPSO significantly outperforms the compared algorithms on 17, 14, 13, 17, 16, 21, 14, 23, 20 datasets in terms of classification error rate, highlighting its efficiency in reducing the classification error rate and irrelevant features.},
  archive      = {J_EAAI},
  author       = {Chong Zhou and Rumeng Liang and Qi Liu and Sirui Niu},
  doi          = {10.1016/j.engappai.2025.112397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A binary particle swarm optimization with dual encoding mechanism for feature selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection. <em>EAAI</em>, <em>162</em>, 112394. (<a href='https://doi.org/10.1016/j.engappai.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT (red-green-blue and thermal) salient object detection (SOD) aims to identify and highlight the most visually salient objects in an image by leveraging the complementary information from both RGB and thermal (TIR) modalities. It is particularly effective for 24/7 intelligent surveillance and autonomous perception in smart city security and traffic monitoring, especially under low light and adverse weather. However, existing methods primarily rely on manually aligned datasets, which are limited in handling the challenges posed by unaligned multi-modal data in real-world applications. Furthermore, these methods usually extract complementary information from both modalities using fixed-size windows (Liuet al., 2022, Wanget al., 2024b). However, such fixed-size windows are not effective in dealing with unaligned multi-modal images due to spatial inconsistencies. Additionally, existing methods often use single-layer high-level feature to represent semantic information, which fails to fully exploit the complementary benefits of multi-level features, thereby reducing the effectiveness of semantic guidance. To address these challenges, we propose a Hierarchical Semantics guided Multi-scale correlation Network (HSMNet) for alignment-free RGBT SOD. A Hierarchical Semantic Fusion Module (HSFM) dynamically assigns weights to features from multiple levels, enabling adaptive fusion of multi-level semantic information. A Multi-scale Asymmetric Correlation Module (MACM) employs windows of various sizes to capture asymmetric correlations between unaligned multi-modal data, enhancing cross-modal complementary information extraction even when data are not perfectly aligned. We conduct extensive experiments on unaligned, weakly aligned and aligned RGBT SOD datasets, with results demonstrating that our method outperforms state-of-the-art algorithms, achieving superior accuracy and robustness in both unaligned and weakly aligned RGBT SOD scenarios.},
  archive      = {J_EAAI},
  author       = {Chengmei Han and Lei Liu and Kunpeng Wang and Fei Xie and Bing Wei},
  doi          = {10.1016/j.engappai.2025.112394},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112394},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear dynamic modeling of turbojet engines using combined convolutional and long short-term memory networks. <em>EAAI</em>, <em>162</em>, 112393. (<a href='https://doi.org/10.1016/j.engappai.2025.112393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Turbojet engines are widely used in small-scale aerial vehicles, but their nonlinear and time-varying dynamics present significant challenges for accurate modeling and control. Traditional system identification methods often struggle to capture these complex behaviors, particularly under limited data conditions. This study proposes a novel hybrid neural network architecture that combines convolutional neural networks and long short-term memory units. The model is specifically designed for small-sample scenarios, enabling robust learning and precise engine speed prediction from real input-output sequences. The input vector comprises the current engine speed, the next-step pulse-width modulation command, and its increment, enhancing the model’s responsiveness and reducing phase-lag effects. The proposed model is trained and evaluated on a real-world dataset containing 38,257 samples, with 80 % used for training and 20 % for testing. Its predictive performance is assessed using step input responses and three evaluation metrics: mean absolute error, root mean square error, and Pearson correlation coefficient. Experimental results demonstrate that the proposed hybrid architecture outperforms other recurrent models in capturing transient dynamics and accurately reproducing real engine behavior. These findings highlight the model’s effectiveness in modeling nonlinear engine dynamics and its potential as a data-efficient alternative to traditional identification techniques for small-scale turbojet applications.},
  archive      = {J_EAAI},
  author       = {Chen Lei and Dong Wei and Su Hang and Chi Yutian and Tian Congling and Gao Yongzhuo and Wu Dongmei and Dong Hui},
  doi          = {10.1016/j.engappai.2025.112393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear dynamic modeling of turbojet engines using combined convolutional and long short-term memory networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scientific machine learning for generic compact model parameter extraction of nanoscale transistors. <em>EAAI</em>, <em>162</em>, 112392. (<a href='https://doi.org/10.1016/j.engappai.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a framework to automate modelcard extraction of industry-standard compact models. This framework presents a Scientific Machine Learning (ScML) approach capable of inverse modeling. It integrates a random forest model with an artificial neural network to produce efficient and precise regression results. This new method is used for parameter extraction in the standard compact models of the semiconductor device industry. Modeling of a multi-gate Field Effective Transistor (FET) with an industry-standard compact model like Berkeley Short-channel Insulated-Gate Field-Effect Transistor Model – Common Multi-Gate (BSIM-CMG) is taken as an example to illustrate and describe the framework and highlight its key advantages. Proposed framework is useful in numerous aspects; it holds vital principles of physics, avoids depending on massive datasets, and has a sparse architecture while avoiding accuracy trade-offs. The framework is tested on production-level experimental devices to evaluate the real-world performance. This framework significantly reduces the time and cost of parameter extraction for the Process Design Kits (PDKs) development. Therefore, this is of immediate importance for fabrication and Electronic Design Automation (EDA) industries.},
  archive      = {J_EAAI},
  author       = {Kumar Sheelvardhan and Surila Guglani and Abhilash Dubey and Shashank Dubey and Sindhu Ramaswamy and Vaidy Subramanian and Kassandra Anderson and Glenn Workman and Sourajeet Roy and Avirup Dasgupta},
  doi          = {10.1016/j.engappai.2025.112392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scientific machine learning for generic compact model parameter extraction of nanoscale transistors},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed graph neural network for 3D spatiotemporal structural response modeling of flexible pavements. <em>EAAI</em>, <em>162</em>, 112391. (<a href='https://doi.org/10.1016/j.engappai.2025.112391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying pavement damage is crucial for roadway agencies' maintenance planning. This study proposed a Physics-informed Graph Neural Network-based Pavement Simulator (PhyGPS) to predict three-dimensional (3D) asphalt concrete pavement responses, building upon an established data-driven Graph Neural Network-based Pavement Simulator (GPS) model. The key innovation lies in integrating knowledge graphs and mechanics equations to create a physics loss function, distinguishing it from its data-driven counterpart. The physics loss function comprises strain-displacement and stress loss components derived from 3D strain-displacement relations and stress equilibrium principles. A thorough 3D finite element (FE) pavement database supported the model development. The 3D FE pavement data was transformed into graph format where nodes and edges represent 3D FE pavement models’ nodes and node connections, respectively. Performance evaluation employed two case studies: “OneStep” for assessing short-term predictive capabilities and “Rollout” for examining long-term prediction accuracy under practical conditions. Results demonstrated that the physics-informed GPS model showed superior long-term predictive capability and robustness while maintaining excellent short-term accuracy compared to the data-driven model. Both models achieve rollout time under 8 s per FE simulation case, a dramatic improvement over the 12-h runtime of traditional 3D FE pavement models. The PhyGPS model successfully integrates physics principles, spatial relationships between structural components, temporal correlations in structural data, and complex material properties, offering an accurate, robust, and computationally efficient solution for predicting 3D pavement responses.},
  archive      = {J_EAAI},
  author       = {Fangyu Liu and Imad L. Al-Qadi},
  doi          = {10.1016/j.engappai.2025.112391},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112391},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed graph neural network for 3D spatiotemporal structural response modeling of flexible pavements},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks. <em>EAAI</em>, <em>162</em>, 112389. (<a href='https://doi.org/10.1016/j.engappai.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in communication technologies, remote monitoring and control of drug delivery are becoming prevalent in bio-medical engineering. In a chemotherapy system, the measurement signals can be wirelessly transferred to the control center by communication networks. Nevertheless, the avenues of communication might be jeopardized by false data injection (FDI), which poses significant risks to the security and stability of biomedical systems. In this work, a defense mechanism is developed to tackle the effect of FDI threats in the networked chemotherapy system. In particular, the effect of FDI attacks on the chemotherapy system is modeled by the Markov chain process. The proposed defense mechanism is designed in two parts: i ) a data-driven sliding mode observer (DDSMO) is utilized to identify the occurrence of cyber attacks in the tumor signals measured by the bio-sensor, and ii ) a mitigation scheme based on a dynamic rejection compensator (DRC) to compensate for the impact of cyber threats. In the mitigation phase, a goal representation heuristic dynamic programming (GrHDP) is adopted to adaptively adjust the parameters of DRC and to dynamically handle the cyber threats. The designed mitigation mechanism not only regulates the cancerous cells against cyber threats but also minimizes the side effects of drug delivery by regulating the output of normal cell and immune cell. Compared to prevalent methodologies, the proposed approach yields significant performance, including a 60.23 % improvement over the without protection, 37.48 % over the DDSMO-based model predictive controller (MPC), 35.95 % over the reinforcement learning (RL) based Kalman filter, and 70.44 % over the proportional integral (PI) based Kalman filter.},
  archive      = {J_EAAI},
  author       = {Mostafa Taheri and Juliang Yin and Zahra Rasooli Berardehi},
  doi          = {10.1016/j.engappai.2025.112389},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112389},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial. <em>EAAI</em>, <em>162</em>, 112386. (<a href='https://doi.org/10.1016/j.engappai.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain adaptive methods are becoming a growing focus of fault diagnosis, which can provide enhanced data support for models using the feature information from various source domains. As a most commonly used method, unsupervised multi-domain adaptive methods (UMA) can eliminate the requirement for the label of the target domain samples. However, the neglect of contributions from different source domains to the target domain and insufficient utilization of diagnostic information from multiple source domains are the widely limitation of UMA. Therefore, a dual-adversarial weighted multi-source domain unsupervised adaptive network (DAWMUN) is proposed to utilize diagnostic information from multi-source domains and consider the contribution of different source domains. Firstly, the shared feature extractor and dual adversarial training with the domain adversarial modules between multi-source domains and source-target domains are used to enhance domain confusion between multi-source and target domains (MSTD). Secondly, based on Multiple Kernel Maximum Mean Discrepancy (MK-MMD), a novel weighting mechanism and the corresponding training framework are constructed to effectively reduce negative transfer. Finally, a novel weighted classifier is proposed to merge the outputs of multiple classifiers and synthesize the impact of each source domain. The performance of the DAWMUN is validated using a rotating machinery dataset across various transfer tasks under different rotational speed and load conditions. The experimental results demonstrate that the diagnostic accuracy using the proposed DAWMUN is superior to existing SSDA and MSDA methods, with the average accuracies of 98.53 % and 98.23 % across six tasks in two separate experimental setups. The comparison to the existing methods results that the DAWMUN still demonstrates superior performance with improvements of 2.54 % and 2.86 %, respectively.},
  archive      = {J_EAAI},
  author       = {Wenqi Wang and Zongzhen Zhang and Jinrui Wang and Baokun Han and Huaiqian Bao and Zhikang Fan and Rongkang Ge},
  doi          = {10.1016/j.engappai.2025.112386},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112386},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information. <em>EAAI</em>, <em>162</em>, 112385. (<a href='https://doi.org/10.1016/j.engappai.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wave prediction is a critical challenge in ocean and coastal engineering, particularly for understanding and mitigating the effects of sea waves on structures such as ships, offshore platforms, and coastal defenses. A novel machine learning model, Twin-Stream Network (TSNet), is proposed to enhance wave prediction accuracy by leveraging temporal and spatial dependencies in historical data. The TSNet model along with other baseline models are evaluated, in both single-point and multi-point forecasting tasks, by various performance metrics across different datasets including one-dimensional-linear, one-dimensional-nonlinear, two-dimensional-linear and two-dimensional-nonlinear water waves. The comprehensive comparative analysis demonstrates that the TSNet model outperforms others, especially in the multi-point forecasting task. This study provides a valuable insight into the effectiveness of machine learning approaches and highlights the potential of the accuracy improvement for wave prediction.},
  archive      = {J_EAAI},
  author       = {Junhao Xu and Zhongying Feng and Zhan Wang and Kun Zheng and Ruipeng Li},
  doi          = {10.1016/j.engappai.2025.112385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning. <em>EAAI</em>, <em>162</em>, 112383. (<a href='https://doi.org/10.1016/j.engappai.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval enables efficient integration of information by linking different data modalities, such as images and text. As data volumes increase rapidly, the need for effective cross-modal interaction grows. Cross-modal hashing is favored for its low storage requirements and fast retrieval speed, but many existing methods depend on accurately labeled data, which can be subjective and expensive to obtain. To address this limitation, we propose Clean-guided Adaptive Weighted Contrastive Hashing (CAWCH), a novel framework designed to improve robustness against noisy labels. CAWCH incorporates two main components: a Gaussian Mixture Model (GMM)-based noise purifier that identifies reliable and noisy samples by modeling sample loss, and a contrastive learning strategy that selectively chooses positive samples and adaptively assigns weights based on multi-label similarity, considering both intra- and inter-modal relationships. Extensive experiments demonstrate that CAWCH significantly outperforms existing methods under noisy label conditions, highlighting its effectiveness and potential for real-world cross-modal retrieval applications.},
  archive      = {J_EAAI},
  author       = {Shuni Jiang and Zhixin Li},
  doi          = {10.1016/j.engappai.2025.112383},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112383},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network. <em>EAAI</em>, <em>162</em>, 112382. (<a href='https://doi.org/10.1016/j.engappai.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic flux leakage (MFL) signal denoising is essential for the nondestructive inspection of oil and gas pipelines, where complex noise interference can severely degrade defect quantification accuracy. Traditional approaches such as mean filtering and wavelet transform offer limited suppression of multi-type mixed noise and often distort critical features, including defect peaks and valleys. Even deep learning–based MFL denoising methods struggle in scenarios with substantial signal-noise overlap due to inadequate feature extraction and limited adaptability.This work presents an advanced denoising framework that combines dynamic feature fusion with a multi-scale autoencoder network. The framework jointly exploits time- and frequency-domain signal components, employing an adaptive weighting mechanism for dynamic feature fusion. Parallel convolutional branches extract multi-scale features, improving the capture of both global structures and fine-grained details, while a Squeeze-and-Excitation (SE) channel attention mechanism enhances defect-sensitive features and suppresses noise. Extensive experiments demonstrate that the proposed model outperforms mean filtering, wavelet denoising, and a baseline autoencoder, achieving notable gains in signal-to-noise ratio (SNR), mean squared error (MSE), and signal similarity. Beyond superior noise suppression, the method preserves critical defect characteristics, providing a robust and reliable foundation for precise defect quantification in pipeline MFL inspection.},
  archive      = {J_EAAI},
  author       = {Lushuai Xu and Shaohua Dong and Haotian Wei and Feng Li and Pengkun Zhang and Cong Zuo and Mingxing Guo and Penghui Liao},
  doi          = {10.1016/j.engappai.2025.112382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight segmentation model based on segment anything model for tongue image segmentation. <em>EAAI</em>, <em>162</em>, 112379. (<a href='https://doi.org/10.1016/j.engappai.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tongue image segmentation plays a crucial role in intelligent of diagnosis of Traditional Chinese Medicine. Accurate, efficient, and lightweight tongue segmentation significantly improves both the quality and practical applicability of intelligent disease diagnosis models. To address this challenge, we propose TongueSAM_Lite, a lightweight and fully automated tongue image segmentation model. Based on the Segment Anything Model. Our approach employs knowledge distillation and parameter-efficient fine-tuning to develop a novel lightweight image encoder, high-parameter modules in the Vision Transformer are partially replaced with lightweight image modules, which facilitate the transfer of its feature extraction capabilities while accelerating inference speed and reducing computational resource requirements. Additionally, to eliminate manual annotation of tongue region bounding boxes, we integrate a YOLOX-based automatic Box-prompt generator, enabling end-to-end fully automated prompting and segmentation of tongue images. To validate our approach, various experiments were conducted in three datasets. The results show that compared to the original large-scale model of the Segment Anything Model, TongueSAM_Lite reduces the size of the model by 42.7% and shortens the inference time to 45.43% while retaining the near-complete segmentation accuracy of few-shot learning. TongueSAM_Lite achieves Mean Intersection over Union scores of 96.48%, 98.36%, and 97.53% in the three datasets, respectively, outperforming state-of-the-art segmentation methods. Further validation confirms that the YOLOX-based prompt encoder yields optimal performance for the generation of tongue image bounding boxes. Our proposed approach provides new research insights to advance tongue diagnosis technology of Traditional Chinese Medicine. All codes in this article are available at https://github.com/ruanqunsheng/TongueSAM_Lite .},
  archive      = {J_EAAI},
  author       = {Qunsheng Ruan and Shan Cao and Zhirong Luo},
  doi          = {10.1016/j.engappai.2025.112379},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112379},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight segmentation model based on segment anything model for tongue image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cross-branch information for semi-supervised remote sensing object detection. <em>EAAI</em>, <em>162</em>, 112378. (<a href='https://doi.org/10.1016/j.engappai.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection (SSOD) provides a promising solution to mitigate the annotation costs in remote sensing applications. Mainstream teacher-student based SSOD methods leverage unlabeled images through pseudo labeling, and their effectiveness is fundamentally limited by the inevitable noise in pseudo labels, particularly for remote sensing (RS) scenarios with complex backgrounds and dense, multi-scale and oriented objects. Current methods primarily focus on reducing pseudo label noise through category, scale and Intersection over Union information mining, as well as designing fine-grained confidence thresholding strategies. However, the inherent discrepancy between classification and localization reliability is neglected. In this study, with analyzing the characteristic discrepancies between the classification and localization branches, We propose artificial intelligence (AI) methodological innovation method named cross-branch information incorporation method (i.e., CBI-SSOD) to utilize these discrepancies to assist the training of the classification branch, and thus improve the performance of SSOD methods. Specifically, our method present two key AI innovations. Firstly, we propose a pretext task to extract cross-branch information, which can improve the classification ability by reinforce the consistent predictions between the classification branch and the pretext task. Besides, we propose a pseudo label reassignment approach to adjust the soft classification pseudo labels, and thus suppress pseudo label noise and improve the detection performance. Extensive experiments on Dataset for Object Detection in Aerial Images (DOTAv1.0) and DOTAv1.5 datasets validate the effectiveness and superiority of our method, and demonstrate the practical engineering impact of our method on RS applications and interpretation systems.},
  archive      = {J_EAAI},
  author       = {Shitian He and Huanxin Zou and Yingqian Wang and Xu Cao and Hao Chen and Ning Jing},
  doi          = {10.1016/j.engappai.2025.112378},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112378},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring cross-branch information for semi-supervised remote sensing object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond trial-and-error: Predicting user abandonment after a moderation intervention. <em>EAAI</em>, <em>162</em>, 112375. (<a href='https://doi.org/10.1016/j.engappai.2025.112375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current content moderation follows a reactive, trial-and-error approach, where interventions are applied and their effects are only measured post-hoc. In contrast, we introduce a proactive, predictive approach that enables moderators to anticipate the impact of their actions before implementation. We propose and tackle the new task of predicting user abandonment following a moderation intervention. We study the reactions of 16,540 users to a massive ban of online communities on Reddit, training a set of binary classifiers to identify those users who would abandon the platform after the intervention—a problem of great practical relevance. We leverage a dataset of 13.8 million posts to compute a large and diverse set of 142 features, which convey information about the activity, toxicity, relations, and writing style of the users. We obtain promising results, with the best-performing model achieving micro F1-score = 0 . 914 . Our model shows robust generalizability when applied to users from previously unseen communities. Furthermore, we identify activity features as the most informative predictors, followed by relational and toxicity features, while writing style features exhibit limited utility. Theoretically, our results demonstrate the feasibility of adopting a predictive machine learning approach to estimate the effects of moderation interventions. Practically, this work marks a fundamental shift from reactive to predictive moderation, equipping platform administrators with intelligent tools to strategically plan interventions, minimize unintended consequences, and optimize user engagement.},
  archive      = {J_EAAI},
  author       = {Benedetta Tessa and Lorenzo Cima and Amaury Trujillo and Marco Avvenuti and Stefano Cresci},
  doi          = {10.1016/j.engappai.2025.112375},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112375},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond trial-and-error: Predicting user abandonment after a moderation intervention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction. <em>EAAI</em>, <em>162</em>, 112374. (<a href='https://doi.org/10.1016/j.engappai.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The industrial data sequences frequently exhibit irregular sampling frequencies, which pose a number of difficulties for data analysis and modeling. The traditional dynamic models like Recurrent Neural Network (RNN) and Transformer are difficult to model such data sequences. The main reason is that these models assume that data sampling frequency should be constant. To this end, a Sampling Interval-Adaptive Transformer (SIA-Trans) is proposed in this paper to adaptively model the temporal information for heterogeneous sampling sequences in industrial processes. The SIA-Trans uses the sampling interval and position embedding block to address the problem of unequal time intervals and rectify the temporal correlations in time series. Then, the interval-aware self-attention net is designed for dynamic data relationship modeling, taking the processed data through the self-attention mechanism. Finally, the predicted output is obtained after the point-wise feed-forward layer. The proposed SIA-Trans is validated on a real-world hydrocracking process to predict the content of hydrocarbon mixture with five carbon atoms (C5) hydrocarbons in light naphtha, as well as the final boiling point of jet fuel.},
  archive      = {J_EAAI},
  author       = {Zijian Xu and Nuo Xu and Kai Wang and Xiaofeng Yuan and Yalin Wang and Chunhua Yang and Weihua Gui and Shuqiao Cheng and Lingjian Ye},
  doi          = {10.1016/j.engappai.2025.112374},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112374},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. <em>EAAI</em>, <em>162</em>, 112373. (<a href='https://doi.org/10.1016/j.engappai.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of face forgery technology, many forged faces threaten information security. Although existing face forgery detection methods obtain better detection performance on intra-dataset evaluation, the generalization of cross-dataset detection and the robustness against image post-processing operations still need to be improved. To address these issues, we propose a multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. Specifically, a two-branch architecture is designed to extract spatial and frequency features. To realize the interaction and communication of spatial and frequency information, the cross-modality interaction module is designed to explore the inter-modality correlation by applying across self-attention. Subsequently, a multi-scale feature enhancement module is introduced in the spatial branch to enhance the texture and semantic information of spatial features, improving the robustness of tackling image post-processing operations. In addition, to exploit the complementary relationship between the spatial and frequency features, an adaptive fusion module is designed to establish forged feature dependencies by leveraging spatial self-attention, while learning discriminative feature representations by fusing spatial and frequency features in an adaptive weighted manner. Extensive experimental results on four public datasets demonstrate that the proposed method outperforms other state-of-the-art methods for intra-dataset, cross-dataset, and perturbed dataset evaluations.},
  archive      = {J_EAAI},
  author       = {Chunyin Shi and Chengyou Wang and Xiao Zhou and Zhiliang Qin},
  doi          = {10.1016/j.engappai.2025.112373},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112373},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive neural network tracking control for unknown high-order nonlinear systems: A constructive approximation set based approach. <em>EAAI</em>, <em>162</em>, 112371. (<a href='https://doi.org/10.1016/j.engappai.2025.112371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the problem of adaptive neural network (NN) tracking control for unknown high-order nonlinear systems, with a focus on accurately constructing NN approximation sets. To guarantee the local approximation capabilities of NNs, it is crucial that their input signals remain within corresponding compact sets. However, the unknown functions and powers in high-order nonlinear systems make it difficult to determine these sets accurately. To solve this, we introduce a novel adaptive NN tracking control strategy that integrates signal substitution technique, barrier functions (BFs), and NNs. Specifically, the signal substitution technique converts the original system states into state error variables, along with the desired reference signal and its time derivatives, which serve as part of the NN input. BFs are employed to constrain the state errors, while NNs approximate the transformed unknown system functions. This approach enables precise calculation of bounds for the NN weight estimators, ensuring that the NN approximation sets are constructed. Unlike existing methods, our approach not only proves the existence of NN approximation sets but also provides a constructive design strategy, significantly enhancing the approximation accuracy for unknown nonlinear functions. Simulation results demonstrate the effectiveness and advantages of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yu-Fa Liu and Yong-Hua Liu and Jin-Wa Wu and Jie Tao and Ming Lin and Chun-Yi Su and Renquan Lu},
  doi          = {10.1016/j.engappai.2025.112371},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112371},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive neural network tracking control for unknown high-order nonlinear systems: A constructive approximation set based approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting. <em>EAAI</em>, <em>162</em>, 112370. (<a href='https://doi.org/10.1016/j.engappai.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price forecasting has become a significant and complex research area within financial technology. The dynamic correlations among stocks and the inherent noise in price volatility present considerable challenges in accurately forecasting stock prices and enhancing investment returns. This paper introduces a novel Dynamic Correlation Graph Convolution Network (DyCGCN) with embedded temporal correlation extraction. First, we propose a dual-scale dynamic graph generation method to capture the topological relationships among stocks. Second, we develop a dynamic correlation-temporal convolution module that extracts high-level temporal correlations. Third, we introduce a prospect theory-guided multi-strategy loss function that accommodates the diverse risk preferences of investors. Furthermore, we present a joint regression-classification learning method to extract and leverage stock trend information. Experiments conducted on four real-world datasets demonstrate the superiority of DyCGCN, achieving an average 24.7% reduction in prediction error and a 10.5% improvement in predictive accuracy over baseline models, underscoring its strong potential for practical stock price forecasting.},
  archive      = {J_EAAI},
  author       = {Fang He and Wei Yin and Yilun Jin and Zhengyang Chen},
  doi          = {10.1016/j.engappai.2025.112370},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112370},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach. <em>EAAI</em>, <em>162</em>, 112361. (<a href='https://doi.org/10.1016/j.engappai.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific Emitter Identification (SEI) distinguishes radio-frequency (RF) devices by exploiting hardware-induced signal fingerprints, thereby strengthening wireless-layer security. Existing deep learning-based SEI methods depend heavily on labeled data and fixed confidence thresholds for pseudo-labeling, which limits their effectiveness under label scarcity or open-set conditions. To overcome these issues, we propose a progressive semi-supervised learning (ProSSL) method for SEI that combines iterative clustering with contrastive learning to generate adaptive pseudo-labels. ProSSL introduces an “uncertain” class and employs a dual-constraint selector—prediction stability and class diversity—to suppress noisy pseudo-labels and ensure robust propagation. Experiments on the public real-world long range(LoRa) RF-fingerprint dataset show that ProSSL gains 2.90%–6.01% absolute accuracy over state-of-the-art baselines, reaching 96.48% accuracy with 90% labels and 59.88% with only 5% labels. While on the public automatic dependent surveillance-broadcast(ADS-B) Top-10 dataset, ProSSL achieves 84.40% accuracy with 5% labeled data and 99.40% accuracy with 90%labeled data, again outperforming all competing methods. Open-set evaluations further demonstrate that overall accuracy rises from 18.81% when only two classes are known to 62.25% when eight classes are known, confirming strong generalization to unseen emitters and validating ProSSL’s robustness and practicality in realistic wireless environments.},
  archive      = {J_EAAI},
  author       = {Yiting Gao and Ke Wang and Hao Huang and Jiao Wang and Jiaxu Liu and Yao Zheng and Jianqing Li},
  doi          = {10.1016/j.engappai.2025.112361},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112361},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing scene text image super-resolution via gradient-based graph attention network. <em>EAAI</em>, <em>162</em>, 112360. (<a href='https://doi.org/10.1016/j.engappai.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text image super-resolution is crucial for enhancing text recognition in low-resolution real-world images. Existing methods usually overlook the structured and repetitive layout of text, which can serve as powerful prior knowledge for guiding reconstruction. In this work, we propose a novel framework that incorporates gradient-based graph attention to explicitly model patch-level text layout. The architecture combines a non-local group-wise attention module, a cascaded channel attention module, and a gradient-guided graph attention module to capture both global and local structural dependencies. This design enables more accurate restoration of text contours and layout consistency. Extensive experiments on the benchmark dataset demonstrate that our method achieves superior performance in both image quality and recognition accuracy, outperforming state-of-the-art methods. The code is available at: https://github.com/cvzxy/TSANv2 .},
  archive      = {J_EAAI},
  author       = {Xiangyuan Zhu and Xuchong Liu and Kehua Guo and Wei Zhao},
  doi          = {10.1016/j.engappai.2025.112360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing scene text image super-resolution via gradient-based graph attention network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs. <em>EAAI</em>, <em>162</em>, 112359. (<a href='https://doi.org/10.1016/j.engappai.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern biomedical research and livestock management, accurate multi-organ segmentation in pigs is essential for breeding programs. However, current methods face challenges due to low imaging contrast, size disparities, and organ shape variability. Additionally, the manual annotation of computed tomography (CT) scans is labor-intensive and costly, limiting available labeled samples. To address these issues, we propose a consistency regularization-based network guided by anatomical structural relationships and global organ category representations, specifically designed for multi-organ segmentation using a limited number of annotated CT scan samples from pigs. Specifically, we designed the SpatialLink Gated Recurrent Unit (GRU) module to extract anatomical structural information and capture dynamic spatial relationships between organs, thereby minimizing segmentation biases caused by organ shape variations. Moreover, we developed the Organ Category Coding module and Guidance module, which integrate consistency regularization and attention mechanisms, enabling the network to accurately extract global organ category representations during the decoding phase, even with a small number of labeled samples, significantly improving segmentation consistency across organs of different sizes. Additionally, We are the first to apply the Visual State Space block to multi-organ segmentation in pigs, using it to extract contextual information. Experiments on 60 pigs demonstrate that our method achieves state-of-the-art results, with significant improvements in segmentation accuracy for the gallbladder and bladder, including a 9.8% and 4.2% Dice score increase, respectively, and a 12.4% and 6.2% boost in Jaccard scores compared to compared with a selection of published methods.},
  archive      = {J_EAAI},
  author       = {Xiang Pan and Hang Fan and Jianlan Wang and Yan Fu and Wei Chu and Weipeng Tai and Jing Gu and Jianming Ni},
  doi          = {10.1016/j.engappai.2025.112359},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112359},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable chest X-ray localization using principal component-based feature selection in deep learning. <em>EAAI</em>, <em>162</em>, 112358. (<a href='https://doi.org/10.1016/j.engappai.2025.112358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification and localization of diseases in chest X-ray (CXR) images are crucial for early diagnosis and timely medical intervention. Traditional localization techniques like Class Activation Mapping (CAM), depend on Global Average Pooling (GAP) layers, restricting their flexibility, while gradient-based methods like Grad-CAM involve computational overhead and limited interpretability. To address these limitations, this study introduces a novel Principal Component Analysis (PCA)-based localization method that eliminates reliance on GAP layers and gradient computations. Utilizing publicly available Kaggle datasets, namely the COVID-19 Radiography Dataset and Tuberculosis (TB) Chest X-ray Database. The proposed approach employs PCA to compress high-dimensional convolutional feature maps extracted from the pretrained VGG16 model into a lower-dimensional, spatially meaningful representation. This enables rapid, interpretable heatmap generation highlighting precise abnormal regions. Experimental results demonstrate that the proposed method achieved an average training loss of 0 . 0835 ± 0 . 1830 and validation loss of 0 . 1385 ± 0 . 0741 across 5-fold cross-validation. In addition, it achieved an impressive accuracy of 97.5%, sensitivity of 98.2%, specificity of 99.4%, a Dice Similarity Coefficient (DSC) of 97.5%, and an Intersection-over-Union (IoU) of 95.1%. Compared to CAM, and Grad-CAM, PCA-based localization significantly reduces inference time, enhances interpretability, and provides robust multi-class localization performance suitable for clinical deployment.},
  archive      = {J_EAAI},
  author       = {Diwakar Diwakar and Deepa Raj},
  doi          = {10.1016/j.engappai.2025.112358},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112358},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable chest X-ray localization using principal component-based feature selection in deep learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast simulation for scattering muography applications using generative adversarial neural networks. <em>EAAI</em>, <em>162</em>, 112357. (<a href='https://doi.org/10.1016/j.engappai.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muography is an emergent non-destructive testing technique that uses cosmic muons to probe the interior of objects and structures. This technique can be employed to perform preventive maintenance of critical equipment in the industry in order to test the structural integrity of the facility. Several muography imaging algorithms based on machine learning methods are being developed in the recent years. These algorithms make exhaustive use of simulated data, usually using packages such as GEANT4 (GEometry ANd Tracking), that exhaustively simulate the detector, to produce training samples. This work presents a faster alternative for the generation of simulated samples based on generative adversarial neural networks. A speed up factor of 80 is observed with this system without any significant degradation of the quality of the simulation.},
  archive      = {J_EAAI},
  author       = {Rubén López Ruiz and Celia Fernández Madrazo and Sergio Sánchez Cruz and Lara Lloret Iglesias and Pablo Martínez Ruiz del Árbol},
  doi          = {10.1016/j.engappai.2025.112357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast simulation for scattering muography applications using generative adversarial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation. <em>EAAI</em>, <em>162</em>, 112356. (<a href='https://doi.org/10.1016/j.engappai.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular and real-time monitoring of corrosion is crucial for ensuring structural safety and extending the service life of infrastructure. With the continuous development of advanced structural health monitoring technologies, intelligent corrosion detection has become an inevitable trend. This study addresses the issues of low accuracy, incomplete detail processing, and missed or false detections in complex scenarios in steel structure corrosion detection, as well as the challenges of high complexity and insufficient real-time performance in deep learning models. We propose a high-performance, lightweight, real-time corrosion detection model, Real-Time Detection Transformer for Corrosion (RT-DETR-Corrosion), based on knowledge distillation. By incorporating lightweight optimization on the RT-DETR-R18 baseline model and a hybrid knowledge distillation approach, the model significantly improves real-time performance and detection accuracy, meeting the application requirements for efficiency and precision in steel structure corrosion detection. Experimental results show that the model exhibits excellent optimization effects in terms of localization accuracy, classification accuracy, and position regression error on both the training and validation sets, while also demonstrating strong generalization ability. In extreme weather conditions (such as rain, fog, snow, and strong light) and complex scenarios (such as occlusion, blur, and low-light environments), the model maintains stable Precision, Recall, and mAP metrics, validating its reliability and applicability in diverse real-world engineering environments. Moreover, visualized heatmap analysis of detection results for different scenarios further confirms the model's precise attention to corrosion regions and its generalization ability, providing essential technical support for steel structure corrosion risk assessment and intelligent monitoring, with significant potential for engineering applications.},
  archive      = {J_EAAI},
  author       = {Jia Hou and Wei Chen and Zhen Duan and Hang Li and Mingyu Yu},
  doi          = {10.1016/j.engappai.2025.112356},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112356},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy. <em>EAAI</em>, <em>162</em>, 112355. (<a href='https://doi.org/10.1016/j.engappai.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval-valued intuitionistic fuzzy set (IVIFS) represents an organic integration of interval-valued fuzzy sets and intuitionistic fuzzy sets, but it fails to meet the requirements of linearity and closure in arithmetic operations, rendering its computations relatively intricate. Consequently, this paper employs an interval partitioning strategy to mitigate the complexity of arithmetic operations, thereby constructing a novel fuzzy set structure characterized by efficient piecewise linear approximation capabilities. Furthermore, the paper presents the structural form of arithmetic operations for the IVIFS with piecewise linear approximation and demonstrates the simplicity of these operations by an numerical example. In addition, we extend the findings on information measures for polygonal interval-valued intuitionistic fuzzy set pertaining to abstract functions that fulfill particular criteria. Furthermore, we delve into the transformation relationships among these information measures, from which a range of structural formats for information measures can be deduced based on functional expressions and transformation relationships. Finally, similarity measures are applied to company site selection. The validity, practicality and stability of proposed measures have been proven through sensitivity analysis and comparative analysis.},
  archive      = {J_EAAI},
  author       = {Le Fu and Chunfeng Suo},
  doi          = {10.1016/j.engappai.2025.112355},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112355},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing. <em>EAAI</em>, <em>162</em>, 112354. (<a href='https://doi.org/10.1016/j.engappai.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-dimensional ensemble dispersion entropy (EDE 1D ) can effectively characterize the nonlinear dynamic characteristics of one-dimensional time series, but the complexity of two-dimensional space is not reflected, and only single-scale features can be captured. Firstly, to comprehensively capture the feature information of two-dimensional space, the symmetrized dot pattern (SDP) is introduced to overcome the shortcomings of the ordinary images lack of physical meaning and the time-frequency distribution methods exhibit incomplete information representation, etc. Simultaneously, the amplitude and frequency information are intuitively expressed by a two-dimensional mirror snowflake symmetrized image (MSSI 2D ). Secondly, to overcome the shortcomings of single-scale and traditional coarse-graining, a two-dimensional refined composite multi-scale coarse-graining method is proposed, which improves the accuracy of feature extraction and reduces the calculation deviation. After that, a new feature extraction method namely two-dimensional refined composite multi-scale revised ensemble dispersion entropy (RCMREDE 2D ) is proposed, whose parameter stability and performance are explored through simulation analysis. The results demonstrate that the RCMREDE 2D exhibits excellent stability and anti-noise interference ability. Based on the advantages of RCMREDE 2D , a novel fault diagnosis method for rolling bearings is developed by integrating RCMREDE 2D and a firefly algorithm optimized support vector machine (FA-SVM) multi-fault classifier for pattern recognition. The proposed method is further validated through two measured bearing data sets and five comparative methods, and the results indicate that the RCMREDE 2D and FA-SVM achieve the highest recognition accuracy while demonstrating superior stability.},
  archive      = {J_EAAI},
  author       = {Wenqing Ding and Jinde Zheng and Haiyang Pan and Jian Cheng and Jinyu Tong},
  doi          = {10.1016/j.engappai.2025.112354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse and robust elastic net support vector machine with bounded concave loss for large-scale problems. <em>EAAI</em>, <em>162</em>, 112352. (<a href='https://doi.org/10.1016/j.engappai.2025.112352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The elastic net support vector machine is an extensively employed method for addressing a range of classification tasks. Nevertheless, a significant drawback of the elastic net support vector machine is its high computational cost when dealing with large-scale classification problems. To address this drawback, we first introduce an innovative non-convex elastic net support vector machine model that employs our newly created bounded concave loss function, which effectively attains both sparsity and robustness. Based on proximal stationary point, we have effectively constructed an innovative optimality theory tailored for our newly created elastic net support vector machine model. By leveraging the innovative optimality theory, we have successfully developed a new and exceptionally effective algorithm designed to enhance computational efficiency through the division of the entire dataset into two distinct categories: working sets and non-working sets. During each learning cycle, the parameters associated with the non-working set remain unchanged. In contrast, the parameters related to the working set are subject to updates. Consequently, our new algorithm facilitates quicker modifications on smaller datasets, improving runtime efficiency and lowering computational complexity. Numerical experiments have demonstrated significant efficiency, particularly regarding computational speed, the number of support vectors, and classification accuracy, surpassing eleven other leading solvers.},
  archive      = {J_EAAI},
  author       = {Huajun Wang and Wenqian Li},
  doi          = {10.1016/j.engappai.2025.112352},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112352},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse and robust elastic net support vector machine with bounded concave loss for large-scale problems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of speaker verification: Methods, network architectures, tasks and challenges. <em>EAAI</em>, <em>162</em>, 112351. (<a href='https://doi.org/10.1016/j.engappai.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker verification is an important branch of biometric recognition, with wide applications in identity authentication, audio monitoring, and other fields. In recent years, deep learning and meta-learning have made remarkable advancements in the field of speaker verification. Therefore, it is necessary to update existing reviews of speaker verification to reflect the latest research developments. We review literature from the past decade to provide a timely and comprehensive survey of the field. First, we outline the concept and system process of speaker verification. Then, we analyze the speech preprocessing process and common acoustic features used in the systems. Next, we present an overview of speaker modeling approaches, covering traditional probabilistic methods, deep learning-based speaker methods, and meta-learning-based speaker methods, focusing on the latter two methods. We provide an in-depth analysis and summary of the characteristics and the latest network architectures of these methods, focusing on the development of Transformer and large-scale pre-trained Transformer. Furthermore, we introduce the datasets and evaluation metrics used in speaker verification systems, focusing on a detailed and fair comparison of the performance of text-dependent and text-independent speaker verification systems. Finally, we explore the challenges faced by speaker verification systems and discuss future research opportunities.},
  archive      = {J_EAAI},
  author       = {Weijie Wang and Hong Zhao and Yikun Yang and Yongjuan Yang},
  doi          = {10.1016/j.engappai.2025.112351},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112351},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of speaker verification: Methods, network architectures, tasks and challenges},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-cost and sparsity for continual semantic segmentation. <em>EAAI</em>, <em>162</em>, 112350. (<a href='https://doi.org/10.1016/j.engappai.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have contributed to significant progress in semantic segmentation tasks. However, deep neural networks exhibit a critical drop in performance due to catastrophic forgetting when they are required to learn new tasks incrementally. The more plastic the network is, the easier it can learn new tasks. Whereas, for continual semantic segmentation, it is more reliable to preserve the knowledge it has learned from previous tasks. Here, gated 0-1 Bernoulli variable is used as a regularization method to optimize performance by enhancing network sparsity. Then, the special case of gated 0-1 Bernoulli variable is applied in the replay-based method of continual semantic segmentation. Specifically, when the value of the sub-network sampling rate reaches 0.5, the network reaches the strongest stability. Finally, the gated 0-1 Bernoulli variable improves the network’s performance in complex scenarios and reduces cost under similar performance. Experimental results indicate that in using 100% samples for incremental training, the Mean Intersection over Union(mIoU) of the old classes improves by up to 4.6% and 5.5% compared to the baseline at the end of the overall training in continual semantic segmentation scenarios 10-1 and 10-2. Furthermore, in using 60% samples for incremental training, the performance for the old tasks only drops by less than a percentage, while the time cost to complete the full setup decreases by 22%.},
  archive      = {J_EAAI},
  author       = {Qing Ji and Bin Li and Shaobo Li and Hongchao An and Jing Yang},
  doi          = {10.1016/j.engappai.2025.112350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Low-cost and sparsity for continual semantic segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos. <em>EAAI</em>, <em>162</em>, 112349. (<a href='https://doi.org/10.1016/j.engappai.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activist video advertisements represent a strategic form of brand communication in which companies express their stance on social or environmental issues through emotionally driven storytelling and slogan-based narratives. Despite their growing prevalence, there is a notable lack of systematic and quantitative methods for evaluating their performance or comparing their effectiveness across competing brands. This research addresses that gap by proposing a comprehensive decision support system (DSS) designed to assess the performance of activist video advertisements in a structured and reproducible manner. The study introduces a novel hybrid multi-criteria decision-making (MCDM) framework: the spherical cubic fuzzy (SCF)–Aczel-Alsina–ranking comparison (RANCOM)–method based on the removal effects of criteria (MEREC)–deviation-based pairwise assessment ratio technique (DEPART). This methodology integrates subjective weights obtained via SCF–RANCOM and objective weights derived through SCF–MEREC, with both sets of weights combined using SCF-based aggregation operators that incorporate Aczel-Alsina t-norm and t-conorm functions. Performance rankings are then generated using the SCF–DEPART method. To demonstrate the model's applicability, a real-world case study involving eight sustainability-oriented activist video advertisements released in Türkiye was conducted. Evaluations were based on input from ten domain experts across eleven criteria. The analysis identified “convincingness and credibility” as the most critical factor, with “The Voice of Nature” campaign achieving the highest performance rating. The model's robustness was confirmed through scenario-based sensitivity analyses, and its consistency was validated by benchmarking against thirteen alternative MCDM approaches. The findings offer meaningful implications for both academic research and advertising practice.},
  archive      = {J_EAAI},
  author       = {Galip Cihan Yalçın and Karahan Kara and Gülcan Işık and Esra Serdar Tekeli and Vladimir Simic and Abdullah Ballı and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112349},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112349},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated clustering with mutual knowledge distillation for traffic flow prediction. <em>EAAI</em>, <em>162</em>, 112347. (<a href='https://doi.org/10.1016/j.engappai.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction plays a critical role in intelligent transportation systems. Conventional traffic flow prediction methods primarily rely on centralized training, which poses a risk of privacy leakage. Federated learning, a privacy-preserving framework to machine learning, enables distributed participants to jointly train a shared model without sharing local private data. However, traffic flow is typically collected from different devices and contains different temporal patterns, leading to non-independent and identically distributed. To address these challenges, we propose a traffic flow prediction method based on federated clustering with mutual knowledge distillation. We first perform temporal decomposition on the traffic flow data and use mutual learning with adaptive distillation loss to facilitate mutual knowledge transfer among local models during training. Then, we apply spectral clustering to cluster clients based on the cosine similarity of model parameters at the server and design a global model aggregation method to improve the performance of federated learning. Finally, the proposed method is evaluated on two real-world traffic datasets, and the experiment results show significant improvements over traditional federated learning approaches and also outperform federated mutual learning. The results demonstrate that the proposed method effectively captures temporal information and mitigates the effect of non-independent and identically distributed issues.},
  archive      = {J_EAAI},
  author       = {Yao Lin and Shengwu Xiong},
  doi          = {10.1016/j.engappai.2025.112347},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112347},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated clustering with mutual knowledge distillation for traffic flow prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques. <em>EAAI</em>, <em>162</em>, 112346. (<a href='https://doi.org/10.1016/j.engappai.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to identify failure types in Reinforced Concrete Shear Walls (RCSWs) by quantifying the contributions of shear and flexural modes in the force-deformation response of the walls. The supporting research database includes images, cyclic curve backbones, and geometric and mechanical characteristics of 253 RCSWs. Initially, the database is manually classified into shear, flexure, and shear-flexure failure modes based on observations of surface damage and the cyclic response of the wall. Subsequently, unsupervised clustering and supervised learning algorithms are employed to probabilistically quantify and predict the participation of flexural and shear modes in the overall seismic response of the walls, respectively. The unsupervised model, utilizing the K-means algorithm, identifies the primary failure modes of the walls, achieving over 90 % concordance with manual expert labeling. Based on the results of unsupervised clustering, a hybridity index is proposed to demonstrate the contributions of shear and flexure failure modes to the overall seismic response. Supervised learning is then used to predict hybridity indices from wall characteristics, with the Extremely Randomized Trees (Extra Trees) model achieving the best results based on a balanced evaluation of multiple performance metrics. SHapley Additive exPlanations (SHAP), a tool for exploring model sensitivity, highlights the aspect ratio as the key influencing factor on failure mode, in accordance with relevant structural engineering codes and standards. Implementation of the proposed framework in exploring the behaviors of four unseen case studies reveals a significant correlation between the predicted hybridity indices and observed damage, consistent with existing guidelines.},
  archive      = {J_EAAI},
  author       = {Pouya Ebrahimi and Amir Hossein Asjodi and Kiarash M. Dolatshahi},
  doi          = {10.1016/j.engappai.2025.112346},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112346},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path multiple attention-guided feature interaction network for camouflaged object detection. <em>EAAI</em>, <em>162</em>, 112345. (<a href='https://doi.org/10.1016/j.engappai.2025.112345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Camouflaged Object Detection (COD) methods rely on features from a pre-trained backbone with a single-encoder structure, leading to initial features biased towards global or local preferences. This affects subsequent feature modeling and degrades COD performance. Some studies use modular or auxiliary flow structures to balance feature preferences but often focus only on interactions between hierarchical features or information flows, ignoring potential redundancy or noise within aggregated features. Therefore, we propose a novel dual-path multiple attention-guided feature interaction network (DMAFI-Net) for COD, which contains four main components: global and local features interaction module (GLFI), intra-feature interaction module (IFI), multi-scale feature enhancement module (MFE), and two decoders including neighbor connection decoder based feature aggregation (NFA) and refine decoder. Specifically, the GLFI is designed to implement the interaction and combination of global and local features, and the combined features will be sent to IFI to mine intra-feature information. Besides, the MFE is introduced to further enrich the extracted features obtained in the IFI. In the feature decoding stage, the NFA module utilizes neighbor connection decoder to fuse multi-scale features and ultimately generates a coarse prediction. Finally, the refine decoder leverages multiple attention modules to refine the initial prediction with the combined features as auxiliary cues and obtain the final camouflaged map. Extensive experiments on four COD benchmark datasets demonstrate the superiority of the proposed framework when compared to 24 state-of-the-art (SOTA) methods in terms of five widely used evaluation metrics. Furthermore, the ablation studies show the effectiveness of main components of our DMAFI-Net.},
  archive      = {J_EAAI},
  author       = {Anzhi Wang and Jintao Wu and Shuang Zhao and Yun Liu},
  doi          = {10.1016/j.engappai.2025.112345},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112345},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-path multiple attention-guided feature interaction network for camouflaged object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection. <em>EAAI</em>, <em>162</em>, 112344. (<a href='https://doi.org/10.1016/j.engappai.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application of speech-based depression detection systems expands, differences in cross-domain data distribution pose significant challenges. This paper proposes the framework of Time–Frequency Calibrated Transfer Learning (TFCTL). This framework first introduces Frequency-Delay Neural Network (FDNN), inspired by Time-Delay Neural Network (TDNN), extending the concept of temporal feature extraction using sliding windows and weight sharing from the time domain to the frequency domain. A multi-level information aggregation module then integrates features of varying abstraction levels from both time-delay and frequency-delay neural networks, balancing global and local speech information. Finally, TFCTL uses transfer learning to calibrate the distribution of the aggregated time–frequency embedding vectors, uncovering commonalities of depression features across different domains. Cross-speaker and cross-corpus experiments were conducted using the Chinese Multimodal Depression Corpus (CMDC) and the Distress Analysis Interview Corpus Wizard-of-Oz (DAIC-WOZ). In cross-speaker scenarios, TFCTL achieved F1 scores of 0.7324 on DAIC and 0.9660 on CMDC, outperforming other methods. In cross-corpus scenarios, TFCTL achieved F1 scores of 0.6743 on DAIC and 0.6879 on CMDC, demonstrating its robustness in addressing domain mismatch issues. The source code used in the paper is available at https://anonymous.4open.science/r/TFCTL-A545/ .},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Li Ding and Zuo Yang and Zhe Wang and Ke Zhao},
  doi          = {10.1016/j.engappai.2025.112344},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112344},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual information guided invertible image hiding network. <em>EAAI</em>, <em>162</em>, 112343. (<a href='https://doi.org/10.1016/j.engappai.2025.112343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hiding techniques are commonly used for secure communication, copyright protection, and visual privacy. Invertible neural network (INN) have emerged as a promising approach for image steganography, enabling the concealment and recovery of secret images through forward and backward mappings within the network. However, existing methods often face limitations in the accuracy of recovered images due to challenges in estimating the lost information during the forward process. To address this issue, we propose a Mutual Information Guided Invertible Image Hiding Network (MIGIIHNet), which leverages mutual information estimation between the lost information and the stego image in the forward process to guide the backward mapping for reconstruction. Specifically, we propose a lightweight INN with a channel attention feature aggregation module (CAFAM), integrating a channel attention mechanism to optimize the multi-scale aggregation of both low-level and high-level features in a single forward pass. Also, an association learning module (ALM) is designed to model the mutual information between the stego image and the lost information during the forward hiding process. Then, the mutual information is utilized to reconstruct the secret image with high accuracy. Extensive experimental results show that MIGIIHNet outperforms existing state-of-the-art methods in terms of invisibility, security, and recovery accuracy, while maintaining low computational complexity.},
  archive      = {J_EAAI},
  author       = {Kehan Zhang and Fen Xiao and Jingwen Cai and Xieping Gao},
  doi          = {10.1016/j.engappai.2025.112343},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112343},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mutual information guided invertible image hiding network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales. <em>EAAI</em>, <em>162</em>, 112342. (<a href='https://doi.org/10.1016/j.engappai.2025.112342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor engineering, high yield of wafers relies on accurate detection and classification of wafer defects. The dataset for detecting wafer defects presents three primary challenges: (i) different background types, (ii) variable image or defect scales, and (iii) imbalanced data with a long-tailed distribution of defect types. These challenges create significant limitations for traditional classification techniques. To address these issues, we propose a stratified framework called Wafer Detection and Classification (WaferDC), designed specifically for detecting and classifying wafer defects from scanning electron microscope (SEM) images. Our framework achieves high defect detection performance on SEM wafer images by utilizing a multi-cluster memory bank, which effectively handles the challenges of (i) variable background types and (ii) differing image or defect scales. Building on this robust detection, we propose Segmentation and Mix (SegMix), a novel defect augmentation technique based on anomaly heatmaps, which enhances the reliability of defect detection and classification in a (iii) long-tailed imbalanced environment. Finally, we pass defect-classified images through a parameter-efficient fine-tuning (PEFT)-based classifier (Shiet al., 2023) utilizing a vision transformer (ViT) architecture, further improving overall defect detection and classification performance. We rigorously tested WaferDC on a proprietary SEM wafer dataset and the public Describable Textures Dataset-Synthetic (DTD-Synthetic) and Magnetic Tile Defect (MTD) datasets. The results confirm the effectiveness of our method in improving defect detection and classification in wafer manufacturing. Our code is available at https://github.com/SpatialAILab/WaferDC .},
  archive      = {J_EAAI},
  author       = {Taekyeong Park and Yongho Son and Sanghyuk Moon and Seungju Han and Je Hyeong Hong},
  doi          = {10.1016/j.engappai.2025.112342},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112342},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators. <em>EAAI</em>, <em>162</em>, 112341. (<a href='https://doi.org/10.1016/j.engappai.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating obstacle-free trajectories for robotic manipulators in unstructured and cluttered environments remains a significant challenge. Existing motion planning methods often require additional computational effort to generate the final trajectory by solving kinematic or dynamic equations. This paper highlights the strong potential of model-free reinforcement learning methods over model-based approaches for obstacle-free trajectory planning in joint space. We propose a fast trajectory planning system for manipulators that combines vision-based path planning in task space with reinforcement learning-based obstacle avoidance in joint space. We divide the framework into two key components. The first introduces an innovative vision-based trajectory planner in task space, leveraging the large-scale fast segment anything (FSA) model in conjunction with basis spline (B-spline)-optimized kinodynamic path searching. The second component enhances the proximal policy optimization (PPO) algorithm by integrating action ensembles (AE) and policy feedback (PF), which greatly improve precision and stability in goal-reaching and obstacle avoidance within joint space. These proximal policy optimization (PPO) enhancements increase the algorithm’s adaptability across diverse robotic tasks, ensuring consistent execution of commands from the first component by the manipulator, while also enhancing both obstacle avoidance efficiency and reaching accuracy. The experimental results demonstrated the effectiveness of proximal policy optimization (PPO) enhancements, as well as simulation-to-simulation (Sim-to-Sim) and simulation-to-reality (Sim-to-Real) transfer, in improving model robustness and planner efficiency in complex scenarios. These enhancements allowed the robot to perform obstacle avoidance and real-time trajectory planning in obstructed environments. https://sites.google.com/view/ftp4rm/home},
  archive      = {J_EAAI},
  author       = {Yongliang Wang and Hamidreza Kasaei},
  doi          = {10.1016/j.engappai.2025.112341},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112341},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm. <em>EAAI</em>, <em>162</em>, 112340. (<a href='https://doi.org/10.1016/j.engappai.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the urgency, timeliness and uncertainty of power batteries recycling, we extend a novel network model for retired battery recycling systems, bi-level capacitated location-routing problem with time windows for heterogeneous battery mixed-load (CLRPTW-HBM). Firstly, the expected interval and linear weighting methods are used to transform and process the lower-level multi-objective function that contains fuzzy variables. Secondly, a Transformer-based improved deep reinforcement learning algorithm (Transformer-IDRL) is proposed. (1) The bi-level CLRPTW-HBM is modeled as Markov decision process, and a policy network model with dual-layer encoder-decoder structure is designed based on Transformer architecture. (2) Randomly generate instance data, and the asynchronous advantage Actor-Critic with adaptive dynamic parameter tuning strategy is employed for training. (3) The action sampling strategy based on roulette reverse selection mechanism, and local search strategy incorporating problem characteristics are introduced to improve solution quality. Finally, extensive experiments are conducted on benchmark datasets and actual cases, and the results demonstrate superior performance of Transformer-IDRL, with an average Gap of 0.22 % and 0.19 %, a 5.30 % reduction in recycling cost, and a 6.06 % reduction in battery exposure risk. These satisfactory results highlight the feasibility and efficiency of the proposed model and method. Additionally, sensitivity analysis of model parameters shows that under different decision-maker preferences and vehicle loading capacity, the sensitivity range of path cost is [5.77 %, 39.85 %] and [16.04 %, 35.54 %], while that of exposure risk is [1.40 %, 3.39 %] and [1.35 %, 5.54 %], indicating that parameter variations significant influence the layout of recycling network and overall path cost. Therefore, decision-makers should flexibly adjust key parameters to balance economic benefits and sustainable development in battery recycling.},
  archive      = {J_EAAI},
  author       = {Mengna Zhao and Shiping Chen},
  doi          = {10.1016/j.engappai.2025.112340},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112340},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instantaneous power prediction for industrial robots using tree-based machine learning methods. <em>EAAI</em>, <em>162</em>, 112339. (<a href='https://doi.org/10.1016/j.engappai.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a tree-based machine learning methodology for instantaneous power prediction designed, tested and validated using data from an articulated industrial robot. The proposed methodology for instantaneous power prediction materializes through a generic system architecture with functionalities consisting of data acquisition, time alignment of data samples, storage, model learning, instantaneous power prediction and integration in time to evaluate energy consumption at robot operation level. This methodology is designed to evaluate offsite energy consumption of robotized workstations for different layouts characterized by relative position of the robot with respect to the serviced and fly-by points. This is important both for offline virtual commissioning of robotized workstations (determine layout) and for online operation for maintenance purposes (determine energy spikes different from normal model). The analyzed operation is the linear motion of the robot Tool Control Point in Cartesian space, characterized by the complexity of the kinematic model: each joint operates in coordinated motion, adjusting its velocity and acceleration continuously to ensure a straight path with constant speed. A custom Internet of things (IoT) device enables synchronized energy and motion data logging for robots, ensuring consistent values for sampled trajectories. Justification for the usage of tree-based methods and experimental results are provided.},
  archive      = {J_EAAI},
  author       = {Ionuţ Lenţoiu and Silviu Răileanu and Theodor Borangiu and Mihnea Constantinescu and Octavian Morariu},
  doi          = {10.1016/j.engappai.2025.112339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instantaneous power prediction for industrial robots using tree-based machine learning methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management. <em>EAAI</em>, <em>162</em>, 112338. (<a href='https://doi.org/10.1016/j.engappai.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wastewater treatment plants (WWTPs) are among the most energy-intensive components of urban infrastructure and bear strict regulatory responsibilities for wastewater quality. These dual challenges, minimizing energy consumption and maintaining environmental compliance, are deeply interrelated and must be managed simultaneously to achieve sustainable plant operation. This study proposes a framework that comprises two customized components. The first component employs a voting ensemble model based on transformer architecture to predict energy consumption. It processes heterogeneous feature domains — including hydraulic, wastewater, and climatic variables — through parallel attention-driven streams. The outputs from these streams are then aggregated using a weighted voting mechanism to produce the final prediction. Second, a multitask Bidirectional Gated Recurrent Unit (Bi-GRU) forecasts wastewater quality indicators concurrently (ammonia, Biochemical Oxygen Demand (BOD), and Chemical Oxygen Demand (COD)), capturing shared temporal dependencies and reducing model complexity. A hybrid preprocessing strategy is applied, incorporating domain-aware outlier detection (z-score and Interquartile Range (IQR)), K-Nearest Neighbors (KNN) Imputation, and feature selection using Extreme Gradient Boosting (XGBoost). Experimental results showed that. The voting ensemble model achieved the best results for energy consumption prediction with 31.61 of Root Mean Squared Error (RMSE). The multitask Bi-GRU achieved the best results for wastewater quality indicators with RMSE at 6.1689, 48.0323, and 88.2214 for ammonia, BOD, and COD, respectively. This work is among the first to integrate transformer ensembles and multitask learning in a unified WWTP forecasting system. Simultaneously addressing energy efficiency and water quality assurance, this offers a practical, scalable, and intelligent decision-support tool for sustainable wastewater management.},
  archive      = {J_EAAI},
  author       = {Hager Saleh and Sherif Mostafa and Shaker El-Sappagh and Abdulaziz AlMohimeed and Michael McCann and Saeed Hamood Alsamhi and Niall O’Brolchain and John G. Breslin and Marwa E. Saleh},
  doi          = {10.1016/j.engappai.2025.112338},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112338},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards non-visual bowel cancer diagnosis: A certainty-aware data-driven method of lesion characterisation using a vibrating capsule. <em>EAAI</em>, <em>162</em>, 112336. (<a href='https://doi.org/10.1016/j.engappai.2025.112336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in miniaturised, dynamically actuated robots have opened new pathways for non-visual, in-situ disease diagnosis. This study explores a novel method for early bowel cancer detection using a self-propelled robotic capsule that navigates the bowel and detects lesions based on variations in tissue stiffness. The approach capitalises on the sensitivity of the capsule’s dynamic responses to surrounding tissue properties. A dual-phase machine learning framework is proposed. The first phase uses regression models including multilayer perceptron (MLP), support vector regression (SVR), and Gaussian process regression (GPR) to predict tissue stiffness from displacement signal features. The second phase uses a Gaussian mixture model (GMM) to cluster the predicted stiffness values into different categories. Unlike our previous work, this study emphasises the robustness of the models under varying data conditions using both accuracy and reliability-oriented metrics. Based on our studies, MLP provided the most reliable regression results for simulated data and downstream clustering, though GPR performed better on experimental datasets. SVR consistently underperformed, especially on experimental data. The GMM achieved over 89% clustering accuracy across both simulated and experimental datasets, with improved results when predictions from more accurate regression models are used as the inputs. This work demonstrates a promising step toward dynamic, in-situ lesion characterisation and highlights the potential for integrating lesion biomechanics into future endoscopic diagnosis.},
  archive      = {J_EAAI},
  author       = {Kenneth Omokhagbo Afebu and Yang Liu and Evangelos Papatheou and Shyam Prasad},
  doi          = {10.1016/j.engappai.2025.112336},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112336},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards non-visual bowel cancer diagnosis: A certainty-aware data-driven method of lesion characterisation using a vibrating capsule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural model of the adaptive tuned particle impact damper. <em>EAAI</em>, <em>162</em>, 112334. (<a href='https://doi.org/10.1016/j.engappai.2025.112334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a novel approach for the modeling of the Adaptive Tuned Particle Impact Damper (ATPID) using Multilayer Perceptron (MLP). The main motivation was the recognition that such an approach can support the development of novel neural modeling and the optimal determination of damper parameters in terms of mechanical vibration attenuation. The training data were obtained using a theoretical model validated experimentally. The optimally selected MLP was compared with other regression models using 10 different metrics. A hyperparameter tuning of the determined neural network architecture was conducted based on the input parameters such as excitation amplitude, grain mass, and ATPID damper height. The analyses show that the proposed neural network could quickly and accurately estimate the system’s vibration amplitude and efficiently predict the optimal damper height. The ability to effectively determine the correct optimal height is crucial for ATPID damper control. The high efficiency in predicting the system’s vibration amplitude allows for the replacement of the theoretical model with applied time-consuming contact forces. The MLP accurately estimated vibration amplitudes with 1%–10% error for interpolated data and up to 15% for extrapolated cases. The issue raised is particularly important from the perspective of real-time damper control. It was found that computing a single case using the artificial neural network is more than ten times faster compared to the theoretical model. Therefore, the proposed ATPID damper model based on a neural network forms the basis for further considerations and scientific research to finally propose a control algorithm in the future.},
  archive      = {J_EAAI},
  author       = {Mateusz Żurawski and Karolina Grabska and Robert Zalewski and Adam Kulawik},
  doi          = {10.1016/j.engappai.2025.112334},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112334},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural model of the adaptive tuned particle impact damper},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations. <em>EAAI</em>, <em>162</em>, 112333. (<a href='https://doi.org/10.1016/j.engappai.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion-cause pair extraction in conversations (MECPEC) has gradually evolved into an emerging task aimed at discovering deeper causal relationships between emotions and their corresponding causes in conversational contexts. It has widespread application in fields such as human–computer interaction, social media analysis, customer feedback management, and empathetic companion, among others. However, the challenges posed by the oversimplified multimodal feature fusion mechanism and the failure to account for the relative positional relationship between emotions and causes still hinder the performance of MECPEC. In this study, we propose an adaptive hybrid machine reading comprehension (AHMRC) framework to extract potential emotion-cause pairs inherent in conversations. The MECPEC task is first transformed into a two-round hybrid machine reading comprehension task that sequentially enforces the global emotion query and the local cause query with the goal of exploring the relative position constraint specific to conversations. Subsequently, an adaptive multimodal attention module is designed by incorporating features extracted from text, video, and audio modalities, and adaptively fusing them according to their contributions. Extensive experiments were carried out on the benchmark datasets to demonstrate the effectiveness of the proposed AHMRC framework in comparison to other state-of-the-art methods in the literature.},
  archive      = {J_EAAI},
  author       = {Guorui Li and Xufeng Duan and Cong Wang and Sancheng Peng},
  doi          = {10.1016/j.engappai.2025.112333},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112333},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction. <em>EAAI</em>, <em>162</em>, 112332. (<a href='https://doi.org/10.1016/j.engappai.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretical and computational modelling of heat conduction in a functionally graded cylinder has been rigorously investigated in prior studies, owing to its critical significance in high-stakes engineering applications such as nuclear reactor design, aerospace structural systems, and pressure vessel technology. Despite this extensive body of work, the majority of these studies have mostly focused on simplified two-dimensional models, frequently presuming idealized thermal parameters such as isotropic thermal conductivity, constant convection coefficients, and spatially uniform ambient temperatures. These simplifications overlook the crucial role of spatially varying thermal characteristics and three-dimensional (3D) temperature distributions, which are essential for accurately simulating the complex heat conduction behaviors found in real-world engineering. Unlike prior research, this study presents an analytical solution for heat conduction under non-homogeneous generalized Robin boundary conditions, capturing 3D thermal conductivity inhomogeneities along three orthogonal directions using Sturm-Liouville theory and finite integral transforms. However, while such analytical methods are highly accurate for simpler geometries, they often encounter significant challenges when extended to scenarios involving complex material gradients and irregular domains. A gradient-enhanced physics-informed neural network (g-PINN) framework is proposed to tackle these challenges, utilizing neural networks that incorporate physical laws and gradient information to enhance its applicability to complex configurations. This combined approach presents a novel framework that integrates classical theory with machine learning, facilitating precise modelling of thermal phenomena in functionally graded cylinders. The findings indicate that both the analytical and machine learning approaches (g-PINN) align closely with presented solutions, precisely capturing the energy equation and more complex boundary conditions.},
  archive      = {J_EAAI},
  author       = {Palash Das and Md Ashraful Islam and Dipayan Mondal},
  doi          = {10.1016/j.engappai.2025.112332},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112332},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism. <em>EAAI</em>, <em>162</em>, 112331. (<a href='https://doi.org/10.1016/j.engappai.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spurious drug–drug interactions arising from experimental biases can compromise treatment safety and hinder effective clinical decision-making for patients. However, current molecular representation learning methods still face significant challenges in addressing this problem. First, most graph neural network-based approaches consider only single-direction interactive semantic extraction between drug molecules, failing to capture more granular relationships between drugs fully. Moreover, during training, they are vulnerable to noise from negative sampling and cannot sufficiently leverage the complete drug–drug interaction annotations, resulting in reduced robustness and accuracy in downstream tasks. To this end, we propose a robust spurious DDI detection framework that employs chi-square-guided bidirectional attention to capture fine-grained and bidirectional interaction patterns. First, considering their mutual information flow, a two-way cross-attention mechanism is introduced for a more granular extraction of cross-drug molecular interaction semantic representations through bidirectionally perceiving interactive features between drugs. Second, on the basis of robust minimum covariance determinant theory, we propose a chi-square distribution-based spurious detection method to approximate the correctly annotated drug–drug interactive feature space to a chi-square distribution for a complete feature representation. Extensive experiments on benchmark datasets further validate our method’s effectiveness over state-of-the-art methods, particularly in noisy interference scenarios. Our code is available at https://github.com/AlexCostra/cd .},
  archive      = {J_EAAI},
  author       = {Wei-Yu Shi and Yi-Jia Zhang and Jin-Zhong Ning},
  doi          = {10.1016/j.engappai.2025.112331},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112331},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel high-accuracy graph neural network-based rumor detection method. <em>EAAI</em>, <em>162</em>, 112329. (<a href='https://doi.org/10.1016/j.engappai.2025.112329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors spreading on social media platforms result in potential damages. A precise rumor detection mechanism can help form a healthy public opinion environment. In recent years, deep learning-based rumor detection methods, especially graph model-based ones, have risen and reached promising performance. However, there are several defects in existing methods, which limit models from efficiently utilizing the propagation structure. In this paper, we propose a novel rumor detection model, which has high accuracy and reaches state-of-the-art performance. First, we design a powerful comprehensive rumor feature extractor that explicitly overcomes the restriction of previous Graph Neural Networks-based models. Then, by introducing Kernel Subtree features, our model acquires the capability to learn crucial local features from important nodes. Comparative experiments performed on two real-world social media platforms demonstrate that our work reaches state-of-the-art performance, which outperforms the best baseline with 1.6% and 1.9% in accuracy respectively.},
  archive      = {J_EAAI},
  author       = {Xi Xiao and Zeming Wu and Chengzong Cai and Tian Bian and Guangwu Hu and Qing Li and Cheng Huang},
  doi          = {10.1016/j.engappai.2025.112329},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112329},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel high-accuracy graph neural network-based rumor detection method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting. <em>EAAI</em>, <em>162</em>, 112325. (<a href='https://doi.org/10.1016/j.engappai.2025.112325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dependable stock price predictions are vital for optimizing economic policies and investment strategies in both national and corporate settings. However, the intrinsic volatility and intricacy of stock prices pose considerable challenges. Thus, this paper introduces a novel Committee of Multi-scale Nonlinear Learning Frameworks (CoML) that employs a three-stage model: decomposition, reconstruction, and prediction. First, a complete ensemble empirical mode decomposition with adaptive noise is adopted to decompose the original stock prices into multiple intrinsic mode functions. Secondly, a fine-to-coarse algorithm is applied to reconstruct the intrinsic mode functions, so as to effectively extract short-term fluctuations and long-term trends. Finally, an ensemble of nonlinear models including bidirectional long short-term memory (BiLSTM), support vector regression (SVR) and multi-layer perceptron (MLP) is used to learn and forecast features extracted to obtain high performance. Experimental results indicate that the model performs exceptionally well in both emerging and developed markets highlighting the innovative capabilities of CoML in highly complex and volatile financial markets. The proposed model is further validated using Model Confidence Set and the results indicate that the model is statistically significant.},
  archive      = {J_EAAI},
  author       = {Qian He and Yanhui Liang and Yu Lin and Dazhi Pan and Yuying Yue},
  doi          = {10.1016/j.engappai.2025.112325},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112325},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning robust brain tumor segmentation under label corruption and data scarcity. <em>EAAI</em>, <em>162</em>, 112322. (<a href='https://doi.org/10.1016/j.engappai.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models for medical image segmentation often struggle with performance issues when datasets are affected by label noise or annotation errors, commonly introduced during manual process or lack of proficiency. These noisy annotations disrupt the loss function, leading to "partially incorrect" gradients that impair the model's learning and overall performance. Additionally, the limited availability of scanned data for training often makes it challenging to develop a robust model. A common approach to address this issue is to leverage similar large annotated datasets. However, differences in dataset distributions can also lead to inconsistencies, introducing erroneous gradients during training and further impacting model performance. To address these challenges, we propose MGR-DAS (Meta-Gradient Reweighting via Direction-Aware Similarity), a novel meta-learning-based approach that can automatically evaluate the reliability of training samples during training using a small, clean subset easily curated from the noisy dataset. Our method quantifies reliability by measuring the cosine similarity between the gradients of noisy training samples and those of the clean subset. Samples with higher gradient alignment are assigned greater weights during training, effectively reducing the impact of noisy labels and improving model robustness. We evaluate our method using three standard metrics for medical image segmentation: the Dice Similarity Coefficient (DSC), the 95th percentile Hausdorff Distance (HD95), and Intersection over Union (IoU). The proposed MGR-DAS achieved an overall 2.4 % improvement in the DSC on the brain tumor segmentation (BraTS, 2021) dataset. Remarkably, even with only 10 clean annotations used in the reweighting algorithm, our method yielded a 28.7 % gain in DSC. In real-world, data-scarce scenarios, our proposed MGR-DAS also improved the overall DSC score by 2.6 % on BraTS pediatric (BraTS-PEDs) and by 1.0 % on BraTS-Africa, demonstrating strong generalizability and robustness. Experimental results confirm that the proposed method reliably identifies noisy data, prioritizes clean data through adaptive weighting, and outperforms existing fine-tuning, curriculum learning techniques, and other meta-learning frameworks commonly employed in classification tasks.},
  archive      = {J_EAAI},
  author       = {Abdulkhalek Al-Fakih and Abbas Mohamed Rezk and Abdullah Shazly and Kanghyun Ryu and Mohammed A. Al-masni},
  doi          = {10.1016/j.engappai.2025.112322},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112322},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning robust brain tumor segmentation under label corruption and data scarcity},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale embedding with guided attention for medical image analysis. <em>EAAI</em>, <em>162</em>, 112319. (<a href='https://doi.org/10.1016/j.engappai.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of medical images is pivotal for enhancing diagnostic accuracy and optimizing treatment strategies. Traditional methods encounter challenges in delineating clear inter-class boundaries within high-dimensional feature spaces affected by class overlap. This study introduces a Multi-Scale Embedding with Guided Attention (MSEGA) framework based on deep learning autoencoders that integrates innovative guided attention learning mechanisms without explicit target mask supervision for tumor detection and classification. The framework incorporates Multi-scale Feature Extraction Blocks and Depthwise Separable Convolution Blocks to comprehensively capture image features. Through Channel Attention and Spatial Attention mechanisms, the MSEGA method prioritizes critical tumor regions across scales. We also propose a novel interpretable embedding learning loss function to optimize image embeddings, highlighting crucial regions and refining category distinctions. Empirical evaluations on two brain tumor Magnetic Resonance Imaging (MRI) datasets demonstrate our approach surpasses conventional methods including Convolutional Neural Networks and Vision Transformers in classification accuracy and generalizability. These results underscore the framework’s potential as a versatile artificial intelligence-powered tool in medical image analysis.},
  archive      = {J_EAAI},
  author       = {Zeyan Li and Yifei Peng and Yizun Lin},
  doi          = {10.1016/j.engappai.2025.112319},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112319},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale embedding with guided attention for medical image analysis},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient anchor-free model for ore particle size detection. <em>EAAI</em>, <em>162</em>, 112304. (<a href='https://doi.org/10.1016/j.engappai.2025.112304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection of ore size is crucial in mineral processing, directly impacting equipment efficiency and product quality. However, traditional anchor-based models often struggle with the irregular shapes and varying scales of ore particles, resulting in limited performance. To overcome these challenges, an anchor-free detection framework was proposed. It incorporates a cross-stage partial bottleneck and a spatial pyramid pooling cross-stage partial connections (SPPCSCP-DualConv), both enhanced with dual convolution, to improve feature extraction and multi-scale fusion. In the backbone, the dual convolution module combines group convolution with heterogeneous convolution to improve feature diversity. The SPPCSCP-DualConv module further enhances feature representation in complex backgrounds. Additionally, a simplified path aggregation network (simPANet) feature fusion module is employed in the neck to refine the integration of multi-scale features. The proposed model was trained using a combination of binary cross-entropy, complete intersection over union (IoU), and distribution focal loss to optimize detection accuracy. The proposed model achieved a mean average precision of 86.80 % at an IoU threshold of .5 and 78.50 % across IoU thresholds from .5 to .95, surpassing existing methods while maintaining a lightweight architecture with only 10.10 million parameters and 89.45 giga floating point operations per second. Ablation studies confirmed the effectiveness of the simPANet and SPPCSPC-DualConv modules in enhancing feature representation. Generalization tests across mining sites with similar distributions demonstrated strong performance, although limitations remain for exceptionally large ore blocks due to dataset bias. The proposed model significantly improved the accuracy and efficiency of ore particle size detection, providing reliable real-time insights to improve grinding control and mineral processing operations.},
  archive      = {J_EAAI},
  author       = {Kanghui Zhang and Qingkai Wang and Guobin Zou and Jiawei Yang and Tao Song and Yang Liu and Daoxi Liu},
  doi          = {10.1016/j.engappai.2025.112304},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112304},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient anchor-free model for ore particle size detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance. <em>EAAI</em>, <em>162</em>, 112300. (<a href='https://doi.org/10.1016/j.engappai.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wood surface defect segmentation is extremely critical for defect refinement and quality control of wooden products. However, it is a challenging task to develop an efficient method with current algorithms due to the complicated characteristics of wood defects with obscure boundary, intraclass difference and interclass similarity. To address these issues, a lightweight network via multi-dimension boundary perception and guidance is proposed for precise segmentation of wood defects. At first, based on the Segformer, a boundary prediction branch is added to enrich detailed boundary information in the encoder, and supervised by the Gaussian signal and cosine similarity, to balance the effect of the boundary gradient information. Then, a double-flow enhancing module is designed to integrate the adjacent level features, by embedding two enhancing paths, to adaptively generate discriminative information of the defects. Finally, a binary segmentation head following the predicted map is introduced to strengthen the penalty for the false prediction results of the boundary. Experimental results demonstrate the proposed method outperforms the state-of-the-arts on our wood surface defect dataset, as well as on three public datasets.},
  archive      = {J_EAAI},
  author       = {Yuhang Zhu and Ye Lin and Zhezhuang Xu and Dan Chen and Kunxin Zheng and Yazhou Yuan},
  doi          = {10.1016/j.engappai.2025.112300},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112300},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks. <em>EAAI</em>, <em>162</em>, 112295. (<a href='https://doi.org/10.1016/j.engappai.2025.112295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the wood industry, logs are commonly quality screened by discrete X-ray scans on a moving conveyor belt from a few source positions. Typically, the measurements are obtained in a single two-dimensional (2D) plane (a “slice”) by a sequential scanning geometry. The data from each slice alone does not carry sufficient information for a three-dimensional tomographic reconstruction in which biological features of interest in the log are well preserved. In the present work, we propose a learned iterative reconstruction method based on the Learned Primal-Dual neural network, suited for sequential scanning geometries. Our method accumulates information between neighbouring slices, instead of only accounting for single slices during reconstruction. Evaluations were performed by training U-Nets on segmentation of knots (branches), which are crucial features in wood processing. Our quantitative and qualitative evaluations show that with as few as five source positions our method yields reconstructions of logs that are sufficiently accurate to identify biological features like knots (branches), heartwood and sapwood.},
  archive      = {J_EAAI},
  author       = {Buda Bajić and Johannes A.J. Huber and Benedikt Neyses and Linus Olofsson and Ozan Öktem},
  doi          = {10.1016/j.engappai.2025.112295},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112295},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators. <em>EAAI</em>, <em>162</em>, 112285. (<a href='https://doi.org/10.1016/j.engappai.2025.112285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to long-term outdoor exposure, composite insulators are susceptible to degradation and abnormal temperature rise, making Unmanned Aerial Vehicle (UAV)-based infrared inspections essential for effective monitoring. However, traditional manual interpretation of these images is inefficient and subjective. To improve detection automation and accuracy, we propose an intelligent detection method for composite insulators in infrared images based on an improved You Only Look Once version 11 (YOLOv11) model. The proposed approach introduces Oriented Bounding Boxes (OBBs) for annotation and designs an Angle-Enhanced Probabilistic Intersection over Union (AE-ProbIoU) loss function to enhance the model's ability to detect rotated objects. Experimental results demonstrate that the proposed Angle-Enhanced You Only Look Once (AE-YOLO) model achieves a mAP50:95 of 94.0 % and an angle prediction accuracy of 94.3 %. In addition, a temperature extraction module based on the OBBs is developed to accurately derive the temperature profile of the insulator core rod. This method significantly enhances the intelligence level of infrared image analysis for composite insulators and provides technical support for condition assessment and fault prediction in power transmission lines.},
  archive      = {J_EAAI},
  author       = {Xinzhe Yu and Zhenan Zhou and Yu Deng and Kun Zhang and Chen Gu and Zheyuan Liu and Songsong Zhou},
  doi          = {10.1016/j.engappai.2025.112285},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112285},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures. <em>EAAI</em>, <em>162</em>, 112283. (<a href='https://doi.org/10.1016/j.engappai.2025.112283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of vehicle states is a fundamental component of vehicle stability control systems. To address the issue of inaccurate estimation of vehicle state parameters resulting from yaw rate sensor failures, this study proposes a three-mode collaborative fault-tolerant state estimation method based on Bayesian Bidirectional Long Short-Term Memory (BiLSTM) kinematics-dynamics fusion. First, the kinematics-based method is established using the kinematics model. Second, the dynamics-based method is designed by integrating the Unscented Kalman Filter (UKF) with the dynamics model. Subsequently, a BiLSTM network fusion model based on Bayesian optimization is presented. The model utilizes estimates from kinematic and kinetic methods as a priori inputs and combines the bidirectional information capturing capability of BiLSTM with hyperparameter tuning from Bayesian optimization. The results indicate that when the yaw rate sensor fails, the proposed method achieves an average Root Mean Square Error (RMSE) of 0.0276 km per hour (km/h) for longitudinal speed, 0.0008 radian (rad) for side slip angle, and 0.0072 radian per second (rad/s) for yaw rate across all scenarios. This performance demonstrates a superiority over various maneuvers. This paper combines kinematics, dynamics, and deep learning to provide a reliable solution for fault-tolerant estimation of vehicle states.},
  archive      = {J_EAAI},
  author       = {Min Gao and Jiaqi Li and Wei Wang and Renguang Wang and Jin Luo and Jing Li},
  doi          = {10.1016/j.engappai.2025.112283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-vocabulary object detection via neighboring region attention alignment. <em>EAAI</em>, <em>162</em>, 112270. (<a href='https://doi.org/10.1016/j.engappai.2025.112270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nature of diversity in real-world environments necessitates neural network models to expand from closed category settings to accommodate novel emerging categories. In this paper, we study open-vocabulary object detection (OVD), which facilitates the detection of novel object classes under the supervision of only base annotations and open-vocabulary knowledge. However, we find that the inadequacy of distilled information from the detector head during the alignment process inevitably constrains the performance of recent distillation-based OVD strategies. To this end, we propose Neighboring Region Attention Alignment (NRAA), which performs alignment within the attention mechanism to boost the open-vocabulary inference. Specifically, for a given proposal region, we randomly explore the neighboring boxes to capture the surrounding contextual vocabulary knowledge. Then, a set of regional token features, encompassing both the proposal and neighboring regions, utilize our proposed Neighboring Region Attention (NRA) to extract interaction information. Finally, this information is seamlessly provided to the distillation procedure to assist the alignment between the detector and the pre-trained vision-language models (VLMs). Extensive experiments validate that our proposed model exhibits superior performance on open-vocabulary benchmarks.},
  archive      = {J_EAAI},
  author       = {Sunyuan Qiang and Xianfei Li and Yanyan Liang and Wenlong Liao and Tao He and Pai Peng},
  doi          = {10.1016/j.engappai.2025.112270},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112270},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Open-vocabulary object detection via neighboring region attention alignment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration. <em>EAAI</em>, <em>162</em>, 112269. (<a href='https://doi.org/10.1016/j.engappai.2025.112269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of industrial robots, ensuring operational reliability and Long-Term Autonomy hinges on the accurate detection of anomalies. However, this sample difference due to noise, joint random errors and sensor errors increases the challenge of robot anomaly detection. To address this problem, an unsupervised deep learning method based on inertial measurement unit (IMU) error calibration is proposed. Firstly, the attitude signals acquired by the IMU from the end of the robot were calibrated using Kalman filtering. The three dimensional (3D) free acceleration was corrected based on the calibrated attitude signal and the calibrated 3D free acceleration signal was used as a signal sample. Secondly, a time and frequency convolutional autoencoder model (TFCAE) is proposed. And the distribution of the different component signals is fitted by stacking multiple encoder modules and 3D-TFCAE is used for 3D free acceleration signal reconstruction model. Then, the error sphere radius is calculated based on the reconstruction error of the 3D free acceleration signal. And the error sphere radius is used as the anomaly detection threshold to realize the robust detection of different types of anomalies. The model was evaluated on a constructed anomaly dataset. This study contributes an innovative 3D-TFCAE architecture, integrating Kalman filtering with time-frequency feature fusion, markedly enhancing anomaly detection in complex signal environments. Experimental findings reveal that 3D-TFCAE significantly outperforms 18 baseline models, improving detection accuracy by about 20 %–40 %, offering an effective solution for high-precision anomaly detection in industrial robots. The code for this project is available at https://github.com/LJlong977/3DTFCAE .},
  archive      = {J_EAAI},
  author       = {Jianlong Li and Xiaoqin Liu and Xing Wu and Dongxiao Wang and Kai Xu and Yashan Li},
  doi          = {10.1016/j.engappai.2025.112269},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112269},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging. <em>EAAI</em>, <em>162</em>, 112259. (<a href='https://doi.org/10.1016/j.engappai.2025.112259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic tomography (PAT) offers optical contrast, whereas magnetic resonance imaging (MRI) excels in imaging soft tissue and organ anatomy. The fusion of PAT with MRI holds promising application prospects due to their complementary advantages. Existing image fusion has made considerable progress in pre-registered images, yet spatial deformations are difficult to avoid in medical imaging scenarios. More importantly, current algorithms focus on visual quality and statistical metrics, thus overlooking the requirements of high-level tasks. To address these challenges, we propose an unsupervised fusion model, termed PAMRFuse+, which integrates image generation and registration. Specifically, a cross-modal style transfer network is introduced to simplify cross-modal registration to single-modal registration. Subsequently, a multi-level registration network is employed to predict displacement vector fields. Furthermore, a dual-branch feature decomposition fusion network is proposed to address the challenges of cross-modal feature modeling and decomposition by integrating modality-specific and modality-shared features. PAMRFuse+ achieves satisfactory results in registering and fusing unaligned PAT–MRI datasets. Moreover, for the first time, we evaluate the performance of medical image fusion with multi-organ instance segmentation. Extensive experimental demonstrations reveal the advantages of PAMRFuse+ in improving the performance of medical image analysis tasks.},
  archive      = {J_EAAI},
  author       = {Yutian Zhong and Jinchuan He and Zhichao Liang and Shuangyang Zhang and Qianjin Feng and Lijun Lu and Li Qi},
  doi          = {10.1016/j.engappai.2025.112259},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112259},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning methods comparison by using statistical tests in solar energy forecasting based on weather features. <em>EAAI</em>, <em>162</em>, 112239. (<a href='https://doi.org/10.1016/j.engappai.2025.112239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change necessitates precise solar forecasting due to its weather-dependent intermittency. Key parameters - temperature, visibility, altitude, pressure, and wind speed - were analyzed using non-parametric tests. We prioritized short-term weather patterns over random data splitting for enhanced accuracy.Non-parametric tests, such as the Kolmogorov-Smirnov test, were used to assess data normality and select highly correlated features. Principal Component Analysis (PCA) reduces dataset dimensionality while preserving critical trends. Various machine learning approaches were evaluated, including: weighted linear regression (both with and without dimensionality reduction), boosted regression trees, and deep learning architectures-comprising both fundamental models (Convolutional Neural Networks [CNNs] and Recurrent Neural Networks [RNNs]) and advanced hybrid architectures (Temporal Convolutional Networks (TCN) Convolutional Neural Network-Long Short-Term Memory network (CNN-LSTM). All models were optimized through systematic hyperparameter tuning to enhance predictive performance, reduce computational complexity, and improve learning convergence rates. Special attention was given to addressing vanishing gradient problems in deep neural network implementations. Results show TCN outperform other deep learning models, achieving lower training and testing errors with fewer parameters and reduced time complexity. CNN-LSTM models, designed for spatial-sequence prediction, perform well but require more parameters and computational time. The lowest test and training errors belong to CNN-LSTM and TCN, with approximately 9 % and 2 % lower than the maximum amount, respectively. A trade-off between model complexity, error rates, and computational efficiency must be considered when selecting the optimal approach. Since relevant weather features vary by location, the proposed methodology serves as an adaptable algorithm for solar energy prediction in diverse geographical regions.},
  archive      = {J_EAAI},
  author       = {Mohammadreza pourmir and Seyedeh Mohadeseh Miri},
  doi          = {10.1016/j.engappai.2025.112239},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112239},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning methods comparison by using statistical tests in solar energy forecasting based on weather features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph neural network with historic-sequential information representation. <em>EAAI</em>, <em>162</em>, 112234. (<a href='https://doi.org/10.1016/j.engappai.2025.112234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s interconnected world, networks, whether social, technological, or biological, are constantly evolving, with relationships forming, shifting, and dissolving over time. Traditional models struggle to capture this fluidity, treating networks as static snapshots rather than living systems. While existing research has made strides in analyzing either spatial–temporal patterns or temporal sequences separately, these approaches often fall short in scalability and fail to unify discrete and continuous-time perspectives. To bridge this gap, we introduce DyGHS (Dynamic Graph Historical-Sequential), an innovative framework that harnesses dynamic graph neural networks to model how nodes, edges, and their historical interactions evolve together. By seamlessly integrating discrete-time and continuous-time graph representations, DyGHS not only captures the richness of real-world networks but also efficiently predicts future connections and node behaviors. Our experiments reveal that combining continuous-time Fourier transform (CTFT) with graph neural networks significantly boosts prediction accuracy, outperforming current methods in tasks like link prediction and node classification. This advancement opens new doors for understanding and anticipating the ever-changing tapestry of networked systems.},
  archive      = {J_EAAI},
  author       = {Adam Abakar Hamid and Anping Zhao and Alladoumbaye Ngueilbaye},
  doi          = {10.1016/j.engappai.2025.112234},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic graph neural network with historic-sequential information representation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing anomaly detection with few-shot fine-tuned long text-to-image models. <em>EAAI</em>, <em>162</em>, 112174. (<a href='https://doi.org/10.1016/j.engappai.2025.112174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial anomaly detection plays a crucial role in the industrial manufacturing field. Currently, utilizing generated data to improve the performance of the anomaly detection model is an effective approach. However, most existing methods often rely on mask-guided synthesis, where the distribution of the generated defects is limited by masks that are typically random or learned by a model. In addition, the scarcity of real anomalous samples makes it difficult for generative models to capture genuine defect patterns and align with the real anomaly distribution. To tackle these issues, we propose DefectGen, the first long-text-guided few-shot text-to-image data generation pipeline for industrial anomaly detection. To improve distribution alignment under limited anomaly samples, DefectGen incorporates a Prompt Generation and Variation Module, which uses MLLMs (Multimodal Large Language Models) to expand few-shot image–text pairs into diverse and semantically rich prompts, and DoKr (Weight- D ecomposed L o w-Rank Adaptation with Kr onecker product), a lightweight fine-tuning strategy with structured low-rank adaptation. To ensure the quality of synthetic data, DefectGen further introduces the Real-Guided Clustering Filter, which selects high-quality generated samples by comparing their features with those of real anomalies. Experiments on the MVTec AD(MVTec AnomalyDetection) dataset show that DefectGen generates more diverse and realistic synthetic anomalies and achieves a 5.58% average improvement in anomaly classification accuracy compared to state-of-the-art methods. Code and data are available at: https://anonymous.4open.science/r/DefectGen-CD04/ .},
  archive      = {J_EAAI},
  author       = {Jiachen Liu and Jiajia An and Junbin Lu and Zhuoqin Yang and Jinbao Wang and Ping Lu and Yuying Wang and Linlin Shen},
  doi          = {10.1016/j.engappai.2025.112174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing anomaly detection with few-shot fine-tuned long text-to-image models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed fine-tuning for physics discovery from random and sparse data. <em>EAAI</em>, <em>162</em>, 112132. (<a href='https://doi.org/10.1016/j.engappai.2025.112132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although significant advances have been made in both numerical methods and machine learning approaches for solving differential equations across various scientific sectors, these methods often rely on complete information about the differential equations, including precise parameter values, which are not easily obtainable in real-world scenarios. To address this challenge, data-driven methods for discovering differential equations have gained growing popularity in recent years. However, many existing approaches demand unrealistic prerequisites, such as extensive high-fidelity data or carefully designed low-fidelity data and functions. In this paper, we propose a novel method: P hysics- I nformed F ine- T uning ( PIFT ) to discover the unknown parameters in differential equations when only randomly distributed sparse data points are available. PIFT consists of three stages; (i) generating low fidelity data from prior knowledge under realistic settings, (ii) pre-training a single neural network with the generated low fidelity data, and (iii) fine-tuning the pre-trained model using physics-informed loss function. PIFT is evaluated on seven scientific problems including five ordinary differential equations and two partial differential equations. We also demonstrate the robustness and generalizability of PIFT to out-of-distribution tasks. PIFT exhibits high accuracy and robustness in discovering unknown parameters of differential equations from randomly distributed sparse data points.},
  archive      = {J_EAAI},
  author       = {Yong Jin Jeong and Taesup Moon},
  doi          = {10.1016/j.engappai.2025.112132},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112132},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed fine-tuning for physics discovery from random and sparse data},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep Q-learning with feature extraction and prioritized experience replay for edge node overload in edge computing. <em>EAAI</em>, <em>162</em>, 112124. (<a href='https://doi.org/10.1016/j.engappai.2025.112124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keeping track of the edge nodes’ status information is crucial, which is the condition of their available compute capacity as measured by their Age-of-Information. In Internet of Things-oriented edge computing systems, the computational and software-defined infrastructure resources are heterogeneous and subject to rapid change. Edge computing systems often face dynamic workloads and limited computational resources, leading to frequent node overload scenarios. These overloads degrade system responsiveness and service availability, especially in latency-sensitive applications. The scheduling of computation tasks would consider both current resource availability and predicted overload risks. An intelligent, adaptive method that learns optimal task allocation under resource constraints has the potential to boost the operational efficiency of Internet of Things-oriented edge computing systems. Addressing edge node overload is critical for the sustainable and scalable deployment of edge-based infrastructures. This research designs a resource-overloaded detection model specifically for diverse workloads in edge computing systems. The proposed Deep Reinforcement Learning model explores two significant challenges: the selection of pertinent feature sets from the workload resource utilization storage, and their classification of overload and detection of fatal failure of edge computing nodes. We propose a Deep-Q Network with a prioritized experience replay framework for edge node resource overload. The framework relies on feature learning using Linear Discriminant Analysis and Deep Q Network with a prioritized experience replay to efficiently indicate the overload status of edge nodes and reward the system with actions that enhance edge resources allocation. Deep-Q Network is well-suited for sequential decision-making in dynamic environments, while prioritized experience replay improves sample efficiency by focusing on updating on high-priority transitions with larger temporal-difference errors. Features are learned automatically from the edge node resource profiling data generated on a real edge-based container infrastructure. Linear Discriminant Analysis reduces the high-dimensional state space by emphasizing the most discriminative features for scheduling decisions. The infrastructure executes an intelligent inference of containerized applications considered as resource-intensive applications. When the feature extraction is added to the proposed deep reinforcement learning model, the overload classifier’s performance is improved. Comparing the model with selection to the one without it, the total accuracy and F1-score were improved by 1.3% and 1.4%, respectively.},
  archive      = {J_EAAI},
  author       = {Lionel Nkenyereye and Boon Giin Lee and Wan-Young Chung},
  doi          = {10.1016/j.engappai.2025.112124},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112124},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep Q-learning with feature extraction and prioritized experience replay for edge node overload in edge computing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STEval: A framework for evaluating spatio-temporal crime prediction models. <em>EAAI</em>, <em>162</em>, 112123. (<a href='https://doi.org/10.1016/j.engappai.2025.112123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-Temporal predictive models are crucial for forecasting where and when crimes will occur, aiding public security organizations in resource allocation and crime prevention. Despite numerous literature proposals, a lack of standardized evaluation criteria hinders comparability and reliability. To address this, we propose STEval, a comprehensive and flexible evaluation framework for spatio-temporal predictive models. STEval consists of four modules: data preparation, spatial structure definition, model training, and model evaluation. The framework’s robustness was demonstrated using a 40-million-record crime dataset from Minas Gerais State (Brazil) across five experimental scenarios, including variations in temporal granularity, spatial resolution, and distribution shifts. Results demonstrate that no single model is universally superior, and the most appropriate model depends on the specific application context. For instance, Spatio-Temporal Kernel Density Estimation (STKDE) consistently achieved high Hit Rates (HR), often exceeding 0.98 in fine spatial resolutions (e.g., 100-square meters grid) for violent crimes, while Spatial-Temporal Autoregressive Integrated Moving Average (STARIMA) demonstrated strong performance in temporal granularity tests, reaching HRs of up to 0.65 for theft predictions. Conversely, Extra Tree Regressor, though exhibiting significantly lower HRs (e.g., as low as 0.02 in some spatial tests), consistently provided the fastest execution times, often under 5 s, contrasting with STKDE’s execution times that could extend to thousands of seconds in dense spatial grids. The framework’s detailed analysis provides important insights for informed model selection and optimization, revealing each model’s strengths and limitations, and providing a robust foundation for future advancements in spatio-temporal crime prediction research, leveraging Machine Learning (ML) techniques.},
  archive      = {J_EAAI},
  author       = {Gabriel Amarante and Matheus Pimenta and Yan Andrade and Matheus Senna and Rainer Menezes and Antônio Hot Faria and Marcelo Vilas-Boas and Frederico Martins de Paula Neto and João Paulo da Silva and Everton Renato de Sousa and Jamicel da Silva and Wagner Meira Jr. and George Teodoro and Leonardo Rocha and Renato Ferreira},
  doi          = {10.1016/j.engappai.2025.112123},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112123},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STEval: A framework for evaluating spatio-temporal crime prediction models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inland waterway object detection in multi-environment: Dataset and approach. <em>EAAI</em>, <em>162</em>, 111994. (<a href='https://doi.org/10.1016/j.engappai.2025.111994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has advanced intelligent ship visual perception, but the scarcity of dedicated inland waterway vessels dataset limits system adaptability in complex environments. Narrow waterways, variable weather, and urban interference challenge the robustness of existing object detection systems. To address these issues, this paper constructs the Multi-environment Inland Waterway Vessels Dataset (MEIWVD), comprising 32,478 high-quality images from diverse Yangtze River basin scenarios, including sunny, rainy, foggy, and artificially lit conditions. The diversity and multi-scale characteristics of MEIWVD establish it as a rigorous benchmark for vessel detection. To leverage the characteristics of the MEIWVD, this paper proposes a scene-guided image enhancement module for multi-environment scenarios, which adaptively enhances water surface images based on environmental conditions to improve detector performance in complex scenarios. Additionally, a parameter-limited dilated convolution is introduced to enhance the representation of salient features of inland waterway vessels by leveraging their geometric characteristics. Finally, a multi-scale dilated residual fusion method is proposed to effectively integrate multi-scale features and improve the detection of multi-scale objects. Comprehensive statistical analysis and experiments on the MEIWVD demonstrate that it poses higher demands on object detection algorithms compared to existing water surface datasets, owing to its diverse and challenging scenarios. The proposed methods, including scene-guided image enhancement, parameter-limited dilated convolution, and multi-scale dilated residual fusion, advance research in multi-environment dataset, achieving a mean average precision over intersection over union thresholds from 0.5 to 0.95 of 81.6 % on the MEIWVD, outperforming state-of-the-art object detection algorithms.},
  archive      = {J_EAAI},
  author       = {Shanshan Wang and Haixiang Xu and Hui Feng and Xiaoqian Wang and Pei Song and Sijie Liu and Jianhua He},
  doi          = {10.1016/j.engappai.2025.111994},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111994},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inland waterway object detection in multi-environment: Dataset and approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ejor">EJOR - 24</h2>
<ul>
<li><details>
<summary>
(2026). Optimistic and pessimistic approaches for cooperative games. <em>EJOR</em>, <em>328</em>(2), 725-733. (<a href='https://doi.org/10.1016/j.ejor.2025.09.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative game theory explores how to fairly allocate the joint value generated by a group of decision-makers, but its application is compromised by the large number of counterfactuals needed to compute the value of all coalitions, a problem made even more complicated when externalities are present. We provide a theoretical foundation for a simplification used in many applications, in which the value of a coalition is computed assuming that they either select before or after the complement set of agents, providing optimistic and pessimistic values on what a coalition should receive. In a vast set of problems exhibiting what we call feasibility externalities, we show that ensuring a coalition does not receive more than its optimistic value is always at least as difficult as ensuring it receives its pessimistic value. Furthermore, under the presence of negative externalities, we establish the existence of stable allocations that respect these bounds. Finally, we examine well-known optimization-based applications and their corresponding cooperative games to show how our results lead to new insights and allow the derivation of further results from the existing literature.},
  archive      = {J_EJOR},
  author       = {Ata Atay and Christian Trudeau},
  doi          = {10.1016/j.ejor.2025.09.002},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {725-733},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimistic and pessimistic approaches for cooperative games},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sustainable product development under profit-sharing crowdfunding: An analytical approach to market structure and government policy. <em>EJOR</em>, <em>328</em>(2), 704-724. (<a href='https://doi.org/10.1016/j.ejor.2025.08.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an integrated analytical framework to examine how crowdfunding, market structure, and government policy interact to shape environmentally sustainable product development (SPD). Focusing on profit-sharing and securities-based crowdfunding, we model how investor opportunity costs, risk preferences, platform fees, and regulatory schemes (voluntary vs. mandatory under fiscal vs. non-fiscal policy regimes) influence firm strategies and outcomes across economic, social, and environmental (ESE) dimensions. Firm behavior is analyzed under monopoly and duopoly settings to explore variation in market power and competitive intensity. Findings reveal that voluntary greening can achieve strong ESE outcomes in monopolistic markets with low financial frictions and environmentally aware consumers. In contrast, competitive or uncertain environments often require benchmark-based regulation and fiscal instruments to sustain environmental investments. Two dominant firm profiles emerge: the Voluntary sustainability leader, which performs well under favorable market and investor conditions without policy intervention, and the Policy-driven strategist, which depends on regulatory standards and fiscal tools to overcome competitive pressures and risk constraints. By formalizing investor-entrepreneur interactions and embedding environmental quality as a strategic variable, this research advances the literature on crowdfunding and market-driven sustainability. It provides actionable insights for aligning crowdfunding design and policy frameworks with the broader goals of green innovation and public sustainability.},
  archive      = {J_EJOR},
  author       = {Raziyeh Reza-Gharehbagh and Madeleine Pullman},
  doi          = {10.1016/j.ejor.2025.08.020},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {704-724},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sustainable product development under profit-sharing crowdfunding: An analytical approach to market structure and government policy},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal dividend and scale of business strategies with reinsurance and premium pricing for insurance company. <em>EJOR</em>, <em>328</em>(2), 694-703. (<a href='https://doi.org/10.1016/j.ejor.2025.07.039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the optimal dividend and business scale strategies aimed at maximizing the value of an insurance company. While prior studies typically assume that insurers can only adjust their business scale through reinsurance, this study extends the framework by allowing the insurer to control the premium rate. Under more realistic market assumptions, we examine the joint optimization problem for two common types of reinsurance — proportional and excess-of-loss — across both arbitrage and non-arbitrage scenarios. We derive the optimal strategies for dividends and premium pricing, along with their corresponding value functions. The results show that the insurer should decrease the premium rate and reduce reinsurance coverage as the surplus increases. The optimal dividend policy follows a barrier strategy. Economic interpretations and numerical examples are provided to illustrate the findings.},
  archive      = {J_EJOR},
  author       = {Dingjun Yao and Bo Yang and Xin Xu and Youwei Li and Yizhi Wang},
  doi          = {10.1016/j.ejor.2025.07.039},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {694-703},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal dividend and scale of business strategies with reinsurance and premium pricing for insurance company},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anticipating delays in recruitment: Explainable machine learning for the prediction of hard-to-fill online job vacancies. <em>EJOR</em>, <em>328</em>(2), 680-693. (<a href='https://doi.org/10.1016/j.ejor.2025.06.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online job vacancy (OJV) platforms have transformed the labor market by enabling employers to advertise jobs to a wide audience. Particularly in tight labor markets, quickly identifying vacancies likely to suffer prolonged durations is crucial. This study utilizes data from the Flemish public employment service's OJV platform to examine the effectiveness of machine learning in predicting hard-to-fill vacancies. We achieve notable predictive performance with XGBoost in forecasting recruitment delays and demonstrate the importance of capturing non-linear patterns in OJV data. SHAP (SHapley Additive exPlanations) values reveal that the textual content of vacancies and latent company characteristics are key predictors of hiring delays. Counterfactual-SHAP insights provide practical guidance for refining recruitment strategies, enhancing labor market forecasts, and informing targeted policies.},
  archive      = {J_EJOR},
  author       = {Wouter Dossche and Sarah Vansteenkiste and Bart Baesens and Wilfried Lemahieu},
  doi          = {10.1016/j.ejor.2025.06.027},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {680-693},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Anticipating delays in recruitment: Explainable machine learning for the prediction of hard-to-fill online job vacancies},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Using diet optimization and machine learning for the design of healthy and acceptable menu plans. <em>EJOR</em>, <em>328</em>(2), 668-679. (<a href='https://doi.org/10.1016/j.ejor.2025.06.015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of dietary plans relies on understanding and modelling consumer acceptance, yet quantifying this poses a challenge due to the complexity of individual preferences. Recent research is focused on deriving acceptability constraints directly from data, as demonstrated by its application in designing food baskets with a limited number of commodities. In this study, we applied diet optimization with machine learning to the more complex task of menu planning. This involved considering hundreds of potential food alternatives and assessing their compatibility within a meal using a recipe completion algorithm. Compared to the traditional diet modelling approach of food group filtering, the recipe completion model delivered diets with either higher nutritional adequacy or greater substitute acceptability, depending on the number of food groups used in the traditional method. While more research is needed to further improve the acceptability of substitutions, combining diet optimization with recipe completion presents a promising approach to enhance the nutritional adequacy of individual diets while maintaining the acceptability of food combinations within meals.},
  archive      = {J_EJOR},
  author       = {Dominique van Wonderen and Johanna C. Gerdessen and Alida Melse-Boonstra and Marleen C. Onwezen},
  doi          = {10.1016/j.ejor.2025.06.015},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {668-679},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using diet optimization and machine learning for the design of healthy and acceptable menu plans},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Project monitoring and control with an empirically grounded budget-release model. <em>EJOR</em>, <em>328</em>(2), 646-667. (<a href='https://doi.org/10.1016/j.ejor.2025.06.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Project monitoring and control (PMC) is a process of measuring a project’s progress and taking corrective action when necessary to ensure successful project completion. However, most existing models lack empirical validation of their assumptions and effectiveness, which limits their practical use. We fill in this gap by using empirical data from 97 real projects to calibrate activity-duration distributions and assess activity-duration dependencies, integrating these empirical foundations into an enhanced PMC model. We further improve the model by incorporating budget-release timing constraints and introducing two new policies for crashing and fast-tracking based on a project’s specific time and cost characteristics. Extensive computational experiments using empirical and artificial data evaluate the effectiveness of these policies. Because the budget-release policies and corrective action types depend on project characteristics such as activity-duration dependencies and topological network structure, key insights from this study can be usefully applied by project managers as heuristics even without a detailed model of their project.},
  archive      = {J_EJOR},
  author       = {Jie Song and Jinbo Song and Tyson Browning and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2025.06.007},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {646-667},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Project monitoring and control with an empirically grounded budget-release model},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The continuous roll-on roll-off dual cycling problem with tugs and driver-handled cargo units. <em>EJOR</em>, <em>328</em>(2), 633-645. (<a href='https://doi.org/10.1016/j.ejor.2025.05.050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roll-on roll-off vessels are a popular mode of transport in short-sea shipping. In this domain, appropriate stevedoring procedures are crucial to enhance efficiency. This includes dual cycling, where tugs simultaneously load and unload the vessel. Dual cycling reduces turnaround time, thereby giving the vessel more time to travel and allowing for slow steaming and reduced emissions. We extend the roll-on roll-off dual cycling problem by incorporating a continuous time horizon and differentiating cargo units that are handled by their own drivers and units that must be handled by a tug. We propose a mixed integer linear programming model for generating an efficient schedule that minimizes overall makespan by optimizing the sequence of cargo units and the assignment of cargo units to tugs. To solve instances of real-world size with acceptable computational effort, we provide a range of heuristics, including a biased random-key genetic algorithm. Compared to the linear programming model and on instances of real-world size, the genetic algorithm finds good solutions quickly. We derive managerial insights from a sensitivity analysis and show that dual cycling and strategic positioning of driver-handled units can reduce turnaround time by 14.5%, reducing emissions of the considered vessel by more than 8%. We demonstrate the robustness of these insights in uncertain environments through a simulation study.},
  archive      = {J_EJOR},
  author       = {Teresa Marquardt and Arne Heinold and Catherine Cleophas and Frank Meisel},
  doi          = {10.1016/j.ejor.2025.05.050},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {633-645},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The continuous roll-on roll-off dual cycling problem with tugs and driver-handled cargo units},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing treatment allocation in the presence of interference. <em>EJOR</em>, <em>328</em>(2), 620-632. (<a href='https://doi.org/10.1016/j.ejor.2025.09.015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Influence Maximization (IM), the objective is to — given a budget — select the optimal set of entities in a network to target with a treatment so as to maximize the total effect. For instance, in marketing, the objective is to target the set of customers that maximizes the total response rate, resulting from both direct treatment effects on targeted customers and indirect, spillover, effects that follow from targeting these customers. Recently, new methods to estimate treatment effects in the presence of network interference have been proposed. However, the issue of how to leverage these models to make better treatment allocation decisions has been largely overlooked. Traditionally, in Uplift Modeling (UM), entities are ranked according to estimated treatment effect, and the top entities are allocated treatment. Since, in a network context, entities influence each other, the UM ranking approach will be suboptimal. The problem of finding the optimal treatment allocation in a network setting is NP-hard, and generally has to be solved heuristically. To fill the gap between IM and UM, we propose OTAPI: Optimizing Treatment Allocation in the Presence of Interference to find solutions to the IM problem using treatment effect estimates. OTAPI consists of two steps. First, a causal estimator is trained to predict treatment effects in a network setting. Second, this estimator is leveraged to identify an optimal treatment allocation by integrating it into classic IM algorithms. We demonstrate that this novel method outperforms classic IM and UM approaches on both synthetic and semi-synthetic datasets.},
  archive      = {J_EJOR},
  author       = {Daan Caljon and Jente Van Belle and Jeroen Berrevoets and Wouter Verbeke},
  doi          = {10.1016/j.ejor.2025.09.015},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {620-632},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing treatment allocation in the presence of interference},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Soft regression trees: A model variant and a decomposition training algorithm. <em>EJOR</em>, <em>328</em>(2), 607-619. (<a href='https://doi.org/10.1016/j.ejor.2025.08.050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees are widely used for classification and regression tasks in a variety of application fields due to their interpretability and good accuracy. During the past decade, growing attention has been devoted to globally optimized decision trees with deterministic or soft splitting rules at branch nodes, which are trained by optimizing the error function over all the tree parameters. In this work, we propose a new variant of soft multivariate regression trees (SRTs) where, for every input vector, the prediction is defined as the linear regression associated to a single leaf node, namely, the leaf node obtained by routing the input vector from the root along the branches with higher probability. SRTs exhibit the conditional computational property, i.e., each prediction depends on a small number of nodes (parameters), and our nonlinear optimization formulation for training them is amenable to decomposition. After showing a universal approximation result for SRTs, we present a decomposition training algorithm including a clustering-based initialization procedure and a heuristic for rerouting the input vectors along the tree. Under mild assumptions, we establish asymptotic convergence guarantees. Experiments on 15 well-known datasets indicate that our SRTs and decomposition algorithm yield higher accuracy and robustness compared with traditional soft regression trees trained using the nonlinear optimization formulation of Blanquero et al. (2021), and a significant reduction in training times as well as a slightly better average accuracy compared with the mixed-integer optimization approach of Bertsimas and Dunn (2019). We also report a comparison with the Random Forest ensemble method.},
  archive      = {J_EJOR},
  author       = {Antonio Consolo and Edoardo Amaldi and Andrea Manno},
  doi          = {10.1016/j.ejor.2025.08.050},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {607-619},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Soft regression trees: A model variant and a decomposition training algorithm},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable machine learning framework for recurrent event data analysis. <em>EJOR</em>, <em>328</em>(2), 591-606. (<a href='https://doi.org/10.1016/j.ejor.2025.09.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel explainable temporal point process (TPP) model, Stratified Hawkes Point Process (SHPP), for modelling recurrent event data (RED). Unlike existing approaches that treat temporal influence as a black box or rely on post-hoc explanations, SHPP structurally decomposes event intensities into semantically meaningful components for describing self-, Markovian, and joint influences. This decomposition enables direct quantification of how past events contribute to future event risks, termed as influence values. We further provide a sufficient condition for mean-square stability based on kernel decay, ensuring long-term boundedness of intensities and realistic behavioural predictions. Experiments and an e-commerce case study demonstrate SHPP’s ability to deliver accurate, interpretable, and stable modelling of complex event-driven systems.},
  archive      = {J_EJOR},
  author       = {Qi Lyu and Shaomin Wu},
  doi          = {10.1016/j.ejor.2025.09.005},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {591-606},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An explainable machine learning framework for recurrent event data analysis},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Decision space dynamic niching-based method for constrained multiobjective evolutionary optimization. <em>EJOR</em>, <em>328</em>(2), 574-590. (<a href='https://doi.org/10.1016/j.ejor.2025.07.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a set with a good approximation to the Pareto-optimal solutions in the multiobjective optimization problem (MOP) is a challenging task in terms of convergence toward and diversity across the Pareto optimal front (PoF). In some cases, solving MOPs requires satisfying certain constraints, which significantly increases the complexity of the problem. Such problems are constrained multiobjective optimization problems (CMOPs) and pose considerable computational challenges. Many constrained multiobjective evolutionary algorithms (CMOEAs) face challenges in avoiding becoming trapped in local optima, which impacts convergence, and offer solutions that lack good coverage of the PoF, implying weak diversity. All these nonoptimal or partially optimal solutions in the objective space are essentially clustered in local optimality dilemmas in the decision space. To better eliminate the convergence and diversity challenges caused by clustered solutions, this paper proposes a decision space dynamic niching-based (DSDN) method to better address CMOPs. Specifically, the DSDN method adds a dynamic decision space niche as an additional criterion to the traditional Pareto-constrained dominance principle (Pareto-CDP). The better preserved solutions must satisfy the Pareto-CDP and the condition within the niche radius of other solutions, which strictly meets the original dominance relationship requirement while relaxing the nondominance threshold. As a result, the dynamic adjustment of the niche radius ( N R ) effectively balances the exploitation and exploration of solutions in the decision space while enhancing both convergence and diversity in the objective space. Experiments conducted on four widely recognized test suites and three real-world case studies have demonstrated that the DSDN method yields significantly better results than the original Pareto-CDP algorithms. Furthermore, the proposed approach is competitive with or comparable to seven other state-of-the-art CMOEAs.},
  archive      = {J_EJOR},
  author       = {Fan Yu and Qun Chen and Jinlong Zhou},
  doi          = {10.1016/j.ejor.2025.07.002},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {574-590},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision space dynamic niching-based method for constrained multiobjective evolutionary optimization},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Impact of technology spillovers and subsidies on innovation consortia dynamics. <em>EJOR</em>, <em>328</em>(2), 560-573. (<a href='https://doi.org/10.1016/j.ejor.2025.06.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In innovation consortia, governments and enterprises view technology spillovers and subsidies differently, which reduces the effectiveness of policies and undermines cooperation. This work investigates the dynamics of cooperation among leading enterprises (LEs) and small/medium enterprises (SMEs), using an evolutionary game model with intrinsic, extrinsic and mixed strategies. We show that there may exist more than one evolutionary equilibrium of enterprise cooperation under multi-strategy choices. A high subsidy may induce enterprises to speculate and reach a suboptimal evolutionary equilibrium. Furthermore, our findings indicate that SMEs are particularly sensitive to changes in subsidy levels, income distribution ratios, and project income, with their speculative behavior exhibiting a lagging effect. Also, increasing the income distribution ratio of LEs can promote active cooperation between the groups and reduce the speculative tendency of SMEs. This occurs because it magnifies the effect of technology spillover on the income of SMEs and enhances the income of the leading enterprises. Our work improves understanding of cooperative factors and provides new recommendations for government and leading enterprises to improve cooperation and managerial performance.},
  archive      = {J_EJOR},
  author       = {Zheng Yang and Lin Li and Nicholas G. Hall and Yongzeng Lai and Yijiang Zhou},
  doi          = {10.1016/j.ejor.2025.06.031},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {560-573},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impact of technology spillovers and subsidies on innovation consortia dynamics},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online quality endorsement to improve consumer trust: Blockchain or self-hosted livestream?. <em>EJOR</em>, <em>328</em>(2), 545-559. (<a href='https://doi.org/10.1016/j.ejor.2025.04.010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online products have long suffered from consumer distrust, putting them at a disadvantage when online brands compete with offline brands. To address this issue, many online brands have adopted blockchain as a means of quality endorsement to improve consumer trust. Alternatively, livestream e-commerce has shown the capability of both quality endorsement and demand creation by real-time interactions with consumers because the application of AR/VR technology and the use of online sales force can effectively induce the herding mentality. For many small and medium-sized online brands, it remains unclear which approach is better, so we formulate the key tradeoffs in the online brand's choice to improve consumer trust in the presence of offline brand's competition. Our research delves into the influence of three key factors on livestream e-commerce: the cost associated with adopting blockchain technology, the strength of positive network externality, and the potential downside of consumer returns. Contrary to conventional wisdom, we find that when the return cost is high and the network externality in livestream is weak, opting for livestream as a quality endorsement can actually benefit the online brand. We also find that the online brand is capable of mitigating the return cost by transferring it to consumers through charging a high retail price, which increases the likelihood of favoring livestream. Our findings shed light on the building and improvement of online consumer trust, contributing to the high-quality development of online-offline business in the new era of consumption.},
  archive      = {J_EJOR},
  author       = {Baozhuang Niu and Jian Dong and Xinhu Yu and Yulan Wang},
  doi          = {10.1016/j.ejor.2025.04.010},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {545-559},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Online quality endorsement to improve consumer trust: Blockchain or self-hosted livestream?},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Production trade-offs in free disposal hull technologies. <em>EJOR</em>, <em>328</em>(2), 530-544. (<a href='https://doi.org/10.1016/j.ejor.2025.06.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data envelopment analysis, production trade-offs are value judgements that represent simultaneous changes to the inputs and outputs assumed to be technologically possible for any production unit in the technology. The specification of production trade-offs generally leads to an enlargement of the model of technology and increasing its discriminating power on efficiency. In conventional convex variable and constant returns-to-scale models, production trade-offs are the dual forms of weight restrictions. In this paper, we extend the use of production trade-offs to the free disposal hull model of technology and its constant, non-increasing and non-decreasing returns-to-scale variants, in a single unifying development. We provide an axiomatic definition of the new nonconvex technologies, explore the notion of consistent trade-offs in such technologies and develop methods for its testing. We further develop different computational approaches for nonconvex models with production trade-offs. We illustrate the new models by an application in the context of higher education.},
  archive      = {J_EJOR},
  author       = {Mahmood Mehdiloo and Grammatoula Papaioannou and Victor V. Podinovski},
  doi          = {10.1016/j.ejor.2025.06.032},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {530-544},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Production trade-offs in free disposal hull technologies},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Price optimization for round trip car sharing. <em>EJOR</em>, <em>328</em>(2), 511-529. (<a href='https://doi.org/10.1016/j.ejor.2025.06.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Car sharing, car clubs and short-term rentals could support the transition toward net zero but their success depends on them being financially sustainable for service providers and attractive to end users. Dynamic pricing could support this by incentivizing users while balancing supply and demand. We describe the usage of a round trip car sharing fleet by a continuous time Markov chain model, which reduces to a multi-server queuing model where hire duration is assumed independent of the hourly rental price. We present analytical and simulation optimization models that allow the development of dynamic pricing strategies for round trip car sharing systems; in particular identifying the optimal hourly rental price. The analytical tractability of the queuing model enables fast optimization to maximize expected hourly revenue for either a single fare system or a system where the fare depends on the number of cars on hire, while accounting for stochasticity in customer arrival times and durations of hire. Simulation optimization is used to optimize prices where the fare depends on the time of day or hire duration depends on price. We present optimal prices for a given customer population and show how the expected revenue and car availability depend on the customer arrival rate, willingness-to-pay distribution, dependence of the hire duration on price, and size of the customer population. The results provide optimal strategies for pricing of car sharing and inform strategic managerial decisions such as whether to use time- or state-dependent pricing and optimizing the fleet size.},
  archive      = {J_EJOR},
  author       = {Christine S.M. Currie and Rym M’Hallah and Beatriz Brito Oliveira},
  doi          = {10.1016/j.ejor.2025.06.024},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {511-529},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Price optimization for round trip car sharing},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The development strategy of supply chain intelligent technology considering technology development uncertainty. <em>EJOR</em>, <em>328</em>(2), 496-510. (<a href='https://doi.org/10.1016/j.ejor.2025.07.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It’s crucial for both manufacturing and logistics industries to improve logistics efficiency and reduce logistics loss during transportation, storage, and other processes through the development and application of intelligent technology. By focusing on three potential modes of intelligent technology development cooperation between a manufacturer and its logistics provider, we examine the impact of such collaboration on reducing Logistics loss, as well as explore the optimal mode of cooperation for both firms. Our analytical results indicate that compared to independent technology development, collaborative development of intelligent technology can mitigate the adverse effects of double-marginalization. Comparing the three modes of cooperation, we find that higher development cost can incentivize the collaboration between two firms, while higher integration cost and price elasticity may make the cost sharing mode preferable. It is noteworthy that the uncertainty of intelligent technology development exerts a significant moderating effect on the choice of cooperation mode. Heightened technology development uncertainty tends to incentivize both firms to pursue joint development in order to alleviate the negative impact of the uncertainty.},
  archive      = {J_EJOR},
  author       = {Peng Han and Yanfang Huo and Weihua Liu and Ershi Qi and Helen Cai},
  doi          = {10.1016/j.ejor.2025.07.026},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {496-510},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The development strategy of supply chain intelligent technology considering technology development uncertainty},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal price, quantity, and return policy decisions of a two-period newsvendor with product reviews. <em>EJOR</em>, <em>328</em>(2), 477-495. (<a href='https://doi.org/10.1016/j.ejor.2025.06.023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online retailers (e-tailers) have high product return rates. To decrease product returns and consumers’ purchase risk, e-tailers can increase available product information through product reviews and/or offer money back guarantees (MBGs). We examine the rational expectations equilibrium of an e-tailer selling to myopic and strategic consumers over two periods. By the end of period 1, product reviews become available, providing a signal to strategic consumers who may wait to purchase in period 2. The e-tailer decides order quantity, prices, and return policy. We find that under both no returns and MBG, as strategic consumers’ patience increases, the optimal range of having them purchase in period 2 increases. For low signal accuracy, it is optimal to have strategic consumers purchase in period 1, whereas for high signal accuracy, it is optimal to have them purchase in period 2. However, under no returns and for a low signal accuracy, it may be optimal to have strategic consumers purchase in period 2 if their proportion is medium and they are patient. We also find that as consumers’ patience increases, the range where MBG dominates no returns increases. For heterogeneous signal accuracy among strategic consumers, equilibrium strategies are similar to the homogeneous case, except that when consumers’ patience is low, high heterogeneity allows the e-tailer to price discriminate, making low-signal accuracy consumers purchase in period 1 and high-signal accuracy consumers purchase in period 2. Also, as the proportion of low-signal accuracy consumers increases, price discrimination increases. Therefore, heterogeneity increases profit.},
  archive      = {J_EJOR},
  author       = {Huirong Fan and Moutaz Khouja and Jing Zhou},
  doi          = {10.1016/j.ejor.2025.06.023},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {477-495},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal price, quantity, and return policy decisions of a two-period newsvendor with product reviews},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Probabilistic forecast aggregation with statistical depth. <em>EJOR</em>, <em>328</em>(2), 460-476. (<a href='https://doi.org/10.1016/j.ejor.2025.06.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers aggregation methods for interval forecasts and forecasts of cumulative distribution functions (CDFs) when there are many forecasters, and past forecast accuracy may not be known. For aggregation, the median and trimmed means have been proposed as simple and robust alternatives to the mean, with some trimmed mean approaches enabling recalibration to widen or narrow the resulting interval or CDF forecast. For interval forecast aggregation, the median and trimming are applied to each bound separately. To try to use the available information better, we treat the bounds as a bivariate point with statistical depth used to order the points in terms of centrality. The deepest point can be viewed as the median interval forecast, and the depth of each point can be used as the basis for trimming. For CDF forecasts, the literature presents aggregation methods for which the median or trimmed mean are obtained for each point on the domain of the distribution. However, if one part of a CDF forecast is outlying, the appeal of using the rest of the CDF forecast is perhaps reduced. We use functional depth to provide a measure of centrality for each CDF forecast, and hence identify the deepest function, which can be viewed as the median forecast. We also use functional depth as the basis for trimming, and consider weighted depth to control the width of the resulting aggregated interval or CDF forecast. We provide empirical illustration using data from surveys of professional macroeconomic forecasters, and an application to growth-at-risk.},
  archive      = {J_EJOR},
  author       = {James W. Taylor},
  doi          = {10.1016/j.ejor.2025.06.028},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {460-476},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Probabilistic forecast aggregation with statistical depth},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven approach for strategic inventory placement in multi-echelon supply networks. <em>EJOR</em>, <em>328</em>(2), 446-459. (<a href='https://doi.org/10.1016/j.ejor.2025.06.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a data-driven solution for optimizing inventory buffers in large-scale supply networks. We study the placement and sizing of strategic inventories in multi-echelon supply chains where the decision maker faces uncertain demand with an unknown distribution influenced by explanatory variables. State-of-the-art multi-echelon inventory optimization models, such as the well-known guaranteed-service model (GSM), are non-linear and typically informed by distributional and parametric assumptions. They often rely on dynamic programming and are difficult to solve for large networks. We adapt the GSM to introduce a nonparametric, feature-driven approach to supply chain safety stock optimization that is based on mixed-integer linear programming (MILP). The MILP formulation sets cost-optimal base stocks, which are learned as linear functions of feature data under consideration of service level requirements. This integrated estimation and optimization approach is solved with commercial mathematical programming solvers and is enhanced by a Benders decomposition method for large networks. We extend the literature on data-driven inventory control by a multi-period and multi-echelon approach for safety stock planning in general, acyclic networks. On the real-world networks from Willems (2008), we find that incorporating feature information when setting safety stocks in large supply chains, on average, reduces operational costs out-of-sample. This value of feature information that the proposed model offers to decision-makers increases in demand volatility and is dependent on certain network characteristics.},
  archive      = {J_EJOR},
  author       = {Josef Svoboda and Stefan Minner},
  doi          = {10.1016/j.ejor.2025.06.022},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {446-459},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A data-driven approach for strategic inventory placement in multi-echelon supply networks},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Minimizing the maximum flow loss in the network maintenance scheduling problem with flexible arc outages. <em>EJOR</em>, <em>328</em>(2), 430-445. (<a href='https://doi.org/10.1016/j.ejor.2025.07.056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a network maintenance scheduling problem where maintenance tasks are carried out on the arcs of a network within flexible time windows. During maintenance, an arc is interrupted and no flow can pass through it. Such arc outages introduce flow loss and thus affect network capacity and service capability. For some public services operated on networks, possible blackouts and serious flow loss introducing extreme risks are generally unacceptable. The problem is to find a feasible schedule of maintenance tasks so that the maximum flow loss during the planning horizon is minimized. We introduce a mixed integer programming formulation and a Benders reformulation for the problem. A Benders decomposition algorithm based on a branch-and-cut framework is designed. Strengthened initial cuts and effective cuts are introduced to reduce feasible region so that the exact algorithm is accelerated. An efficient separation procedure is proposed to generate Benders optimality cuts. Computational experiments were conducted on a set of benchmark instances and a set of simulated instances based on telecommunication networks. Computational results show that our algorithm performs much better than applying a solver to the formulation and an existing Benders decomposition algorithm for a related problem. Optimal schedules can reduce extreme risks caused by large flow loss on the network. Since multiple optimal solutions may exist, hierarchical optimization is used to further select a desirable schedule, by either minimizing total flow loss or minimizing the duration of maximum flow loss. With adaptations, our algorithm also performs well for two extensions.},
  archive      = {J_EJOR},
  author       = {Shuang Jin and Ying Liu and Jing Zhou and Qian Hu},
  doi          = {10.1016/j.ejor.2025.07.056},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {430-445},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing the maximum flow loss in the network maintenance scheduling problem with flexible arc outages},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stochastic quay partitioning problem. <em>EJOR</em>, <em>328</em>(2), 415-429. (<a href='https://doi.org/10.1016/j.ejor.2025.07.043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the problem of dividing a quay of a container terminal into berth segments so that the quality of service for future ship arrivals is as good as possible. Since future arrivals are unknown, the alternative solutions are evaluated on various arrival scenarios generated for certain arrival intensity from a stochastic model referred to as a ship traffic model (STM). This problem will be referred to as a stochastic quay partitioning problem (SQPP). SQPP is defined by an STM, arrival intensity, quay length and a set of admissible berth lengths. Evaluation of an SQPP solution on one scenario is a problem of scheduling the arriving vessels on the berths, which is a classic berth allocation problem (BAP). In SQPP the sizes of BAP instances that must be solved by far exceed capabilities of the methods presented in the existing literature. Therefore, a novel approach to solving BAP is applied. Tailored portfolios of algorithms capable of solving very large BAP instances under limited runtime are used. Features of SQPP solutions are studied experimentally: patterns in selected berth lengths, dispersion of solutions quality and solutions similarity. We demonstrate, that partitioning a quay into equal-length berths is not the best approach. The largest vessel traffic is dominating in defining best quay partitions, but dedicating quays for shorter vessels give lower dispersion of solution quality. A set of algorithms to partition a quay is proposed and evaluated: methods based on integer linear programming (ILP) to match vessel classes arrival intensities with berth availability, hill climber, tabu search and a greedy approach. Only under high arrival intensity can these methods show their prowess. ILP methods have an advantage of low solution evaluation cost. Tabu is most flexible, but at high evaluation costs. To the best of our knowledge, SQPP is posed and solved for the first time in the operations research.},
  archive      = {J_EJOR},
  author       = {Jakub Wawrzyniak and Maciej Drozdowski and Éric Sanlaville},
  doi          = {10.1016/j.ejor.2025.07.043},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {415-429},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic quay partitioning problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scheduling mixed batch machines with inclusive processing set restrictions and non-identical capacities. <em>EJOR</em>, <em>328</em>(2), 407-414. (<a href='https://doi.org/10.1016/j.ejor.2025.07.012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new batch scheduling problem, name mixed batch scheduling problem, is received attentions recently. In a mixed batch scheduling model, the processing time of a job batch H is defined as α max j ∈ H { p j } + ( 1 − α ) ∑ j ∈ H p j , where α ∈ [ 0 , 1 ] is a constant. In other words, the processing time of a job batch is the weighted sum of the maximum processing time and the total processing time of jobs in the batch. In this paper, we study the problem of scheduling mixed batch machines with non-identical capacities under inclusive processing set restrictions, where the objective is to minimize the makespan of finishing all the jobs. We present a fast approximation algorithm with a performance ratio of 4 / 3 + α for the problem, which improves up the existing performance bounds in the literature. By providing a technical lemma, we are able to develop the first polynomial time approximation scheme (PTAS) for the problem. We also design linear-time approximation schemes for two important special cases of the problem.},
  archive      = {J_EJOR},
  author       = {Jinwen Ou and Weidong Li},
  doi          = {10.1016/j.ejor.2025.07.012},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {407-414},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling mixed batch machines with inclusive processing set restrictions and non-identical capacities},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A matheuristic approach for the robust coloured travelling salesman problem with multiple depots. <em>EJOR</em>, <em>328</em>(2), 390-406. (<a href='https://doi.org/10.1016/j.ejor.2025.06.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a special type of the travelling salesman problem (TSP) called the coloured TSP (CTSP) is considered. The CTSP, which has many real-world applications, involves a set of salesmen, each assigned a specific colour, and cities that may have one or multiple colours. Salesmen are restricted to visiting only cities that share their colour. We consider a specific depot for each salesman, and the edge weights are uncertain, meaning that there is a set of possible scenarios for their values. A robust objective is considered and minimised using an artificial intelligence (AI)-driven matheuristic approach due to the high computational complexity of the problem. This approach integrates a variable neighbourhood search (VNS) framework with genetic algorithm (GA) and simulated annealing (SA) operators. More importantly, local improvements based on mathematical programming are applied to different parts of a proportion of the solutions using the concept of partial optimisation metaheuristic under special intensification conditions (POPMUSIC). A key innovation of our method is the use of an artificial neural network to guide the POPMUSIC procedure by selecting only solution segments with high improvement potential, thereby reducing computation time. Extensive computational experiments demonstrate the effectiveness of the proposed algorithm, which outperforms four state-of-the-art methods in solution quality and runs faster than three of them. We also investigate the contribution of individual algorithmic components and the cost of robustness. Furthermore, our method improves upon the best-known results for the single-depot deterministic version of the CTSP from the literature.},
  archive      = {J_EJOR},
  author       = {Abtin Nourmohammadzadeh and Stefan Voß},
  doi          = {10.1016/j.ejor.2025.06.018},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {390-406},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A matheuristic approach for the robust coloured travelling salesman problem with multiple depots},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fifty years of research on resource-constrained project scheduling explored from different perspectives. <em>EJOR</em>, <em>328</em>(2), 367-389. (<a href='https://doi.org/10.1016/j.ejor.2025.03.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resource-constrained project scheduling problem is one of the most investigated problems in the project scheduling literature, and has a rich history. This article provides a perspective on this challenging scheduling problem, without having the ambition to provide a complete overview. Instead, the article does aim to summarize a number of reasons why this problem has been so intensely investigated from different perspectives. It will be shown that this scheduling problem has many faces, and therefore deserves a lot of research time from a computational and theoretical point of view as well as from a practical point of view. An overview of possible extensions to other problems and a detailed overview of the used (both heuristic and exact) solution methods will be given. In addition, the data used will be discussed and interesting avenues for further research will be mentioned throughout the different sections.},
  archive      = {J_EJOR},
  author       = {Christian Artigues and Sönke Hartmann and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2025.03.024},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {367-389},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of research on resource-constrained project scheduling explored from different perspectives},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="eswa">ESWA - 279</h2>
<ul>
<li><details>
<summary>
(2026). Modeling trust in human–Robot collaborative construction: An improved cloud bayesian network. <em>ESWA</em>, <em>298</em>, 129928. (<a href='https://doi.org/10.1016/j.eswa.2025.129928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust developed by workers towards robotic systems is critical to the successful implementation of human-robot collaboration (HRC) in construction, directly influencing operational efficiency and safety outcomes. To accurately evaluate trust risks within HRC scenarios, this study proposes an integrated method combining an improved Cloud Model (CM) with Bayesian Networks (BNs) for dynamic trust risk analysis. Initially, key factors influencing trust risks in HRC were identified through literature review and expert elicitation. The improved CM was then employed to capture inherent uncertainties and fuzziness in trust state definitions, facilitating the discretization of continuous expert evaluations into appropriate risk states. Subsequently, the BN was developed to perform forward reasoning, sensitivity analysis, and backward diagnosis, enabling proactive trust risk prediction, critical factor identification, and targeted interventions. The primary contributions of this research include: (a) identifying 11 trust factors from human, organizational, and robotic perspectives, offering a comprehensive basis for analyzing HRC trust risk in construction; (b) employing an optimized cloud entropy approach to accurately capture fuzziness and randomness in expert evaluations, thereby producing robust prior probabilities; and (c) developing a hybrid CBN framework to assess HRC trust risk in construction, demonstrating superior performance in risk perception, analysis, and control. Overall, this study provides valuable insights into safer and more effective HRC through dynamic evaluation of trust risk.},
  archive      = {J_ESWA},
  author       = {Lei Wang and Mingyu Zhang and Heng Li and Yinong Hu and Jie Ma and Waleed Umer and Xin Fang},
  doi          = {10.1016/j.eswa.2025.129928},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129928},
  shortjournal = {Expert Syst. Appl.},
  title        = {Modeling trust in human–Robot collaborative construction: An improved cloud bayesian network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A machine learning-based medical device recall initiator prediction framework: From supply chain risk management and resilience view. <em>ESWA</em>, <em>298</em>, 129922. (<a href='https://doi.org/10.1016/j.eswa.2025.129922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent quality problems with medical devices and the associated recall present potential health risks to users, bringing extra costs and disturbances to the supply chain. Classical medical device recall strategy neglects the significance of the failure detection process in the premarket phase, increasing the medical device recall risks. This research first established the theoretical foundation for the medical device recall reasons detection problem by reconstructing the medical device recall strategy from the supply chain risk and resilience view and reinforced the importance of failure detection and quality inspection work in the premarket stage. Moreover, existing medical device failure reason prediction research was limited in practicality and scalability. To address this problem, we developed a machine learning-based medical device recall initiator prediction system framework to conduct proactive failure detection based on the industrial case. By redesigning in dataset, clustering method and input feature selection, an accuracy rate of 88.85% is achieved, which indicates the potential of the proposed framework in assisting manufacturers with asset predictive failure detection for reducing recall. A comparative analysis of prediction performance between our framework and the most similar research that utilized the same prediction algorithms was presented. The comparison results showed that our distinctive design in the dataset, clustering method, and key input features chosen are valid and efficient. Before redesigning the prediction algorithms that require higher technical investment, our elaborate research design in selecting the dataset, cluster method, and key input features can be the antecedents of better prediction performance for manufacturers. The proposed predictive framework obtains higher accuracy, scalability, practicality, with accessibility.},
  archive      = {J_ESWA},
  author       = {Yang Hu and Davy Monticolo and Pezhman Ghadimi},
  doi          = {10.1016/j.eswa.2025.129922},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129922},
  shortjournal = {Expert Syst. Appl.},
  title        = {A machine learning-based medical device recall initiator prediction framework: From supply chain risk management and resilience view},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A computational learning pipeline for glaucoma progression detection based on the prediction of visual field changes from fundus photographs. <em>ESWA</em>, <em>298</em>, 129907. (<a href='https://doi.org/10.1016/j.eswa.2025.129907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of glaucoma progression is crucial to managing patients, permitting individualized care plans and treatment. It is a challenging task requiring the assessment of structural changes to the optic nerve head and functional changes based on visual field testing. Artificial intelligence, especially deep learning techniques, has shown promising results in many applications, including glaucoma diagnosis. This paper proposes a two-stage computational learning pipeline for detecting glaucoma progression using only fundus photographs. In the first stage, a deep learning model takes a time series of fundus photographs as input and outputs a vector of predictions where each element represents the overall rate of change in visual field (VF) sensitivity values for a sector (region) of the optic nerve head (ONH). We implemented two deep learning models—ResNet50 and InceptionResNetV2—for this stage. In the second stage, a binary classifier (weighted logistic regression) takes the predicted vector as input to detect progression. We also propose a novel method for constructing annotated datasets from temporal sequences of clinical fundus photographs and corresponding VF data suitable for machine learning. Each dataset element comprises a temporal sequence of photographs together with a vector-valued label. The label is derived by computing the pointwise linear regression of VF sensitivity values at each VF test location, mapping these locations to eight ONH sectors, and assigning the overall rate of change in each sector to one of the elements of the vector. We used a retrospective clinical dataset with 82 patients collected at multiple timepoints over five years in our experiments. The InceptionResNetV2-based implementation yielded the best performance, achieving detection accuracies of 97.28 ± 1.10 % for unseen test data (i.e., each dataset element is unseen but originates from the same set of patients appearing in the training dataset), and 87.50 ± 0.70 % for test data from unseen patients (training and testing patients are entirely different). The testing throughput was 11.60 ms per patient. These results demonstrate the efficacy of the proposed method for detecting glaucoma progression from fundus photographs.},
  archive      = {J_ESWA},
  author       = {Md.Reduanul Haque and Andrew Mehnert and William Huxley Morgan and Graham Mann and Ferdous Sohel},
  doi          = {10.1016/j.eswa.2025.129907},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129907},
  shortjournal = {Expert Syst. Appl.},
  title        = {A computational learning pipeline for glaucoma progression detection based on the prediction of visual field changes from fundus photographs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Operator learning-based springback behavior prediction for complex-shaped tube free-bending forming. <em>ESWA</em>, <em>298</em>, 129899. (<a href='https://doi.org/10.1016/j.eswa.2025.129899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Free-bending (FB) technology enables the efficient processing of spatially complex-shaped tubes. Springback causes variations in curvature and torsion of the tube axis during the FB process. The mapping relationship of bent tube curvature and torsion from ideal to actual values can be abstracted as nonlinear physical operators. This paper first proposes a novel six-axis FB processing method that can control geometric features of tube transition segments. Then, an operator learning-based springback behavior prediction (OL-SBP) framework is presented, which includes an OL module and an SBP module. A feature-information-enhanced deep operator network (FIE-DeepONet) is integrated into the first module to learn tube springback operators. The curvature and torsion predicted by the OL module are then fed into the SBP module to calculate the overall shape of the springback axis. This paper also introduces a set of similarity evaluation indicators that are independent of the curve’s spatial attitude. Planar and spatial bent tubes are selected as case studies. Results show that the framework yields more accurate predictions compared to the analytical model. The framework also exhibits excellent generalization performance. Once FIE-DeepONet has learned the springback operators, it can accurately predict the springback curvature and torsion, even for tube shapes not present during training.},
  archive      = {J_ESWA},
  author       = {Yongzhe Xiang and Zili Wang and Shuyou Zhang and Le Wang and Caicheng Wang and Yaochen Lin and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129899},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129899},
  shortjournal = {Expert Syst. Appl.},
  title        = {Operator learning-based springback behavior prediction for complex-shaped tube free-bending forming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exact reliability of cold chain networks with multi-state travel time and transport capacity. <em>ESWA</em>, <em>298</em>, 129892. (<a href='https://doi.org/10.1016/j.eswa.2025.129892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-pandemic lifestyle changes have increased reliance on e-commerce, boosting the logistics sector. One of the most highly regarded industries is cold chain logistics, especially for vaccines and refrigerated foods. In cold chain networks, transport routes have varying capacities based on customer orders, and travel times fluctuate due to traffic and weather. Thus, this study focuses on evaluating network reliability, i.e., the probability to meet given demands within the specified time threshold, of cold chain networks considering the two multi-state factors: travel time and transport capacity. To account for practical situations, a multi-state cold chain network (MCCN) is constructed with retailers, third-party logistics companies, and suppliers as nodes, and transportation routes as arcs. The concept of minimal path is used to determine the transport flow that complies with the time threshold and to determine the transport capacity vectors that satisfy the demands. An algorithm is proposed to resolve different characteristics of time thresholds and demand requirements for efficient assessment. Network reliability is successfully calculated, as shown in the case and sensitivity analysis. This allows managers to grasp the performance of MCCN and make informed decisions based on the achieved network reliability.},
  archive      = {J_ESWA},
  author       = {Thi-Phuong Nguyen and Chin-Lung Huang and Louis Cheng-Lu Yeng and Yi-Kuei Lin},
  doi          = {10.1016/j.eswa.2025.129892},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129892},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exact reliability of cold chain networks with multi-state travel time and transport capacity},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An RL-NSGA-DP algorithm for optimization of robot placement and trajectory allocation in mobile robotic grinding of wind turbine blades. <em>ESWA</em>, <em>298</em>, 129876. (<a href='https://doi.org/10.1016/j.eswa.2025.129876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robot machining, offering a more flexible and reconfigurable approach compared to fixed-base robots, has therefore become a promising solution for efficiently machining large and complex wind turbine blades. In this context, determining proper machining placements and allocating machining trajectories are two pivotal factors in the mobile robotic automation grinding of wind turbine blades, directly affecting machining efficiency and quality. However, the highly nonlinear performance distribution of the robot in the task space, combined with the complexity of the machining surface, presents significant challenges. To address these challenges, this paper presents a general optimization model of this problem with the objectives of completion time and robot manipulability, considering singularity avoidance and collision avoidance. Based on this model, an improved non-dominated sorting genetic algorithm integrated with reinforcement learning and dual population co-evolution (RL-NSGA-DP) is developed. In RL-NSGA-DP, each solution is coded using a novel two-layer metavariable encoding scheme, and a tailored dominated-recessive crossover operator is designed. Moreover, a dual-population collaborative search strategy employing different operators and an adaptive switching environmental selection mechanism based on reinforcement learning are implemented to ensure the convergence and maintain population diversity. Comparative experiments on test instances and a practical case study demonstrate that RL-NSGA-DP outperforms five well-known multi-objective evolutionary algorithms, and effectively addresses robot placement and trajectory allocation problem in mobile robotic machining systems.},
  archive      = {J_ESWA},
  author       = {Yi Hua and Xuewu Wang},
  doi          = {10.1016/j.eswa.2025.129876},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129876},
  shortjournal = {Expert Syst. Appl.},
  title        = {An RL-NSGA-DP algorithm for optimization of robot placement and trajectory allocation in mobile robotic grinding of wind turbine blades},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RAFN: A risk-aware feature network for identifying risk factors in supply chain finance. <em>ESWA</em>, <em>298</em>, 129874. (<a href='https://doi.org/10.1016/j.eswa.2025.129874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As supply chain finance businesses expand, traditional risk assessment systems, which rely heavily on manual processes and static rule-based frameworks, are increasingly unable to keep up with the complexity and dynamism of modern risk patterns. This often leads to delayed responses and inefficiencies in risk management. To address key challenges such as difficulties in integrating heterogeneous data, low detection rates for hidden risks, and limited ability to capture dynamic risk patterns, this paper introduces a novel Risk-Aware Feature Network (RAFN) driven by an adaptive attention mechanism. The RAFN model is designed with a dual-channel architecture to process numerical and categorical data separately, employs gated linear units to dynamically merge heterogeneous data streams, and incorporates a multi-head attention mechanism with dynamic coefficients to focus on risk-sensitive features adaptively. Experiments conducted on both public and proprietary datasets show that RAFN outperforms mainstream algorithms, achieving a 1.73%-5.81% improvement in accuracy, recall, and F1-score, while maintaining a strong balance between specificity and recall. Furthermore, this study proposes a closed-loop risk management framework based on RAFN, which integrates “smart contract triggering, off-chain model evaluation, and on-chain consensus validation.” This approach offers an efficient technical solution to break down data silos and enhance the precision of risk identification in supply chain finance, paving the way for more effective and reliable risk control systems.},
  archive      = {J_ESWA},
  author       = {Yang Zhang and Yating Zhao and Wenjuan Lian and Bin Jia},
  doi          = {10.1016/j.eswa.2025.129874},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129874},
  shortjournal = {Expert Syst. Appl.},
  title        = {RAFN: A risk-aware feature network for identifying risk factors in supply chain finance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Novel design and speed-adaptive control of a cable-driven parallel elastic hip exoskeleton for compliant locomotion assistance. <em>ESWA</em>, <em>298</em>, 129871. (<a href='https://doi.org/10.1016/j.eswa.2025.129871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic hip exoskeletons hold enormous potential to enhance human locomotion. However, the rigid structures and predefined control laws limit their compliance and adaptability during dynamic human-robot interactions. Here, a novel parallel elastic hip exoskeleton is developed for human locomotion assistance. The exoskeleton utilizes a remote cable actuation system to improve compliance and incorporates a parallel elastic mechanism at the hip wearable components to enhance actuator energy efficiency by generating a compensatory torque. For exoskeleton control, a speed-adaptive torque control strategy is implemented to modulate the assistance torque in real time, based on the user’s gait phase and hip movement frequency estimated by adaptive oscillators. The system was tested on seven healthy subjects, and preliminary results indicate that the parallel elastic element achieves a 40.2 % reduction in peak motor torque through energy conversion. The controller exhibits excellent torque tracking performance and effectively extracts human gait features across walking speeds with hip frequency correlation ( R 2 = 0.89). Furthermore, the hip exoskeleton significantly reduced users’ peak hip moments and muscle activity while preserving natural kinematics. The parallel elastic hip exoskeleton demonstrates strong adaptive assistive capabilities and is expected to enhance locomotion in real-world applications.},
  archive      = {J_ESWA},
  author       = {Jing Zhang and Aibin Zhu and Bingsheng Bao and Xinyu Wu and Chunli Zheng and Meng Li and Jing Wang and Yu Zhang and Xue Wu and Xiao Li},
  doi          = {10.1016/j.eswa.2025.129871},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129871},
  shortjournal = {Expert Syst. Appl.},
  title        = {Novel design and speed-adaptive control of a cable-driven parallel elastic hip exoskeleton for compliant locomotion assistance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Short-term high-speed rail passenger flow forecasting integrated extended empirical mode decomposition with multivariate and bidirectional support vector machine. <em>ESWA</em>, <em>298</em>, 129870. (<a href='https://doi.org/10.1016/j.eswa.2025.129870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed rail (HSR) short-term passenger flow forecasting is of great significance for dynamically adjusting operation plans and optimizing transportation resource allocation. For this reason, this paper proposes an innovative complete ensemble empirical mode decomposition with adaptive noise integrated with multivariate and bidirectional support vector machine (CEEMDAN-MBSVM) method with four key steps. First, we analyze the correlations between multiple origin–destination (OD) passenger flows and select strongly correlated ODs incorporated with their opposite OD for joint bidirectional forecasting. Second, we decompose the original passenger flow time series by using period division technique of CEEMDAN, which yield multiple intrinsic mode functions (IMFs) and a residual trend term (RES). Then we apply MBSVM to predict the IMFs of each OD and use trend extrapolation to forecast the RES. Finally, we reconstruct the predicted IMFs and RES to obtain the final bidirectional HSR OD daily passenger flows. Subsequently, we conduct a comprehensive validation exercise and significance testing, using real data from Beijing-Shanghai HSR Line, against seven prediction methods. In particular, for five selected ODs, benchmarking against EEMD-MSVM method, the best performer among the six existing models, our model reduces the minimum mean absolute percentage error (MAPE) by 1.30 % to 4.97 % and benchmarking against ARIMA model, the worst performer among the six existing models, our model reduces the MAPE by 11.57 % to 22.72 %. This research has clearly demonstrated the value of leveraging bidirectional OD data on improving short-term passenger flow forecasting.},
  archive      = {J_ESWA},
  author       = {Xueyi Guan and Michael Z.F. Li and Jin Qin and Chengna Wang},
  doi          = {10.1016/j.eswa.2025.129870},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129870},
  shortjournal = {Expert Syst. Appl.},
  title        = {Short-term high-speed rail passenger flow forecasting integrated extended empirical mode decomposition with multivariate and bidirectional support vector machine},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Frequency-decomposed attention joint optimization network for image compressive sensing. <em>ESWA</em>, <em>298</em>, 129866. (<a href='https://doi.org/10.1016/j.eswa.2025.129866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network approaches for image compressive sensing (ICS) have garnered significant attention due to their high efficiency and fidelity in image reconstruction. Reconstructing complex image textures from highly compressed measurements has been a longstanding goal of ICS, yet existing methods often struggle to varying degrees with the restoration of low-frequency (LF) textures and high-frequency (HF) details, which potentially limits the quality of the reconstructed image. In this paper, we propose a Frequency-decomposed Attention Joint Optimization Network (FAJO-Net) for ICS, which is capable of enhancing the attention to LF and HF components of images. Specifically, we introduce a frequency-decomposed sparse prior and coupling fidelity constraints, and incorporate a tri-optimization network framework for full, low, and high-frequency (FLH) features, where each component is optimized using an optimization-unfolded multi-scale network (OM-Net), inclusive of Principal Component Augmented Gradient Descent Module (PCAGDM) and U-shaped Proximal Mapping Module (UPMM). The PCAGDM optimizes the FLH features efficiently by supplementing the optimization of the minimum dimension principal component augmented features while optimizing the principal component features. The UPMM is able to perform multi-scale proximal mapping for all FLH features. Finally, we design a Frequency-decomposed Interaction Attention Module (FIAM) to enhance the fusion of FLH features, particularly the HF and LF components related to the full-frequency features, while reducing the impact of unnecessary features introduced by frequency decomposition. Extensive experiments demonstrate that our proposed FAJO-Net surpasses the state-of-the-art ICS networks in terms of image fidelity and visual effect, and validates that the proposed FAJO-Net framework can help enhance the image reconstruction capabilities of the vast majority of existing ICS networks, further unlocking the potential for high-fidelity restoration in ICS. Code is available at https://github.com/giant-pandada/FAJO-Net .},
  archive      = {J_ESWA},
  author       = {Zhifu Tian and Tao Hu and Di Wu and Shu Wang and Tingli Li and Ming Zhang},
  doi          = {10.1016/j.eswa.2025.129866},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129866},
  shortjournal = {Expert Syst. Appl.},
  title        = {Frequency-decomposed attention joint optimization network for image compressive sensing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Identification of critical nodes by fusing propagation probabilities and entropy in binary networks. <em>ESWA</em>, <em>298</em>, 129861. (<a href='https://doi.org/10.1016/j.eswa.2025.129861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of critical nodes is crucial for effectively allocating resources and prioritizing tasks in complex networks, which significantly enhances the stability and the efficiency of networks in real-world environments. Generally, existing studies primarily focus on extracting multiple different influential factors from network topology, but they have to face accuracy limitations due to high computational complexity, overlapping influence ranges, and information loss. Inspired by information entropy, in this paper, we explore to identify critical node in complex networks from the perspective of inter-node propagation probabilities. We introduce an innovative critical node ranking algorithm, named MNIE (Mixed Node Information Entropy). MNIE initially segments the node influence within the network topology by distinguishing between global and local effects so as to integrate a more comprehensive topological features set. Then, we refine the connection probability calculation and integrate the features derived from the network structural topology with the probabilities of information transmission (infection rates) among the nodes. Experimental results on 9 real-world networks and 4 synthetic datasets indicate that MNIE enhances the identification of critical nodes and accomplishes better than state-of-the-art methods on monotonicity and accuracy.},
  archive      = {J_ESWA},
  author       = {Lintao Zhang and Jianing Zhang and Rong Yan and Guoqin Yu},
  doi          = {10.1016/j.eswa.2025.129861},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129861},
  shortjournal = {Expert Syst. Appl.},
  title        = {Identification of critical nodes by fusing propagation probabilities and entropy in binary networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive energy management for battery swapping stations using HMDE-PSO: Optimizing charge-discharge control against cyber-physical attacks. <em>ESWA</em>, <em>298</em>, 129860. (<a href='https://doi.org/10.1016/j.eswa.2025.129860'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery Swapping Stations (BSSs) are emerging as critical components in smart power systems, offering rapid energy refueling, grid load balancing, and improved battery lifecycle management for electric vehicles (EVs). However, the economic operation and cyber-physical security of BSSs remain underexplored, particularly in microgrids that integrate distributed generation (DG) and face increasing vulnerability to cyber-attacks. This paper presents a novel, adaptive energy management framework that optimally schedules the charge and discharge cycles of BSSs under uncertain EV user behavior and potential cyber-physical disruptions. A key innovation lies in modeling two types of cyber-attacks—power disruption and control hijacking—and embedding their technical and economic impacts directly into the optimization process. To solve this multi-objective problem, a Hybrid multi-objective Differential Evolution–Particle Swarm Optimization (HMDE-PSO) algorithm is proposed, which efficiently balances cost minimization, system reliability, and resilience. The framework is validated using the IEEE 69-bus distribution system, demonstrating substantial improvements: over 40% reduction in power losses, enhanced voltage stability, and lower operational costs compared to conventional methods. This work distinguishes itself by integrating cyber-defense considerations with real-time energy scheduling, providing a comprehensive and resilient solution for future BSS-integrated microgrids.},
  archive      = {J_ESWA},
  author       = {Mehdi Ahmadi Jirdehi and Hamdi Abdi and Hazhir Dousti},
  doi          = {10.1016/j.eswa.2025.129860},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129860},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive energy management for battery swapping stations using HMDE-PSO: Optimizing charge-discharge control against cyber-physical attacks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-enhanced 3D residual networks for knee abnormality classification. <em>ESWA</em>, <em>298</em>, 129858. (<a href='https://doi.org/10.1016/j.eswa.2025.129858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of deep learning technologies, particularly through Convolutional Neural Networks (CNNs), has substantially enriched medical image analysis. This study focuses on improving knee MRI diagnostics by comparing 2D and 3D CNN architectures using the MRNet and SKM-TEA datasets. Initially, modified 2D CNNs, such as ResNet50, were applied for plane-specific and integrated multi-plane analyses. Plane-specific models captured detailed anatomical features, while integrated approaches synthesized information across multiple planes, improving diagnostic capability but lacking full volumetric data utilization. To address these limitations, a novel 3D CNN architecture enhanced with residual attention blocks was developed, leveraging volumetric MRI data. These blocks integrate spatial attention and Squeeze-and-Excitation (SE) mechanisms, optimizing feature focus for accurate diagnostics. This approach improved both model precision and interpretability, which are crucial for clinical applications. Experimental evaluation on the MRNet dataset demonstrated that the proposed 3D CNN outperformed 2D models, achieving 83.58 % accuracy for abnormalities. On the SKM-TEA dataset, the model classified Meniscal Tear (71.36 %), Ligament Tear (79.84 %), Cartilage Lesion (84.28 %), and Effusion (76.74 %), demonstrating robustness in complex pathology detection. Gradient-weighted Class Activation Mapping (Grad-CAM) further enhanced interpretability by highlighting critical diagnostic regions. These findings emphasize the effectiveness of attention-guided 3D CNNs in knee abnormality classification. Future work will explore broader applications in medical imaging, refining the model’s generalizability across diverse clinical datasets.},
  archive      = {J_ESWA},
  author       = {Mohamad M.A. Ashames and Semih Ergin and Omer N. Gerek and H. Serhan Yavuz},
  doi          = {10.1016/j.eswa.2025.129858},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129858},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-enhanced 3D residual networks for knee abnormality classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SmartScope: Smart contract vulnerability detection via heterogeneous graph embedding with local semantic enhancement. <em>ESWA</em>, <em>298</em>, 129857. (<a href='https://doi.org/10.1016/j.eswa.2025.129857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart contracts are integral to blockchain ecosystems, yet their security remains a critical concern due to the prevalence of exploitable vulnerabilities. Existing conventional and deep learning-based vulnerability detection methods often struggle to capture the fine-grained semantics and heterogeneous structural dependencies essential for accurate analysis. We propose and implement SmartScope , a novel technique for smart contract vulnerability detection that leverages heterogeneous graph embedding with local semantic enhancement. Specifically, SmartScope constructs a semantically rich contract graph that depicts control-flow, data-flow, and fallback relations among critical code elements. To guide the graph learning process, we empirically assign various importance coefficients to vulnerability-relevant subgraphs, thereby enhancing the detection model’s focus on semantically critical regions. The heterogeneous graph transformer is then employed to generate context-aware node representations, which are then passed to an MLP-based detector for vulnerability classification. To the best of our knowledge, this is the first method that structurally encodes domain knowledge into the heterogeneous graph learning for achieving effective smart contract analysis. Experimental results demonstrate that SmartScope outperforms 10 representative conventional and deep learning-based baselines on over 5K smart contracts. The evaluation spans multiple vulnerability types, including reentrancy, timestamp dependence, and infinite loops, highlighting the effectiveness and robustness of our work.},
  archive      = {J_ESWA},
  author       = {Zhaoyi Meng and Zexin Zhang and Wansen Wang and Jie Cui and Hong Zhong},
  doi          = {10.1016/j.eswa.2025.129857},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129857},
  shortjournal = {Expert Syst. Appl.},
  title        = {SmartScope: Smart contract vulnerability detection via heterogeneous graph embedding with local semantic enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Short-term air quality prediction using a multi-scale attention fusion model with 3DIGAT-CBAM-BiLSTM based on spatio-temporal correlation. <em>ESWA</em>, <em>298</em>, 129856. (<a href='https://doi.org/10.1016/j.eswa.2025.129856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air Quality Index (AQI) prediction is crucial for environmental management and public health. However, most existing studies focus on single site modeling, neglecting the complex spatial correlations of meteorological factors and air pollutants. Therefore, a multi-scale spatio-temporal prediction model, 3DIGAT-CBAM-BiLSTM, is proposed to fully capture the spatio-temporal evolution characteristics of AQI. To reduce the interference of redundant information, the Maximum Information Coefficient and Dynamic Time Series Trend Correlation Method are employed to select the neighboring sites and influencing factors that are highly correlated with the AQI of the target site. The original air quality data is decomposed and reconstructed into high-frequency, low-frequency, and trend-term subsequences using Multivariate Variational Mode Decomposition and Sample Entropy to enhance prediction accuracy. To forecast the three-dimensional spatial tensors of these reconstructed subsequences based on time steps, monitoring sites, and influencing factors, we propose the 3DIGAT-CBAM-BiLSTM model. The spatial dependencies between sites are effectively captured by the Improved Graph Attention Network, which constructs a graph adjacency matrix based on MIC and geographic distance. Meanwhile, the Convolutional Block Attention Mechanism enhances the focus on important sites and features by combining channel and spatial attention. Furthermore, the Bidirectional Long Short-Term Memory network extracts global temporal patterns. The experimental results on the Beijing dataset show that the proposed model achieves a relative reduction of 8.53 % in RMSE and 5.83 % in MAE compared with the optimal baseline model, demonstrating clear performance improvements and offering a novel approach for modeling complex spatio-temporal data.},
  archive      = {J_ESWA},
  author       = {Liangqiong Zhu and Liren Chen and Huayou Chen},
  doi          = {10.1016/j.eswa.2025.129856},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129856},
  shortjournal = {Expert Syst. Appl.},
  title        = {Short-term air quality prediction using a multi-scale attention fusion model with 3DIGAT-CBAM-BiLSTM based on spatio-temporal correlation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG-based emotion identification from nerve conduction mechanisms: A gustatory-emotion coupling model combined with multiblock attention module. <em>ESWA</em>, <em>298</em>, 129855. (<a href='https://doi.org/10.1016/j.eswa.2025.129855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG)-based emotion identification enables accurate emotional interaction in brain-computer fusion by decoding brain signals, thereby enhancing the intelligence of human-computer collaboration. Data augmentation (DA) techniques offer a promising solution to the challenge of data scarcity in emotion identification. However, traditional DA methods often overlook the physiological mechanisms underlying EEG data, limiting their effectiveness and constraining the performance of emotion classification. To address this, a DA model based on human nerve conduction mechanisms (NCMs), named the gustatory-emotion coupling model and multiblock attention module (GECM-MBAM), is proposed to improve the performance of emotion identification. First, the 1/ f characteristics and synchronization of brain responses are reproduced in the GECM output when stimulated by EEG. The bionic performance of the model in EEG processing is validated, demonstrating brain-like perception of EEG signals via the GECM. Second, the MBAM is designed based on the characteristics of the GECM output, facilitating data augmentation of emotion-related EEG. Comparative experiments demonstrate that GECM-MBAM remarkably outperforms multiple existing DA models in recognition accuracy ( p < 0.05), confirming its effectiveness and superiority in EEG data augmentation. Finally, when compared with state-of-the-art algorithms and in ablation studies, GECM-MBAM demonstrates superior performance in emotion recognition. Specifically, GECM-MBAM attains accuracies of 96.91 % and 94.52 %, recalls of 96.23 % and 93.86 %, and kappa coefficients of 95.45 % and 94.29 % on the SEED and SEED-IV datasets, respectively. In conclusion, the performance of emotion identification is improved using the GECM-MBAM, offering a novel bionic processing approach for affective computing.},
  archive      = {J_ESWA},
  author       = {Wenbo Zheng and Yong Peng and Ancai Zhang and Quan Yuan},
  doi          = {10.1016/j.eswa.2025.129855},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129855},
  shortjournal = {Expert Syst. Appl.},
  title        = {EEG-based emotion identification from nerve conduction mechanisms: A gustatory-emotion coupling model combined with multiblock attention module},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CoSemiGNN: Blockchain fraud detection with dynamic graph neural networks based on co-association of semi-supervised. <em>ESWA</em>, <em>298</em>, 129853. (<a href='https://doi.org/10.1016/j.eswa.2025.129853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of blockchain technology, the increasing number of cyber frauds has caused huge economic losses, prompting more and more researchers to focus on how to effectively detect criminal activities in the blockchain transaction environment. Currently, graph neural network (GNN)-based methods have made significant progress in the field of blockchain illegal transaction detection due to their advantages in extracting graph structure features. However, existing illegal transaction pattern detection methods usually rely on historical labeled data. In the blockchain transaction environment, transaction data changes over time, and it is often difficult to obtain transaction labels. As a result, the performance of these methods is often unsatisfactory when faced with newly distributed transaction data. To address this challenge, this paper proposes a dynamic graph neural network based on co-association of semi-supervised (CoSemiGNN) for more efficiently identifying illegal transactions in blockchain environments under conditions of dynamically changing transaction data. The model combines semi-supervised learning with a dynamic graph neural network, enabling it to effectively identify novel illegal transaction patterns from unlabeled data and adapt to the evolving blockchain network environment. Specifically, CoSemiGNN captures features of novel transactions by integrating semi supervised learning results. It utilizes co-occurrence relations of edges and co-occurrence feature aggregation of nodes to skillfully integrate semi-supervised methods into feature extraction of transaction graphs, enabling the model to extract novel illegal transaction patterns from unlabeled data. In addition, the model utilizes self attention recurrent neural networks (RNNs) to capture temporal information in transactions, ensuring the dynamics of CoSemiGNN. Finally, we theoretically analyze the model, and experiments on a real Bitcoin transaction dataset demonstrate that CoSemiGNN outperforms existing methods by as much as 30 % in terms of F1 scores for detecting illegal transactions when the transaction data undergoes distributional migration. This research compensates the problem that existing methods ignore the distributional changes of blockchain transaction data, and provides a new perspective and an effective solution for blockchain illegal transaction detection.},
  archive      = {J_ESWA},
  author       = {Yulong Wang and Qingxiao Zheng and Xuedong Li and Lingfeng Wang and Ling Lin},
  doi          = {10.1016/j.eswa.2025.129853},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129853},
  shortjournal = {Expert Syst. Appl.},
  title        = {CoSemiGNN: Blockchain fraud detection with dynamic graph neural networks based on co-association of semi-supervised},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-based exploration and analysis of real-time and historical blockchain data. <em>ESWA</em>, <em>298</em>, 129851. (<a href='https://doi.org/10.1016/j.eswa.2025.129851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has revolutionized digital transactions and decentralized applications through its transparent and immutable ledger system, with platforms like Ethereum processing millions of transactions daily. However, as blockchain networks grow, traditional blockchain explorers show limitations when providing intuitive access to this vast data landscape, particularly when handling complex analytical queries, interpreting transaction patterns, and serving users without technical expertise. In this paper, we address these limitations by proposing an intelligent blockchain explorer that combines a Large Language Model (LLM)-powered agent for real-time blockchain interactions with a schema-aware SQL agent for historical data analysis. For real-time interactions, a dedicated blockchain agent connects to live networks through external APIs and specialized tools to process queries about current transactions and network states. When analyzing historical data patterns, we use an approach in which a Retrieval-Augmented Generation (RAG) system enhances the SQL agent’s understanding of the blockchain database schema and structure. This SQL agent subsequently translates natural language queries into SQL commands for efficient data retrieval from our periodically synchronized blockchain database. A query processor, powered by an LLM, intelligently routes user queries between these components based on temporal and contextual requirements, which enables both immediate blockchain state analysis and complex historical data querying. We evaluate our system on diverse blockchain queries, including complex analytical scenarios and multi-step operations. The experimental results demonstrate the effectiveness of our schema-aware SQL agent in accurate query translation and the overall system’s capability in handling both real-time and historical blockchain data exploration tasks.},
  archive      = {J_ESWA},
  author       = {S. Gebreab and A. Musamih and K. Salah and R. Jayaraman},
  doi          = {10.1016/j.eswa.2025.129851},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129851},
  shortjournal = {Expert Syst. Appl.},
  title        = {LLM-based exploration and analysis of real-time and historical blockchain data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-DFN: A reinforcement learning-driven dual-view feature fusion network for aspect-based sentiment analysis in online public opinion. <em>ESWA</em>, <em>298</em>, 129850. (<a href='https://doi.org/10.1016/j.eswa.2025.129850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis of online public opinion plays a vital role in understanding emotional dynamics on social media. However, most existing approaches focus on overall sentiment within text, often neglecting fine-grained sentiment information. This limitation restricts the depth of insights obtainable for public opinion monitoring. Aspect-based sentiment analysis (ABSA) addresses this issue by identifying sentiment toward specific aspects. Despite its advantages, current ABSA methods struggle to effectively integrate syntactic and sequential features, leading to incomplete contextual understanding. Additionally, noisy dependency trees introduce irrelevant syntactic features, which mislead sentiment classification and degrade accuracy. To address these challenges, we propose RL-DFN, a reinforcement learning-driven dual-view feature fusion network that enhances the robustness of ABSA models. RL-DFN consists of a dual-view feature fusion network and an actor-critic reinforcement learning module. The dual-view feature fusion network employs a graph attention network (GAT) to extract syntactic features and a transformer to capture sequential features. These complementary features are then fused through a bilinear affine transformation (Biaffine) module which captures fine-grained and bidirectional correlations between syntactic and sequential representations, enabling more expressive cross-view interactions. Simultaneously, an actor-critic reinforcement learning module dynamically refines the dependency tree representations by identifying key dependency types and filtering out noise, ensuring the reliability of syntactic features used in fusion. Extensive experiments on five widely used benchmark datasets demonstrate that RL-DFN significantly outperforms existing models, validating the effectiveness of our approach.},
  archive      = {J_ESWA},
  author       = {Ziheng Li and Kui Zhao},
  doi          = {10.1016/j.eswa.2025.129850},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129850},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-DFN: A reinforcement learning-driven dual-view feature fusion network for aspect-based sentiment analysis in online public opinion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Truck scheduling optimization at a cold chain cross-docking terminal considering uncertainties and the door-mixed service mode. <em>ESWA</em>, <em>298</em>, 129849. (<a href='https://doi.org/10.1016/j.eswa.2025.129849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing global demand for perishable agricultural products necessitates advancements in cold chain logistics. Cross-docking, known for its efficiency, is particularly well-suited for the transfer and distribution of such goods. However, truck scheduling at cold chain cross-dock terminals (CDTs) presents unique challenges, including product perishability, stringent time windows, and temperature-controlled environments. This work investigates a truck scheduling problem within a cold chain CDT, explicitly addressing uncertainties in refrigerated product damage (affecting supply) and repackaging times. A two-stage stochastic programming model is developed to capture these uncertainties. To solve this model, a scenario reduction approach employing K-means++ and K-medoids clustering is used, followed by Sample Average Approximation. Small-scale instances are solved optimally using CPLEX. For larger instances, a novel hybrid heuristic algorithm, combining the global search capabilities of Genetic Algorithms with the local search capabilities of Adaptive Large Neighborhood Search and Simulated Annealing, is proposed. Numerical experiments demonstrate the effectiveness of this algorithm, and sensitivity analysis provides valuable managerial insights.},
  archive      = {J_ESWA},
  author       = {Feifeng Zheng and Yuzhi Yi and Ming Liu and Huaxin Qiu},
  doi          = {10.1016/j.eswa.2025.129849},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129849},
  shortjournal = {Expert Syst. Appl.},
  title        = {Truck scheduling optimization at a cold chain cross-docking terminal considering uncertainties and the door-mixed service mode},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage hybrid heuristic approach combining genetic algorithm and variable neighborhood descent for the clustered electric vehicle routing problem. <em>ESWA</em>, <em>298</em>, 129848. (<a href='https://doi.org/10.1016/j.eswa.2025.129848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a new variant of the Electric Vehicle Routing Problem (EVRP), termed the Clustered Electric Vehicle Routing Problem (CluEVRP). In CluEVRP, all customers are pre-divided into clusters, and each charging station is either located within a cluster or independent of any cluster. Each electric vehicle must complete service for all customers within the current cluster before proceeding to the next cluster or returning to the depot. Electric vehicles can charge at any available charging station while serving a cluster, but incur a penalty cost upon entering each cluster. The objective is to minimize the total logistics cost, comprising vehicle startup costs, cluster entry penalty costs, and energy consumption costs. To solve CluEVRP, a two-stage hybrid heuristic combining a Genetic Algorithm (GA) and Variable Neighborhood Descent (VND) is proposed (HGA-VND), where GA ensures population diversity and VND enhances local search capability. To evaluate the algorithm’s performance, 75 test instances are adapted from classic Clustered Vehicle Routing Problem (CluVRP) dataset, incorporating electric vehicle characteristics. Computational results demonstrate that HGA-VND consistently obtains high-quality solutions within reasonable time for both CluVRP and CluEVRP instances, exhibiting good performance. Furthermore, sensitivity analysis indicates that moderately increasing vehicle capacity, optimizing battery configuration, and adopting lightweight designs can significantly reduce total operating costs. This study extends traditional EVRP research by introducing clustered customer distribution, enriching solutions for routing problems in practical logistics networks, particularly for “milk run” models in industrial parks, and providing significant managerial insights.},
  archive      = {J_ESWA},
  author       = {Yuheng Jin and Xiaoguang Bao and Zhaocai Wang},
  doi          = {10.1016/j.eswa.2025.129848},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129848},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage hybrid heuristic approach combining genetic algorithm and variable neighborhood descent for the clustered electric vehicle routing problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Group-guided prompt learning for vision-language models. <em>ESWA</em>, <em>298</em>, 129846. (<a href='https://doi.org/10.1016/j.eswa.2025.129846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt learning has become one of the mainstream approaches for enabling Vision-Language Models (VLMs) to effectively adapt to downstream tasks. Recent approaches enhanced the generalization of models by integrating prior knowledge from large language models (LLMs). However, these approaches overlook the potential value of group knowledge derived from semantic correlations across different classes, which may limit the performance of the model in the face of complex downstream tasks. To overcome this challenge, we propose Group-guided Prompt Learning (GGPL) , which integrates group knowledge into the original text prompts through LLMs. Specifically, GGPL uses LLMs to group all classes and integrates the group knowledge into the original text prompts to construct the final text prompts. Furthermore, we introduce a novel Group Knowledge Alignment (GKA) module, which aligns the learnable prompt features with the pre-trained features that contain group knowledge, preventing the learnable prompt features from feature shift during the training process and thus reducing overfitting. Experimental results across 11 public datasets demonstrate that the proposed GGPL method achieves significant improvement on various prompt learning approaches, while numerous ablation experiments also demonstrate the effectiveness of the each component of our GGPL method.},
  archive      = {J_ESWA},
  author       = {Yufei Zheng and Shengsheng Wang and Yansheng Gao},
  doi          = {10.1016/j.eswa.2025.129846},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129846},
  shortjournal = {Expert Syst. Appl.},
  title        = {Group-guided prompt learning for vision-language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MTMP: Multimodal targeted molecule generation model with protein features. <em>ESWA</em>, <em>298</em>, 129845. (<a href='https://doi.org/10.1016/j.eswa.2025.129845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular generation is a fundamental task in computational chemistry and drug discovery, aiming to design molecular structures with specific properties through algorithmic approaches. Traditional molecular generation models predominantly rely on SMILES representations or molecular topological graphs, limiting their ability to comprehensively capture molecular characteristics. To address this limitation, we propose MTMP, a generative model that bridges molecular structure and sequence. It uses a graph neural network to encode topological features and a GRU decoder to generate SMILES strings. This integration enhances the joint modeling of chemical properties and structure. Furthermore, MTMP incorporates a pre-trained language model trained on large-scale protein sequence data to extract target protein features, enabling a direct and more precise encoding of protein-specific information. This facilitates the generation of molecules with enhanced binding affinity to specific protein targets. To further improve molecular design efficacy, the model was pre-trained on the ZINC molecular database and subsequently fine-tuned via transfer learning using a curated dataset of ligand molecules with known activity against specific target proteins. Experimental evaluations demonstrate that MTMP achieves competitive performance compared to state-of-the-art molecular generation methods. The model produces structurally valid and diverse molecules with favorable physicochemical properties and strong drug-likeness. Notably, it generates novel compounds with high docking scores against target proteins, underscoring its potential for de novo drug design and targeted molecular discovery.},
  archive      = {J_ESWA},
  author       = {Dingming Liang and Runfu Yu and Xiaofeng Wang and Kaiyu Dong and Yunjing Zhang and Huicong Liang and Ximing Xu and Tao Song and Shuang Wang},
  doi          = {10.1016/j.eswa.2025.129845},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129845},
  shortjournal = {Expert Syst. Appl.},
  title        = {MTMP: Multimodal targeted molecule generation model with protein features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing mixture-of-experts model with prior knowledge for infrared and visible image fusion in complex degraded environments. <em>ESWA</em>, <em>298</em>, 129844. (<a href='https://doi.org/10.1016/j.eswa.2025.129844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims to generate a composite image that simultaneously preserves thermal radiation information from infrared images and the rich texture details of visible images. However, existing studies have overlooked the adverse effects of scene degradation in visible images on the fusion process, leading to suboptimal fusion outcomes. To address the challenges posed by scene degradation in image fusion tasks, this paper proposes an image fusion network with degradation correction capability named the Enhancing Mixture-of-Experts model with Prior knowledge for infrared and visible image fusion (EMPFusion), which pioneers the automated execution of multiple degradation restoration tasks during the fusion process. First, we develop a diffusion model for degradation removal to generate high-quality pseudo-labels of visible images, thereby providing supervisory signals for training the fusion network. Second, to overcome the significant challenges in feature extraction caused by complex and diverse degradation scenarios, we design a Degradation removal backbone based on Prior knowledge and the Mixture-of-Experts (DPM) module. This architecture removes degradation with low loss and moderate computational overhead by integrating domain-specific prior knowledge and the Mixture-of-Experts framework. Furthermore, to mitigate semantic loss under extreme environmental conditions, we propose a Semantic Deconstruction and Segmentation (SDS) module based on image-text foundation models, enhancing semantic consistency throughout the fusion process. Extensive experiments demonstrate that EMPFusion excels in infrared-visible fusion tasks within complex degraded scenes. Across the LLVIP, M3FD, RoadScene, and MSRS datasets, EMPFusion achieves state-of-the-art (SOTA) performance on multiple evaluation metrics, showcasing exceptional degradation robustness and visual-semantic information preservation capabilities. By unifying adaptive degradation correction with fusion, this research addresses fusion distortion caused by degraded multimodal data in harsh environments, significantly enhancing applicability and robustness in downstream tasks such as autonomous driving and security monitoring.},
  archive      = {J_ESWA},
  author       = {Gang Li and Chengrun Jiang and Jiachen Li and Jin Wan and Mingle Zhou and Delong Han},
  doi          = {10.1016/j.eswa.2025.129844},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129844},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing mixture-of-experts model with prior knowledge for infrared and visible image fusion in complex degraded environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scenario building change detection in remote sensing images using CNN-mamba hybrid network and consistency enhancement learning. <em>ESWA</em>, <em>298</em>, 129843. (<a href='https://doi.org/10.1016/j.eswa.2025.129843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scenario building change detection (BCD) plays a crucial role in scientific decision-making for urban development, natural disasters, and war scenarios. Nevertheless, current research confronts several challenges: (1) In deep learning (DL) methods, convolutional neural networks (CNN) fail to capture global information, and transformer has high computational overhead. (2) The clear distinction and collaborative suppression of scene-level and data-level pseudo-changes remain unresolved. (3) Multi-scenario BCD remains under-explored. To address these challenges, this study proposes a dual pseudo-change suppression framework for multi-scenario BCD. The framework includes the novel C 2 Mamba DL model (CNN collaborates with Mamba) and the consistency enhancement learning strategy (CELS). Among them, the C 2 Mamba merges the local feature extraction capability of CNN with the efficient global modeling capability of Mamba. It further integrates the proposed progressive context information aggregation module (PCIA) and the multi-scale differential feature enhancement module (MDFE). These two modules enable the model to effectively distinguish building changes among various ground targets, thereby suppressing the scene-level pseudo-changes. The CELS first performs data augmentation on the post-temporal images, including weather (clouds, rain, and overcast) and sensor differences. Subsequently, a novel difference-focused loss function is designed to ensure the accurate alignment of the change features between the original and enhanced image pairs, thereby suppressing the data-level pseudo-changes. In experiments, the BCD performance of urban development, natural disasters, and war scenarios is evaluated using WHU-CD, xBD, and WraBCD datasets, respectively. Compared to the second-best methods, the proposed method achieves F1-score improvements of 1.36%, 2.69%, and 1.65%, and IoU improvements of 2.49%, 3.21%, and 2.32%, respectively. Additionally, numerous ablation experiments are conducted to validate the validity of the proposed method. And the robustness of the proposed method is verified through zero-shot generalization and few-shot testing.},
  archive      = {J_ESWA},
  author       = {Wei Li and Guorui Ma and Haiming Zhang and Peng Chen and Di Wang and Rong Chen},
  doi          = {10.1016/j.eswa.2025.129843},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129843},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-scenario building change detection in remote sensing images using CNN-mamba hybrid network and consistency enhancement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Software defect prediction based on graph code semantics. <em>ESWA</em>, <em>298</em>, 129842. (<a href='https://doi.org/10.1016/j.eswa.2025.129842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As software systems become larger and more complicated, researchers are focusing more on how to effectively determine whether a program is flawed. Convolutional neural networks (CNNs) have been employed by several researchers in recent years to extract latent semantic information based on Abstract Syntax Trees (AST). However, the small granularity of code information in AST makes it easy to focus on local information and difficult to capture global semantic information. Further, ASTs lack control flow and data flow edges to fully utilize the code’s contextual semantic information. In this paper, we obtain the Control Flow Graph (CFG) and Program Dependence Graph (PDG) of a program through the improved TinyPDG. The Continuous Bag-of-Words (CBOW) model is utilized to train the corpus of CFG and PDG. Additionally, an improved PNIAT layer that combines multi-head attention and BiLSTM is employed to obtain method-level semantic feature vectors. Subsequently, methods based on weighted summation and linear fully connected are respectively proposed to aggregate method-level semantic feature vectors into file-level semantic feature vectors. The joint features are then constructed in combination with the hand-labeled features. Finally, after balancing the data using the SMOTETomek method, 11 machine learning models are used as classifiers for defect prediction. The experimental findings demonstrate that, compared to current software defect prediction techniques, the PDG using a weighted summation-based approach in the QDA model (W-PDG-QDA) presented in this research is the best, and improves AUC, F1, and accuracy scores by 0.723 % -21.72 %, 5.18 % -55.25 % and 1.99 % -25.16 %.},
  archive      = {J_ESWA},
  author       = {Hongwei Tao and Tao Wang and Zhenhao Geng and Xiaoxu Niu and Qiaoling Cao},
  doi          = {10.1016/j.eswa.2025.129842},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129842},
  shortjournal = {Expert Syst. Appl.},
  title        = {Software defect prediction based on graph code semantics},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel grey possibility clustering method based on inverse perspective and its applications. <em>ESWA</em>, <em>298</em>, 129837. (<a href='https://doi.org/10.1016/j.eswa.2025.129837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The center-point mixed possibility functions (CMPFs), which are determined by the decision makers qualitatively, are the most important element to obtain the effective clustering results in a grey clustering model. However, different decision makers provide different CMPFs which may lead to inconsistent or contradictory clustering results. In response to this problem, this article proposes an inverse grey possibility clustering model which can determine the CMPFs based on the part of the given final results. This novel matrix-based method can derive all of the required CMPFs which satisfy the partially known clustering results. More specifically, four theorems are put forward to analyze the four different cases, which are single index single object (SISO), single index multiple objects (SIMO), multiple indices single object (MISO) and multiple indices multiple objects (MIMO), respectively, to derive the required CMPFs of a given clustering result using algebraic expressions. For the purpose of developing the matrix representations for the MISO and MIMO situations, a new unified expression of the CMPFs to replace their existing segmented function expression is proposed. Finally, in order to demonstrate how it can be used in practice, the proposed method is applied for evaluating the effects of the reduction of pollution and carbon emissions and determining aerospace equipment component suppliers with different types of data. Compared to the forward GPC models, the proposed IGPC model has higher accuracy.},
  archive      = {J_ESWA},
  author       = {Junjie Wang and Xun Li and Yaoguo Dang and Zhongju Shang and Li Ye and Sifeng Liu},
  doi          = {10.1016/j.eswa.2025.129837},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129837},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel grey possibility clustering method based on inverse perspective and its applications},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing semantic and structural decoding for fMRI-to-image reconstruction. <em>ESWA</em>, <em>298</em>, 129836. (<a href='https://doi.org/10.1016/j.eswa.2025.129836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing visual images from fMRI signals is an enticing task that opens new horizons in understanding the intricate workings of human cognition. Most existing methods benefit from the diffusion model to decode high-level semantic information from fMRI signals, achieving promising semantic reconstruction. However, such a solution ignores low-level structure information, e.g. , object location and color, leading to an uncompleted visual reconstruction. In this work, we present a novel fMRI-to-image approach to reconstruct high-quality images by balancing semantic and structural decoding in the diffusion model. Specifically, we first utilize the CLIP model and an MLP module to extract sufficient semantic information and structural details, respectively. Then we design a S emantic and S tructural A wareness B alanced module ( SSAB ) to predict the weight of structural information for the current denoising step, thus generating high-quality images by gradually integrating semantic and structural information during image reconstruction. Experimental results demonstrate that the proposed SSAB model is effective with only a few extra parameters, it achieves state-of-the-art performance in comprehensively evaluating both semantic and structural metrics. All code is available on https://github.com/Venchy-he/SSAB .},
  archive      = {J_ESWA},
  author       = {Wanqi He and Jin Wang and Hui Li and Hanyang Chi and Bingfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129836},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129836},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing semantic and structural decoding for fMRI-to-image reconstruction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cohen’s class bilinear distributions and convolutional neural networks applied to broken rotor bar diagnosis. <em>ESWA</em>, <em>298</em>, 129835. (<a href='https://doi.org/10.1016/j.eswa.2025.129835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-frequency (t-f) signal processing techniques are particularly advantageous for induction motor (IM) fault diagnosis under dynamic and variable industrial operating conditions. Broken rotor bar (BRB) faults remain among the most challenging to detect because of their proximity to the fundamental frequency and significantly lower amplitude in comparison. Additionally, traditional approaches often result in false positives or negatives in scenarios involving load variation, power quality issues, and inverter-fed operations. To address these issues, this work proposes a comprehensive and objective methodology to evaluate eight Cohen-Class Bilinear Distributions (CCBD) to diagnose BRB. CCBDs offer high-resolution t-f representations, a crucial advantage for fault identification. However, their use is limited by cross-terms, nonlinear artifacts inherent to bilinear processing. To overcome this limitation, convolutional neural networks (CNNs) are applied to automatically classify t-f images and identify the CCBD methods that effectively minimize the cross-terms while preserving fault signature harmonics. This strategy also avoids subjective and time-consuming visual inspections. In addition, this work proposes a novel CNN architecture with an attention module (CNN-Attention), designed to enhance performance in this context. The evaluation considers challenging conditions, including 1) line-fed and 2) inverter-fed operation, 3) voltage unbalance, and 4) load oscillations, applied to a 2 HP, 60 Hz motor. Generalization capability is validated with data collected from a different laboratory, using an independent 1 HP, 50 Hz motor and five different inverter models. Experimental results show that combining CNN-Attention with CCBDs enables highly accurate and fast classification, achieving approximately 96% accuracy even when trained and tested on distinct laboratory datasets, demonstrating the effectiveness and adaptability of the proposed method.},
  archive      = {J_ESWA},
  author       = {Avyner L.O. Vitor and Alessandro Goedtel and Wesley A. Souza and Marcelo F. Castoldi and Daniel Morinigo-Sotelo and Oscar Duque-Perez},
  doi          = {10.1016/j.eswa.2025.129835},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129835},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cohen’s class bilinear distributions and convolutional neural networks applied to broken rotor bar diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven spatio-temporal driving risk field mechanism for path planning. <em>ESWA</em>, <em>298</em>, 129834. (<a href='https://doi.org/10.1016/j.eswa.2025.129834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterizing the future risk posed by surrounding human-driven vehicles is crucial for enhancing the safety of autonomous vehicles. Existing risk field methods build spatiotemporal risk fields using mathematical models with fixed parameters, making them struggle to capture dynamic human driving behaviors such as frequent acceleration, deceleration or lane changes, and are prone to overlooking rare but critical sudden events, which leads to unstable risk assessments in complex long-term scenarios. To address the aforementioned issues, a data-driven spatio-temporal risk field framework is proposed, which builds on a Bidirectional Deep Ultra-Gated Recurrent Unit (BDUGRU) to capture the high-dimensional spatio-temporal features of nearby vehicles and precisely predict vehicle distribution patterns over extended horizons. The introduced approach manages to yield a more accurate risk field and significantly improves long-term risk assessment in complex traffic environments. Furthermore, to validate the model’s practicality in engineering, we integrated Rapidly-exploring Random Tree with spatiotemporal data-driven risk field (SRF-RRT) and conducted path-planning simulations for autonomous vehicles using real-world traffic data. The results demonstrate that the proposed model excels in both prediction accuracy and reliability, and effectively reduces the measurement error based on collision time (TTC), offering strong applicability and providing a novel theoretical foundation and technological route for path planning in intelligent connected vehicles (ICVs).},
  archive      = {J_ESWA},
  author       = {Zhuoer Wang and Baohan Shi and Jianping Zhang and Xiaowen Zhu and Jian Zhou and Bingrong Xu and Bijun Li},
  doi          = {10.1016/j.eswa.2025.129834},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129834},
  shortjournal = {Expert Syst. Appl.},
  title        = {A data-driven spatio-temporal driving risk field mechanism for path planning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated pothole detection and volume assessment using PointPSSN and smartphone LiDAR point clouds. <em>ESWA</em>, <em>298</em>, 129833. (<a href='https://doi.org/10.1016/j.eswa.2025.129833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid detection and assessment of potholes are critical for ensuring road traffic safety. However, point cloud-based techniques relying on surveying vehicles or drones are often expensive and may be limited by roadside obstruction or narrow roadways. This study proposes a novel approach for assessing road potholes using point cloud data collected by smartphone LiDAR. The method integrates the Point Pothole-Specialized Segmentation Network (PointPSSN), a lightweight point cloud segmentation model designed to achieve high accuracy with low parameter complexity and rapid inference, together with scale-adjustable voxelization for assessment. The PointPSSN model incorporates a Geometric Feature Encoder module to capture the geometric attributes of potholes by extracting local geometric features. Neighbor Finder module identifies and aggregates neighboring points that provide more significant information. Experiments were conducted using a smartphone LiDAR device within a 7.28 km 2 area of Wuchang District, Wuhan, China, encompassing diverse road conditions. A dataset of 1040 potholes was constructed for model training and evaluation. The results demonstrate that the PointPSSN model achieves a segmentation accuracy of 97.336 %, precision of 91.322 %, recall of 79.888 %, an F1-score of 85.223 %, and an intersection-over-union (IoU) of 74.251 %. Notably, the accuracy, F1-score, and IoU surpass the performance of state-of-the-art models by 0.233 %, 1.336 %, and 2.006 %, respectively. In terms of efficiency, PointPSSN requires only one-seventh of the FLOPs and one-fifteenth of the parameters of state-of-the-art models, while achieving an 18.37 % faster inference speed. Furthermore, the average relative errors in depth and volume assessment using voxelization methods are 9.08 % and 9.04 %, respectively.},
  archive      = {J_ESWA},
  author       = {Tingrui Zhang and Xuequan Zhang and Zichuan Yang and Yumin Chen and Li Song and Weichen Zhang},
  doi          = {10.1016/j.eswa.2025.129833},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129833},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated pothole detection and volume assessment using PointPSSN and smartphone LiDAR point clouds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PAD: Popularity-aware debiasing for high-value item recommendation. <em>ESWA</em>, <em>298</em>, 129830. (<a href='https://doi.org/10.1016/j.eswa.2025.129830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems play a crucial role in our daily lives. However, in the context of high-value item recommendation, they face significant challenges. Due to the high price of these items, user purchase histories are often extremely sparse, making it difficult for recommender systems to accurately capture user preferences. Consequently, they tend to over-rely on popularity information. Moreover, the high-value item market exhibits a pronounced imbalanced distribution, where most user interactions focus on popular items. As a result, traditional recommender systems tend to prioritize these items while rarely recommending less popular ones, leading to low recommendation coverage. To address this challenge, we propose a P opularity- A ware D ebiasing (PAD) model, which improves recommendation coverage in high-value item scenarios without compromising accuracy. First, we employ soft prompts to guide a pre-trained language model (PLM) in enriching user representations. By incorporating semantic knowledge from the PLM, our model captures more comprehensive user preferences, ensuring recommendation accuracy while mitigating the model’s dependence on popularity signals. Building upon this, we apply popularity-aware debiasing to reduce overfitting and enhance coverage. PAD prevents the recommendation model from indiscriminately recommending the most popular items to all users, encouraging it to explore a wider range of items in its recommendations. Experiments conducted on industrial and public datasets demonstrate that our method mitigates popularity bias, significantly improving item recommendation coverage while maintaining accuracy.},
  archive      = {J_ESWA},
  author       = {Yuchen Zheng and Dongming Zhao and Xiangrui Cai and Yanlong Wen and Xiaojie Yuan},
  doi          = {10.1016/j.eswa.2025.129830},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129830},
  shortjournal = {Expert Syst. Appl.},
  title        = {PAD: Popularity-aware debiasing for high-value item recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HWA-net: Hierarchical window aggregate network for cross-resolution remote sensing change detection. <em>ESWA</em>, <em>298</em>, 129829. (<a href='https://doi.org/10.1016/j.eswa.2025.129829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-resolution remote sensing change detection (CD) is a critical task in various applications, including urban monitoring, environmental changes, and disaster management, where images captured at different times often possess varying spatial resolutions. Current methods typically address this by resampling low-resolution (LR) images to high-resolution (HR) formats, but such image-level strategies lead to significant artifacts and misalignment in the change map. These imperfections not only reduce detection accuracy but also lead to misleading or false change identifications, resulting in incorrect or incomplete conclusions in time-sensitive applications, such as land-use change detection or disaster monitoring. To address these challenges, we propose the Hierarchical Window Aggregate Network(HWA-Net), a novel framework that directly operates on cross-resolution image pairs without preprocessing, aiming to accurately aggregate cross-resolution representations for robust CD. HWA-Net initially employed window-based feature extraction to produce scale-independent representations, subsequently transferring these features to layered decoding. This process effectively enhances detection accuracy across diverse resolutions. Our approach establishes new state-of-the-art results on three synthesized datasets and one real-world cross-resolution change detection dataset.},
  archive      = {J_ESWA},
  author       = {Hualin Yang and Boran Ren and Zhijun Yang and Jing Xiong and Xiying Li and Calvin Yu-Chian Chen},
  doi          = {10.1016/j.eswa.2025.129829},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129829},
  shortjournal = {Expert Syst. Appl.},
  title        = {HWA-net: Hierarchical window aggregate network for cross-resolution remote sensing change detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Photovoltaic cluster power ultra-short-term cross-seasonal prediction integrating multi-channel information probabilistic diffusion generation and improved offset loss strategy. <em>ESWA</em>, <em>298</em>, 129826. (<a href='https://doi.org/10.1016/j.eswa.2025.129826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate photovoltaic (PV) power prediction under complex meteorological conditions remains challenging, particularly given the pronounced seasonal variations that obscure generation patterns. This study presents a novel ultra-short-term prediction framework integrating meteorological volatility analysis with seasonal characteristic modeling. We developed a specialized multi-channel Gram angular summation field (MGASF) transformation matrix to holistically capture meteorological fluctuations, subsequently leveraging denoising diffusion probabilistic model (DDPM) for strategic augmentation of under-represented weather scenarios to enhance similar-day identification. Our hybrid architecture combines multi-channel vision Transformer (VIT) with bidirectional long and short-term memory (BILSTM) networks to synergistically analyze temporal dependencies and spatial patterns in PV similarity recognition. Furthermore, we engineered a seasonal-adaptive prediction system through an improved variable-weight Smooth L1 loss function, establishing an optimized seasonal alignment mechanism that achieves high-precision prediction across varying meteorological conditions with minimal computational overhead. Through rigorous validation using operational data from a utility-scale photovoltaic cluster in Western Inner Mongolia, the proposed method achieved consistent accuracy improvements: 3.02 % reduction in N RMSE , 1.65 % decrease in N MAE , and 2.19 % enhancement in R 2 compared to baseline approaches in PV cluster. These statistically significant enhancements demonstrate our framework’s capability to mitigate seasonal impacts while maintaining prediction reliability in complex meteorological environments.},
  archive      = {J_ESWA},
  author       = {Mao Yang and Yue Jiang and Yunfeng Guo and Jianfeng Che and Wei He and Kang Wu},
  doi          = {10.1016/j.eswa.2025.129826},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129826},
  shortjournal = {Expert Syst. Appl.},
  title        = {Photovoltaic cluster power ultra-short-term cross-seasonal prediction integrating multi-channel information probabilistic diffusion generation and improved offset loss strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards large-scale multi-objective feature selection: A two-stage evolutionary algorithm guided by dual feature weightings. <em>ESWA</em>, <em>298</em>, 129823. (<a href='https://doi.org/10.1016/j.eswa.2025.129823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature Selection (FS) is a critical task in high-dimensional data processing, aiming to identify the most discriminative subset of features to improve model performance and reduce computational complexity. In recent years, multi-objective evolutionary algorithms have been widely applied to FS problems due to their ability to simultaneously optimize multiple objectives (i.e., classification accuracy and subset size for an FS problem). However, when dealing with large-scale multi-objective FS problems, existing algorithms often suffer from the vast search space and limited search capability, which makes them prone to local optima. To address these challenges, this paper proposes a two-stage evolutionary algorithm guided by dual feature weightings, named TSEA/DFW. In the first stage, an evolutionary search is performed under the guidance of the filter-based feature weighting strategy. The key features are then identified based on the population distribution and optimal solutions, thereby shrinking the search space. In the second stage, a refined search is conducted in the shrunken feature space to boost search efficiency and solution quality. To this end, a novel weighting strategy named Pareto-based hierarchical feature weighting is proposed, which captures the variation in feature performance across different non-dominated levels, reinforces the contribution of high-quality solutions, and preserves useful information from suboptimal solutions. Additionally, a novel offspring reproduction procedure guided by stage-specific feature weights is designed to further enhance search capability. Experimental results on 13 real-world datasets show that the proposed TSEA/DFW performs best on 10 datasets in terms of HV metric and on 11 datasets in terms of IGD, demonstrating the significant superiority of TSEA/DFW over seven state-of-the-art feature selection methods. The performance improvements stem from the two-stage evolutionary framework guided by dual feature weighting, which enables the early identification of important features, thereby effectively reducing the search space and enhancing search efficiency. In addition, further analysis demonstrates that the proposed TSEA/DFW has strong generality across diverse classifiers, and the developed two-stage evolutionary framework in TSEA/DFW is a general powerful framework that can integrate any mainstream FS algorithm into its second stage, exhibiting robust applicability and scalability.},
  archive      = {J_ESWA},
  author       = {Gaohui Li and Zefeng Chen and Yuren Zhou and Zhengxin Huang and Xiaoyun Xia},
  doi          = {10.1016/j.eswa.2025.129823},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129823},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards large-scale multi-objective feature selection: A two-stage evolutionary algorithm guided by dual feature weightings},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-temporal ensemble for few-shot action recognition. <em>ESWA</em>, <em>298</em>, 129821. (<a href='https://doi.org/10.1016/j.eswa.2025.129821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Action Recognition (FSAR) aims to recognize novel action classes with only a few labeled samples. Due to the scarcity of labeled data, FSAR models suffer from high variance and low confidence. To address this issue, this paper first introduces ensemble learning into the field of FSAR, leveraging the diversity among multiple temporal action representations to generate base models. Specifically, we propose a Multi-Temporal Ensemble (MTE) method for FSAR. By combining sub-sequences of video frames of various lengths (i.e., tuples), MTE creates multiple sets of action representations and generates base models based on these representations. All base models share a single embedding network to learn frame-level features. The proposed method adaptively captures temporal relations with different lengths and speeds while avoiding the computational cost of training multiple deep neural networks. Furthermore, we introduce a Short-term Temporal Modeling Module (STMM) that uses self-attention to highlight frames with high variation, enhancing short-term temporal representation at the frame level. The proposed method has been validated on four benchmark datasets. Extensive experimental results demonstrate that MTE outperforms 26 state-of-the-art FSAR methods. The source code is available at https://github.com/CharmainCahill/MTE.git .},
  archive      = {J_ESWA},
  author       = {Zhen Jiang and Jianlong Sun and Haodong Liu and Haizhen Guan},
  doi          = {10.1016/j.eswa.2025.129821},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129821},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-temporal ensemble for few-shot action recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSIDiff:Multi-stage interaction-aware diffusion model for protein-specific 3D molecule generation. <em>ESWA</em>, <em>298</em>, 129820. (<a href='https://doi.org/10.1016/j.eswa.2025.129820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure-based drug design (SBDD) focuses on developing 3D ligand molecules that bind with high affinity to specific protein targets, which requires the accurate capture of the complex interactions between proteins and ligands. Although existing diffusion models have demonstrated potential in molecular generation tasks, they typically consider only a single stage of the generation process. This limitation prevents them from integrating the multi-stage protein-ligand interaction information from both forward and reverse processes, which may negatively impact the binding affinity of the generated molecules. To address this problem, MSIDiff ( M ulti- S tage I nteraction-Aware Diff usion Model), a multi-stage interaction-aware diffusion model for protein-specific molecule generation, is proposed. MSIDiff leverages the pre-trained model MSINet to extract authentic protein-ligand interaction information during the initial diffusion stage and incorporates this information into the reverse process to ensure that the generated molecules accurately interact with target proteins. Through a scoring mechanism, MSIDiff filters key nodes to extract crucial protein-ligand interaction data and employs a GRU-based cross-layer interaction update module to recursively integrate information across different denoising stages, facilitating effective cross-layer information transmission. Experimental results on the CrossDocked2020 dataset show that MSIDiff can generate molecules with more realistic 3D structures and higher binding affinity to protein targets, achieving an Avg. Vina Score of up to -6.36, while maintaining appropriate molecular properties.Our code and data are available at: https://github.com/zhangyaoxiang/MSIDiff .},
  archive      = {J_ESWA},
  author       = {Yaoxiang Zhang and Junteng Ma and Ze Zhang and Zhaoyang Dong and Shuang Wang},
  doi          = {10.1016/j.eswa.2025.129820},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129820},
  shortjournal = {Expert Syst. Appl.},
  title        = {MSIDiff:Multi-stage interaction-aware diffusion model for protein-specific 3D molecule generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OSATG-GPT: Instruction-tuning large language models with open-source atomic tasks in github. <em>ESWA</em>, <em>298</em>, 129819. (<a href='https://doi.org/10.1016/j.eswa.2025.129819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Across numerous application scenarios in Natural Language Processing (NLP), Large Language Models (LLMs) have demonstrated exceptional capabilities in text comprehension and generation. These models exhibit significant potential across various interdisciplinary fields. However, their effectiveness is somewhat constrained by the unique characteristics of the open-source ecosystem. Developing an LLM with generalization capabilities across datasets and tasks, specifically tailored for the open-source ecosystem, is an urgent research need. To address this challenge, this paper introduces open-source atomic tasks, which are defined as intermediate tasks essential for solving complex objectives. These tasks are designed through strategies such as simplification, reversal, decomposition, and composition, enabling models to gradually acquire domain knowledge and understand task interdependencies. By integrating public resources with open-source atomic tasks, we construct OSE-Instruct–an instruction dataset for the open-source ecosystem. We first unify open-source atomic tasks within an instruction-tuning paradigm that reflects real-world developer behavior, and develop OSATG-GPT at various parameter scales by fine-tuning the BLOOMZ backbone model on OSE-Instruct. This enables the model to learn fine-grained developer actions and the underlying task dependencies. Extensive experiments validate the effectiveness of OSATG-GPT compared to other advanced LLMs with larger parameter scales, and highlight its advantages over GPT-4 in specific and complex open-source collaboration tasks.},
  archive      = {J_ESWA},
  author       = {Fanyu Han and Li Ma and Fenglin Bi and Yantong Wang and Mingdong You and Wei Wang and Jiaheng Peng and Xiaoya Xia},
  doi          = {10.1016/j.eswa.2025.129819},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129819},
  shortjournal = {Expert Syst. Appl.},
  title        = {OSATG-GPT: Instruction-tuning large language models with open-source atomic tasks in github},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploiting knowledge graph communities to fine-tune large language models. <em>ESWA</em>, <em>298</em>, 129816. (<a href='https://doi.org/10.1016/j.eswa.2025.129816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the introduction of GPT-2, Large Language Models (LLMs) have proven to be able to handle various tasks with impressive performance. However, they sometimes generate incorrect output or even hallucinations. To overcome this problem, many researchers have investigated the possibility of integrating external factual knowledge, such as that encoded in Knowledge Graphs (KGs), into LLMs. Although there are many approaches in the existing literature that integrate KGs and LLMs in different ways, few of them use KGs to fine-tune LLMs, and none of them systematically use KG substructures. In this paper, we propose CoFine (Community-Based Fine-Tuner), an approach to fine-tune an LLM using the communities of a KG. CoFine works as follows: it first divides the KG into communities, each of which contains a homogeneous portion of the knowledge expressed by the KG. It then uses these communities to fine-tune the LLM. This way of proceeding allows LLM fine-tuning to focus on specific homogeneous information contained in the KG expressed by each community. CoFine allows the LLM to achieve a very high accuracy in knowledge completion tasks. This is evidenced by comparisons between CoFine and a baseline LLM fine-tuning approach, which showed that our approach achieves better results for all metrics considered with several KG.},
  archive      = {J_ESWA},
  author       = {Alessia Amelio and Christopher Buratti and Michele Marchetti and Davide Traini and Domenico Ursino and Luca Virgili},
  doi          = {10.1016/j.eswa.2025.129816},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129816},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploiting knowledge graph communities to fine-tune large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale fusion graph convolutional networks. <em>ESWA</em>, <em>298</em>, 129815. (<a href='https://doi.org/10.1016/j.eswa.2025.129815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph analysis methods, as important tools for mining complex information, have made remarkable progress driven by graph neural networks (GNNs). However, existing approaches still face challenges in handling complex topological structures and multi-dimensional node features, making it difficult to fully capture deep-level feature and structural information. When analyzing attribute networks, a key challenge is how to effectively integrate node attribute features with graph topological structure information. To address this issue, this paper proposes a multi-scale fusion graph convolutional network (MSF-GCN) method. This method combines shallow and deep convolution strategies while adaptively fusing information across three parallel channels — the original topological structure, a feature-derived graph, and a deep-combination channel that captures shared depth information between them. An autoencoder is employed to reconstruct the adjacency matrix, enhancing the representation capability of the network. Additionally, an attention mechanism is introduced to dynamically assign weights to attribute and structural features at different scales, optimizing node representation. Experimental results demonstrate that, in node classification tasks across multiple benchmark datasets, MSF-GCN achieves outstanding performance, strongly validating the effectiveness and robustness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhi Kong and Jie Ren and Lifu Wang and Ge Guo},
  doi          = {10.1016/j.eswa.2025.129815},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129815},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-scale fusion graph convolutional networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient deep template matching and in-plane pose estimation method via template-aware dynamic convolution. <em>ESWA</em>, <em>298</em>, 129813. (<a href='https://doi.org/10.1016/j.eswa.2025.129813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial inspection and component alignment tasks, template matching requires efficient estimation of a target’s position and geometric state (rotation and scaling) under complex backgrounds to support precise downstream operations. Traditional methods rely on exhaustive enumeration of angles and scales, leading to low efficiency under compound transformations. Meanwhile, most deep learning-based approaches only estimate similarity scores without explicitly modeling geometric pose, making them inadequate for real-world deployment. To overcome these limitations, we propose a lightweight end-to-end framework that reformulates template matching as joint localization and geometric regression, outputting the center coordinates, rotation angle, and independent horizontal and vertical scales. A Template-Aware Dynamic Convolution Module (TDCM) dynamically injects template features at inference to guide generalizable matching. The compact network integrates depthwise separable convolutions and pixel shuffle for efficient matching. To enable geometric-annotation-free training, we introduce a rotation-shear-based augmentation strategy with structure-aware pseudo labels. A lightweight refinement module further improves angle and scale precision via local optimization. Experiments show our 3.07M model achieves high precision and ∼ 14 ms inference under compound transformations. It also demonstrates strong robustness in small-template and multi-object scenarios, making it highly suitable for deployment in real-time industrial applications. The code is available at: https://github.com/ZhouJ6610/PoseMatch-TDCM .},
  archive      = {J_ESWA},
  author       = {Ke Jia and Ji Zhou and Hanxin Li and Zhigan Zhou and Haojie Chu and Xiaojie Li},
  doi          = {10.1016/j.eswa.2025.129813},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129813},
  shortjournal = {Expert Syst. Appl.},
  title        = {An efficient deep template matching and in-plane pose estimation method via template-aware dynamic convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GraphShield: Advanced dynamic graph-based malware detection using graph neural networks. <em>ESWA</em>, <em>298</em>, 129812. (<a href='https://doi.org/10.1016/j.eswa.2025.129812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising complexity of modern malware-such as polymorphic, fileless, and sandbox-aware variants-has severely diminished the reliability of conventional detection techniques. Models based on sequential data frequently miss intricate behavioral patterns and long-range dependencies, resulting in poor accuracy and limited adaptability to new threats. This paper introduces GraphShield, a graph-centric behavioral detection framework that identifies malware with high precision by analyzing dynamic API call sequences. GraphShield converts raw API calls into temporal graphs, applies semantic vectorization, and leverages attention mechanisms to extract both localized activity and extended behavioral correlations, directly addressing the weaknesses of earlier systems. We design and assess multiple Graph Neural Network (GNN) variants, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), Graph Isomorphism Networks (GINs), and Transformer-based architectures combining convolutional, recurrent, and autoencoding layers. These models capture structural and temporal traits of execution traces using both classification-only and combined classification-reconstruction strategies. To enhance transparency, we incorporate GNN interpretation tools that isolate key API call subgraphs and critical decision pathways, making detection outcomes explainable for analysts. GraphShield is trained on 300,000 balanced instances and tested on a separate 200,000-sample holdout set, achieving over 58 % improvement in accuracy over advanced sequence-driven deep learning models while maintaining a false positive rate under 1 %. Key features include BERT-based API call grouping for reducing dimensionality and a Markov-inspired graph stabilization method for managing graphs of variable length. Our top models attain a 99.5 % F1-score on the test set. GraphShield aligns recent graph learning techniques with operational cybersecurity needs, delivering accurate detection and clear, interpretable results.},
  archive      = {J_ESWA},
  author       = {Eslam Amer and Shaker El-Sappagh and Tamer Abuhamad and Bander Ali Saleh Al-Rimy and Alaa Mohasseb},
  doi          = {10.1016/j.eswa.2025.129812},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129812},
  shortjournal = {Expert Syst. Appl.},
  title        = {GraphShield: Advanced dynamic graph-based malware detection using graph neural networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LFRSCNet: Skin defect detection based on lightweight flexible residual separable convolutional network. <em>ESWA</em>, <em>298</em>, 129811. (<a href='https://doi.org/10.1016/j.eswa.2025.129811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft skin is prone to surface damage, such as cracks and dents, during long-term service or manufacturing processes. These defects not only threaten structural integrity but may also pose potential safety hazards. The industrial sector continually explores more efficient and precise detection methods to address this issue. Therefore, this paper proposes a skin defect detection method based on a lightweight and flexible residual separation convolutional network to improve detection accuracy and efficiency. Therefore, this paper proposes a skin defect detection method based on a lightweight flexible residual separable convolution network to improve detection accuracy and efficiency. First, a lightweight flexible residual separable convolution module (LFRCM) is designed, which effectively integrates multi-modal features by combining multi-scale receptive fields with an adaptive channel attention mechanism; at the same time, a lightweight backbone network based on PP-LCNet is constructed, employing a collaborative optimization strategy of depthwise separable convolutions and the h-swish activation function to significantly enhance inference speed while maintaining detection accuracy; finally, the MPDIoU metric criterion is introduced, which effectively improves target localization accuracy by implementing a center point offset penalty mechanism. Experiments on the self-built professional dataset SD-DET and the public dataset GC10-DET show that the model achieves mAP@0.5 of 99.5% and 86.2%, respectively, demonstrating significant advantages over mainstream detection models. Systematic ablation experiments confirm the synergistic effect of various innovative modules. Finally, verification experiments are conducted on the AIRCRAFT skin defect dataset, achieving an mAP@0.5 of 30.7%. Quantitative analysis and comparative experiments verify that LFRSCNet can achieve detection accuracy breakthroughs while maintaining low parameter counts and computational costs. Its balanced accuracy-efficiency characteristics provide an efficient and reliable solution for surface defect detection in industrial scenarios.},
  archive      = {J_ESWA},
  author       = {Zhenyu Lu and Jue Wang and Jiteng Zhu and Yuwen Sun},
  doi          = {10.1016/j.eswa.2025.129811},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129811},
  shortjournal = {Expert Syst. Appl.},
  title        = {LFRSCNet: Skin defect detection based on lightweight flexible residual separable convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The knowledge-driven adaptive late acceptance iterative hill-climbing heuristics for the bus and ADR collaborative delivery problem. <em>ESWA</em>, <em>298</em>, 129810. (<a href='https://doi.org/10.1016/j.eswa.2025.129810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban-rural bus transit services encounter a dilemma between the necessity for enhanced services and the challenge of low profitability due to scant travel demand. Combining freight transportation with passenger services can enhance the efficiency and profitability of buses in both urban and rural areas, while also reducing environmental impacts. A case in point is the integration of freight deliveries into rural bus networks in China. Concurrently, with the advancement of autonomous delivery robot (ADR) technology, there is a growing deployment of ADRs for last-mile delivery purposes. In this paper, we have studied a new collaborative passenger and freight transportation problem involving buses and ADRs, namely, the bus and ADR collaborative delivery problem (BACDP). In this scenario, a bus route transports several ADRs, which carry multiple parcels, to distribution regions for door-to-door delivery, each ADR boards a bus to reach the sub-region and then boards another bus to return to the distribution center. We have proposed a mathematical model for BACDP, which can be decomposed into a master problem and a sub-problem. and the condition that the optimal solution to the master problem is also the optimal solution to the original problem has been proved. To tackle the BACDP effectively, we designed a novel three-stage iterative method, guided by adaptive late acceptance hill-climbing heuristics (ALAHH). Specifically, at the first stage, the k-means++ and Hamiltonian graph-guided algorithms are used to cluster customers; at the second stage, the variable neighborhood search plans the ADRs’ routes; at the third stage, we utilize the solver to address subproblems, and the evaluation and invocation mechanism is proposed to achieve the efficient utilization of solvers. Extensive experiments have been conducted on synthetic instances of varying scales to investigate the efficiency of ALAHH. The experimental results demonstrate that the objective values and the computation time are significantly lower than those of SA and LAHC, and our algorithm has achieved the best solutions for 16 problems to date. Additionally, the impacts of two key parameters and mechanisms have been analyzed, and further validation of the robustness of the algorithm parameters and the effectiveness of the mechanisms.},
  archive      = {J_ESWA},
  author       = {Lijun Pan and Changshi Liu and Yifan Zhang and Shun Li},
  doi          = {10.1016/j.eswa.2025.129810},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129810},
  shortjournal = {Expert Syst. Appl.},
  title        = {The knowledge-driven adaptive late acceptance iterative hill-climbing heuristics for the bus and ADR collaborative delivery problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Simultaneous multi-objective path planning with cumulative hazardous dosage constraint for mobile detection robots in complex environments. <em>ESWA</em>, <em>298</em>, 129808. (<a href='https://doi.org/10.1016/j.eswa.2025.129808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning for a mobile robot operating in complex hazardous environments often requires simultaneous optimization of multiple objectives, such as minimal path length, low energy consumption, and safe passing under cumulative hazard dosage (CHD) constraint. Available methods, involving deterministic algorithms and meta -heuristic algorithms, have drawbacks in solving this problem to meet these simultaneous requirements. A flexible jump point search strategy (FlexJPS) is proposed to address the problem. In the scheme, jump points are divided into two categories, dominant waypoints (DWPs) and linkage jump points (LJPs). Each DWP is flexibly assigned to one limited zone and all the limited zones are distributed in a spaced form in the grid-based environment. The LJPs are generated in a limited short range by the modified jump point search rule. The DWPs followed by LJPs are evaluated by a designed multi-operator differential evolution algorithm to achieve the optimal solution meeting the safe passing constraint. Various experiments are carried out to validate the performance of the proposed scheme with comparisons to feasible famous counterparts. Statistical results and achieved planning success rates from the experiments under stringent CHD constraint indicate superior performance of the proposed method. It is concluded that the proposed method contributes a high-efficacy multi-objective path planning method for a mobile robot operating in complex environments with CHD constraint.},
  archive      = {J_ESWA},
  author       = {Xiankun Lin and Xiaoting Peng and Linsen Liang},
  doi          = {10.1016/j.eswa.2025.129808},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129808},
  shortjournal = {Expert Syst. Appl.},
  title        = {Simultaneous multi-objective path planning with cumulative hazardous dosage constraint for mobile detection robots in complex environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-domain feature-based epileptic seizure prediction method using EEG source estimation and graph theory. <em>ESWA</em>, <em>298</em>, 129807. (<a href='https://doi.org/10.1016/j.eswa.2025.129807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a disorder caused by abnormal discharges of cerebral neurons, affecting 50 million people worldwide. Most existing research on seizure prediction remains at the scalp level. To explore and harness the potential of information flow among cortical regions as well as the intrinsic brain networks and functional mechanisms for seizure prediction, this study proposes a novel multi-domain feature fusion seizure prediction framework based on Electroencephalography (EEG) source estimation and graph theory. Specifically, dSPM source estimation and singular value decomposition (SVD) are first applied to extract 44 subcortical regions defined by the “HCPMMP1_combined” atlas. Brain networks are then constructed using coherence (COH) and phase lag index (PLI), from which specific network topological features based on graph theory are calculated. These features are further extended to higher-order brain networks to enhance connectivity modeling. We also build a multi-domain feature hybrid (MFH) prediction model that adopts a multi-branch structure. One branch employs hypergraph convolution attention along with time–frequency node features derived from continuous wavelet transform (CWT) to capture high-order spatial correlations; another branch inputs the temporal signals from cortical brain regions and combines the hybrid Mamba2-Transformer expert (HMT) model with a frequency-domain dot-product channel attention network (FDCA). By fusing these branches, the model demonstrates satisfactory results across multiple age-groups in the epilepsy EEG dataset of Gansu Province Central Hospital, as well as in the CHB − MIT dataset. This framework highlights the potential of integrating source estimation, hypergraph analysis, and multi-domain feature learning for personalized seizure prediction.},
  archive      = {J_ESWA},
  author       = {Bingyang Ji and Wenwen Chang and Guanghui Yan and Dandan Li and Rong Yin and Xuan Liu and Yaxuan Wei},
  doi          = {10.1016/j.eswa.2025.129807},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129807},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-domain feature-based epileptic seizure prediction method using EEG source estimation and graph theory},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-hop commonsense knowledge injection framework for zero-shot commonsense question answering. <em>ESWA</em>, <em>298</em>, 129806. (<a href='https://doi.org/10.1016/j.eswa.2025.129806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot commonsense question answering (QA) task is to evaluate the general reasoning ability of the language model without training on the specific datasets. The existing zero-shot framework transforms triples within the commonsense knowledge graphs (KGs) into QA-format samples, serving as a pre-training data source to integrate commonsense knowledge into the language model. However, this approach still faces the following challenges: 1) The model trained from synthetic QA generated from triples lacks the multi-hop commonsense knowledge required for handling complex QA problems. 2) Ambiguity caused by confusing commonsense knowledge within synthetic QA, making it challenging for models to discern semantically similar entities. To address the above problem, we propose a novel M ulti-hop C ommonsense K nowledge I njection Framework (MCKI). Specifically, we draw inspiration from human complex reasoning thinking and further propose a synthetic multi-hop commonsense QA generation method. Meanwhile, we introduce negative samples with high confusion in synthetic QA, and then use contrastive learning to improve the model’s ability to distinguish similar commonsense knowledge. Extensive experiments on five commonsense question answering benchmarks demonstrate that our framework achieves state-of-the-art performance, surpassing existing methods, including large language models like GPT3.5 and ChatGPT.},
  archive      = {J_ESWA},
  author       = {Xin Guan and Jiuxin Cao and Biwei Cao and Qingqing Gao and Bo Liu},
  doi          = {10.1016/j.eswa.2025.129806},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129806},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-hop commonsense knowledge injection framework for zero-shot commonsense question answering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CR-GAC: Cross-modal recombination via graph-attention collaborative optimization for multimodal sentiment analysis. <em>ESWA</em>, <em>298</em>, 129805. (<a href='https://doi.org/10.1016/j.eswa.2025.129805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis integrates linguistic, audio, and visual modalities for predicting human emotional states. However, current algorithms encounter three challenges: limitations in adjacency matrix modeling, noise interference and modality imbalances in cross-modal attention, and inefficient cross-modal feature alignment. To address these, we propose the C ross-modal R ecombination via G raph- A ttention C ollaborative Optimization (CR-GAC) by unifying graph and sequence learning in a collaborative framework. Specifically, we first design the modality-adaptive M ultimodal G raph C onstruction (MGC) to tackle the first challenge. For the linguistic modality, a local sparse graph based on a K-Nearest Neighbors-Radial Basis Function kernel is designed to preserve fine-grained semantics; for the audio and visual modalities, a low-rank representation method combined with nuclear norm regularization is designed to capture latent cross-sample structures via singular value decomposition, while suppressing noise interference. Modalities that have been processed are then input into graph attention networks to achieve higher-order feature aggregation. Next, we construct the L anguage-guided H ierarchical C ross-modal I nteraction (LHCI) to tackle the second challenge, which leverages bidirectional cross-modal attention and multi-level Transformer blocks to hierarchically enhance feature representations. Subsequently, the H igh-level M ultimodal F eature C ontainer (HMFC) iteratively accumulates multi-grained semantics, providing a high-level feature pool for fusion. Finally, the dynamic matching-based H igh-level F eature R ecombination (HFR) is designed to tackle the third challenge, which uses the linguistic feature as an anchor to achieve semantically controllable explicit alignment and flexible implicit alignment by matching the most relevant features. Experimental results show our model achieves state-of-the-art performance on CMU-MOSI and CMU-MOSEI datasets, and demonstrates generalization capability on CH-SIMS dataset.},
  archive      = {J_ESWA},
  author       = {Haoran Chen and Jiapeng Liu and Zuhe Li and Yushan Pan and Hongwei Tao and Huaiguang Wu and Yunyang Wang and Chenguang Yang},
  doi          = {10.1016/j.eswa.2025.129805},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129805},
  shortjournal = {Expert Syst. Appl.},
  title        = {CR-GAC: Cross-modal recombination via graph-attention collaborative optimization for multimodal sentiment analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sustainable time-dependent intermodal hub-and-spoke logistic network considering hub failure: A mathematical model and a hybrid artificial bee colony algorithm. <em>ESWA</em>, <em>298</em>, 129804. (<a href='https://doi.org/10.1016/j.eswa.2025.129804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the design of a sustainable hub-and-spoke logistics network that integrates intermodal transportation between the hubs, hub failures, time dependency, and environmental parameters. Accordingly, we propose a novel mixed-integer linear programming (MILP) model and a hybrid artificial bee colony-based algorithm (HABCb) to minimize transportation costs and emissions in robust network configurations. The model is the first to simultaneously integrate intermodality, sustainability metrics, and hub disruption scenarios within a single framework. Computational experiments using real-life data from Turkey demonstrate that the proposed HABCb approach outperforms both genetic algorithm (GA) and artificial bee colony (ABC) algorithm. On medium-sized problem sets, it achieves average cost reductions of 7% compared to GA and 10% compared to ABC algorithm, while on large-sized problems the reductions are 10% and 15%, respectively. Furthermore, the HABCb approach provides faster convergence and higher-quality solutions for larger problem sizes. The findings highlight the practical and theoretical insights of incorporating sustainability, intermodality, and robustness into hub-and-spoke network design.},
  archive      = {J_ESWA},
  author       = {Burcu Tokbay Erkek and Salih Himmetoğlu and Yılmaz Delice and Emel Kızılkaya Aydoğan},
  doi          = {10.1016/j.eswa.2025.129804},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129804},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sustainable time-dependent intermodal hub-and-spoke logistic network considering hub failure: A mathematical model and a hybrid artificial bee colony algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A belief rule-based system for online and centralized collaborative performance assessment of networked physical systems subject to nonideal channels. <em>ESWA</em>, <em>298</em>, 129803. (<a href='https://doi.org/10.1016/j.eswa.2025.129803'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networked physical systems (NPSs) are widely applied in modern engineering practices characterized by intensive domain knowledge and imperfect observational data. Meanwhile, collaborative performance assessment provides strong support for them to operate safely and stably over a long period of time. For a specific NPS and its corresponding online and centralized collaborative performance assessment system, the existence of interference and noise in the real-world channel that is rather nonideal inevitably obstructs the smooth progress of the assessment. To this end, in this paper, a symbolic systematic solution is proposed resorting to an improved version of the belief rule base with continuous inputs (BRB-CI). First, the extrapolation module is enhanced by integrating a matched filtering-based link. Second, the existing robustness analysis for systems based on the fundamental belief rule base is extended to systems based on the BRB-CI. Third, the optimization module is ameliorated by designing a multimetric-balanced pattern of the grey wolf optimizer with interpretability reinforcement. Ultimately, by choosing an instance of NPSs in the field of aerospace with continuous time dynamics, pertinent empirical studies are carried out to substantiate the good engineering practicability of our proposal. Note that this paper is the first piece inquiring into belief rule-based systems such a class of expert systems for online and centralized cooperative performance assessment of NPSs with continuous time dynamics such an application, with considerable attention paid to the nonideality of real-world channels.},
  archive      = {J_ESWA},
  author       = {Haoran Zhang and Lining Xing and Jian Wu and Ruohan Yang and Zhichao Feng},
  doi          = {10.1016/j.eswa.2025.129803},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129803},
  shortjournal = {Expert Syst. Appl.},
  title        = {A belief rule-based system for online and centralized collaborative performance assessment of networked physical systems subject to nonideal channels},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). E2D-GS: Event-enhanced deblurring gaussian splatting. <em>ESWA</em>, <em>298</em>, 129802. (<a href='https://doi.org/10.1016/j.eswa.2025.129802'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, implicit neural representations and explicit 3D Gaussian Splatting(3DGS) have demonstrated substantial advancements in the domain of novel view synthesis. Nevertheless, the efficacy of these approaches is predominantly contingent upon the availability of well-defined, clear imagery and precise camera pose information. Consequently, they exhibit a pronounced susceptibility to motion blur, which impedes the rendering of sharp images. Event cameras, which measure intensity changes with microsecond temporal precision, possess an inherent robustness to motion-induced blur. This characteristic offers new avenues for 3D reconstruction in challenging scenarios characterized by high-speed motion or low-light conditions. This paper introduces E2D-GS, a novel algorithm for deblurring and reconstruction based on event cameras and 3D Gaussian Splatting. To enhance reconstruction accuracy, our proposed framework leverages event streams to physically model the formation process of motion blur. This is achieved by optimizing the discrepancy between synthesized data and the observed blurry images, while simultaneously recovering the camera’s motion trajectory. Additionally, to enhance robustness in real-world scenarios, this paper proposes a differential consistency module. This module effectively mitigates noise within the event data and regularizes the optimization of Gaussian parameters, thereby improving reconstruction quality under non-ideal conditions. Comprehensive experimental evaluations on both simulated and real-world benchmarks validate the proposed method’s capability to reconstruct latent sharp imagery via the learned 3DGS representations, and further demonstrate its capacity for stable reconstruction under adverse scenarios. The results show that our approach surpasses the performance of previous works.},
  archive      = {J_ESWA},
  author       = {Lifeng Lin and Shuangjie Yuan and Lu Yang},
  doi          = {10.1016/j.eswa.2025.129802},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129802},
  shortjournal = {Expert Syst. Appl.},
  title        = {E2D-GS: Event-enhanced deblurring gaussian splatting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated universal information extraction for chinese legal texts. <em>ESWA</em>, <em>298</em>, 129801. (<a href='https://doi.org/10.1016/j.eswa.2025.129801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing knowledge graphs in legal domains requires simultaneous extraction of entities and relations. To reduce repeated modeling in traditional approaches, we adopt the Universal Information Extraction (UIE) model as a foundation and propose an enhanced variant named Adaptive Gated Universal Information Extraction (AGUIE). This study develops a new decoder based on the Adaptive Focusing Gated Attention Unit (AFGAU). This unit enhances the standard Gated Attention Unit (GAU) by integrating two key components—learnable dynamic convolution and reset/update gating mechanisms. Moreover, the study employs a cross-pointer structure as the output layer to better identify information boundaries. To support this study, we construct a domain specific dataset for extracting key information from legal judgment documents. Systematic comparative analysis and ablation studies demonstrate that AGUIE achieves significant performance gains over baseline UIE, with an F1 score of 85.56% on our legal judgment documents dataset. Additionally, we evaluate the model’s generalization on public datasets such as ACE04, ACE05, and CoNLL04, covering both entity recognition and relation extraction tasks. Experimental results indicate that AGUIE demonstrates competitive results with recent studies on ACE04-Ent and CoNLL04, outperforms them on the ACE05 dataset, achieving F1 scores of 87.19% on ACE05-Ent and 79.29% on ACE05-Rel. In conclusion, AGUIE is a reliable and effective solution for universal information extraction in both legal and general domains.},
  archive      = {J_ESWA},
  author       = {Yabo Liu and Yatong Zhou and Kuo-Ping Lin},
  doi          = {10.1016/j.eswa.2025.129801},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129801},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated universal information extraction for chinese legal texts},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid graph and LLM approach for measuring scientific novelty via knowledge recombination and propagation. <em>ESWA</em>, <em>298</em>, 129794. (<a href='https://doi.org/10.1016/j.eswa.2025.129794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific novelty constitutes a fundamental catalyst for both disciplinary innovation and interdisciplinary progress. Nevertheless, prevailing approaches to novelty assessment predominantly emphasize a single analytical dimension–either the semantic content of the focal paper or its cited references. Content-based methodologies frequently fail to incorporate the foundational knowledge cited by the target publication, whereas reference-based strategies tend to disregard the intrinsic conceptual contributions of the focal work itself. To address this limitation, the present study introduces a hybrid graph and large language model approach to jointly capture and integrate knowledge embedded in both the focal paper and its cited literature. The proposed method, which integrates knowledge recombination and propagation, is structured into four primary stages. First, prompt-based extraction techniques using general LLMs are applied to extract knowledge. Second, a Reference Knowledge Combination Network (RKCN) is constructed to model the knowledge referenced by the focal paper. Third, the RKCN is initialized with representations generated by SciDeBERTa(CS), and a graph attention network is employed to propagate knowledge across the network. Finally, the novelty of the focal paper is quantified by aggregating the novelty scores of all internal knowledge combinations based on the propagated representations. Experimental evaluation in the domain of artificial intelligence (AI) demonstrates that the proposed method significantly outperforms existing baseline approaches in quantifying scientific novelty. Additional ablation studies further validate the contribution of the knowledge propagation module. A case study illustrates the interpretability of our approach, and a cross-field validation in Biomedical Engineering (BME) domain highlights its robustness and cross-domain generalizability. A multi-dimensional comparative analysis between award-winning and non-award papers further reveals that the former generally incorporate a larger volume of knowledge and exhibit greater diversity in knowledge combinations. Moreover, while both groups encompass knowledge combinations spanning a wide range of novelty, award-winning papers display a stronger concentration at higher novelty levels, in contrast to the more uniform distribution observed in non-award papers. Data, code, and more detailed results are publicly available at: https://github.com/haihua0913/graphLLM4ScientificNovelty .},
  archive      = {J_ESWA},
  author       = {Zhongyi Wang and Zeren Wang and Guangzhao Zhang and Jiangping Chen and Markus Luczak-Roesch and Haihua Chen},
  doi          = {10.1016/j.eswa.2025.129794},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129794},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid graph and LLM approach for measuring scientific novelty via knowledge recombination and propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph-based approaches for rumor detection in social networks: A systematic review. <em>ESWA</em>, <em>298</em>, 129786. (<a href='https://doi.org/10.1016/j.eswa.2025.129786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased public anxiety and fear, disrupted decision-making, social instability, and other significant societal challenges are the results of the rapid spread of rumors on social media platforms. The unique characteristics of these platforms contribute to the rapid spread of both verified and unverified information. These pressing issues highlight the need to develop advanced technologies for early detection and prevention of rumors. This paper presents a systematic review of graph-based approaches for rumor detection in social networks, analyzing 53 studies published between 2018 and 2025. The selected studies are comprehensively reviewed with a focus on graph models and the integration of propagation structure, social, temporal, and content features, which enhances detection accuracy. This review critically evaluates the effectiveness of various methods, highlighting their strengths, limitations, and key challenges. The key contributions of this paper include: (i) an in-depth analysis of current graph-based rumor detection approaches (ii) a categorization of graph models and feature extraction strategies, (iii) the identification of major challenges and research gaps, and (iv) recommendations for future research to develop scalable, robust, and accurate early rumor detection systems. The findings of this study provide valuable insights for researchers aiming to advance the state-of-the-art in fighting misinformation on social networks.},
  archive      = {J_ESWA},
  author       = {Fatima Al-Thulaia and Seyyed Alireza Hashemi Golpayegani},
  doi          = {10.1016/j.eswa.2025.129786},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129786},
  shortjournal = {Expert Syst. Appl.},
  title        = {Graph-based approaches for rumor detection in social networks: A systematic review},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatiotemporal online fuzzy modeling with knowledge-driven differential evolution automatic clustering for distributed parameter systems. <em>ESWA</em>, <em>298</em>, 129785. (<a href='https://doi.org/10.1016/j.eswa.2025.129785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed parameter systems are prevalent in various industrial processes and attract significant attention. However, these systems exhibit complex spatiotemporal coupling characteristics, and effectively determining the fuzzy rules of the antecedent set is crucial for improving modeling performance. Traditional clustering methods typically rely on empirical heuristics and are unable to adapt to dynamic system characteristics under changing environments. In high-dimensional and nonlinear scenarios, the number of fuzzy rule combinations grows exponentially, significantly increasing computational complexity. Therefore, an online spatiotemporal three-dimensional fuzzy modeling method based on knowledge-driven differential evolution automatic clustering and extreme learning machine (3D-OSADE-ELM) is proposed for the complex nonlinear distributed parameter system. First, an automatic clustering mechanism based on differential evolution and extreme learning machine initializes the fuzzy rules within the three-dimensional fuzzy system. Subsequently, a knowledge-driven archiving mechanism dynamically updates the fuzzy rules of the antecedent set during the online incremental learning phase. Finally, the spatial basis function is obtained by learning the output weight of the online extreme learning machine. The validation experiments conducted on the rapid thermal chemical vapor deposition reactor system and the nonisothermal packed-bed system demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_ESWA},
  author       = {Gang Zhou and Xianxia Zhang and Bing Wang},
  doi          = {10.1016/j.eswa.2025.129785},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129785},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatiotemporal online fuzzy modeling with knowledge-driven differential evolution automatic clustering for distributed parameter systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CG-TRAN: A novel multi-label retinal disease classification model with partially known pathologies. <em>ESWA</em>, <em>298</em>, 129784. (<a href='https://doi.org/10.1016/j.eswa.2025.129784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of retinal diseases is vital to preventing partial or permanent blindness. However, the diagnostic process is often impeded by the complexity of interrelated lesions and the challenge of incomplete or missing pathology labels, which require specialized expertise in ophthalmic diagnosis. To address these limitations, we propose CG-Tran, a novel multi-label classification model that leverages partially known pathology information to diagnose retinal diseases. This approach integrates a pathology graph neural network with graph-based feature extraction to handle partially known pathologies, enabling more accurate multi-label classification of retinal diseases. To model the intricate interrelationships among ocular diseases, CG-Tran employs BERT-GNN to learn label interactions and construct a comprehensive fundus pathology graph. Additionally, an enhanced attention mechanism incorporates known pathology label features, bridging the gap between incomplete pathology information and fundus image data. These innovations collectively empower the model to overcome the challenges of missing or incomplete pathology labels. The model’s performance is rigorously evaluated on the Multilabel Retinal Disease (MuReD) dataset. Results demonstrate that CG-Tran significantly improves diagnostic accuracy, especially as more pathology labels become available. Under conditions with 0% and 75% partially known labels, CG-Tran achieves mean average precision (mAP) scores of 69.9% and 72.1%, respectively—outperforming the baseline model by 1.0% and 1.9%. This innovative architecture excels in multi-label classification tasks, particularly in recognizing and distinguishing complex and interrelated retinal lesions with partially known pathology. It offers a promising solution for early detection and accurate diagnosis of retinal diseases, addressing critical limitations in existing diagnostic methods.},
  archive      = {J_ESWA},
  author       = {Jia Sheng Yang and Zihao Ning and Xu Xiao and Rui Zhong and Chenbo Xia and Ya Ding},
  doi          = {10.1016/j.eswa.2025.129784},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129784},
  shortjournal = {Expert Syst. Appl.},
  title        = {CG-TRAN: A novel multi-label retinal disease classification model with partially known pathologies},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-balanced MSE for machinery imbalanced degradation trend prediction. <em>ESWA</em>, <em>298</em>, 129783. (<a href='https://doi.org/10.1016/j.eswa.2025.129783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate degradation trend prediction (DTP) is crucial for optimizing equipment operation and maintenance. With the rapid development of artificial intelligence, many data-driven methods have been applied to machinery degradation trend prediction. In practice, most machineries are in the early stages of degradation, with only a few reaching the final stages, leading to a temporal imbalanced data distribution. Current research on imbalanced distributions mainly focuses on classification tasks. However, DTP involves multiple time-dependent continuous targets, making classification-based methods unsuitable. To address this issue, the degradation trend prediction task is reformulated as a multi-task problem and a novel time-balanced Mean Square Error (TBMSE) loss function is proposed. In each prediction task, the Gaussian Mixture Model (GMM) is used to fit the training label distribution. Additionally, the cumulative information noise for each prediction task is modeled using GMM, and an end-to-end network structure is designed to learn the GMM parameters. Experiments are conducted on the IMS bearing dataset and the turboprop engine dataset, demonstrating that the TBMSE loss effectively mitigates the issue of temporal imbalanced distribution in degradation trend prediction.},
  archive      = {J_ESWA},
  author       = {Yu-Qiang Wang and Yong-Ping Zhao and Tian-Ding Zhang and Yu-Wei Wang},
  doi          = {10.1016/j.eswa.2025.129783},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129783},
  shortjournal = {Expert Syst. Appl.},
  title        = {Time-balanced MSE for machinery imbalanced degradation trend prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Differentiable histogram-guided unsupervised retinex enhancement for paired low-light images. <em>ESWA</em>, <em>298</em>, 129782. (<a href='https://doi.org/10.1016/j.eswa.2025.129782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing low-light image enhancement (LIE) methods rely on expensive paired low-light and normal-light datasets, while unsupervised approaches depend on handcrafted priors to design networks or select similar normal-light images as pseudo-references, limiting their generalization and robustness. To address these challenges, we propose a novel differentiable histogram-guided unsupervised Retinex enhancement (DHURE) method, which leverages the distribution of illumination histograms in real-world scenarios to achieve high-fidelity color preservation and refined brightness distribution across diverse extremely low-light images. DHURE avoids reliance on scene-specific features and effectively captures both fine-grained details and overall brightness information. Specifically, our method consists of two key components: 1) The lightweight architecture of DHURE is composed of Retinex decomposition and illumination enhancement. We perform Retinex decomposition on paired low-light images (PRD) and design the Illumination Histogram-guided Enhancement (IHE) module. Both modules employ lightweight architectures. 2) To fully exploit the adaptive priors inherent in paired low-light images, we introduce a self-supervised reflectance map loss that aligns with the Retinex basis loss. Based on the illumination distribution of real-world normal-light images, we define two unsupervised illumination histogram losses, enabling more generalized and robust enhancement. Extensive and diverse experiments demonstrate that our method achieves competitive performance compared to existing unsupervised LIE approaches, showing superior results on most evaluation metrics. The source code is available at https://github.com/yoonyin/DHURE-main .},
  archive      = {J_ESWA},
  author       = {Liyuan Yin and Pingping Liu and Tongshun Zhang and Hongwei Zhao and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129782},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129782},
  shortjournal = {Expert Syst. Appl.},
  title        = {Differentiable histogram-guided unsupervised retinex enhancement for paired low-light images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SUNRISE: Multi-agent reinforcement learning via neighbors’ observations under fully noisy environments. <em>ESWA</em>, <em>298</em>, 129781. (<a href='https://doi.org/10.1016/j.eswa.2025.129781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) methodologies have achieved notable advancements across diverse domains. Despite these successes, the susceptibility of neural networks to perturbed data and the ubiquity of external attacks in real-world settings, such as sensor noise, pose challenges for MARL approaches. The pivotal issue revolves around the effective transfer of policies learned in idealized simulation environments to the complexities inherent in real-world scenarios. More precisely, when agents are unable to obtain any accurate observations of the external environment throughout the entire policy learning process, the MARL methods cannot learn effective policies. In addressing this issue, we propose a methodology wherein noisy observations from neighboring agents are utilized, with an agent’s own noisy observations serving as surrogate ground truth. This approach facilitates the learning of effective policies by MARL methods in environments characterized by pervasive noise. We design a denoising representation network to filter out the principal state information from environment data characterized by noise to mitigate the adverse effects of noise on the process of policy learning. Then, we integrate the denoising representation network with classic MARL methodologies to learn effective policies within environments characterized by pervasive noise. A series of exhaustive experimental results demonstrate the efficacy of our approach in attenuating the impact of external attacks on the optimization parameters of neural networks during the policy-learning process. Moreover, our methodology exhibits compatibility with classic MARL methods, allowing for the learning of effective policies.},
  archive      = {J_ESWA},
  author       = {Kaiyu Wang and Bohao Qu and Menglin Zhang and Xianchang Wang and Ximing Li},
  doi          = {10.1016/j.eswa.2025.129781},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129781},
  shortjournal = {Expert Syst. Appl.},
  title        = {SUNRISE: Multi-agent reinforcement learning via neighbors’ observations under fully noisy environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RSUTrajRec: Multi-granularity trajectory recovery based on roadside units sensing. <em>ESWA</em>, <em>298</em>, 129780. (<a href='https://doi.org/10.1016/j.eswa.2025.129780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle mobility trajectories, especially fine-grained trajectories, provide valuable insights for understanding urban dynamics and play a crucial role in intelligent transportation systems and urban planning. Obtaining fine-grained vehicle trajectories can be realized by trajectory recovery, but traditional efforts suffer from defects such as poor privacy protection and low recovery accuracy. To address these issues, we propose a new scenario of trajectory recovery based on roadside unit (RSU) sensing. However, this scenario introduces a significant challenge: recovering high-precision trajectories from the incomplete and unevenly distributed sensing data. To tackle this, we design RSUTrajRec , a multi-granularity trajectory recovery framework that comprises a graph neural network-based module for road information prediction, a Transformer-based module for multi-granularity recovery, and an RSU deployment planning module. Extensive real-world dataset evaluations reveal that RSUTrajRec has a significant advantage in recovering missing vehicle trajectories outside the RSU coverage area. In addition, evaluations also verify that the performance of the trajectory recovery task can be effectively improved by optimizing the RSU deployment plan.},
  archive      = {J_ESWA},
  author       = {Xianjing Wu and Xutao Chu and Jianyu Wang and Shengjie Zhao},
  doi          = {10.1016/j.eswa.2025.129780},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129780},
  shortjournal = {Expert Syst. Appl.},
  title        = {RSUTrajRec: Multi-granularity trajectory recovery based on roadside units sensing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system. <em>ESWA</em>, <em>298</em>, 129779. (<a href='https://doi.org/10.1016/j.eswa.2025.129779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology foresight analyses technological trends and potential impacts to provide strategic guidance. However, existing methods either rely on experts to discover emerging directions leading to subjective bias or adopt machine learning to predict without explanation. We propose a Machine Learning and Weak Signal-based Technology Forecasting System (MLWS-TF), which is entirely data-driven to enhance the objectivity of technology foresight and can interpret emerging directions through weak signals. The system adopts a two-phase machine learning model (2P-ML), the first phase identifies papers related to the robotics field, while the second further classifies them into fine-grained research directions. Keywords are extracted from the papers using a Word2Vec-based approach, and a three-dimensional signal classification method (DVI) is developed to quantify the foresight value of keywords across the Diffusion, Visibility, and Impact dimensions, identifying weak signals for technology forecasting. Experiments evaluate various machine learning algorithms, and XGBoost outperforms in constructing the 2P-ML classifier. The model achieved over 90% accuracy, demonstrating its effectiveness in identifying the theme of scientific documents based on textual features. For each research theme, the DVI provides a more comprehensive assessment of signal strength to detect weak signals. Finally, MLWS-TF analyses the growth potential of themes and successfully identifies critical development directions. Our approach offers a novel automated technology foresight system, which completely avoids the subjectivity and dependence on expert judgment that characterize traditional technology foresight approaches, and extends weak signal theory by introducing the Impact dimension to evaluate signal strength.},
  archive      = {J_ESWA},
  author       = {Ruihan Wang and Yuhao Zhu},
  doi          = {10.1016/j.eswa.2025.129779},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129779},
  shortjournal = {Expert Syst. Appl.},
  title        = {Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generating realistic pruning solutions for automated grape vine pruning using graph neural networks. <em>ESWA</em>, <em>298</em>, 129778. (<a href='https://doi.org/10.1016/j.eswa.2025.129778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our prior work we showed that graph neural networks (GNNs) can be trained to generate pruning solutions that could direct robotic pruning robots to perform automated cane pruning of wine grape vines. That study introduced the feasibility of the technology but also showed that there were many open questions and issues with the research results that needed to be addressed. In this study we address some of these questions. For example, we answer the question of how would a model like this perform on real vine architectures compared with pruning solutions from real experienced pruners. Our most notable contributions include moving away from a per-cane classification model that attempts to define a single perfect pruning solution, to a model that ranks multiple good solutions and picks the best one. We addressed a key limitation of the previous training data by moving away from synthetic vine architectures to realistic ones recorded from real vines and using pruning solutions collected by expert pruners as our ground-truth. Our primary goal was to show that learning by example using a GNN-based model was a viable approach to automated pruning, even when compared with experienced pruners. We showed robust performance from our model by training on a dataset of 90 pruning solutions generated by expert pruners in the 2022 season, and testing our performance on 117 pruning solutions from an independent set of pruners from the 2021 season. The model was able to correctly score all the pruning solutions from the 2021 dataset as good to very good and none of the expert solutions were classified as poor .},
  archive      = {J_ESWA},
  author       = {Jaco Fourie and Jeffrey Hsiao and Oliver Batchelor and Kevin Langbroek and Henry Williams and Richard Green and Armin Werner},
  doi          = {10.1016/j.eswa.2025.129778},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129778},
  shortjournal = {Expert Syst. Appl.},
  title        = {Generating realistic pruning solutions for automated grape vine pruning using graph neural networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disruption-responsive berth allocation and quay crane scheduling with inter-terminal collaboration. <em>ESWA</em>, <em>298</em>, 129776. (<a href='https://doi.org/10.1016/j.eswa.2025.129776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Container terminal operations frequently encounter disruptions, including delays, extended handling times, and unscheduled vessel arrivals, all of which necessitate intelligent rescheduling strategies to maintain operational efficiency. This study investigates the integrated problem of disruption-responsive berth allocation and quay crane (QC) scheduling, explicitly considering vessel gathering status and incorporating inter-terminal shifting (ITS) and reassignment to terminals different from its originally designated one (RT) as adaptive response strategies to mitigate these disruptions. A rescheduling model is developed to minimize associated costs. To efficiently solve large-scale problems, an adaptive large neighborhood search (ALNS)-based heuristic is proposed. The effectiveness of the proposed scheme is validated through comparative experiments involving three alternative schemes, highlighting its superior performance. Furthermore, algorithm comparison experiments are conducted to verify the robustness of parameter settings. Computational results demonstrate that the proposed model and algorithm achieve high efficiency and solution quality. Additionally, sensitivity analysis reveals that neglecting vessel gathering status leads to substantial cost increases, particularly in large-scale operations. The integration of ITS and RT proves to be an effective strategy for mitigating disruptions, enhancing scheduling flexibility, and improving operational performance.},
  archive      = {J_ESWA},
  author       = {Hongxing Zheng and Zhaoyang Wang and Lingxiao Wu},
  doi          = {10.1016/j.eswa.2025.129776},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129776},
  shortjournal = {Expert Syst. Appl.},
  title        = {Disruption-responsive berth allocation and quay crane scheduling with inter-terminal collaboration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mining spatiotemporal dominant co-location patterns. <em>ESWA</em>, <em>298</em>, 129775. (<a href='https://doi.org/10.1016/j.eswa.2025.129775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial co-location pattern mining is an important branch of spatial data mining, which can identify spatial features that prevalently occur in proximity. Based on spatial co-location patterns, the research of dominant relationships mining within co-location patterns further considers the influence relationship among features. However, relying solely on spatial data to analyze the positions and distribution of features for mining dominant relationships is insufficient and may lead to incorrect patterns. To address this limitation, this paper introduces the temporal factor into the research of dominant relationships mining and proposes the spatiotemporal dominant co-location pattern mining (STDCPM). At first, we define the concepts of spatiotemporal dominant relationship from both temporal and spatial dimensions, and then propose the spatiotemporal dominant participation index to assess the prevalence of spatiotemporal dominant co-location patterns. Furthermore, we design two algorithms, the spatiotemporal dominant co-location pattern mining algorithm with level-by-level search and its improved version, i.e., the spatiotemporal dominant co-location pattern mining approach based on dual pruning and refining set (STDCPM-DPR), to ensure efficient mining in spatiotemporal datasets. The time complexity, correctness, and completeness of proposed algorithms are discussed. Extensive experiments on real-world datasets demonstrate the effectiveness of STDCPM and the efficiency of STDCPM-DPR algorithm.},
  archive      = {J_ESWA},
  author       = {Jiangchuan Mei and Peizhong Yang and Hongmei Chen and Lizhen Wang},
  doi          = {10.1016/j.eswa.2025.129775},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129775},
  shortjournal = {Expert Syst. Appl.},
  title        = {Mining spatiotemporal dominant co-location patterns},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-scale content adaptive network for three-dimensional multi-object tracking and fish activity quantification. <em>ESWA</em>, <em>298</em>, 129774. (<a href='https://doi.org/10.1016/j.eswa.2025.129774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking and quantifying fish activity are vital for evaluating their health status and adaptability to the environment. However, most current research on fish tracking and activity quantification suffers from the limitation of being two-dimensional, losing crucial vertical or horizontal information. To facilitate tracking and quantitative analysis of fish activity in three-dimensional (3D) space, a cross-scale content-adaptive network-based 3D multi-object tracking method for fish is proposed, through which fish movements are quantified accordingly. Firstly, a cross-scale content-adaptive fusion network is proposed to accurately determine the fish positions from top-down and side views, thereby mitigating the issue of scale variation across different perspectives. Secondly, a hierarchical tracking method is implemented to obtain the 3D trajectories of the fish, addressing the challenge of cross-view identity matching. Finally, activity parameters in 3D space, including the activity quantity and trajectory length for individual fish, as well as the dispersion and cohesion for the fish group, are calculated. The proposed method was validated, achieving a Multi-Object Tracking Accuracy (MOTA) of 97.68% and an Identification F1 Score (IDF1) of 97.93%. For activity quantification, the Mean Absolute Error (MAE) was found to be 0.088 (unit weight·(cm/s) 2 ), and the Root Mean Square Error (RMSE) was 0.1064 (unit weight·(cm/s) 2 ). These results affirm the method’s adaption of fish features across scales for 3D tracking and activity analysis. With its efficient performance, our method presents as an instrument for activities such as fish behavior monitoring, selective breeding, and environmental assessment.},
  archive      = {J_ESWA},
  author       = {Yiran Liu and Dingshuo Liu and Mingrui Kong and Beibei Li and Qingling Duan},
  doi          = {10.1016/j.eswa.2025.129774},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129774},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-scale content adaptive network for three-dimensional multi-object tracking and fish activity quantification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive multimodal semantic knowledge enhanced framework for sarcasm detection. <em>ESWA</em>, <em>298</em>, 129773. (<a href='https://doi.org/10.1016/j.eswa.2025.129773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sarcasm detection (MSD) has become an important research topic for understanding sentiments on social media, while various recent MSD approaches extract high-level semantic knowledge from images to improve performance. However, some key semantic information, such as emotions expressed in images, is still neglected, limiting reliable sentiment understanding. To address this issue, we propose an adaptive multimodal semantic knowledge enhanced framework for sarcasm detection. We first design an adaptive processing pipeline to extract emotion-aware visual semantics as an auxiliary modality to enhance multimodal feature representations. Enabled by two attention mechanisms, bidirectional cross-modal attention and graph attention, interactions between modalities are analysed to improve MSD performance. Extensive experiments are conducted on two public multimodal sarcasm detection datasets, MMSD and MMSD 2.0, comprising approximately 19,000 tweet samples. Our proposed approach achieves consistent improvements in both sarcasm detection accuracy and F1-score compared to strong baseline models such as DIP and KnowleNet. Built upon a ViT-based architecture, the fine-tuned model offers competitive performance with lower computational overhead, highlighting its potential for practical deployment.},
  archive      = {J_ESWA},
  author       = {Jing Dong and Yu Sui and Qiang Zhang and Hui Fang and Gerald Schaefer and Rui Liu and Pengfei Yi and Xiaoyong Fang},
  doi          = {10.1016/j.eswa.2025.129773},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129773},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive multimodal semantic knowledge enhanced framework for sarcasm detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FoRKER: Focused reasoner with knowledge editing and self-reflection. <em>ESWA</em>, <em>298</em>, 129771. (<a href='https://doi.org/10.1016/j.eswa.2025.129771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop question answering (MHQA) is a complex question answering (QA) benchmark that requires agents to integrate information from diverse sources and utilize cross-referencing reasoning to answer intricate questions. Existing MHQA-handling frameworks typically employ a retrieve-read paradigm. However, these efforts rooted in the retrieve-read paradigm are still constrained by: 1) unstable document retrieval performance , 2) weak knowledge refinement capabilities , and 3) the absence of a reflection mechanism for error awareness . To address these limitations, we propose FoRKER ( Fo cused R easoner with K nowledge E diting and Self- R eflection), which is a plug-and-play framework. Specifically, we develop a novel progressive focusing mechanism to pinpoint highly relevant document resources and introduce knowledge editing techniques to further eliminate noise interference within textual information. Additionally, we design a novel prompting method, named Chain-of-Evidence (CoE), which is designed to augment the reasoning capabilities of FoRKER . Notably, the integration of Self-Reflection technology further endows FoRKER with the ability to learn and improve from its mistakes. Extensive experiments on widely-used datasets demonstrate that FoRKER achieves new state-of-the-art results in information retrieval and reading comprehension, while also exhibiting effective generalization. Exhilaratingly, on the MusiqueQA dataset, FoRKER demonstrates a 20 % improvement in Answering scores compared to the advanced competitors.},
  archive      = {J_ESWA},
  author       = {Chunbai Zhang and Haoyang Li and Chao Wang and Yang Zhou and Yan Peng},
  doi          = {10.1016/j.eswa.2025.129771},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129771},
  shortjournal = {Expert Syst. Appl.},
  title        = {FoRKER: Focused reasoner with knowledge editing and self-reflection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel fuzzy clustering approach with transition matrix for explainable evaluation of social media-based digital literacy interventions. <em>ESWA</em>, <em>298</em>, 129769. (<a href='https://doi.org/10.1016/j.eswa.2025.129769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the effectiveness of digital literacy interventions often relies on raw score comparisons or hard classifications, which may obscure nuanced changes in conceptual understanding and provide limited interpretability. Traditional approaches fail to capture the probabilistic and fuzzy nature of learning progression and do not support transparent analysis of how learners transition across conceptual clusters over time. This study proposes an explainable evaluation framework that integrates fuzzy clustering with a fuzzy transition matrix to model the redistribution of aggregated membership values between pretest and posttest conceptual clusters. The framework applies Fuzzy C-Means (FCM) to derive soft cluster memberships and constructs a transition matrix that represents probabilistic learning progression in a linguistically interpretable form. Unlike conventional methods, this approach enables the analysis of gradual transitions across levels of proficiency rather than binary outcomes. The model was applied to real-world educational data from control and experimental classes, the latter of which received a social media-based instructional intervention. Results indicate that the control class exhibited downward or stagnant patterns, particularly among high-performing learners, while the experimental class showed more coherent upward cluster transitions among low- and moderate-level learners. By enabling interpretable modeling of pre–post cluster transition patterns, the proposed framework contributes to the advancement of explainable machine learning in education. It also highlights the potential of social computing platforms to foster scalable, data-driven digital literacy development.},
  archive      = {J_ESWA},
  author       = {Rustam and Diana Noor Anggraini and Koredianto Usman and Loveleen Gaur},
  doi          = {10.1016/j.eswa.2025.129769},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129769},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel fuzzy clustering approach with transition matrix for explainable evaluation of social media-based digital literacy interventions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting. <em>ESWA</em>, <em>298</em>, 129768. (<a href='https://doi.org/10.1016/j.eswa.2025.129768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively modeling the relations between variables in multivariate time series is of utmost importance for accomplishing accurate predictions. In real-world scenarios, in addition to sequential correlations, the evolution of relations between variables also exhibits nonadjacent correlations at different scales. However, existing methods primarily focus on constructing dynamic graph structures at each time step using temporal features extracted by continuous temporal models, which cannot capture above latent dependencies. In this study, we introduce the Dynamic Graph Structure Correction (DGC) model, leveraging a multi-scale framework with dilated convolution. To take full advantage of nonadjacent correlations in the evolution of relations between variables, we adaptively select history-related graph structures to correct initial graph structure constructed by Gate Recurrent Units. In addition, we design a time-decay-based attention mechanism to address the influence of time intervals between history-related and current time steps. Finally, the evolved graph structures are fed into graph neural networks to handle the multi-scale and complex structural relations. Our proposed model achieves superior performance compared to state-of-the-art methods in multivariate time series forecasting, as evidenced by the evaluation results on four widely used benchmark datasets.},
  archive      = {J_ESWA},
  author       = {Dandan He and Yueyang Wang and Chaoli Lou and Gang Tan and Qingyu Xiong and Guodong Sa},
  doi          = {10.1016/j.eswa.2025.129768},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129768},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimized homomorphic linear computation in privacy-preserving CNN inference. <em>ESWA</em>, <em>298</em>, 129767. (<a href='https://doi.org/10.1016/j.eswa.2025.129767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning as a Service (MLaaS) provides robust solutions for deploying deep learning inference in cloud environments. However, it also raises serious privacy concerns regarding user data and proprietary model parameters. Numerous hybrid cryptographic protocols that integrate homomorphic encryption (HE) and garbled circuits (GC) have been proposed to enable secure inference with low latency. In these protocols, the homomorphic evaluation of linear operations remains the primary performance bottleneck and warrants further optimization. In this work, we propose novel optimizations for HE-based linear computations within the hybrid cryptographic framework for secure neural network inference. Specifically, we devise two efficient strategies for homomorphic matrix-vector multiplication and convolution. For matrix-vector multiplication, we introduce a grouped diagonal extraction technique that encodes the weight matrix more compactly and enables configurable ciphertext rotation reuse, while for homomorphic convolution, we present a group-wise combine-and-merge evaluation method. Both methods significantly reduce the number of required ciphertext rotations. Our approach achieves up to a 3.9 × speedup in matrix-vector multiplication and a 2.9 × improvement in convolution over state-of-the-art (SOTA) solutions. The HE-GC hybrid secure convolutional neural networks (CNN) inference framework incorporating these enhancements yields speedups of 2.5 × on widely used ResNets deep learning architectures.},
  archive      = {J_ESWA},
  author       = {Chenglong Li and Xirong Ma and Xiuhao Wang and Fanyu Kong and Yunting Tao and Chunpeng Ge},
  doi          = {10.1016/j.eswa.2025.129767},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129767},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimized homomorphic linear computation in privacy-preserving CNN inference},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. <em>ESWA</em>, <em>298</em>, 129766. (<a href='https://doi.org/10.1016/j.eswa.2025.129766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding in encrypted images (RDHEI) is a promising technique for multimedia cloud computing that enables the embedding of secret data into encrypted images while preserving confidentiality. However, the existing RDHEI algorithms fail to meet the high-security requirements of distributed storage systems in the cloud. Although, secret sharing based RDHEI (SS-RDHEI) may solve this problem, the current methods have weakness such as insufficient embedding capacity and unsatisfactory balance between image security and redundancy. To enhance the algorithm’s ability to carry information, this paper proposes a SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. Firstly, pixel-difference preservation based modulation (PDPM) ensures secure encryption by modifying all pixels except for a reference block, minimizing damage; moreover, an improved block-level pixel predictor enhances carrier redundancy. Secondly, auxiliary data free coding (ADFC) marks prediction errors directly in the binary sequence of the original pixel without auxiliary information while maintaining accuracy, and reduces the impact of different textures on embedding performance byselecting optimal parameters for each share image. Finally, by combining PDPM with secret sharing, it achieves independent embedding for multiple data hiders while ensuring fair information embedding. Experimental results demonstrate that the proposed algorithm outperforms existing state-of-the-art schemes in terms of information-carrying capability.},
  archive      = {J_ESWA},
  author       = {Zhihua Gan and Zongwei Tang and Yalin Song and Gongyao Cao and Xiuli Chai and Yushu Zhang},
  doi          = {10.1016/j.eswa.2025.129766},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129766},
  shortjournal = {Expert Syst. Appl.},
  title        = {SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved convolutional neural networks for the bullwhip effect in supply chains. <em>ESWA</em>, <em>298</em>, 129764. (<a href='https://doi.org/10.1016/j.eswa.2025.129764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bullwhip Effect (BWE) introduces significant challenges to production systems by amplifying demand and order oscillations. One of the most effective methods for predicting and modeling complex systems is Convolutional Neural Networks (CNNs). However, certain phenomena, such as the BWE in supply chains (SC), are difficult to predict and identify directly. The primary challenge for Machine Learning (ML) algorithms in this context lies in the training phase: the raw demand and order data are fed into the network, yet the desired training outcome is the oscillatory behavior of these data from the perspective of the BWE. Consequently, conventional max pooling, average pooling operators, kernels, and weighted linear combinations of data are insufficient for capturing this type of learning. To address this issue, in this paper, a novel structure containing new pooling operators and kernels of CNNs is proposed to tailor the unique characteristics of the BWE. Specifically: a ) Considering the temporal propagation nature of the BWE, new filters and pooling operators were designed to enable CNNs to predict the BWE accurately. b ) A tensor structure was also proposed for the time signal of demand as inputs of the CNNs to facilitate the analysis of all factors influencing the occurrence of the BWE. c ) To capture the magnitude of the BWE among features, a novel combination of filters and pooling operators was proposed, enabling the CNNs to account for hidden but yet significant feature effects during training. The benefits of the proposed approach lie in its versatility, and it can be applied to train CNNs to model structured fluctuations like the BWE in various dynamic systems.},
  archive      = {J_ESWA},
  author       = {Sajjad Aslani Khiavi and Farzad Hashemzadeh},
  doi          = {10.1016/j.eswa.2025.129764},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129764},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved convolutional neural networks for the bullwhip effect in supply chains},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid risk assessment method combining CatBoost and FAHP-grid search optimized risk matrix for container ship accident. <em>ESWA</em>, <em>298</em>, 129763. (<a href='https://doi.org/10.1016/j.eswa.2025.129763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a dominant mode of maritime transportation with unique risk characteristics, container shipping requires accurate and applicable risk assessment. However, conventional risk matrices oversimplify complex interactions, while pure data-driven models lack operational utility. To address this, a hybrid method for container ship risk assessment is proposed. This method integrates CatBoost-based predictive method, FAHP-grid search optimized risk matrix, and GIS-supported risk mapping. A comprehensive study of maritime casualties and piracy accidents is conducted, utilizing historical incident data sets collected from the Global Integrated Shipping Information System (GISIS). The global maritime accident risk of container ships is then evaluated and mapped. The sensitivity analysis confirms the robustness of the method under varying linguistic distance parameters, while expert weights have a moderate impact on the assessment results. Finally, the effectiveness of the proposed method is validated through comparative analyses on predictive performance, risk discrimination capability, and risk assessment accuracy. CatBoost algorithm outperforms XGBoost, LightGBM, and Random Forest algorithms in predictive metrics. The designed risk matrix shows strong discriminatory ability for container ship risk levels. In historical accident data validation, the proposed method also achieves higher accuracy than combinations involving XGBoost, LightGBM, or Random Forest with the designed risk matrix.},
  archive      = {J_ESWA},
  author       = {Yuqing Xiao and Shilian Han and Xinwang Liu},
  doi          = {10.1016/j.eswa.2025.129763},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129763},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid risk assessment method combining CatBoost and FAHP-grid search optimized risk matrix for container ship accident},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards. <em>ESWA</em>, <em>298</em>, 129762. (<a href='https://doi.org/10.1016/j.eswa.2025.129762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation of quadrotors is a fundamental prerequisite for numerous applications. This work proposes a novel deep reinforcement learning (DRL) framework that explicitly addresses quadrotor attitude dynamics during autonomous navigation, a critical yet underexplored challenge in existing learning-based UAV navigation studies. In the proposed method, high-level velocity commands will be generated by a deep neural network policy and translated by a low-level control algorithm to achieve precise control of both positions and rotations of quadrotors. A specialized network structure is designed to effectively extract environmental obstacle features and quadrotor sequence features to improve navigation performance. In addition, a novel tangent path reward (TPR) calculation method is developed to adequately utilize the known contours and positions of obstacles during the training phase. Experimental results demonstrate that the proposed method enables quadrotors to autonomously navigate complex virtual obstacle environments with superior efficiency compared with other algorithms. Furthermore, the feasibility and adaptability of the proposed method are validated through simulations by varying obstacle density and map size, as well as replicating real-world obstacle distributions.},
  archive      = {J_ESWA},
  author       = {Qizhang Luo and Yuqi Li and Jiaheng Zeng and Guohua Wu and Yalin Wang},
  doi          = {10.1016/j.eswa.2025.129762},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129762},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dynamic tri-stage framework with neural network-assisted search for constrained multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129761. (<a href='https://doi.org/10.1016/j.eswa.2025.129761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems involve the optimization of multiple objective functions and the satisfaction of different constraints, which poses a challenge for algorithms to achieve a good balance between convergence and diversity. However, indiscriminately enhancing diversity can hinder convergence, while solely focusing on convergence may impair the exploration of the objective space, especially when the current stage is not well-defined. To address this issue, we propose a three-stage multi-task framework for constrained multi-objective optimization with dynamically switchable stages. This framework introduces two auxiliary tasks: one that operates during the exploration and transition stages to accelerate convergence towards the boundary of the infeasible regions and assist the population in crossing it, and another that operates in the final convergence stage to guide the population towards the constrained Pareto front. Moreover, a stage detection method is proposed, which evaluates the current stage to determine the appropriate evolutionary direction for the population, thus enabling dynamic stage transitions. In addition, a neural network-assisted search operator is designed for the auxiliary task during the transition stage, which learns the optimal offspring generation process. This operator enhances the ability of the auxiliary population to cross the infeasible regions. Finally, the performance of the proposed algorithm is superior and competitive on three test suites and six real-world engineering problems compared to seven state-of-the-art algorithms.},
  archive      = {J_ESWA},
  author       = {Qianlong Dang and Xinkang Hong and Xianpeng Sun},
  doi          = {10.1016/j.eswa.2025.129761},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129761},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dynamic tri-stage framework with neural network-assisted search for constrained multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A physics-informed neural network surrogate model and many-objective optimization algorithm for coupled multi-energy systems in smart grids. <em>ESWA</em>, <em>298</em>, 129760. (<a href='https://doi.org/10.1016/j.eswa.2025.129760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scope of smart grids is progressively extending toward Integrated Energy Systems (IES) that couple electricity with gas, heating, and cooling. Due to the unsteady-state physical characteristics inherent in the transmission of gas, heat, and cooling resources, IES scheduling must not only balance multiple typical objectives but also account for the dynamic coupling of heterogeneous physical domains. To address these challenges, this paper formulates a Many-objective Optimization Model for Coupled Multi-Energy Flows (MaOCMFM) with partial differential equations (PDEs) in IES, which captures the dynamic physical behaviors of electricity, gas, heat, and cooling subsystems. Building upon this model, we propose a Probabilistic Contributing Many-objective Evolutionary Algorithm enhanced by a Physics-Informed Neural Network surrogate model (PC-MaOEA-PINN). Cubic B-spline functions are employed to achieve a continuous representation of the decision variables, while multi-physics constraints are embedded into the loss function of the surrogate model. This design enables efficient approximation of the objective function with a limited number of samples and facilitates focused exploration in critical evolutionary regions, thereby accelerating population convergence. The effectiveness of the proposed model and algorithm is validated on 9 typical scheduling days across four simulated IES scenarios.},
  archive      = {J_ESWA},
  author       = {Jingbo Zhang and Xingjuan Cai and Zhihua Cui and Jinjun Chen},
  doi          = {10.1016/j.eswa.2025.129760},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129760},
  shortjournal = {Expert Syst. Appl.},
  title        = {A physics-informed neural network surrogate model and many-objective optimization algorithm for coupled multi-energy systems in smart grids},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An emergency scheduling method based on AutoML for space maneuver objective tracking. <em>ESWA</em>, <em>298</em>, 129759. (<a href='https://doi.org/10.1016/j.eswa.2025.129759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large-scale constellations has led to a dramatic increase in the number of Resident Space Objectives (RSOs), significantly intensifying the complexity of Space Situational Awareness (SSA). Furthermore, the maneuver behaviors of non-cooperative RSOs pose potential threats to space safety, making the real-time monitoring of their post-maneuver orbital becomes more critical. In particular, the maneuvering characteristics of large-scale constellation satellites impose more stringent demands on the timeliness and adaptability of existing scheduling algorithms for observation resources. To address the emergency scheduling demands of heterogeneous ground-based observation resources, this paper proposes an Emergency Task Three-phase Scheduling Framework (ETTSF) based on Automated Machine Learning (AutoML) and auction algorithm. The framework collaboratively optimizes resource allocation through three phases: resource matching, task scheduling, and rescheduling. First, AutoML combined with an auction algorithm predicts and assigns emergency tasks to the most appropriate resources, reducing solution space complexity, simultaneously, the auction algorithm’s corrected results are fed back to AutoML for model fine-tuning. Second, a heuristic algorithm with dynamic neighborhood structures efficiently inserts emergency tasks into the routine observation plan. Finally, affected routine tasks are rescheduled to minimize the operational impact. Simulation results demonstrate that compared to baselines-Real-Time Dynamic Scheduling (RTDS) and Improved Adaptive Large Neighborhood Search (IALNS)-ETTSF achieves a 2.82% improvement in Completion Rate of Emergency RSOs (CRER) and a 27.83% reduction in Impact Rate (IR) on routine tasks. Ablation experiments further validate the effectiveness of the resource matching and rescheduling phases.},
  archive      = {J_ESWA},
  author       = {Xi Long and Jinrun Chen and Leping Yang and Huan Huang},
  doi          = {10.1016/j.eswa.2025.129759},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129759},
  shortjournal = {Expert Syst. Appl.},
  title        = {An emergency scheduling method based on AutoML for space maneuver objective tracking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploiting point-language models with dual-prompts for 3D anomaly detection. <em>ESWA</em>, <em>298</em>, 129758. (<a href='https://doi.org/10.1016/j.eswa.2025.129758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) in 3D point clouds is crucial in a wide range of industrial applications, especially in various forms of precision manufacturing. Considering the industrial demand for reliable 3D AD, several methods have been developed. However, most of these approaches typically require training separate models for each category, which is memory-intensive and lacks flexibility. In this paper, we propose a novel P oint- L anguage model with dual-prompts for 3D AN omaly d E tection (PLANE). The approach leverages multi-modal prompts to extend the strong generalization capabilities of pre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD, achieving impressive detection performance across multiple categories using a single model. Specifically, we propose a dual-prompt learning method, incorporating both text and point cloud prompts. The method utilizes a dynamic prompt creator module (DPCM) to produce instance-specific dynamic prompts, which are then integrated with class-specific static prompts for each modality, effectively driving the PLMs. Additionally, based on the characteristics of point cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) to improve the model’s detection capabilities in the unsupervised setting. Experimental results demonstrate that the proposed method, which is under the multi-class-one-model paradigm, achieves a +8.7 %/+7.0 % gain on anomaly detection and localization performance as compared to the state-of-the-art one-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains +4.3 %/+0.3 % gain for the Real3D-AD dataset. Code will be available upon publication.},
  archive      = {J_ESWA},
  author       = {Jiaxiang Wang and Haote Xu and Xiaolu Chen and Haodi Xu and Yue Huang and Xinghao Ding and Xiaotong Tu},
  doi          = {10.1016/j.eswa.2025.129758},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129758},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploiting point-language models with dual-prompts for 3D anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Path-aware routing system for multimodal vigilance estimation: A structured fusion perspective. <em>ESWA</em>, <em>298</em>, 129757. (<a href='https://doi.org/10.1016/j.eswa.2025.129757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver vigilance is a critical cognitive factor in ensuring the safety of intelligent driving systems. With advances in physiological and behavioral sensing technologies, multimodal data have become an essential source for modeling drivers’ cognitive states. However, vigilance, as an implicit cognitive state, is difficult to model accurately using a single modality. Efficient fusion of multiple modalities and structured information interaction remains a core challenge in this task. Existing approaches often rely on strategies such as feature concatenation and attention mechanisms, which lack explicit structural constraints. As a result, heterogeneous modality features are fused in an uncontrolled and entangled manner, making the interaction process opaque and difficult to interpret. To address these issues, we propose the Path-Aware Routing System (PARS), which formulates multimodal fusion as a feature routing task. In PARS, intra-modal enhancement and cross-modal interaction are abstracted into independent semantic channels, and a confidence-aware mechanism is introduced to enable dynamically weighted fusion. PARS explicitly constructs a path space, allowing features to be selectively routed and integrated along semantical pathways, thereby enhancing the model’s discriminative power and robustness. We conduct extensive experiments on a public dataset and a self-constructed driving simulation dataset. The results demonstrate that PARS significantly outperforms existing multimodal fusion methods in the task of driver vigilance estimation, achieving superior performance in terms of accuracy, interpretability, and generalization. These findings highlight the broad potential of PARS in intelligent driving applications. Our code and models are available at: https://github.com/SunYu-Gavin/PARS .},
  archive      = {J_ESWA},
  author       = {Yu Sun and Shiwu Li and Yiming Bie and Linhong Wang and Tongtong Jin and Mengzhu Guo and Zhifa Yang},
  doi          = {10.1016/j.eswa.2025.129757},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129757},
  shortjournal = {Expert Syst. Appl.},
  title        = {Path-aware routing system for multimodal vigilance estimation: A structured fusion perspective},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Homophone-aware offensive language detection via semantic-phonetic collaboration. <em>ESWA</em>, <em>298</em>, 129756. (<a href='https://doi.org/10.1016/j.eswa.2025.129756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of implicit and obfuscated expressions poses significant challenges to offensive language detection in Chinese online platforms. In particular, users often exploit homophone substitutions to bypass keyword-based moderation, making traditional detection systems inadequate. This study addresses the problem of detecting offensive content masked through homophonic substitutions, which retain aggressive intent while altering character representations. Existing methods fall into two main categories: (1) semantic-only models, which struggle with phonetic manipulations due to their reliance on text features alone, and (2) auxiliary-enhanced models, which incorporate phonetic or syntactic signals but lack deep integration between modalities. To overcome these limitations, we propose a lightweight dual-branch model that separately encodes textual semantics and pinyin phonetics under a multi-view learning framework. A Dual-Branch Interactive Training strategy is introduced to enable dynamic cross-modal alignment via contrastive objectives, allowing each modality to mutually refine the other and enhance robustness to adversarial inputs. We conduct experiments on two benchmark datasets, COLD and SWSR, both of which are augmented with varying levels of homophone noise to simulate real-world evasion strategies. The proposed model outperforms all baseline models, achieving an average F1-score improvement of 6.3 % under high-noise conditions, while reducing inference latency and memory usage by more than 60 %, demonstrating both effectiveness and efficiency for real-time deployment. We will release the source code for further use by the community https://github.com/hjhhlc/DBIT .},
  archive      = {J_ESWA},
  author       = {Jiahao Hu and Shanliang Pan},
  doi          = {10.1016/j.eswa.2025.129756},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129756},
  shortjournal = {Expert Syst. Appl.},
  title        = {Homophone-aware offensive language detection via semantic-phonetic collaboration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing traffic signal control through model-based reinforcement learning and policy reuse. <em>ESWA</em>, <em>298</em>, 129755. (<a href='https://doi.org/10.1016/j.eswa.2025.129755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) has shown significant potential in traffic signal control (TSC). However, current MARL-based methods often suffer from insufficient generalization due to the fixed traffic patterns and conditions of the road network used during training. This limitation results in poor adaptability to new traffic scenarios, leading to high retraining costs and complex deployment. To address this challenge, we propose two algorithms: PLight and PRLight. PLight employs a model-based reinforcement learning approach, pretraining control policies, and environment models using predefined source-domain traffic scenarios. The environmental model predicts state transitions, facilitating the comparison of environmental characteristics. PRLight further enhances adaptability by adaptively selecting pre-trained PLight agents based on the similarity between the source and target domains to accelerate the learning process in the target domain. We evaluated the algorithms through two transfer settings: (1) adaptability to different traffic scenarios within the same road network, and (2) generalization across different road networks. The results show that PRLight significantly reduces the adaptation time compared to learning from scratch in new TSC scenarios, achieving optimal performance using similarities between available and target scenarios.},
  archive      = {J_ESWA},
  author       = {Yihong Li and Chengwei Zhang and Furui Zhan and Wanting Liu and Kailing Zhou and Longji Zheng},
  doi          = {10.1016/j.eswa.2025.129755},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129755},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing traffic signal control through model-based reinforcement learning and policy reuse},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated transfer learning for anomaly detection in HPC systems: First real-world validation on a tier-0 supercomputer. <em>ESWA</em>, <em>298</em>, 129754. (<a href='https://doi.org/10.1016/j.eswa.2025.129754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-Performance Computing (HPC) systems increasingly require intelligent, scalable anomaly detection to ensure operational reliability. However, conventional centralized approaches often struggle with data privacy constraints, poor generalization across heterogeneous nodes, and limited scalability. This study presents the first real-world application of federated transfer learning (FTL) for anomaly detection in a production-grade Tier-0 supercomputer. By combining federated learning with transfer learning, the proposed framework enables decentralized model training and personalized adaptation to unseen nodes, without accessing raw data. We validate the approach using two large-scale telemetry datasets collected from 100 nodes of the Marconi100 supercomputer, evaluating its effectiveness across supervised, semi-supervised, and unsupervised learning paradigms. Results show that FTL consistently improves anomaly detection performance on nodes that did not participate in federated training, with F1-score gains reaching up to 0.50. These improvements demonstrate the framework’s ability to generalize across non-identically distributed data and maintain detection accuracy under real-world conditions. This work establishes FTL as a scalable, privacy-preserving solution for fault detection in HPC environments. Its practical deployment on production hardware confirms its readiness for real-time monitoring applications in large-scale, heterogeneous computing systems.},
  archive      = {J_ESWA},
  author       = {Emmen Farooq and Michela Milano and Andrea Borghesi},
  doi          = {10.1016/j.eswa.2025.129754},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129754},
  shortjournal = {Expert Syst. Appl.},
  title        = {Federated transfer learning for anomaly detection in HPC systems: First real-world validation on a tier-0 supercomputer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Security script arrangement based on enhanced BERT for cooperative defense in networked control systems. <em>ESWA</em>, <em>298</em>, 129753. (<a href='https://doi.org/10.1016/j.eswa.2025.129753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the mutual collaboration and in-depth integration among multiple defense technologies through information sharing, the cooperative defense in networked control systems has emerged as a feasible solution to counter increasingly diversified cyber threats under the unique security characteristics and requirements of industrial environments. However, one of the chief challenges is how to automatically and intelligently develop effective cooperative working strategies when an attack occurs. Leveraging the advantages of large-scale AI (Artificial Intelligence) models, this paper defines a new concept named “security script”, and proposes a security script arrangement approach based on enhanced BERT to achieve fine-grained cooperative defense in networked control systems. Furthermore, this approach introduces intrusion detection and industrial firewall as two practical examples, and can automatically arrange effective security scripts to enable the dynamic interaction of two defense technologies. Additionally, to improve efficiency, the encoder structure adjusting and AdamW optimizing are further presented to enhance the traditional BERT. Experimental results clearly demonstrate that: for one thing, these two optimization ways can make greater achievements in reducing unnecessary time consumption and enhancing accuracy of security script arrangement; for another, compared with other typical BERT and large-scale AI models, the proposed approach can exhibit more favorable performance advantages in achieving cooperative defense based on security script arrangement. In particular, through its successful application and verification in one real-world manufacturing control system, our approach may bring a potential opportunity or direction for further research and improvement of AI-based cooperative defense.},
  archive      = {J_ESWA},
  author       = {Ming Wan and Xueqing Liu and Shengbao An and Aiping Tan and Xi Jin and Chuan Sheng},
  doi          = {10.1016/j.eswa.2025.129753},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129753},
  shortjournal = {Expert Syst. Appl.},
  title        = {Security script arrangement based on enhanced BERT for cooperative defense in networked control systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ScSCDT: Self-contrastive neural network with deep topology mining for scRNA-seq data clustering. <em>ESWA</em>, <em>298</em>, 129751. (<a href='https://doi.org/10.1016/j.eswa.2025.129751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in single-cell sequencing technologies have enabled researchers to better identify cells based on gene-level information. Cell clustering is a key task in single-cell analysis and plays an important role in distinguishing cell types. However, due to the high dimensionality and sparsity of scRNA-seq data, single-cell clustering remains a major challenge. Although many methods based on deep learning and machine learning have been developed for single-cell clustering, they often fail to capture the deep topological structure between cells, which limits clustering precision. In addition, most existing clustering approaches cannot effectively construct suitable sample pairs to optimize clustering models. To address these issues, we propose a topology-aware deep contrastive clustering model for single-cell data, named scSCDT. First, scSCDT employs a ZINB-based autoencoder to simultaneously learn cell embeddings and topological information, effectively handling the challenges posed by the high-dimensional and sparse nature of the data. Then, we introduce a dual clustering-guided loss to supervise the clustering task, combining a probabilistic soft assignment strategy and a hard pseudo-labeling strategy for optimization. Finally, based on the topological structure in the low-dimensional embedding space, we construct negative pairs within a single view and design a self-contrastive learning method to further improve clustering performance. We conduct extensive experiments on ten real scRNA-seq datasets and evaluate performance using four clustering metrics. The results indicate that scSCDT achieves strong clustering performance across multiple datasets, thereby facilitating more accurate cell type identification in single-cell transcriptomic analysis.},
  archive      = {J_ESWA},
  author       = {Zhongyang Zhou and Bin Tang and Feiyu Chen and Wei Wang and Shangshang Zhao and Nanjun Yu},
  doi          = {10.1016/j.eswa.2025.129751},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129751},
  shortjournal = {Expert Syst. Appl.},
  title        = {ScSCDT: Self-contrastive neural network with deep topology mining for scRNA-seq data clustering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Visual mamba-CNN for scribble-based segmentation in weakly supervised learning for photoacoustic tomography. <em>ESWA</em>, <em>298</em>, 129749. (<a href='https://doi.org/10.1016/j.eswa.2025.129749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic (PA) imaging is a powerful non-invasive medical imaging technique that combines the high contrast of optical imaging with the deep tissue penetration of ultrasound, offering both structural and functional insights into tissues and organs. Organ-level analysis of photoacoustic tomography (PAT) images enables quantification of specific morphological and functional parameters, making accurate organ segmentation a critical step in PA image-based analysis. However, the limited availability of large-scale annotated datasets remains a major challenge. To address this, we employ cross-modality data augmentation by generating synthetic PA images from MRI scans. To further reduce manual annotation efforts, we propose a weakly supervised learning (WSL) framework that leverages scribble annotations. Since many deep learning models struggle to capture global context from sparse labels, we introduce a novel architecture that combines traditional convolutional neural networks (CNNs) with Visual Mamba, integrating both local and global feature extraction capabilities. This hybrid design improves segmentation performance in weakly supervised settings. We validate our method on a simulated PA abdominal dataset and real in vivo mouse abdominal PAT data, demonstrating notable improvements in segmentation accuracy and robustness.},
  archive      = {J_ESWA},
  author       = {Meng Zhou and Ziyin Ren and Qinlin Tan and Xin Du and Hengrong Lan and Fei Gao and Raymond Kai-Yu Tong},
  doi          = {10.1016/j.eswa.2025.129749},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129749},
  shortjournal = {Expert Syst. Appl.},
  title        = {Visual mamba-CNN for scribble-based segmentation in weakly supervised learning for photoacoustic tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 3D modeling from a single sketch with multifaceted semantic understanding. <em>ESWA</em>, <em>298</em>, 129748. (<a href='https://doi.org/10.1016/j.eswa.2025.129748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of 3D shape generation from a single sketch. Prior works rely on directly extracted visual features of sketches as guidance for the generation process. However, the sparse visual cues and abstract nature of sketches, which are inherited in the guiding features, lead to semantic ambiguity and geometry incompleteness in the generated shapes, compromising accuracy. To address this, we propose MSU-3D, a diffusion-based framework for sketch-to-3D generation, leveraging Multifaceted Semantic Understanding to explicitly analyze the construction information of sketches from multiple facets before providing fine-grained guidance over 3D shape generation. Specifically, we decompose sketches through three interpretative facets (semantics, depth, and normal), introducing reasoning of three representations to capture 3D features from distinct perspectives: local components, basic 3D geometry, and 3D surface details. One step further, we propose a multifaceted perception module. It aggregates multifaceted feature representations and leverages local component features as a two-pronged guiding representation to jointly guide the perception of basic shapes and surface details. To ensure fine-grained control, the hierarchical perception strategy adaptively injects varying granularity of perception features at different stages of the 3D generation. Extensive experiments and comparisons with state-of-the-art methods on various complex posture datasets validate the effectiveness of our framework in mitigating semantic ambiguity and geometry incompleteness in 3D generation.},
  archive      = {J_ESWA},
  author       = {Yuxiao Zhang and Jin Wang and Yang Zhou and Senyun Jia and Zhi Zheng and Dongliang Zhang and Guodong Lu},
  doi          = {10.1016/j.eswa.2025.129748},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129748},
  shortjournal = {Expert Syst. Appl.},
  title        = {3D modeling from a single sketch with multifaceted semantic understanding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Continuous learning approach to synergize shimmering image enhancement and de-fogging with small sample. <em>ESWA</em>, <em>298</em>, 129747. (<a href='https://doi.org/10.1016/j.eswa.2025.129747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shimmering Image Enhancement and Defogging (SIED) are two important aspects of image recovery. However, most methods are often fail to consider image context information, overexposure of image and the intrinsic correlation between SIED without enough sample. Furthermore, current methods may lead to the amplification of external color interference during image recovery, and can’t fine-tune the model with new samples. Firstly, we propose an Adjustable Multiscale Attention Codec Network (AMACNet) architecture. AMACNet includes variable restorative coder decoder and group channel attention to fuse multi-level contextual and channel information of images, respectively. These components are designed as plug-and-play modules. Secondly, a Continuous Learning with Small Sample (CLS) training method is presented. It utilizes few samples based on a front-and-back stage receding structure. The method synergizes the tasks of SIED, allowing the network to perform both tasks without incresing the number of parameters. It also enables the network to adapt to new tasks with a small number of unpaired samples. Finally, a color adjustment module for image post-processing is designed. The post-processing method is used to balance the impact of color illumination on the inherent color of materials. Extensive experiments demonstrate that training AMACNet by CLS allow the final image recovery results to exceed the GT in terms of ENIQA, FES, PIQE, and other unparameterized metrics.},
  archive      = {J_ESWA},
  author       = {Fenglin Yao and Zhengxiang Liu},
  doi          = {10.1016/j.eswa.2025.129747},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129747},
  shortjournal = {Expert Syst. Appl.},
  title        = {Continuous learning approach to synergize shimmering image enhancement and de-fogging with small sample},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning domain-invariant representation for generalizable iris segmentation. <em>ESWA</em>, <em>298</em>, 129746. (<a href='https://doi.org/10.1016/j.eswa.2025.129746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain iris segmentation (CDIS) seeks to transfer knowledge from a labeled source dataset to an unlabeled target dataset. Existing CNN-based iris segmentation methods commonly assume that training and application stages share the same data distribution and modality setting, thus their performance may decline substantially on open-domain iris datasets unseen before. Furthermore, the process of annotating pixel-wise labels is labor-intensive and time-consuming, resulting in limited applicability of these methods in realistic scenarios. Therefore, we propose a generic domain adaptation iris segmentation framework ( DAIrisSeg ), which can be flexibly incorporated into existing methods. First, a domain-sensitive feature whitening strategy is proposed to effectively mitigate the domain-specific styles while preserving the domain-invariant content, thereby improving the model’s generalizability to unknown domain distribution. We then utilize the prototype estimation and the context-similarity learning adapter to produce reliable segmentation labels. In addition, DAIrisSeg incorporates prior constraints of the iris to further refine the segmentation results. Extensive experiments on three iris datasets demonstrate that the proposed method has shown consistent improvements over state-of-the-art (SOTA) methods.},
  archive      = {J_ESWA},
  author       = {Dawei Lin and Meng Yuan and Ying Chen and Xiaodong Zhu and Yuanning Liu},
  doi          = {10.1016/j.eswa.2025.129746},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129746},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning domain-invariant representation for generalizable iris segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cycle-CFM: An unsupervised framework for robust multimodal anomaly detection in industrial settings. <em>ESWA</em>, <em>298</em>, 129745. (<a href='https://doi.org/10.1016/j.eswa.2025.129745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial multimodal anomaly detection is confronted with three pivotal challenges: cross-modal feature drift, noise sensitivity, and modality imbalance. To address these issues, we propose Cycle-Consistent Cross-Modal Feature Mapping (Cycle-CFM), an unsupervised framework that integrates cycle-consistent cross-modal mapping with channel-attention-guided adaptive loss weighting. Cycle-CFM establishes bidirectional feature alignment between RGB and 3D modalities via reversible cycle mappings, yielding consistent representations robust to vibration and depth noise. To further mitigate dynamic interferences such as illumination variations, we introduce a joint optimization strategy that combines cross-consistency and cycle-consistency losses. Experimental results on our self-constructed SteelDefect-3D-AD dataset demonstrate that Cycle-CFM achieves an AUPRO@1 % of 0.371, outperforming state-of-the-art methods by 17–45 %. It also attains a pixel-level AUROC (P-AUROC) of 0.991 and an image-level AUROC (I-AUROC) of 0.998. On the public MVTec 3D-AD benchmark, Cycle-CFM reaches a mean P-AUROC of 0.960 and improves accuracy by 37.5 % for elongated anomalies. With a runtime of 11.03 FPS and 469.52 MB of parameters, the model highlights both its effectiveness and deployability for real-time industrial inspection.},
  archive      = {J_ESWA},
  author       = {Yikang Shi and Xin Zhan and Yaqian Li and Zhongqiang Wu and Wenming Zhang and Haibin Li},
  doi          = {10.1016/j.eswa.2025.129745},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129745},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cycle-CFM: An unsupervised framework for robust multimodal anomaly detection in industrial settings},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable transfer learning approach to predict carbon emission intensity of coal-fired power plants with multi-source monitoring data. <em>ESWA</em>, <em>298</em>, 129743. (<a href='https://doi.org/10.1016/j.eswa.2025.129743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon mitigation policies and emission trading systems have heightened the need to monitor and predict the carbon emission intensity (CEI) of coal-fired power plants. Leveraging big data and machine learning (ML) technologies, this study trains predictive models of CEI using operational parameters, load rate, and coal-quality data from three Chinese power plants. The performance of Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Support Vector Machine (SVM), and Artificial Neural Network (ANN) was evaluated, and the challenge of limited data in individual plants was mitigated through instance-based transfer learning (ITL) and graft learning (GL) technologies. The results indicate that while traditional ML models struggle with poor data quality and limited samples, transfer learning between different plants will improve predictive accuracy substantially, and GL delivers the greatest gains. Among the most influential features, air supply temperature and load rate critically impact CEI and therefore should be carefully managed to achieve emission reductions. Nevertheless, the effectiveness of transfer learning depends on source data quality and model choice, and the proposed operational strategies require further validation before practical adoption. Our findings offer a robust framework for enhancing the predictive accuracy of plant CEI under data-scarce conditions and inform effective strategies for promoting a low-carbon transition in the energy sector.},
  archive      = {J_ESWA},
  author       = {Xiaodong Jin and Lingzhen Zhang and Fangyi Li and Wu Xie and Dawei Ma and Yan Wu},
  doi          = {10.1016/j.eswa.2025.129743},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129743},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable transfer learning approach to predict carbon emission intensity of coal-fired power plants with multi-source monitoring data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Uncertainty-guided denoising bi-classifier adversarial domain adaptation network for cross-domain fault diagnosis. <em>ESWA</em>, <em>298</em>, 129742. (<a href='https://doi.org/10.1016/j.eswa.2025.129742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis is crucial for ensuring the safety and reliability of modern industrial systems. However, the performance of deep learning models often significantly degrades due to the domain shift between training and testing data. Domain Adaptation (DA) methods, particularly bi-classifier adversarial networks, have proven effective in transferring knowledge from a labeled source domain to an unlabeled target domain. However, existing approaches often pay insufficient attention to target sample prediction accuracy, resulting in reduced feature discriminability and generalization. Additionally, due to the absence of labeled target data, most approaches rely on pseudo-labels, which are often noisy and unreliable, especially in the early stages of training. To address these issues, this paper proposes a novel uncertainty-guided denoising bi-classifier adversarial domain adaptation network (UGDBAN) for cross-domain fault diagnosis. Specifically, a feature generator based on Transformer layers is designed to capture long-range dependencies and local features. To mitigate the impact of noisy pseudo-labels, an uncertainty-based denoising pseudo-labeling mechanism is introduced to enhance the discriminability of features by redefining pseudo-labels and dynamically selecting high-confidence samples as clean samples. Building upon this denoised pseudo-label set, a Dirichlet uncertainty estimation-based class prototype alignment strategy is proposed to align domain features at the class level by selecting low-uncertainty samples representative of each class as prototypes. Extensive experiments demonstrate the effectiveness of UGDBAN, and comparative results with mainstream methods highlight its superiority.},
  archive      = {J_ESWA},
  author       = {Zheng Li and Lei Geng and Yanbei Liu and Feng Rong and Ming Ma and Jun Tong and Zhitao Xiao},
  doi          = {10.1016/j.eswa.2025.129742},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129742},
  shortjournal = {Expert Syst. Appl.},
  title        = {Uncertainty-guided denoising bi-classifier adversarial domain adaptation network for cross-domain fault diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partially view-aligned clustering via data recoupling and elastic bi-consistency learning. <em>ESWA</em>, <em>298</em>, 129741. (<a href='https://doi.org/10.1016/j.eswa.2025.129741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern multi-view data often suffer from partial view alignment issues, yet most existing multi-view clustering (MVC) methods assume that the data are fully aligned, which is rarely the case in real-world scenarios. This misalignment leads to False Negative Pairs (FNPs), disrupting the learning process. While some methods address partial alignment, they often neglect intra-view consistency and multi-scale inter-view relationships, limiting their ability to capture both global and local structural dependencies. Additionally, the prevalent use of Mean Squared Error (MSE) as a reconstruction loss is suboptimal for discrete data, potentially causing severe performance degradation. To overcome these limitations, we propose Partially View-aligned Clustering via Data Recoupling and Elastic Bi-consistency Learning (PVC-DREBL). Our method integrates two key components: (1) a Data Recouple Module, which realigns the data to mitigate the effects of FNPs while leveraging an exponential contrastive loss to enhance learning stability and prevent overfitting; (2) an Elastic Bi-consistency Learning Module, designed to reconstruct diverse data types robustly while enforcing intra-view and multi-scale inter-view consistency. Extensive experiments on six benchmark datasets demonstrate that PVC-DREBL significantly outperforms existing methods, highlighting its effectiveness in handling partially view-aligned clustering tasks.},
  archive      = {J_ESWA},
  author       = {Wenzhe Liu and Jiongcheng Zhu and Jingbo Tan and Huibing Wang and Yong Zhang},
  doi          = {10.1016/j.eswa.2025.129741},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129741},
  shortjournal = {Expert Syst. Appl.},
  title        = {Partially view-aligned clustering via data recoupling and elastic bi-consistency learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china. <em>ESWA</em>, <em>298</em>, 129740. (<a href='https://doi.org/10.1016/j.eswa.2025.129740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsurface lithological distribution is essential for extrapolating geological information from core to block or basin scales. Given the limited availability of core data, there is a critical need to develop a reliable method for establishing robust correlations between logging curves and lithologies in cores, thereby maximizing the value of large historical logging data. Here, we propose a novel attention-based convolutional neural network (ATT-CNN), which employs a 1D-CNN to transform six types of logging curves into high-dimensional feature space at each depth, and applies an attention mechanism to the 1D-CNN outputs along both the depth and feature dimensions. The architecture is designed to mimic human perceptual processing for lithology identification, leveraging curve combination, thresholding, and local pattern recognition within this enriched and high-dimensional feature representation. In addtion, the study employs wavelet-based preprocessing on logging curves to eliminate the impact of compaction-induced data drift on model generalization—an issue rarely considered in prior studies. The result showes that: ① The proposed ATT-CNN model demonstrates superior performance over benchmark models—the bidirectional gated recurrent unit (BiGRU) and an ensemble of machine learning models (En-ML)—across all evaluation metrics; ②Wavelet-based preprocessing enhances the generalization capability of both ATT-CNN and BiGRU, yielding higher metric scores and improved predictions, particularly in shallow-depth intervals; ③ For blind wells, the ATT-CNN outperforms BiGRU and En-ML in both accuracy and its ability to capture lithological variations even from low-amplitude curve deviations. The integration of ATT-CNN with wavelet-based preprocessing demonstrates significant potential for accurately characterizing subsurface lithological distribution, then provides critical support for key petroleum geology workflows, including provenance analysis, sedimentary facies mapping, and reservoir property prediction.},
  archive      = {J_ESWA},
  author       = {Jianguo Yin and Shuai Zhang and Zhixiong Wu and Shouji Pang and Rui Wang},
  doi          = {10.1016/j.eswa.2025.129740},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129740},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models. <em>ESWA</em>, <em>298</em>, 129739. (<a href='https://doi.org/10.1016/j.eswa.2025.129739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a clustering-based framework for the analysis of functional magnetic resonance imaging (fMRI) data, with a particular focus on brain segmentation into functional sub-regions. The proposed approach comprises two key modules: representation learning and brain functional segmentation. To extract meaningful latent representations from high-dimensional fMRI signals while preserving temporal dependencies, we introduce the Spherical Variational Recurrent Autoencoder (SVRAE), a deep generative model built upon the Variational Autoencoder (VAE) architecture. Unlike conventional VAEs that assume a Gaussian prior, SVRAE employs the von Mises-Fisher (vMF) distribution to model latent variables on a unit hypersphere, which is more suitable for L 2 -normalized data. To further enhance temporal modeling, we replace standard fully connected layers with Long Short-Term Memory (LSTM) networks. For the segmentation module, we adopt a Collapsed Nonparametric von Mises-Fisher Mixture Model (Co-vMFMM), formulated within a Bayesian nonparametric framework. This model automatically adapts its complexity to the input data without requiring a predefined number of clusters. An efficient variational Bayes learning algorithm is developed to perform inference in a collapsed parameter space. Extensive experiments on publicly available fMRI datasets demonstrate the effectiveness and robustness of the proposed method in delineating functionally coherent brain sub-regions.},
  archive      = {J_ESWA},
  author       = {Wentao Fan and Wenchuan Zhang and Xiao Dong and Nizar Bouguila},
  doi          = {10.1016/j.eswa.2025.129739},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129739},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An optimized hierarchical path planning method based on deep reinforcement learning for mobile robots. <em>ESWA</em>, <em>298</em>, 129736. (<a href='https://doi.org/10.1016/j.eswa.2025.129736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of elderly mobile robot technology, the training efficiency and path planning of robots have become key issues in research. Current mobile robot training faces challenges such as local optima and slow convergence speeds. To address these issues, this paper proposes a hierarchical path planning method based on deep reinforcement learning (H-DDQN). This method first introduces a global path planning module, which uses a density function to select high-value key points. In areas with dense obstacles, these key points provide the robot with effective global path guidance, enabling it to avoid getting stuck in a local optimum due to reliance solely on local information. In the local path planning module, we introduce a spatial attention mechanism based on global information, which weights global path points to enable the robot to focus on critical areas, thereby enhancing local decision-making capabilities and addressing dynamic obstacles on the basis of global optimality. Finally, this paper designs a new comprehensive reward function that combines path guidance from global key points with goal-oriented dense rewards, avoiding excessive unnecessary exploration and providing timely feedback to accelerate the model’s convergence speed. Experimental results show that compared to other existing algorithms, the H-DDQN algorithm converges more quickly during training and generates shorter and more efficient paths. In dynamic obstacle environments, the algorithm also demonstrates strong adaptability, combining global and local capabilities to achieve superior performance.},
  archive      = {J_ESWA},
  author       = {Jilin Zhang and Jia Qiao and Ke Huang and Menghua Zhang},
  doi          = {10.1016/j.eswa.2025.129736},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129736},
  shortjournal = {Expert Syst. Appl.},
  title        = {An optimized hierarchical path planning method based on deep reinforcement learning for mobile robots},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Assessing the renewable energy sources for sustainable energy generation systems: Interval-valued q-rung orthopair fuzzy SWARA-TOPSIS. <em>ESWA</em>, <em>298</em>, 129735. (<a href='https://doi.org/10.1016/j.eswa.2025.129735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable Energy Sources (RESs) help decarbonize power systems, but selecting among them is a challenging decision problem due to multiple, often conflicting, technical, economic, environmental, and health-related criteria. Consequently, numerous studies in the literature have attempted to address this decision-making issue using objective, subjective, and fuzzy decision-making procedures. However, there are still unaddressed research gaps in the literature, particularly regarding the explicit modeling of expert hesitation and ambiguity in real-world RES selection cases. The current study develops a decision-making model based on Step-wise Weight Assessment Ratio Analysis (SWARA) and Technique of Order Preference Similarity to the Ideal Solution (TOPSIS) methods integrated with Interval-Valued q-Rung Orthopair Fuzzy Sets (IV-q-ROFSs) to fill these gaps. Unlike previous studies that have predominantly applied conventional fuzzy MCDM techniques, our model introduces the first integration of IV-q-ROFS into RES selection. This novelty enables a more accurate representation of expert hesitation and uncertainty. The study is applied to a real industrial case in Turkey, where six RES alternatives are evaluated across 43 criteria by five senior experts under the supervision of a three-member professionals’ board. Furthermore, the structured robustness check and systematic literature mapping ensure that the proposed approach is methodologically robust and practically relevant for policymakers and energy planners. The application results of the developed model demonstrate that the estimated energy production potential of the RES and the effects of carcinogens generated from utilizing these energy sources are the critical factors influencing the selection of the most appropriate RESs. Solar energy ranked first among the alternatives. The applicability and validity of the developed model are examined by a comprehensive robustness check consisting of tests of sensitivity, comparison, and resilience to the rank reversal problem. Overall, the study provides (i) a novel methodological framework integrating IV-q-ROFS with SWARA and TOPSIS, (ii) empirical evidence from a comprehensive real-world RES selection case, and (iii) policy-relevant insights into the drivers of renewable energy adoption.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Ahmet Aytekin and Selçuk Korucuk and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129735},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129735},
  shortjournal = {Expert Syst. Appl.},
  title        = {Assessing the renewable energy sources for sustainable energy generation systems: Interval-valued q-rung orthopair fuzzy SWARA-TOPSIS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer. <em>ESWA</em>, <em>298</em>, 129734. (<a href='https://doi.org/10.1016/j.eswa.2025.129734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver cancer is a complex and life-threatening disease with significant diagnostic and therapeutic challenges. Automated liver cancer detection assists radiologists in identifying tumors and their severity accurately. In recent years, several deep-learning techniques have been implemented for diagnosing liver tumors and classification. Despite advancements in deep learning for medical imaging, existing liver cancer detection approaches continue to face several critical limitations. These include suboptimal diagnostic accuracy due to inadequate feature extraction, excessive computational demands that hinder real-time deployment, significant class imbalance within medical datasets leading to biased predictions, and overfitting caused by limited annotated training data. To address these challenges, this study introduces a novel and automated deep learning framework called CustomLiverNet, specifically designed for accurate and efficient liver cancer diagnosis using Computed Tomography images. The Generative Adversarial Network is introduced for generating realistic synthetic images, effectively improving the performance of the proposed technique and reducing class imbalance problems. The proposed technique integrates the strengths of Residual Networks and Vision Transformer to extract significant information from the input images and further enhance the performance of the proposed framework. The Residual Networks capture both low-level and high-level semantic features, whereas the Vision Transformer derives global and contextual feature representations from the input images. The model designs a customized fusion layer for combining the extracted features from both Residual Networks and Vision Transformer models. The classification layer predicts whether the liver tumor is benign or malignant. Further, Gradient-Weighted Class Activation Mapping is applied to highlight the critical regions of the image to enhance model transparency. The CustomLiverNet framework was trained and validated on two publicly available liver cancer datasets, including the liver tumor segmentation dataset, which contains 131 contrast-enhanced abdominal Computed Tomography scans, and the 3D image reconstruction for comparison of algorithm database, which includes 20 computed tomography scans. Experimental evaluation using standard metrics shows that CustomLiverNet achieved an accuracy of 98.79 %, precision of 98.64 %, recall of 98.58 %, and specificity of 98.35 %. These results demonstrate that the proposed model holds strong potential for enhancing early and accurate liver cancer diagnosis compared to previous studies.},
  archive      = {J_ESWA},
  author       = {Shivani Joshi and Avinash Dwivedi and Rajiv Kumar and Ashish Kumar and Raju Kumar and Amrita},
  doi          = {10.1016/j.eswa.2025.129734},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129734},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unleashing the power of large language models for low-resource relation triplet extraction by structure-to-text data generation. <em>ESWA</em>, <em>298</em>, 129733. (<a href='https://doi.org/10.1016/j.eswa.2025.129733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling language models have revolutionized widespread NLP tasks, yet little investigation has been conducted to assess the ability of Large Language Models (LLMs) to explore low-resource relation triplet extraction. This paper investigates essential methodologies, k -shot demonstration of in-context learning, and many-shot instruction tuning for few-shot and zero-shot relation triplet extraction using FlanT5, supported by exhaustive experiments. To enhance low-resource setting performance, we further propose different types of demonstration examples and task-related instructions for data generation. Specifically, we leverage LLMs to construct a structured prompt template for generating synthetic training data based on structured text and efficiently explore the boundary issues of examples in both instruction tuning and in-context learning, assessing their impact on model performance. To address the challenge of extracting multiple relation triplets from a single sentence, we design a novel Multiple Triplet Search (MTS) algorithm. Furthermore, we find that in-context learning can match the performance of previous prompt learning methods. Additionally, integrating synthetic data with the LLM can improve existing solutions in low-resource scenarios, achieving new state-of-the-art results. Experiments conducted on six relation extraction datasets demonstrate the efficacy of the proposed model for the zero-shot and few-shot RTE tasks. Our source code is publicly available at https://github.com/Phevos75/LLMRTE.},
  archive      = {J_ESWA},
  author       = {Qian Guo and Yi Guo and Jin Zhao},
  doi          = {10.1016/j.eswa.2025.129733},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129733},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unleashing the power of large language models for low-resource relation triplet extraction by structure-to-text data generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LDATA-net: Dynamic feature adaptation for efficient feature learning in resource-limited UAV detection. <em>ESWA</em>, <em>298</em>, 129725. (<a href='https://doi.org/10.1016/j.eswa.2025.129725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) image analysis faces the dual challenges of complex background interference and limited onboard computational resources, particularly when processing extreme scale variations across multiple viewpoints. Existing approaches typically enhance detection accuracy by increasing model complexity, but this often leads to parameter proliferation that exceeds the deployment limits of airborne platforms. To address this fundamental contradiction, we propose LDATA-Net (Lightweight Dynamic Aggregation Task-Aligned Network), which pioneers a “Dynamic Feature Adaptation” design paradigm aimed at achieving synergistic optimization between parameter efficiency and detection accuracy. This framework systematically realizes end-to-end dynamic adaptive capabilities through three core components that operate collaboratively across feature extraction, fusion, and detection stages: (1) Dynamic Multi-Branch Depthwise Block (DMBD-Block), whose core innovation is our proposed novel operator DIDWConv, which adaptively adjusts receptive fields according to input features to capture targets of extreme scales and orientations; (2) Lightweight Dynamic Aggregation Network (LDANet), which effectively preserves critical spatial contextual information through hierarchical fusion architecture and dynamic weighting mechanisms; (3) Dynamic Adaptive Head (DA-Head), which effectively mitigates task conflicts through geometric and semantic dynamic feature alignment. LDATA-Net achieves 35.4 %, 77.9 %, and 51.2 % AP 50 on VisDrone2019, DOTA1.0, and AI-TODv2 datasets respectively with only 2.8M parameters, establishing a new paradigm for designing memory-efficient yet high-performance detection systems, particularly for resource-constrained heterogeneous computing aviation platforms.},
  archive      = {J_ESWA},
  author       = {Shuming Lin and Sang Feng and Junnan Tan},
  doi          = {10.1016/j.eswa.2025.129725},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129725},
  shortjournal = {Expert Syst. Appl.},
  title        = {LDATA-net: Dynamic feature adaptation for efficient feature learning in resource-limited UAV detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach. <em>ESWA</em>, <em>298</em>, 129724. (<a href='https://doi.org/10.1016/j.eswa.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing complexity and scale of technological knowledge ecosystems, organizations face challenges in identifying intra- and inter-organizational collaboration opportunities. In this respect, prior studies have proposed patent-based approaches, but they are subject to several limitations: (1) insufficient consideration of technological relationships within the ecosystem, (2) simplified unit of analysis, and (3) limited organization-centric assessments. This study proposes a network embedding and text-reranking approach to explore potential intra- and inter-organizational collaboration opportunities. First, the technological knowledge ecosystem is represented as a heterogeneous patent network comprising patents, inventors, assignees, and technology classification codes. Second, inventor nodes are embedded using metapath2vec, which performs random walks along predefined metapaths to capture diverse knowledge flows within the ecosystem. Third, potential collaborators are explored through (1) screening candidates based on technological reachability, which measures the possibility of knowledge exploration based on contextual similarity within the network, and (2) reranking candidates based on technological relevance, which quantifies the possibility of knowledge exploitation based on the similarity of technological know-how and experiences. Finally, ten quantitative patent indicators are developed to assess the implications of these opportunities at both the inventor and organization levels. The validity of the proposed approach is demonstrated through a case study involving 28,888 US patents and 9,196 inventors in the field of energy storage technology. This study contributes to advancing the theoretical understanding of technological knowledge ecosystems while also serving as a supplementary tool to explore organizational collaboration opportunities.},
  archive      = {J_ESWA},
  author       = {Jaemin Chung and Jaewoong Choi and Janghyeok Yoon},
  doi          = {10.1016/j.eswa.2025.129724},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129724},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved actor-critic architecture with PPO for the traveling salesman problem. <em>ESWA</em>, <em>298</em>, 129723. (<a href='https://doi.org/10.1016/j.eswa.2025.129723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) is a classic NP-hard problem in combinatorial optimization with extensive practical applications. In this paper, we present an improved Actor-Critic architecture incorporating Proximal Policy Optimization (PPO) to effectively solve TSP. We introduce adaptive temperature scheduling, comprehensive state representation, and layer normalization to enhance learning stability. Experimental results demonstrate our Improved Actor-Critic approach achieves significant improvements ranging from 8.7 % to 55.9 % for different problem sizes compared to established reinforcement learning baselines including Q-Learning, SARSA, Double Q-Learning, Actor-Critic with Experience Replay (ACER), and Trust Region Policy Optimization (TRPO), with particularly strong performance on smaller instances between 20 to 100 cities. When testing on standard TSPLIB benchmarks, our method shows consistent advantages of 12 % to 33 % compared to classical approaches While tabular methods become computationally infeasible beyond 250 cities due to memory constraints, our approach maintains high solution quality for problems up to 1432 cities on our experimental setup (Intel® Core™i9-10900X CPU @ 3.70GHz × 20 with four NVIDIA Quadro RTX 5000 GPUs). Our ablation studies confirm the importance of each component in our proposed architecture, in which the improved state representation provides the most significant contribution to our model performance. This research significantly advances reinforcement learning approaches to combinatorial optimization, with practical implications for logistics, telecommunications, and manufacturing. The developed source code is available at: https://github.com/LetuQingge/TSP_Environment .},
  archive      = {J_ESWA},
  author       = {Hailemicael Lulseged Yimer and Pei Yang and Letu Qingge},
  doi          = {10.1016/j.eswa.2025.129723},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129723},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved actor-critic architecture with PPO for the traveling salesman problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of semi-markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks and its application. <em>ESWA</em>, <em>298</em>, 129718. (<a href='https://doi.org/10.1016/j.eswa.2025.129718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the synchronization issue of the semi-Markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks is addressed, in which the dual-scale hybrid attacks mean that hybrid attacks can be encountered in different time scales transmission channels. Based on mismatched membership functions, a new ϵ -dependent combined synchronization controller is proposed to ensure the synchronization of the master semi-Markov jump two-time-scale fuzzy neural networks and the slave ones while it is capable of resisting independent dual-scale hybrid attacks. Through the development of a Lyapunov function incorporating the singular perturbation parameter ϵ , stability conditions and a computational approach for determining the synchronization controller gain are derived for semi-Markov jump two-time-scale fuzzy neural networks. Finally, some simulations and two encryption and decryption processes are used to show the effectiveness of obtained results.},
  archive      = {J_ESWA},
  author       = {Feng Li and Ya-Nan Wang and Lei Su and Sangmoon Lee},
  doi          = {10.1016/j.eswa.2025.129718},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129718},
  shortjournal = {Expert Syst. Appl.},
  title        = {Synchronization of semi-markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks and its application},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning. <em>ESWA</em>, <em>298</em>, 129717. (<a href='https://doi.org/10.1016/j.eswa.2025.129717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dendritic or cellular morphologies of alloys and metals formed during casting processes significantly influence key properties such as mechanical strength, toughness, hardness, and electrical or thermal conductivities. The literature presents correlations between these properties and the microstructural length scale, which requires accurate characterization at the micrometer level. However, traditional evaluation methods demand extensive experimental efforts, including careful metallographic preparation, high-quality imaging, and a large number of measurements for statistical reliability - often relying on analyst proficiency. This study proposes a machine learning-based workflow tailored for the automated processing of microstructure images. The approach enables the autonomous measurement of key microstructural features while minimizing bias and inconsistencies among analysts. By integrating advanced image processing techniques with object detection algorithms based on Convolutional Neural Networks (CNNs), the method autonomously identifies microstructural morphologies and quantifies their spacing scales. Three model types-Cell, Dendrite, and Hybrid (exhibiting both dendritic and cellular features)-were trained and validated on using a dataset of 200 images. Among them, the Cell detection model achieved the highest performance, with a mean Average Precision (mAP) of 78.77 %, followed by the Hybrid (75.63 %) and Dendrite (72.87 %) models. Finally, the automated measurements models were applied to literature images and compared to reported microstructural growth correlations.},
  archive      = {J_ESWA},
  author       = {Guilherme Marim da Silva and Rafael Kakitani and Carlos Henrique da Silva Santos and Amauri Garcia and Noé Cheung},
  doi          = {10.1016/j.eswa.2025.129717},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129717},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time. <em>ESWA</em>, <em>298</em>, 129716. (<a href='https://doi.org/10.1016/j.eswa.2025.129716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of manufacturing systems, reentrancy has become prevalent in many production environments. This study investigates a bi-objective distributed reentrant flow shop scheduling problem with sequence-dependent setup times (DRFSP-SDST). The objectives are to minimize the total energy consumption (TEC) and the maximum completion time (makespan), simultaneously. First, a bi-objective mathematical model for the DRFSP-SDST is formulated based on practical reentrant production scenarios. Second, the artificial bee colony (ABC) algorithm and its variants are employed to solve the DRFSP-SDST. According to the characteristics of the DRFSP-SDST, six local search operators are specifically designed to enhance the performance of the proposed algorithms. For promoting greener and more energy-efficient production, two speed-scaling strategies are developed. Third, two reinforcement learning (RL) algorithms, Q-learning and State-Action-Reward-State-Action (SARSA), are integrated into the iterative process as online learning strategies to guide the selection of high-quality local search strategies during the iterations of the proposed algorithms. For each RL algorithm, two distinct selection strategies for local search operators are designed. Finally, the effectiveness of the proposed enhancement strategies is evaluated through comprehensive numerical experiments on 36 benchmark instances. The performance of the proposed algorithms is further validated via the Friedman test. The experimental results and analysis demonstrate that the ABC algorithm enhanced by SARSA-based local search exhibits superior competitiveness in solving the DRFSP-SDST.},
  archive      = {J_ESWA},
  author       = {Ao Yao and Kaizhou Gao and Ponnuthurai Nagaratnam Suganthan and Hongyan Sang},
  doi          = {10.1016/j.eswa.2025.129716},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129716},
  shortjournal = {Expert Syst. Appl.},
  title        = {Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Defects inspection system for building facades using drones and deep learning method. <em>ESWA</em>, <em>298</em>, 129715. (<a href='https://doi.org/10.1016/j.eswa.2025.129715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular inspection and maintenance of building facades are essential for preserving structural integrity and aesthetic quality, especially in aging urban high-rises. While drone-based visual inspection powered by artificial intelligence (AI) offers benefits in speed, safety, and scalability, existing methods are typically limited to single defect types or uniform facade categories due to the challenges of detecting multi-scale defects in complex, heterogeneous environments. This study introduces an automated multiclass defects inspection system for building facades by integrating drone technology, an AI-driven segmentation platform, and automatic report generation. Central to the system is a segmentation AI model capable of detecting multiclass defects with orders-of-magnitude differences in scale across diverse facade backgrounds. To handle the pixel imbalance of defects ranging from fine cracks to large spalling and glass breakage, the model is built upon EfficientUNet++, trained on a carefully curated dataset and optimized using adjustable batch sizes and active learning rates to improve multi-scale feature learning and mitigate overfitting. Evaluations on validation and out-of-sample datasets demonstrate that the proposed model achieves superior performance across all defect classes. Real-world drone experiments further confirm the model’s practical applicability, with high recall rates in detecting spalling, water seepage, cracks, and glass breakage across different types of facades. This work pioneers a robust, scalable, and efficient AI-based framework for automated multiclass facade defect inspection, providing actionable information for engineers and supporting urban infrastructure maintenance.},
  archive      = {J_ESWA},
  author       = {Xiaoling Zhou and Robert Lee Kong Tiong},
  doi          = {10.1016/j.eswa.2025.129715},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129715},
  shortjournal = {Expert Syst. Appl.},
  title        = {Defects inspection system for building facades using drones and deep learning method},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects. <em>ESWA</em>, <em>298</em>, 129713. (<a href='https://doi.org/10.1016/j.eswa.2025.129713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative characterization of apparent quality defects in infrastructure is a crucial component of operations and maintenance. It enables rapid assessment of defect severity and supports the timely formulation of preventive strategies. However, a singular visual modality struggles to simultaneously ensure the dual tasks of defect detection and measurement accuracy. To solve these problems, this paper proposes a novel framework for cross-modal multitask learning networks, which comprehensively integrates the advantages of image detection and point cloud measurement. The pixel points identified in the image are mapped to their corresponding three-dimensional coordinates in the point cloud through intensive feature matching. A measurement strategy for the inherent characteristics of the defect is subsequently proposed. Based on prior knowledge of the defect, the area and volume of defects are quantified accurately. Finally, extensive experiments on detection, matching and measurement demonstrate the efficacy of the proposed method. The results provide a valuable reference for the quantitative characterization of infrastructure defects.},
  archive      = {J_ESWA},
  author       = {Yu Wang and Yingchao Dai and Xiaodong Gan and Zhengtao Yang and Zhou Wu},
  doi          = {10.1016/j.eswa.2025.129713},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129713},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language proficiency assessment of autistic children using large language models. <em>ESWA</em>, <em>298</em>, 129712. (<a href='https://doi.org/10.1016/j.eswa.2025.129712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language impairment is a common comorbidity in children with autism spectrum disorder (ASD), and language proficiency assessment is a primary method for identifying such impairments. However, traditional assessment tools are often subjective and inefficient, while existing computer-assisted methods are limited by a narrow focus and insufficient use of natural language samples. To address these issues, this study proposes a framework for assessing children’s language abilities based on large language models (LLMs). We first preprocess the natural language samples from children and design multiple assessment dimensions and workflows. To enhance the stability of the assessment, we introduce a multi-expert voting mechanism and perform a comparative analysis of various large language models’ performance. The experimental results demonstrate a strong correlation between the framework’s assessment results and the Mullen Scales of Early Learning (MSEL) verbal developmental quotients, with a Pearson correlation coefficient of 0.8 ( p < 0.001). Furthermore, the results show that the multi-dimensional evaluation can accurately differentiate between ASD and typically developing (TD) children, achieving a classification accuracy of 0.98. These findings suggest that the proposed framework has significant potential for improving the accuracy of ASD identification.},
  archive      = {J_ESWA},
  author       = {Saige Qin and Min Liu and Tongquan Wei and Qiaoyun Liu},
  doi          = {10.1016/j.eswa.2025.129712},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129712},
  shortjournal = {Expert Syst. Appl.},
  title        = {Language proficiency assessment of autistic children using large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EQUINAS: Equilibrium-guided differentiable neural architecture search. <em>ESWA</em>, <em>298</em>, 129711. (<a href='https://doi.org/10.1016/j.eswa.2025.129711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has significantly mitigated the performance collapse issue in Differentiable Architecture Search (DARTS) by either refining architecture parameters to better reflect the true strengths of operations or developing alternative metrics for evaluating operation significance. However, the actual role and impact of architecture parameters remain insufficiently explored, creating critical ambiguities in the search process. To address this gap, we conduct a rigorous theoretical analysis demonstrating that the change rate of architecture parameters reflects the sensitivity of the supernet’s validation loss in architecture space, thereby influencing the derived architecture’s performance by shaping supernet training dynamics. Building on these insights, we introduce the concept of a Stable Equilibrium State to capture the stability of the bi-level optimization process and propose the Equilibrium Influential ( E I ) metric to assess operation importance. By integrating these elements, we propose EQUINAS, a differentiable NAS approach that leverages the Stable Equilibrium State to identify the optimal state during the search process and derives the final architecture using the E I metric. Extensive experiments across diverse datasets and search spaces demonstrate that EQUINAS achieves competitive test accuracy compared to state-of-the-art methods while significantly reducing search costs. Additionally, EQUINAS shows remarkable performance in Transformer-based architectures and excels in real-world applications such as image classification and text recognition.},
  archive      = {J_ESWA},
  author       = {Weisheng Xie and Xiangxiang Gao and Xuwei Fang and Hui Li and Chen Hang and Shaoyuan Li},
  doi          = {10.1016/j.eswa.2025.129711},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129711},
  shortjournal = {Expert Syst. Appl.},
  title        = {EQUINAS: Equilibrium-guided differentiable neural architecture search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Freq-DETR: Frequency-aware transformer for real-time small object detection in unmanned aerial vehicle imagery. <em>ESWA</em>, <em>298</em>, 129710. (<a href='https://doi.org/10.1016/j.eswa.2025.129710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in unmanned aerial vehicle (UAV) and remote sensing technologies have propelled UAV object detection to the forefront of computer vision research. Despite significant progress in deep learning-based detection algorithms, critical challenges persist in small object detection, including high-frequency information loss, inadequate multiscale feature representation, etc. To address these limitations, this paper proposes Freq-DETR, a frequency-aware real-time transformer detection framework leveraging frequency domain analysis to enhance edge detail preservation and global contextual modeling through three novel innovations. First, the frequency-enhanced convolution module (FECM) synergistically integrates spatial and frequency features via dual-branch processing; Second, the decoupled intra-feature scale interaction module (DSC-Clo block) facilitates the integration of high-frequency local and low-frequency global information; Finally, the attention-guided selective feature pyramid network (AGS-FPN) employs context-aware attention for high-level screening feature fusion. Extensive evaluations on the VisDrone2019 benchmark demonstrate that Freq-DETR outperforms the baseline RT-DETR by 4.9 % m a p @ 50 gain while maintaining computational efficiency. There are also remarkable improvements on both UAVDT and HIT-UAV datasets. Ablation investigations and visual interpretability analyses further confirm the complementary benefits of its frequency-domain components and the framework’s robustness in complex aerial scenarios.},
  archive      = {J_ESWA},
  author       = {Jiayi Chen and Ningzhong Liu and Han Sun and Yu Wang},
  doi          = {10.1016/j.eswa.2025.129710},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129710},
  shortjournal = {Expert Syst. Appl.},
  title        = {Freq-DETR: Frequency-aware transformer for real-time small object detection in unmanned aerial vehicle imagery},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Companion learning networks: A deep reinforcement learning algorithm with partner networks. <em>ESWA</em>, <em>298</em>, 129709. (<a href='https://doi.org/10.1016/j.eswa.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep reinforcement learning (DRL) agents suffer from severe reward instability during late-stage exploration, particularly when encountering novel states in complex continuous environments. A variety of existing studies focus on improving an agent’s reward exploration. However, they ignore the instability problem that arises when the agent faces new states in the later stages of exploration. This paper proposes a novel companion learning network (CLN) based on the idea that the guidance can accelerate human learning efficiency and reduce the risk of making mistakes. The CLN integrates a short-term partner network to intensively learn localized environmental patterns, offering adaptive action guidance for recent states. Simultaneously, a global Q-network dynamically incorporates the partner’s decaying guidance signals, balancing autonomous exploration with error mitigation. As training progresses, the partner’s influence gradually diminishes, allowing the Q-network to solidify robust policies without persistent dependence. Extensive experiments on four OpenAI Gym environments demonstrate that the CLN can significantly improve the exploration stability in most tested scenarios, achieving up to 49% reduction in late-stage reward standard deviation compared to baseline DRL methods.},
  archive      = {J_ESWA},
  author       = {Jin Xu and Jinfeng Bu and Yu Zhang and Jia-Dong Zhang and Chi-Yin Chow},
  doi          = {10.1016/j.eswa.2025.129709},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129709},
  shortjournal = {Expert Syst. Appl.},
  title        = {Companion learning networks: A deep reinforcement learning algorithm with partner networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Expensive multiobjective immune algorithm using a novel differential evolution in objective space. <em>ESWA</em>, <em>298</em>, 129708. (<a href='https://doi.org/10.1016/j.eswa.2025.129708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating offspring solutions with strong convergence and diversity is critical when solving expensive multiobjective optimization problems due to the limited number of objective function evaluations. However, existing algorithms produce offspring solutions in the decision space, causing significant uncertainty in obtaining offspring with strong convergence and diversity. To address this issue, we devise a novel differential evolution based on the objective space rather than the decision space, called Differential Objective Evolution (DOE). Specifically, DOE generates objective values with strong convergence and diversity and then maps these values to the decision space to achieve high-quality offspring. Furthermore, we utilize a multiobjective immune algorithm to produce high-quality samples for effectively training the mapping in DOE. When compared with eleven recently proposed algorithms on 105 expensive multiobjective optimization problems, the experiments demonstrate the superiority of our algorithm and the contributions of DOE in both population convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Yuchao Su and Wu Lin and Daxin Zhu and Anhui Tan and Ka-Chun Wong and Qiuzhen Lin},
  doi          = {10.1016/j.eswa.2025.129708},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129708},
  shortjournal = {Expert Syst. Appl.},
  title        = {Expensive multiobjective immune algorithm using a novel differential evolution in objective space},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation. <em>ESWA</em>, <em>298</em>, 129707. (<a href='https://doi.org/10.1016/j.eswa.2025.129707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User reviews reflect user preferences and item characteristics, optimizing the predictive accuracy and explanation generation of personalized recommendation systems. However, existing models face challenges due to subjective uncertainty in user feedback and a lack of transparency. Reviews often contain ambiguous emotional expressions, with the same product receiving positive, neutral, and negative sentiments. Many recommendation models assume alignment between ratings and review sentiments, but in practice, users may give high ratings while expressing dissatisfaction or vice versa. These inconsistencies complicate accurate modeling of user preferences. To address these issues, a Large Language Model (LLM)-driven sentiment-enhanced heterogeneous graph neural network framework is proposed. This framework jointly models interaction data and fuzzy sentiment information from reviews to improve both recommendation accuracy and explainability. By leveraging LLM with dual-prompt strategies, high-quality sentiment distributions and semantic insights are extracted. Review sentiments are then quantified using intuitionistic fuzzy numbers to address data sparsity and uncertainty, capturing implicit relationships between users, items, and entities in a sentiment-enhanced heterogeneous relational graph. A fuzzy sentiment-weighted graph convolutional network (FSGCN) is introduced for dynamic higher-order feature learning, adjusting sentiment weights based on user-item interactions and emotional context. The framework also integrates LLM-driven query interpretation to generate recommendations with transparent, context-aware rationales. This approach enables users to understand the reasoning behind recommendations, significantly enhancing explainability and trust.},
  archive      = {J_ESWA},
  author       = {Zhinan Li and Zhenyu Liu and Guodong Sa and Mingjie Hou and Jiacheng Sun and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129707},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129707},
  shortjournal = {Expert Syst. Appl.},
  title        = {Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Geodesic-based path planning for port transfer robots on riemannian manifolds. <em>ESWA</em>, <em>298</em>, 129706. (<a href='https://doi.org/10.1016/j.eswa.2025.129706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid intelligent transformation of the automotive industry and the surge in production volume, intelligent autonomous robots equipped with integrated perception and planning systems are playing an increasingly vital role in vehicle transfer operations. Optimizing dispatch paths of robots is essential for improving overall operational efficiency, yet achieving a balance among path length, feasibility, and safety margin remains a significant challenge. To address this issue, we propose a geodesic-based path planning method formulated on Riemannian manifolds. The approach jointly considers directional motion constraints, steering effort, and obstacle accessibility boundaries to construct a Riemannian metric tensor that encodes local path cost structures. This transforms the planning task into a geodesic shortest path problem, which is efficiently solved using the Geometric heat flow (GHF) method. The resulting paths naturally comply with kinematic constraints and exhibit strong obstacle-avoidance capabilities, significantly enhancing safety and executability. Extensive simulations and real-world experiments in high-density port yard environments demonstrate the practicality and robustness of the proposed method under complex spatial constraints and obstacle configurations.},
  archive      = {J_ESWA},
  author       = {Runjiao Bao and Junzheng Wang and Shoukun Wang},
  doi          = {10.1016/j.eswa.2025.129706},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129706},
  shortjournal = {Expert Syst. Appl.},
  title        = {Geodesic-based path planning for port transfer robots on riemannian manifolds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation. <em>ESWA</em>, <em>298</em>, 129705. (<a href='https://doi.org/10.1016/j.eswa.2025.129705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by empirical decision-making (EDM) processes, we propose a novel modeling framework where agents iteratively integrate social neighbors’ opinions into their cognitive inertia sequences (CISs), gradually prioritizing their accumulated CISs over time. This framework simulates the transition from group decision-making (GDM) to EDM through dynamic trust/distrust propagation and aggregation mechanisms grounded in social balance theory–capturing relational scenarios such as “a friend of a friend is a friend”, “a friend of an enemy is an enemy”, “an enemy of a friend is an enemy”, and “an enemy of an enemy is a stranger”. The paradigm incorporates two core mechanisms: (1) an endogenous cognitive inertia mechanism that uses the psychological serial-positioning effect to model cognitive inertia weights, accounting for primacy, recency, and U-shaped memory effects; and (2) an exogenous mechanism that quantifies comprehensive trust/distrust degrees via opinion similarity, stability similarity, and network structure similarity. To prevent followers from falling into cognitive freezing, a cluster leader-based consensus-reaching strategy is introduced. Extensive comparative experiments on real-world network datasets confirm the model’s effectiveness and robustness.},
  archive      = {J_ESWA},
  author       = {Jianglin Dong and Yiyi Zhao and Shangqun Mu and Haixia Mao and Jiangping Hu},
  doi          = {10.1016/j.eswa.2025.129705},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129705},
  shortjournal = {Expert Syst. Appl.},
  title        = {A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features. <em>ESWA</em>, <em>298</em>, 129704. (<a href='https://doi.org/10.1016/j.eswa.2025.129704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is essential for indoor service robots to achieve reliable navigation and mapping. While point and line features have been extensively utilized to enhance the accuracy of visual odometry (VO), current methods often overlook the rich geometric information embedded in the spatial relationships among structural lines. In particular, the parallelism and collinearity within groups of line segments are underexploited, and geometric constraints are typically applied only heuristically or post hoc, limiting robustness in low-texture and repetitive environments. To address these challenges, a robust VO system is proposed that integrates structural feature grouping with adaptive MW tracking. A unified feature extraction strategy is introduced to detect point and line features simultaneously, improving computational efficiency. To mitigate pose drift caused by unreliable line segments, a set of parallel line features is constructed based on local geometric constraints, and a novel reprojection error model is formulated to enhance pose estimation. Furthermore, a tracking strategy based on local Manhattan World (MW) structure is developed to ensure low-drift estimation across various structured indoor scenes. Extensive experiments on multiple public datasets and a custom-built service robot platform demonstrate that the proposed method outperforms existing state-of-the-art approaches under dynamic lighting conditions and in environments rich in lines and planes. The system also operates at a real-time speed of 30 frames per second, meeting the requirements of practical robotic applications.},
  archive      = {J_ESWA},
  author       = {Zhiyu Wang and Weili Ding and Ying Zhang and Changchun Hua},
  doi          = {10.1016/j.eswa.2025.129704},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129704},
  shortjournal = {Expert Syst. Appl.},
  title        = {OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated meta graph retention network: A model for urban traffic flow prediction. <em>ESWA</em>, <em>298</em>, 129703. (<a href='https://doi.org/10.1016/j.eswa.2025.129703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for urban transportation systems. Existing models are still deficient in training efficiency and modeling dynamic spatial-temporal dependencies, various external factors, time-varying topology. Based on this, this paper introduces the Adaptive Gated Meta Graph Retention Network (AGMGRN), a novel model for spatial-temporal traffic flow prediction. Specifically, the AGMGRN integrates the attention mechanism with the retention network to model spatial-temporal dependencies. The AGMGRN proposes a gated dynamic connection block to enhance the model’s dynamic modeling capabilities. The AGMGRN considers the influence of external factors on traffic conditions through meta-learning approaches. The AGMGRN proposes an adaptive graph block to construct time-varying topologies. Experiments on four actual large-scale datasets demonstrate that the AGMGRN achieves superior prediction accuracy and high applicability.},
  archive      = {J_ESWA},
  author       = {Xing Li and Yuequan Bao},
  doi          = {10.1016/j.eswa.2025.129703},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129703},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated meta graph retention network: A model for urban traffic flow prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations. <em>ESWA</em>, <em>298</em>, 129702. (<a href='https://doi.org/10.1016/j.eswa.2025.129702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defensive Counter-Air (DCA) operations are pivotal for modern air defense, but existing studies are limited by static defender populations and oversimplified attacker models. We address these limitations with the Dynamic Agent-Scaling Framework with Game-Augmented Reinforcement Learning (DASF-GRL), which dynamically scales defender populations based on real-time threat levels. Specifically, we introduce a hybrid imitation-reinforcement training strategy that integrates attention mechanisms into critic networks to enable dynamic agent scaling. By incorporating a safety barrier function rooted in differential game theory, we constrain agents’ action spaces and enhance policy reliability. Furthermore, we developed a DCA simulation platform supporting reinforcement learning validation and designed a novel Apollonius-based penetration strategy for attackers to improve algorithmic robustness. Experiments demonstrate that DASF-GRL adaptively adjusts defender populations across scenarios involving 20, 40, and 60 attackers, markedly outperforming baseline methods in convergence speed and defense success rates. This framework offers novel theoretical paradigms and practical tools for intelligent decision-making in DCA environments.},
  archive      = {J_ESWA},
  author       = {Yuxuan Chen and He Luo and Guoqiang Wang},
  doi          = {10.1016/j.eswa.2025.129702},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129702},
  shortjournal = {Expert Syst. Appl.},
  title        = {DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction. <em>ESWA</em>, <em>298</em>, 129701. (<a href='https://doi.org/10.1016/j.eswa.2025.129701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven spatial and temporal distribution of renewable energy resources poses significant challenges for multi-microgrid (MG) systems, resulting in high operational costs and low renewable energy utilization. To overcome these challenges, this work investigates a peer-to-peer electricity transaction and hydrogen-methanol-hydrogen technology-based methanol transaction among multi-MG. Besides, to realize net-zero emissions and carbon cycle utilization, the carbon capture system and hydrogen blending system are introduced into MG to reduce carbon dioxide emissions and capture and reform carbon dioxide for methanol synthesis equipment. Additionally, a cooperative operation model based on the Nash bargaining theory for multi-MGs under the transaction amount and price constraints of electricity and methanol is constructed. Due to the characteristics of non-convex and non-linear, the Nash bargaining is transformed into minimizing operation costs (sub-problem one) and maximizing payment benefits (sub-problem two). During the process of benefit allocation in sub-problem two, this work adopts a nonlinear energy sharing mapping method to quantify the comprehensive contribution rate of each MG to the multi-MG system, thereby achieving fair allocation of benefits. Finally, the alternating direction multiplier method is used to solve the model, effectively protecting the privacy of each MG. The simulation results demonstrate that a multi-MG system considering electricity and methanol transactions can effectively decrease carbon emissions and the total operational costs by 21.53% and 27.01% compared to only considering electricity transactions, respectively. Overall, the proposed electricity and methanol transactions strategy simultaneously reduces the overall system operation costs and carbon emissions, underscoring its advantages and significance.},
  archive      = {J_ESWA},
  author       = {Jiale Li and Bo Yang and Yiming Zhou and Hongchun Shu and Hongbiao Li and Dengke Gao and Lin Jiang},
  doi          = {10.1016/j.eswa.2025.129701},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129701},
  shortjournal = {Expert Syst. Appl.},
  title        = {Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming. <em>ESWA</em>, <em>298</em>, 129700. (<a href='https://doi.org/10.1016/j.eswa.2025.129700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosion in popularity of crowdsourced live streaming (CLS) has led to a huge increase in demand for cloud resources to support real-time video transcoding. CLS transcoding is real-time, geographically distributed and computationally intensive. Therefore, transcoding service providers need to cost-effectively utilize diverse heterogeneous cloud resources, while guaranteeing quality of service standards to ensure a good streaming experience for the viewers. To support the above, we developed a novel proactive-reactive resource allocation framework that optimizes the overall cost of supporting the CLS transcoding service using heterogeneous edge and cloud computing resources. The offline proactive policy evaluator aims to provide a good and adaptable resource usage plan in advance, matching the predicted demand with the heterogeneous resources. The reactive execution module monitors the actual demand online and controls the resource usage to compensate for deviations from the offline prediction. Our experiments show that the proposed approach leads to a cost reduction of 42 % compared to the fixed usage ratio strategy based on expert knowledge.},
  archive      = {J_ESWA},
  author       = {Yinuo Li and Jin-Kao Hao and Kwong Meng Teo and Liwei Song},
  doi          = {10.1016/j.eswa.2025.129700},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129700},
  shortjournal = {Expert Syst. Appl.},
  title        = {Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach. <em>ESWA</em>, <em>298</em>, 129699. (<a href='https://doi.org/10.1016/j.eswa.2025.129699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-robot path planning problem requires algorithms with high convergence speed and accuracy, as well as the completeness of the search probability for the optimal path. The integration of metaheuristic algorithms in path planning has proven to be remarkably efficient. This paper introduces a novel hybrid metaheuristic algorithm, Beluga Whale-Crayfish Optimization (BWCOA), for enhanced global optimization in path planning applications. While the Crayfish Optimization (COA) demonstrates superior convergence speed, its inherent probabilistic path completeness remains suboptimal. To address this limitation, we present three key innovations: a dynamic probability completion mechanism, adaptive convergence acceleration factors, and balanced exploration–exploitation trade-off parameters. The proposed BWCOA synergizes Beluga Whale Optimization (BWO)’s basin-hopping capability with COA’s swarm intelligence through parallel combined exploration strategies. To prove its powerfulness, a series of comparative analyses were conducted between BWCOA and other leading algorithms across two comprehensive test function suites. The numerical experiment results underscore the significant superiority of BWCOA over its counterparts. In the context of path planning simulations, BWCOA demonstrated notable improvements over COA within the same number of function evaluations, with average enhancement rates of 6.49 %, 7.42 %, 15.09 %, 76.42 %, and 0.73 % across five evaluation metrics. Similarly, when compared to BWO on the same set of indicators, BWCOA showed average improvement rates of 22.39 %, 27.71 %, 70.53 %, 260.86 %, and 41.22 %. Furthermore, the running time of BWCOA is comparable to that of similar algorithms.},
  archive      = {J_ESWA},
  author       = {Liguo Yao and Guanghui Li and Taihua Zhang and Abdelazim G. Hussien and Yao Lu},
  doi          = {10.1016/j.eswa.2025.129699},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129699},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm based on hybrid penalty strategy and its application to multi-UAV path planning. <em>ESWA</em>, <em>298</em>, 129698. (<a href='https://doi.org/10.1016/j.eswa.2025.129698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained optimization problems with complex and dynamic constraints pose significant challenges for evolutionary algorithms, as the constraints reshape the solution space and create conflicts between feasibility maintenance and global exploration. To address this issue, this study proposes TSC-PSODE, a two-stage evolutionary algorithm based on a hybrid penalty strategy. The algorithm employs an external penalty in the early stage to preserve population diversity and enhance exploration, while an internal penalty in the later stage accelerates convergence toward high-quality feasible solutions. In addition, a cooperative strategy combining differential evolution operators strengthens robustness and helps the population escape local optima. Experimental evaluations on the CEC2017 benchmark suite (the IEEE Congress on Evolutionary Computation 2017 benchmark) and multi-Unmanned Aerial Vehicle path planning tasks demonstrate that TSC-PSODE consistently outperforms state-of-the-art algorithms. The results confirm that the proposed method not only provides an effective mechanism for constraint handling, but also achieves a favorable balance between exploration and exploitation by maintaining diversity and accelerating convergence. In practical terms, TSC-PSODE is capable of generating safe and feasible flight paths for multiple UAVs in complex environments, highlighting its adaptability and competitiveness for real-world applications.},
  archive      = {J_ESWA},
  author       = {Eryang Guo and Yuelin Gao and Chenyang Hu},
  doi          = {10.1016/j.eswa.2025.129698},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129698},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm based on hybrid penalty strategy and its application to multi-UAV path planning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”. <em>ESWA</em>, <em>298</em>, 129697. (<a href='https://doi.org/10.1016/j.eswa.2025.129697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ESWA},
  author       = {Ngaiming Kwok},
  doi          = {10.1016/j.eswa.2025.129697},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129697},
  shortjournal = {Expert Syst. Appl.},
  title        = {Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time. <em>ESWA</em>, <em>298</em>, 129696. (<a href='https://doi.org/10.1016/j.eswa.2025.129696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of global data volume, the usage of hard disk drives (HDDs) is also increasing rapidly. Consequently, the number of failed disks is continuously rising, which can affect storage service quality and even lead to data loss when failures occur.In recent years, the active fault-tolerant technology, which collects hard disks’ Self Monitoring Analysis and Reporting Technology (SMART) data-set, predicts hard disk failure by machine learning model, and repairs near-failure disks’ data to health disks in advance, has become a common research hotspot in both academia and industry. Aiming at the existing problems such as interference characteristics, inaccurate failure time prediction, competition of system resources between data migration and front service, this paper researches the two-stage prediction model and data migration strategy based on hard disk failure time, including the two-stage hard disk information feature selection method, the two-stage prediction method of hard disk failure time, and the data migration elastic system resource allocation strategy. Feature selection is performed by combining embedding methods with visualization, and the importance of the selected features is evaluated using a random forest model. Based on the feature importance, further refinement is carried out to obtain the final feature set. Before predicting the failure time of hard drives, XGBoost is first used in a voting manner to identify drives predicted to be faulty. Then, a trained Bidirectional Long Short-Term Memory network (Bidirectional LSTM) enhanced with a self-attention mechanism is employed to predict the exact failure time.Experimental results show that on the Backblaze dataset, the model achieves a mean absolute error of 1.24 when predicting failure times. The recall rate for predicting failures within 7 days reaches 98.79 %, the error rate is 0.30 %, the F1 score is 99.24 %, and the precision is 99.69 %. The elastic system resource allocation strategy for data migration improves business IOPS by 47.19 % and reduces latency by 38.68 %.},
  archive      = {J_ESWA},
  author       = {Huiyuan Qiang and Yuequan Li and Hongzhang Yang and Ping Wang and Yaofeng Tu and Shang Yang},
  doi          = {10.1016/j.eswa.2025.129696},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129696},
  shortjournal = {Expert Syst. Appl.},
  title        = {2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG emotion recognition through a domain-adversarial multi-feature fusion network. <em>ESWA</em>, <em>298</em>, 129694. (<a href='https://doi.org/10.1016/j.eswa.2025.129694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate recognition of EEG signals linked to emotions is crucial for neuroscience and human-computer interaction. However, variability in EEG emotion recognition among individuals results in inconsistent feature distributions and limited generalization across subjects. To enhance the robustness of the model, we propose a deep learning approach integrating a domain adversarial migration network with an attention mechanism. Initially, a feature extractor with a hierarchical architecture (low-medium-high levels) is employed to capture multi-scale EEG features, which are then normalized for age and encoded for genderand education before being aligned with EEG features through spatio-temporal replication. Subsequently, global distribution alignment is achieved using multi-kernel maximum mean difference (MK-MMD), subdomain adversarial alignment is accomplished with a gradient inversion layer (GRL), and decision boundary clarity is enhanced through joint emotion classification loss. The generalization capability and effectiveness of the model are validated using the DEAP and DREAMER datasets, offering insights for cross-subject emotion recognition research and applications.},
  archive      = {J_ESWA},
  author       = {Weitong Sun and Yuping Su and Yumei Zhang and Xiaojun Wu},
  doi          = {10.1016/j.eswa.2025.129694},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129694},
  shortjournal = {Expert Syst. Appl.},
  title        = {EEG emotion recognition through a domain-adversarial multi-feature fusion network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFHD: Dual-granularity fusion network using historical drugs for drug recommendation. <em>ESWA</em>, <em>298</em>, 129693. (<a href='https://doi.org/10.1016/j.eswa.2025.129693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug recommendation is a task in clinical medicine aimed at suggesting a set of safe and effective medications based on a patient’s electronic health records. Current approaches either rely on diagnoses and procedures documented in electronic health records to recommend drug combinations or focus on enhancing drug recommendation safety by considering drug-drug interactions. However, these approaches often overlook the significance of historical medication information in drug recommendation despite its strong correlation with current diagnostic and prescription recommendation. Therefore, we propose a Dual-granularity Fusion Network using Historical Drugs. Specifically, at the time-series modeling level, recurrent neural networks are used to extract time-series features from historical drug data to construct coarse-grained drug characterizations. At the molecular structure modeling level, a graph neural network is used to build a relationship map between drug molecular structures and drug substructures to capture the fine-grained interactions within drug molecules. In addition, we designed a historical drug molecule awareness module to capture historical drug information during drug molecule modeling so as to identify the drugs that really help to cure patients. To effectively integrate dual-granularity information, we design a dual-granularity fusion module to realize the synergistic learning of temporal and structural features. To ensure drug safety, we introduce the DDI loss function to adaptively adjust the loss weights based on the drug interaction risk results, taking into account the optimization goals of efficacy and safety. Our source code is available at https://github.com/AK-321/DFHD .},
  archive      = {J_ESWA},
  author       = {Kang An and Ming-Yu Lu and Yan-Kai Tian and Yi-Jia Zhang},
  doi          = {10.1016/j.eswa.2025.129693},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129693},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFHD: Dual-granularity fusion network using historical drugs for drug recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm. <em>ESWA</em>, <em>298</em>, 129692. (<a href='https://doi.org/10.1016/j.eswa.2025.129692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time delay and Doppler shift parameters in radar system echo signals serve as effective tools for multi-target identification and localization in covert environments. However, the nonlinear characteristics of stationary targets are often masked by surrounding environmental factors, and traditional joint parameter estimation algorithms tend to suffer from high computational complexity and errors during demodulation. To address these challenges, this paper proposes an acoustic-electromagnetic intermodulation detection system based on a novel atomic-paradigm algorithm, which ensures localization accuracy with minimal computational complexity and zero false alarms. Specifically, the system excites the target by introducing acoustic field energy coupling, generating discernible micromotion features. The resulting acoustically modulated signal is then modeled as a two-dimensional line spectral estimation problem, capturing the target’s time delay and Doppler shift. Furthermore, the joint parameter estimation algorithm is enhanced by relaxing dyadic constraints under sufficient conditions. In our experiments, a harmonic radar physical system is constructed to simultaneously localize and measure multiple non-clustered micromotion targets. The recognition accuracy is quantitatively evaluated using a classical neural network model, achieving 86.9 % accuracy across five classified targets. The improved algorithm’s performance in joint parameter estimation is also assessed under varying signal-to-noise ratios and demodulation error rates, with a detailed time complexity analysis provided.},
  archive      = {J_ESWA},
  author       = {Sheng Wu and Yilin Cai and Yijing Zheng and Dingzhao Li and Hongjun Lai and Haixin Sun},
  doi          = {10.1016/j.eswa.2025.129692},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129692},
  shortjournal = {Expert Syst. Appl.},
  title        = {An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data. <em>ESWA</em>, <em>298</em>, 129691. (<a href='https://doi.org/10.1016/j.eswa.2025.129691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a fundamental task in supervised machine learning. This problem becomes challenging when dealing with imbalanced and overlapping datasets. In such cases, learning algorithms often perform well in identifying the labels of majority class data points but exhibit high error rates in predicting the minority class. This paper proposes an innovative method based on the convex-hull concept to enhance classification for imbalanced and overlapping datasets. Unlike undersampling approaches that may lead to the loss of valuable information, our method focuses on preserving the data. The process begins by clustering the data points for each class separately in such a way that no points from the opposite class fall within the convex-hull of each cluster. Then, the support vector machine (SVM) is used to separate every cluster of a given class from the data points of the opposite class. Afterward, data points inside the SVM boundaries are considered as non-overlapping, while those outside the SVM boundaries are identified as overlapping data. The XGBoost algorithm is then employed to classify the data points within the overlapping region. Extensive experiments on a variety of simulated and real-world datasets confirm the effectiveness of the proposed method in terms of various evaluation metrics, compared to existing relevant algorithms for handling imbalanced and overlapping datasets.},
  archive      = {J_ESWA},
  author       = {Farnaz Hooshmand and Sogol Peik-Mortazavi},
  doi          = {10.1016/j.eswa.2025.129691},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129691},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unbiased representation learning via feature decoupling network for cross-scene hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129690. (<a href='https://doi.org/10.1016/j.eswa.2025.129690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For hyperspectral cross-scene classification (HSIC) tasks, the model is trained on the source domains (SDs) and applied directly to the unseen target domains (TDs). For this domain generalization (DG) challenge, a significant issue is the contradiction between the overparameterized model and the limited training domain, which results in the absorption of spurious correlations from environmental features. To alleviate this contradiction, this study proposes a domain extension generator with a feature decoupling network (FDNet). The generator initially decouples the SD into reflectance and shading components, treating them as causal and environmental features, respectively. Considering possible causal residues in environmental features, the shading components are shuffled by style to eliminate undesired correlations. Then, the reflectance and sparsified shading are reconstructed for extension, enriching the training diversity without environmental interference. In addition, to enhance the stability of class-level causal representation, a supervised aggregation strategy is designed to minimize the intra-class distance of the reflectance domain, and supervised contrastive learning is employed to enhance the class-domain semantic consistency information. Comparative analysis with advanced domain generalization and adaptation approaches on three HSI datasets validates the superiority in accuracy and Kappa coefficient metrics of the proposed method.},
  archive      = {J_ESWA},
  author       = {Hanqing Zhao and Lianlei Lin and Zongwei Zhang and Sheng Gao and Junkai Wang},
  doi          = {10.1016/j.eswa.2025.129690},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129690},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unbiased representation learning via feature decoupling network for cross-scene hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy. <em>ESWA</em>, <em>298</em>, 129689. (<a href='https://doi.org/10.1016/j.eswa.2025.129689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presented an Automatic Role Prompting System that seeks to improve the performance of the Large Language Model (LLM) by allowing models to assume varied roles through role-based prompting and, as a result, qualitatively improve the relevance of outputs. Our Automatic Role Prompting System’s target audience is people who do not have domain knowledge. The guiding framework (consisting of an Automated Script for discovering roles and fields layered on top of prompt engineering, and Natural Language Inference (NLI) models trained in advance), was robustly tested through the use of three datasets: our set of 1990 curated prompts, WikiQA, and the AwesomeChatGPTPrompts. We implemented a novel evaluation strategy using GPT-Eval, which scales prompts according to completeness, clarity, and relevance. We found substantially better performance than traditional rule- and template-based approaches, yielding accuracy improvements as high as 97.6 %. Overall, this work demonstrates the promise of an Automated Role Prompting System to help people engage and work more effectively and efficiently with Large Language Models (LLMs).},
  archive      = {J_ESWA},
  author       = {Samar Hendawi and Tarek Kanan and Mohammed Elbes and Ala Mughaid and Shadi Alzu’bi},
  doi          = {10.1016/j.eswa.2025.129689},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129689},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid fusion network using convolutional vision transformers for landslide identification. <em>ESWA</em>, <em>298</em>, 129688. (<a href='https://doi.org/10.1016/j.eswa.2025.129688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have made great strides in the segmentation of remote sensing images, but they still have certain inherent drawbacks when working with small targets and complex geological structures. These drawbacks include incomplete contextual information integration, blurry edges, and inaccurate target localisation. This study suggests using a hybrid CNN-Transformer network to improve the segmentation of landslide regions in high-resolution remote sensing images in order to overcome these difficulties. A comprehensive investigation has been conducted on the use of CNN and transformers to accomplish the task of semantic segmentation. According to experimental data, our model outperforms the state-of-the-art CNN-based, Transformer-based, and even CNN-plus-Transformer combination models for image segmentation tasks by a large margin. When it comes to landslide area segmentation, it performs exceptionally well.},
  archive      = {J_ESWA},
  author       = {S. Sreelakshmi and S.~S. Vinod Chandra},
  doi          = {10.1016/j.eswa.2025.129688},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129688},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid fusion network using convolutional vision transformers for landslide identification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards intelligent online cross-selling. <em>ESWA</em>, <em>298</em>, 129686. (<a href='https://doi.org/10.1016/j.eswa.2025.129686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquity of online cross-selling for fashion demands a large number of qualified outfit compositions. This paper targets practical and intelligent online cross-selling by providing a more accurate fashion compatibility model and a reliable evaluation protocol for evaluating the fashion compatibility model. Firstly, a Hierarchical Outfit Network (HON) is proposed to leverage multi-layer relations among attributes, items, and outfits. The awareness of multiple relations hidden in various outfits enables the HON to outperform all state-of-the-art methods on fill-in-the-blank (FITB) accuracy and compatibility Area Under Curve (AUC) on the Maryland and Type-aware test sets. Meanwhile, a new evaluation protocol is introduced to assess the fashion compatibility model more objectively and accurately, namely, Aesthetic 100 (A100). A100 possess three desirable characteristics: 1) Completeness . All types of standards in the fashion aesthetic system are covered through two tests, namely LAT (Liberalism Aesthetic Test) and AAT (Academicism Aesthetic Test); 2. Reliability . It is an agnostic protocol and consistent with major indicators. It provides an objective and fair assessment for model comparison. 3. Explainability . A100 assesses the model on more fine-grained dimensions, e.g. , Color, Material, and Balance demonstrating its superiority in identifying essential characteristics of fashion aesthetics. Experimental results demonstrate the progress of A100 in the aspects of Reliability and Explainability. The evaluation results on A100 also show the generalization ability of HON from both quantitative and qualitative perspectives. Finally, solutions for multiple applications in fashion retailing are proposed to show how HON can be utilized to help online cross-selling.},
  archive      = {J_ESWA},
  author       = {Kaicheng Pang and Xingxing Zou and Zowie Broach and Waikeung Wong},
  doi          = {10.1016/j.eswa.2025.129686},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129686},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards intelligent online cross-selling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection. <em>ESWA</em>, <em>298</em>, 129679. (<a href='https://doi.org/10.1016/j.eswa.2025.129679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral Object Detection has shown significant advantages under various lighting and weather conditions, with efficient fusion of RGB and thermal information playing a key role. Previous studies have demonstrated the effectiveness of feature fusion based on convolutional neural networks, but limited local feature interactions hinder the capture of global complementary information. To address these limitations, some methods adopt complex fusion strategies to enhance complementary feature extraction, yet fail to mitigate feature redundancy, which negatively impacts detection performance. In this paper, we propose a novel Global-aware Cross-attention and Mask-guided Fusion (GCMF) module for Multispectral Object Detection, following a fusion-refinement paradigm. In the fusion stage, we first introduce Efficient Channel Attention with Weighted Max-Pooling (ECA-WM) to focus on key information within each modality and achieve implicit alignment before fusion. Subsequently, the Global-aware Cross-Attention Transformer (GCAT) effectively captures complementary cross-modal information and models global features. In the refinement stage, the Mask-guided Refinement Strategy (MRS) generates segmentation masks to distinguish target features from the background. These masks are applied before and after cross-modal interaction to highlight target-relevant information while suppressing irrelevant features, resulting in highly discriminative fused representations. Extensive experimental comparisons demonstrate that the proposed GCMF fusion strategy achieves state-of-the-art performance on the publicly available FLIR, LLVIP and DVTOD datasets, with absolute improvements of 2.8 %, 4.2 % and 4.0 % over the previous methods, respectively. Moreover, the proposed strategy is general and effective, making it adaptable to various detection frameworks.},
  archive      = {J_ESWA},
  author       = {Zhong Qu and Jin Yang and Shufang Xia},
  doi          = {10.1016/j.eswa.2025.129679},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129679},
  shortjournal = {Expert Syst. Appl.},
  title        = {GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Oriented bounding box detection algorithm for dense scenarios of robotic arm operation. <em>ESWA</em>, <em>298</em>, 129678. (<a href='https://doi.org/10.1016/j.eswa.2025.129678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the national promotion of intelligent manufacturing and the ’Industry4.0’ strategy, the demand for intelligent robotic arms in industrial production has steadily increased. However, challenges such as occlusion, significant object scale variations, and strict real-time requirements have made target detection in densely packed environments more challenging. This study, based on the YOLOv11 algorithm, proposes an efficient oriented bounding box detection method aimed at improving the model’s performance in feature extraction, computational efficiency, and network lightweighting to tackle target detection challenges in dense industrial settings. A Dynamic-Cross-Stage-Dual-Conv module was designed to enhance the Bottleneck section, employing a parallel dual-branch structure for local feature extraction and global context fusion. Simultaneously, a CIoU loss function with geometric perception was introduced to improve object localization accuracy and strengthen the network’s ability to handle densely stacked objects. Next, a Modulated-Deform-Conv deformable convolution module was integrated into the Backbone structure, dynamically adjusting the convolution kernel sampling positions, enabling the network to learn deformation features in dense scenes, improving adaptability to shape and scale variations while reducing computational load. Additionally, a C3K2_FasterBlock lightweight structure, utilizing partial convolutions and sparse connections, was proposed to minimize redundant calculations and optimize feature interactions. On a custom-built dense object dataset, the model achieved a 2.9 % increase in mAP@0.5 and reduced computational cost by 14 %. Finally, the improved model was deployed on the Jetson Orin Nano development board, demonstrating its practical value in robotic arm recognition and grasping tasks in dense industrial environments, offering a new paradigm for future applications.},
  archive      = {J_ESWA},
  author       = {Jinshun Dong and Lixia Deng and Dapeng Wan and Chenxu Liu and Jianqin Yin and Meiqi Guo and Hongyu Zhang and Shoujun Lin and Haiying Liu and Lida Liu},
  doi          = {10.1016/j.eswa.2025.129678},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129678},
  shortjournal = {Expert Syst. Appl.},
  title        = {Oriented bounding box detection algorithm for dense scenarios of robotic arm operation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction. <em>ESWA</em>, <em>298</em>, 129677. (<a href='https://doi.org/10.1016/j.eswa.2025.129677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in complex environments, particularly under conditions such as low illumination or adverse weather, remains a significant challenge. Multispectral detection techniques that integrate visible and infrared imagery offer a promising solution by leveraging complementary modality information. However, substantial discrepancies between these modalities hinder traditional fusion strategies, which often fail to adaptively align and integrate features, resulting in information loss and diminished detection performance. To overcome this limitation, we propose CrossModalNet, a novel cross-modal fusion and channel interaction framework. CrossModalNet comprises two key modules: Convolutional Attention Interaction Module (CAIM) and Bidirectional Cross-Modal Attention Module (BiCAM). CAIM enables effective cross-modal integration across varying semantic levels by employing convolutional attention mechanisms combined with pixel-wise channel guidance. In parallel, BiCAM enhances inter-modal feature complementarity by modeling channel-level interactions through bidirectional attention pathways. Extensive experiments conducted on four public multispectral datasets, FLIR, LLVIP, M3FD, and VEDAI, demonstrate that the proposed method consistently outperforms existing state-of-the-art approaches across multiple performance metrics. Moreover, with an inference speed of 12.6 FPS on embedded platforms, the proposed model is suitable for real-time deployment.},
  archive      = {J_ESWA},
  author       = {Hanyun Li and Linsong Xiao and Lihua Cao and Di Wu and Yangfan Liu and Yi Li and Yunfeng Zhang and Haiyang Bao},
  doi          = {10.1016/j.eswa.2025.129677},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129677},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification. <em>ESWA</em>, <em>298</em>, 129676. (<a href='https://doi.org/10.1016/j.eswa.2025.129676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear segmentation and classification play a crucial role in pathological image analysis. However, it is frequently challenged by blurred nuclear boundaries and complex structures in digital pathology slides, due to factors such as staining techniques and imaging methods, posing a significant challenge for accurate segmentation and classification. To this end, we propose a novel and efficient approach for nuclear identification, termed Information Propagation with Multi-Granularity Morphology-Guided Network (IPMMG). Specifically, IPMMG progressively captures edge morphology information from different network layers while simultaneously incorporating structural morphology features at multiple granularities. By explicitly propagating features related to both the edge and the structure, our approach constrains semantic features to focus on contours of the region of interest in the nuclear segmentation task, thus mitigating the challenge of blurred morphology. Experiments on public datasets demonstrate that IPMMG achieves state-of-the-art (SOTA) performance in segmentation, as measured by Dice and IoU scores, while also attaining competitive results in classification with DQ, SQ, and PQ metrics. In particular, our proposal IPMMG excels in handling nuclei with blurred edges and complex structures.},
  archive      = {J_ESWA},
  author       = {Dawei Fan and Jun Li and Chengfei Cai and Lihui Lin and Riqing Chen and Yanping Chen and Lifang Wei},
  doi          = {10.1016/j.eswa.2025.129676},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129676},
  shortjournal = {Expert Syst. Appl.},
  title        = {IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MECA: Modular editing via customized expert networks and adaptors in large language models. <em>ESWA</em>, <em>298</em>, 129675. (<a href='https://doi.org/10.1016/j.eswa.2025.129675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Updating language models with new information through targeted edits without resorting to expensive full model retraining remains a critical challenge, particularly when aiming to preserve pre-existing capabilities. In this work, we introduce M odular E diting via C ustomized expert networks and A daptors) (MECA), a unified framework that selectively integrates new knowledge into language models. MECA employs a module-level deferral router to evaluate whether incoming queries fall within the scope of existing edit requests. Queries are then dynamically routed to either customized editing experts or key-value adaptors. This modular strategy ensures that updates are localized, thereby mitigating risks of unintended alterations on unrelated outputs. We validate our approach on sequential editing tasks using Llama2-7B, Llama2-13B and Falcon 11B, benchmarked across two diverse datasets ZsRE and Hallucination. Experimental results show that MECA consistently outperforms several state-of-the-art knowledge editing techniques, achieving improved integration of new information while preserving the model’s original performance. Our analysis further demonstrates that the deferral routing mechanism for selecting modules effectively balances editing precision with overall model stability.},
  archive      = {J_ESWA},
  author       = {Roseline Nyange and Shanbao Qiao and Seung Hoon Na},
  doi          = {10.1016/j.eswa.2025.129675},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129675},
  shortjournal = {Expert Syst. Appl.},
  title        = {MECA: Modular editing via customized expert networks and adaptors in large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication. <em>ESWA</em>, <em>298</em>, 129674. (<a href='https://doi.org/10.1016/j.eswa.2025.129674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG-based personal identification confronts critical hurdles, including high dimensionality, noise, and real-time variability. While RSVP and P300 paradigms provide cognitive-response-driven security, feature extraction challenges prevent practical deployment. Although deep learning has addressed unstructured EEG data, pinpointing optimal RSVP and P300-specific features remains an unresolved issue. To overcome these limitations, we introduced a hybrid GWO-MSE-XAI framework integrating Grey Wolf Optimization (GWO), Multiscale Entropy (MSE), and SHAP-based Explainable AI (XAI) to select the most relevant features from RSVP-evoked P300 EEG signals. The framework prioritizes discriminative feature selection, improves class separability, and incorporates a hybrid cross-entropy loss function fused with Fisher’s score-based feature selection. Benchmark-driven optimization refines EEG-specific feature subsets, while evaluation using classifiers (Random Forest, LightGBM, CatBoost, XGBoost) demonstrates substantial dimensionality reduction, faster convergence, and superior performance (98.89% accuracy). Experimental results confirm robustness, scalability, and enhanced interpretability, positioning the framework as a viable solution for EEG-based identity authentication in real-world RSVP and P300 applications.},
  archive      = {J_ESWA},
  author       = {S Abinayaa and S.S. Sridhar},
  doi          = {10.1016/j.eswa.2025.129674},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129674},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interlink reconfiguration against cascading failures on cyber-physical power systems based on an improved memetic algorithm. <em>ESWA</em>, <em>298</em>, 129673. (<a href='https://doi.org/10.1016/j.eswa.2025.129673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical power systems (CPPSs) are the deep integration of advanced information and other technologies applied to the grid to achieve fundamental changes in the power industry. Thus, it is very significant to enhance the robustness of the power communication system in order to ensure security. For instance, when an interdependent CPPSs is under attack, the failure can diffuse along interconnect topology to the whole system, even causing a system crash. Recall that most of the existing models are one-to-one coupling structures. Drawing close to reality, we develop a modified memetic algorithm to reconstruct CPPSs with multiple-to-multiple interlinks, called MA-Multiple, which is dedicated to improving the robustness of CPPSs. To improve the accuracy of the optimal solution of the MA-Multiple, we devise a crossover operator (CO) based on the null model to increase population diversity. Further improving the suitability of algorithms on CPPSs, we propose a new Kirchhoff centrality (KIC) based on the approximation of the inverse matrix to measure network connectivity and design a local search operator (LSO). In the experiment, we comprehensively compare the MA-Multiple with four closely relevant methods in different scenarios. The results imply that MA-Multiple performs better in enhancing network robustness and resisting attacks.},
  archive      = {J_ESWA},
  author       = {Wei Lin and Li Xu and Yuexin Zhang and Jie Li},
  doi          = {10.1016/j.eswa.2025.129673},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129673},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interlink reconfiguration against cascading failures on cyber-physical power systems based on an improved memetic algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective portfolio optimization for stock return prediction using machine learning. <em>ESWA</em>, <em>298</em>, 129672. (<a href='https://doi.org/10.1016/j.eswa.2025.129672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach that integrates stock return prediction with the mean–variance (MV) model to enhance the performance of the original model. Firstly, stock returns are predicted using machine learning algorithms, including Robust Linear Regression (OLS-H), Random Forest (RF), and Long Short-Term Memory Networks (LSTM), to select a pre-screened stock pool composed of stocks with high predicted returns. Secondly, a linear weighting method combines the predictions above with the MV model, constructing the Mean-Variance-Forecast Error (MVF) model and determining the investment proportions for the pre-selected stocks. Finally, empirical research is conducted using the components of the CSI 300 Index as sample data. The results indicate that the RF + MVF model outperforms other models and the CSI 300 Index in return and risk metrics. At the same time, a sensitivity analysis of relevant parameters further confirms that considering return uncertainty is beneficial for improving the out-of-sample performance of the MV model.},
  archive      = {J_ESWA},
  author       = {Meiyu Huang and Shili Dang and Miraj Ahmed Bhuiyan},
  doi          = {10.1016/j.eswa.2025.129672},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129672},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective portfolio optimization for stock return prediction using machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKT-ML: An efficient knowledge tracing model with multi-task learning. <em>ESWA</em>, <em>298</em>, 129671. (<a href='https://doi.org/10.1016/j.eswa.2025.129671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) aims to trace a student’s mastery of knowledge, known as knowledge states, and has become a popular research area, with Self-Attention (SA)-based KT models achieving the state-of-the-art performance. However, existing SA-based KT models seem to still have issues that need further investigation. Firstly, there commonly exists incorrect question-knowledge concept (Q-KC) mapping, yet most models fail to address this issue. Secondly, existing SA-based KT models suffer from high time complexity due to their extensive use of the SA mechanism. Finally, from real-world datasets, we observe that there exists a repeated attempts pattern which is often overlooked by existing KT models. Motivated by the above observations, we propose a novel Efficient Knowledge Tracing Model with Multi-task Learning (EKT-ML), an SA-based model with three crucial features. Firstly, we formulate the KT as a Multi-task Learning, with Q-task and KC-task as two tasks; by training them simultaneously and treating Q-KC mapping as shared information, the proposed EKT-ML tends to mitigate the impact of incorrect Q-KC mapping. Moreover, we propose an SVD-MLP component to replace the initial SA layers commonly used in existing SA-based KT models, thereby reducing the time complexity of EKT-ML. Finally, experimental results show that EKT-ML improves performance by up to 8.84 % across four metrics on three widely used datasets. Furthermore, it demonstrates that the EKT-ML has reduced time complexity compared with the benchmark baseline.},
  archive      = {J_ESWA},
  author       = {Wei Liu and Bo Yang and Haotian Su and Yaowei Wang and Qing Li},
  doi          = {10.1016/j.eswa.2025.129671},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129671},
  shortjournal = {Expert Syst. Appl.},
  title        = {EKT-ML: An efficient knowledge tracing model with multi-task learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention dilated deep learning network-based distributed data mining with energy efficient heuristic-aided routing model in WSN. <em>ESWA</em>, <em>298</em>, 129670. (<a href='https://doi.org/10.1016/j.eswa.2025.129670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSNs) are comprised of autonomous nodes, where the physical devices and other equipment are embedded for monitoring the environment. Yet, it consumes larger energy consumption while it fails to provide the optimal routing path. The data aggregation in WSN is accomplished by several classification approaches, but the delay and utilization of the resource are high. So, it is necessary to solve the challenges by implementing the developed model for the energy efficient routing in WSN. A distributed data mining scheme is developed based on a deep learning approach to provide greater energy efficiency and optimal load balancing in WSN. The distributed data mining is performed to distribute the appropriate data to the sensor nodes. This data distribution highly reduces the overhead at the fusion center. The data are categorized via Fused Deep Structural Network (FDSNet), where the Attention-based Dilated Deep Temporal Context Networks (DTCN) are fused with a Deep Shallow Network. The necessary data are distributed to the sensor nodes. The optimal routing is carried out based on optimal path selection using Stability Bound-based Energy Valley Optimizer (SBEVO). The optimal routing is done via the multi-objective functions such as “energy consumption, PDR, delay, and shortest path”. The energy-efficient data transmission is accomplished with the help of developed distributed data mining with a routing scheme. The developed energy-efficient optimal routing in WSN is compared to conventional routing approaches with several performance metrics to show energy efficiency. While comparing with existing methods, the developed model attains the value of 0.95% with regards of accuracy, precision, and F1-score. These findings of the developed model show accurate performance with an efficient routing mechanism in WSN.},
  archive      = {J_ESWA},
  author       = {Kiran Goud Palakuri and Manjeet Singh},
  doi          = {10.1016/j.eswa.2025.129670},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129670},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention dilated deep learning network-based distributed data mining with energy efficient heuristic-aided routing model in WSN},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Curriculum learning for a hybrid approach for aspect-based sentiment analysis. <em>ESWA</em>, <em>298</em>, 129669. (<a href='https://doi.org/10.1016/j.eswa.2025.129669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past years, the amount of unstructured online review data has grown exponentially. Many people express their opinions about different aspects of goods and services on the Web. Aspect-Based Sentiment Analysis (ABSA) automatically extracts the sentiments with respect to aspects given in a sentence. We improve the training procedure of the state-of-the-art Hybrid Approach for Aspect-Based Sentiment Analysis with deep contextual word embeddings and hierarchical attention (HAABSA++). In this method, a domain sentiment ontology is used as a main classifier, and if it is not conclusive, a neural network is employed as a back-up. We extend the training of the neural network by incrementally adding more difficult instances, also known as curriculum learning. Restaurant reviews obtained from the SemEval-2015 and SemEval-2016 datasets are used to evaluate the effect of implementing curriculum learning. Using baby steps curriculum learning and a specific curriculum strategy, the accuracy of HAABSA++ is improved from 86.3 % to 87.5 %.},
  archive      = {J_ESWA},
  author       = {Nana Lange and Flavius Frasincar and Maria Mihaela Truşcǎ},
  doi          = {10.1016/j.eswa.2025.129669},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129669},
  shortjournal = {Expert Syst. Appl.},
  title        = {Curriculum learning for a hybrid approach for aspect-based sentiment analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm. <em>ESWA</em>, <em>298</em>, 129668. (<a href='https://doi.org/10.1016/j.eswa.2025.129668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is a key technique for extracting object structures and region boundaries in images, serving as an important foundation for visual tasks such as image segmentation and object recognition. However, during real-world image acquisition, various types of noise are inevitably introduced into the images. Traditional edge detection methods suffer significant performance degradation in noisy environments, often resulting in false edges or missing true edges. To address this issue, this paper proposes a novel edge detection method for noisy images. The method begins by adaptively selecting an optimal fractional order p , based on the distribution characteristics of the image’s subband modulus coefficients. This order is then used to perform a p -order discrete fractional wavelet transform (DFRWT) on the noisy image. Then, within the DFRWT domain, an enhanced Canny algorithm is applied to detect edges. This algorithm improves upon the standard method by replacing the traditional gradient operator with a more robust fractional-order Sobel operator to compute the gradient magnitude. This detection process is performed on both the low- and high-frequency subbands to capture features at different scales. Finally, the edge images from the low- and high-frequency components are reconstructed to obtain the final edge detection result. Experimental results demonstrate that, compared to four representative edge detection algorithms, the proposed method exhibits superior noise robustness and edge preservation capability in noisy environments.},
  archive      = {J_ESWA},
  author       = {Xiaozhong Yang and Chunmeng Li},
  doi          = {10.1016/j.eswa.2025.129668},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129668},
  shortjournal = {Expert Syst. Appl.},
  title        = {A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning. <em>ESWA</em>, <em>298</em>, 129667. (<a href='https://doi.org/10.1016/j.eswa.2025.129667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electron Backscatter Diffraction (EBSD) is a crucial characterisation method in materials engineering. The reliability of EBSD data is essential in the aerospace, nuclear, and automotive industries, as material performance greatly affects operational safety. While industrial practice makes perfect EBSD data difficult, with sample preparation errors, beam drift, and instrumental noise corrupting up to one-third of datasets. Automated crystallographic fidelity restoration solutions are needed because corrupted data force engineers to abandon valuable experiments or manually restore datasets at risk of errors. Current image inpainting techniques fail to maintain crystallographic constraints, resulting in restorations that violate the basic rules for crystalline materials. A novel physics-constrained framework is proposed to fill this gap. It integrates adversarial learning with graph neural networks (GNNs) for crystallographically consistent EBSD image inpainting. The proposed GTRG method consists of three elements: i ) a generative adversarial network (GAN) for reconstructing grain boundaries; i i ) a crystallography-guided graph transformer (T) that converts pixel data into orientation-boundary graphs; and i i i ) a regression graph convolutional network (RGCN) that links grain, orientation and boundaries to predict missing crystal orientations. The framework mandates a single orientation per grain and preserves grain boundary structure through structured graph representations. A strategy for creating automated EBSD datasets that incorporates realistic corruption patterns supports effective model training and evaluation. Experimental validation shows better performance than current methods, with a 3.5 % improvement in SSIM (0.950 vs. 0.918) and a 63.0 % reduction in FID (16.55 vs. 44.70) compared to AOT-GAN. The study on aerospace niobium alloys further validates practical utility, showing statistically consistent grain orientation and size distributions (Kolmogorov-Smirnov D = 0.02 , p > 0.98 ). This work introduces two key advancements: 1) the first integration of graph neural networks with adversarial learning for topology-aware image inpainting, and 2) a physics-informed framework bridging computer vision and materials science, enabling effective restoration of corrupted EBSD data for subsequent engineering applications.},
  archive      = {J_ESWA},
  author       = {Baiyang Zheng and Jiongran Wen and Yat-Sze Choy and Chengwei Fei},
  doi          = {10.1016/j.eswa.2025.129667},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129667},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks. <em>ESWA</em>, <em>298</em>, 129666. (<a href='https://doi.org/10.1016/j.eswa.2025.129666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gathering and sharing of information lay the groundwork for decision-making, while large-scale group decision-making (LSGDM) strategies address biases, promoting a more comprehensive evaluation of alternatives. Regarding information representation, incomplete multi-scale information systems (MSISs), as an application of granular computing, combine inputs from decision-makers (DMs) and tackle data gaps through multi-level analysis to foster LSGDM. Furthermore, given the interference effect among DMs, quantum social networks (SNs) and three-way decisions (TWD) are vital for effective decision-making. Quantum SNs provide a framework for modeling complex trust relationships among DMs, while TWD offers a structured approach to manage uncertainty. Therefore, this paper seeks to investigate quantum SN-guided three-way LSGDM under incomplete MSISs. First, MSISs are designed to gather information across spatial dimensions. Second, trust propagation paths within SNs are aggregated using quantum theory. Following community clustering through the Leiden algorithm, each community is further divided into core and fringe regions by three-way clustering (TWC), where core alternatives reflect the central members and fringe alternatives represent uncertain members. Third, to achieve intra-group consensus, the weights of DMs in fringe regions and those with low consensus levels are adjusted, while for inter-group consensus, the weight and decision information of community representatives with low consensus levels are modified. Fourth, alternatives are classified using the TWD method, which is grounded in the Dempster-Shafer theory and incorporates the enhanced belief Jensen-Sharma-Mittal ( E B J S M ) divergence. Finally, air quality datasets are used to validate the practicality of this method through sensitivity analysis, simulation analysis, comparative analysis, and statistical analysis.},
  archive      = {J_ESWA},
  author       = {Rui Li and Chao Zhang and Hamido Fujita and Wentao Li and Witold Pedrycz and Oscar Castillo},
  doi          = {10.1016/j.eswa.2025.129666},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129666},
  shortjournal = {Expert Syst. Appl.},
  title        = {Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GDCR: Geometry-enhanced directional consistency representation for point cloud analysis. <em>ESWA</em>, <em>298</em>, 129665. (<a href='https://doi.org/10.1016/j.eswa.2025.129665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds provide discrete representations of 3D scenes. The relative positions and directions between points collectively describe the objects. Variations in sampling angles, distances, or noises can introduce perturbations, disrupting these spatial and directional relationships. These pose significant challenges for achieving robust feature representations. However, research on the robust representation of point clouds is limited. Although advanced models achieve impressive performance, they exhibit poor robustness to perturbations. To address this issue, we propose Geometry-enhanced Directional Consistency Representation (GDCR), a novel method designed to enhance robustness. In GDCR, we introduce Statistic-based Geometric Reasoning (SGR) to achieve precise spatial geometric estimation for discrete point sets, explicitly enriching spatial geometric information. Furthermore, GDCR vectorizes features embedded with SGR information and applies feature rotation and relative direction refinement in the expanded feature space for robust directional representation. GDCR improves the flexibility and directional expressiveness of point cloud features, significantly improving robustness against perturbations. Extensive experiments demonstrate that GDCR exhibits outstanding robustness while surpassing or matching the performance of state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Ziming Wang and Boxiang Zhang and Ming Ma and Yue Wang and Taoli Du and Ying Wang and Wenhui Li},
  doi          = {10.1016/j.eswa.2025.129665},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129665},
  shortjournal = {Expert Syst. Appl.},
  title        = {GDCR: Geometry-enhanced directional consistency representation for point cloud analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement. <em>ESWA</em>, <em>298</em>, 129664. (<a href='https://doi.org/10.1016/j.eswa.2025.129664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-Light Image Enhancement (LLIE) plays a crucial role in computer vision applications. Beyond spatial-based approaches, recent works have explored the Fourier domain. To better preserve structural details in extremely dark scenes, infrared modality has also been introduced as a robust prior for capturing scene geometry. However, existing methods suffer from limited enhancement performance due to the independent modeling of Fourier amplitude and phase, the limitations of cross-modal guidance, and the information loss in sequential feature extraction. To address these challenges, we propose APMoE-Net, a dual-stage Fourier network framework with amplitude-phase joint enhancement and spatial Mixture of Experts (MoE) compensation. Stage one performs coarse enhancement by leveraging infrared images to jointly optimize Fourier amplitude and phase, enabling mutual guidance learning between them. Subsequently, a Modality Refinement Module leverages edge information to refine infrared inputs, producing a refined modality map as a more accurate cross-modal prior for subsequent processing. The second stage employs a dual-branch design for texture refinement. Our key innovation lies in the MoE Compensation Module integrated within the Multi-scale Convolution Branch. This module employs a dynamic routing network to selectively activate specialized experts, enabling the recovery of fine-grained textures that are lost during sequential processing. Meanwhile, the Fourier Branch integrates the refined modality map to improve overall detail and contrast. Comprehensive experiments demonstrate that APMoE-Net surpasses state-of-the-art (SOTA) methods in both qualitative and quantitative evaluations. Notably, APMoE-Net achieves outstanding performance with a lightweight design, offering an efficient LLIE solution.},
  archive      = {J_ESWA},
  author       = {Mengen Cai and Tongshun Zhang and Pingping Liu and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129664},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129664},
  shortjournal = {Expert Syst. Appl.},
  title        = {APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms. <em>ESWA</em>, <em>298</em>, 129663. (<a href='https://doi.org/10.1016/j.eswa.2025.129663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection and identification of harmful algal bloom (HAB) images are crucial for developing effective early warning systems for HABs. However, existing edge detection models, primarily designed for natural scenes, struggle with HAB-specific challenges such as blurred cell contours and interference from impurity bubbles. To address these issues, we propose a novel edge detection approach tailored for marine HABs, integrating a diffusion probability model with Sobel convolutional inter-layer attention mechanisms. Firstly, we develop an image enhancement algorithm specifically for HABs images, significantly improving real-time dynamic sampling data by enhancing contrast, edges, and texture features. Next, we introduce the SIAnet network, which utilizes inter-layer attention and convolutional operations to generate comprehensive global information. This network enhances feature correlation by aggregating shared features across multiple layers and modeling both long-range and short-range dependencies, effectively suppressing noise and background interference. This facilitates precise extraction of algae boundaries and morphological characteristics. Additionally, an improved Sobel operator is employed to generate supplementary edge features, accelerating the training process. Experimental results demonstrate that the proposed method achieves robust performance on the HABs dataset, with an Optimal Dataset Scale (ODS) of 0.645, an Optimal Image Scale (OIS) of 0.702, and an Average Precision (AP) of 0.813. Compared to existing methodologies, our approach demonstrates strong generalization on BSDS and BIPED datasets, significantly enhancing performance and mitigating typical CNN issues of edge thickening and fragmentation. It offers essential technical support for efficient HAB early warning system development.},
  archive      = {J_ESWA},
  author       = {Gengkun Wu and Yining Fan and Xin Tian and Chao Cui and Jiazheng Han},
  doi          = {10.1016/j.eswa.2025.129663},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129663},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches. <em>ESWA</em>, <em>298</em>, 129662. (<a href='https://doi.org/10.1016/j.eswa.2025.129662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring an individual’s BioGeographical Ancestry (BGA) through DNA analysis is a valuable tool in various fields such as forensic science, especially when traditional methods fail to identify suspects or victims. Advances in Next-Generation Sequencing (NGS) have revolutionized genomic data acquisition, enabling the development of comprehensive Single Nucleotide Polymorphism (SNP) panels for ancestry inference. This study assessed the effectiveness of a novel panel containing 3234 SNPs at both inter-continental and a more detailed BGA level, using various supervised Machine Learning (ML) models, including Categorical Naive Bayes, Penalized Multinomial Logistic Regression, Linear Support Vector Machines, Random Forest, and tree-based Gradient Boosting. A nested cross-validation approach was employed for model tuning and evaluation, with balanced accuracy as the main performance metric to address class imbalance. At the inter-continental level, all ML models demonstrated high balanced accuracy, confirming their reliability for BGA inference. However, performance declined at the more detailed continental level, likely due to a combination of factors including increased class imbalance, reduced sample sizes for certain populations, and the inherent complexity of distinguishing genetically and geographically proximate groups. Nonetheless, promising results were observed for South Asians, Northeast Asians, Europeans, and West Africans classes. In contrast, performance was notably lower for underrepresented classes such as Inner Asians. Misclassification patterns at both levels appeared to reflect known geographical and historical relationships, although further analysis revealed that these were often concentrated in underrepresented or genetically complex groups. These findings highlighted the potential of this SNP panel and ML approaches as valuable tools for forensic investigations.},
  archive      = {J_ESWA},
  author       = {Cosimo Grazzini and Giorgia Spera and Stefania Morelli and Daniele Castellana and Giulia Cosenza and Michela Baccini and Giulia Cereda and Elena Pilli},
  doi          = {10.1016/j.eswa.2025.129662},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129662},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image. <em>ESWA</em>, <em>298</em>, 129661. (<a href='https://doi.org/10.1016/j.eswa.2025.129661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting small regions of interest (ROIs) from abdominal CT images presents significant challenges, particularly due to class imbalance and variations in the sizes of foreground objects. A commonly adopted solution is the two-stage segmentation. However, this approach has two key limitations: i) Difficulty in balancing localization accuracy and target preservation. To reduce information loss in the first stage, existing methods typically enlarge the predicted bounding boxes, which improves coverage but compromises localization precision. ii) Independent optimization of the two stages, which lacks a collaborative mechanism. This fragmented pipeline limits the flow of information between stages, thereby constraining performance improvements. To address these limitations, we propose a reinforcement learning-based collaborative localization and segmentation (RL-CoSeg) framework, which comprises three sub-networks: localization network (LN), segmentation network, and localization-segmentation collaboration network (LSCN). The LN integrates prior knowledge and incorporates a dynamic reward mechanism to enhance the accuracy and efficiency of target detection through reinforcement learning (RL) strategies. The LSCN further introduces segmentation predictions as a reward signal, which, together with the localization reward, jointly drives policy learning. In addition, a heuristic exploration strategy is employed to avoid local optima and improve training stability. This design strengthens the information interaction and collaborative performance between the two tasks. Experimental results demonstrate that the proposed method achieves superior collaborative performance in small-target medical image segmentation.},
  archive      = {J_ESWA},
  author       = {Feilong Xu and Feiyang Yang and Xiaoli Zhang and Zhaojun Liu},
  doi          = {10.1016/j.eswa.2025.129661},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129661},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction. <em>ESWA</em>, <em>298</em>, 129660. (<a href='https://doi.org/10.1016/j.eswa.2025.129660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to extract relations between entity pairs across the entirety of a document. Current methods have begun to adopt logical rules to enhance the performance of DocRE models. However, the pipeline’s rule learning framework will suffer from the issue of error propagation, and the end-to-end method may lead to mistakes in rule reasoning. Additionly, they ignore entity type information when learning the rules. To address these issues, we propose a novel framework named Soft-Hard Rules with Entity Type Constraints (SH-ETRs) for improving the rules’ expressiveness and quality. Specifically, we first propose a Hard Entity Type Rules Module (H-ETRs) to learn entity type information and provide hard rule constraints. Then, we propose a Soft Entity Type Rule Reasoning Module (S-ETRs), which parameterizes the rule inference process and reduces error propagation during the process. Furthermore, by applying a rule consistency loss function to S-ETRs, we achieve the learning of soft rules under hard rule constraints, thereby aiming to prevent the learning of inaccurate rules during the training process. The experimental results demonstrate that our method outperforms existing rule learning frameworks, achieving state-of-the-art performance with an F1 score of 74.39 and an IgnF1 score of 67.43 across three public datasets and two baseline models.},
  archive      = {J_ESWA},
  author       = {Haisong Chen and Nisuo Du and Qing He and Yuji Wang},
  doi          = {10.1016/j.eswa.2025.129660},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129660},
  shortjournal = {Expert Syst. Appl.},
  title        = {SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MCAD-EUC: Multi-context adaptive decoding with entropy-based uncertainty calibration for knowledge conflict mitigation. <em>ESWA</em>, <em>298</em>, 129659. (<a href='https://doi.org/10.1016/j.eswa.2025.129659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knowledge sources of large language models (LLMs) encompass both parametric internal knowledge and external contextual information. However, conflicts between these two sources can significantly impair model performance. Existing methods typically assume a priori correctness of either the context or the parametric knowledge, lacking dynamic coordination mechanisms and being limited to single-context scenarios. To address this issue, this work proposes a lightweight and training-free decoding method, M ulti- C ontext A daptive D ecoding ( MCAD-EUC ), which dynamically measures the effectiveness of both knowledge through E ntropy based U ncertainty C alibration. It does not concern itself with whether the knowledge is false or true, the internal or the external, but balancing them according to their contributions to correctly answering the question. Particularly, MCAD-EUC is naturally multi-contextual. It can dynamically amplify the distribution of golden context while mitigating the influence of noisy context, thereby optimizing the final logits for predicting the next token during the decoding process. To comprehensively evaluate the model performance in multi-context scenarios, this work constructs MCQA, a multi-context question answering dataset that includes golden context, irrelevant context, and six categories of misleading context (crowd, logic, temporal, authority, emotional, numeric), simulating the diversity of noise in real-world settings. Extensive experiments on four LLMs and four MCQA datasets demonstrate that MCAD-EUC achieves an average accuracy improvement of 3.17 % over the best-performing baseline methods. Further sensitivity analysis confirms that the entropy-based adaptive weighting mechanism consistently outperforms all fixed-weight settings. Our dataset and code will be publicly available.},
  archive      = {J_ESWA},
  author       = {Yimin Ou and Yifan Wang and Ping Jian and Tianhe Zhang and Xing Pei},
  doi          = {10.1016/j.eswa.2025.129659},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129659},
  shortjournal = {Expert Syst. Appl.},
  title        = {MCAD-EUC: Multi-context adaptive decoding with entropy-based uncertainty calibration for knowledge conflict mitigation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable knowledge tracing with dual-level knowledge states. <em>ESWA</em>, <em>298</em>, 129658. (<a href='https://doi.org/10.1016/j.eswa.2025.129658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is a critical technology for achieving personalized learning. It estimates learners’ knowledge states and predicts future performance using historical interaction data. Despite recent advances, two significant challenges remain. First, the accuracy of knowledge state modeling is limited by the insufficient fusion of multi-scale information across temporal and spatial dimensions. Second, a trade-off persists between improving predictive performance and enhancing interpretability. This paper proposes an interpretable knowledge tracing method based on dual-level knowledge states (DIKT) to address these challenges. From the temporal perspective, DIKT incorporates a forgetting-aware RoLinear Transformer and a semantic similarity-based review mechanism to model learners’ problem-level knowledge states. From the spatial perspective, it leverages a Knowledge Concept (KC) relational graph to propagate influence among related KCs and dynamically update learners’ concept-level knowledge states through three sequential learning phases: forgetting, aggregation, and updating. Student performance is predicted using a two-parameter Item Response Theory (IRT) model, which incorporates guess and slip parameters to account for response anomalies. We conduct extensive comparisons between DIKT and 20 state-of-the-art KT models on five widely used public datasets. Experimental results demonstrate that DIKT achieves superior performance while preserving interpretability, highlighting its practical potential for real-world educational applications. The code is available at https://github.com/ting214/DIKT .},
  archive      = {J_ESWA},
  author       = {Yanting Li and Tao Zhou and Tianyu Cai and Shenggen Ju},
  doi          = {10.1016/j.eswa.2025.129658},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129658},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interpretable knowledge tracing with dual-level knowledge states},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RASpan: Improving toponym recognition through span representation model with retrieval augmentation. <em>ESWA</em>, <em>298</em>, 129657. (<a href='https://doi.org/10.1016/j.eswa.2025.129657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toponym recognition aims to identify place names from natural language texts, which is vital for various applications including geographic information retrieval, emergency response, and natural disaster analysis. Currently, mainstream studies mainly adopt deep learning models for toponym recognition. However, these approaches encounter significant limitations due to the inherent ambiguity, variation, and abbreviation of toponyms. To address these issues, we propose a novel Span Representation Model with R etrieval A ugmentation ( RASpan ) that leverages more accurate span representation and effective external geo-entity information to enhance the semantic representation of place names for improving the performance of toponym recognition. On the one hand, RASpan retrieves diverse geo-entities and concatenates geo-entity knowledge with an input sequence to construct a new prompt sequence. On the other hand, RASpan utilizes the prompt encoder based on the language model to encode this prompt sequence and employs a dedicated span representation module to obtain more accurate span representations. In addition, a new geo-entity prediction task is designed to learn the entire representation of each geo-entity while minimizing noise interference. Experiments on three publicly available datasets demonstrate that our model achieves new state-of-the-art results, highlighting the effectiveness of RASpan in toponym recognition by introducing prior geo-entity knowledge.},
  archive      = {J_ESWA},
  author       = {Hui Wu and Anran Yang and Zhinong Zhong and Ye Wu and Fei Yang and Luo Chen and Ning Jing},
  doi          = {10.1016/j.eswa.2025.129657},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129657},
  shortjournal = {Expert Syst. Appl.},
  title        = {RASpan: Improving toponym recognition through span representation model with retrieval augmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An interpretable automated optimized machine learning for predicting concrete compressive strength. <em>ESWA</em>, <em>298</em>, 129656. (<a href='https://doi.org/10.1016/j.eswa.2025.129656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel, interpretable, and automated machine learning (AutoML) framework for accurately predicting the compressive strength of environmentally sustainable concrete mixtures that incorporate supplementary cementitious materials (SCMs) by addressing the growing need for transparent and data driven tools in structural material design, particularly for concrete mixes enriched with various SCMs. A robust unified dataset of 1,317 samples was curated by integrating peer-reviewed experimental studies for this study. The proposed methodology incorporates feature contribution ranking through mutual information, model screening with AutoML to identify the most effective regression models, Bayesian optimization for fine-tuning model parameters, and interpretability techniques including SHAP and counterfactual analysis. The best performance metrics, in training include R 2 of 0.999, a mean absolute error 0.114, root mean squared error 0.7094, and mean absolute percentage error of 0.51 %, in testing phase R 2 of 0.944, a mean absolute error 3.479, root mean squared error 4.8173, and mean absolute percentage error of 9.86 %. The weakest performance, with a training R 2 of 0.982 and a mean absolute error of 1.911 MPa, root mean squared error 2.7990 and mean absolute percentage error 5.43 %, in testing phase R 2 of 0.786 and a mean absolute error of 5.754 MPa, root mean squared error 9.4336 and mean absolute percentage error 16.16 %. The interpretability analysis values provided insights into the most important features, such as curing time and cement are crucial in predicting the strength. Counterfactual analysis further validated the model by illustrating the significant impact of cement, age and water on concrete strength.},
  archive      = {J_ESWA},
  author       = {Aparna Kamarthi and Baskar Kaliyamoorthy},
  doi          = {10.1016/j.eswa.2025.129656},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129656},
  shortjournal = {Expert Syst. Appl.},
  title        = {An interpretable automated optimized machine learning for predicting concrete compressive strength},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT. <em>ESWA</em>, <em>298</em>, 129655. (<a href='https://doi.org/10.1016/j.eswa.2025.129655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI paraphrased text can be used for copyright infringement and the AI paraphrased content can deprive substantial revenue from original content creators. Despite this recent surge of malicious use of generative AI, there are few academic publications that research this threat. In this article, we demonstrate the ability of pattern-based similarity detection for AI paraphrased news recognition. We propose an algorithmic scheme, which is not limited to detect whether an article is an AI paraphrase, but, more importantly, to identify that the source of infringement is the ChatGPT. The proposed method is tested with a benchmark dataset specifically created for this task that incorporates real articles from BBC, incorporating a total of 2,224 articles across five different news categories, as well as 2,224 paraphrased articles created with ChatGPT. Results show that our pattern similarity-based method, that makes no use of deep learning, can detect ChatGPT assisted paraphrased articles at percentages 96.23% for accuracy, 96.25 for precision, 96.21% for sensitivity, 96.25% for specificity and 96.23% for F1 statistic.},
  archive      = {J_ESWA},
  author       = {Konstantinos F. Xylogiannopoulos and Petros Xanthopoulos and Panagiotis Karampelas and Georgios A. Bakamitsos},
  doi          = {10.1016/j.eswa.2025.129655},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129655},
  shortjournal = {Expert Syst. Appl.},
  title        = {The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition. <em>ESWA</em>, <em>298</em>, 129654. (<a href='https://doi.org/10.1016/j.eswa.2025.129654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant progress has been made in emotion recognition research based on electroencephalogram (EEG) signals. However, existing methods face two key limitations: on one hand, the reliance on fixed physical connections or static topological relationships makes it difficult to effectively represent the dynamic non-Euclidean spatial characteristics between EEG electrodes; on the other hand, spatiotemporal feature extraction is often conducted independently. This lack of a collaborative mechanism for spatiotemporal features results in insufficient fine-grained emotional representation capability. To address these issues, a dynamic collaborative evolutionary network (DCENet) is proposed based on graph-aware enhancement and global convolutional Transformer for EEG emotion recognition. DCENet constructs the causal relationship between electrodes by constructing the graph-aware enhancement (GAE) module, obtains spatial features with the causal relationship, and enhances key features. At the same time, DCENet constructs the global convolutional Transformer (GCT) module, which utilizes the global modeling advantage of the Transformer and the local perception ability of the convolutional operation to capture the temporal features with different scales. In addition, DCENet adaptively fuses temporal and spatial features through the local differential fusion (LDF) module to achieve cross-domain feature alignment and feature alignment of emotion categories to collaboratively evolve emotion representation features with more fine-grained information. This paper conducts experiments on the SEED, SEED-IV, and MPED datasets to validate the effectiveness of DCENet. The experimental results show that the model achieves cross-subject average accuracies of 87.55 %, 73.04 %, and 27.72 % on SEED, SEED-IV, and MPED, respectively, outperforming the state-of-the-art methods. The source code is publicly available at: https://github.com/cvmdsp/DCENet .},
  archive      = {J_ESWA},
  author       = {Shuaiqi Liu and Zhihui Gu and Yuan Zhang and Yanling An and Shuhuan Zhao and Bing Li and Yudong Zhang},
  doi          = {10.1016/j.eswa.2025.129654},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129654},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trust in recommender systems: A survey. <em>ESWA</em>, <em>298</em>, 129653. (<a href='https://doi.org/10.1016/j.eswa.2025.129653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust-based recommender systems incorporate interpersonal trust relationships into the recommendation process, operating on the principle that users are more likely to accept suggestions from people they trust. Empirical studies have shown that trust-aware approaches often deliver more accurate recommendations than their trust-unaware counterparts. In this comprehensive, up-to-date survey, we analyze a variety of trust-based recommendation methods, categorize different trust inference techniques, and examine how trust is integrated into recommendation algorithms. We then organize the investigated approaches according to a clear taxonomy, explore their underlying concepts, and highlight the key challenges and open issues that remain in the field.},
  archive      = {J_ESWA},
  author       = {Imane Akdim and Loubna Mekouar and Youssef Iraqi},
  doi          = {10.1016/j.eswa.2025.129653},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129653},
  shortjournal = {Expert Syst. Appl.},
  title        = {Trust in recommender systems: A survey},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Composite human activity recognition utilizing knowledge distillation and sensor fusion focusing on resource constrained microcontrollers. <em>ESWA</em>, <em>298</em>, 129652. (<a href='https://doi.org/10.1016/j.eswa.2025.129652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a cost-effective, low-computation system for composite Human Activity Recognition (HAR) that leverages knowledge-distilled neural networks on a Microcontroller Unit (MCU) to minimize reliance on cloud processing. A key contribution of this work is the investigation of plantar pressure sensor data within a knowledge distillation framework, addressing a notable gap in the existing literature. The proposed solution centers around the ESP32-S3 DevKit C1, equipped with a dual-core 240 MHz Tensilica chip, 320 KiB of usable Static Random Access Memory (SRAM), and built-in Wi-Fi and Bluetooth. Significantly, both the teacher and the student models surpass existing state-of-the-art methods, achieving F1-scores of 99.33 %, 98.36 %, and 97.68 % respectively, in classifying a comprehensive set of 21 activities (15 composite and 6 simple). The distilled student models demonstrate remarkable efficiency, with execution times of 1.83 and 0.64 s, memory footprints of only 62 KB and 82 KB, and flash memory usage of approximately 209 KB and 127 KB, while maintaining low power consumption of 210 mW and 215 mW, respectively. Furthermore, we have developed an end-to-end prototype that integrates the ESP32-S3 with a WitMotion Inertial Measurement Unit (IMU) sensor. This system autonomously manages data acquisition, feature extraction, and inference in under 7 s with a total power consumption of approximately 295 mW.},
  archive      = {J_ESWA},
  author       = {Athar Noor Mohammad Rafee and John Clear and Jannatun Noor},
  doi          = {10.1016/j.eswa.2025.129652},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129652},
  shortjournal = {Expert Syst. Appl.},
  title        = {Composite human activity recognition utilizing knowledge distillation and sensor fusion focusing on resource constrained microcontrollers},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation. <em>ESWA</em>, <em>298</em>, 129651. (<a href='https://doi.org/10.1016/j.eswa.2025.129651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synthesis of cross-modal medical images plays a vital role in bridging diagnostic gaps between imaging modalities such as CT, MRI, and PET. This integration enables a more comprehensive evaluation of a patient’s condition, improving diagnostic accuracy and aiding clinical decision-making. However, the performance of conditional denoising diffusion probabilistic models is often hindered by pronounced structural and intensity discrepancies between modalities, as well as the inherently slow nature of the diffusion process. To address these challenges, this paper proposes Wavelet-Based Diffusion in the Difference Domain for Cross-Modality Medical Image Generation (Med-D3CG), a novel framework that transforms the synthesis process by emphasizing the difference domain. Instead of directly generating target images like conventional methods, Med-D3CG models the residual information between conditioned and target images. This strategy allows the framework to accurately capture essential structural and intensity variations between modalities, leading to more precise and realistic image synthesis. Additionally, Med-D3CG integrates the Discrete Wavelet Transform (DWT) to improve efficiency, accelerating the diffusion process while maintaining high image fidelity. On SynthRAD2023 and HMIFD datasets, state-of-the-art performance is achieved on pelvis and HMIFD using Med-D3CG , with the best Learned Perceptual Image Patch Similarity (LPIPS) and competitive FID observed on brain. Code and pretrained models are provided at https://github.com/ZgzTTTer/Med-D3CG .},
  archive      = {J_ESWA},
  author       = {Guangzhen Zhu and Midi Wan and Wenming Cao and Zhiwen Yu and Jin Hu and Bing Li and Xiaotao Fan},
  doi          = {10.1016/j.eswa.2025.129651},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129651},
  shortjournal = {Expert Syst. Appl.},
  title        = {Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search. <em>ESWA</em>, <em>298</em>, 129650. (<a href='https://doi.org/10.1016/j.eswa.2025.129650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set model(NRSM) has shown its powerful capacity in feature selection. However, a challenge still exists in describing the diversity between the attributes deeply while avoiding the impact caused by the neighborhood parameters. To address this problem, in this paper, we propose a two-stage feature selection by utilizing a three-way adaptive characteristic measure and an optimal combination search. First, we define a fitness function for applying the Stochastic Fractal Search(SFS) to design an novel adaptive neighborhood rough set model(ANRSM). To better utilize the construction characteristic of the adaptive model and reduce the computational cost, the lower and upper approximations of the SFS-based ANRSM are redefined through the fitness function. Second, based on the two approximations, we analyze the fitness function thresholds that can partition the universe into three regions and design the three-way adaptive neighborhood characteristic regions, which provide a more direct classification of samples without the inclusion and union operations. Third, we design different measures for the samples in diverse regions based on their corresponding characteristic. Afterward, a three-way adaptive characteristic measure is designed by integrating the three measures to evaluate the uncertainty of attributes. Then, we apply the measure to design a feature selection approach with greedy search. Considering that the greedy strategy may output redundant attributes, we introduce an optimal combination search approach through a novel wrapper technology to explore the potential optimal feature combinations. Compared with nine algorithms on fourteen public datasets, the experimental results show the effectiveness of our algorithm.},
  archive      = {J_ESWA},
  author       = {Bowen Lin and Duoqian Miao and Caihui Liu and Hongyun Zhang and Ruizhi Wang and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.129650},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129650},
  shortjournal = {Expert Syst. Appl.},
  title        = {Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm. <em>ESWA</em>, <em>298</em>, 129648. (<a href='https://doi.org/10.1016/j.eswa.2025.129648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering leverages prior information to improve algorithm performance and is widely valued by researchers. This paper analyzes the traditional semi-supervised fuzzy C-means (SFCM) objective function, noting that as a labeled sample’s membership degree aligns with its prior information, the impact of this information on the deviation constraint weakens. This reduces its supervisory effect on optimizing the membership partition matrix, especially with a large regularization factor. To overcome this, we propose a novel semi-supervised fuzzy C-means method based on an asymmetric deviation constraint and develop a two-level alternating iterative optimization algorithm, supported by theoretical convergence analysis using Zangwill’s theorem and the bordered Hessian matrix. To address the slow convergence and high computational cost typical of semi-supervised fuzzy clustering, we further enhance the algorithm with affinity filtering and a membership scaling scheme for improved efficiency. Experimental results demonstrate that our methods significantly outperform existing state-of-the-art techniques, advancing semi-supervised fuzzy C-means clustering.},
  archive      = {J_ESWA},
  author       = {Chengmao Wu and Jun Hou},
  doi          = {10.1016/j.eswa.2025.129648},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129648},
  shortjournal = {Expert Syst. Appl.},
  title        = {New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BayesAHDD: A new bayesian rule-based adaptive hypersphere data description for few-shot one-class classification. <em>ESWA</em>, <em>298</em>, 129647. (<a href='https://doi.org/10.1016/j.eswa.2025.129647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot one-class classification (FS-OCC) is a challenging classification problem that involves learning from a very limited number of training samples, all from a single class. Recently, several data description methods have been proposed to address the FS-OCC problem. Unlike conventional one-class classification problems, the few-shot setting requires the model to generalize to novel tasks with previously unseen positive classes. Most existing methods learn decision boundaries in the feature space without explicitly modeling the underlying data distributions, which limits the generalization ability of the learned representations. To address this issue, we propose Bayesian Rule-based Adaptive Hypersphere Data Description (BayesAHDD), a probabilistic framework that represents data with multivariate Gaussian distributions and performs classification according to the Bayes decision rule. Based on the assumption that negative samples are more dispersed in the feature space, BayesAHDD models the negative class by scaling the positive class variance vector element-wise using a learnable vector. To address the challenges of exploding gradients and numerical overflow, we impose a lower bound on the positive class variance vector and introduce a trainable parameter that integrates the class prior probability ratio with the normalization constants of the Gaussian class-conditional densities. Experimental results on both benchmark and domain-specific datasets show that BayesAHDD consistently outperforms existing baselines and state-of-the-art FS-OCC methods. Moreover, quantitative analysis demonstrates that the learned feature representations exhibit superior discriminative ability compared to those produced by previous approaches.},
  archive      = {J_ESWA},
  author       = {Yuchen Ren and Xiabi Liu and Yan Pei and Yunlong Li and Yongxia Wei},
  doi          = {10.1016/j.eswa.2025.129647},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129647},
  shortjournal = {Expert Syst. Appl.},
  title        = {BayesAHDD: A new bayesian rule-based adaptive hypersphere data description for few-shot one-class classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A network selection algorithm for space-air-ground integrated network based on location prediction model and multi-attribute decision making. <em>ESWA</em>, <em>298</em>, 129646. (<a href='https://doi.org/10.1016/j.eswa.2025.129646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an indispensable component of 5G and even the future 6G networks, the Space-Air-Ground Integrated Network (SAGIN) is envisioned to provide ubiquitous network connectivity and services by integrating satellite, aerial, and terrestrial networks. However, due to the frequent network selection of in-vehicle terminals, the user’s Quality of Service (QoS) can significantly deteriorate. To address this issue, a network selection algorithm based on terminal location prediction has been proposed. Firstly, we enhanced the Particle Swarm Optimization (PSO) algorithm to optimize the hyper-parameters of the Long Short-Term Memory (LSTM) network, thereby improving the accuracy of terminal location prediction. After constructing the network sets of the current terminal position and the predicted position, respectively, we designed a network selection judgment mechanism with a dynamically adjustable switching threshold based on Fuzzy Logic and K-Means theory. Finally, through the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) algorithm, we have achieved robust network selection in fast-moving scenarios. The simulation results show that the proposed algorithm can adaptively adjust the switching threshold and provide precise positions. Compared to existing algorithms, it can significantly reduce the number of candidate networks and the number of selections, thereby reducing the computational load and increasing the throughput of users.},
  archive      = {J_ESWA},
  author       = {Jianli Xie and Weicheng Pan and Lei Wu and Zishan Wu},
  doi          = {10.1016/j.eswa.2025.129646},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129646},
  shortjournal = {Expert Syst. Appl.},
  title        = {A network selection algorithm for space-air-ground integrated network based on location prediction model and multi-attribute decision making},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anomaly detection based on graph neural networks incorporating with domain knowledge for industrial cyber-physical systems. <em>ESWA</em>, <em>298</em>, 129645. (<a href='https://doi.org/10.1016/j.eswa.2025.129645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective anomaly detection heavily relies on accurately modeling the normal behavior of the industrial cyber-physical systems (ICPSs). Current popular data-driven black-box methods’ performance depends on the quantity and quality of data from the ICPS, rather than integrating with the intrinsic characteristics of the system, such as mass conservation and structural dependencies of industrial processes. The data used to train these models often fails to cover all operating conditions of ICPSs, resulting in a distributional mismatch between training and testing data. This limitation significantly reduces the generalization capability of trained data-driven models for detecting anomalies under unseen and unknown operational conditions. Meanwhile, constructing well-generalized behavior models using white-box mechanism models (MM)–which represent the internal behavior of controllers and physical processes using first-principles equations or physical laws, such as conservation principles and kinetic dynamics–is not always feasible in real-world industrial applications. To address this issue, this paper presents a novel anomaly detection approach employing a domain knowledge-embedded hybrid graph neural network (HGNN) that integrates control, physical, and structural characteristics of ICPSs into a data-driven modeling framework. It establishes a domain knowledge-based MM to predict the behavior of controllers and physical processes, and utilizes a HGNN model with embedded state topology and spatial distribution knowledge to compensate for the predictive error of MM, forming a hybrid model called mechanism-embedded HGNN (MEHGNN). This model can detect anomalies in unknown operational conditions by analyzing the predictive error of MEHGNN. In the experiments, MEHGNN raises the detection accuracy of GNNs from 36.6 %–82.4 % to 79.4 %–96.3 % under distribution shift scenarios, achieving the best detection performance among all compared methods.},
  archive      = {J_ESWA},
  author       = {Xin Du and Chunjie Zhou and Yu-Chu Tian and Bo Xu},
  doi          = {10.1016/j.eswa.2025.129645},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129645},
  shortjournal = {Expert Syst. Appl.},
  title        = {Anomaly detection based on graph neural networks incorporating with domain knowledge for industrial cyber-physical systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm. <em>ESWA</em>, <em>298</em>, 129644. (<a href='https://doi.org/10.1016/j.eswa.2025.129644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In screw whirling milling, the relationship between machining quality and processing parameters exhibits highly nonlinear characteristics. The traditional multiple regression models may not be able to capture this complex relationship accurately. Therefore, it is necessary to consider more flexible and applicable algorithms to establish their connections and optimize processing parameters. It can improve the accuracy and reliability of products, and provide more scientific method guidance for screw whirling milling processing. The originality of this article lies in proposing an adaptive dynamic optimization hybrid model. This model combines improved sparrow search algorithm optimized backpropagation (ISSA-BP) and non-dominated sorting genetic algorithm (NSGA-III). It can effectively adapt to dynamic data and find the optimal balance point among multiple objectives to better predict and optimize responses (cutting force, vibration, roughness, and residual compressive stress) in screw whirling milling. Firstly, a suitable network structure is identified by comparing the effects of five improvement strategies, population size, and the ratio of producers to scouters on the sparrow search algorithm. Then, an ISSA-BP prediction model is developed for four responses based on this structure. On this basis, the superiority of the established ISSA-BP model is verified by comparing prediction performance of five algorithms, and the relative prediction errors are all within 2%. The R 2 values of the models are all above 0.99, and they also perform well in indicators such as MAE (Mean Absolute Error), MSE (Mean Squared Error), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Squared Error). Then, ISSA-BP model is encapsulated and embedded into the optimization algorithm as the fitness function of NSGA-III. Finally, with the processing parameters of whirling milling as constraints, the NSGA-III algorithm is used to solve the proposed model and obtain the Pareto optimal solution set. Choosing appropriate processing parameters according to different needs in actual machining can help improve the quality and efficiency of screw machining.},
  archive      = {J_ESWA},
  author       = {Chao Liu and Hao Ding and Juanjuan Zheng and Yan He and Shaofu Huang and Junbo Tuo and Zuqing Luo and Gang Shen},
  doi          = {10.1016/j.eswa.2025.129644},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129644},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of large language models for data challenges in graphs. <em>ESWA</em>, <em>298</em>, 129643. (<a href='https://doi.org/10.1016/j.eswa.2025.129643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. While graph learning has achieved remarkable progress, real-world graph data presents a number of challenges that significantly hinder the learning process. In this survey, we focus on four fundamental data-centric challenges: (1) Incompleteness , real-world graphs have missing nodes, edges, or attributes; (2) Imbalance , the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity , graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability , graphs evolve over time in unpredictable ways. Recently, Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey focuses on how LLMs can address four fundamental data-centric challenges in graph-structured data, thereby improving the effectiveness of graph learning. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges: https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges .},
  archive      = {J_ESWA},
  author       = {Mengran Li and Pengyu Zhang and Wenbin Xing and Yijia Zheng and Klim Zaporojets and Junzhou Chen and Ronghui Zhang and Yong Zhang and Siyuan Gong and Jia Hu and Xiaolei Ma and Zhiyuan Liu and Paul Groth and Marcel Worring},
  doi          = {10.1016/j.eswa.2025.129643},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129643},
  shortjournal = {Expert Syst. Appl.},
  title        = {A survey of large language models for data challenges in graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129642. (<a href='https://doi.org/10.1016/j.eswa.2025.129642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic multi-objective optimization problems, effectively predicting and tracking the Pareto optimal front (POF) under environmental changes has been one of the core challenges. In this paper, we propose a region-aware prediction strategy based on shared points and multiple scales (RADMOEA) that combines global and local characteristics, aiming to enhance the algorithm’s ability to sense and adapt to POF. Firstly, the center-point movement strategy is used to move the non-dominated solution set from the previous moment to obtain the non-dominated solution set after the movement. The actual non-dominated solution set at the current moment and the non-dominated solution set after the movement share points in the objective space, and these shared points divide the non-dominated solution set at the current moment into several subregions. Within each region, all individuals are appropriately rescaled, and a local coordinate system is established. Then, within the local coordinate system, each individual is associated with the nearest post-movement non-dominated individual. Finally, new populations adapted to environmental changes are generated by combining centroid movement directions, Gaussian perturbations, and multi-scale individual association relationships. The proposed strategy is compared with six advanced algorithms, and the experimental results demonstrate that RADMOEA is effective in tracking the POF under dynamic environments.},
  archive      = {J_ESWA},
  author       = {Yaru Hu and Sitong Wang and Junwei Ou and Zhenlin Mei and Juan Zou and Shengxiang Yang},
  doi          = {10.1016/j.eswa.2025.129642},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129642},
  shortjournal = {Expert Syst. Appl.},
  title        = {Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion. <em>ESWA</em>, <em>298</em>, 129641. (<a href='https://doi.org/10.1016/j.eswa.2025.129641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passive microwave remote sensing plays a vital role in Earth observation, with applications in soil moisture, ocean salinity, and atmospheric monitoring. However, improving spatial resolution at low frequencies remains challenging. Recently, combining multiple small antenna arrays into a larger one has emerged as a technological approach to enhance spatial resolution. Nevertheless, aperture synthetic radiometers formed by such combinations usually consist of non-uniform antenna arrays (one-dimensional, two-dimensional, or three-dimensional). Compared with regular antenna arrays, they complicate the inversion of brightness temperature (BT) images. This paper proposes NASRT, a transformer-based inversion method designed for multi-dimensional non-uniform ASRs. The network extracts and fuses spectral and UVW spatial distribution features from the visibility function (VF), and introduces a learnable position weight matrix during training to capture spatial information of the non-uniform array. Through supervised learning, NASRT effectively maps the VF to BT images. Simulations across 1-D, 2-D, and 3-D NASR scenes demonstrate that NASRT achieves higher accuracy and stability than traditional methods. In a 1-D NASR indoor experiment, the proposed method also shows improved inversion accuracy and lower sidelobes, validating its effectiveness.},
  archive      = {J_ESWA},
  author       = {Jian Dong and Jiaxin Li and Chengwang Xiao and Rigeng Wu and Haofeng Dou and Wenjing Wang and Yuanchao Wu and Liangbing Chen},
  doi          = {10.1016/j.eswa.2025.129641},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129641},
  shortjournal = {Expert Syst. Appl.},
  title        = {A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OceanAgent: A small-scale multi-modal assistant for ocean exploration. <em>ESWA</em>, <em>298</em>, 129640. (<a href='https://doi.org/10.1016/j.eswa.2025.129640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of key information and the subsequent generation of actionable knowledge from multimodal data are critical for ocean exploration. Traditional knowledge generation methods rely heavily on expert experience and are labor-intensive. Recently, Large Multimodal Models (LMMs) have shown exceptional capabilities for knowledge generation from multimodal data in many complex tasks. These models also have potential to assist knowledge mining in ocean exploration. However, two major challenges faced by the LMMs when used in ocean exploration include the scarcity of ocean instruction-following data and the degradation of underwater visual environments. In this paper, a small-scale LMM for ocean exploration, named the OceanAgent, is designed. First, a swarm-intelligence-based leaderless multi-agent collaboration framework is proposed to generate visual instruction-following data. Subsequently, we present a visual-language connector to simultaneously extract multi-scale features. It is formed by integrating a multi-scale residual network with a multi-layer perceptron, which can enhance the model’s performance on severely low-quality images. Experiments show that the proposed method for constructing visual instruction-following datasets improves both the textual quality and visual dialogue. When severely degraded ocean visual data are processed using the trained OceanAgent, the image description accuracy and image comprehension are improved by 23.6 % and 21.6 %, respectively, compared to existing models. Additionally, the model demonstrates superior domain expertise, with a 95.7 % win rate in dialogue quality assessments.},
  archive      = {J_ESWA},
  author       = {Yun Xu and Yue Liu and Junpeng Shang and Jianmin Lin and Dongfang Ma},
  doi          = {10.1016/j.eswa.2025.129640},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129640},
  shortjournal = {Expert Syst. Appl.},
  title        = {OceanAgent: A small-scale multi-modal assistant for ocean exploration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs. <em>ESWA</em>, <em>298</em>, 129639. (<a href='https://doi.org/10.1016/j.eswa.2025.129639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection(GAD) plays a critical role in fields such as fraud detection and network security. Although existing graph anomaly detection methods have achieved promising performance, most graph neural networks (GNNs) rely on the homophily assumption, which presumes that connected nodes share similar labels. However, real-world graphs frequently exhibit pronounced heterophily. Owing to class imbalance, normal nodes tend to have lower heterophily while anomalous nodes display higher heterophily. Furthermore, feature inconsistency induced by node camouflage exacerbates the detection challenge, rendering many existing approaches ineffective. To overcome these limitations, we propose SPS-GAD, a spectral-spatial graph structure learning framework specifically designed for detecting anomalous nodes in heterophilic graphs. First, to alleviate the feature inconsistency resulting from node camouflage, we develop a node reconstruction module that learns intermediate node representations to mitigate camouflage-induced bias, and applies spectral filters to extract the graph’s inherent structural features. Second, to address the heterophily disparities arising from class imbalance, we introduce a subgraph-type-aware spectral filtering module that leverages edge scores generated by an edge partitioner to segregate the graph into homophilic, ambiguous, and heterophilic subgraphs. Distinct spectral filters are subsequently applied to capture features across various frequency bands. Additionally, we integrate a neighbor-type-aware graph attention module that employs edge scores within an attention mechanism to guide the feature aggregation process, thereby enhancing spatial representation learning. Experimental evaluations on six real-world datasets reveal that SPS-GAD significantly outperforms all baseline methods in key metrics such as F1-Macro and AUC, thereby confirming its effectiveness in graph anomaly detection. The source code is publicly available at https://github.com/cozy24/SPS-GAD .},
  archive      = {J_ESWA},
  author       = {Chen Zhu and Yaying Zhang},
  doi          = {10.1016/j.eswa.2025.129639},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129639},
  shortjournal = {Expert Syst. Appl.},
  title        = {SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient vision transformer-based 3D adaptive residual densenet with gated recurrent unit for early detection of alzheimer disease from magnetic resonance imaging. <em>ESWA</em>, <em>298</em>, 129638. (<a href='https://doi.org/10.1016/j.eswa.2025.129638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise identification of Alzheimer’s disease (AD) holds a crucial position in patient healthcare, particularly in the early stages. This early detection is essential, as it allows patients to understand the severity of the disease and take preventive measures before irreversible brain damage occurs. Although recent studies have harnessed machine learning techniques for Computer-Aided Diagnosis (CAD) of AD, many of these research efforts have encountered limitations in diagnostic performance. In this research, a novel AD detection system using Magnetic Resonance Imaging (MRI) is developed to identify subtle brain changes at an early stage through deep learning strategies. The goal is to reduce the risk for individuals facing challenges such as aging and brain-related diseases. The MRI images were obtained from the internet. The detection phase begins by receiving the MRI images. A Vision Transformer-based 3D Adaptive Residual DenseNet combined with a Gated Recurrent Unit (VARD-GRU) architecture is employed for effective AD identification. Here, the model parameters are optimized using the proposed Fitness-based Walrus Optimization Algorithm (FWOA). The AD detection system’s performance is evaluated against several existing frameworks using validation metrics to assess its effectiveness. The accuracy of the developed FWOA-VARD-GRU model is 94.11%. The results demonstrate that the FWOA-VARD-GRU model significantly enhances diagnostic accuracy, outperforming comparable methods. The model’s effectiveness confirms its strong capability in detecting early-stage AD. This system offers a promising approach to reduce risks for individuals affected by aging and neurological conditions by enabling timely and accurate detection.},
  archive      = {J_ESWA},
  author       = {Dr. A. Hemlathadhevi and Indumathy Paranthaman and Moorthy Agoramoorthy and Dr. Hari Kumar Palani},
  doi          = {10.1016/j.eswa.2025.129638},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129638},
  shortjournal = {Expert Syst. Appl.},
  title        = {An efficient vision transformer-based 3D adaptive residual densenet with gated recurrent unit for early detection of alzheimer disease from magnetic resonance imaging},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pareto optimization of two-agent scheduling on parallel batch machines. <em>ESWA</em>, <em>298</em>, 129637. (<a href='https://doi.org/10.1016/j.eswa.2025.129637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a Pareto optimization problem of scheduling jobs of two competing agents on parallel batch machines. The jobs have equal processing times and non-identical job sizes. The objective is to find Pareto optimality and the corresponding schedules for minimizing both agents’ makespans. We analyze and identify an approximate Pareto region with a guarantee of 2-approximate Pareto optimal. We propose an integrated algorithm to find the approximate Pareto optimal points. Our computational study shows that the proposed algorithm outperforms the widely used non-dominated sorting genetic algorithm (NSGA-II), and that the obtained approximate Pareto optimal front is very close to the Pareto optimal front.},
  archive      = {J_ESWA},
  author       = {Cui-Lin Zhang and Guo-Qiang Fan},
  doi          = {10.1016/j.eswa.2025.129637},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129637},
  shortjournal = {Expert Syst. Appl.},
  title        = {Pareto optimization of two-agent scheduling on parallel batch machines},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach. <em>ESWA</em>, <em>298</em>, 129636. (<a href='https://doi.org/10.1016/j.eswa.2025.129636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the dual pressure of explosive growth in cross-border e-commerce demand and increasing timeliness requirements from overseas customers, cross-border logistics service providers are compelled to establish logistics facilities and deploy fleets across multiple regions to ensure rapid response. However, during freight transportation, the lack of effective management over these complex and heterogeneous fleets—particularly in terms of fleet composition and routing decisions—has led to high transportation costs and low operational efficiency. This study is grounded in the practical operational context of cross-border logistics in the Guangdong–Hong Kong–Macau Greater Bay Area and models a multi-level, multi-node cross-border transportation network. To minimize the overall operational cost, the problem is addressed from two interrelated decision-making perspectives: fleet composition at the strategic level and routing planning at the operational level. Thus, a bi-level programming model is proposed to systematically capture the hierarchical structure and the logical relationship between these two decision layers. Furthermore, the model incorporates cost differences among trucks with different functional capabilities to reflect the significant disparity in logistics cost structures between domestic and overseas operations. To address the above multi-objective mixed-integer linear programming (MILP) problem, a tailored Non-dominated Sorting Genetic Algorithm II (MNSGA-II) is developed. Several key components of the algorithm are modified and enhanced to improve its search efficiency and solution quality in handling the problem’s complexity. Comparative experiments against classical algorithms demonstrate the superior solution quality and robustness of the proposed approach. The influence of cost differentials on composition and scheduling decisions is further analyzed, providing practical insights for the strategic planning of cross-border logistics systems.},
  archive      = {J_ESWA},
  author       = {Zhi Tang and Ting Qu and Yanghua Pan and George Q. Huang},
  doi          = {10.1016/j.eswa.2025.129636},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129636},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems. <em>ESWA</em>, <em>298</em>, 129635. (<a href='https://doi.org/10.1016/j.eswa.2025.129635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) has long been a fundamental challenge in the field of optimization. Due to the existence of multiple roots, such problems often exhibit complex and multimodal characteristics. Although numerous differential evolution-based algorithms have been developed to solve NESs, most of them employ only a single mutation operator, which is not adaptable to different problem scenarios. To this end, a diversity-based niching differential evolution with neighborhood competition (DNDE) is proposed to solve NESs. First, a control mechanism that takes into account population diversity and the evolutionary stage is proposed to adaptively assign appropriate mutation strategies to each subpopulation (niche), thereby enhancing the efficiency of root-finding. Second, a neighborhood priority competition mechanism is proposed to reduce cross-peak competition between populations, which ensures local convergence while improving global convergence. Finally, a reinitialization strategy based on opposition learning is introduced to guide the population toward more promising areas of the search space. Experimental results on 18 complex NESs and two real-world engineering problems show that DNDE outperforms many advanced algorithms in both root rate and success rate, demonstrating its effectiveness and value in practical applications.},
  archive      = {J_ESWA},
  author       = {Jianwei Li and Xinchao Zhao and Lingyu Wu and Yizhan Wu and Lingjuan Ye},
  doi          = {10.1016/j.eswa.2025.129635},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129635},
  shortjournal = {Expert Syst. Appl.},
  title        = {A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ill-posed regions-aware self-supervised stereo matching with left-right consistency. <em>ESWA</em>, <em>298</em>, 129634. (<a href='https://doi.org/10.1016/j.eswa.2025.129634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo matching presents a significant challenge due to the difficulty in accurately matching pixels between two images. These challenging pixels are typically found in ill-posed regions, which include areas with weak or repetitive textures, occlusions, and invisible regions. In recent years, there has been extensive research into stereo matching methods based on deep learning. However, these methods often struggle to accurately handle ill-posed regions, resulting in limited improvements in accuracy. To address this issue, this paper introduces a stereo matching model, IASSM-LRC, that is not constrained by disparity range. This model employs self-attention and cross-attention from the Transformer for dense attention computation and generates an initial disparity map. To effectively manage ill-posed regions, invalid masks are generated using left and right disparity maps. The initial disparity map is then fine-tuned through these invalid masks. IASSM-LRC is trained in an unsupervised manner. Experimental results from multiple different scenes demonstrate that the IASSM-LRC model exhibits strong disparity prediction performance. On KITTI2015, its D1-fg metric is 13.48 %, outperforming both PASM-Net’s 16.36 % and Flow2Stereo’s 14.62 %. The prediction results on the self-built calibration board dataset and Middlebury dataset show that the model has better predictive performance for both textureless and repetitive texture regions and has better generalization performance.This method can improve disparity measurement and depth measurement in binocular universal scenes.},
  archive      = {J_ESWA},
  author       = {Shengwei Yang and Yuehang Wang and Zenghui Li and Shan Zhou and Zheng Wang and Yining Hu and Lizhe Xie},
  doi          = {10.1016/j.eswa.2025.129634},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129634},
  shortjournal = {Expert Syst. Appl.},
  title        = {Ill-posed regions-aware self-supervised stereo matching with left-right consistency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGNet: Texture-enhanced guidance network for RGB-D salient object detection. <em>ESWA</em>, <em>298</em>, 129633. (<a href='https://doi.org/10.1016/j.eswa.2025.129633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection achieves salient region localization in complex scenes by fusing RGB images and depth images. Existing methods typically employ two-stream networks to extract features separately followed by cross-modal fusion. However, differences between heterogeneous modalities can easily lead to feature degradation during cross-modal fusion, while the inherent noise interference in low-quality depth maps may generate cumulative effects during multi-stage propagation, severely constraining detection performance. To address these challenges, this paper proposes a texture-enhanced guided network. The core innovations lie in three aspects: during the feature encoding stage, a texture-enhanced module is constructed to utilize high-frequency texture information from RGB images through attention mechanisms for hierarchical optimization of depth features; in the feature fusion stage, a dual-path adaptive interaction module is designed to establish cross-modal semantic correlations via channel-spatial cooperative driving mechanisms, effectively suppressing redundant feature interference; for the decoding reconstruction stage, a dynamic hierarchical guidance mechanism is proposed to drive progressive calibration of low-level spatial details by high-level semantic features through learnable cross-scale transformation modules. Extensive experiments conducted on five benchmark datasets demonstrate that our method achieves competitive performance compared to other approaches.},
  archive      = {J_ESWA},
  author       = {Xiaogang Song and Hexiang Huang and Qin Zhao and Xinwei Guo and Xinhong Hei},
  doi          = {10.1016/j.eswa.2025.129633},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129633},
  shortjournal = {Expert Syst. Appl.},
  title        = {TGNet: Texture-enhanced guidance network for RGB-D salient object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling. <em>ESWA</em>, <em>298</em>, 129632. (<a href='https://doi.org/10.1016/j.eswa.2025.129632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake, as a generative technology, has opened up new avenues for the development of the film, television, and art industries. However, its abusive use has triggered serious social security threats, such as infringement of portrait rights and the spread of misinformation, which has drawn widespread attention to research on deepfake detection techniques. Current deep learning-based face forgery detection methods face critical challenges: 1) insufficient focus on common forgery traces leads to poor generalization performance on datasets generated by unknown forgery methods; 2) traditional spatio-temporal feature fusion mechanisms struggle to balance the representational weights of spatial details and temporal dynamics, and exhibit inadequate robustness against post-processing operations like compression and cropping. To address these issues, this paper first designs a phase consistency edge artifact mining module is designed to extract common forgery traces from edge textures by leveraging the deep-phase information of images, significantly enhancing the model’s generalization ability. Second, a multi-frame synthesis strategy is designed to effectively integrate spatial and temporal features while balancing the network’s attention to these two feature domains. Third, a visual state-space model based on 3D scanning is designed, which for the first time employs the Mamba model to analyze spatio-temporal forgery patterns, notably improving the robustness of the model against unknown perturbations. Experimental results on standard benchmarks–FaceForensics++, Celeb-DFv2, WildDeepfake and DFDC(Preview)–demonstrate that the proposed method achieves state-of-the-art performance in three core dimensions: detection accuracy, cross-dataset generalization, and robustness against perturbations.},
  archive      = {J_ESWA},
  author       = {Zhong Chen and Siyang Wang and Zuxi Wang},
  doi          = {10.1016/j.eswa.2025.129632},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129632},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LSTT: Long short-term feature enhancement transformer for video small object detection. <em>ESWA</em>, <em>298</em>, 129631. (<a href='https://doi.org/10.1016/j.eswa.2025.129631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging temporal information is crucial for small object detection in videos. Existing methods typically incorporate long-term or short-term temporal information uniformly, neglecting distinct cues from different frames that are essential for small object detection. In this paper, we propose LSTT, an end-to-end multi-frame fusion network that concurrently extracts global scene context from long-term frames and fine-grained appearance and motion cues from short-term frames. First, we introduce a progressive spatiotemporal sampling module that sparsely samples long-range frames and densely samples short-range frames. Second, we design a spatiotemporal alignment encoder module to extract frame-level temporal and spatial pixel features. Finally, We propose a long short-term feature aggregation module that employs a dynamic query generator to derive adaptive queries by implicitly modeling motion relationships among short-term frames, and guides a cascaded fusion of aggregated features from long-term, short-term, and current frames to fuse temporal information. Compared to state-of-the-art methods, our LSTT achieves absolute gains of 1.4 % and 2.1 % in detection precision on VisDrone-VID and UAVDT datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jinsheng Xiao and Wenbo Liu and Ruidi Chen and Yuchen Yan and Wei Yang},
  doi          = {10.1016/j.eswa.2025.129631},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129631},
  shortjournal = {Expert Syst. Appl.},
  title        = {LSTT: Long short-term feature enhancement transformer for video small object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scale-invariant information bottleneck for domain generalization. <em>ESWA</em>, <em>298</em>, 129628. (<a href='https://doi.org/10.1016/j.eswa.2025.129628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One significant challenge in deep learning is the inability to effectively generalize to new data whose distribution differs from that of the training data. Hence, domain generalization has received increasing attention in related fields. Classical methods aim to identify an invariant predictor that can recognize invariant representations across all the training domains. However, these methods limit the model to rely solely on invariant representations, which hinders the learning of important finer details. To address this challenge, we propose a Scale-invariant Information Bottleneck (SIB) method to identify both invariant and scale-invariant features. We subsequently introduce a tractable loss function derived from the variational analysis. This novel method captures more detailed information, including fine textures and unique characteristics, while also eliminating irrelevant or spurious representations by using information bottleneck. Finally, extensive experiments conducted on Rotated MNIST, Colored MNIST, Colored Fashion-MNIST, PACS, Office-Home and Camelyon17-WILDS validate the effectiveness of our SIB method in addressing the domain generalization problems. Notably, our approach outperforms 14 existing methods with an average improvement of 4.74 %. More significantly, it surpasses 6 recent, related methods by an average of 2.21 %. Furthermore, we demonstrate the superiority of our method through the analysis of hidden feature maps and representations.},
  archive      = {J_ESWA},
  author       = {Mengyao Li and Jiangshe Zhang and Chunxia Zhang and Junmin Liu and Lizhen Ji},
  doi          = {10.1016/j.eswa.2025.129628},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129628},
  shortjournal = {Expert Syst. Appl.},
  title        = {Scale-invariant information bottleneck for domain generalization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading. <em>ESWA</em>, <em>298</em>, 129627. (<a href='https://doi.org/10.1016/j.eswa.2025.129627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific and rational prices are determinant for the success of transfer of development rights (TDR). Nevertheless, previous studies largely overlook the multifaceted impacts of risks on pricing, hampering market participation and value revelation. This is especially relevant in the context of China’s inter-provincial construction land quota trading due to its broader scope and dynamic complexities. This study addresses this gap by proposing an integrated decision-making framework to identify TDR risk factors and determine the optimal pricing for TDR under risk sharing. Results show that among 28 identified risk factors across the trading lifecycle, pre-transaction (remediation application and remediation acceptance) risk factors exhibit lower weights (0.017 and 0.218) but demand greater responsibility from quota-sending governments (80.5% and 73.0%); quota transfer risk factors hold the highest weight (0.306), with nearly balanced responsibility sharing between trading parties; while post-transaction (remediation acceptance and post monitoring) risk factors (weighted at 0.215 and 0.218) should be borne mainly by quota-receiving governments (64.1% and 60.9%). A paradigmatic trading case study between Muli and Jiashan Counties empirically reveals that risk factors elevate the optimal price to 621171.89 yuan/mu—24.23% above the current national standard price—by increasing costs, reducing profits, decreasing the supply–demand ratio, and complicating ecological compensation. These findings underscore the importance of risk responsibility management and risk-based pricing mechanisms.},
  archive      = {J_ESWA},
  author       = {Jia-He Zhou and Yu-Jia Wei and Yu-Ming Zhu and Hong-Li Lin},
  doi          = {10.1016/j.eswa.2025.129627},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129627},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent urban on-street parking space management for autonomous vehicles. <em>ESWA</em>, <em>298</em>, 129626. (<a href='https://doi.org/10.1016/j.eswa.2025.129626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curbside lanes are valuable spatial assets, with on-street parking, driving, and other travel modes competing for the space. Autonomous vehicle (AV) transport is expected to park at the curbside for diverse purposes, raising conflicts between driving and parking in the city centre. This study presents a framework to determine on-street parking configurations under different traffic flow and parking supply scenarios for the downtown region. The main contribution stems from solving the macro-level parking configuration problem using customised metaheuristics while considering microscopic AV operations. We tested the framework using a road network comprising a downtown central business district and adjacent urban areas. Among the considered metaheuristics, the discrete particle swarm optimisation outperformed the genetic algorithm in minimising network-level travel delays but at the cost of higher computational time. Three main empirical findings are derived. First , parking lanes are more likely to be assigned to edges in downtown areas or those with lower traffic and driving speeds. Second , high parking supply negatively affects the macroscopic fundamental diagram by increasing congestion and reducing flow efficiency, but such an effect diminishes in congested networks. Third , there exists an optimal parking supply level (40 % in the case study) for most flow rate conditions that can help reduce congestion. The proposed framework was validated through a case study in Midtown Manhattan, New York City. This study provides valuable insights for urban and transportation agencies to manage on-street parking lane assignments to balance parking and driving demands in the AV transport era. The approach has broader applicability as it is transferable to human-driven vehicles and mixed autonomy scenarios.},
  archive      = {J_ESWA},
  author       = {Qiming Ye and Prateek Bansal and Yuxiang Feng and Simon Hu and Panagiotis Angeloudis},
  doi          = {10.1016/j.eswa.2025.129626},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129626},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent urban on-street parking space management for autonomous vehicles},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-session interest extraction for recommendation. <em>ESWA</em>, <em>298</em>, 129625. (<a href='https://doi.org/10.1016/j.eswa.2025.129625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, due to device privacy restrictions, sometimes we can only obtain anonymous users’ interaction behavior within a single session. This type of recommendation is called session-based recommendation. Modeling users’ interest based on session data is one of the core issues in session-based recommendation. However, most existing methods only model users’ interest within individual sessions, neglecting information propagation across sessions. This paper addresses this challenge by designing a contrastive learning module based on clustering to model inter-session information propagation. Specifically, in addition to propagating information within sessions using hypergraph convolution, a cluster algorithm is applied to group all nodes across sessions. Then a contrastive learning loss is designed based on the clustering results to facilitate information propagation across sessions, thereby explicitly modeling the semantic similarity of similar items across different sessions. We call our model Clustering Hypergraph Neural Network (CluHNN). CluHNN explicitly learns the correlation between similar items across different sessions, improving the quality of item representations and, consequently, yielding better interest representations through cross-session information propagation. Experimental results on two real-world datasets show the effectiveness of the proposed CluHNN. For example, in terms of MRR@20, CluHNN achieves significant improvements of 1.3 % and 2.0 % relative gains over the strongest baseline, respectively.},
  archive      = {J_ESWA},
  author       = {Jin Jin and Chaoqun Li and Liangxiao Jiang},
  doi          = {10.1016/j.eswa.2025.129625},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129625},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-session interest extraction for recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images. <em>ESWA</em>, <em>298</em>, 129624. (<a href='https://doi.org/10.1016/j.eswa.2025.129624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a burgeoning theme in optical remote sensing image (ORSI) analysis, salient object detection (SOD) plays a vital role in traffic monitoring, agriculture, disaster management, and other fields. However, the existing ORSI-SOD methods are all single-modal (RGB images primarily), which suffer from performance drop when facing complex scenes (e.g., intricate backgrounds, low contrast scenes, and similar objects). To address this challenge, we introduce estimated depth map to complement RGB image in ORSI-SOD for the first time, which provides 3D geometric cues to improve detection accuracy in complex scenes, thus advancing ORSI-SOD from single-modal to multi-modal. Furthermore, we design a novel pretraining framework: multi-modal reconstructed image pretraining (MMRIP) to pretrain SOD model in multi-modal ORSI-SOD. MMRIP initially utilizes a masked autoencoder (MAE) to restore the masked RGB image; subsequently, it feeds the restored RGB image and clean depth map to the SOD model to generate the saliency map, which can help SOD model more effectively integrate cross modal information and extract better feature. Besides, we present a simple RGB-D SOD model, namely SimSOD, which is pretrained by MMRIP for ORSI-SOD. SimSOD has two major components: DFormer (encoder) and MLP head (decoder). Specifically, we first input RGB image and depth data into the encoder to generate four multi-scale features, then use the decoder to fuse these features and yield the prediction result. Without bells and whistles, our proposed method outperforms the state-of-the-art methods on three public ORSI-SOD datasets. The code can be accessed at: https://github.com/Voruarn/MMRIP .},
  archive      = {J_ESWA},
  author       = {Yuxiang Fu and Wei Fang},
  doi          = {10.1016/j.eswa.2025.129624},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129624},
  shortjournal = {Expert Syst. Appl.},
  title        = {Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An approach for linking dynamic network information models based on ontology matching. <em>ESWA</em>, <em>298</em>, 129622. (<a href='https://doi.org/10.1016/j.eswa.2025.129622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic network information models are typically heterogeneous and isolated systems that impede effective interoperability, significantly hindering end-to-end service integration and data sharing across network segments. To address this challenge, we propose a new approach for linking heterogeneous dynamic network models based on ontology matching, which can be applied in various domains utilizing dynamic networks. For ontologies matching we use different existing duplicate detection algorithms but we reduce the computational complexity of ontology matching due to splitting initial set of matched entities into a number of subsets using domain knowledge. Using telecommunications as case study, we represent operator networks as knowledge graphs and match them with standardized model ontologies using business process context to create an Extended Operator Network Ontology. Our approach ensures linking of dynamic network models used in operators information systems that is of primary importance for implementing complex business processes, and providing integrated services while maintaining existing models.},
  archive      = {J_ESWA},
  author       = {Tianxing Man and Igor Kulikov and Jiafeng Yang and Nataly Zhukova},
  doi          = {10.1016/j.eswa.2025.129622},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129622},
  shortjournal = {Expert Syst. Appl.},
  title        = {An approach for linking dynamic network information models based on ontology matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem. <em>ESWA</em>, <em>298</em>, 129621. (<a href='https://doi.org/10.1016/j.eswa.2025.129621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional irregular layout problem, which involves placing convex or non-convex components within a confined boundary without overlaps, is NP-complete and widely encountered in industrial applications such as glass cutting, garment manufacturing, and packaging. To overcome the limitations of existing methods in computational efficiency and material utilization, we propose a new hybrid algorithm IDE-V-NFP-MIP: (1) An improved differential evolution (IDE) algorithm combines the memory mechanism to guide the crossover and mutation operations; (2) A vector No-Fit Polygon (V-NFP) algorithm effectively handles complex geometric constraints, including voids and degradation; (3) A mixed-integer programming (MIP) model ensures accurate layout and non-overlapping constraints. Experimental results demonstrate superior performance: IDE ranked first in CEC2022 Friedman tests, while practical applications show 22.10% reduction in board length and 41.47% improvement in filling rate. The framework successfully handles real-world garment cutting applications and large-scale problems up to 1,280 polygons, demonstrating significant improvements in both computational efficiency and solution quality for industrial layout optimization. The source code for the algorithm is available at https://github.com/xhj-6/IDE-V-NFP-MIP .},
  archive      = {J_ESWA},
  author       = {Huijie Xu and Qifang Luo and Yongquan Zhou},
  doi          = {10.1016/j.eswa.2025.129621},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129621},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach. <em>ESWA</em>, <em>298</em>, 129620. (<a href='https://doi.org/10.1016/j.eswa.2025.129620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of smart grid security, the precise identification of False Data Injection Attack (FDIA) is crucial for ensuring the stable operation of power systems. Existing approaches for handling measurement data often overlook the correlation between local time–frequency variations caused by FDIA nodes and global spatial information in analyzing measurement data, leading to inaccurate localization. To address this issue, we propose a novel approach: a multilevel wavelet spatio-temporal map embedded FDIA localization method. Initially, a multi-resolution time–frequency signal decomposition model is utilized to separate the time–frequency mutation signals induced by FDIA from the measurement data using fast wavelet transform. Subsequently, a multi-channel time–frequency feature extraction technique is developed to capture the mutation characteristics of FDIA in time–frequency signals. This involves extracting detailed features of the time–frequency signals pre and post-attack via a multi-channel convolution operation encompassing “temporal-local-global” aspects. Finally, we propose an FDIA localization model based on multi-level graph wavelet embedding. The model embeds spatio-temporal information into time–frequency features via graph wavelet convolution and builds a spatio-temporal dependency map through multi-level neighborhood sampling. To mitigate measurement loss and noise, graph smoothing regularization and graph dropout are introduced during training. A graph attention mechanism further captures spatio-temporal dependencies among nodes, enabling accurate FDIA localization. Experimental results verify the effectiveness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhaoyang Qu and Feng Liang and Nan Qu and Tao Jiang and Xiaoyu Xu},
  doi          = {10.1016/j.eswa.2025.129620},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129620},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management. <em>ESWA</em>, <em>298</em>, 129619. (<a href='https://doi.org/10.1016/j.eswa.2025.129619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the integration of the 5G-enabled Internet of Things has revolutionized through high-speed data transmission, ultra-low latency, and interconnectivity of massive devices. However, the proliferation of 5G-enabled Internet of Things introduces major challenges, such as energy inefficiency and unreliable data delivery in the resource constrained Internet of Things devices. This research proposes a novel Q-Learning-based optimization framework tailored to address these challenges by integrating Radio Frequency energy harvesting, adaptive beamforming, and dynamic resource allocation within the massive Multiple-Input-Multiple-Output system. The proposed model utilizes reinforcement learning to manage the network resources including modulation schemes, beamforming, and energy allocation. By modeling the optimization problem as a Markov Decision Process, the proposed framework dynamically adapts to real-time network conditions to enhance energy efficiency, reliable data delivery, and throughput. The experimental validation demonstrates that the Q-Learning-based strategy effectively optimizes the energy efficiency as well as data transmission and achieves a higher energy efficiency of 98.87 %, higher packet delivery ratio of 98.85 %, lower latency of 1.5 ms, and higher throughput of 200Mbps compared to existing methodologies. This result indicates that the proposed Q-Learning-based framework has the potential to enhance the sustainability and reliability of the 5G-enabled Internet of Things.},
  archive      = {J_ESWA},
  author       = {Bavethra Murthy and Palani Uthirapathy},
  doi          = {10.1016/j.eswa.2025.129619},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129619},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-behavioral recommendation algorithm based on decoupled graph convolution. <em>ESWA</em>, <em>298</em>, 129618. (<a href='https://doi.org/10.1016/j.eswa.2025.129618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation models primarily rely on display feedback and typically utilize a single type of user-item interaction data, which often results in significant data sparsity issues. In contrast, multi-behavioral recommendation models leverage various behaviors such as browsing, favoriting, and other interactions. These additional behaviors help improve the prediction of user-item interactions. Existing multi-behavioral recommendation methods often overlook the potential factors influencing multi-behavioral interactions and the differences between various behavior types. In this study, we introduce a multi-behavioral recommendation algorithm utilizing decoupled graph convolution (MBR-DGC), which effectively mitigates the data sparsity of the target behaviors and improves recommender system performance by capturing the differences between the semantics of different behaviors. Specifically, we construct multiple non-overlapping independent isomorphic graphs and separate potential factors affecting the interactions among users, items, and behaviors using decoupled convolutional networks to reconstruct the node features of users in different behaviors. Afterwards, multi-behavioral features of users are aggregated using contrastive learning to achieve personalized multi-behavioral information aggregation. Experimental results on multiple datasets show that MBR-DGC effectively leverages multi-behavioral data, significantly enhancing recommendation performance compared to other state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xu Yu and Pengju Ding and Jie Yu and Junyu Lin and Lei Guo and Guanfeng Liu and Liang Xi},
  doi          = {10.1016/j.eswa.2025.129618},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129618},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-behavioral recommendation algorithm based on decoupled graph convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy. <em>ESWA</em>, <em>298</em>, 129617. (<a href='https://doi.org/10.1016/j.eswa.2025.129617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swarm intelligence aggregation system represents a key capability in current-generation UAV swarm, demonstrating robust collective intelligence. Currently, leveraging Multi-Agent Deep Reinforcement Learning (MADRL) offers a promising approach for building UAV swarm intelligence aggregation systems. However, the MADRL methods are difficult to cope with the challenge of exponential increase in computation when facing the collaboration problem of large-scale swarms, and the agents also have the problem of partial observability of the environment. This paper proposes an Information Aggregation Decision Method for UAV swarm based on Joint Communication and Proximal Strategy (IADM-JCPS). This method designs a communication information aggregation (CIA) network to enable UAVs to gather observation information from neighbor UAVs, and uses the attention mechanism to screen important information. Then, the aggregated information is used as part of the input of the policy network to increase the information diversity of the decision-making process. Finally, the gradient clipping mechanism is used to trim the policy gradient to enhance the stability of the training process. A UAV swarm multi-target tracking (MTT) mission scenario is designed to verify the effectiveness of the proposed IADM-JCPS algorithm. Experimental results show that the proposed algorithm is superior to the baseline algorithm in terms of task collaboration and scalability.},
  archive      = {J_ESWA},
  author       = {Zhaotian Wei and Ruixuan Wei},
  doi          = {10.1016/j.eswa.2025.129617},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129617},
  shortjournal = {Expert Syst. Appl.},
  title        = {An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-based trajectory planning for AGVs in dynamic environment. <em>ESWA</em>, <em>298</em>, 129616. (<a href='https://doi.org/10.1016/j.eswa.2025.129616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a learning-based framework for rapid trajectory planning of autonomous ground vehicles (AGVs) in dynamic environments. The approach integrates optimization techniques with deep learning to design a real-time planner capable of generating kinematically feasible trajectories. A continuous iterative method is first developed for dataset construction, enabling efficient generation of optimal trajectory sets. Based on this dataset, a neural network is trained to learn the mapping between AGV states and actions while capturing their temporal dependencies. During online planning, the trained model produces decision actions from the current state and sensor feedback, enabling real-time planning of safe and feasible trajectories. Results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_ESWA},
  author       = {Runda Zhang and Zhida Xing and Senchun Chai and Yuanqing Xia and Runqi Chai},
  doi          = {10.1016/j.eswa.2025.129616},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129616},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning-based trajectory planning for AGVs in dynamic environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Model-agnostic post-hoc explainability for recommender systems. <em>ESWA</em>, <em>298</em>, 129608. (<a href='https://doi.org/10.1016/j.eswa.2025.129608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems often benefit from complex feature embeddings and deep learning algorithms, which deliver sophisticated recommendations that enhance user experience, engagement, and revenue. However, these methods frequently reduce the interpretability and transparency of the system. In this research, we develop a systematic application, adaptation, and evaluation of deletion diagnostics in the recommender setting. The method compares the performance of a model to that of a similar model trained without a specific user or item, allowing us to quantify how that observation influences the recommender, either positively or negatively. To demonstrate its model-agnostic nature, the proposal is applied to both Neural Collaborative Filtering (NCF), a widely used deep learning-based recommender, and Singular Value Decomposition (SVD), a classical collaborative filtering technique. Experiments on the MovieLens and Amazon Reviews datasets provide insights into model behavior and highlight the generality of the approach across different recommendation paradigms.},
  archive      = {J_ESWA},
  author       = {Irina Arévalo and Jose L. Salmeron},
  doi          = {10.1016/j.eswa.2025.129608},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129608},
  shortjournal = {Expert Syst. Appl.},
  title        = {Model-agnostic post-hoc explainability for recommender systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS. <em>ESWA</em>, <em>298</em>, 129607. (<a href='https://doi.org/10.1016/j.eswa.2025.129607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable assessment of precipitation is crucial for incorporating meteorological and hydrological research into industrial and agricultural applications. Accurately estimating precipitation is a challenging task. In addressing this problem, we propose to develop AERO-Net, a novel deep learning framework designed to correct spatial, temporal, and amplitude biases in WRF-ROMS precipitation data. The integration of the Weather Research and Forecasting (WRF) model with the Regional Ocean Modeling System (ROMS) makes it a valuable tool for precipitation forecasting. AERO-Net incorporates autoencoders (AEs) for handling fluctuation and generalizing latent space representations, a latent module (LM) for transforming WRF-ROMS data into bias-corrected representations, a residual module (RM) for error minimization via boost, and a calibration module (CM) for improving near-zero precipitation. Empirical results show that AERO-Net achieves a balanced error reduction across precipitation cohorts grouped by intensity, reducing the macro-averaged root mean square error (macro RMSE) by 3.6 mm/day and the macro-averaged mean absolute deviation (macro MAD) by 0.68 mm/day compared to the original WRF-ROMS. AERO-Net is seen to improve the correlation coefficient (CC) by 26.32 %, increasing it from 0.38 to 0.48, in comparison to the original WRF-ROMS. These findings underscore its potential as an effective solution for enhancing precipitation estimates in high-resolution modeling systems.},
  archive      = {J_ESWA},
  author       = {Passin Pornvoraphat and Kanoksri Sarinnapakorn and Ken-Ichi Fukui and Peerapon Vateekul},
  doi          = {10.1016/j.eswa.2025.129607},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129607},
  shortjournal = {Expert Syst. Appl.},
  title        = {AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography. <em>ESWA</em>, <em>298</em>, 129606. (<a href='https://doi.org/10.1016/j.eswa.2025.129606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are now achieving strong results for segmentation tasks, and the standard metric for evaluating methods is the Intersection over Union (IOU). However, we show in this paper that IOU is not efficient in evaluating the quality of segmentation for electron tomography (ET) images of zeolites. We perform a physics-oriented evaluation to ensure that the segmentation results yield coherent physical measures. We also formalize Mixed Supervised / Self-Supervised Contrastive Learning Segmentation (M3S-CLS), a semi-supervised approach using a contrastive learning approach that uses expert annotations to train the neural network model. A detailed comparison of this method with a standard cross-entropy-based model is provided. In addition, we publish a database of five fully segmented ET volumes along with corresponding baseline results. The code and the database is available at http://gitlab.univ-st-etienne.fr/labhc-iscv/M3S-CLS .},
  archive      = {J_ESWA},
  author       = {Cyril Li and Christophe Ducottet and Maxime Moreaud and Sylvain Desroziers and Valentina Girelli Consolaro and Virgile Rouchon and Ovidiu Ersen},
  doi          = {10.1016/j.eswa.2025.129606},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129606},
  shortjournal = {Expert Syst. Appl.},
  title        = {Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy. <em>ESWA</em>, <em>298</em>, 129605. (<a href='https://doi.org/10.1016/j.eswa.2025.129605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged objects often closely resemble their surroundings, causing standard RGB images to be confounded by background, texture, and color variations. This often leads to incomplete or absent target segmentation, reducing overall accuracy. To address this issue, we present a Deep Surrounding-Awareness Mirror Network (DSANet) for camouflaged object detection, leveraging depth information to expose objects incongruent with their environment, thus improving localization accuracy. First, a Convolutional Spatial Gating module processes batched RGB and depth inputs, suppressing extraneous background noise while isolating fine-grained segmentation and structural features and unifying channel representation. Subsequently, a Deep Surrounding-Awareness Localization module and a Contour-Guided Integrity Aggregation module collaboratively refine and merge multi-level features, focusing on the global form of camouflaged objects while iteratively enhancing segmentation detail. Finally, a Guided Residual Channel Attention module further refines low-layer structural cues. Extensive experiments on ten challenging benchmark datasets using four widely used evaluation metrics demonstrate that our method exhibited superior performance, outperforming 40 state-of-the-art methods. The results demonstrate the versatility of our model. The source code and results of our method are available at https://github.com/lixu11/DSANet.},
  archive      = {J_ESWA},
  author       = {Xu Li and Xiaosheng Yu and Peng Chen},
  doi          = {10.1016/j.eswa.2025.129605},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129605},
  shortjournal = {Expert Syst. Appl.},
  title        = {DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FTUAttack: Feature truncation unrestricted attack based on stable diffusion model. <em>ESWA</em>, <em>298</em>, 129604. (<a href='https://doi.org/10.1016/j.eswa.2025.129604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of adversarial example generation and defense, compared to restricted attacks with L p -norm constraints, unrestricted attacks without L p -norm constraints emanate better visual imperceptibility. Existing unrestricted attacks typically manipulate the semantic content of examples (e.g. texture or color) to generate adversarial examples. However, current works usually ignore multifaceted features or loss optimization strategy, which limits attack performance. In this paper, we draw inspiration from stable diffusion model and propose a unrestricted attack method called Feature Truncation Unrestricted Attack (FTUAttack) to achieve both better transferability and imperceptibility. Specifically, we promote the performance of unrestricted attacks from the perspectives of both diffusion principle and feature truncation for the first time. Firstly, we propose a Global Deep Feature Extractor (GDFE) module to truncate global feature for the subsequent diffusion denoising process. Secondly, to further boost the transferability, we design a novel Critical Latent Feature Extractor (CLFE) module to obtain critical local feature that need to be truncated during the denoising process and investigate the influence of the different segmentation ways on critical local feature. Thirdly, we propose Multi-Loss Fusion (MLF) strategy to balance the conflict between perturbations and examples’ quality by guiding the optimization direction. Extensive experiments on various model structures and datasets demonstrate the superiority of our attack over the existing attack methods.},
  archive      = {J_ESWA},
  author       = {Shaojie Han and Gangzheng Zhai and Kun Chen and Shihui Zhang},
  doi          = {10.1016/j.eswa.2025.129604},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129604},
  shortjournal = {Expert Syst. Appl.},
  title        = {FTUAttack: Feature truncation unrestricted attack based on stable diffusion model},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram. <em>ESWA</em>, <em>298</em>, 129603. (<a href='https://doi.org/10.1016/j.eswa.2025.129603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of labeling Electrocardiogram (ECG) has prompted researchers to use self-supervised learning to enhance diagnostic performance. Masked autoencoders (MAE) are a mainstream paradigm where models learn a latent representation of the signal by reconstructing masked portions of the ECG. However, existing methods lack a specific design for the spatial–temporal characteristics of ECG. Specifically, leads represent spatial projections of cardiac activity, while timestamps capture temporal patterns, and the two correspond to different axes of information. Existing MAE frameworks tend to unify them prematurely, potentially weakening critical local dependencies. In this paper, we propose a Spatial-Temporal Hierarchical Decoupled Masked Autoencoder (STHD-MAE). This framework decouples ECG into isolated leads or time steps in the shallow layer to capture local dependencies with different views, then aligns spatial–temporal representations and re-establishes global dependencies in the deep layer to comprehensively represent pathological information. We also design a medical report fusion module during pre-training, which uses cross-attention to align the ECG report text encoded by a medical language model with the signal’s latent representation, thereby guiding the encoder to focus on pathological information through implicit cross-modal learning. We validate the effectiveness of STHD-MAE on multiple downstream classification and reconstruction tasks. The results show that STHD-MAE outperforms existing self-supervised learning methods by approximately 2% in F1-scores for both coarse-grained and fine-grained classification performance, and its reconstruction quality also exceeds the baseline generative model.},
  archive      = {J_ESWA},
  author       = {Xiaoyang Wei and Zhiyuan Li and Yuanyuan Tian and Mengxiao Wang and Yanrui Jin and Weiping Ding and Chengliang Liu},
  doi          = {10.1016/j.eswa.2025.129603},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129603},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching. <em>ESWA</em>, <em>298</em>, 129602. (<a href='https://doi.org/10.1016/j.eswa.2025.129602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The local correspondence learning has gained increasing attention in image-text matching, which establishes fine-grained alignments between image regions and textual words to improve both interpretability and accuracy. While these approaches have made significant progress in identifying meaningful semantic correspondences, one critical limitation persists in current methods, i.e., overlooking the crucial spatial position information of visual regions in cross-modal interaction. To address this challenge, we propose a novel Geometric contextual Aggregation and Regional contextual Enhancement Network (GARE-Net) that introduces two innovative components: the Geometric Contextual Feature Aggregation (GCFA) module and the Regional Contextual Feature Enhancement (RCFE) module. Specifically, GCFA generates the spatial geometric information of visual regions to enhance the region features by feature aggregation. RCFE further refines the aggregated region features by constructing a region graph and graph convolution. Extensive experiments and analyses are conducted on Flickr30k and MSCOCO to evaluate the importance of our framework. The results demonstrate the superiority of our method in image-text matching. Moreover, the ablation studies and visualization case studies also highlight the importance of geometric contextual feature aggregation and regional contextual feature enhancement. The code is available at https://github.com/chinaBoy123/GARE-Net .},
  archive      = {J_ESWA},
  author       = {Fangming Zhong and Tao Zhou and Zhikui Chen and Suhua Zhang},
  doi          = {10.1016/j.eswa.2025.129602},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129602},
  shortjournal = {Expert Syst. Appl.},
  title        = {GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation. <em>ESWA</em>, <em>298</em>, 129600. (<a href='https://doi.org/10.1016/j.eswa.2025.129600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing quantum group decision-making models face significant challenges in the bid evaluation of engineering projects, including the strong subjectivity of expert evaluations, the difficulty in aggregating expert opinions, the large gap of expert opinions, and the complexity of expert psychological behaviors. To address these issues, this paper proposes a novel quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation. Firstly, a quantum Bayesian network is constructed to aggregate expert opinions and capture the interference effect among experts. Secondly, the matrix fluctuation grey correlation degree is defined and applied to the calculation of quantum interaction terms that reflect the intricate psychological behavior of experts. Subsequently, a decision item search model is proposed and applied to adjust preferences during the consensus reaching process, thereby narrowing the gap of expert opinions. The consensus effect optimization model is utilized to determine optimal values for unknown parameters within this process, effectively reducing the subjectivity of expert evaluations. Finally, the proposed model is applied to a bid evaluation of bridge anti-collision engineering project, which verifies the feasibility and effectiveness of the model, and evaluates the stability and superiority of the model through sensitivity analysis and comparative analysis.},
  archive      = {J_ESWA},
  author       = {Jiuru Zhu and Xinping Xiao and Congjun Rao},
  doi          = {10.1016/j.eswa.2025.129600},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129600},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks. <em>ESWA</em>, <em>298</em>, 129599. (<a href='https://doi.org/10.1016/j.eswa.2025.129599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical node detection is an important tool for measuring network robustness. The main purpose of critical node detection is to detect a set of nodes that cause the greatest damage to the network connectivity, and it has been applied in many fields such as social network analysis and traffic network management. As a classic non-deterministic polynomial time complete problem, critical node detection faces enormous challenges with the continuous expansion of network size. The existing methods are difficult to achieve a good balance between effectiveness and efficiency, especially when the scale of complex networks becomes larger. To this end, this paper proposes a dual population based critical node detection method (DPCND) to effectively and efficiently obtain a set of critical nodes, which utilizes the co-evolution of auxiliary population generated from reduced graph and main population generated from original graph to find the optimal solution. In the proposed algorithm, a dual population interaction mechanism consists of influence and expansion strategies is proposed for information exchange, where the influence strategy transfers candidate good solutions from the auxiliary population to the main population to improve search efficiency, and the expansion strategy provides node information of the main population to guide the expansion of search space for the auxiliary population. Finally, the experimental results on 20 real-world complex networks clearly demonstrate the effectiveness of the proposed algorithm comparing to the state-of-the-arts.},
  archive      = {J_ESWA},
  author       = {Lei Zhang and Xinyi Feng and Yuanyuan Ge and Zhanpeng Wang and Haipeng Yang},
  doi          = {10.1016/j.eswa.2025.129599},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129599},
  shortjournal = {Expert Syst. Appl.},
  title        = {DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem. <em>ESWA</em>, <em>298</em>, 129598. (<a href='https://doi.org/10.1016/j.eswa.2025.129598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern agriculture, efficiently picking and distributing fresh product is crucial for the competitiveness of smart farms within the globalized agricultural market. However, the integrated scheduling problem involving both picking and distribution processes has received limited attention in existing research. To bridge this gap, this study establishes a mathematical model with dual objectives: (1) minimizing the picking completion time and (2) reducing penalties incurred due to early or delayed deliveries. A novel two-stage evolutionary algorithm incorporating a restart mechanism is proposed to effectively balance the optimization of these objectives with a high degree of consistency. The algorithm features an efficient encoding scheme and advanced genetic operators, specifically designed to enhance exploration and exploitation based on the characteristics of the problem. A comprehensive set of test instances is generated and the proposed method is benchmarked against several state-of-the-art metaheuristics from the literature. Experimental results demonstrate that the proposed algorithm outperforms the competing approaches by a significant margin for solving the problem under consideration.},
  archive      = {J_ESWA},
  author       = {Yiran Pan and Xuan He and Nan Li and Zhonghua Miao},
  doi          = {10.1016/j.eswa.2025.129598},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129598},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm. <em>ESWA</em>, <em>298</em>, 129597. (<a href='https://doi.org/10.1016/j.eswa.2025.129597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful simulation of constrained differential evolution (CDE) algorithm for solving phase equilibrium calculation has first verified that heuristic optimization algorithms are effective ways to solve this kind of problems. Their insensitivity to initial values overcomes the limitations associated with two kinds of traditional methods, i.e., direct solution methods based on Newton’s method and indirect solution methods based on thermodynamic principles. This article proposes a constrained quadratic interpolation optimization algorithm (CQIO) for obtaining the satisfactory solutions of phase equilibrium calculation under given volume, temperature, and moles (NVT-flash). The proposed CQIO regards the total Helmholtz free energy of a NVT-flash problem as its objective function, while the moles vector and volume of a certain phase as its decision variables. The consistency between the four cases’ experimental results of CQIO and those of published articles demonstrates the effectiveness of CQIO in solving NVT-flash problems. Then the computational overhead and algorithmic stability of CQIO were analyzed. In Cases 1, 2 and 3, the average CPU time of CQIO compared to CDE has increased by 46.98 % , 54.56 % and 21.02 % respectively. The Std values of CQIO are significantly smaller than those of CDE in all cases except for Example 2. The proposed CQIO greatly promotes the application of heuristic algorithm in the field of phase equilibrium calculation.},
  archive      = {J_ESWA},
  author       = {Wangyu Tong and Baoduo Su and Yaqian Zhan},
  doi          = {10.1016/j.eswa.2025.129597},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129597},
  shortjournal = {Expert Syst. Appl.},
  title        = {An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge graph life cycle for cognitive agents – A case study on automated negotiation in smart grids. <em>ESWA</em>, <em>298</em>, 129596. (<a href='https://doi.org/10.1016/j.eswa.2025.129596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) can enhance cognitive artificial agents by improving their semantic understanding, adaptability to dynamic contexts, explainability, continuous learning, and informed, case-based decision-making. However, the development of any KG rarely follows an explicit and structured procedure to improve its consistency, modifiability, and interoperability. This ultimately restricts the utility of KGs for real-world agentic AI systems. To overcome this limitation, this paper proposes a life cycle for developing and evolving KGs in domain-specific applications, encompassing three phases to i) conceptualize the problem domain and competency questions, ii) formalize a schema using ontologies, and iii) implement the KG to foster agents’ cognition through queries and graph data science. The proposed approach is validated with a case study on context-aware automated negotiations within smart grids, where agents negotiate for energy trading while considering private and contextual circumstances. Agents may take actions with or without the aid of a KG, and can adopt one of three negotiation strategy configurations: heuristic, metaheuristic, or reinforcement learning-based. Negotiation outcomes consistently indicate that, regardless of the configuration employed, the use of a KG improves agents’ rewards by at least 1.21 % and up to 90.91 %. Results highlight that the proposed life cycle enables the integration of contextual and domain-specific data and metadata into a KG that enhances agents’ learning, while also allowing for the development and selection of relevant queries and graph data science algorithms to improve the strategic behavior of negotiation agents with cognitive abilities.},
  archive      = {J_ESWA},
  author       = {Dan E. Kröhling and Ernesto C. Martínez},
  doi          = {10.1016/j.eswa.2025.129596},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129596},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge graph life cycle for cognitive agents – A case study on automated negotiation in smart grids},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets. <em>ESWA</em>, <em>298</em>, 129595. (<a href='https://doi.org/10.1016/j.eswa.2025.129595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a novel VRP variant integrating seasonal demand fluctuations, heterogeneous vehicle sources, and multi-endpoint constraints, focusing on the distribution of seasonal products in a steel parts enterprise. It tackles the complex vehicle routing problem with time windows involving heterogeneous fleets, which encompass different vehicle sources (owned and rented), types (fuel-powered and electric), capacities, ranges, and endpoints. To balance enterprise profitability, greenhouse gas emissions, and environmental quality, we develop a mathematical model centered on optimizing distribution costs, greenhouse gas emissions, and vehicle utilization. Drawing inspiration from ancient competitive activities, we propose a novel Huashan Swords Algorithm (HSSA). Through simulations using real enterprise data, we demonstrate the HSSA’s effectiveness, with comparative experiments against existing advanced algorithms highlighting its superiority. Applying the algorithm to design logistics distribution schemes, we conduct in-depth tests considering different customer groups and fuel station distributions. Analyzing the results from the perspectives of profitability, emissions, and environmental quality, we offer targeted operational suggestions for the enterprise based on its situation, geographical characteristics, and fiscal policies. Moreover, we provide recommendations to local governments on fuel station construction and vehicle subsidy policies, contributing practical solutions to both enterprise operations and regional development.},
  archive      = {J_ESWA},
  author       = {Zhang Yanhu and Yan Lijuan and Kong ShuMei and Miao Decheng},
  doi          = {10.1016/j.eswa.2025.129595},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129595},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch. <em>ESWA</em>, <em>298</em>, 129594. (<a href='https://doi.org/10.1016/j.eswa.2025.129594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting gold prices through the analysis of key economic indicators such as inflation rates, Government Bond Yields, and the U.S. Dollar Index, alongside historical Gold Prices, is crucial for enabling investors to better understand market dynamics and make vital decisions to maximize returns. However, previous studies have faced challenges in extracting hidden factors related to gold price prediction from diverse economic indicators, and the comprehensive exploration of gold price data is yet to be fully achieved. To address this, the present study introduces a mid to long-term gold price prediction model named DPformer. This model utilizes a patching strategy to investigate the relationships between different economic indicators and Gold Prices. It also employs a decomposition approach to discover the mid to long-term trend characteristics and yearly seasonal patterns of Gold Prices. The core of the model integrates a Transformer module, which is solely based on an Encoder structure, and enhances it with multiple attention mechanisms and convolutions. This enhancement allows the improved Transformer model to more effectively capture the long-term dependencies of Gold Prices. The empirical results demonstrate that DPformer consistently outperforms a suite of advanced models widely adopted in terms of mid to long-term forecasting accuracy, including LSTM, GRU, Transformer, DLinear, and PatchTST. Notably, for the 30-step gold price prediction task, DPformer achieves a 21.78 % reduction in Mean Squared Error compared to PatchTST. Moreover, by quantitatively analyzing how various economic indicators influence gold price forecasts, this study provides substantial support for investors in making informed decisions at critical moments.},
  archive      = {J_ESWA},
  author       = {Guanhao Bao and Yunbo Niu and Baisheng Cui and Wanying Ji},
  doi          = {10.1016/j.eswa.2025.129594},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129594},
  shortjournal = {Expert Syst. Appl.},
  title        = {Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven optimization of project portfolios in corporate ecosystems with synergies and strategic factors. <em>ESWA</em>, <em>298</em>, 129593. (<a href='https://doi.org/10.1016/j.eswa.2025.129593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the optimization of project portfolios in corporate ecosystems by considering both strategic factors and return synergies between projects. We propose a hybrid method that combines machine learning with mathematical programming to address this enhanced form of project portfolio optimization. Unlike traditional approaches, which evaluate projects mainly based on individual risks and returns, our framework considers strategic priorities and the extra value created when projects reinforce each other. Machine learning models predict synergies, while exact optimization ensures consistent portfolio selection under resource and strategic constraints. A numerical proof-of-concept illustrates the methodology. Computational experiments show that portfolios designed with synergy and strategy in mind might achieve a significantly higher performance than portfolios that do not account for project synergies. The paper also examines computational efficiency and scalability, highlighting the approach’s potential for practical application in complex and dynamic corporate ecosystems.},
  archive      = {J_ESWA},
  author       = {Patricia Rodriguez-Garcia and Angel A. Juan and Jon A. Martin and David Lopez-Lopez and Josep M. Marco},
  doi          = {10.1016/j.eswa.2025.129593},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129593},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven optimization of project portfolios in corporate ecosystems with synergies and strategic factors},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches. <em>ESWA</em>, <em>298</em>, 129592. (<a href='https://doi.org/10.1016/j.eswa.2025.129592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a systematic mapping of machine learning in class imbalance scenarios, offering a broad overview of key challenges, promising emerging techniques, and established methodologies across various application domains. The investigation stands out by employing a hybrid search and selection protocol that combines methodological rigor with technical innovation. The adopted strategy integrated manual searches in reference sources with automated processes based on machine learning, semantic embeddings, and graph-based ranking algorithms. To enhance selection quality, the Quasi-Golden Set (QGS) method was used to build a reference set from manually selected articles – a critical foundation for calibrating and evaluating automated search strings. This combination ensured broad coverage of the topic while improving sensitivity and precision in identifying relevant studies. The initial analysis reviewed 25,593 publications. After screening and applying eligibility criteria, 468 articles were included in the final dataset. The results indicate that 55 % of the studies address multiple domains, with a strong predominance of tabular data ( 84 % ). SMOTE and hybrid approaches were among the most common techniques, present in 61 % of the studies. In terms of evaluation metrics, ROC-AUC was the most frequently used, followed by F1-score and accuracy – the latter noted for limitations in highly imbalanced scenarios. Building on these findings, we derive an empirically grounded taxonomy that links problem context, solution algorithms, and scenario-appropriate evaluation metrics, and we provide a minimal selection guideline table to support applied use. While sampling-based methods remain prevalent, deep learning approaches such as convolutional neural networks and graph-based models are increasingly adopted. Additionally, federated, contrastive, and semi-supervised learning are emerging as relevant paradigms, particularly suited for privacy-aware or low-label environments. This study consolidates current knowledge, identifies methodological and application gaps, and highlights trends that are likely to shape future research. It contributes both a comprehensive synthesis of the field and strategic insights for advancing machine learning techniques in the presence of class imbalance.},
  archive      = {J_ESWA},
  author       = {Gilberto Sussumu Hida and André Câmara Alves Do Nascimento},
  doi          = {10.1016/j.eswa.2025.129592},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129592},
  shortjournal = {Expert Syst. Appl.},
  title        = {Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches. <em>ESWA</em>, <em>298</em>, 129591. (<a href='https://doi.org/10.1016/j.eswa.2025.129591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process planning in reconfigurable manufacturing systems usually considers a single product, this reduces the efficiency of the overall production plan when multiple products are combined. This paper tackles the Multi-Product Process Planning Problem (MPPP), optimizing both individual process plans and their sequencing. We propose a 0–1 LP model, the model is relaxed by fixing the product sequencing variables and implemented in a Normal-Boundary Intersection method (NBI-es), the method uses a function for iteratively updating β values. Three metaheuristics are also developed: NSGA-II, and two variants of MOEA/D, one enhanced by Opposition-based learning (OBL). Computational experiments show that the update function enhances the performance of NBI over simple Normalized-Weighted Sum (NWS) method. Additionally, NBI-es performs better in HV metric for small size instances if it is given enough CPU times, while MOEA/D significantly outperforms NSGA-II on larger instances on most convergence and spread based metrics. OBL further enhances solution diversity for MOEA/D, albeit with less convergence. A special case of the MPPP is investigated, involving identical products: the Multi-Unit Process Planning (MUPP). An integrated approach was compared with a sequential separated approach. Results indicate that the integrated approach outperforms the separated method for smaller problem instances. Moreover, the analysis of high-quality MUPP solutions revealed a tendency towards diverse process plan combinations rather than repetitive identical ones.},
  archive      = {J_ESWA},
  author       = {Abdelkader Mechaacha and Fayçal Belkaid and Nadjib Brahimi},
  doi          = {10.1016/j.eswa.2025.129591},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129591},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs. <em>ESWA</em>, <em>298</em>, 129590. (<a href='https://doi.org/10.1016/j.eswa.2025.129590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing has attracted increasing attention for its environmental and economic benefits. Since it is difficult to achieve economies of scale when processing small amounts of remanufacturing jobs alone, these jobs are processed in the same job-shop for new jobs in some enterprises. The processing times of remanufacturing jobs are uncertain due to unpredictable status, leading to certain impacts on scheduling performance. Therefore, we address a flexible job-shop scheduling problem with new and remanufacturing jobs to minimize makespan. To solve this problem, a slack-based two-stage improved particle optimization algorithm is proposed. The first stage aims to yield a solution set with minimum makespan, while the second stage aims to search the best robust solution with maximum total slack from the set. Both stages are executed alternately to optimize makespan and total slack. Moreover, a position updating mechanism with genetic operators and a tabu search inspired local search strategy are implemented to improve algorithmic performance. Computational experiments are conducted using adapted benchmark problems and an industrial case to validate the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Jun Liu and Zhui Gui and An Li and Qiong Liu},
  doi          = {10.1016/j.eswa.2025.129590},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129590},
  shortjournal = {Expert Syst. Appl.},
  title        = {A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach. <em>ESWA</em>, <em>298</em>, 129589. (<a href='https://doi.org/10.1016/j.eswa.2025.129589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates and predicts green economic efficiency (GEE) across 248 Chinese cities from 2010 to 2021 using a three-stage network SBM model based on subsystems of economic production, social development, and environmental governance. To enhance accuracy in both assessment and forecasting, machine learning methods are incorporated, and the Dagum Gini coefficient is employed to analyze regional disparities. This study innovatively proposes a three-stage network SBM model to resolve the “black box” limitation of conventional DEA approaches, while a DEA-ML model is developed to achieve enhanced prediction accuracy. The results reveal that GEE in Chinese cities remains low, with the eastern region leading and the western region trailing. However, efficiency has improved since 2016, primarily driven by advancements in environmental governance. Regional disparities, largely attributed to interregional differences, are gradually decreasing. Among forecasting models, the backpropagation neural network (BPNN) delivers the highest accuracy, predicting sustained leadership in the east, strong growth in the northeast, and a reduction in national disparities. This study offers a comprehensive framework for evaluating and predicting GEE, providing valuable insights for sustainable development policies.},
  archive      = {J_ESWA},
  author       = {Zhishuo Zhang and Hu Liu and Yunpeng Gong and Huayong Niu},
  doi          = {10.1016/j.eswa.2025.129589},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129589},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization. <em>ESWA</em>, <em>298</em>, 129587. (<a href='https://doi.org/10.1016/j.eswa.2025.129587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid algorithm integrating a couple of individual evolutionary algorithms (sub-algorithms) is widely recognized as an effective approach to enhance both robustness and optimization performance. Nevertheless, such integration often destroys the structure of the sub-algorithm and makes it difficult to incorporate additional evolutionary algorithms. To address these limitations, this study introduces a novel framework, the Heterogeneous Alternating Evolutionary Algorithm (HAEA), designed to integrate multiple evolutionary algorithms while enabling the flexible addition, removal, and replacement of internal sub-algorithms. To facilitate the integration of a broad spectrum of sub-algorithms, this study draws inspiration from the particle swarm optimization algorithm to devise a suite of information indicators for the transmission of optimization information between sub-algorithms with disparate structures. Furthermore, HAEA is endowed with an adaptive mechanism that dynamically modifies the selection probabilities of its sub-algorithms based on their long-term and short-term performance throughout the evolutionary process. We conducted a comparative analysis of HAEA against all its sub-algorithms across three widely recognized function test sets: CEC2013, CEC2017, and CEC2022. Meanwhile, we applied the HAEA separately to basic metaheuristic algorithms and advanced evolutionary algorithms in recent years and conducted two comparative experiments. Both experimental results show that HAEA outperforms all sub-algorithms in terms of robustness and optimization performance. Its distinctive flexibility allows for the incorporation of additional superior evolutionary algorithms in the future, thereby enhancing its overall performance.},
  archive      = {J_ESWA},
  author       = {Taiyong Li and Tianhao Yi and Zhenda Hu and Wu Deng and Donglin Zhu and Zhilong Xie and Jiang Wu},
  doi          = {10.1016/j.eswa.2025.129587},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129587},
  shortjournal = {Expert Syst. Appl.},
  title        = {HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients. <em>ESWA</em>, <em>298</em>, 129586. (<a href='https://doi.org/10.1016/j.eswa.2025.129586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, free quadratic coefficients are proposed in order to deeply study the flexible criteria of synchronization problem for two kinds of fractional-order higher-dimension-valued neural networks (FOHDVNN) with usual neurons and threshold ones, respectively. First, the uniform system is constructed for two kinds of FOHDVNN which contains both fractional-order octonion-valued neural networks (FOOVNN) and fractional-order quaternion-valued neural networks (FOQVNN). Based on higher-dimension algebra multiplication rules, the studied FOHDVNN are directly decomposed into the eight or four subsystems in real-valued field. Subsequently, free quadratic coefficients are taken into the establishment of two types of Lyapunov-Krasovskii functional (LKF) which is newer and more general. Then, mainly based on the very recent lemmas and Lyapunov theories, the flexible criteria are generally acquired for the global Mittag-Leffler synchronization (MLSY) problem of FOHDVNN. The final criteria have the advantage in being easily calculated and widely used. It is worth noting that the optimal solutions of these criteria can be obtained through the genetic algorithm and the synchronization performance can be improved by optimizing the quadratic coefficients. Finally, three simulation examples are presented to express the availability and progress of the derived results.},
  archive      = {J_ESWA},
  author       = {Jianying Xiao and Yongtao Li},
  doi          = {10.1016/j.eswa.2025.129586},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129586},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex-order darwinian particle swarm optimization. <em>ESWA</em>, <em>298</em>, 129584. (<a href='https://doi.org/10.1016/j.eswa.2025.129584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Particle Swarm Optimization (PSO) algorithm has been one of the most effective methods for solving various complex optimization problems. However, non-adaptive versions of the PSO do not use historical information for performance enhancement and suffer from performance degradation problems. This paper presents a Complex-Order Darwinian PSO (CoDPSO) algorithm, which effectively enhances the performance of the PSO. A complex-order derivative mechanism is introduced into the velocity update rule to improve local exploitation using historical velocity information. Additionally, a Degradation Elimination (DE) strategy is designed to mitigate performance drop during the optimization process. Sensitivity analysis is conducted to evaluate the impact of control parameters on the algorithm’s behavior, demonstrating its robustness across a wide range of settings. Comparative experiments on CEC 2022 benchmark functions show that the CoDPSO outperforms other PSO variants in terms of accuracy, stability, and convergence. Wilcoxon statistical tests further confirm the significance of these improvements. The experimental results indicate the feasibility and efficiency of the CoDPSO.},
  archive      = {J_ESWA},
  author       = {Xiaobo Wu and Liping Chen and Huafeng Li and António M. Lopes and Chuang Liu and Yangquan Chen and Yi Chai},
  doi          = {10.1016/j.eswa.2025.129584},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129584},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complex-order darwinian particle swarm optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions. <em>ESWA</em>, <em>298</em>, 129583. (<a href='https://doi.org/10.1016/j.eswa.2025.129583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting public opinion trends during major infectious disease outbreaks is critical for guiding effective public health responses. However, predicting public opinion remains challenging because it is influenced by socio-economic, psychological, and media factors. This paper presents a novel framework for predicting public opinion trends related to significant infectious diseases, with a focus on COVID-19 as a case study. The proposed framework identifies the key factors influencing public opinion development and enables both point and interval predictions. The framework uses information ecology theory and applies the NSGA-II algorithm to select the features that best drive public opinion trends. By incorporating this framework, accurate point forecasts are produced alongside prediction intervals, effectively quantifying the uncertainty inherent in public opinion dynamics. This approach minimizes the quality-driven loss function to generate precise prediction intervals, providing decision-makers with critical insights into public opinion fluctuations during epidemics. The results offer valuable, real-time public sentiment warnings, supporting timely and effective interventions in epidemic prevention and control efforts.},
  archive      = {J_ESWA},
  author       = {Futian Weng and Meng Su and Petr Hajek and Mohammad Zoynul Abedin},
  doi          = {10.1016/j.eswa.2025.129583},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129583},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism. <em>ESWA</em>, <em>298</em>, 129581. (<a href='https://doi.org/10.1016/j.eswa.2025.129581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge for multimodal multi-objective problem (MMOP) resolution lies in maintaining synergistic interactions between convergence and diversity. However, the existing algorithms usually consider convergence-first, which neglect to consider both diversity and convergence into account during the evolutionary process. Likewise, the optimization methods tend to gravitate toward locally optimal regions rapidly, leading to lose diversity for the local PS. This paper proposes a Deep Reinforcement Learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism (DRLMMEA) to investigate the impact of different operator selection on the performance of MMEAs, which greatly helps to balance the convergence and diversity. DRLMMEA utilizes Q-Network to select the operator with the highest reward to enhance the population’s search ability. An improved sorting method (ISM) based on neighborhood dominance updates the population by sorting individuals according to their convergence quality, thereby enhancing convergence performance in the objective space. Moreover, this study proposes a series-parallel mechanism, a series structure enhances the diversity in the decision space, while the parallel structure reduces the computational burden of the algorithm evidently. The proposed Deep Reinforcement Learning-assisted operator selection mechanism, which enables effective balance between diversity and convergence, and an improved crowding distance approach that enhances convergence performance. DRLMMEA undergoes comprehensive testing against 6 contemporary approaches using MMF and IDMP benchmark problems, achieving supremacy in 4 principal performance metrics according to experimental findings. The multimodal gearbox parameter optimization is addressed using the proposed DRLMMEA, which demonstrates superior performance against 6 algorithms in comparative evaluations. It has demonstrated a significant role in solving the MMOPs with the imbalance between convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Ying Huang and Xiaojian Cao and Benben Zhou and Wei Li and Shuling Yang and S.M. Shafi and Zhou Yang},
  doi          = {10.1016/j.eswa.2025.129581},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129581},
  shortjournal = {Expert Syst. Appl.},
  title        = {A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evolutionary multitasking optimization based on cross-task association mapping strategy. <em>ESWA</em>, <em>298</em>, 129580. (<a href='https://doi.org/10.1016/j.eswa.2025.129580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multitasking optimization, knowledge transfer between tasks through subspace generation has been widely employed to enhance the convergence performance of algorithms. However, this approach fails to account for the inter-task knowledge mapping relationships. Therefore, cross-task knowledge transfer during the optimization process remains inherently blind, potentially leading to mismatched subspace information and consequently degrading the algorithm’s performance. To address this issue, this paper proposes a multitask evolutionary algorithm based on an association mapping strategy and an adaptive population reuse mechanism, namely PA-MTEA. Specifically, to fully represent the correlations between multitask domains and enhance the adaptability of transfer solutions in target tasks, this paper introduces a subspace projection strategy based on partial least squares, which achieves the correlation mapping between the source and target tasks during the dimensionality reduction of the search space. Additionally, to further enhance knowledge transfer across tasks, an alignment matrix is obtained by adjusting the subspace Bregman divergence after deriving the respective subspaces, minimizing variability between task domains. Finally, to balance the global exploration of algorithms with local exploitation, an adaptive population reuse mechanism based on the residual structure is designed. This mechanism reuses historically successful individuals to guide the evolutionary direction of the population, thus improving the algorithm’s convergence performance. Experimental results on various benchmark suites and real-world cases demonstrate that PA-MTEA exhibits significantly superior performance compared to six other advanced multitask optimization algorithms.},
  archive      = {J_ESWA},
  author       = {Tao Yin and Lizhong Yao and Xin Zong and Pengjie Qin and Haoming Dong},
  doi          = {10.1016/j.eswa.2025.129580},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129580},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evolutionary multitasking optimization based on cross-task association mapping strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation. <em>ESWA</em>, <em>298</em>, 129578. (<a href='https://doi.org/10.1016/j.eswa.2025.129578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of different tissues within blastocysts is essential for embryologists to objectively observe and evaluate embryos, thereby contributing to a higher success rate of in vitro fertilization treatment. Inspired by the primary observation of skeletal patterns and boundary information by clinical doctors, we present an interesting task-aware view for blastocyst segmentation with semi-supervised learning, focusing on task-invariant and task-specific dependencies of segmentation. Firstly, we explore one strong-correlation task with bidirectional transformation between its outputs and the segmentation results, and another weak-correlation task with monodirectional transformation from segmentation maps. The correlation among different tasks inspires us to propose Task-Aware Smoothness (TAS) Assumption , thereby deducing different types of task-aware consistency. Then, a new Unified Task-aware Consistency Interaction (UniTask+) framework is developed to unify and fully take advantage of these strong, weak, and strong-to-weak task-aware consistency. It is comprised of a medical segmentation (MS) branch to implement segmentation and two extra branches performing strong/weak-correlation tasks based on the same backbone. Concretely, a level-set (LS) branch promotes the strong consistency while a point-set (PS) branch stimulates the weak consistency with underlying task perturbations. Numerous experiments have been conducted on the inner cell mass (ICM), blastocyst, proving the effectiveness of our tactics. Furthermore, we have also conducted experiments with datasets from the left atrium (LA), which shares similar structural features with embryos, to validate the robustness of the model. Our methods have shown prominent improvements over up-to-date SSL methods, which advocates our precedent hypothesis.},
  archive      = {J_ESWA},
  author       = {Hua Wang and Linwei Qiu and Jingfei Hu and Jicong Zhang},
  doi          = {10.1016/j.eswa.2025.129578},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129578},
  shortjournal = {Expert Syst. Appl.},
  title        = {UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval. <em>ESWA</em>, <em>298</em>, 129577. (<a href='https://doi.org/10.1016/j.eswa.2025.129577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has been widely used in large-scale multimedia retrieval due to its advantages in terms of low storage cost and computational efficiency. Deep hashing algorithms can jointly learn semantic features and hash functions, encoding the original data into compact binary codes with significant discriminative power. However, in multi-label scenarios, especially when the number of samples is extremely large, a high negative-positive imbalance may occur, particularly when the proportion of negative samples is too high, which can lead to bias in the semantic relationships between the learned images. To solve this problem, symmetric losses such as focal loss were proposed, which treat positive and negative samples equally, but the retrieval results are suboptimal. This may be because the equal-weighted processing strategy causes the model to over-focus on hard negative samples and ignore the learning of positive sample features. Besides, mislabeled negative samples, especially those with a probability close to 1, can lead the model to learn incorrect features, harming its discrimination ability, reducing accuracy and recall, and causing overfitting and poor generalization. Accordingly, this paper proposes a novel hashing model, Deep Asymmetric Semantic Hashing with Probability Shifting framework (DASH-PS), for discriminative binary code learning. Specifically, by combining asymmetric focusing strategy and probability shifting strategy, asymmetric semantic loss is designed to solve negative-positive imbalance and ground-truth mislabeling. To keep the contribution of positive samples while focusing on hard negative samples, asymmetric focusing strategy is proposed to decouple negative and positive samples and assign different attenuation factors. By offsetting the probability of negative samples, probability shifting strategy completely discards easy negative samples and very hard negative samples suspected of being mislabeled. Additionally, an adaptive asymmetric learning mechanism is proposed to reduce the fixed difference in average probabilities between positive and negative samples, thereby simplifying hyperparameter selection and improving retrieval efficiency. Extensive experimental results on multiple benchmark datasets validate that our DASH-PS outperforms various state-of-the-art hashing methods. The code for the implementation of our DASH-PS framework is available at https://github.com/QinLab-WFU/DASH-PS.},
  archive      = {J_ESWA},
  author       = {Yongyue Fu and Qibing Qin and Jinkui Hou and Congcong Zhu and Lei Huang and Wenfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129577},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129577},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed tensor autoencoder with memory for video anomaly detection. <em>ESWA</em>, <em>298</em>, 129576. (<a href='https://doi.org/10.1016/j.eswa.2025.129576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video data can be naturally represented as tensors. Despite great progress in anomaly detection with memory-augmented autoencoders, the memory module therein can only handle vectors and inevitably breaks tensor structures, thus leading to performance degradation. Moreover, after the mapping of the encoder, some abnormal features may directly fall into the normal convex polytope, as autoencoders only use the output error to guide the construction of latent variables without imposing any constraint. The memory module can not handle these abnormal features, so that the abnormal observations may not be identified. To solve these problems, we propose a Physics-Informed Tensor AutoEncoder (PITAE) framework, which incorporates both neural networks and physical laws, i.e., tensor operation rules. Specifically, we design a tensor decomposition network followed by an explicit tensor operation to decompose the latent variable into low-rank and sparse components, and only the low-rank component is inputted to the decoder. In this way, we reserve the tensor structure and meanwhile impose a low-rank constraint on the latent variable, thereby compressing the features of normal samples into a ”smaller” region where anomalies are less likely to fall into. Consequently, the non-low-rank anomalies can be identified. But the low-rank anomalies may still not be identified. To further solve this problem, we design a tensor Memory module, and the overall model is named as PITAEM. Finally, based on the proposed framework, we design a novel composite anomaly score to identify anomalies of various kinds. Experiments on various video datasets demonstrate the effectiveness of the proposed method, especially in the small data regime.},
  archive      = {J_ESWA},
  author       = {Jianan Liu and Chunguang Li},
  doi          = {10.1016/j.eswa.2025.129576},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129576},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-informed tensor autoencoder with memory for video anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust medical image encryption technique using inverse cosine chaotic map. <em>ESWA</em>, <em>298</em>, 129574. (<a href='https://doi.org/10.1016/j.eswa.2025.129574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid proliferation of digital imaging technologies, the need for robust and lightweight image encryption techniques has become increasingly critical, particularly for medical, military, and personal data applications. In this paper, we propose a novel image encryption scheme based on a one-dimensional inverse cosine chaotic map (1D-ICC), which introduces a highly sensitive and structurally complex nonlinear dynamical system. The proposed method integrates a dynamic Josephus-based intra-block scrambling mechanism, a global zigzag permutation strategy, and an adaptive diffusion process guided by chaotic sequences, thereby enhancing the confusion and diffusion characteristics of the cipher. Unlike conventional approaches, our scheme dynamically derives the encryption key from the SHA-512 hash of the original image, ensuring both sensitivity to plaintext changes and resistance to known-plaintext and chosen-plaintext attacks. The use of the 1D-ICC map, featuring a tunable control parameter r 5 enables rich chaotic behavior even in one dimension, reducing computational complexity without sacrificing security. Comprehensive experiments validate the robustness and efficiency of the encryption scheme, with performance metrics including correlation coefficients below 0.003, information entropy of 7.9993, a Number of Pixels Change Rate (NPCR) of 99.61 %, and a Unified Averaged Changed Intensity (UACI) of 33.42 %. These results demonstrate that our method surpasses several existing techniques in both security strength and computational performance, underscoring the potential of the 1D-ICC map for practical image encryption applications.},
  archive      = {J_ESWA},
  author       = {Jackson J and Perumal R},
  doi          = {10.1016/j.eswa.2025.129574},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129574},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust medical image encryption technique using inverse cosine chaotic map},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing text classification with neural label embedding and weakly-supervised learning. <em>ESWA</em>, <em>298</em>, 129569. (<a href='https://doi.org/10.1016/j.eswa.2025.129569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the widespread adoption of deep-learning-based models in a range of linguistic tasks including the fundamental text classification. These deep neural networks, however, often face challenges due to the limited availability of large-scale training data with high-quality label annotations. Furthermore, while supervised learning has proven to be superior in training sentence representations for downstream tasks like text classification, this aspect has received relatively little attention. In this study, a novel model named L abel Em bedding joint with We akly-supervised C lassification ( LemWec ) is proposed, which aims to establish a unified framework by combining supervised sentence embedding with multiclass classification. For supervised sentence embeddings, the model incorporates seed information such as label names and designs an encoder network with a new pooling layer. Additionally, the model adopts a pseudo-labeling approach to leverage a substantial amount of unlabeled samples. This approach specifically addresses the drawback of generating pseudo-labels with the highest confidence and introduces a noise adaptation method to mitigate this issue. The results of extensive experiments conducted on four real-world datasets demonstrate that the proposed LemWec model can significantly enhance the performance of text classification when compared to a comprehensive set of baselines.},
  archive      = {J_ESWA},
  author       = {Xiao Jing and Zhe Li and Zhiang Wu and Dejun Mu},
  doi          = {10.1016/j.eswa.2025.129569},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129569},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing text classification with neural label embedding and weakly-supervised learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data. <em>ESWA</em>, <em>298</em>, 129568. (<a href='https://doi.org/10.1016/j.eswa.2025.129568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell clustering plays a vital role in single-cell RNA sequencing (scRNA-seq) data analysis. Although many deep cell clustering methods have been proposed to cluster the scRNA-seq data, they overlook the structural partitioning objectives during the representation learning process, leading to challenges with non-linearly separable structures. In this paper, we present a novel end-to-end deep kernel cell clustering model for scRNA-seq data based on self-supervised ZINB-based kernel representation learning, named scDKC, which simultaneously learns cell kernel representations and identifies cell clusters. Specifically, a kernel-aid hybrid representation learning encoder is developed to effectively learn the separable kernel representation of cells, consisting of cells’ expression characteristics and cell-cell topological interactions. To guide the direction of kernel representation learning, a ZINB-based kernel representation learning decoder is designed by capturing the global probabilistic structure, the representation and the cell graph structure of the scRNA-seq data. By leveraging the clustering self-supervised strategy, representation self-supervised strategy, ZINB-based distribution self-supervised strategy, and kernel self-supervised strategy, scDKC optimizes cell cluster label assignment and learns cell kernel representations through a joint mutual self-supervised mechanism. Extensive experiments on 15 real scRNA-seq datasets, comparing scDKC with 10 competing methods, highlight its competitive advantages.},
  archive      = {J_ESWA},
  author       = {Lina Ren and Maoxuan Yao and Ruizhang Huang and Yongbin Qin},
  doi          = {10.1016/j.eswa.2025.129568},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129568},
  shortjournal = {Expert Syst. Appl.},
  title        = {Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dual uncertainty-aware fusion framework for face expression recognition in the wild. <em>ESWA</em>, <em>298</em>, 129567. (<a href='https://doi.org/10.1016/j.eswa.2025.129567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition(FER) is a key task in the broader landscape of affective computing and human-computer interaction, enabling machines to interpret human emotions. To better learn discriminative features under complex facial variations, recent FER research has increasingly adopted multi-branch fusion architectures that aim to capture complementary features from diverse perspectives. However, existing multi-branch fusion strategies, including static weighting, simple concatenation, or uncertainty-aware modeling, lack the capacity to comprehensively capture and reconcile the reliability variations across both individual instances and structural branches. To overcome these limitations, we propose a novel multi-branch fusion strategy, named Dual Uncertainty-Aware Fusion Framework(DUAFF), which improves the discriminability of integrated features by simultaneously modeling instance-wise uncertainty and inter-branch correlations. Specifically, the proposed method comprises two complementary modules: Instance-Discrepant Uncertainty-Aware Fusion Module (ID-UAFM) and Branch-Discrepant Uncertainty-Aware Fusion Module (BD-UAFM). ID-UAFM is introduced to perform channel-wise entropy analysis between semantically distinct samples to estimate instance-level uncertainty, enabling selective channel-wise fusion that emphasizes reliable representations while suppressing uncertain responses. BD-UAFM is further proposed to capture structural uncertainty by evaluating the relative reliability of features across multiple branches and adaptively weighting their contributions based on inter-branch discrepancies. Experimental results demonstrate that the proposed DUAFF consistently outperforms POSTER across three benchmark datasets, achieving accuracy improvements of 0.23 % on RAF-DB, 0.69 % on FER2013, and 0.29 % on AffectNet (7-class), thereby confirming its effectiveness in enhancing the reliability and discriminability of facial representations.},
  archive      = {J_ESWA},
  author       = {Wenfeng Jiang and Ziyi Zhao and Lin Wang and Fang Liu and Chunmei Qing and Xiaofen Xing and Xiangmin Xu and Weiquan Fan and Zhanpeng Jin},
  doi          = {10.1016/j.eswa.2025.129567},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129567},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dual uncertainty-aware fusion framework for face expression recognition in the wild},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data. <em>ESWA</em>, <em>298</em>, 129566. (<a href='https://doi.org/10.1016/j.eswa.2025.129566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel multiscale and multivariable deep learning framework for tourism stock index forecasting. To address the research gap concerning emerging media’s impact on the tourism sector, our study innovatively integrate multi-source data, including Douyin (China’s prominent short video platform), into our predictive model. Our methodology employs a multiscale decomposition strategy to streamline feature extraction complexity, coupled with an enhanced temporal convolutional network model incorporating soft-thresholding denoising to mitigate noise interference. Furthermore, we implement an adaptive differentiated prediction strategy to optimize model flexibility. Empirical analysis utilizing the CSI Tourism Stock Index demonstrates that our proposed model outperforms benchmark models in both predictive accuracy and stability, thereby validating its efficacy in tourism stock index forecasting.},
  archive      = {J_ESWA},
  author       = {Feng Shen and Shuai Huang and Wanqing Zhao and Dao Lan},
  doi          = {10.1016/j.eswa.2025.129566},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129566},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing adversarial transferability through frequency-domain boundary samples tuning. <em>ESWA</em>, <em>298</em>, 129565. (<a href='https://doi.org/10.1016/j.eswa.2025.129565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer-based attacks evaluate the robustness of deep learning models and advance adversarial research to improve the security and reliability of deep learning and its applications. Previous efforts have improved the transferability through advanced gradients, augmented models, or augmented data. In this paper, we understand and enhance the transferability from a new perspective. Delving into intermediate features, we empirically find a difference between the distances of adversarial and original samples from cluster centers of the original classes. The adversarial samples are simultaneously far from both the original samples and the cluster centers, close to generalized decision boundaries. Based on this observation, we propose a novel spectrum tuning attack. Boundary samples are utilized to guide the generation of adversarial samples that are far away from the cluster centers. Specifically, randomized boundary samples are generated by frequency-domain transformations. With the gradients of the diverse boundary samples, the adversarial perturbation moves the examples away from cluster centers, thus approaching generalized decision boundaries. In the optimization process, conjugate directions are employed to avoid oscillations and stabilize the update direction. Given the strong Wolfe parameters, the analysis of the descent direction and current gradient further ensures the convergence speed and stability of the optimization. In addition, Gaussian preprocessing is introduced to smooth the update direction, further stabilize the direction and enhance the transferability. The proposed method is flexible enough to be combined with existing methods to further improve the transferability. Experiments conducted on the ImageNet-compatible dataset validate the effectiveness of the proposed method, e.g., 92.6 % success rate against nine defense methods.},
  archive      = {J_ESWA},
  author       = {Shuyan Cheng and Peng Li and Keji Han and Yangjun Xiong and He Xu and Ruchuan Wang},
  doi          = {10.1016/j.eswa.2025.129565},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129565},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing adversarial transferability through frequency-domain boundary samples tuning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When graph anomaly breaks the coherence: A multi-evidence approach with language models. <em>ESWA</em>, <em>298</em>, 129557. (<a href='https://doi.org/10.1016/j.eswa.2025.129557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is critical in domains such as healthcare and economics, where identifying deviations can prevent substantial losses. However, current detection methods, primarily reliant on Graph Neural Networks (GNNs), suffer from a critical limitation: they make judgment on a single piece of evidence – the classification of learned node representations. This “single-verdict” approach is inherently susceptible to misjudgments arising from noisy or biased representations. To address this limitation, we introduce Multi-AD, a novel Multi-evidence-based graph Anomaly Detection framework that leverages the power of Language Models (LMs) to enable more robust and reliable anomaly detection. We provide a paradigm shift by constructing multiple evidence sequences for each target node, and employing LMs to assess the coherence of these sequences. By aggregating coherence scores across multiple sequences, Multi-AD leverages converging evidence to make more informed decisions about anomaly status as the presence of anomalous nodes disrupts coherence. Furthermore, we introduce a coherence-aware edge representation method to enhance the discriminative power of the constructed sequences and a multi-round adaptive integration strategy to handle challenging scenarios where normal nodes might be surrounded by anomalies. Extensive experiments demonstrate that Multi-AD consistently outperforms state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xuan Cheng and Jiahui Lu and Chunjing Xiao and Meiyi Yang and Meihui Zhong and Fan Zhou},
  doi          = {10.1016/j.eswa.2025.129557},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129557},
  shortjournal = {Expert Syst. Appl.},
  title        = {When graph anomaly breaks the coherence: A multi-evidence approach with language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal joint subspace model for parkinson’s disease diagnosis. <em>ESWA</em>, <em>298</em>, 129556. (<a href='https://doi.org/10.1016/j.eswa.2025.129556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is an irreversible neurodegenerative disorder that significantly impacts patients’ lives. Accurate early diagnosis prediction is crucial for providing timely treatment to delay disease progression. However, current diagnostic methods predominantly rely on the experience and judgment of clinicians, introducing subjectivity and a lack of standardized, quantitative measures. Sparse subspace learning, as a machine learning technique, can extract critical information from multimodal data while addressing issues such as noise, high-dimensional complexity, and class imbalance. Our study utilizes longitudinal, multimodal neuroimaging data collected at multiple time points to develop a diagnostic model for PD. The approach involves extracting latent local features and leveraging deep learning techniques to generate a comprehensive global feature subset. Adaptive sparse selection is employed to reduce feature redundancy. Finally, support vector machine is used for classification and regression tasks, specifically for PD diagnosis and disease progression score prediction. Extensive experiments were conducted on the PPMI dataset, achieving an accuracy of 90.78 % for Scan Without Evidence of Dopaminergic Deficit (SWEDD) vs. Normal Control (NC) classification, 83.79 % for PD vs. NC, and 91.50 % for PD vs. SWEDD. The results demonstrate that the proposed method improves PD classification and prediction performance, showing promise for early diagnostic applications.},
  archive      = {J_ESWA},
  author       = {Haojie Song and Haijun Lei and Yukang Lei and Zhongwei Huang and Jiaqiang Li and Tianfu Wang and Peng Yang and Baiying Lei},
  doi          = {10.1016/j.eswa.2025.129556},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129556},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal joint subspace model for parkinson’s disease diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spectral relevance analysis approach to pattern recognition of financial time series. <em>ESWA</em>, <em>298</em>, 129555. (<a href='https://doi.org/10.1016/j.eswa.2025.129555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding patterns in financial time series is crucial for improving prediction accuracy in algorithmic trading and risk management. This paper presents a novel AI-based computer vision approach for classifying financial time series. Historical price sequences are transformed into Gramian Angular Difference Field (GADF) images and fed into a convolutional neural network (CNN) for pattern recognition. To interpret the CNN’s decision-making process, we apply Spectral Relevance Analysis (SpRAy), enabling the identification of distinct clusters based on relevance maps. Clustering the images according to their relevance profiles reveals groups with significantly higher predictive performance compared to the full dataset. The corresponding relevance patterns highlight favorable price movement structures and are identified via the associated clusters.},
  archive      = {J_ESWA},
  author       = {Christine Distler and Yarema Okhrin and Jonathan Pfahler},
  doi          = {10.1016/j.eswa.2025.129555},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129555},
  shortjournal = {Expert Syst. Appl.},
  title        = {A spectral relevance analysis approach to pattern recognition of financial time series},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector. <em>ESWA</em>, <em>298</em>, 129554. (<a href='https://doi.org/10.1016/j.eswa.2025.129554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object identification is one of the computer vision-based methods used in locating and labelling objects in images. Object detection has been greatly advanced as it is now applicable for detecting night vision images with great accuracy. Most accurate object detection at night can be useful in many applications like nighttime driving, regulating harsh traffic in harsh weather conditions, and surveillance. Object detection in normal conditions can be smoother, but low illumination and harsh weather can lead to low versatility. Images captured at night can reflect a lot of noise with low visual features. Due to its challenging nature, a highly effective object detection model is a challenge for high-level applications. Traditional models still face issues and challenges related to uneven light conditions, brightness variations, different light sources, and noisy backgrounds that need to be addressed. Thus, it is necessary to develop an object detection model for dealing with images with low illumination and varying light conditions. Hence, in this work, an effective object detection framework is implemented for night vision images. At first, from the standard datasets, the significant night vision images are fetched and fed into the proposed model as a Residual 3D Transformer-based YoloV8 with an Adaptive Gated Recurrent Unit (R3DT-YAGRU) for detecting the objects. This includes combining spatial–temporal modelling capabilities into YOLOv8, particularly using 3D transformers for improved feature extraction and an adaptive GRU to manage temporal dependencies at night. Here, the Modified Random Variable-based Dollmaker Optimization Algorithm (MRV-DOA), which is a metaheuristic algorithm motivated by the doll-making procedure. Also, it helps in balancing the exploration phase and exploitation phase to discover the best solutions and is used for tuning the parameters of the R3DT-YAGRU model. At last, the experimental validation is carried out for the recommended object detection process by comparing with other models to establish the supremacy of the suggested work. From the study, the suggested framework achieves an accuracy of 96%, leading to enhanced decision making and better accuracy than other conventional models. The work has prepared its implementation accessible at https://github.com/charlesvprabhu56/Object-Detection .},
  archive      = {J_ESWA},
  author       = {V.Charles Prabu and Queen Mary Vidya. M and V. Sathiyamoorthi and P. Durgadevi and M. Gowthami},
  doi          = {10.1016/j.eswa.2025.129554},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129554},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning diversified features for pulmonary hypertension detection using chest X-ray. <em>ESWA</em>, <em>298</em>, 129553. (<a href='https://doi.org/10.1016/j.eswa.2025.129553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional Computed Tomography (CT) scans and floatation catheters, chest X-ray offers an efficient, safe and timely examination paradigm, with broader range of scenarios (including intensive care units), for the detection of Pulmonary Arterial Hypertension (PAH). However, it is difficult to learn the variable radiological features of PAH from X-rays due to its low resolution and low contrast. To address the above issues, we propose a diversified features learning framework to fully explore the PAH-related representation from chest X-ray. We first employ a Chest Feature Enhancement Attention (CFEA) module to enhance the initial feature representation. Then, we employ the Deep Temporal Anti-Interference Metric Learning (TAIML) module to fully explore the PAH-related features. We incorporate the information on the temporal evolution of patients’ conditions. Specifically, a patient x , after undergoing treatment, may exhibit two possible states: x + (ill) and x − (cured). Therefore, we can define the distance d ( x , x + ) as the intra-class structural distance, and the distance d ( x , x − ) as the inter-class safe distance. Unlike existing metric learning, we adopt a new strategy: we push positive samples towards negative samples, but ensure distance between them is no less than d ( x , x − ) , thereby enhancing intra-class diversity while maintaining discriminability. Meanwhile, we ensure that the distance between positive samples is greater than d ( x , x + ) , thereby preserving the intra-class structure. Through these two steps, we can learn a diversified but discriminative representation of PAH. Comprehensive experiments showed the our model achieved an impressive accuracy of 86.27 % and an AUC of 0.857 in identifying PAH patients. The code is available at https://github.com/zgfdmn/PAH .},
  archive      = {J_ESWA},
  author       = {Chengjin Yu and Huanghui Wang and Yuanting Yan and Zhuyang Chu and Dongsheng Ruan},
  doi          = {10.1016/j.eswa.2025.129553},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129553},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning diversified features for pulmonary hypertension detection using chest X-ray},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data. <em>ESWA</em>, <em>298</em>, 129552. (<a href='https://doi.org/10.1016/j.eswa.2025.129552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the emergency triage has faced several challenges, including insufficient manual triage with physicians, limited medical resources contributing to incorrect triage, overcrowding in the emergency department (ED), and extended patient waiting time. Hence, the Medical Emergency prediction remains the major research area that identifies emergencies about specific diseases using the Medical Transcriptions (MT) provided by physicians. However, the existing methods face the challenges of handling the ambiguity of words, unstructured data, and increased computation complexity. Consequently, this research proposes the Tri-Head Attention-based Bidirectional Encoder Representations from Transformers enabled Distributed Bidirectional Long-Short Term Memory (TriHAtt-BERT-DBiLSTM) for predicting medical emergencies. Specifically, the proposed approach integrates the Tri-Head Attention mechanisms into BERT, which is further hybridized with the DBiLSTM model that offers the synergic strength of providing the dense feature representations to capture the complex dependencies, and enhancement of model ability with the structured parameters to facilitate the medical emergency prediction. Besides, the utilization of BERT in the proposed approach assists in capturing more complex language representations and further executes a better embedding representation of words. The TriHAtt-BERT-DBiLSTM model surpasses other state-of-the-art techniques and achieves 96.40% of accuracy, 96.12% of F1-score, 96.09% of precision, and 96.15% of recall for medical emergency prediction.},
  archive      = {J_ESWA},
  author       = {Amita Mishra and Sunita Soni},
  doi          = {10.1016/j.eswa.2025.129552},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129552},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing. <em>ESWA</em>, <em>298</em>, 129551. (<a href='https://doi.org/10.1016/j.eswa.2025.129551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contact ring seals (CRSs) used in electroplating processes during semiconductor manufacturing are susceptible to degradation through chemical etching, electrochemical dissolution, and mechanical wear mechanisms. Despite the implementation of state-of-the-art surface treatment and coating technologies to mitigate CRS corrosion, manual intervention remains frequently required to address this problem. Conventional static defect detection systems for CRSs rely on predefined regions of interest (ROIs) and threshold-based defect area calculations, with surface anomalies identified by comparing the percentage of defective areas within these ROIs. However, this approach exhibits detection failures for millimeter-scale defects, low-contrast anomalies, and geometrically irregular patterns, especially under complex or dynamic environmental conditions. To address these systematic detection failures, we developed a dynamic defect detection system for CRSs by integrating artificial intelligence and traditional computer vision algorithms, achieving a 5.2x improvement in defect detection sensitivity. This system achieved detection accuracy and recall values of over 99 % as well as a response time of 1.43 s average latency, thereby demonstrating a substantial performance improvement compared to a static system, which achieved a recall rate of 18.9 % on the adopted dataset. The system satisfies real-time processing requirements while substantially reducing the need for manual intervention in defect detection and increases production efficiency. Finally, the experimental results of this study indicated that the postprocessing approaches used in the developed system enabled it to flexibly adapt to the different requirements of various production environments.},
  archive      = {J_ESWA},
  author       = {Ting-Han Chen and Hsin-Hung Chou and Shuang Zou and Yu-Han Chen and Sun-Yuan Hsieh},
  doi          = {10.1016/j.eswa.2025.129551},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129551},
  shortjournal = {Expert Syst. Appl.},
  title        = {System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification. <em>ESWA</em>, <em>298</em>, 129549. (<a href='https://doi.org/10.1016/j.eswa.2025.129549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of land remote sensing using single-modal data has reached a bottleneck, which has spurred significant interest in the joint utilization of multimodal remote sensing data to enhance classification performance. However, existing methods exhibit limitations in extracting intricate local and global features. Furthermore, achieving effective information interaction and deep fusion between multimodal datasets remains an unresolved challenge. To address these issues, we propose a Complementary Information-Guided Interactive Fusion Network (CIGIF-Net) for the classification of hyperspectral image (HSI) and light detection and ranging (LiDAR) data. The core idea of our approach leverages the capability of Convolutional Neural Networks (CNNs) to extract local spatial features while utilizing the strengths of Transformers in modeling long-range dependencies. Furthermore, our method facilitates deep fusion by designing mechanisms for the interactive integration of multimodal local spatial features, complemented by guidance from multimodal data during long-range dependency modeling, thereby improving overall classification performance. Specifically, CIGIF-Net incorporates multiscale feature learning, interactive feature fusion, and the complementary information-guided attention mechanism. Initially, CNNs are used to learn multiscale local spatial features. Subsequently, we perform an interactive fusion of multimodal spatial information based on channel attention techniques. Finally, the complementary information-guided attention mechanism dynamically utilizes complementary insights to inform deeper attention distributions, which guide global feature construction and enable efficient information aggregation. This methodology allows for the comprehensive extraction and synergistic utilization of complementary information across multimodal datasets. Extensive experiments conducted on three widely recognized HSI and LiDAR datasets demonstrate that the proposed CIGIF-Net achieves superior classification performance.},
  archive      = {J_ESWA},
  author       = {Shufang Xu and Qiyuan Xue and Zhonghao Chen and Shuyu Fei and Hongmin Gao},
  doi          = {10.1016/j.eswa.2025.129549},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129549},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GPT–empowered question–answer dataset for informative and empathetic support for korean childhood cancer survivors. <em>ESWA</em>, <em>298</em>, 129548. (<a href='https://doi.org/10.1016/j.eswa.2025.129548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite improvements in survival rates, childhood cancer survivors in South Korea still face significant challenges in accessing the psychological and informational support they need. To address these challenges, we developed the Korean Childhood Cancer Survivor Question-Answer (KCCSQA) dataset in which contains 3876 question-answer pairs. The questions were sourced from websites, academic articles, and an online survey, where 119 childhood cancer survivors contributed 1283 questions. We used GPT-4 Turbo to generate the responses, followed by an expert evaluation by 11 specialists to ensure factual accuracy, complementarity, comprehensibility, and empathy. The overall quality of the GPT-generated responses was rated 4.98 out of 6, indicating a high level of quality. To enhance the dataset, we integrated a relational knowledge graph to mitigate hallucinations in the AI-generated answers, achieving a performance of 0.979 in hallucination detection. Additionally, a pseudo-scoring system was implemented for continuous quality assessment. The dataset’s effectiveness was evaluated through a pilot study involving 14 childhood cancer survivors, who interacted with a retrieval-based QA system using a single-turn chatbot format. The mean satisfaction rating was 4.36 on a 6-point Likert scale, and all participants expressed a willingness to use the system again.},
  archive      = {J_ESWA},
  author       = {Kyubum Hwang and Mirae Kim and Min Ah Kim and Chaerim Park and Yehwi Park and Chungyeon Lee and Jooyoung Lim and Hayoung Oh},
  doi          = {10.1016/j.eswa.2025.129548},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129548},
  shortjournal = {Expert Syst. Appl.},
  title        = {GPT–empowered question–answer dataset for informative and empathetic support for korean childhood cancer survivors},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach. <em>ESWA</em>, <em>298</em>, 129544. (<a href='https://doi.org/10.1016/j.eswa.2025.129544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced Decision Support System (DSS) for long-term open-pit mine planning that integrates established optimization techniques—Large Neighborhood Search (LNS), Simulated Annealing (SA), and Dantzig-Wolfe decomposition—within a novel GPU-accelerated framework addressing geological uncertainty and computational complexity. The key methodological contributions include dynamic uncertainty modelling with time-dependent factors capturing geological confidence degradation and GPU-parallelized evaluation architecture enabling industrial-scale mine planning. Validation using 50,000 blocks across 10 geological scenarios demonstrates robust economic performance, achieving mean NPV of $1.514 billion with limited variability (standard deviation $16 million). The GPU-parallelized architecture achieves 29.6 % average computational speedup with peaks of 37 % compared to CPU implementations, enabling concurrent evaluation of 262,144 mining scenarios. Risk analysis reveals P90 Value-at-Risk of $1.488 billion, indicating strong downside protection. The system maintains profit margins exceeding 95 % across all scenarios with cumulative cash flow reaching $1.789.4 million by period 6. Narrow risk envelopes (P10-P90 spread <$60 M) demonstrate robust performance under uncertainty, providing mining companies with practical tools for risk-informed strategic decision-making.},
  archive      = {J_ESWA},
  author       = {Iman Rahimi},
  doi          = {10.1016/j.eswa.2025.129544},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129544},
  shortjournal = {Expert Syst. Appl.},
  title        = {A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment. <em>ESWA</em>, <em>298</em>, 129543. (<a href='https://doi.org/10.1016/j.eswa.2025.129543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of IoT devices in daily applications, securing them against intrusions has become increasingly critical. Domain adaptation (DA)-based intrusion detection is a promising approach that transfers knowledge from a source domain to improve detection in a target IoT domain. However, effective DA methods must address various types of domain heterogeneity - such as differences in feature representation, intrusion distribution, and attack strategies. Existing intrusion detection datasets rarely consider these aspects, limiting their utility for evaluating heterogeneous DA approaches. To bridge this gap, we introduce TriHID , a new dataset specifically designed to capture heterogeneities from three perspectives. We evaluate four types of DA-based IoT intrusion detectors - multi-source, semi-supervised, unsupervised, and open-set on TriHID. Experimental results demonstrate that TriHID enables robust training and comprehensive evaluation of DA-based intrusion detection methods in heterogeneous IoT settings.},
  archive      = {J_ESWA},
  author       = {Jiashu Wu and Yang Wang},
  doi          = {10.1016/j.eswa.2025.129543},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129543},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning. <em>ESWA</em>, <em>298</em>, 129542. (<a href='https://doi.org/10.1016/j.eswa.2025.129542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing environments, job shop scheduling systems are characterized by heightened complexity and ever-changing dynamics, often involving multi-objective optimization and the need to accommodate unanticipated events like new job insertions and uncertain machine availability, underscores the necessity for effective real-time multi-objective scheduling approaches. Therefore, to tackle the multi-objective dynamic flexible job shop scheduling problem (MODFJSP) involving new job insertions, this paper introduces an online scheduling framework called multi-head deep Q network (MHDQN), designed to simultaneously minimize both total tardiness and total machine idle time. The core architecture of MHDQN framework is an innovative multi-head network agent based on Dueling deep Q network (Deuling DQN), consisting of a shared network layer and objective-specific network layers. The shared network layer extracts and transforms the input global state features layer by layer, generating a high-dimensional, semantically rich shared feature. This provides a unified input foundation for the objective-specific network layers, which are responsible for extracting the specialized information related to each objective from the shared features and calculating the corresponding Q -values, thereby enabling the parallel optimization of each objective. Six combined scheduling rules are developed to form the action set, each incorporating both job and machine selection. An improved multi-objective action selection strategy is proposed, incorporating inverse sigmoid ϵ decay and Q -value maximum absolute (max-abs) normalization to optimize decision-making. Additionally, a multi-head network training mechanism leveraging the Double deep Q network (Double DQN) architecture has been developed. Extensive computational experiments demonstrate that the MHDQN outperforms widely used traditional scheduling rules, multi-objective metaheuristic algorithms, and other reinforcement learning (RL) based scheduling methods, showing significant advantages and strong generalizability in multi-objective optimization tasks.},
  archive      = {J_ESWA},
  author       = {Kai Li and Bao Zheng and Liping Xu and Fulong Xie and Zhicheng Wang},
  doi          = {10.1016/j.eswa.2025.129542},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129542},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain. <em>ESWA</em>, <em>298</em>, 129539. (<a href='https://doi.org/10.1016/j.eswa.2025.129539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing platelet supply chains poses significant challenges due to the product’s short shelf life, highly uncertain demand, and the critical nature of its medical use. Previous studies in the blood supply chain rely on fixed-order quantities and ignore collaborative inventory-sharing strategies, which can lead to either excessive waste or severe shortages. However, in many real-world situations, fixed order quantities are often insufficient to accommodate fluctuating demand, especially in healthcare systems. Moreover, existing distribution models in the literature often overlook the equitable allocation of services across hospitals, leading to disparities in access to critical healthcare resources. This study proposes a novel two-phase decision-making framework that integrates a fuzzy periodic review inventory model with a cluster-based reactive transshipment strategy to optimize platelet supply and distribution. In Phase I, a fuzzy periodic review model determines optimal order quantities under uncertain demand using a possibilistic chance-constrained programming approach. In Phase II, hospitals are clustered based on service levels, enabling equitable transshipment among facilities to reduce disparities and improve overall responsiveness. A real-world case study from Tehran province is used to evaluate the model’s effectiveness. Results show an approximate 6% reduction in total shortages and a 2% improvement in average service levels. The proposed framework offers actionable insights for healthcare managers aiming to enhance resilience, equity, and efficiency in critical medical supply chains.},
  archive      = {J_ESWA},
  author       = {Seyyed-Mahdi Hosseini-Motlagh and Mohammad Reza Ghatreh Samani and Hannaneh Kordhaghi},
  doi          = {10.1016/j.eswa.2025.129539},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129539},
  shortjournal = {Expert Syst. Appl.},
  title        = {A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-insights guided evolutionary algorithm for optimization. <em>ESWA</em>, <em>298</em>, 129538. (<a href='https://doi.org/10.1016/j.eswa.2025.129538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are a class of optimization algorithms inspired by the theory of biological evolution. They solve optimization problems by emulating the processes of natural selection. EAs produce abundant data during evolution, which contains valuable information that reflects their evolutionary patterns. Effectively utilizing this information can enhance the algorithms’ effectiveness and efficiency. Deep learning excels at extracting knowledge from data. Inspired by this, we propose a novel insights-infused framework that utilizes deep neural networks to learn the evolutionary processes of EAs and extract useful synthesis insights from the evolutionary data. These synthesis insights not only guide the algorithm to evolve in a better direction on the original problems, but also improve its performance on new problems. The choice of neural networks is important. During pre-training, to reduce the inductive bias introduced by human prior knowledge, we design an MLP model to process the data. Additionally, we develop a variable-length encoding method to enable MLP networks to handle variable-length data. To verify the transfer evolution ability of synthesis insights, we devise a self-evolution strategy that fine-tunes the network using only the data generated by the algorithm itself, without introducing any external knowledge, when dealing with new problems. Experimental results demonstrate that the synthesis insights extracted from the CEC2014 dataset guide the algorithms to evolve in a better direction for the CEC2014 problems, and in addition enhance their performance on new problems like CEC2017, CEC2022 and the real-world optimization problems.},
  archive      = {J_ESWA},
  author       = {Kun Bian and Juntao Zhang and Hong Han and Jun Zhou and Yifei Sun and Shi Cheng},
  doi          = {10.1016/j.eswa.2025.129538},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129538},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-insights guided evolutionary algorithm for optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MambaGen: Efficient visual representation learning for automatic radiology report generation. <em>ESWA</em>, <em>298</em>, 129537. (<a href='https://doi.org/10.1016/j.eswa.2025.129537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation focuses on producing comprehensive and clinically precise medical reports based on radiographic images, thereby improving medical efficiency and alleviating the burden on radiologists. Although existing deep learning methods have demonstrated superior performance, they are constrained by the local receptive field of convolutional neural networks and are inadequate for modeling long-range dependencies, making it challenging to detect critical lesion features in medical images. Recently, State Space Models (SSMs), particularly Mamba, have shown great potential in modeling long-range dependencies with linear computational complexity. Inspired by this, we propose MambaGen, the enhanced Mamba model specifically designed for radiology report generation tasks. Specifically, we design a Mamba-Visual Recalibration Module (MVRM), which utilizes a two-stage training strategy to effectively capture the efficient visual representation of medical images. This first stage combines convolutional layers with SSMs to model long-sequence dependencies and learn multi-level visual feature information. This second stage introduces local convolution and a channel attention mechanism to further recalibrate the local feature and mitigate channel redundancy. Comprehensive experiments on widely available datasets, such as IU X-Ray and MIMIC-CXR, demonstrate our model’s superior performance compared to existing methods, particularly with an improvement of 2.7 % on the BLEU-4 metric. The code is available at https://github.com/Eleanorhxd/MambaGen.git .},
  archive      = {J_ESWA},
  author       = {Xiaodi Hou and Xiaobo Li and Simiao Wang and Mingyu Lu and Hongfei Lin and Yijia Zhang},
  doi          = {10.1016/j.eswa.2025.129537},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129537},
  shortjournal = {Expert Syst. Appl.},
  title        = {MambaGen: Efficient visual representation learning for automatic radiology report generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction. <em>ESWA</em>, <em>298</em>, 129532. (<a href='https://doi.org/10.1016/j.eswa.2025.129532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling nitrogen oxide (NO x ) emissions from diesel vehicles is a critical environmental challenge. Advanced SCR strategies depend on accurate multistep forecasting of NO x and ammonia (NH 3 ), but existing models often struggle with error accumulation and the non-stationary dynamics of emissions data. In this work, we first establish a new benchmark for this task, confirming that handling data non-stationarity is essential for robust prediction. Building on this insight, we propose FiTformer, a novel Transformer architecture that adopts an encoder-only framework to jointly forecast both NO x and NH 3 concentrations, where we introduce Intra-series Temporal-Frequency Fusion mechanism to capture intrinsic emissions dynamics and Inter-series Covariate Interaction mechanism to model external influences. Validated on real-world engine data, FiTformer consistently outperforms baseline models across all evaluated prediction horizons, with up to 44.1 % MAE and 36.9 % SMAPE reductions in 24-step NO x prediction and similarly strong gains for NH 3 prediction, compared to the state-of-the-art baseline TimesNet. Its high computational efficiency (0.30G MACs and 8.3 ms/iter) along with robust generalization and high resilience to data imperfections, underscores its suitability for real-time embedded SCR control, enabling more effective strategies for NO x reduction and NH 3 slip minimization.},
  archive      = {J_ESWA},
  author       = {Yuhan Luo and Yujun Zhang and Ying He and Kun You and Wei Huang and Wenqing Liu and Hao Xie},
  doi          = {10.1016/j.eswa.2025.129532},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129532},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes. <em>ESWA</em>, <em>298</em>, 129530. (<a href='https://doi.org/10.1016/j.eswa.2025.129530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-limited epilepsy with centrotemporal spikes (SeLECTS) is the most common form of focal epilepsy in childhood, accounting for 20–25 % of all childhood epilepsy cases and may be associated with cognitive dysfunction and behavioral issues. Accurate detection and assessment of epileptic discharges in EEG signals, particularly the spike-wave index (SWI), are crucial for timely intervention and treatment. Manual analysis of EEG data is labor-intensive and prone to errors, underscoring the need for automated methods. In the present study, we propose a novel D ual-Str e am Sp a tial- S pectral- T emporal L arge model (DeaSTL) that leverages a large-scale EEG architecture to effectively capture the multidimensional characteristics of EEG signals associated with SeLECTS syndrome. Our model integrates multi-view temporal representations and spatial-spectral representations through a dual-stream approach, enhancing the learning of complex patterns in EEG data. We introduce the S JTU Se L ECTS E EG D ataset (SLED), a comprehensive EEG dataset from 212 patients diagnosed with SeLECTS, including annotations for abnormal discharge detection, wake-sleep period classification, and SWI estimation. Addressing the previously unexplored problem of SWI prediction, we provide a novel method for quantifying the severity of epileptic discharges during sleep. Extensive experiments demonstrate that our DeaSTL model significantly outperforms several state-of-the-art methods across multiple tasks, showcasing its potential for clinical application in assisting diagnosis and treatment planning.},
  archive      = {J_ESWA},
  author       = {Lin Zhang and Yun Ren and Fang Yuan and Xuqin Chen and Shikui Tu and Lei Xu},
  doi          = {10.1016/j.eswa.2025.129530},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129530},
  shortjournal = {Expert Syst. Appl.},
  title        = {An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic learning of sample ambiguity-driven sample weighting for medical image classification. <em>ESWA</em>, <em>298</em>, 129527. (<a href='https://doi.org/10.1016/j.eswa.2025.129527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have delivered impressive results in medical image classification tasks. However, their performance is still challenging in medical scenarios with limited data, where training set biases such as label noise or class imbalance impede model learning. Dynamic learning based sample weighting achieves adaptive adjustment of sample importance through learnable weight functions and shows great potential in improving model robustness. Nevertheless, existing methods directly employ model states such as loss value or training accuracy to evaluate sample importance, ignoring the role of ambiguous samples in model optimization. This limitation hinders the performance of dynamic learning based sample weighting in medical image classification. In this paper, we propose a new sample weighting approach based on sample ambiguity and dynamic learning for improving medical image classification, named DLSA-SW. We introduce a dual-space sample ambiguity method by evaluating the category proximity in the feature space and the prediction confidence in the label space. Subsequently, to dynamically calculate sample weights according to sample ambiguity, a learnable sample weighting network is developed to adaptively adjust the weights during training to guide the task model. DLSA-SW performs alternate optimization to enable mutual adaptation of the sample weighting network and the task network. We evaluate the effectiveness of our approach on three medical image classification benchmarks: PatchCamelyon for lymph node histopathology classification, ISIC 2020 for skin lesion classification, and MTC for medullary thyroid cancer classification. DLSA-SW outperforms existing state-of-the-art sample weighting methods on all three datasets and yields substantial improvements over methods without sample weighting. These results demonstrate the robustness and practical applicability of our approach in clinical diagnostic tasks.},
  archive      = {J_ESWA},
  author       = {Guanxiu Yi and Xiabi Liu and Ling Ma and Mengqiao Han and Lijuan Niu},
  doi          = {10.1016/j.eswa.2025.129527},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129527},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic learning of sample ambiguity-driven sample weighting for medical image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement. <em>ESWA</em>, <em>298</em>, 129526. (<a href='https://doi.org/10.1016/j.eswa.2025.129526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact manner of measuring heart rate variability (HRV) by deriving blood volume pulse (BVP) signals from facial videos. The performance of rPPG-based HRV measurement is challenging due to short-range noises (e.g., head movements) suppression and sufficient-duration BVP signal generation. Recent Transformer-based rPPG methods have shown advantages of global spatio-temporal feature modeling in eliminating noise and recovering high-quality BVP signals. However, these methods often face significant computational and memory constraints, limiting duration scalability of the generated BVP signals that might decrease HRV measurement performance. To address the above issue, this paper proposes a duration-scalable Transformer-based rPPG method, capable of global Long-range Spatio-Temporal modelling (LST), termed LST-rPPG, to generate high-quality BVP signals with a much longer duration. On the one hand, by employing spatial and temporal encoders, the original image-based rPPG issue is converted to a time-series problem. Besides, a sparse computation mechanism is integrated into the temporal encoder. This combination allows LST-rPPG to recover flexible-duration BVP signals, supporting continuous modeling of segments beyond 30 s with low computation and memory overhead. On the other hand, a dynamic loss function with stringent temporal constraints is designed to guarantee the quality of the generated BVP signals. Comprehensive experiments are performed on two public datasets, PURE and UBFC-RPPG, and the results demonstrate the feasibility of LST-rPPG for generating high-quality BVP signals with a much longer duration while requiring substantially fewer computational resources. Besides, LST-rPPG achieves at least the second-best results during all experiments.},
  archive      = {J_ESWA},
  author       = {Jiajie Li and Juan Cheng and Rencheng Song and Yu Liu},
  doi          = {10.1016/j.eswa.2025.129526},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129526},
  shortjournal = {Expert Syst. Appl.},
  title        = {LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel scheme integrating graph-based analysis and opposition-based learning for S-box optimization by population-based metaheuristics. <em>ESWA</em>, <em>298</em>, 129524. (<a href='https://doi.org/10.1016/j.eswa.2025.129524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-linearity of symmetric block cryptographic algorithms, which is crucial for resisting linear and differential cryptanalysis, depends on the design of substitution boxes. This work proposes a novel scheme, named GOM, combining opposition-based learning with graph-based representation to be integrated into three population-based metaheuristics. This scheme is applied to address the 8 × 8 S-box design problem. The GOM-enhanced metaheuristics improve population diversity and convergence, achieving a non-linearity of 112. Hardware simulations indicate that GOM-based designs require similar resources to AES, while side-channel evaluations confirm their resilience against power analysis attacks. Scalability is supported by successful results on 10 × 10 and 12 × 12 S-boxes. The design of GOM, leveraging generalizable components such as opposition-based learning and graph-based representations, suggests its potential applicability to other population-based metaheuristics and optimization problems.},
  archive      = {J_ESWA},
  author       = {Francisco González and Ricardo Soto and José M. Lanza-Gutiérrez and Broderick Crawford},
  doi          = {10.1016/j.eswa.2025.129524},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129524},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel scheme integrating graph-based analysis and opposition-based learning for S-box optimization by population-based metaheuristics},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking. <em>ESWA</em>, <em>298</em>, 129523. (<a href='https://doi.org/10.1016/j.eswa.2025.129523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding models have demonstrated strong performance in tasks like clustering, retrieval, and feature extraction while offering computational advantages over generative models and cross-encoders. Benchmarks such as MTEB have shown that text embeddings from large language models (LLMs) capture rich semantic information, but their ability to reflect code-level functional semantics remains unclear. Existing studies largely focus on code clone detection, which emphasizes syntactic similarity and overlooks functional understanding. In this paper, we focus on the functional consistency of LLM code embeddings, which determines if two code snippets perform the same function regardless of syntactic differences. We propose a novel data synthesis framework called Functionality-Oriented Code Self-Evolution to construct diverse and challenging benchmarks. Specifically, we define code examples across four semantic and syntactic categories and find that existing datasets predominantly capture syntactic properties. Our framework generates four unique variations from a single code instance, providing a broader spectrum of code examples that better reflect functional differences. Extensive experiments on three downstream tasks-code clone detection, code functional consistency identification, and code retrieval-demonstrate that embedding models significantly improve their performance when trained on our evolved datasets. These results highlight the effectiveness and generalization of our data synthesis framework, advancing the functional understanding of code.},
  archive      = {J_ESWA},
  author       = {Zhuohao Li and Wenqing Chen and Jianxing Yu and Zhichao Lu},
  doi          = {10.1016/j.eswa.2025.129523},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129523},
  shortjournal = {Expert Syst. Appl.},
  title        = {Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129522. (<a href='https://doi.org/10.1016/j.eswa.2025.129522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have demonstrated the effectiveness for hyperspectral image (HSI) classification, but still face challenges, such as insufficient exploitation of data structure information, limited labeled samples, and high susceptibility to noise and outliers. To address these issues, a semisupervised graph U-Net with graph convolutional long short-term memory is proposed for HSI classification, abbreviated as SSGU-Net. Specifically, we design a novel graph convolutional long short-term memory feature extractor to learn discriminative spatial-spectral joint features by simultaneously modeling the correlations in the spatial and spectral domains. Then, we develop a semisupervised graph U-Net with mutually inverse operation of the graph pooling and the graph unpooling modules which uses both labeled samples and unlabeled samples to train a well-parameterized network for HSI classification. In particular, to suppress the effects of noise and outliers, the graph pooling module is designed to selectively retain discriminative samples and fully learn the optimal correlation between these retained samples. Meanwhile, the graph unpooling module employs the local spatial context to reconstruct the reduced samples, thus restoring the pooled data to its original scale for classification task. Extensive experiments show the effectiveness of the proposed method, achieving overall accuracy gains of 5.22 %, 1.58 %, and 1.57 % over the state-of-the-art competitors on the Indian Pines, University of Pavia, and Houston datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jin-Yu Yang and Heng-Chao Li and Xin-Ru Feng and Feng Gao and Qian Du and Antonio Plaza},
  doi          = {10.1016/j.eswa.2025.129522},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129522},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems. <em>ESWA</em>, <em>298</em>, 129521. (<a href='https://doi.org/10.1016/j.eswa.2025.129521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet, building a multilingual dialogue generation system to attract more users while reducing costs in the global market has become increasingly important. However, current end-to-end multilingual approaches often face semantic disparity issues across languages. When given parallel queries with the same semantics but in different languages, the generated responses may vary in meaning across languages, which may greatly affect the stability and reliability of multilingual systems in different language scenarios. We attribute this issue to open-domain/model uncertainty and language differences. To mitigate this issue, we first propose a novel Anchor-based Semantic Constraint (ASC) designed to reduce semantic disparity across languages for Encoder-Decoder Transformers. ASC employs language-independent anchor signal to guide the behaviors in both the encoder and decoder, thereby reducing uncertainty. Additionally, ASC incorporates a two-stage tuning process to further minimize the impact of language differences by ensuring the encoder remains language-independent. Extensive experiments and in-depth analyses conducted on XDailyDialog demonstrate that ASC can effectively mitigate semantic disparity across languages and will not compromise dialogue response quality like the previous related baselines.},
  archive      = {J_ESWA},
  author       = {Sixing Wu and Jiahao Chen and Jiong Yu and Wei Zhou},
  doi          = {10.1016/j.eswa.2025.129521},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129521},
  shortjournal = {Expert Syst. Appl.},
  title        = {Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards CPU performance prediction: New challenge benchmark dataset and novel approach. <em>ESWA</em>, <em>298</em>, 129520. (<a href='https://doi.org/10.1016/j.eswa.2025.129520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CPU performance prediction based on hardware characteristics is crucial for system design and resource management. However, this field faces two major challenges. First, collecting real-world data is challenging due to the diversity of CPU products and the specialized nature of hardware characteristics. This field lacks a standard dataset with unified hardware characteristics, wide data coverage, and comprehensive benchmarks. Second, existing methods based on hardware simulation models or machine learning exhibit notable shortcomings, such as lengthy simulation test cycles and low prediction accuracy. To bridge these gaps, we first collect, preprocess, and standardize historical data from the 4th Generation Intel® Xeon® Scalable Processors across multiple benchmark suites to create a new dataset, named PerfCastDB. Subsequently, we design a deep learning based model called Nova CPU Performance Predictor (NCPP) as the baseline for this new dataset. The NCPP network is designed based on group attention mechanism. It effectively quantifies the implicit relationships between hardware characteristics within and across groups and comprehensively models the impact of various hardware characteristics on CPU performance prediction. We conduct comparative experiments using the proposed PerfCastDB dataset. Compared to existing approaches, NCPP achieves superior evaluation results, demonstrating its effectiveness. Furthermore, we have open-sourced part of the dataset and the NCPP network code to facilitate subsequent research. The resources can be accessed at https://github.com/xiaoman-liu/NCPP .},
  archive      = {J_ESWA},
  author       = {Xiaoman Liu},
  doi          = {10.1016/j.eswa.2025.129520},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129520},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards CPU performance prediction: New challenge benchmark dataset and novel approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Glyph graph isomorphism network for structure recognition of oracle bone inscription. <em>ESWA</em>, <em>298</em>, 129519. (<a href='https://doi.org/10.1016/j.eswa.2025.129519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure recognition of oracle bone inscription glyphs plays an important role in studying the evolutionary process of oracle bone inscriptions and the history of the Shang Dynasty. Currently, most methods have decomposed oracle bone inscription glyphs into multilevel features, which are used to recognize hierarchical feature fusion. This strategy cannot recognize the primitive internal structures of keypoints, strokes, and components. Moreover, mainstream graph neural networks cannot fully utilize the rich structural information of oracle bone inscription glyphs, resulting in their inability to meet the needs of structure recognition. So we have developed a graph structure recognition method to implement structure recognition of oracle bone inscription glyphs. A graph extraction method is given to get the structure of oracle bone inscription glyphs; each graph structure’s representation vector can be learned by a glyph graph isomorphism network, which is developed to recognize the graph of oracle bone inscription glyphs to enhance the discriminability representation of the structure. Our model has achieved advanced results across structure recognition experiments in the HWOBC dataset and the Oracle-50K dataset.},
  archive      = {J_ESWA},
  author       = {Zhan Zhang and Hanbin Liu and Xingkun Zhang and Yiyuan Wang and Feng Gao and An Guo and Han Zhang and Qingju Jiao and Bang Li and Yongge Liu},
  doi          = {10.1016/j.eswa.2025.129519},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129519},
  shortjournal = {Expert Syst. Appl.},
  title        = {Glyph graph isomorphism network for structure recognition of oracle bone inscription},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation. <em>ESWA</em>, <em>298</em>, 129516. (<a href='https://doi.org/10.1016/j.eswa.2025.129516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overweight and oversized transport (O&OT) has become one of the most critical elements of project logistics, driven by advancements in transportation and lifting technologies that now allow high-volume loads to be moved across long distances. This type of transportation operation, also called abnormal transportation, is greatly affected by technical factors such as the weight and geometry of the load, road surface, axle load limitations, slope, and ground strength, as well as external variables such as weather conditions, traffic density, and legal regulations. In planning and operational processes, Decision-Makers (DMs) and practitioners who plan and execute operations without adequately considering these factors and variables can lead to delays in operations, serious risks, and loss of productivity. This research proposes a flexible decision support model that integrates Step-wise Weight Assessment Ratio Analysis (SWARA) and Logarithmic Percentage Change-driven Objective Weighting (LOPCOW), and a ranking technique; i.e., Mixed Aggregation by Comprehensive Normalization Technique (MACONT) techniques to address the decision problems related to route selection, one of the most critical problems in transporting heavy and bulky loads, and to produce reasonable solutions. The proposed model significantly reduces information losses by processing subjective and objective information and integrating subjective (SWARA) and objective (LOPCOW) methods. Unlike traditional ranking approaches, the MACONT method combines three different normalization techniques to determine the ranking performance of alternatives. In this way, it provides more reliable and accurate results by reducing the deviations of the results provided by the single normalization technique. In addition, it shows each alternative’s good and bad performance compared to the others and is more convincing about the results obtained. According to the results obtained by applying the proposed model, fuel consumption (0.096) is determined as the most effective and critical factor in selecting the route on which heavy and bulky loads will be transported. In this context, choosing routes that allow lower fuel consumption can contribute to reducing carbon emissions and external costs arising from transportation. The extensive robustness and validation check to test the proposed model prove that the proposed model is a reliable, robust, and practical decision-making tool for making reasonable and rational decisions in O&OT.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Pradip Kundu and Hande Küçükönder and Gürkan Doğan and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129516},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129516},
  shortjournal = {Expert Syst. Appl.},
  title        = {An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EvoMapX: An explainable framework for metaheuristic optimization algorithms. <em>ESWA</em>, <em>298</em>, 129514. (<a href='https://doi.org/10.1016/j.eswa.2025.129514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based optimization algorithms (POAs) are widely adopted solutions for NP-hard and complex high-dimensional optimization problems. However, their internal dynamics often remain opaque, limiting trust and insight into how solutions evolve. This paper introduces EvoMapX, a novel explainable framework designed to interpret the internal dynamics of population-based optimization algorithms. EvoMapX includes three interpretable structures to visualize evolutionary optimization dynamics: the Operator Attribution Matrix (OAM) quantifies the contribution of specific operators over iterations; the Population Evolution Graph (PEG) traces the ancestry and transformation of candidate solutions; and the Convergence Driver Score (CDS) identifies which operators drive convergence, helping interpret why the algorithm improved. EvoMapX was evaluated across four POAs on the CEC 2021 test suite in order to demonstrate how it reveals meaningful textual and graphical insights into algorithm behavior. EvoMapX paves the way for interpretable metaheuristic optimization. The source code of EvoMapX is available at https://www.github.com/Bilal20252025/EvoMapX},
  archive      = {J_ESWA},
  author       = {Bilal H. Abed-Alguni},
  doi          = {10.1016/j.eswa.2025.129514},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129514},
  shortjournal = {Expert Syst. Appl.},
  title        = {EvoMapX: An explainable framework for metaheuristic optimization algorithms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set. <em>ESWA</em>, <em>298</em>, 129513. (<a href='https://doi.org/10.1016/j.eswa.2025.129513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random permutation set (RPS) extends Dempster-Shafer evidence theory by incorporating event order information, providing a powerful framework for modeling uncertainty. However, existing orthogonal sum methods within the RPS framework may encounter loss of order information and counterintuitive belief distribution during permutation event fusion. To address these two issues, this paper proposes a new method termed belief-distance-based orthogonal sum (BDOS). BDOS operates through three core mechanisms: order-information preservation via mathematical constructs like order-space and inverse mapping; belief-value weighting that prioritizes events with high belief mass for rational outcomes; and element-distance weighting that incorporates dissimilarity among permutations to improve ordinal accuracy. Numerical examples validate the effectiveness of BDOS in permutation event fusion, with comparative results demonstrating its advantages in order retention and belief distribution. Furthermore, BDOS is applied to threat assessment, illustrating its rationality and effectiveness in handling uncertainty and threat ranking.},
  archive      = {J_ESWA},
  author       = {Xiaoyan Su and Xu Chen and Hong Qian and Cheng Jiang},
  doi          = {10.1016/j.eswa.2025.129513},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129513},
  shortjournal = {Expert Syst. Appl.},
  title        = {BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks. <em>ESWA</em>, <em>298</em>, 129510. (<a href='https://doi.org/10.1016/j.eswa.2025.129510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objective With the rapid growth in the number of medical images, the need for content- based medical image retrieval (CBMIR) in clinical aid diagnosis is becoming increasingly important. Most current content-based CT image similarity retrieval methods use the entire CT image, ignoring the fact that the localized lesion region is the main target of similarity retrieval; Methods To address this issue, the paper proposes a fine-grained similarity retrieval method for lung CT images based on image block( IB ) similarity matching, taking lung CT images as an example. In this method, two enabling techniques are introduced: 1) a hybrid Convolution and Vision Transformer Model(CVTM) that effectively captures both local texture and global context features of lesion regions; 2) the iDS high-dimensional index designed to accelerate retrieval among IB ; Results With the aid of these techniques, fine-grained similarity retrieval optimization of lung CT images can be achieved, which facilitates more accurate lesion-level comparison and supports clinical decision-making; Conclusions Extensive experiments are conducted to indicate that the proposed fine-grained similarity retrieval method achieves excellent performance, with a mAP of 91.33%. Meanwhile, the retrieval efficiency of the iDS high-dimensional index is about 150% higher than that of sequential retrieval, especially when the retrieval radius is large and the database size is substantial.},
  archive      = {J_ESWA},
  author       = {Yi Zhuang and Jiayu Zhang and Yujia Ge and Nan Jiang},
  doi          = {10.1016/j.eswa.2025.129510},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129510},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traffic prediction using an active causality recurrent graph convolutional network. <em>ESWA</em>, <em>298</em>, 129506. (<a href='https://doi.org/10.1016/j.eswa.2025.129506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of our daily lives is significantly influenced by traffic conditions, highlighting the importance of incorporating complex spatiotemporal dependencies in interconnected traffic data for effective prediction. Although recent advancements have demonstrated prediction accuracy using graph convolutional networks, their depends heavily on the accuracy of the graph structures that represent the spatial relationships within the traffic network. To address this challenge, we introduce a novel approach to traffic prediction, the Active Causal Recurrent Graph Convolution Network (ACRGCN), as shown in Fig. 2. ACRGCN offers a new framework that effectively integrates a causal-embedded approach for traffic prediction, leveraging both structural and feature information from correlated traffic time series. Additionally, it incorporates a time-varying dynamic Bayesian network to capture the intricate spatiotemporal topology of traffic data. The model extracts spatiotemporal dependencies from traffic signals using the Active Causality Graph Recurrent Module (ACGRM), while efficiently modeling nonlinear traffic propagation patterns. Furthermore, ACRGCN employs a deep learning-based module that functions as a hyper-network, progressively generating dynamic causal graphs. Finally, extensive experiments on multiple real-world traffic graph datasets validate ACRGCN, and the results demonstrate its superiority over state-of-the-art method},
  archive      = {J_ESWA},
  author       = {Jinde Zhu and Junhao Yuan and Fulan Ye and Trong-The Nguyen and Ruoxi Wang and Wu Zeng and Chien-Chun Liu},
  doi          = {10.1016/j.eswa.2025.129506},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129506},
  shortjournal = {Expert Syst. Appl.},
  title        = {Traffic prediction using an active causality recurrent graph convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system. <em>ESWA</em>, <em>298</em>, 129502. (<a href='https://doi.org/10.1016/j.eswa.2025.129502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical computing architecture of cloud-edge-client (CEC) formed with the combination of cloud computing and edge computing can provide processing, storage and low-latency services close to end devices. To protect data privacy, federated learning (FL), as a novel intelligent edge computing framework with localized training mechanisms, has been integrated into edge computing to form a system called CEC-FL and is widely studied. However, they are susceptible to potential poisoning attacks. Existing poisoning attack methods are mostly explored by performing malicious operations on training samples or labels directly and implementing corresponding defense strategies: they are designed to ignore the label transferability and diverse attack environments and are not work against stealthy security threats, mainly because they do not take into account the inherent vulnerabilities of the attack environment. Yet few general defense schemes have been developed. In response to the above vulnerabilities, in this work, we explore a B arycenter Po isoning method with L abel T ransferability (BPoLT) initiated by malicious attackers, resulting in a dynamic attack capability on the CEC-FL system. To address poisoning attacks, we provide a two-phase defense algorithm Res isting L abel T ransferability Pois oning called ResLT-Pois to distinguish malicious attackers from benign participants. Extensive experimental results demonstrate that our scheme is feasible and effective in dealing with the vulnerability of the CEC-FL system.},
  archive      = {J_ESWA},
  author       = {Yaru Zhao and Yihao Cao and Jianbiao Zhang and Zhaoqian Zhang and Weiru Wang},
  doi          = {10.1016/j.eswa.2025.129502},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129502},
  shortjournal = {Expert Syst. Appl.},
  title        = {Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting. <em>ESWA</em>, <em>298</em>, 129498. (<a href='https://doi.org/10.1016/j.eswa.2025.129498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting faces significant challenges due to the variability and complexity of real-world data. Traditional methods often require manual adjustments of wavelet transform parameters, which are labor-intensive and prone to over-fitting or inadequate feature extraction. To address these limitations, this study proposes SAMForecast, a novel hybrid model that integrates Adaptive Wavelet Transform, self-attention mechanisms, and the selective state space model. We introduce an Adaptive Wavelet Block that dynamically adjusts decomposition levels and basis functions using a Mixture of Experts network and lifting scheme, eliminating the need for manual parameter tuning. Furthermore, the model deeply integrates the attention mechanism of the Transformer architecture, leveraging its advantages in capturing complex dependencies to identify correlations between time series data. By combining self-attention with Mamba, SAMForecast effectively captures both global dependencies and local key features in time series, enhancing robustness against noise and redundant information. SAMForecast demonstrates promising performance in multivariate time series forecasting tasks, showcasing an average 2 % performance improvement compared to existing models across datasets in energy, transportation, and other fields. The code is available at https://github.com/Kiki-V/SAMForecast-main .},
  archive      = {J_ESWA},
  author       = {Dunlu Peng and Qiqi Lin},
  doi          = {10.1016/j.eswa.2025.129498},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129498},
  shortjournal = {Expert Syst. Appl.},
  title        = {SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting. <em>ESWA</em>, <em>298</em>, 129497. (<a href='https://doi.org/10.1016/j.eswa.2025.129497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate PM2.5 prediction is crucial for effective environmental management and public health protection, yet current models show limited dynamic adaptability to complicated air pollution scenarios. Robust models are essential to support timely interventions in response to sudden pollution events or rapidly changing air quality patterns. However, existing models predominantly rely on predefined graph structures and pairwise spatial relationships, limiting their ability to capture the complex and dynamic interactions inherent in PM2.5 pollution. Furthermore, such models often assume equal contributions from neighboring nodes, neglecting heterogeneity and compromising predictive accuracy. To address these limitations, we propose an Adaptive Hypergraph-based Convolution Network with a Dual Spatiotemporal Attention mechanism (AHCN-DA) for PM2.5 forecasting. This framework leverages representation learning and hypergraph structures to capture and integrate pairwise as well as higher-order spatial interactions, producing richer spatial-feature representations. The dual spatiotemporal attention mechanism dynamically assigns time-varying weights to neighboring nodes based on their relevance to target nodes, effectively mitigating the impact of irrelevant inputs. Additionally, AHCN-DA integrates a dilated convolution network with multi-scale kernels to capture temporal patterns effectively across varying scales. Extensive experiments on the 2023 China National Air Quality Dataset show significant improvements in predictive accuracy, particularly in enhancing the proportion of high-precision monitoring stations, with an R 2 of 0.9224, outperforming baseline models. Our findings underscore the effectiveness of AHCN-DA in enhancing prediction accuracy under complex pollution response patterns, contributing to more informed decision-making in environmental management.},
  archive      = {J_ESWA},
  author       = {Haipeng Gao and Chonghui Qian and Yang Su and Wei Zhang and Hengjun Huang},
  doi          = {10.1016/j.eswa.2025.129497},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129497},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans. <em>ESWA</em>, <em>298</em>, 129496. (<a href='https://doi.org/10.1016/j.eswa.2025.129496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial team games represent scenarios where cooperation and competition coexist and hold numerous applications in the real world. These scenarios are particularly challenging due to asymmetric information among team members and limited communication capabilities. Fictitious team-play extend self-play algorithms to these scenarios, offering a novel approach to obtain equilibrium. However, it depends on normal-form team plans, which expand exponentially with game size, significantly constraining their applicability in large games. To overcome the challenge of computing equilibrium in large scale imperfect information team games, we propose a team self-play algorithm that utilizes refined team plans. Specifically, we pre-solve the equilibrium in a perfect recall environment to extract essential team plans from the original strategy space. To adapt these plans to an imperfect recall environment, we construct an auxiliary game with transformed ex ante coordinated information based on the original game and then solve equilibrium in auxiliary game to derive equilibrium for the original game. The experiments demonstrate the effectiveness of our team self-play algorithm in eight different Kuhn poker scenarios. Compared to existing team self-play algorithms, our method efficiently handles large games and exhibits superior convergence compared to reinforcement learning based algorithms. Additionally, our experiments offer valuable insights and guidance on adapting equilibrium strategies from perfect recall environments to those with imperfect recall.},
  archive      = {J_ESWA},
  author       = {Jinheng Xiao and Chen Qiu and Yingying Xu and Jiajia Zhang and Shuhan Qi and Xuan Wang},
  doi          = {10.1016/j.eswa.2025.129496},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129496},
  shortjournal = {Expert Syst. Appl.},
  title        = {Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images. <em>ESWA</em>, <em>298</em>, 129490. (<a href='https://doi.org/10.1016/j.eswa.2025.129490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma detection identifies the early signs of eye conditions that can lead to vision loss by analyzing the retinal images to detect abnormalities, such as increased intraocular pressure, changes in the optic nerve head, or structural alterations in the retina. The challenges faced by the existing models include the difficulty in detecting subtle features, variability in image quality, and complex patterns that may resemble normal variations. Moreover, the traditional models struggle to adapt to the evolving patient data, capture long-term dependencies, and often suffer from lower accuracy. Hence, this research proposes the Proactive Hybridized Bidirectional Long Short-Term Memory (BiLSTM) model for Glaucoma detection. The proactive hybridized BiLSTM model is designed to enhance the detection of glaucoma by processing the retinal images. The proactive hybridized BiLSTM model enables the model to capture complex temporal dependencies and relationships within the data, which are crucial for identifying subtle patterns indicative of glaucoma, for which multifaceted feature extraction is employed. Moreover, the Proactive Hybridized BiLSTM model adapts to dynamic changes in the data to learn and predict glaucoma-related features, ultimately improving detection performance over time. The proposed Proactive hybridized BiLSTM model attains higher accuracy, sensitivity, and specificity of 96.65%, 96.51%, and 96.79% using the OCT and FUNDUS image dataset.},
  archive      = {J_ESWA},
  author       = {M.Kiran Mayee and M.Humera Khanam and Shaik Lathifa Tabasum},
  doi          = {10.1016/j.eswa.2025.129490},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129490},
  shortjournal = {Expert Syst. Appl.},
  title        = {Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks. <em>ESWA</em>, <em>298</em>, 129487. (<a href='https://doi.org/10.1016/j.eswa.2025.129487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current deep learning methods for community detection in attributed networks face a critical limitation: they often fail to identify communities that are both structurally cohesive and semantically similar, thereby falling short of the balance typically observed in human-labeled partitions. This shortcoming stems from the absence of explicit mechanisms to jointly optimize these two objectives. In this paper, this challenge is addressed by proposing Deep Balanced Community Detection (DBCD), a novel unsupervised framework for community detection that balances topology and semantics. DBCD first constructs a powerful topology-semantic clustering consensus by integrating insights from both structural and attribute spaces. This consensus then steers a Graph Neural Network to simultaneously maximize global neural modularity and local cross-view consistency, while adaptively determining the number of communities. Extensive experiments reveal a striking result: DBCD consistently discovers communities that surpass the topology-semantic balance of the ground truth across multiple real-world networks. An empirical Pareto frontier analysis further validates that DBCD achieves a non-dominated solution, establishing it as a strong competitor among state-of-the-art methods. The source code of DBCD is available at https://github.com/wy980125/DBCD .},
  archive      = {J_ESWA},
  author       = {Yan Wang and Yupeng Liu and Xiaojie Sun and Jun Fu},
  doi          = {10.1016/j.eswa.2025.129487},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129487},
  shortjournal = {Expert Syst. Appl.},
  title        = {DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Network traffic forecasting with transfer learning-based algorithm for long continuous missing data. <em>ESWA</em>, <em>298</em>, 129484. (<a href='https://doi.org/10.1016/j.eswa.2025.129484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate network traffic forecasting is critical for power dispatch networks. Network traffic forecasting aims to use historical data to predict future network traffic trends. Different from other networks, the traffic data of the power dispatch network is mainly composed of the port traffic from routers and switches. However, network accidents in power enterprises can cause long periods of missing network traffic data, reducing the number of learning samples for network traffic prediction models and making the forecasting results unreliable. Due to the long periods of missing data, this paper uses transfer learning (TL) to impute missing data with the knowledge from a relevant task, which has ample samples. However, the imputation result contains complex source and target data characteristics. Therefore, this paper introduces the idea of frequency decomposition to decompose the imputation results into different sub-sequences through variational mode decomposition (VMD). Additionally, this paper uses long short-term memory (LSTM) networks to extract the potential features of decomposition results. Finally, this paper combines TL, VMD, and LSTM to design the TL-VMD-LSTM algorithm. The effectiveness of the proposed algorithm is validated using inflow and outflow traffic data from two State Grid Corp. of China networks. The results demonstrate that TL-VMD-LSTM has excellent generalization performance, with mean absolute percentage errors (MAPEs) of 0.380 % and 0.734 % for the Provincial access network and Information region network, respectively.},
  archive      = {J_ESWA},
  author       = {Yang Yang and Zhihao Chen and Yuchao Gao and Zijin Wang and Zhe Ding and Jinran Wu},
  doi          = {10.1016/j.eswa.2025.129484},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129484},
  shortjournal = {Expert Syst. Appl.},
  title        = {Network traffic forecasting with transfer learning-based algorithm for long continuous missing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional multi-objective feature selection with niche-based binary differential evolution. <em>ESWA</em>, <em>298</em>, 129478. (<a href='https://doi.org/10.1016/j.eswa.2025.129478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a critical step in machine learning and data mining, aiming to identify the most relevant features from a dataset to improve model performance while reducing computational costs. In high-dimensional data, as the dimensionality of data increases rapidly, feature selection faces an enormous search space, limiting the efficiency and effectiveness of traditional methods. To address these challenges, multi-objective optimization algorithms have emerged as a promising strategy for feature selection due to their ability to optimize multiple conflicting objectives simultaneously. We propose a niche-based binary differential evolution algorithm (MONBDE) for high-dimensional multi-objective feature selection. MONBDE enhances feature selection performance through several mechanisms: a niche-based binary differential evolution operator, redundant solution repair mechanism and an environmental selection strategy. In experiments, the proposed algorithm was compared with five advanced multi-objective optimization algorithms and tested on 15 benchmark datasets using three common metrics. Experimental results show that the MONBDE algorithm outperforms comparative algorithms in terms of classification accuracy and feature subset size across most datasets. The proposed strategy effectively eliminates redundant and irrelevant solutions in feature selection, leading to a significant improvement in model classification performance.},
  archive      = {J_ESWA},
  author       = {Xuezhi Yue and Xiang Zuo and Pengfei Ling and Chao Xiong and Hu Peng and Yuan Zeng},
  doi          = {10.1016/j.eswa.2025.129478},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129478},
  shortjournal = {Expert Syst. Appl.},
  title        = {High-dimensional multi-objective feature selection with niche-based binary differential evolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation. <em>ESWA</em>, <em>298</em>, 129477. (<a href='https://doi.org/10.1016/j.eswa.2025.129477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and rapid segmentation of the clinical target volume (CTV) is essential for cervical cancer radiotherapy. However, due to the soft boundaries of CTV, complex connections with surrounding tissues, and high interpatient variability, existing deep learning methods still face significant challenges, particularly for image slices that lack clear boundary information or where applicators are distant from CTV edges. Hence, we introduce DFCNet, a dual-path fusion network with cross-slice consistency constraints for CTV segmentation. The first path employs a dual-stream intra-slice feature encoding module to capture local and inter-regional details, thereby refining boundary delineation amidst the complex interplay with adjacent tissues. The second path integrates a cross-slice consistency constraint module to address soft boundaries and high interpatient variability, while ensuring the coherence and smoothness of the segmentation results. A feature fusion and decoding module combines semantic features from both paths, improving CTV region accuracy. Tests on 432 cervical cancer brachytherapy cases show DFCNet outperforms eighteen state-of-the-art segmentation methods, with Dice score improvements over two percentage points. The second path and feature fusion module can enhance other U-Net-based models, boosting their CTV segmentation performance. DFCNet excels in high-precision CTV segmentation, particularly for challenging slices, demonstrating its potential to improve cervical cancer radiotherapy accuracy, efficiency, and patient outcomes.},
  archive      = {J_ESWA},
  author       = {Mingxu Huang and Deyu Sun and Chaolu Feng and Ming Cui and Dazhe Zhao and Yuhua Gao},
  doi          = {10.1016/j.eswa.2025.129477},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129477},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users. <em>ESWA</em>, <em>298</em>, 129466. (<a href='https://doi.org/10.1016/j.eswa.2025.129466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of data, numerous e-commerce platforms are actively collecting consumer data to obtain business insights. However, consumers and merchants on platforms exhibit diverse attribution behaviors, including single-homing and multi-homing (access to only one platform/multiple platforms), not only affecting the platform’s market scale but also complicating their data provision strategies and data pricing strategies. Inspired by this practice, this paper considers varying attribution behaviors and studies the data operation strategies of competitive platforms. By constructing a two-period game model, we capture the entire process of platform’s data collection and provision, and solve the equilibrium decisions by reverse solution method. This research aims to identify the impact of attribution behaviors on platforms’ data strategies, thereby filling the gap in analyzing this issue from the perspective of two-sided platforms. Results show that when both groups of users (consumers and merchants) are multi-homing, platform facing higher operational costs may benefit more from implementing low data provision but high data pricing strategy, while more cost-efficient platform may choose the opposite strategy. This strategy is still applicable when only one group of users (consumers) becomes single-homing. However, once both groups of users are single-homing, both platforms’ strategies will change. Specifically, when merchant’s cross-side network effect (CNE) intensity is relatively low (high), compared with less cost-efficient platform, platform enjoying cost efficiencies should provide more (less) data at a relatively high (low) price. Moreover, platforms should cautiously provide data when both groups of users are single-homing, as it may hurt profits.},
  archive      = {J_ESWA},
  author       = {Wei Chen and Yijia Hu and Ronghua Sui and Zili Guan and Yi Liu},
  doi          = {10.1016/j.eswa.2025.129466},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129466},
  shortjournal = {Expert Syst. Appl.},
  title        = {Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration. <em>ESWA</em>, <em>298</em>, 129465. (<a href='https://doi.org/10.1016/j.eswa.2025.129465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the multi-trip vehicle routing problem with time windows (MTVRPTW) and its variants have been extensively studied, their application in natural disaster contexts remains underexplored. This study addresses this gap by developing a model and solution algorithm for the MTVRPTW with limited trip duration (MTVRPTW-LD), tailored to emergency supplies distribution in the early post-disaster phase. First, we replace the service-dependent loading time in traditional models with service-dependent unloading time and formulate an MTVRPTW-LD model to minimize total operational time, encompassing travel, service, and unloading times, based on the characteristics of emergency supplies distribution. Furthermore, a more practical method for calculating travel time is proposed to enhance the model’s applicability. Subsequently, a branch-and-price algorithm is designed to solve the MTVRPTW-LD model, in which the cumulative relative deprivation cost (CRDC) is introduced to improve equity in emergency supplies distribution. Finally, we conduct numerical experiments on Solomon instances and test instances generated based on emergency scenarios. The results show that, in the test instances, incorporating CRDC can improve the equity by up to 34.3 %.},
  archive      = {J_ESWA},
  author       = {Longfei Fan and Zhongming Wu and Zaiwu Gong and David Z.W. Wang},
  doi          = {10.1016/j.eswa.2025.129465},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129465},
  shortjournal = {Expert Syst. Appl.},
  title        = {Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy. <em>ESWA</em>, <em>298</em>, 129460. (<a href='https://doi.org/10.1016/j.eswa.2025.129460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pareto set (PS) of a continuous multi-objective optimization problem exhibit a distribution along a low-dimensional manifold structure. This regularity property significantly contributes to generating high-quality offspring in large-scale multi-objective evolutionary algorithms (LSMOEAs). However, conventional regularity model-based algorithms face several challenges when dealing with large-scale multi-objective optimization problems (LSMOPs), including high computational costs for modeling, difficulty in capturing the true PS structure, and neglecting individual directional information. To address these challenges, we propose a dual-information offspring reproduction strategy that considers both the distribution information of the population and the directional information of the outstanding individuals. Specifically, this strategy comprises a sampling approach based on an augmented regularity model specifically designed for LSMOPs. Leveraging this model, we explore and exploit the decision space to sample a promising set of solutions. Additionally, the strategy also involves a search method based on competitive learning among individuals. By assigning a positive evolutionary direction to losing solutions, we update the losing solutions to generate high-quality offspring. We continuously refine the proposed regularity model to approximate the true PS more closely. In extensive experiments on large-scale multi-objective benchmark functions, we compare our algorithm with eight state-of-the-art algorithms. The results demonstrate that our approach excels in handling LSMOPs.},
  archive      = {J_ESWA},
  author       = {Ying Wu and Ziliang Du and Gonglin Yuan and Zhenzhou Tang and Ferrante Neri and Yaqing Hou},
  doi          = {10.1016/j.eswa.2025.129460},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129460},
  shortjournal = {Expert Syst. Appl.},
  title        = {Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning. <em>ESWA</em>, <em>298</em>, 129448. (<a href='https://doi.org/10.1016/j.eswa.2025.129448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying product defects and process anomalies in manufacturing processes is a critical task for product quality and system stability. Although the existing unsupervised anomaly detection methods do not require the annotation of anomalies, they are difficult to deal with the zero-shot scenario faced by multi-variety and small-batch production where there is no available data. In addition, many zero-shot detection algorithms need to represent the image features in tensor form with multiple local feature vectors, and then measure each local feature to infer the overall anomaly of the object. In this paper, we propose GlobalCLIP, a novel approach for zero-shot anomaly detection using only global feature vectors to enhance performance. Specifically, we use CLIP model to aggregate the global features, and design two kinds of adaptive modules from the error level and uncertainty level to realize the series integration of different discriminant models. The adaptive modules encourage the model to learn both normal and abnormal patterns with different granularity, and the self-cyclic training progressively improves model performance. Experiments show that compared to many unsupervised/weakly supervised methods, the performance of GlobalCLIP maintains its advantage even without known samples, and achieves significant improvement over available zero-shot methods.},
  archive      = {J_ESWA},
  author       = {Haoyuan Shen and Enrico Zio and Jiawei Xiong and Yizhong Ma},
  doi          = {10.1016/j.eswa.2025.129448},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129448},
  shortjournal = {Expert Syst. Appl.},
  title        = {GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Key performance indicator-related process monitoring for irregular scenarios with incomplete data. <em>ESWA</em>, <em>298</em>, 129440. (<a href='https://doi.org/10.1016/j.eswa.2025.129440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industries exhibit irregular characteristics due to factors such as mode transitions, incomplete data and outliers. Accurate monitoring of key performance indicators (KPIs) in irregular processes is essential for improving product quality and reducing scrap rates. This paper proposes a novel KPI-related process monitoring method that leverages the multiple kernel learning (MKL) technique, designed specifically for irregular scenarios with incomplete data. First, a novel MKL-based nonlinear matrix completion is proposed that utilizes a hierarchical strategy-based algorithm to estimate the missing values in incomplete data and the linear coefficients of multiple kernels. In addition, the corresponding convergence analysis is given. Based on the estimated completed data matrix, a novel MKL-based feature correlation analysis is proposed for indirect prediction of KPIs. Two statistics are established for detecting KPI-related and KPI-unrelated faults, respectively. A numerical case and an industrial example demonstrate that the proposed method not only accurately identifies the missing data, but also effectively detects the KPI-related faults.},
  archive      = {J_ESWA},
  author       = {Yanyu Chen and Hao Ma and Yan Wang and Xiang Liu},
  doi          = {10.1016/j.eswa.2025.129440},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129440},
  shortjournal = {Expert Syst. Appl.},
  title        = {Key performance indicator-related process monitoring for irregular scenarios with incomplete data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm. <em>ESWA</em>, <em>298</em>, 129437. (<a href='https://doi.org/10.1016/j.eswa.2025.129437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, practical machine learning methodologies are extensively employed for the automation of detecting the intrusion available in the network. In key infrastructure scenarios involving communication strategies, the interplay between different industrial control systems and the inherent connection to the Internet environment through the Internet of Things renders them vulnerable to cyber threats. Considering the substantial volume of network traffic within critical Cyber-Physical Systems, conventional machine-learning approaches utilized for detecting anomalies prove to be ineffective. Hence, newly designed machine learning methods, with a focus on deep learning, are demonstrating effective applications in identifying and categorizing anomalies on both network and individual device levels. This article introduces an innovative Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm designed for the identification of cyber threats. To augment the effectiveness of the suggested method, it employs a dual-step process for the detection of network irregularities. During the initial phase, the approach involves data pre-processing and dimensionality reduction through the application of Kernel Principal Component Analysis to select the most suitable features. In the subsequent stage, the novel Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm is employed for classification. The effectiveness of the approach presented in this study is evaluated on diverse datasets, encompassing information collected within the Internet of Things context, specifically IoT-23 and LITNET-2020 datasets. The findings of the assessment of the suggested method are deliberated upon, including the examination of statistical significance and a comparative analysis with contemporary approaches in the field of network anomaly detection. Evaluations confirmed this robust model attained 98.56% accuracy, 97.78% precision, 98.2% F1-score, and produced less FPR of 1.55%.},
  archive      = {J_ESWA},
  author       = {Prabakeran Saravanan and Annamalai Balaji and Hemalatha Murugan and Manickam Muruganantham and Indumathi Varadharajan},
  doi          = {10.1016/j.eswa.2025.129437},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129437},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved DQN-based recommender system on three-way decision. <em>ESWA</em>, <em>298</em>, 129431. (<a href='https://doi.org/10.1016/j.eswa.2025.129431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems, which utilize algorithms and data analysis to provide personalized suggestions to users, have become an indispensable part of modern life. However, traditional recommendation algorithms face challenges such as the cold start problem, lack of diversity, and limited scalability. Reinforcement learning (RL), particularly deep reinforcement learning (DRL), emerges as a promising solution to these problems by allowing agents to learn optimal strategies through interaction with their environment. Nevertheless, as the scale of data increases, RL-based recommendation systems often struggle to achieve a good balance between exploration and exploitation, impacting the overall performance of the algorithms. In this paper, we propose a reinforcement learning-based recommendation algorithm enhanced by a three-way decision (3WD) framework to address the exploration-exploitation balance challenge. The 3WD algorithm, rooted in rough set theory, categorizes decision outcomes into acceptance, rejection, and uncertainty regions. By applying 3WD in the action selection process of RL, we optimize the trade-off between exploration and exploitation, thereby improving the quality and computational efficiency of recommendations. Additionally, we introduce a dynamic threshold adjustment mechanism to adaptively refine the decision boundary during the action selection process in reinforcement learning, further enhancing the algorithm’s performance. Using the MovieLens dataset as a foundation, we conduct extensive experiments with several randomly generated data sets to evaluate the proposed method. Our results demonstrate that the 3WD-based RL algorithm outperforms traditional methods, such as epsilon-greedy and Softmax, in terms of runtime, recommendation accuracy, and error rate. Notably, the dynamic threshold adjustment model exhibits greater stability and surpasses static methods in recommendation success rates. These findings highlight the effectiveness of combining 3WD with RL in recommendation systems, providing a powerful and efficient solution to the challenges faced by traditional methods. Finally, we analyze the limitations of the model based on the experimental results and propose avenues for future research.},
  archive      = {J_ESWA},
  author       = {Zian Chen and Bao Qing Hu},
  doi          = {10.1016/j.eswa.2025.129431},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129431},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved DQN-based recommender system on three-way decision},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports. <em>ESWA</em>, <em>298</em>, 129429. (<a href='https://doi.org/10.1016/j.eswa.2025.129429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an Integral Gaussian Process (IntegralGP) framework for volumetric estimation of subterranean properties in mineral deposits. It provides a unified representation for data with different spatial supports, which enables blasthole geochemical assays to be properly modelled as interval observations rather than points. This approach is shown to improve regression performance and boundary delineation. A core contribution is a description of the mathematical changes to the covariance expressions which allow these benefits to be realised. The gradient and anti-derivatives are obtained to facilitate learning of the kernel hyperparameters. Numerical stability issues are also discussed. To illustrate its application, an IntegralGP data fusion algorithm is described. The objective is to assimilate line-based blasthole assays and update a block model that provides long-range prediction of Fe concentration beneath the drilled bench. Heteroscedastic GP is used to fuse chemically compatible but spatially incongruous data with different resolutions and sample spacings. Domain knowledge embodied in the structure and empirical distribution of the block model must be generally preserved while local inaccuracies are corrected. Using validation measurements within the predicted bench, our experiments demonstrate an improvement in bench-below grade prediction performance. For material classification, IntegralGP fusion reduces the absolute error and model bias in categorical prediction, especially instances where waste blocks are mistakenly classified as high-grade.},
  archive      = {J_ESWA},
  author       = {Anna Chlingaryan and Arman Melkumyan and Raymond Leung},
  doi          = {10.1016/j.eswa.2025.129429},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129429},
  shortjournal = {Expert Syst. Appl.},
  title        = {IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer. <em>ESWA</em>, <em>298</em>, 129406. (<a href='https://doi.org/10.1016/j.eswa.2025.129406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a Deep Multi-view Least Squares Support Vector Machine with Consistency and Complementarity Principles based on Cross-Output Knowledge Transfer (MDCTM), which has four distinctive features: 1) It integrates the idea of deep stacking architecture, which is the first attempt to use transfer learning to form deep architectures in multi-view learning. It can enhance the ability to handle complex problems. Starting from the second layer, it incorporates extra input attributes that consider the predictions made by all preceding layers, effectively revealing the manifold structure of the original data. 2) Each layer follows the consistency and complementarity principles, which can fully excavate the information in multi-view data. In each layer, the model is solved by an alternating optimization strategy. 3) Cross-output knowledge transfer leverages predictions from earlier layers to improve the learning of subsequent ones, which can improve the classification performance of the model. Additionally, the extent of cross-output knowledge transfer between sequential layers can be assessed autonomously and effectively by utilizing a fast leave-one-out cross-validation method. 4) The model allows random assignment of model parameters in each layer, such as weights and kernel widths, boosting learning speed. Numerical experiments demonstrate the model’s effectiveness and efficiency.},
  archive      = {J_ESWA},
  author       = {Shuangrui Jia and Sijie Liang and Ziyi Mo and Chunxiao Liu and Huiru Wang and Chen Chen},
  doi          = {10.1016/j.eswa.2025.129406},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129406},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting. <em>ESWA</em>, <em>298</em>, 129388. (<a href='https://doi.org/10.1016/j.eswa.2025.129388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Koopman operator provides a new way to model complex data patterns, revealing the intrinsic dynamics of time series from a dynamical system perspective. Despite its potential, the Koopman operator has received limited attention in time series forecasting, particularly in addressing these complex, real-world challenges such as carbon emission dynamics characterized by nonlinearity, non-stationarity, and multi-scale coupling effects. To this end, this study proposes a novel forecasting paradigm, Fourier-Enhanced adaptive Koopman operator for carbon emission forecasting (F-KOCE). This approach conceptually extends traditional Koopman frameworks by embedding a spectral-decoupled time series representation into a dual Koopman learning structure, which enables the model to linearize nonlinear dynamics across multiple time scales in a theoretically grounded and practically adaptive manner. By integrating Fourier filter decomposition into Koopman operator theory, F-KOCE separates raw emissions into long-term trends and short-term fluctuations while achieving global linearization of system dynamics. A learnable Koopman operator captures intrinsic temporal structures, while a multi-granularity adaptive weight learning strategy enhances resilience against data variability. To further improve robustness, we introduce an adaptive residual fusion structure for block-level feature compression, noise suppression, and cross-scale information fusion. Additionally, the effective Trend Corrector mechanism dynamically modulates the influence of trend and fluctuation components, refining predictive accuracy. Beyond point forecasting, the framework is also extended to interval forecasting, providing uncertainty-aware predictions. Extensive experiments conducted on 36 Carbon Monitor datasets across six regions and six sectors demonstrate the superiority of F-KOCE over advanced existing models across multiple evaluation metrics. These results confirm the framework’s efficacy in capturing high-dimensional emission dynamics and underscore the potential of Koopman operator theory in carbon forecasting. By offering a robust, interpretable, and data-driven approach, F-KOCE provides valuable insights for climate policy formulation.},
  archive      = {J_ESWA},
  author       = {Jinxing Che and Wei Dong and Qian Sun and Yuhua Zhang},
  doi          = {10.1016/j.eswa.2025.129388},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129388},
  shortjournal = {Expert Syst. Appl.},
  title        = {A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems. <em>ESWA</em>, <em>298</em>, 129364. (<a href='https://doi.org/10.1016/j.eswa.2025.129364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 0–1 knapsack problem (KP) is a well-known combinatorial optimization problem with wide real-world applications. While evolutionary algorithms have demonstrated promise in solving 0–1 KPs, their performance deteriorates as the problem dimension increases. Cooperative co-evolution (CC) is an algorithmic framework based on a divide-and-conquer strategy, which has been used in solving large-scale optimization problems. Inspired by the similarity between item grouping in the 0–1 KP and decomposition strategies in CC, this paper proposes a novel grouping strategy that uses the position information of break items and profit-to-weight ratio to solve large-scale 0–1 KP. The strategy aims to divide the large-scale 0–1 KP into multiple subproblems, thus having a reduced search space for each subproblem. To enhance population diversity and search efficiency, the profit-to-weight ratio is used to generate an initial elite population. Additionally, to obtain the complete solution for the original large-scale KP, a subgroup merging method is designed to accelerate convergence and further improve population diversity. A three-phase repair operator is developed to fix infeasible solutions directly to create more feasible solutions. The resulting cooperative co-evolutionary algorithm is compared with ten state-of-the-art algorithms for solving 0–1 KPs with variables ranging from 100 to 5,000, including EAs, CC-based approaches, and a deep reinforcement learning method. Experimental results show that the proposed algorithm exhibits higher solution accuracy and faster convergence than other competing algorithms. The CC framework takes considerably less running time than high-performing algorithms, providing an overall novel approach for solving large-scale 0–1 KPs.},
  archive      = {J_ESWA},
  author       = {Xiaotong Li and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.eswa.2025.129364},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129364},
  shortjournal = {Expert Syst. Appl.},
  title        = {A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Life cycle cost reliability assessment for strategic real estate decision-making. <em>ESWA</em>, <em>298</em>, 129329. (<a href='https://doi.org/10.1016/j.eswa.2025.129329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real estate projects prioritize minimizing initial development costs while often overlooking the long-term financial implications of their decisions. This short-term focus frequently leads to increased operational, maintenance, and renewal expenses, ultimately reducing overall profitability. Life Cycle Costing (LCC) provides a comprehensive approach to evaluating total project costs over time; however, its adoption remains limited due to challenges such as data constraints, uncertainty about future cost savings, and the lack of standardized performance measurement tools. To tackle these issues, this paper proposes a structured LCC reliability assessment model designed for real estate decision-makers. The model systematically identifies and analyzes key cost factors across all project phases, including construction, operation, renewal, maintenance, and end-of-life, while integrating technical, economic, environmental, and social dimensions. A structured survey was employed to quantify and prioritize these cost factors, facilitating the development of category-specific LCC models and a standardized evaluation framework. Additionally, a benchmarking scale was created to measure the reliability of input factors. Although this study emphasizes the reliability dimension, it establishes a foundation for the future integration of an optimization module to enhance decision-making and maximize life cycle cost efficiency. The proposed model has been automated to improve usability and accessibility, allowing stakeholders to make informed investment decisions that promote long-term financial sustainability in real estate development.},
  archive      = {J_ESWA},
  author       = {Elin A. Eldars and Amin A. Sorour},
  doi          = {10.1016/j.eswa.2025.129329},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129329},
  shortjournal = {Expert Syst. Appl.},
  title        = {Life cycle cost reliability assessment for strategic real estate decision-making},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing forecast accuracy and switching costs in online optimization of energy management systems. <em>ESWA</em>, <em>298</em>, 129305. (<a href='https://doi.org/10.1016/j.eswa.2025.129305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the integration of forecasting and optimization in energy management systems, focusing on how switching costs, penalties incurred from frequent operational adjustments, affect the balance between forecast accuracy and stability in online decision-making. We develop a theoretical framework analyzing Fixed Horizon Control (FHC) algorithms under switching costs, deriving performance bounds that reveal trade-offs between commitment periods and forecast properties. We introduce a novel Scenario Distribution Change (SDC) metric for measuring temporal consistency in probabilistic forecasts. The framework is validated through empirical evaluation using a real-world battery scheduling case study based on the CityLearn 2022 challenge, comparing deterministic and stochastic optimization approaches across different commitment periods. Theoretical analysis reveals that switching costs create a U-shaped relationship between commitment period and performance, with optimal commitment depending on forecast stability. Empirical results demonstrate that switching costs significantly alter the accuracy-stability trade-off: while traditional approaches favor frequent updates (1-hour commitment), incorporating switching costs makes longer commitment periods (3+ hours) optimal when combined with stable forecasts. Stochastic optimization with scenario averaging reduces forecast error sensitivity by up to 2.9 % in grid costs compared to deterministic approaches. This work contributes the first theoretical bounds linking forecast stability to switching costs in energy systems, the SDC metric for evaluating probabilistic forecast stability, empirical evidence that longer commitment periods can outperform frequent updates under switching costs, and practical guidelines showing that forecast stability should be factored into decision-making frameworks for energy management systems in the presence of switching costs.},
  archive      = {J_ESWA},
  author       = {Evgenii Genov and Julian Ruddick and Christoph Bergmeir and Majid Vafaeipour and Thierry Coosemans and Salvador García and Maarten Messagie},
  doi          = {10.1016/j.eswa.2025.129305},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129305},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing forecast accuracy and switching costs in online optimization of energy management systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation. <em>ESWA</em>, <em>298</em>, 129267. (<a href='https://doi.org/10.1016/j.eswa.2025.129267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arm trajectory planning of crack repair is critical for automated road maintenance. However, existing crack repair face two main challenges: loss of trajectory edge information and redundant planned distances. This study introduces an automated pavement crack repair system that integrates a lightweight crack segmentation model (Lightweight Focal Modulation, LFM-Net) and a repair trajectory planning algorithm (Fixed Neighborhood Search-Artificial Bee Colony, FNS-ABC). Specifically, LFM-Net incorporates conformer-based focal modulation attention (CFMA), enhancing the detailed information during the decoding phase. Additionally, the FNS-ABC enhances the ABC algorithm by incorporating a fixed neighborhood search strategy, effectively reducing redundant planning paths. The system is executed using a self-developed robotic arm with an edge computing unit. Extensive testing in three typical road scenarios-independent cracks, intersection cracks, and complex cracks-demonstrated that the system achieved a mean Intersection over Union (mIoU) of 83.93 %. Finally, the system exhibited an idle trajectory of 79.51 mm when addressing complex cracks, highlighting its superior performance in repair trajectory planning.},
  archive      = {J_ESWA},
  author       = {Jianqi Zhang and Xu Yang and Wei Wang and Yuhang Zhao and Hainian Wang and Yixue Chen},
  doi          = {10.1016/j.eswa.2025.129267},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129267},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-learning based big data analysis for developing a smart supply chain for increased efficiency. <em>ESWA</em>, <em>298</em>, 129246. (<a href='https://doi.org/10.1016/j.eswa.2025.129246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analysis (BDA) in supply chain management (SCM) is receiving growing attention in the present business environment. This is due to the fact that BDA has a wide range of applications in SCM, including customer behaviour analysis, trend analysis, and demand prediction. The increase in information volume has caused the efficiency and effectiveness of traditional procedures to decline, considering this, researchers have developed techniques that have a high capacity to investigate and comprehend vast amounts of data due to the limitations of these tactics in dissecting and interpreting a lot of information. This study represents a hybrid paper that combines a systematic literature review, a methodological proposal using BP neural networks. The main objective of this paper is to recognize the uses of deep learning in SCM. By fostering a calculated system, this paper recognizes the commitments of deep learning strategies in choosing and sectioning providers, foreseeing store network gambles, and assessing requests and deals, creation, stock administration, transportation and circulation, manageable turn of events, and roundabout economy. The novelty in this paper is the Backpropagation (BP) neural networks with big data-driven demand forecasting in supply chains. This method can improve the accuracy of demand forecasting in supply chain management. The study includes a thorough survey of the applications of predictive BDA in SC request gauging. The review highlighted the BDA methodologies used for production network request estimation and comparatively classified them. We collected and analysed these studies as tactics and methodologies for the popular forecast. Seven standard tactics were selected and studied, along with their benefits and drawbacks. Finally, the box-cox transformation representation over years in which for the year 2011–01, it starts with a box-cox value of 9.7 and it inclined till 2011–06 and then declined very exponentially in 2012–07 at 9 and then it keeps on incrementing and reached at 11 at the year 2013–07. Then from 2014 to 2015, the pattern didn’t lower below the box-cox value 10.},
  archive      = {J_ESWA},
  author       = {Sreekumar Narayanan and Sudhir Ramadass and K. Thilagavathi and Rajiv Kumar},
  doi          = {10.1016/j.eswa.2025.129246},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129246},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-learning based big data analysis for developing a smart supply chain for increased efficiency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="iandc">IANDC - 11</h2>
<ul>
<li><details>
<summary>
(2025). K-universality of regular languages. <em>IANDC</em>, <em>307</em>, 105357. (<a href='https://doi.org/10.1016/j.ic.2025.105357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A subsequence of a word w is a word u such that u = w [ i 1 ] w [ i 2 ] … w [ i k ] , for some set of indices 1 ≤ i 1 < i 2 < … < i k ≤ | w | . A word w is k -subsequence universal over an alphabet Σ if every word in Σ k appears in w as a subsequence. In this paper, we study the intersection between the set of k -subsequence universal words over some alphabet Σ and regular languages over Σ. We call a regular language L k- ∃ -subsequence universal if there exists a k -subsequence universal word in L , and k- ∀ -subsequence universal if every word of L is k -subsequence universal. We give algorithms solving the problems of deciding if a given regular language, represented by a finite automaton recognising it, is k- ∃ -subsequence universal and, respectively, if it is k- ∀ -subsequence universal , for a given k . The algorithms are FPT w.r.t. the size of the input alphabet, and their run-time does not depend on k ; they run in polynomial time in the number n of states of the input automaton when the size of the input alphabet is O ( log ⁡ n ) . Moreover, we show that the problem of deciding if a given regular language is k- ∃ -subsequence universal is NP-complete, when the language is over a large alphabet. Further, we provide algorithms for counting the number of k -subsequence universal words (paths) accepted by a given deterministic (respectively, non-deterministic) finite automaton, and ranking an input word (path) within the set of k -subsequence universal words accepted by a given finite automaton.},
  archive      = {J_IANDC},
  author       = {Duncan Adamson and Pamela Fleischmann and Annika Huch and Tore Koß and Florin Manea and Dirk Nowotka},
  doi          = {10.1016/j.ic.2025.105357},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105357},
  shortjournal = {Inf. Comput.},
  title        = {K-universality of regular languages},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent algorithmic advances in simple temporal networks with uncertainty: From faster controllability checking to faster execution. <em>IANDC</em>, <em>307</em>, 105356. (<a href='https://doi.org/10.1016/j.ic.2025.105356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper advances the state of the art in the dynamic controllability (DC) and dispatchability of Simple Temporal Networks with Uncertainty (STNUs) through four key contributions. First, findSRNC is an algorithm that identifies semi-reducible negative cycles in non-dynamically controllable STNUs. Running in O ( m n + k 2 n + k n log ⁡ n ) time (matching the fastest DC-checking algorithms), it handles repeated edges and uses polynomial space, even when cycles might contain exponentially many edges. Second, minDisp ESTNU + is an algorithm that improves dispatchability computation for STNUs from O ( k n 3 ) to O ( n 3 + k 2 n log ⁡ n ) time. It outputs dispatchable Extended STNUs (ESTNUs) having minimal numbers of edges, which is crucial for subsequent real-time execution. Third, the Canonical Form of Nested Diamond Structures in Dispatchable ESTNUs is a rigorous theory that facilitates correctness proofs for dispatchability algorithms. It also helped reveal and correct a flaw in a previously published algorithm. Fourth, our empirical evaluation using improved open-source implementations demonstrates the practical effectiveness of our algorithms. These contributions address fundamental computational bottlenecks in temporal planning systems, enabling more efficient reasoning about uncertain timing constraints while providing real-time guarantees required for robotics, scheduling, and automated planning applications.},
  archive      = {J_IANDC},
  author       = {Luke Hunsberger and Roberto Posenato},
  doi          = {10.1016/j.ic.2025.105356},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105356},
  shortjournal = {Inf. Comput.},
  title        = {Recent algorithmic advances in simple temporal networks with uncertainty: From faster controllability checking to faster execution},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polynomial turing compressions for some graph problems parameterized by modular-width. <em>IANDC</em>, <em>307</em>, 105355. (<a href='https://doi.org/10.1016/j.ic.2025.105355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A polynomial Turing compression (PTC) for a parameterized problem L is a polynomial time Turing machine that has access to an oracle for a problem L ′ such that a polynomial in the input parameter bounds each query. Meanwhile, a polynomial compression (PC) can be regarded as a restricted variant of PTC where the machine can query the oracle exactly once and must output the same answer as the oracle. Bodlaender et al. (ICALP 2008) and Fortnow and Santhanam (STOC 2008) initiated an impressive hardness theory for PC under the assumption coNP ⊈ NP/poly. Let C be the set of all problems with PTCs but without PCs assuming coNP ⊈ NP/poly. Fernau et al. (STACS 2009) identified Leaf Out-tree( k ) as the first problem in C . However, little is known about C , with only a dozen problems confirmed in it over the last fifteen years. Open questions remain, such as whether CNF-SAT( n ) and k -path are in C , requiring novel ideas to clarify the differences between PTCs and PCs. In this paper, we enrich our knowledge about C by demonstrating that 17 problems parameterized by modular-width ( mw ), such as Chromatic Number( mw ) and Hamiltonian Cycle( mw ) , belong to C . Additionally, we develop a general recipe to prove the existence of PTCs for a class of problems, including these 17.},
  archive      = {J_IANDC},
  author       = {Weidong Luo},
  doi          = {10.1016/j.ic.2025.105355},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105355},
  shortjournal = {Inf. Comput.},
  title        = {Polynomial turing compressions for some graph problems parameterized by modular-width},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On cardinalities of rogers semilattices for families in the ershov hierarchy. <em>IANDC</em>, <em>307</em>, 105354. (<a href='https://doi.org/10.1016/j.ic.2025.105354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of numberings provides classification results for families of sets in various computability-theoretic hierarchies. The algorithmic content of numberings is typically calibrated via the reducibility between numberings. For a given family of sets S , this reducibility gives rise to an upper semilattice of degrees that is often called the Rogers semilattice of S . This paper studies the cardinalities of Rogers semilattices for families of sets at finite levels of the Ershov hierarchy. The classical result of Khutoretskii (1971) shows that the Rogers semilattice of a family of c.e. sets is either one-element or countably infinite. Badaev and Lempp (2009) constructed a family of d.c.e. sets that demonstrates that the methods of Khutoretskii cannot be applied to obtain a similar result for Rogers semilattices already at the second level of the Ershov hierarchy. We prove that for any finite family of sets S at any finite level of the Ershov hierarchy, the corresponding Rogers semilattice is either one-element or countably infinite. We also obtain another sufficient condition for a Rogers semilattice to be infinite. This condition implies that the Rogers semilattice of Badaev and Lempp is also infinite.},
  archive      = {J_IANDC},
  author       = {Keng Meng Ng and Nikolay Bazhenov and Birzhan Kalmurzayev and Dias Nurlanbek},
  doi          = {10.1016/j.ic.2025.105354},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105354},
  shortjournal = {Inf. Comput.},
  title        = {On cardinalities of rogers semilattices for families in the ershov hierarchy},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact counting of subtrees with diameter no more than d in trees: A generating function approach. <em>IANDC</em>, <em>307</em>, 105353. (<a href='https://doi.org/10.1016/j.ic.2025.105353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network motifs, regarded as fundamental building blocks, offer crucial insights into the structure and function of complex networks, with broad applications across disciplines including sociology, computer science, bioinformatics, chemoinformatics, and pharmaceutics. However, the identification of network motifs remains a significant and computationally challenging problem. Among various motifs, subtree enumeration has garnered substantial attention in recent years, particularly due to its relevance in network science and bioinformatics. For an n -vertex tree T , by introducing novel generating functions with ( d + 2 ) variables, we propose an innovative algorithm for the exact enumeration of T 's subtrees rooted at fixed vertex v , where the distance between v and the farthest leaf is k = 0 , 1 , … , d , and the distance between any two leaves is no more than d . Building on this algorithm, we develop novel recursive algorithms for exact enumerating various diameter no more than d subtrees (abbreviated as DNMT- d subtrees) of T . As applications, we apply these algorithms to derive the number of DNMT- d subtrees in a full binary tree B h with h ≥ 2 levels, and briefly discuss the density of DNMT- d subtrees in general trees. Our research generalizes the work of Frank Ruskey on Listing and Counting Subtrees of a Tree in 1981 and makes it a special case of our study where d equals the diameter of the tree T . Moreover, the proposed O ( d n 2 ) algorithms introduce new approaches for enumerating subtrees under diameter constraints and lay the groundwork for counting diameter-constrained subgraphs (motifs) in complex networks.},
  archive      = {J_IANDC},
  author       = {Yu Yang and Bang-Bang Jin and Xiaoming Sun and Xiao-Dong Zhang and Bo Li and Kai Zhao and Hua Wang},
  doi          = {10.1016/j.ic.2025.105353},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105353},
  shortjournal = {Inf. Comput.},
  title        = {Exact counting of subtrees with diameter no more than d in trees: A generating function approach},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision problems for systems of language equations and inequations. <em>IANDC</em>, <em>307</em>, 105344. (<a href='https://doi.org/10.1016/j.ic.2025.105344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems of language equations φ ( X 1 , … , X n ) = ψ ( X 1 , … , X n ) and inequations φ ( X 1 , … , X n ) ≠ ψ ( X 1 , … , X n ) are studied, where φ and ψ may contain Boolean operations and concatenation. It is proved that the problem whether such a system has a solution is Σ 2 0 -complete in the arithmetical hierarchy (cf. the earlier studied case of equations only, where it is co-r.e.-complete), the problem whether it has a unique solution is in Σ 3 0 ∩ Π 3 0 , and is both Σ 2 0 -hard and Π 2 0 -hard, existence of a finite or regular solution is an r.e.-complete problem, while testing whether a system has finitely many solutions is Σ 3 0 -complete. Furthermore, it is shown that the class of languages representable by unique solutions of such systems is exactly the class of recursive sets, but decision procedures for the set cannot be algorithmically constructed out of a system. All results hold already for equations over a unary alphabet.},
  archive      = {J_IANDC},
  author       = {Alexander Okhotin},
  doi          = {10.1016/j.ic.2025.105344},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105344},
  shortjournal = {Inf. Comput.},
  title        = {Decision problems for systems of language equations and inequations},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards a theoretical understanding of why local search works for clustering with fair-center representation. <em>IANDC</em>, <em>307</em>, 105343. (<a href='https://doi.org/10.1016/j.ic.2025.105343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The representative k -median problem generalizes the classical clustering formulations in that it partitions the data points into ℓ disjoint demographic groups and imposes a lower-bound constraint on the number of opened facilities from each group, such that all the groups are fairly represented by the opened facilities. Due to its simplicity, the local-search heuristic, which iteratively swaps a bounded number of closed facilities for the same number of opened ones to improve the solution, has been frequently used in the representative k -median problem. It is known that the local-search heuristic, when restricted to constant-size swaps, yields a constant-factor approximation if ℓ = 2 , and has an unbounded approximation ratio if ℓ is super-constant. However, for any constant ℓ > 2 , the existence of a constant-factor approximation under constant-size swaps remained an open question for a long time. In response to this question, we demonstrate that the local-search heuristic guarantees a ( 4 ℓ + 5 ) -approximation when up to ℓ ( ℓ + 1 ) facilities are allowed to be swapped in each iteration, thus providing an affirmative answer to the question. Our main technical contribution is a novel approach for theoretically analyzing the local-search heuristic, which bounds its approximation ratio by linearly combining the clustering cost increases induced by a set of hierarchically organized swaps. Our techniques also generalize to the k -means clustering formulation and reveal similar approximation guarantees for the local-search heuristic.},
  archive      = {J_IANDC},
  author       = {Zhen Zhang and Junfeng Yang and Limei Liu and Xuesong Xu and Guozhen Rong and Qilong Feng},
  doi          = {10.1016/j.ic.2025.105343},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105343},
  shortjournal = {Inf. Comput.},
  title        = {Towards a theoretical understanding of why local search works for clustering with fair-center representation},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The billaud conjecture for alphabet size 4. <em>IANDC</em>, <em>307</em>, 105342. (<a href='https://doi.org/10.1016/j.ic.2025.105342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Billaud Conjecture, first stated in 1993, is a fundamental problem on finite words and their heirs, i.e., the words obtained by a projection deleting a single letter. The conjecture states that every morphically primitive word, i.e., a word that is not a fixed point of any non-identity morphism, has at least one morphically primitive heir. The correctness of the conjecture has so far been established in a few special cases, which mainly restrict the alphabet size. In this paper we give a proof for the next such case, i.e., for alphabet size 4.},
  archive      = {J_IANDC},
  author       = {Szymon Łopaciuk and Daniel Reidenbach},
  doi          = {10.1016/j.ic.2025.105342},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105342},
  shortjournal = {Inf. Comput.},
  title        = {The billaud conjecture for alphabet size 4},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The g-good-neighbor diagnosability of product networks under the PMC model. <em>IANDC</em>, <em>307</em>, 105341. (<a href='https://doi.org/10.1016/j.ic.2025.105341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of neighbor connectivity originated from the assessment of the subversion of espionage networks caused by underground resistance movements, and it has now been applied to measure the disruption of networks caused by cascading failures through neighbors. In this paper, we give two necessary and sufficient conditions of the existence of g -good-neighbor diagnosability. We introduce a new concept called g -good neighbor cut-component number (gc number for short), which has close relation with g -good-neighbor diagnosability. Sharp lower and upper bounds of the gc number of general graphs in terms of the g -good neighbor connectivity have been proposed, which provide a formula to compute the g -good-neighbor diagnosability for general graphs (therefore for Cartesian product graphs). As their applications, we get the exact values or bounds for the gc numbers and g -good-neighbor diagnosability of grid, torus networks and generalized cubes.},
  archive      = {J_IANDC},
  author       = {Zhao Wang and Yaping Mao and Sun-Yuan Hsieh and Ralf Klasing},
  doi          = {10.1016/j.ic.2025.105341},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105341},
  shortjournal = {Inf. Comput.},
  title        = {The g-good-neighbor diagnosability of product networks under the PMC model},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-state spin systems with negative interactions. <em>IANDC</em>, <em>307</em>, 105340. (<a href='https://doi.org/10.1016/j.ic.2025.105340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the approximability of computing the partition functions of two-state spin systems. The problem is parameterized by a 2 × 2 symmetric matrix. Previous results on this problem were restricted either to the case where the matrix has non-negative entries, or to the case where the diagonal entries are equal, i.e. Ising models. In this paper, we study the generalization to arbitrary 2 × 2 interaction matrices with real entries. We show that in some regions of the parameter space, it's #P-hard to even determine the sign of the partition function, while in other regions there are fully polynomial approximation schemes for the partition function. Our results reveal several new computational phase transitions.},
  archive      = {J_IANDC},
  author       = {Yumou Fei and Leslie Ann Goldberg and Pinyan Lu},
  doi          = {10.1016/j.ic.2025.105340},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105340},
  shortjournal = {Inf. Comput.},
  title        = {Two-state spin systems with negative interactions},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competition among parallel contests. <em>IANDC</em>, <em>307</em>, 105339. (<a href='https://doi.org/10.1016/j.ic.2025.105339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the model of multiple rank-order contests held in parallel, where each contestant only selects one contest to join and each contest designer decides the prize structure to compete for the participation of contestants. We first analyze the strategic behaviors of contestants and completely characterize the symmetric Bayesian Nash equilibrium. As for the strategies of contest designers, when other designers' strategies are known, we show that computing the best response is NP-hard and propose a fully polynomial time approximation scheme to output the ϵ -approximate best response. When other designers' strategies are unknown, we provide a worst-case analysis on one designer's strategy. We give an upper bound on the worst-case utility of any strategy and propose a method to construct a strategy whose utility can guarantee a constant ratio of this upper bound in the worst case.},
  archive      = {J_IANDC},
  author       = {Xiaotie Deng and Ningyuan Li and Weian Li and Qi Qi},
  doi          = {10.1016/j.ic.2025.105339},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105339},
  shortjournal = {Inf. Comput.},
  title        = {Competition among parallel contests},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="icv">ICV - 18</h2>
<ul>
<li><details>
<summary>
(2025). MFET: Multi-frequency enhancement transformer for single-image super-resolution. <em>ICV</em>, <em>163</em>, 105751. (<a href='https://doi.org/10.1016/j.imavis.2025.105751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-Image Super-Resolution (SISR) aims to reconstruct a high-resolution image from a low-resolution input while effectively preserving structural integrity and fine details. However, (i) low-frequency structural cues progressively fade during deep-layer propagation, and (ii) existing upsampling modules either ignore multi-scale context or incur excessive computation, leading to unsatisfactory high-frequency texture recovery. To address these limitations, we propose the Multi-Frequency Enhancement Transformer (MFET), a novel Transformer-based network tailored for efficient SISR. MFET seamlessly integrates low-frequency structural preservation with high-frequency detail recovery through its Multi-Frequency Block (MFB). The MFB employs a Residual Attention Mechanism (RAM) to propagate fine-grained features across layers, ensuring robust retention of low-level details, and an Efficient Upscale Module (EUM) with a pyramidal structure and depthwise separable convolutions to enhance high-frequency components with minimal computational cost. Extensive experiments on benchmark datasets demonstrate that MFET achieves superior performance in PSNR and SSIM, particularly at ×3 and ×4 scales, excelling in texture and edge reconstruction. MFET strikes an optimal balance between quality and efficiency, offering a promising solution for high-quality super-resolution. Our code is available at https://github.com/snh4/MFET .},
  archive      = {J_ICV},
  author       = {Yunlei Sun and Pengxiao Shi and Tiancheng Chen and Danning Qi and Ke Xu},
  doi          = {10.1016/j.imavis.2025.105751},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105751},
  shortjournal = {Image Vis. Comput.},
  title        = {MFET: Multi-frequency enhancement transformer for single-image super-resolution},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fall detection using deep learning with features computed from recursive quadratic splits of video frames. <em>ICV</em>, <em>163</em>, 105749. (<a href='https://doi.org/10.1016/j.imavis.2025.105749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accidental falls are a leading cause of injury and death worldwide, particularly among the elderly. Despite extensive research on fall detection, many existing systems remain limited by reliance on wearable sensors that are inconvenient for continuous use, or vision-based approaches that require full video decoding, human pose estimation, or simplified datasets that fail to capture the complexity of real-life environments. As a result, their accuracy often deteriorates in realistic scenarios such as nursing homes or crowded public spaces. In this paper, we introduce a novel fall detection framework that leverages information embedded in the High Efficiency Video Coding (HEVC) standard. Unlike traditional vision-based methods, our approach extracts spatio-temporal features directly from recursive block splits and other HEVC coding information. This includes creating a sequence of four RGB input images which capture block sizes and splits of the video frames in a visual manner. The block sizes in video coding are determined based on the spatio-temporal activities in the frames, hence the suitability of using them as features. Other features are also derived from the coded videos, including compression modes, motion vectors, and prediction residuals. To enhance robustness, we integrate these features into deep learning models and employ fusion strategies that combine complementary representations. Extensive evaluations on two challenging datasets: the Real-World Fall Dataset (RFDS) and the High-Quality Fall Simulation Dataset (HQFSD), demonstrate that our method achieves superior accuracy and robustness compared to prior work. In addition, our method requires only around 23 GFLOPs per video because the deep learning network is executed on just four fixed-frame representations, whereas traditional pipelines process every frame individually, often amounting to hundreds of frames per video and orders of magnitude higher FLOPs.},
  archive      = {J_ICV},
  author       = {Zahra Solatidehkordi and Tamer Shanableh},
  doi          = {10.1016/j.imavis.2025.105749},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105749},
  shortjournal = {Image Vis. Comput.},
  title        = {Fall detection using deep learning with features computed from recursive quadratic splits of video frames},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PR-DETR: Extracting and utilizing prior knowledge for improved end-to-end object detection. <em>ICV</em>, <em>163</em>, 105745. (<a href='https://doi.org/10.1016/j.imavis.2025.105745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The query initialization in the Transformer-based target detection algorithm has static characteristics, resulting in a limitation to flexibly adjust the degree of attention to different image features during the learning process. In addition, without the guidance of global spatial semantic information, it will cause the model to disregard the relationship between the target and the surrounding environment due to relying on local features for target detection, causing the problem of false detection or missed detection of the target. In order to solve the above problems, this paper proposes a query-optimized target detection model PR-DETR based on feature map guidance. PR-DETR designs the Aggregating Global Spatial Semantic Information module (AGSSI module) to extract and enhance global spatial semantic information. Afterwards, we design queries that participate in the interaction of local and global spatial semantic information in the encoding part in advance, so as to obtain sufficient prior knowledge and provide more accurate and efficient queries for subsequent decoding feature maps. Experiment results show that PR-DETR has significantly improved detection accuracy on the MS COCO data set compared with existing related research work. The mAP is 3.5, 2.3 and 2.0 higher than Conditional-DETR, Anchor-DETR and DAB-DETR respectively.},
  archive      = {J_ICV},
  author       = {Yukang Huo and Mingyuan Yao and Tonghao Wang and Qingbin Tian and Jiayin Zhao and Xiao Liu and Haihua Wang},
  doi          = {10.1016/j.imavis.2025.105745},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105745},
  shortjournal = {Image Vis. Comput.},
  title        = {PR-DETR: Extracting and utilizing prior knowledge for improved end-to-end object detection},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DECF-FGVC: A discriminative enhancement and complementary fusion approach for fine-grained bird visual classification. <em>ICV</em>, <em>163</em>, 105744. (<a href='https://doi.org/10.1016/j.imavis.2025.105744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained bird image recognition plays a critical role in species conservation. However, existing approaches are constrained by complex background interference, insufficient extraction of discriminative features, and limited integration of hierarchical information. While Vision Transformers (ViTs) demonstrate superior performance over CNNs in fine-grained classification tasks, they remain vulnerable to background noise, with class tokens often failing to capture key regions - overlooking the complementarity between low-level details and high-level semantics. This study proposes DECF-FGVC, a novel model incorporating three modules: Patch Contrast Enhancement (PCE), Contrast Token Refiner (CTR), and Hierarchical Token Synthesizer (HTS). These modules synergistically suppress background noise, emphasize key regions, and integrate multi-layer features through attention-weighted image reconstruction, counterfactual learning-based token refinement, and hierarchical token fusion. Extensive experiments on CUB-200-2011, NABirds, and iNaturalist2017 datasets achieve classification accuracies of 91.9%, 91.4%, and 77.92% respectively, consistently outperforming state-of-the-art methods.},
  archive      = {J_ICV},
  author       = {ShuaiShuai Deng and Tianhua Chen and Qinghua Qiao},
  doi          = {10.1016/j.imavis.2025.105744},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105744},
  shortjournal = {Image Vis. Comput.},
  title        = {DECF-FGVC: A discriminative enhancement and complementary fusion approach for fine-grained bird visual classification},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepDCT-VO: 3D directional coordinate transformation for low-complexity monocular visual odometry using deep learning. <em>ICV</em>, <em>163</em>, 105742. (<a href='https://doi.org/10.1016/j.imavis.2025.105742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based monocular visual odometry has gained importance in robotics and autonomous navigation due to its robustness in visually challenging environments and minimal sensor requirements. However, many existing deep learning-based MVO methods suffer from high computational costs and large model sizes, making them less suitable for real-time applications in resource-limited systems. In this study, we propose DeepDCT-VO, a lightweight visual odometry method that combines three-dimensional directional coordinate transformation with a compact deep learning architecture. Unlike traditional approaches that estimate translation in a global coordinate system and are prone to drift accumulation, DeepDCT-VO uses local directional motion derived from composite rotations. This approach avoids global trajectory reconstruction, thereby improving the method’s stability and reliability. The proposed model operates on input images at multiple resolutions (120 × 120, 240 × 240, 360 × 360, and 480 × 480), leveraging attention-guided residual learning to extract robust features. Additionally, it incorporates multi-modal information—specifically depth and semantic maps—to further improve the accuracy of pose estimation. Evaluations on the KITTI odometry benchmark demonstrate that DeepDCT-VO achieves competitive trajectory estimation accuracy while maintaining real-time performance—8 ms per frame on GPU and 12 ms on CPU. Compared to the existing method with the lowest translational drift ( t rel ), DeepDCT-VO reduces model size by approximately 96.3% (from 37.5 million to 1.4 million parameters). Conversely, when compared to the lightest model in terms of parameter count, DeepDCT-VO reduces t rel from 8.57% to 1.69%, achieving an 80.3% reduction in translational drift. These results underscore the effectiveness of DeepDCT-VO in delivering accurate and efficient monocular visual odometry, particularly suited for embedded and resource-limited applications, while the proposed transformation method offers an auxiliary function in reducing translational complexity.},
  archive      = {J_ICV},
  author       = {E. Simsek and B. Ozyer},
  doi          = {10.1016/j.imavis.2025.105742},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105742},
  shortjournal = {Image Vis. Comput.},
  title        = {DeepDCT-VO: 3D directional coordinate transformation for low-complexity monocular visual odometry using deep learning},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-time adaptation for object detection via dynamic dual teaching. <em>ICV</em>, <em>163</em>, 105740. (<a href='https://doi.org/10.1016/j.imavis.2025.105740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Test-Time Adaptation (TTA) is a practical setting in real-world applications, which aims to adapt a source-trained model to target domains with online unlabeled test data streams. Current approaches often rely on self-training, utilizing supervision signals from the source-trained model, suffering from poor adaptation due to diverse domain shifts. In this paper, we propose a novel test-time adaptation method for object detection guided by dual teachers, termed D ynamic D ual T eaching ( DDT ). Inspired by the generalization potentials of Vision-Language Models (VLMs), we integrate the VLM as an additional language-driven instructor. This integration exploits the domain-robustness of language prompts to mitigate domain shifts, collaborating with the teacher of source information within the teacher–student framework. Firstly, we utilize an ensemble prompt to guide the prediction process of the language-driven instructor. Secondly, a dynamic fusion strategy of the dual teachers is designed to generate high-quality pseudo-labels for student learning. Moreover, we incorporate a dual prediction consistency regularization to further mitigate the sensitivity of the adapted detector to domain shifts. Experiments on diverse domain adaptation benchmarks demonstrate that the proposed DDT method achieves state-of-the-art performance on both online and offline domain adaptation settings.},
  archive      = {J_ICV},
  author       = {Siqi Zhang and Lu Zhang and Zhiyong Liu},
  doi          = {10.1016/j.imavis.2025.105740},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105740},
  shortjournal = {Image Vis. Comput.},
  title        = {Test-time adaptation for object detection via dynamic dual teaching},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining fine-grained attributes for vision–semantics integration in few-shot learning. <em>ICV</em>, <em>163</em>, 105739. (<a href='https://doi.org/10.1016/j.imavis.2025.105739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Few-Shot Learning (FSL) have been significantly driven by leveraging semantic descriptions to enhance feature discrimination and recognition performance. However, existing methods, such as SemFew, often rely on verbose or manually curated attributes and apply semantic guidance only to the support set, limiting their effectiveness in distinguishing fine-grained categories. Inspired by human visual perception, which emphasizes crucial features for accurate recognition, this study introduces concise, fine-grained semantic attributes to address these limitations. We propose a Visual Attribute Enhancement (VAE) mechanism that integrates enriched semantic information into visual features, enabling the model to highlight the most relevant visual attributes and better distinguish visually similar samples. This module enhances visual features by aligning them with semantic attribute embeddings through a cross-attention mechanism and optimizes this alignment using an attribute-based cross-entropy loss. Furthermore, to mitigate the performance degradation caused by methods that supply semantic information exclusively to the support set, we propose a semantic attribute reconstruction (SAR) module. This module predicts and integrates semantic features for query samples, ensuring balanced information distribution between the support and query sets. Specifically, SAR enhances query representations by aligning and reconstructing semantic and visual attributes through regression and optimal transport losses to ensure semantic–visual consistency. Experiments on five benchmark datasets, including both general datasets and more challenging fine-grained Few-Shot datasets consistently demonstrate that our proposed method outperforms state-of-the-art methods in both 5-way 1-shot and 5-way 5-shot settings.},
  archive      = {J_ICV},
  author       = {Juan Zhao and Lili Kong and Deshang Sun and Deng Xiong and Jiancheng Lv},
  doi          = {10.1016/j.imavis.2025.105739},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105739},
  shortjournal = {Image Vis. Comput.},
  title        = {Mining fine-grained attributes for vision–semantics integration in few-shot learning},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable deepfake detection across different modalities: An overview of methods and challenges. <em>ICV</em>, <em>163</em>, 105738. (<a href='https://doi.org/10.1016/j.imavis.2025.105738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of deepfake technology enables the creation of realistic and deceptive content, raising concerns about several serious issues, including biometric authentication, misinformation, politics, privacy, and trust. Many Deepfake Detection (DD) models are entering the market to combat the misuse of deepfakes. With these developments, one primary issue occurs in ensuring the explainability of the proposed detection models to understand the rationale of the decision. This paper aims to investigate the state-of-the-art explainable DD models across multiple modalities, including image, video, audio, and text. Unlike existing surveys that focus on detection methodologies with minimal attention to explainability and limited modality coverage, this paper directly focuses on these gaps. It offers a comprehensive analysis of advanced explainability techniques, including Grad-CAM, LIME, SHAP, LRP, Saliency Maps, and Anchors, for detecting deceptive content across the modalities. It identifies the strengths and limitations of existing models and outlines research directions to enhance explainability and interpretability in future works. By exploring these models, we aim to enhance transparency, provide deeper insights into model decisions, and bridge the gap between detection accuracy with explainability in DD models.},
  archive      = {J_ICV},
  author       = {MD Sarfaraz Momin and Abu Sufian and Debaditya Barman and Marco Leo and Cosimo Distante and Naser Damer},
  doi          = {10.1016/j.imavis.2025.105738},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105738},
  shortjournal = {Image Vis. Comput.},
  title        = {Explainable deepfake detection across different modalities: An overview of methods and challenges},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic sparse and weight allocation-based text-driven person retrieval. <em>ICV</em>, <em>163</em>, 105737. (<a href='https://doi.org/10.1016/j.imavis.2025.105737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image person retrieval aims to find the most matching personimages in a large-scale persondataset through textual descriptions. However, most of the existing methods have the following problems: (1) There are still some inaccurate matching pairs in the retrieval system, and the errors of these matching pairs negatively affect the performance of the whole retrieval system. (2) In the whole training process of the model, the whole text is used directly, but there are still non-important parts of the text that are not important for recognizing the images, and how to process the text effectively is still a hot topic in current research. These critical issues significantly degrade the retrieval performance. To this end, we propose a new alignment optimization framework for text-based person retrieval. Precisely, our framework consists of three key components: (1) progressive enhancement for a multimodal integration, which not only simulates coarse-grained alignment through mathematical modeling, but also appropriately combines coarse-grained and fine-grained alignment through progressive learning; (2) global bidirectional match filtering, which utilizes subjective logic to effectively mitigate the interference of incorrectly matched pairs of image text, and at the same time utilizes a bidirectional KL match filtering algorithm so as to select the matching pairs with high degree of image text matching for training; (3) fine-grained dynamic sparse mask modeling, which uses mask language modeling and constructs a dynamic spatial sparsification module, which not only applies more expressive modules to important positions but also mines the relationship between image text pairs at a fine-grained level, thus improving retrieval performance. Extensive experiments show that the method achieves state-of-the-art results on three benchmark datasets and performs well on domain generalization tasks.},
  archive      = {J_ICV},
  author       = {Shuren Zhou and Qihang Zhou and Jiao Liu},
  doi          = {10.1016/j.imavis.2025.105737},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105737},
  shortjournal = {Image Vis. Comput.},
  title        = {Dynamic sparse and weight allocation-based text-driven person retrieval},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MITS: A large-scale multimodal benchmark dataset for intelligent traffic surveillance. <em>ICV</em>, <em>163</em>, 105736. (<a href='https://doi.org/10.1016/j.imavis.2025.105736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General-domain large multimodal models (LMMs) have achieved significant advances in various image-text tasks. However, their performance in the Intelligent Traffic Surveillance (ITS) domain remains limited due to the absence of dedicated multimodal datasets. To address this gap, we introduce MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale multimodal benchmark dataset specifically designed for ITS. MITS includes 170,400 independently collected real-world ITS images sourced from traffic surveillance cameras, annotated with eight main categories and 24 subcategories of ITS-specific objects and events under diverse environmental conditions. Additionally, through a systematic data generation pipeline, we generate high-quality image captions and 5 million instruction-following visual question-answer pairs , addressing five critical ITS tasks : object and event recognition, object counting, object localization, background analysis, and event reasoning. To demonstrate MITS’s effectiveness, we fine-tune mainstream LMMs on this dataset, enabling the development of ITS-specific applications. Experimental results show that MITS significantly improves LMM performance in ITS applications, increasing LLaVA-1.5’s performance from 0.494 to 0.905 (+83.2%), LLaVA-1.6’s from 0.678 to 0.921 (+35.8%), Qwen2-VL’s from 0.584 to 0.926 (+58.6%), and Qwen2.5-VL’s from 0.732 to 0.930 (+27.0%). We release the dataset, code, and models as open-source , providing high-value resources to advance both ITS and LMM research.},
  archive      = {J_ICV},
  author       = {Kaikai Zhao and Zhaoxiang Liu and Peng Wang and Xin Wang and Zhicheng Ma and Yajun Xu and Wenjing Zhang and Yibing Nan and Kai Wang and Shiguo Lian},
  doi          = {10.1016/j.imavis.2025.105736},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105736},
  shortjournal = {Image Vis. Comput.},
  title        = {MITS: A large-scale multimodal benchmark dataset for intelligent traffic surveillance},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UNIR-net: A novel approach for restoring underwater images with non-uniform illumination using synthetic data. <em>ICV</em>, <em>163</em>, 105734. (<a href='https://doi.org/10.1016/j.imavis.2025.105734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoring underwater images affected by non-uniform illumination (NUI) is essential to improve visual quality and usability in marine applications. Conventional methods often fall short in handling complex illumination patterns, while learning-based approaches face challenges due to the lack of targeted datasets. To address these limitations, the Underwater Non-uniform Illumination Restoration Network (UNIR-Net) is proposed. UNIR-Net integrates multiple components, including illumination enhancement, attention mechanisms, visual refinement, and contrast correction, to effectively restore underwater images affected by NUI. In addition, the Paired Underwater Non-uniform Illumination (PUNI) dataset is introduced, specifically designed for training and evaluating models under NUI conditions. Experimental results on PUNI and the large-scale real-world Non-Uniform Illumination Dataset (NUID) show that UNIR-Net achieves superior performance in both quantitative metrics and visual outcomes. UNIR-Net also improves downstream tasks such as underwater semantic segmentation, highlighting its practical relevance. The code is available at https://github.com/xingyumex/UNIR-Net .},
  archive      = {J_ICV},
  author       = {Ezequiel Pérez-Zarate and Chunxiao Liu and Oscar Ramos-Soto and Diego Oliva and Marco Pérez-Cisneros},
  doi          = {10.1016/j.imavis.2025.105734},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105734},
  shortjournal = {Image Vis. Comput.},
  title        = {UNIR-net: A novel approach for restoring underwater images with non-uniform illumination using synthetic data},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFENet: A frequency fusion and enhancement network for camouflaged object detection. <em>ICV</em>, <em>163</em>, 105733. (<a href='https://doi.org/10.1016/j.imavis.2025.105733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of camouflaged object detection (COD) is to accurately find camouflaged objects hidden in their surroundings. Although most of the existing frequency-domain based COD models can boost the performance of COD to a certain extent by utilizing the frequency domain information, the frequency feature fusion strategies they adopt tend to ignore the complementary effects between high-frequency features and low-frequency features. In addition, most of the existing frequency-domain based COD models also do not consider enhancing camouflaged objects using low-level frequency-domain features. In order to solve these problems, we present a frequency fusion and enhancement network (FFENet) for camouflaged object detection, which mainly includes three stages. In the frequency feature extraction stage, we design a frequency feature learning module (FLM) to extract corresponding high-frequency features and low-frequency features. In the frequency feature fusion stage, we design a frequency feature fusion module (FFM) that can increase the representation ability of the fused features by adaptively assigning weights to the high-frequency features and the low-frequency features using a cross-attention mechanism. In the frequency feature guidance information enhancement stage, we design a frequency feature guidance information enhancement module (FGIEM) to enhance the contextual information and detail information of camouflaged objects in the fused features under the guidance of the low-level frequency features. Extensive experimental results on the COD10K, CHAMELEON, NC4K and CAMO datasets show that our model is superior to most existing COD models.},
  archive      = {J_ICV},
  author       = {Haishun Du and Wenzhe Zhang and Sen Wang and Zhengyang Zhang and Linbing Cao},
  doi          = {10.1016/j.imavis.2025.105733},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105733},
  shortjournal = {Image Vis. Comput.},
  title        = {FFENet: A frequency fusion and enhancement network for camouflaged object detection},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UpAttTrans: Upscaled attention based transformer for facial image super-resolution. <em>ICV</em>, <em>163</em>, 105731. (<a href='https://doi.org/10.1016/j.imavis.2025.105731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) aims to reconstruct high-quality images from low-resolution inputs, a task particularly challenging in face-related applications due to extreme degradations and modality differences (e.g., visible, low-resolution, near-infrared). Conventional convolutional neural networks (CNNs) and GAN-based approaches have achieved notable success; however, they often struggle with preserving identity and fine structural details at high upscaling factors. In this work, we introduce UpAttTrans, a novel attention mechanism that connects original and upsampled features for better detail recovery based on vision transformer for SR. The core generator leverages a custom UpAttTrans module that translates input image patches into embeddings, processes them through transformer layers enhanced with connector-up attention, and reconstructs high-resolution outputs with improved detail retention. We evaluate our model on the CelebA dataset across multiple upscaling factors ( 4 × , 8 × , 16 × , 32 × , and 64 × ). UpAttTrans achieves a 24.63% increase in PSNR, 21.56% in SSIM, and 19.61% reduction in FID for 4 × and 8 × SR, outperforming state-of-the-art baselines. Additionally, for higher magnification levels, our model maintains strong performance, with average gains of 6.20% in PSNR and 21.49% in SSIM, indicating its robustness in extreme SR settings. These findings suggest that UpAttTrans holds significant promise for real-world applications such as face recognition in surveillance, forensic image enhancement, and cross-spectral matching, where high-quality reconstruction from severely degraded inputs is critical.},
  archive      = {J_ICV},
  author       = {Neeraj Baghel and Shiv Ram Dubey and Satish Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105731},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105731},
  shortjournal = {Image Vis. Comput.},
  title        = {UpAttTrans: Upscaled attention based transformer for facial image super-resolution},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation. <em>ICV</em>, <em>163</em>, 105729. (<a href='https://doi.org/10.1016/j.imavis.2025.105729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation is a vital early detection method for several severe ocular diseases. Despite significant progress in retinal vessel segmentation with the advancement of Neural Networks, there are still challenges to overcome. Specifically, retinal vessel segmentation aims to predict the class label for every pixel within a fundus image, with a primary focus on intra-image discrimination, making it vital for models to extract more discriminative features. Nevertheless, existing methods primarily focus on minimizing the difference between the output from the decoder and the label, but ignore fully using feature-level fine-grained representations from the encoder. To address these issues, we propose a novel Attention U-shaped Kolmogorov–Arnold Network named AttUKAN along with a novel Label-guided Pixel-wise Contrastive Loss for retinal vessel segmentation. Specifically, we implement Attention Gates into Kolmogorov–Arnold Networks to enhance model sensitivity by suppressing irrelevant feature activations and model interpretability by non-linear modeling of KAN blocks. Additionally, we also design a novel Label-guided Pixel-wise Contrastive Loss to supervise our proposed AttUKAN to extract more discriminative features by distinguishing between foreground vessel-pixel pairs and background pairs. Experiments are conducted across four public datasets including DRIVE, STARE, CHASE_DB1, HRF and our private dataset. AttUKAN achieves F1 scores of 82.50%, 81.14%, 81.34%, 80.21% and 80.09%, along with MIoU scores of 70.24%, 68.64%, 68.59%, 67.21% and 66.94% in the above datasets, which are the highest compared to 11 networks for retinal vessel segmentation. Quantitative and qualitative results show that our AttUKAN achieves state-of-the-art performance and outperforms existing retinal vessel segmentation methods. Our code will be available at https://github.com/stevezs315/AttUKAN .},
  archive      = {J_ICV},
  author       = {Shuang Zeng and Chee Hong Lee and Micky C. Nnamdi and Wenqi Shi and J. Ben Tamo and Hangzhou He and Xinliang Zhang and Qian Chen and May D. Wang and Lei Zhu and Yanye Lu and Qiushi Ren},
  doi          = {10.1016/j.imavis.2025.105729},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105729},
  shortjournal = {Image Vis. Comput.},
  title        = {Novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence content detection techniques using watermarking: A survey. <em>ICV</em>, <em>163</em>, 105728. (<a href='https://doi.org/10.1016/j.imavis.2025.105728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement in AI-generated content has catalyzed artistic creation, advertising, and media dissemination. Despite their widespread applications across several domains, AI-generated content inherently poses risks of identity fraud, copyright violation and unauthorized use. Watermarking has emerged as a critical tool for copyright protection, allowing embedding of identification information in AI-generated content, and enhances traceability and verification without hurting user experience. In this study, we provide a systematic literature review of the technique for detecting AI content, especially text and images, using watermarking, spanning studies from 2010 to 2025. Studies included in this review were peer-reviewed articles that applied watermarking to effectively distinguish AI-generated content from real or human-written content. We report strong past and current approaches to detecting watermarking-based AI content, especially text and images. This includes an analysis of how watermarking methods are used on AI-generated content, their role in enhancing performance, and a detail comparative analysis of notable techniques. Furthermore, we discuss how these methods have been evaluated, identify the research gaps and potential solutions. Our findings provide valuable insights for future watermarking-based AI content detection researchers, applications and organizations seeking to implement watermarking solutions in potential applications. To the best of our knowledge, we are the first to explore the detection of AI content, especially text and image, detection using watermarking.},
  archive      = {J_ICV},
  author       = {Nishant Kumar and Amit Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105728},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105728},
  shortjournal = {Image Vis. Comput.},
  title        = {Artificial intelligence content detection techniques using watermarking: A survey},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Your image generator is your new private dataset. <em>ICV</em>, <em>163</em>, 105727. (<a href='https://doi.org/10.1016/j.imavis.2025.105727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative diffusion models have emerged as powerful tools to synthetically produce training data, offering potential solutions to data scarcity and reducing labelling costs for downstream supervised deep learning applications. However, existing approaches for synthetic dataset generation face significant limitations: previous methods like Knowledge Recycling rely on label-conditioned generation with models trained from scratch, limiting flexibility and requiring extensive computational resources, while simple class-based conditioning fails to capture the semantic diversity and intra-class variations found in real datasets. Additionally, effectively leveraging text-conditioned image generation for building classifier training sets requires addressing key issues: constructing informative textual prompts, adapting generative models to specific domains, and ensuring robust performance. This paper proposes the Text-Conditioned Knowledge Recycling (TCKR) pipeline to tackle these challenges. TCKR combines dynamic image captioning, parameter-efficient diffusion model fine-tuning, and Generative Knowledge Distillation techniques to create synthetic datasets tailored for image classification. The pipeline is rigorously evaluated on ten diverse image classification benchmarks. The results demonstrate that models trained solely on TCKR-generated data achieve classification accuracies on par with (and in several cases exceeding) models trained on real images. Furthermore, the evaluation reveals that these synthetic-data-trained models exhibit substantially enhanced privacy characteristics: their vulnerability to Membership Inference Attacks is significantly reduced, with the membership inference AUC lowered by 5.49 points on average compared to using real training data, demonstrating a substantial improvement in the performance-privacy trade-off. These findings indicate that high-fidelity synthetic data can effectively replace real data for training classifiers, yielding strong performance whilst simultaneously providing improved privacy protection as a valuable emergent property. The code and trained models are available in the accompanying open-source repository .},
  archive      = {J_ICV},
  author       = {Nicolò Francesco Resmini and Eugenio Lomurno and Cristian Sbrolli and Matteo Matteucci},
  doi          = {10.1016/j.imavis.2025.105727},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105727},
  shortjournal = {Image Vis. Comput.},
  title        = {Your image generator is your new private dataset},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the noise robustness of class activation maps: A framework for reliable model interpretability. <em>ICV</em>, <em>163</em>, 105717. (<a href='https://doi.org/10.1016/j.imavis.2025.105717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class Activation Maps (CAMs) are one of the important methods for visualizing regions used by deep learning models. Yet their robustness to different noise remains underexplored. In this work, we evaluate and report the resilience of various CAM methods for different noise perturbations across multiple architectures and datasets. By analyzing the influence of different noise types on CAM explanations, we assess the susceptibility to noise and the extent to which dataset characteristics may impact explanation stability. The findings highlight considerable variability in noise sensitivity for various CAMs. We propose a robustness metric for CAMs that captures two key properties: consistency and responsiveness. Consistency reflects the ability of CAMs to remain stable under input perturbations that do not alter the predicted class, while responsiveness measures the sensitivity of CAMs to changes in the prediction caused by such perturbations. The metric is evaluated empirically across models, different perturbations, and datasets along with complementary statistical tests to exemplify the applicability of our proposed approach.},
  archive      = {J_ICV},
  author       = {Syamantak Sarkar and Revoti P. Bora and Bhupender Kaushal and Sudhish N. George and Kiran Raja},
  doi          = {10.1016/j.imavis.2025.105717},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105717},
  shortjournal = {Image Vis. Comput.},
  title        = {Assessing the noise robustness of class activation maps: A framework for reliable model interpretability},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InceptionWTMNet: A hybrid network for alzheimer’s disease detection using wavelet transform convolution and mixed local channel attention on finely fused multimodal images. <em>ICV</em>, <em>163</em>, 105693. (<a href='https://doi.org/10.1016/j.imavis.2025.105693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has emerged as a critical technique for the diagnosis of Alzheimer’s Disease (AD), with the aim of effectively extracting and utilising complementary information from diverse modalities. Current fusion methods frequently cause the precise alignment of source images and do not adequately address parallax issues. This oversight can result in artifacts during the fusion process when images are misaligned. In response to this challenge, we propose a refined registration fusion technique, termed MURF, which integrates multimodal image registration and fusion within a cohesive framework. The Vision Transformer (ViT) has inspired the application of large-kernel convolutions in the diagnosis of Alzheimer’s disease (AD) because of its ability to model long-range dependencies. This approach aims to expand the receptive field and enhance the performance of diagnostic models. Despite requiring a minimal number of floating-point operations (FLOPs), these deep operators encounter challenges associated with over-parameterisation because of high memory access costs, which ultimately compromises computational efficiency. By utilising wavelet transform convolutions (WTConv), we decompose large-kernel depth-wise convolutions into four parallel branches. One branch employs a wavelet-transform convolution with square kernels, while the other two branches incorporate orthogonal wavelet-transform kernels with an identity mapping. This innovative method, with a Mixed Local Channel Attention mechanism, has facilitated the development of the InceptionWTConvolutions network. This network maintains a receptive field comparable to that of large-kernel convolutions, while concurrently minimising over-parameterisation and enhancing computational efficiency. InceptionWTMNet classified AD, MCI, and NC using MRI and PET data from ADNI dataset with 98.69% accuracy, 98.65% recall, 98.70% F1-score, and 98.98% AUC. and provide Graphical abstract in correct format.},
  archive      = {J_ICV},
  author       = {Zenan Xu and Zhengyao Bai and Han Ma and Mingqiang Xu and Qiqin Huang and Tao Lin},
  doi          = {10.1016/j.imavis.2025.105693},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105693},
  shortjournal = {Image Vis. Comput.},
  title        = {InceptionWTMNet: A hybrid network for alzheimer’s disease detection using wavelet transform convolution and mixed local channel attention on finely fused multimodal images},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijar">IJAR - 1</h2>
<ul>
<li><details>
<summary>
(2026). Choosing the center of star-shaped set-valued data compatible with measure-preserving arithmetic. <em>IJAR</em>, <em>188</em>, 109575. (<a href='https://doi.org/10.1016/j.ijar.2025.109575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set-valued data has traditionally been represented by considering non-empty compact and convex subsets of R d with the usual Minkowski addition. An alternative and flexible setting that admits a functional representation are the star-shaped sets. A framework based on a center-radial characterization has been introduced to treat these sets from a statistical point of view. The arithmetic is defined directionally, which is more natural for representing imprecision propagation in higher dimensions. Nevertheless, the problem of determining a center for star-shaped sets coherent with the arithmetic and sound for statistical purposes has not been fully addressed yet. The aim is to advance on the directional characterization for star-shaped sets by considering a measure-preserving arithmetic together with a center selection fully compatible with this arithmetic. The practicability of the new framework will be illustrated using a classical dataset in set-valued statistics.},
  archive      = {J_IJAR},
  author       = {Gil González-Rodríguez},
  doi          = {10.1016/j.ijar.2025.109575},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109575},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Choosing the center of star-shaped set-valued data compatible with measure-preserving arithmetic},
  volume       = {188},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="ipl">IPL - 2</h2>
<ul>
<li><details>
<summary>
(2026). The harmonious coloring game. <em>IPL</em>, <em>192</em>, 106609. (<a href='https://doi.org/10.1016/j.ipl.2025.106609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A harmonious k -coloring of a graph G is a 2-distance proper k -coloring of its vertices such that each edge is uniquely identified by the colors of its endpoints. Here, we introduce its game version: the harmonious coloring game. In this two-player game, Alice and Bob alternately select an uncolored vertex and assigns to it a color in { 1 , … , k } with the constraint that, at every turn, the set of colored vertices induces a valid partial harmonious coloring. Alice wins if all vertices are colored; otherwise, Bob wins. The harmonious game chromatic number χ h g ( G ) is the minimum integer k such that Alice has a winning strategy with k colors. In this paper, we prove the PSPACE-hardness of three variants of this game. As a by-product, we prove that a variant introduced by Chen et al. in 1997 of the classical graph coloring game is PSPACE-hard even in graphs with diameter two. We also obtain lower and upper bounds for χ h g ( G ) in graph classes, such as paths, cycles, grids and forests of stars.},
  archive      = {J_IPL},
  author       = {Cláudia Linhares Sales and Thiago Marcilon and Nicolas Martins and Nicolas Nisse and Rudini Sampaio},
  doi          = {10.1016/j.ipl.2025.106609},
  journal      = {Information Processing Letters},
  month        = {2},
  pages        = {106609},
  shortjournal = {Inf. Process. Lett.},
  title        = {The harmonious coloring game},
  volume       = {192},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The steiner path aggregation problem. <em>IPL</em>, <em>192</em>, 106608. (<a href='https://doi.org/10.1016/j.ipl.2025.106608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Steiner Path Aggregation Problem , our goal is to aggregate paths in a directed network into a single arborescence without significantly disrupting the paths. In particular, we are given a directed multigraph with colored arcs, a root, and k terminals, each of which has a monochromatic path to the root. Our goal is to find an arborescence in which every terminal has a path to the root, and its path does not switch colors too many times. We give an efficient algorithm that finds such a solution with at most 2 log 4 3 ⁡ k color switches. Up to constant factors this is the best possible universal bound, as there are graphs requiring at least log 2 ⁡ k color switches.},
  archive      = {J_IPL},
  author       = {Da Qi Chen and Daniel Hathcock and D. Ellis Hershkowitz and R. Ravi},
  doi          = {10.1016/j.ipl.2025.106608},
  journal      = {Information Processing Letters},
  month        = {2},
  pages        = {106608},
  shortjournal = {Inf. Process. Lett.},
  title        = {The steiner path aggregation problem},
  volume       = {192},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="isat">ISAT - 39</h2>
<ul>
<li><details>
<summary>
(2025). Voltage tracking and regulation of vehicle PEMFC system under low load condition based on fuzzy LQG hybrid strategy. <em>ISAT</em>, <em>165</em>, 510-523. (<a href='https://doi.org/10.1016/j.isatra.2025.06.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In automotive fuel cell systems, high-voltage operation accelerates carbon support and platinum catalyst degradation, significantly compromising system durability. This study develops a dynamic system model with active cathode recirculation to capture the transient response of voltage, and proposes a hybrid control scheme that combines a proportional compensator with a fuzzy LQG controller to effectively enhance voltage regulation and disturbance tracking capabilities. Extensive simulation and hardware-in-the-loop (HiL) confirm the precision and rapid response of the developed controller. Compared to single LQG and fuzzy LQG controllers, the error reduction achieved is 49.3 % and 40.3 %, respectively, and the overall control benefit ratio improves by 19.2 % and 11 %. This method balances dynamic response with control efforts, effectively reducing the risk of high voltage-induced degradation under low-load conditions.},
  archive      = {J_ISAT},
  author       = {Ze Liu and Sichuan Xu and Baitao Zhang and Sida Guo},
  doi          = {10.1016/j.isatra.2025.06.008},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {510-523},
  shortjournal = {ISA Trans.},
  title        = {Voltage tracking and regulation of vehicle PEMFC system under low load condition based on fuzzy LQG hybrid strategy},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade alarm systems: A study on singular value analysis. <em>ISAT</em>, <em>165</em>, 497-509. (<a href='https://doi.org/10.1016/j.isatra.2025.06.023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel alarm system designed for use with both Independent and Identically Distributed (IID) and non-IID variables. The proposed algorithm, termed the Cascade Alarm System (CAS), utilizes the largest singular value of the signal as the basis for fault detection, employing k alarm subsystems. The greatest singular values extracted from the Lagged Covariance Matrix (LCM) of a sliding window constitute the output of the first alarm subsystem. The CAS offers two primary advantages. First, each subsystem independently generates its own alarm signal, resulting in a more flexible multilevel architecture. Second, the multilevel structure, founded on singular value decomposition (SVD), exhibits a filtering property that enhances its resilience to noise and inaccuracies. The maximum singular value effectively captures the essential information of the signal, ensuring that the filtering capabilities of the proposed method do not significantly compromise the performance of the alarm system or the integrity of critical signal information. The experimental results from the implementation of the proposed alarm system under various fault conditions demonstrate satisfactory performance. Additionally, the performance of the Cascade Alarm System has been compared with leading contemporary alarm system design methodologies, including median, moving average filters, delay timers, Cumulative Sum Control Chart (CUSUM), and serial method.},
  archive      = {J_ISAT},
  author       = {J. Taheri-Kalani and M. Aliyari-Shoorehdeli and Gh. Latif-Shabgahi},
  doi          = {10.1016/j.isatra.2025.06.023},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {497-509},
  shortjournal = {ISA Trans.},
  title        = {Cascade alarm systems: A study on singular value analysis},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow pulsation compensation based composite adaptive active disturbance rejection control for electro-hydrostatic actuators. <em>ISAT</em>, <em>165</em>, 486-496. (<a href='https://doi.org/10.1016/j.isatra.2025.06.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the residual pressure accumulated during the reciprocating movement of the plunger pump, there is a deviation between the flow pulsation and the theoretical calculation value. Current nonlinear control methods for the electro-hydrostatic actuator (EHA) often oversimplify and compensate for flow pulsation linearly, neglecting its nonlinear characteristics and deviation effects. This approach increases matching uncertainties and amplifies noise due to higher control gains, thus limiting the improvement of control performance. To address this issue, this paper proposes a composite adaptive disturbance rejection control method based on flow pulsation compensation for the EHA. This method equates the flow pulsation model of the pump to a combination of a theoretical flow pulsation control input term and a bounded disturbance term (the difference between the theoretical and actual flow pulsation), followed by the design of a composite adaptive law to handle parameter uncertainties, and the design of the expanded state observers based on position and pressure signals to estimate and compensate for the uncertainties nonlinearly. Finally, the effectiveness of the proposed method is verified by comparing with other control methods through experiments.},
  archive      = {J_ISAT},
  author       = {Yaowen Ge and Xiaowei Yang and Weilin Zhu and Wenxiang Deng and Jianyong Yao},
  doi          = {10.1016/j.isatra.2025.06.014},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {486-496},
  shortjournal = {ISA Trans.},
  title        = {Flow pulsation compensation based composite adaptive active disturbance rejection control for electro-hydrostatic actuators},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polytopic inclusion-based model predictive control for quasi-LPV systems using vertex system models and gain scheduling. <em>ISAT</em>, <em>165</em>, 474-485. (<a href='https://doi.org/10.1016/j.isatra.2025.05.051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Model Predictive Control (MPC) strategy for a class of Quasi-Linear Parameter-Varying (quasi-LPV) systems characterized by a measurable time-varying parameter. The core of the proposed quasi-LPV-MPC controller lies in the utilization of a polytopic representation along with a gain-scheduled controller. A terminal cost that depends explicitly on the scheduling parameter is used. However, for the implementation, a complementary cost function is used to frame the optimization problem at each vertex level so that the requirement of updating the varying parameters over the prediction horizon is relaxed. Though the resulting suboptimal controller involves more computational burden, the proposed method demonstrates improvement in control performance over traditional MPC schemes. Experimental validation on a cascaded coupled tank system underscores the practical efficacy of the proposed quasi-LPV-MPC controller, while simulation studies on a twin rotor multi-input multi-output system serve as an additional demonstration example case. Comparative performance evaluations against both linear and nonlinear MPCs clearly illustrate that the quasi-LPV-MPC offers better control precision, adaptability, and the overall system responsiveness, thus positioning it as an effective solution for quasi-LPV systems.},
  archive      = {J_ISAT},
  author       = {Rangoli Singh and Sandip Ghosh and Devender Singh},
  doi          = {10.1016/j.isatra.2025.05.051},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {474-485},
  shortjournal = {ISA Trans.},
  title        = {Polytopic inclusion-based model predictive control for quasi-LPV systems using vertex system models and gain scheduling},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the global energy optimization of multi-source and multi-actuator hydraulic systems based on dynamic programming and improved adaptive genetic algorithm. <em>ISAT</em>, <em>165</em>, 450-473. (<a href='https://doi.org/10.1016/j.isatra.2025.06.010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source and multi-actuator hydraulic systems (MSAHSs) are widely used in high-power energy transmission and construction machinery. However, individual control of each component without considering the overall power matching leads the system to the low-efficiency zone, results in environmental pollution and huge economic loss. Therefore, it is highly desirable to find a way of obtaining energy-saving green MSAHSs. In this paper, the power consumption model of closed MSAHSs is established firstly to analyze theoretical factors affecting the component efficiency and find that the hydraulic pressure is the key factor. On this basis, a multi-algorithm integration global power matching method is then proposed, which consist of back propagation (BP) neural network, dynamic programming (DP) and improved adaptive genetic algorithm (IAGA). BP is used to construct efficiency prediction models for power elements (pumps, motors and engines) respectively, DP is used for elements’ high efficiency zone preliminary search, and IAGA is used to realize the global power matching of the multiple power units with energy conversion and transfer finally through optimal control parameters precise searching. Experiment is conducted on the closed MSAHS in a hydraulic fracturing vehicle. Results demonstrate that the MSAHS applied with multi-algorithm integration method improves the overall efficiency to a highest fuel savings of 35.5 % under normal conditions compared with local power matching control.},
  archive      = {J_ISAT},
  author       = {Yuhang Zhong and Wenting Chen and Zihao Chen and Guanyu Zhai and Chao Ai and Gexin Chen},
  doi          = {10.1016/j.isatra.2025.06.010},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {450-473},
  shortjournal = {ISA Trans.},
  title        = {Research on the global energy optimization of multi-source and multi-actuator hydraulic systems based on dynamic programming and improved adaptive genetic algorithm},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent energy adaptive control of loader shoveling system. <em>ISAT</em>, <em>165</em>, 437-449. (<a href='https://doi.org/10.1016/j.isatra.2025.06.021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loaders are often faced with various working objects during the shoveling process. The differences in working resistance and its time-varying unpredictability when shoveling different objects are the main causes of high energy consumption during the shoveling stage. In this paper, through the analysis of the shoveling process, the influence of the compacted layer on the working resistance is obtained. The constructed Discrete Element Method (DEM) simulation model is used to elucidate that the timely lifting of the boom can have a destructive effect on the compacted layer. Moreover, considering the diversity of working objects, a study was carried out on the effect of different boom lifting ranges on the destruction of the compacted layer. The loader shoveling system's intelligent Energy Adaptive Control (EAC) strategy is constructed by integrating the material recognition model based on the Back Propagation (BP) neural network algorithm. This control strategy can output the set pilot pressure according to the material type, realize the intelligent adjustment of the lifting range of the boom with the change of material type, and reduce the working resistance during the shoveling stage. The peak engine power consumed while shoveling sand, gravel, and boulders decreased by 20.6 %, 19.1 %, and 10.9 %, respectively, improving the energy utilization rate of the loader shoveling system when facing different working objects.},
  archive      = {J_ISAT},
  author       = {Bingwei Cao and Changhao Mu and Jiaqi Dong and Guangliang Tian and Yuqi Wang},
  doi          = {10.1016/j.isatra.2025.06.021},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {437-449},
  shortjournal = {ISA Trans.},
  title        = {Intelligent energy adaptive control of loader shoveling system},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis and design of oscillation frequency correction for servo resonance suppression. <em>ISAT</em>, <em>165</em>, 422-436. (<a href='https://doi.org/10.1016/j.isatra.2025.06.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical resonance poses significant hazards to the normal operation of the servo systems. To mitigate mechanical resonance, online adaptive notch filter is extensive used, thus the precise determination of resonant frequency holds significant importance. However, in certain scenarios involving the high-bandwidth servo system, a phenomenon known as frequency shift can make the notch filter ineffective in addressing servo resonance. To solve this problem, an oscillation frequency correction scheme based on two improved sliding-mode observers (ISMOs) utilizing a dual-power approximation law is proposed. First, the oscillation frequency shift is analyzed around the system delay, which can be equivalently modeled using a Pade approximation method. Subsequently, a feedback loop featuring two adaptive feedback coefficients is designed to automatically tune the time factor. Remarkably, the scheme can dynamically correct oscillation frequency, thereby promoting resonance suppression. At the same time, ISMOs-identified mechanical parameters provide critical foundations for feedback coefficient adjustment. It is worth noting that the dual-power approximation law effectively suppresses high-frequency chatter while maintaining parameter identification accuracy. Finally, the effectiveness of the scheme is validated through simulation and experimental results.},
  archive      = {J_ISAT},
  author       = {Yanan Tang and Shaowu Lu and Puliang Yu and Bao Song},
  doi          = {10.1016/j.isatra.2025.06.011},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {422-436},
  shortjournal = {ISA Trans.},
  title        = {Analysis and design of oscillation frequency correction for servo resonance suppression},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A segmented model based internal model control scheme of electromagnetic micro-mirror systems. <em>ISAT</em>, <em>165</em>, 408-421. (<a href='https://doi.org/10.1016/j.isatra.2025.06.003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a segmented internal model control (SIMC) scheme based on the segmented combination model of the electromagnetic micro-mirror system (EMMS) is established. Notice that highly underdamped oscillation and rate-dependent hysteresis exist in the EMMS, so it is a complex nonlinear dynamic system. In order to control the deflection angle of the EMMS using the internal model control strategy, it is necessary to establish the inverse model of the EMMS. Therefore, a new model structure that is convenient for inversion is proposed in this paper to describe the characteristics of the EMMS with underdamped and rate-dependent hysteresis. In the proposed scheme, the model is a combination of a group of weighted sub-models based on the segmentation of the system's operating frequency. The weight of each segmented sub-model is not a constant but a new type of function which is also called the smoothing factor. Its function is to smooth the switching between sub-models, thereby reducing the dynamic error caused by model switching. In addition, the particle swarm optimization (PSO) algorithm is used to determine the optimal frequency segmentation points, which helps to obtain the optimal model for describing the system characteristics. Based on the proposed segmented combination model, the corresponding segmented internal model control with two-degree-of-freedom filters is proposed, and the corresponding filters in the internal model control are designed based on the small gain theorem. Finally, the proposed control strategy is applied to the control of the deflection angle of the electromagnetic micro-mirror to verify the proposed control method. Moreover, the non-smooth internal model control strategy is also used for comparison in the experiments.},
  archive      = {J_ISAT},
  author       = {Ruili Dong and Qingyuan Tan and Yonghong Tan and Xiaoli Song and Tianyu Wang},
  doi          = {10.1016/j.isatra.2025.06.003},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {408-421},
  shortjournal = {ISA Trans.},
  title        = {A segmented model based internal model control scheme of electromagnetic micro-mirror systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PPAC-pilot: Prescribed-performance augmented control for fixed-wing autopilots. <em>ISAT</em>, <em>165</em>, 395-407. (<a href='https://doi.org/10.1016/j.isatra.2025.06.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a Prescribed-Performance Augmented Control (PPAC) framework designed for fixed-wing Unmanned Aerial Vehicle (UAV) autopilots. The PPAC strategy aims to enhance, rather than replace, existing PID control loops in open-source autopilots. Although traditional autopilots effectively manage routine tasks in most applications, their reliance on meticulous tuning remains a limitation. To address this, PPAC leverages historical flight data, a frequently overlooked resource, to derive dynamic linearization models and control laws without requiring explicit UAV models. The PPAC framework is then integrated with the Total Energy Control System (TECS) for practical deployment in takeoff and cruising scenarios. Comprehensive numerical simulations and Hardware-in-the-Loop (HIL) tests validate the strategy by comparing baseline autopilot performance with PPAC-augmented systems. Results confirm that PPAC ensures prescribed performance bounds for altitude tracking errors across evaluated scenarios, demonstrating its effectiveness in augmenting autopilots with minimized redesign efforts.},
  archive      = {J_ISAT},
  author       = {Qiuyang Tian and Zelin Wang and Tianjiang Hu},
  doi          = {10.1016/j.isatra.2025.06.001},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {395-407},
  shortjournal = {ISA Trans.},
  title        = {PPAC-pilot: Prescribed-performance augmented control for fixed-wing autopilots},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hysteresis observer enhanced integral terminal sliding mode control of piezoelectric platform for precision tracking applications. <em>ISAT</em>, <em>165</em>, 384-394. (<a href='https://doi.org/10.1016/j.isatra.2025.06.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinearity of piezo-actuated positioning platforms significantly impacts their performance in high-precision applications. In this work a dynamic model of piezoelectric platform was developed firstly with the asymmetric Bouc-Wen model. Next, a terminal sliding mode observer with the super-twisting mechanism was designed to accurately estimate the state of the system. Then, a novel control strategy named Hysteresis Observer Enhanced Integral Terminal Sliding Mode Controller (HO-ITSMC) was proposed to achieve precise displacement tracking. Its stability is theoretically proved by the Lyapunov theorem. A key feature of this controller lies in its ability to drive the state of the system into zero in finite time, regardless of the initial state. Extensive experiments have thoroughly validated the effectiveness of the proposed control method, demonstrating its superior precision-tracking performance compared to traditional controllers.},
  archive      = {J_ISAT},
  author       = {Jie Chen and Lei Ni and Xuan Liao and Geng Wang and Lanqiang Zhang and Na Yao and Yijun Li and Sumeet S. Aphale},
  doi          = {10.1016/j.isatra.2025.06.022},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {384-394},
  shortjournal = {ISA Trans.},
  title        = {Hysteresis observer enhanced integral terminal sliding mode control of piezoelectric platform for precision tracking applications},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive robust control for ball-screw drives with flexible transmission and nonlinear friction via dynamic surface control approach. <em>ISAT</em>, <em>165</em>, 372-383. (<a href='https://doi.org/10.1016/j.isatra.2025.05.050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible deformation and nonlinear friction in ball-screw drive systems are important factors that restrict the improvement of tracking performance. In this paper, a high-performance adaptive controller is presented for ball screw drives to suppress vibration and improve tracking accuracy. A two-inertia model with torsional vibration state is established to fit the dynamics of the drive system while the continuously differentiable LuGre model characterizes the nonlinear friction disturbance. Based on the established nonlinear model, an adaptive robust controller (ARC) is designed by using the backstepping approach to overcome the parametric uncertainties and hard-to-model dynamics. The dual-observer is employed in the controller to observe and compensate for the nonlinear friction, which improves the low-velocity tracking performance of the ball-screw drives. Meanwhile, first-order filters are introduced by dynamic surface control (DSC) technique to eliminate the “complexity explosion” problem caused by the backstepping method. The controller theoretically guarantees that all signals of the closed-loop system are bounded, and the convergence of tracking error is also ensured via Lyapunov analysis. The effectiveness of the proposed controller is verified through simulation and experimental results.},
  archive      = {J_ISAT},
  author       = {Yanliang Sheng and Guofeng Wang and Fei Wang and Decai Li and Mantang Hu},
  doi          = {10.1016/j.isatra.2025.05.050},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {372-383},
  shortjournal = {ISA Trans.},
  title        = {Adaptive robust control for ball-screw drives with flexible transmission and nonlinear friction via dynamic surface control approach},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-sensing framework for weak fault detection of planetary gearbox. <em>ISAT</em>, <em>165</em>, 358-371. (<a href='https://doi.org/10.1016/j.isatra.2025.06.009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planetary gearbox fault detection has attracted wide attention due to the planetary gearbox’s key role in modern electro-mechanic equipment. However, traditional fault detection technologies still heavily rely on additional sensors. The resulting enormous cost of sensors restricts the application of those technologies. Given this situation, a self-sensing fault detection framework to explore the weak fault impulses of the planetary gearbox is presented without additional sensors. In this framework, we first capture the preliminary signals from the servo control systems. Then, the hole control model of the motor driving planetary gearbox is constructed. After this step, the feasibility of fault detection for the planetary gearbox through the motor servo control signals is investigated. With the measured servo control signals, a multi-signal assisting adaptive time synchronous averaging method is first proposed to explore fault impulses. This method first introduces a periodic enhanced Gini to select optimal parameters adaptively. Finally, experiments on a weak fault of three components in the planetary gearbox are carried out separately, certifying our framework's validation of planetary gearbox fault detection. This framework hopes to provide a novel scheme for the weak fault self-sensing of planetary gearboxes.},
  archive      = {J_ISAT},
  author       = {Dexin Chen and Ming Zhao and Shudong Ou and Sen Li and Xiaolong Han},
  doi          = {10.1016/j.isatra.2025.06.009},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {358-371},
  shortjournal = {ISA Trans.},
  title        = {A self-sensing framework for weak fault detection of planetary gearbox},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear self-triggered MPC without terminal conditions for trajectory tracking. <em>ISAT</em>, <em>165</em>, 347-357. (<a href='https://doi.org/10.1016/j.isatra.2025.06.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a trajectory tracking problem for a class of nonlinear discrete-time systems is investigated by a model predictive control (MPC) strategy. Compared with the standard MPC strategy, the proposed MPC strategy removes terminal conditions, including terminal penalty terms and terminal state constraints. This novel design requires fewer parameters to be determined, which leads to high practicability. Moreover, to reduce the computational burden, a self-triggered mechanism is presented by using the discrepancy in the cost function between adjacent time instants. Then, an additional compensation variable is designed for the redundancy from the self-triggered mechanism. Finally, we present a mathematical proof for the recursive feasibility of the optimization problem. The effectiveness and practicality of the proposed self-triggered MPC strategy are verified through simulation examples and experimental results on a mobile vehicle experimental platform.},
  archive      = {J_ISAT},
  author       = {Hai Zhao and Hongjiu Yang and Yuanqing Xia and Jinhui Zhang},
  doi          = {10.1016/j.isatra.2025.06.005},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {347-357},
  shortjournal = {ISA Trans.},
  title        = {Nonlinear self-triggered MPC without terminal conditions for trajectory tracking},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control of multi-bus DC microgrids based on distributed dual-projection-layer recurrent neural network considering bus voltage regulation. <em>ISAT</em>, <em>165</em>, 335-346. (<a href='https://doi.org/10.1016/j.isatra.2025.06.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the broad application of plug-and-play loads, it brings new challenges to conventional control issues in DC microgrids. This work addresses the joint optimization of generation costs and transmission line power losses considering bus voltage regulation. Specifically, the concept of virtual load nodes is first introduced so that loads can be implemented as plug-and-play. Through Kron Reduction, bus voltage of load nodes is indirectly controlled by DG nodes. Then, a distributed dual-projection-layer recurrent neural network (DRNN) is proposed for real-time optimal control. The coupled voltage and current are simultaneously maintained within safe bounds. By using Lyapunov synthesis, the convergence of the DRNN is demonstrated. The effectiveness of the proposed methods is evaluated by simulations in terms of plug-and-play test and comparative analysis.},
  archive      = {J_ISAT},
  author       = {Yuanyuan Zhu and Fan Yang and Guoyu Lin},
  doi          = {10.1016/j.isatra.2025.06.029},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {335-346},
  shortjournal = {ISA Trans.},
  title        = {Optimal control of multi-bus DC microgrids based on distributed dual-projection-layer recurrent neural network considering bus voltage regulation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic nonlinear system modelling and parametric oscillation response characteristics of gas turbines. <em>ISAT</em>, <em>165</em>, 320-334. (<a href='https://doi.org/10.1016/j.isatra.2025.06.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas turbines, as highly complex thermal systems, exhibit significant nonlinearity and stochastic coupling in process control. Under closed-loop automatic speed regulation, persistent parametric oscillations may arise, posing serious threats to system reliability and safety. Aiming to reveal the stochastic response characteristics of parametric oscillations in gas turbines, this paper proposes a novel framework for analyzing the evolution law of parametric oscillation and multi-source stochastic excitations based on stochastic dynamics model, which is derived from thermodynamic equations and verified by measurement data. The internal stochastic excitation is determined by information entropy, while the form of the stochastic process of the external stochastic excitation is identified through data-driven reverse identification. The PDF evolution law of parametric oscillation is studied for different excitation forms, and the bifurcation behavior and sensitivity analysis of them are carried out. Under typical operating conditions, the synergistic effect of internal and external stochastic excitations reduces parametric oscillation amplitude by approximately 31 % compared to internal excitation alone. Moreover, the originally tri-modal distribution evolves into a unimodal pattern, revealing the transition trend of parametric oscillation behavior in gas turbines. These findings offer an effective approach to analyze parametric oscillation.},
  archive      = {J_ISAT},
  author       = {Xingyun Jia and Dengji Zhou},
  doi          = {10.1016/j.isatra.2025.06.028},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {320-334},
  shortjournal = {ISA Trans.},
  title        = {Stochastic nonlinear system modelling and parametric oscillation response characteristics of gas turbines},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy modal time-scheduled control and l2-gain analysis for switched nonlinear systems. <em>ISAT</em>, <em>165</em>, 308-319. (<a href='https://doi.org/10.1016/j.isatra.2025.06.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the fuzzy modal time-scheduled control problem for switched nonlinear systems with L 2 -gain performance. Combined with the hybrid dwell time method, we propose a switched fuzzy modal time-scheduled control (FMTSC) strategy, and establish a criterion for H ∞ performance in systems comprising both unstable and stable subsystems. Meanwhile, we further develop a class of time-scheduled multiple discontinuous Lyapunov functions (TMDLFs) for the switched Takagi-Sugeno (T-S) fuzzy system with L 2 -gain property. Finally, comparative and practical examples are provided to demonstrate the validity of derived theoretical result.},
  archive      = {J_ISAT},
  author       = {Jinling Wang and Jun-Guo Lu and Jiarong Li and Qinghao Zhang and Cheng Hu},
  doi          = {10.1016/j.isatra.2025.06.026},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {308-319},
  shortjournal = {ISA Trans.},
  title        = {Fuzzy modal time-scheduled control and l2-gain analysis for switched nonlinear systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving a class of resource allocation problem under dynamic constraints: A predefined-time distributed optimization scheme. <em>ISAT</em>, <em>165</em>, 295-307. (<a href='https://doi.org/10.1016/j.isatra.2025.05.045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a predefined-time distributed optimization algorithm is designed to solve the resource allocation problem (RAP) with dynamic constraints. This algorithm updates auxiliary variables in real time through a distributed approach and allocates resources to each node based on dynamic constraints. Its advantages include ensuring all nodes quickly converge to the optimal value within a predefined time, thereby enhancing algorithm efficiency. Moreover, the auxiliary variables exchanged between nodes do not contain any real physical information, effectively preventing privacy data leakage. In addition, the convergence of the algorithm is analyzed strictly by the Lyapunov method, which ensures the accuracy of the algorithm. Finally, application examples in smart grids and multi-UAV dynamic collaboration are provided to demonstrate the effectiveness and advantages of the algorithm in different application scenarios.},
  archive      = {J_ISAT},
  author       = {Chuxiong Su and Zhongxu Chen and Zhengyuan Zhu and Hao Dai and Jing Chang},
  doi          = {10.1016/j.isatra.2025.05.045},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {295-307},
  shortjournal = {ISA Trans.},
  title        = {Solving a class of resource allocation problem under dynamic constraints: A predefined-time distributed optimization scheme},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-optimal global path planning and collision-avoidance local path planning for USVs in traffic separation scheme-implemented coastal waters. <em>ISAT</em>, <em>165</em>, 280-294. (<a href='https://doi.org/10.1016/j.isatra.2025.06.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under multiple constraints including unmanned surface vehicle (USV) dynamics, traffic separation scheme (TSS) requirements, navigable water boundaries, and safety thresholds for collision risks, time-optimal path planning and collision-avoidance (COLAV) path planning for USVs in TSS-implemented coastal waters remain challenging. To overcome this challenge, we innovatively develop a hierarchical Gaussian-process-based nonlinear programming (GPNLP) approach for the USV time-optimal global path planning and COLAV local path planning. We model irregular static obstacles using Gaussian process regression for the first time, such that navigable waters are more sufficiently utilized for path planning. A TSS compliance assessment function is created to output violation penalties for the TSS requirements that should be satisfied as far as practicable. Accordingly, we plan the time-optimal global path and the COLAV local path hierarchically by minimizing two integral objective functions (with respect to the TSS violation penalties) subject to the multiple constraints. Simulations and simulation comparison results demonstrate that both the planned USV time-optimal global path and COLAV local path under the proposed hierarchical GPNLP approach are USV dynamics compliant and TSS compliant.},
  archive      = {J_ISAT},
  author       = {Yihan Tao and Jialu Du},
  doi          = {10.1016/j.isatra.2025.06.030},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {280-294},
  shortjournal = {ISA Trans.},
  title        = {Time-optimal global path planning and collision-avoidance local path planning for USVs in traffic separation scheme-implemented coastal waters},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time switching tracking control for unmanned helicopter with multiple constraints. <em>ISAT</em>, <em>165</em>, 268-279. (<a href='https://doi.org/10.1016/j.isatra.2025.06.017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a fixed-time switching tracking control scheme based on the fixed-time disturbance observer (FTDO) is proposed for a 6-DOF unmanned helicopter (UH) with multiple constraints and composite disturbances. The developed fixed-time controller guarantees that the system tracks the desired trajectory within a certain time, regardless of initial conditions. The multiple constraints include input saturation and time-varying output constraints. An improved fixed-time auxiliary system is applied to compensate for the effects of input saturation nonlinearity. By developing a novel switching boundary protection algorithm, a switching control scheme is further designed to solve the output constraints better. An improved FTDO is developed to estimate composite disturbances containing saturation function approximation errors and external disturbances. On this basis, a fixed-time switching back-stepping control method is employed for the position and attitude loops, which enables the UH to track the desired trajectory within the flight path constraints. The experimental results verify the effectiveness of the proposed scheme.},
  archive      = {J_ISAT},
  author       = {Haibo Wang and Shuang Shi and Ziyang Zhen and Ju Jiang},
  doi          = {10.1016/j.isatra.2025.06.017},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {268-279},
  shortjournal = {ISA Trans.},
  title        = {Fixed-time switching tracking control for unmanned helicopter with multiple constraints},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leaderless attitude synchronization control of multiple flexible spacecraft on SO(3). <em>ISAT</em>, <em>165</em>, 254-267. (<a href='https://doi.org/10.1016/j.isatra.2025.06.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents adaptive controllers for leaderless attitude synchronization of multiple flexible spacecraft on S O ( 3 ) under communication topologies containing spanning tree(s). To provide a reference attitude for each spacecraft, distributed observers in 9-dimensional Euclidean space are proposed based on a smooth mapping from Euclidean space ℝ 3 × 3 to Lie group S O ( 3 ) . Both the scenarios with arbitrary and almost zero final angular velocities are considered. Subsequently, adaptive continuous controllers on S O ( 3 ) are presented to achieve the leaderless attitude synchronization subject to external disturbance, while guaranteeing boundedness of flexible vibration. Rigorous proofs are presented to show the convergence of the proposed control methods. The effectiveness of the proposed strategies is further demonstrated by numerical simulations.},
  archive      = {J_ISAT},
  author       = {Chenlu Feng and Weicheng Jin and Ti Chen and Lifeng Wang},
  doi          = {10.1016/j.isatra.2025.06.031},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {254-267},
  shortjournal = {ISA Trans.},
  title        = {Leaderless attitude synchronization control of multiple flexible spacecraft on SO(3)},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust predefined fixed-time formation-containment control for multiple unmanned surface vehicles with input saturation. <em>ISAT</em>, <em>165</em>, 241-253. (<a href='https://doi.org/10.1016/j.isatra.2025.06.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predefined fixed-time formation-containment (PFTFC) control problem for unmanned surface vehicles (USVs) under unknown disturbances and input saturation is investigated, where the leaders form a formation configuration and the followers converge to the predefined convex hull formed by the leaders within a fixed time. To address this issue, a two-layer framework is introduced, decomposing the problem into trajectory estimation and trajectory tracking components. In the first layer, a novel fixed-time trajectory estimator is proposed for the leaders and the followers to estimate the desired trajectory. In the second layer, to eliminate the effects of unknown disturbances and input saturation, a fixed-time disturbance observer and an auxiliary system are proposed. Then combining fixed-time Lyapunov stability and integral sliding mode control, fixed-time control laws are proposed for both the leaders and the followers, respectively. Finally, a numerical simulation example is presented to illustrate the effectiveness of the method introduced in this paper.},
  archive      = {J_ISAT},
  author       = {Yong Chen and Jinlong Huang and Fuxi Niu and Xunhua Dai and Haoyue Huang},
  doi          = {10.1016/j.isatra.2025.06.019},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {241-253},
  shortjournal = {ISA Trans.},
  title        = {Robust predefined fixed-time formation-containment control for multiple unmanned surface vehicles with input saturation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-following control for follow-up support systems under model deviation and time delay. <em>ISAT</em>, <em>165</em>, 232-240. (<a href='https://doi.org/10.1016/j.isatra.2025.06.015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Follow-up support technology can flexibly and effectively suppress machining chatter in thin-walled components. This paper proposes a servo collaborative constraint handling scheme that focuses on achieving coordinated control for the follow-up support system under multi-source coupled constraints and uncertainties. Firstly, a four-point constraint method is introduced, which simplifies the description of pose coordination through the introduction of auxiliary points, and constructs the coordinated relationship of the dual robots’ end-effectors under complex geometric constraints in an intuitive and analytical manner. Secondly, a robust controller based on constraint-following theory is designed, providing an effective means to parameterize the total uncertainty boundary structure caused by model deviation and time delay. Finally, the practical stability of the control algorithm is proven, and its effectiveness and strong robustness are validated through comparative simulations.},
  archive      = {J_ISAT},
  author       = {Fangfang Dong and Zhao Liu and Xiaomin Zhao and Jiang Han and Xiaoyong Huang},
  doi          = {10.1016/j.isatra.2025.06.015},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {232-240},
  shortjournal = {ISA Trans.},
  title        = {Constraint-following control for follow-up support systems under model deviation and time delay},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability analysis of delayed neural networks via novel delay-dependent LKF and integral inequality. <em>ISAT</em>, <em>165</em>, 222-231. (<a href='https://doi.org/10.1016/j.isatra.2025.06.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current paper is concerned with the stability analysis of delayed neural networks. In the case that the delay derivative is restricted with an upper bound only, the augmented LKFs often contain high-degree terms of the time-varying delay, resulting in the non-convex derivatives of LKFs, which can be solved by introducing extra delay-multiplied state variables to transform the non-convex delay-dependent terms into convex ones. To make fuller use of the delay-multiplied state variables and the delay-derivative-dependent information, these delay-multiplied state variables are introduced into an LKF and the integral inequality through the proper augmentation in this paper. Meanwhile, some free-matrix-based zero equations are introduced into this delay-dependent inequality to provide more freedom. By applying the augmented LKF and the novel integral inequality, a delay-dependent stability criterion of delayed neural networks with less conservatism is established, whose advantages are verified by three examples.},
  archive      = {J_ISAT},
  author       = {Fei Long and Chuan-Ke Zhang and Yanjun Shen and Qicheng Mei and Qing Chen},
  doi          = {10.1016/j.isatra.2025.06.027},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {222-231},
  shortjournal = {ISA Trans.},
  title        = {Stability analysis of delayed neural networks via novel delay-dependent LKF and integral inequality},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predefined-time adaptive learning control of nonlinear strict-feedback systems via dynamic regressor extension and mixing. <em>ISAT</em>, <em>165</em>, 209-221. (<a href='https://doi.org/10.1016/j.isatra.2025.06.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a parameter identification algorithm and a novel adaptive tracking control strategy for a specific group of nonlinear strict-feedback systems incorporating the concept of predefined time under model uncertainties. A three-layer transformation-based parameter estimation method with predefined-time convergence properties is proposed to relax the strict persistent excitation condition imposed by conventional approaches. The singular terms that may occur in traditional backstepping design procedures are avoided by using a hyperbolic tangent function to design new control laws and filters. Composite learning control approach that incorporates the algorithm for parameter identification into the framework for adaptive dynamic surface control can achieve error convergence within a practical predefined time. By using Lyapunov analysis, the semi-global uniformly predefined-time boundedness for the closed-loop dynamics is demonstrated. Numerical experiments demonstrate the viability of developed control scheme.},
  archive      = {J_ISAT},
  author       = {Zhonghua Wu and Kuncheng Ma and Junkang Ni},
  doi          = {10.1016/j.isatra.2025.06.016},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {209-221},
  shortjournal = {ISA Trans.},
  title        = {Predefined-time adaptive learning control of nonlinear strict-feedback systems via dynamic regressor extension and mixing},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive PI nonlinear cooperative control for motor cluster. <em>ISAT</em>, <em>165</em>, 191-208. (<a href='https://doi.org/10.1016/j.isatra.2025.05.047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the effects of nonlinearities and uncertainties in the speed regulation of permanent magnet synchronous motors (PMSMs), an adaptive PI nonlinear control strategy is introduced. First, a nonlinear system model is developed using the PMSM mathematical model, and an adaptive PI nonlinear control approach is designed. Numerical simulations are conducted to demonstrate that this control method effectively tracks the system’s desired values. Then, through a group of comparative simulation experiments, the comparison effect of the designed adaptive PI nonlinear control method and the traditional PI control method is analyzed and compared. Additionally, four PMSM collaborative control system models, including the speed tracking and speed synchronization control structures, are constructed. Finally, a simulation model for a cooperative PMSM control system is developed to evaluate the system’s speed tracking capability and the synchronization between multiple motors. The results show that in the designed motor cluster cooperative control system, the PMSM motor cluster using adaptive PI nonlinear control method can achieve cooperative control in speed tracking and speed synchronization, and can maintain stable operation against nonlinear problems and unknown disturbances.},
  archive      = {J_ISAT},
  author       = {Yiting Chen and Yushen Wu and Kairui Chen and Jianhui Wang and Zian Wang},
  doi          = {10.1016/j.isatra.2025.05.047},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {191-208},
  shortjournal = {ISA Trans.},
  title        = {Adaptive PI nonlinear cooperative control for motor cluster},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven parallel linear controllers for reference tracking in nonlinear systems. <em>ISAT</em>, <em>165</em>, 183-190. (<a href='https://doi.org/10.1016/j.isatra.2025.05.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference tracking control for nonlinear systems presents significant challenges, particularly when system models are unavailable and real-time computation is required. We present a purely data-driven approach for reference tracking control, referred to as parallel linear controllers (PLIC), which leverages an architecture composed of two linear controllers operating concurrently in distinct dimensional spaces. These controllers are employed for inverse control and mismatch error compensation, respectively. The first controller utilizes the Koopman operator for lifting the system to a high dimension and solves a quadratic program that facilitates constraint handling. The second controller, which works in the original state space, employs the direct data-driven virtual reference tuning approach with some appropriate modifications. The closed-loop properties of the proposed PLIC are analyzed, and the efficacy of the proposed method is exemplified through benchmark simulation.},
  archive      = {J_ISAT},
  author       = {Yao Shi and José M. Maestre and Lei Xie and Hongye Su},
  doi          = {10.1016/j.isatra.2025.05.048},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {183-190},
  shortjournal = {ISA Trans.},
  title        = {Data-driven parallel linear controllers for reference tracking in nonlinear systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time random reference tracking nonlinear model predictive control: A case study on wind turbines. <em>ISAT</em>, <em>165</em>, 170-182. (<a href='https://doi.org/10.1016/j.isatra.2025.06.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a research effort to extend nonlinear model predictive control methods from setpoint stabilization to reference tracking has been felt increasingly. On the other hand, uncertainty in the reference signal and the requirement for its dynamic forecasting in applications such as wind turbine control motivate the need for robust tracking nonlinear model predictive control approaches more and more. Therefore, this study proposes a random reference tracking nonlinear model predictive control with dynamic forecasting of stochastic references. Convergence to a robust invariant set is guaranteed by an additional constraint limiting the previous step’s tracking stage cost function. The proposed predictive approach is implemented using a parallel Newton-type method to make it more efficient and applicable. The proposed approach for wind turbine control is designed considering the random wind speed reference. Simulations are performed for extreme and fatigue load scenarios. The results show that the proposed controller performs more robustly than the nominal nonlinear model predictive control approach, performing better in optimal power extraction and reducing aerodynamic loads.},
  archive      = {J_ISAT},
  author       = {Mohammad Soleymani and Nooshin Bigdeli and Mehdi Rahmani},
  doi          = {10.1016/j.isatra.2025.06.018},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {170-182},
  shortjournal = {ISA Trans.},
  title        = {Real-time random reference tracking nonlinear model predictive control: A case study on wind turbines},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel MPC-based cascaded control for multi-area smart grids: Tackling renewable energy and EV integration challenges. <em>ISAT</em>, <em>165</em>, 143-169. (<a href='https://doi.org/10.1016/j.isatra.2025.06.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced cascaded control scheme for load frequency regulation in multi-area power systems incorporating renewable energy sources (RES) and electric vehicles (EVs). The proposed design (Model predictive control cascaded with one plus proportional-integral control cascaded with tilt control in parallel with one plus fractional-order integral derivative controller (MPC-((1+PI)-(T+(1+I λ D μ )))) combines predictive, tilt, and fractional-order dynamics to improve adaptability and robustness under uncertainties. Controller parameters are tuned using the Lyrebird Optimization Algorithm (LOA), ensuring fast convergence and effective global search. Simulation results under varying operational conditions, including nonlinearity effects such as Generation Rate Constraints (GRC), Governor Dead Band (GDB), and Communication Time Delays (CTD), confirm the controller’s superiority. It achieves a 96.4 % ITAE reduction, 98.6 % undershoot mitigation, and a settling time of just 5.8 s outperforming existing benchmark strategies (GOA: PDf+(0.75+PI), CBOA: PI-PD, JSA: PI, and ARA: 1+PID).},
  archive      = {J_ISAT},
  author       = {Muhammad S. Tolba and Muhammad Majid Gulzar and Ali Arishi and Mohamed Soliman and Ali Faisal Murtaza},
  doi          = {10.1016/j.isatra.2025.06.024},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {143-169},
  shortjournal = {ISA Trans.},
  title        = {A novel MPC-based cascaded control for multi-area smart grids: Tackling renewable energy and EV integration challenges},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency handling by reinforcement of predictive 2DoF-MPC and state observer LADRC for smart power system. <em>ISAT</em>, <em>165</em>, 128-142. (<a href='https://doi.org/10.1016/j.isatra.2025.05.046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preservation of stability is essential for the efficient and reliable functioning of the electrical transmission system. Frequency oscillations are prevalent in interconnected power systems (IPS) and may lead to instability; therefore, it is crucial to monitor and examine them meticulously. Effective frequency management is essential for regulating frequency output in an interconnected smart power system (ISPS) that includes renewable energy sources (RESs), redox flow batteries (RFBs) and static synchronous series compensators (SSSCs). In view of the challenge presented, this research introduces an efficient control architecture that utilizes a 2 degree of freedom-based model predictive controller (2DoF-MPC) to enhance system performance. Additionally, it integrates a linear active disturbance rejection control (LADRC) to employ a state observer alongside the evolving frequency management. The convergence of the predictive and state observer frameworks results in a robust 2DoF-MPC-LADRC to manage frequency disturbances and uncertainties in the power system. The suggested technique is thoroughly validated across several parameters for ISPS, instilling confidence in its capacity to attain minimal frequency variation in multiple scenarios. The performance of the proposed controller design shows that the frequency performance in area 1 and area 2 settles in 5.085 sec and 3.965 sec, when the load changes by 3 %, and it settles in 4.655 sec and 4.050 sec, respectively, when the load changes by 5 %.},
  archive      = {J_ISAT},
  author       = {Muhammad Majid Gulzar},
  doi          = {10.1016/j.isatra.2025.05.046},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {128-142},
  shortjournal = {ISA Trans.},
  title        = {Frequency handling by reinforcement of predictive 2DoF-MPC and state observer LADRC for smart power system},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional-order sliding mode coordinated controller using super-twisting disturbance observer for an NSSS with predefined-time stability. <em>ISAT</em>, <em>165</em>, 111-127. (<a href='https://doi.org/10.1016/j.isatra.2025.06.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a fractional-order sliding mode coordinated control (FOSMCC) strategy incorporating dual super-twisting disturbance observers (STDOs) to enhance the control performance, stability, and reliability of the nuclear steam supply system (NSSS) under complex, time-varying operating conditions and compound disturbances. The FOSMCC strategy synthesizes the fractional-order control and predefined-time theory with sliding mode control, augmented by the disturbance feedforward compensation loop driven by dual STDOs. Such control framework provides enhanced control performance guarantees, including fast transient response, high steady-state precision, and reinforced disturbance rejection. Furthermore, by employing Lyapunov’s direct approach, it is theoretically demonstrated that the entire NSSS, under the developed coordinated strategy, achieves superior predefined-time stability. Finally, comprehensive numerical validation and comparative studies reveal that the developed FOSMCC strategy with STDOs significantly outperforms both the latest fractional-order fixed-time sliding mode controller (FOFTSMC) and the practically adopted coordinated controller (PACC), exhibiting better transient/steady-state control response and stronger robustness against disturbances. Simulation results validate that, in the presence of compound disturbances, the proposed FOSMCC strategy reduces the integral absolute control error of nuclear power and water level by 89.37 % and 87.67 %, respectively, compared to FOFTSMC, and by 99.97 % and 99.99 %, respectively, compared to PACC.},
  archive      = {J_ISAT},
  author       = {Jiuwu Hui},
  doi          = {10.1016/j.isatra.2025.06.032},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {111-127},
  shortjournal = {ISA Trans.},
  title        = {Fractional-order sliding mode coordinated controller using super-twisting disturbance observer for an NSSS with predefined-time stability},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time observer-based saturated nonsingular terminal sliding mode controller design for an over-actuated ROV with time-varying saturation limits. <em>ISAT</em>, <em>165</em>, 98-110. (<a href='https://doi.org/10.1016/j.isatra.2025.06.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Input saturation is critical in over-actuated systems when multiple degrees of freedom (DOF) with different levels of disturbance rejection are controlled simultaneously by a set of actuators. The current study introduces a novel saturated non-singular terminal sliding mode controller to address input saturation for an over-actuated remotely-operated vehicle (ROV). The proposed controller consists of a tuning algorithm to ensure that the control commands do not violate the time-varying saturation limits of each DOF. In addition, a fixed-time extended-state observer is designed to estimate the vehicle’s velocity along with the lumped unknown dynamics of the system. The observer is also employed as a tool to maintain the orientation of the ROV in extreme environmental conditions. The stability analysis shows that all system’s states, except for yaw angle, are globally finite-time stable and the yaw angle is globally asymptotically stable. Several sets of simulations are carried out and the results demonstrate the superiority of the proposed controller in terms of positioning accuracy, saturation compensation and transient behaviour under different environmental conditions.},
  archive      = {J_ISAT},
  author       = {Alireza Hosseinnajad and Navid Mohajer},
  doi          = {10.1016/j.isatra.2025.06.025},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {98-110},
  shortjournal = {ISA Trans.},
  title        = {Fixed-time observer-based saturated nonsingular terminal sliding mode controller design for an over-actuated ROV with time-varying saturation limits},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonsingular fast terminal sliding mode control scheme for robust trajectory tracking of the underactuated EvoBot modular mobile robot in the vertical plane. <em>ISAT</em>, <em>165</em>, 83-97. (<a href='https://doi.org/10.1016/j.isatra.2025.06.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust control strategy for the vertical plane motion of an underactuated EvoBot mobile robot, modeled as a serial double inverted pendulum, is presented in this study. The control objectives include controlling both the directly actuated generalized coordinates and the non-actuated generalized coordinate, which is controllable through dynamic coupling with the actuated coordinates. In this regard, the system's dynamic equations are derived using the Lagrangian approach. A new nonlinear and nonsingular sliding manifold is introduced, based on which a nonsingular fast terminal sliding mode control scheme is proposed for the trajectory tracking control of the robot. This approach addresses the challenges posed by underactuation, system nonlinearities, instability, parameter uncertainties, and external disturbances. Through Lyapunov stability analysis, it is proven that finite-time asymptotic convergence of the tracking error to zero is ensured when the uncertainty upper bound is known, and convergence to a residual set is achieved when the upper bound is unavailable. The theoretical guarantees provided by the proposed control scheme are further validated through comprehensive MATLAB simulations, where its effectiveness is demonstrated under both low- and high-frequency disturbances as well as parameter uncertainties.},
  archive      = {J_ISAT},
  author       = {H. Jokar and S. Amini Serajgah},
  doi          = {10.1016/j.isatra.2025.06.013},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {83-97},
  shortjournal = {ISA Trans.},
  title        = {A nonsingular fast terminal sliding mode control scheme for robust trajectory tracking of the underactuated EvoBot modular mobile robot in the vertical plane},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time event-triggered sliding mode control for fuzzy singular systems under cyber-attacks. <em>ISAT</em>, <em>165</em>, 72-82. (<a href='https://doi.org/10.1016/j.isatra.2025.06.012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a novel secure control scheme for a particular class of Takagi–Sugeno (TS) fuzzy singular systems susceptible to deception attacks. During these attacks, adversaries can randomly introduce erroneous data into the output and control signals. The proposed strategy addresses the impact of attacks and disturbances using an observer-based sliding mode control (SMC) approach. Moreover, an event-triggering protocol is implemented to manage network resources efficiently. Furthermore, by employing the stochastic Lyapunov theory and the finite-time analysis method, sufficient conditions are established to ensure the finite-time boundedness of the resulting closed-loop system throughout both the reaching and sliding motion phases. To mitigate the attack’s effects and improve the system’s performance, the Secretary Bird Optimization Algorithm (SBOA) with the linear matrix inequality (LMI) is explored as a new approach for designing the optimal gains of controllers and observers. Finally, a simulation study based on a disc rolling on a surface is performed to showcase the efficacy and resilience of the proposed control scheme.},
  archive      = {J_ISAT},
  author       = {Mourad Kchaou and Rabeh Abassi and Houssem Jerbi},
  doi          = {10.1016/j.isatra.2025.06.012},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {72-82},
  shortjournal = {ISA Trans.},
  title        = {Finite-time event-triggered sliding mode control for fuzzy singular systems under cyber-attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-based dynamic event-triggered secure control of active suspension systems against deception attacks. <em>ISAT</em>, <em>165</em>, 64-71. (<a href='https://doi.org/10.1016/j.isatra.2025.06.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study deals with the issue of a memory-based dynamic event-triggered control strategy for active quarter-vehicle suspension systems (QVSSs). The main objective is to design an effective event-triggered mechanism (ETM) that ensures suspension performance while reducing network resource usage, even under deception attacks. To this end, an innovative memory-based dynamic ETM is proposed to coordinate sensor data transmission efficiently in the presence of such attacks. The proposed transmission scheme integrates historical release information, which helps suppress false triggering by utilizing averaged data. Additionally, the proposed ETM dynamically updates triggering conditions over time, facilitating dynamic scheduling of network data transmission. Sufficient conditions are derived to guarantee satisfactory performance of the QVSS under the proposed control strategy. A numerical example is provided to validate the effectiveness of the approach.},
  archive      = {J_ISAT},
  author       = {Wangrui Cheng and Tingting Yin and Zhou Gu},
  doi          = {10.1016/j.isatra.2025.06.007},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {64-71},
  shortjournal = {ISA Trans.},
  title        = {Memory-based dynamic event-triggered secure control of active suspension systems against deception attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-varying formation control for heterogeneous multi-agent systems in the presence of actuator faults and deception attacks. <em>ISAT</em>, <em>165</em>, 54-63. (<a href='https://doi.org/10.1016/j.isatra.2025.06.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the control of time-varying formations in a class of heterogeneous multi-agent systems. The key innovation lies in the simultaneous consideration of hybrid actuator faults and deception attacks. To achieve the control objective, a novel distributed double-layer control scheme, comprising a network layer and a physical layer, is proposed. In the network layer, a distributed observer with secure output feedback control is developed to mitigate severe deception attacks, ensuring that the mean square observer error remains within an acceptable range. In the physical layer, fault compensators are designed to address both additive and multiplicative faults. As a result, the followers achieve time-varying formation control, and closed-loop stability analysis is conducted using the Lyapunov method. Finally, to verify the validity of the theoretical findings, numerical simulations are subsequently conducted.},
  archive      = {J_ISAT},
  author       = {Shicheng Cao and Yanhui Yin and Wenyu Li and Zhongxin Liu and Zengqiang Chen},
  doi          = {10.1016/j.isatra.2025.06.004},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {54-63},
  shortjournal = {ISA Trans.},
  title        = {Time-varying formation control for heterogeneous multi-agent systems in the presence of actuator faults and deception attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered consensus of multi-agent systems with uncertain control gain via distributed fuzzy logic observer. <em>ISAT</em>, <em>165</em>, 40-53. (<a href='https://doi.org/10.1016/j.isatra.2025.06.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An event-triggered adaptive backstepping control methodology is proposed to achieve leader-following consensus of uncertain nonlinear high-order multi-agent systems with unknown control gains. In light of the partial observability limitation, adaptive distributed observers are employed to estimate the unobservable states of the leader, whereas local state observers are utilized to reconstruct the states of the followers. By integrating fuzzy logic systems, the unknown nonlinear dynamics are modeled, guaranteeing reliable state prediction in complex and partially observable scenarios. Moreover, the novel relative threshold event-triggered scheme is designed to reduce the frequency of data interactions while ensuring that the tracking error approaches near-zero. Eventually, the effectiveness and superiority of the devised controller are clearly demonstrated through comprehensive simulation results.},
  archive      = {J_ISAT},
  author       = {Konghao Xie and Xiujuan Zhao and Shiming Chen and Zheng Zhang and Yuanshi Zheng},
  doi          = {10.1016/j.isatra.2025.06.020},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {40-53},
  shortjournal = {ISA Trans.},
  title        = {Event-triggered consensus of multi-agent systems with uncertain control gain via distributed fuzzy logic observer},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consensus seeking in large-scale multi-agent systems with homogeneous connections by incorporating two-hop neighbor states. <em>ISAT</em>, <em>165</em>, 27-39. (<a href='https://doi.org/10.1016/j.isatra.2025.06.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of multi-agent consensus raises the importance of network topology. As the number of agents increases, multi-agent systems (MAS) in a large-scale and high-density topology demand higher resources, which consequently degrades efficiency of consensus. Existing approaches that consider only direct point-to-point neighbors may overlook potential topological information, further hindering consensus performance. To achieve fast consensus in large-scale and high-density topologies, a framework named Homogeneous Connections Based on Agents State Fusions MAS (HCASFMAS) is proposed. The framework extracts broader topology information of consensus degree by fusing states of two-hop neighbors. Leveraging homogeneous idea, agents establish homogeneous connections with neighbors that exhibit a higher consensus degree, ultimately accelerating the consensus process while preserving connectivity. First, a neighbor selection strategy based on consensus degree of agent state fusion is introduced to construct candidate neighbors, aiming to reduce redundant connections. Second, an adaptive consensus algorithm is formulated to flexibly adapt to the distribution of neighbors. Finally, a candidate constraints set is established to accelerate consensus by expanding the scope of constraints while preserving connectivity. In this study, connectivity and convergence of the system are theoretically analyzed from a geometric perspective. Simulation experiments are conducted to compare the proposed method with existing approaches under different densities and topologies. Simulation results demonstrate the superiority of this method in achieving fast convergence, particularly in large-scale and high-density scenarios.},
  archive      = {J_ISAT},
  author       = {Guangqiang Xie and Chaohao Shen and Yang Li and Yanda Feng and Fengyang Qiu},
  doi          = {10.1016/j.isatra.2025.06.002},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {27-39},
  shortjournal = {ISA Trans.},
  title        = {Consensus seeking in large-scale multi-agent systems with homogeneous connections by incorporating two-hop neighbor states},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic formation tracking and fault-tolerant control of multi-agent systems based on distance and topology reconstruction methods. <em>ISAT</em>, <em>165</em>, 15-26. (<a href='https://doi.org/10.1016/j.isatra.2025.06.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a distributed approach for dynamic formation tracking and formation fault-tolerant control within the port-Hamiltonian energy framework for multi-agent system (MAS) affected by Coulomb friction. The coupling relationships between agents are equivalently modeled as virtual springs, which simulate the interaction forces between agents to reflect the relative positions and motion states of the agents. A distance-based distributed control scheme is designed, to ensure that the formation composed of multiple agents can continuously adjust the direction and size of the formation while achieving target tracking. Additionally, considering the possibility of communication failure due to agent motion faults, a fault-tolerant algorithm based on topological reconstruction is proposed to reconstruct the formation topology after faults. The feasibility of this control method is verified through numerical simulations.},
  archive      = {J_ISAT},
  author       = {Lu Liu and Yu Cui and Yonghua Wang and Jinglong Wen and Shuaishuai Kong and Yuhang Ma and Dan Liu and Peng Shi and Chenyang Xue},
  doi          = {10.1016/j.isatra.2025.06.006},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {15-26},
  shortjournal = {ISA Trans.},
  title        = {Dynamic formation tracking and fault-tolerant control of multi-agent systems based on distance and topology reconstruction methods},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast actuator fault-tolerant control for a class of nonlinear sampled-data systems via deterministic learning. <em>ISAT</em>, <em>165</em>, 1-14. (<a href='https://doi.org/10.1016/j.isatra.2025.05.049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the fast fault-tolerant control (FTC) problem based on deterministic learning approach (DLA) for a class of nonlinear sampled-data systems with actuator faults, which consist of two stages: incipient faults with small magnitudes and faults with larger magnitudes. First, a learning controller and a learning identifier are constructed. Based on DLA and the exponential stability of a class of linear time-varying (LTV) discrete-time systems, the control knowledge and the diagnosis knowledge of the actuator faults are obtained. Second, a set of controllers and a set of diagnosis estimators are constructed based on the learnt control and diagnosis knowledge. When an incipient actuator fault occurs, fast fault detection and isolation (FDI) can be achieved using the diagnosis estimators. Then, the pattern-based FTC scheme is implemented to improve the control performance. When the small fault grows to a larger one, the rapid FDI and FTC are implemented again, providing fast responses to the occurred larger fault. The advantages of the proposed method are that: (i) a simple adaptive learning controller with the filtering technique is designed, in which the exponential convergence of the tracking error and parameter estimation errors can be achieved simultaneously; (ii) the sensitivity to small actuator faults is enhanced, and the fast FTC to larger actuator faults is achieved by utilizing the learnt knowledge. Simulation results are also included to illustrate the effectiveness of these schemes.},
  archive      = {J_ISAT},
  author       = {Yu Zeng and Tianrui Chen and Fukai Zhang and Cong Wang},
  doi          = {10.1016/j.isatra.2025.05.049},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {1-14},
  shortjournal = {ISA Trans.},
  title        = {Fast actuator fault-tolerant control for a class of nonlinear sampled-data systems via deterministic learning},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="isci">ISCI - 14</h2>
<ul>
<li><details>
<summary>
(2026). Behavioral pattern clustering for thematic user segmentation in web interaction environments. <em>ISCI</em>, <em>724</em>, 122745. (<a href='https://doi.org/10.1016/j.ins.2025.122745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering users based on their interest is a critical component in personalized content delivery. This paper proposes a novel multi modal framework that integrates semantic video classification, contextualized caption generation, and user behavior patterns. The system combines visual and audio features which are computed using convolutional and transformer based encoders to robustly capture the complex contents of video description. User browsing profile is modelled using probabilistic distributions to reflect realistic browsing behavior across six interest categories. These profiles are then clustered using KMeans, DBSCAN, and Agglomerative clustering to identify the various user groups. The quality of clustering is evaluated using Silhouttee Score, Davies-Bouldin Index, and Calinski-Harabasz Index, with PCA and t-SNE applied for visual validation of coherence of clusters. The simulation framework addresses the issues concerning data privacy and the scarcity of real world data by producing controllable and realistic user behavior traces. Experimental results demonstrate that KMeans provides the optimal trade-off between quality of clustering solution and computational cost. These integrated efforts bring personalized content delivery to a new perspective, i.e., fine-grained user segmentation and precise video understanding, respectively. The future work will focus on adopting real-time adaptive learning and integrating with more data types, and will further deploy on large-scale multimedia applications.},
  archive      = {J_ISCI},
  author       = {Suma Srinath and Nagaraju Baydeti},
  doi          = {10.1016/j.ins.2025.122745},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122745},
  shortjournal = {Inf. Sci.},
  title        = {Behavioral pattern clustering for thematic user segmentation in web interaction environments},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automating data preparation pipeline efficiently via monte carlo tree search. <em>ISCI</em>, <em>724</em>, 122730. (<a href='https://doi.org/10.1016/j.ins.2025.122730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial step in machine learning, data preparation is the most time and energy consuming task for data scientists, entailing a number of data processing techniques to improve the performance of output results for ML models. However, end-to-end AutoML research focuses on automated machine learning pipelines consisting of algorithm selection and hyper parameter tuning, falling short in comprehensive automation of data preparation. In this paper, we propose Auto-DP, an MCTS-based framework for efficient and automated data preparation. To guide the search more effectively, a neural network is designed to estimate the subsequent maximum performance gain of each tree node. In order to reduce search space and improve system efficiency, two optimization strategies, meta-learning and accelerated training strategy, are used to determine the type and order of tasks in the data preparation process in advance, and speed up the pipeline creation process. We compare Auto-DP with the popular AutoML systems on 60 real datasets from OpenML repository. Auto-DP improves the Accuracy by up to 18.11 % on the classification task and reduces the Mse by up to 25.75 % on the regression task. Furthermore, it achieves a performance in 10 s that is better than what four popular AutoML systems achieve in 1 h.},
  archive      = {J_ISCI},
  author       = {Yiyi Zhang and Ning Wang and Qixiong Zeng and Liangwei Li},
  doi          = {10.1016/j.ins.2025.122730},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122730},
  shortjournal = {Inf. Sci.},
  title        = {Automating data preparation pipeline efficiently via monte carlo tree search},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven semantic similarity-based job matching framework for recruitment systems. <em>ISCI</em>, <em>724</em>, 122728. (<a href='https://doi.org/10.1016/j.ins.2025.122728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a real-time online recruitment application that integrates semantic similarity and artificial intelligence (AI) to improve job-candidate matching. It addresses the growing volume of job applications and the limitations of traditional keyword-based systems, which often fail to capture contextual meaning and complex semantic relationships in job-candidate alignment. The proposed system leverages natural language processing (NLP) techniques, specifically TF-IDF vectorization, cosine similarity scoring, and domain-specific keyword weighting, to interpret conceptual relevance between resumes and job descriptions, enabling more accurate and inclusive recruitment outcomes. This research developed the system in Python and evaluated it using simulated and real-world recruitment datasets. Experimental results show that the semantic model consistently outperforms keyword-based matching across diverse job domains. For instance, in simulated tests, similarity scores reached 0.74 in the Software Engineer domain, compared to just 0.35 using keyword-based methods. Real-world evaluations further confirmed the model’s effectiveness, with semantic scores of 0.83, 0.76, and 0.74 for the Hadoop, Data Science, and PMP domains, respectively. In contrast, the corresponding keyword-based scores remained below 0.17. Additionally, the system performs well in aligning generalist and specialist profiles, achieving a score of 0.88 for Data analysis roles. These findings validate the system’s robustness, scalability, and ability to interpret varied terminology across job sectors. The research presents a scalable, AI-driven framework that supports context-aware, fair, and accurate job matching, significantly advancing intelligent recruitment technology.},
  archive      = {J_ISCI},
  author       = {Mohammed-Hassan Ajjam and Hamed S. Al-Raweshidy},
  doi          = {10.1016/j.ins.2025.122728},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122728},
  shortjournal = {Inf. Sci.},
  title        = {AI-driven semantic similarity-based job matching framework for recruitment systems},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex network evolution with node strategies driven by information entropy. <em>ISCI</em>, <em>724</em>, 122713. (<a href='https://doi.org/10.1016/j.ins.2025.122713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of evolutionary strategies in dynamic networks remains a fundamental challenge in network science, hindered by computational complexity and the absence of theoretically grounded frameworks to quantify node-level decisions. Current approaches often fail to integrate strategic node behaviour with information-theoretic principles, limiting insights into network optimisation. To bridge this gap, we propose an information-entropy-driven framework for secure network evolution. First, we establish a security evolution model comprising cross-community node identification and a node strategy evolution algorithm based on strategic utility. Second, we rigorously analyse the stability and equilibrium conditions of local network dynamics driven by minimising two-dimensional structural entropy. Finally, we conduct comparative studies examining network evolution under different node strategies and node types. Theoretical analysis and extensive simulations demonstrate that information-driven networks evolve toward fully-connected structures dominated by edge-creation strategies. Critically, this not only confirms that cross-community nodes capture global dynamics but also verifies convergence to a Secure Evolution Principle, the elimination of centralised hubs minimises structural vulnerability while maximizing participation in data sharing, ensuring node safety throughout the evolution process. This entropy-game framework reduces runtime by 80 %-90 % compared with the strategy update of the Imitate Best strategy and the Fermi Rule strategy while maintaining the security of the network structure, providing a theoretically grounded foundation for designing secure, adaptive networks.},
  archive      = {J_ISCI},
  author       = {Ze Yang and Youliang Tian and Jinbo Xiong and Mengqian Li and Kun Niu and Die Zhou and Jianfeng Ma},
  doi          = {10.1016/j.ins.2025.122713},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122713},
  shortjournal = {Inf. Sci.},
  title        = {Complex network evolution with node strategies driven by information entropy},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Agricultural object detection in complex environments via co-attention and self-knowledge distillation. <em>ISCI</em>, <em>724</em>, 122711. (<a href='https://doi.org/10.1016/j.ins.2025.122711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of fruit maturity plays a critical role in the automation of agricultural production and harvesting. However, current maturity detection models still face challenges in complex planting environments including variations in fruit size, occlusion issues, diverse lighting conditions, and inadequate handling of multi-scale information. To address these challenges, an object detection model FMD-DETR (Fruit Maturity Detection-DEtection TRansformer) is proposed for robust fruit maturity detection under varying lighting and occlusion conditions. The model integrates a multi-scale feature fusion re-weighting module to improve the detection ability for fruits of different scales. A co-attention decoder is designed as a key component of the model to refine the interaction between object queries and feature representations, thereby improving detection accuracy. In addition, self-distillation and hierarchical knowledge distillation strategies are integrated into the decoder to enhance the model’s object localization ability, further improving detection accuracy. Experiments on tomato and strawberry datasets show that the model achieves an accuracy of 75.4 % on the tomato dataset, 52.7 % on the real-world tomato dataset, 41.5 % on the strawberry dataset, and 87.1 % on the FruitRipeness dataset. Experimental results demonstrate that the model surpasses existing methods in detection accuracy and robustness in complex environments, providing an effective solution for automated production and harvesting.},
  archive      = {J_ISCI},
  author       = {Yuexing Han and Zhiyi Huang and Yan Sun and Bing Wang and Qiaochuan Chen},
  doi          = {10.1016/j.ins.2025.122711},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122711},
  shortjournal = {Inf. Sci.},
  title        = {Agricultural object detection in complex environments via co-attention and self-knowledge distillation},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy platoon control for CAVs with input constraints. <em>ISCI</em>, <em>724</em>, 122709. (<a href='https://doi.org/10.1016/j.ins.2025.122709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs an adaptive fuzzy controller for connected autonomous vehicles (CAVs) subject to input saturation and model uncertainty. In particular, the continuous-time vehicle model is first discretized using a sampling-based approach combined with a first-order forward-difference method to facilitate digital implementation. Then, a fuzzy logic system is adopted to approximate the unknown nonlinear term in the discrete model, and the adaptive law is adjusted using the gradient descent method. Meanwhile, a hyperbolic tangent function is employed to mitigate input saturation. Subsequently, Lyapunov stability analysis is conducted to investigate both the stability of the vehicle state and the string stability of the vehicle platoon. Finally, the effectiveness of the proposed control method is validated through simulation and co-simulation experiments.},
  archive      = {J_ISCI},
  author       = {Xuelin Yin and Zilin Gao and Min You and Changyuan Guo},
  doi          = {10.1016/j.ins.2025.122709},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122709},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy platoon control for CAVs with input constraints},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Resilient distributed localization for mobile sensor networks under malicious attacks. <em>ISCI</em>, <em>724</em>, 122708. (<a href='https://doi.org/10.1016/j.ins.2025.122708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the cooperative localization problems for mobile sensor networks under malicious attacks, which manipulate relative measurements to mislead the localization process. A distributed attack-resilient cooperative localization algorithm is proposed, addressing the inter-node state dependencies in relative measurements by employing the covariance intersection method. Specifically, by designing an innovation-based saturation mechanism that assigns smaller coefficients for unreasonably large innovations, the adverse impact of the attacks is confined. Within this framework, the consistency of all sensors’ estimates is maintained, and the error covariance matrices are ensured to be bounded. Compared with the existing extended Kalman filter-based positioning approaches, the employed cubature integral rules avoid evaluating Jacobian matrix and improve the performance of nonlinear state estimation. Finally, two cases are conducted to validate the presented strategy.},
  archive      = {J_ISCI},
  author       = {Yuan-Wei Lv and Guang-Hong Yang and Georgi Marko Dimirovski},
  doi          = {10.1016/j.ins.2025.122708},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122708},
  shortjournal = {Inf. Sci.},
  title        = {Resilient distributed localization for mobile sensor networks under malicious attacks},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Information suppression in large language models: Auditing, quantifying, and characterizing censorship in DeepSeek. <em>ISCI</em>, <em>724</em>, 122702. (<a href='https://doi.org/10.1016/j.ins.2025.122702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines information suppression mechanisms in DeepSeek, an open-source large language model (LLM) developed in China. We propose an auditing framework to evaluate the censorship in the model through analyzing the response alignment with the corresponding chain of thought (CoT). By comparing model responses to 646 politically sensitive topics with those to non-politically sensitive topics, our audit unveils evidence of semantic-level information suppression in DeepSeek: sensitive content often appears within the model’s internal reasoning but is omitted or rephrased in the final output. Specifically, DeepSeek suppresses references to transparency, government accountability, and civic mobilization, while occasionally amplifying language aligned with state propaganda. This study underscores the need for systematic auditing of alignment, content moderation, information suppression, and censorship practices implemented into widely-adopted AI models, to ensure transparency, accountability, and equitable access to unbiased information obtained by means of these systems.},
  archive      = {J_ISCI},
  author       = {Peiran Qiu and Siyi Zhou and Emilio Ferrara},
  doi          = {10.1016/j.ins.2025.122702},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122702},
  shortjournal = {Inf. Sci.},
  title        = {Information suppression in large language models: Auditing, quantifying, and characterizing censorship in DeepSeek},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language-based opacity in modular discrete event systems: Compositional secret-based verification using labeled petri nets. <em>ISCI</em>, <em>724</em>, 122701. (<a href='https://doi.org/10.1016/j.ins.2025.122701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on verifying language-based opacity within modular discrete-event systems. We consider a distributed system that is modeled as a composition of multiple interacting modules, each modeled by a labeled Petri net. Ensuring confidentiality in such systems is critical for cyber-physical systems and industrial networks, where unauthorized inference of sensitive data can lead to security breaches. We introduce a new definition of language-based opacity for modular systems and propose three secret-based verification methods that avoid the construction of the monolithic system through parallel composition. Our approach includes three methods: (1) global secret verification via observer synchronization; (2) local, module-level secret verification; and (3) an iterative composition optimization that avoids building the entire modular system, yielding significant computational savings. Experimental results on a benchmark smart manufacturing system demonstrate the practical efficiency of our approach, showing orders-of-magnitude improvement in verification time and memory usage over traditional monolithic approaches.},
  archive      = {J_ISCI},
  author       = {Salwa Habbachi and Imen Ben Hafaiedh and Zhiwu Li},
  doi          = {10.1016/j.ins.2025.122701},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122701},
  shortjournal = {Inf. Sci.},
  title        = {Language-based opacity in modular discrete event systems: Compositional secret-based verification using labeled petri nets},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DWGNet: A dual-path wavelet guidance framework for salient object detection. <em>ISCI</em>, <em>724</em>, 122699. (<a href='https://doi.org/10.1016/j.ins.2025.122699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) is a crucial research direction in computer vision and has garnered significant attention. Despite notable progress, two key limitations remain: (1) Existing methods rely primarily on single-frequency domain features, limiting their ability to extract fine details in complex scenes and achieve accurate saliency recognition and segmentation; (2) Traditional frameworks face limitations in parameters, real-time performance, and storage overhead. To address these limitations, we propose a dual-path wavelet guidance framework (DWGNet) for SOD. The framework has two innovative designs: the wavelet-based encoder–decoder and a multi-feature prediction decoder (MFPD). Specifically, we first construct a dual-path encoder to extract multilevel features, comprising a spatial feature extractor and wavelet feature extractor to capture spatial and frequency domain representations, respectively. Second, the local wavelet fusion decoder is designed to integrate wavelet features across scales, generating decoding features rich in multi-wavelet information. Then, the MFPD processes multi-path outputs in batches, leveraging high-level semantic information to guide the fusion and refinement of low-level features. Finally, the weighted loss function is introduced for fully supervised saliency inference and prediction. Quantitative and qualitative experimental results on nine databases show that our method excels in detecting simple targets, multiple targets, and small targets in low-contrast scenes. It achieves 0.043, 0.043, 0.034, 0.063, 0.055, 0.027, 0.027, 0.149, 0.293 on MAE metrics while retaining only 3.94 M parameters and 2.01 G FLOPs.},
  archive      = {J_ISCI},
  author       = {Baoyu Wang and Mao Yang and Pingping Cao and Aihong Shen},
  doi          = {10.1016/j.ins.2025.122699},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122699},
  shortjournal = {Inf. Sci.},
  title        = {DWGNet: A dual-path wavelet guidance framework for salient object detection},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of folding-based zero-knowledge proofs. <em>ISCI</em>, <em>724</em>, 122698. (<a href='https://doi.org/10.1016/j.ins.2025.122698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey uniquely approaches zero-knowledge proofs (ZKPs) through the lens of folding schemes, offering a fresh framework to analyze efficiency, scalability, and post-quantum resilience. By focusing on folding, we unify diverse protocols, clarify trade-offs, and identify practical engineering constraints, providing both researchers and practitioners with actionable insights. Folding schemes have emerged as the simplest and fastest approach to incrementally verifiable computation (IVC), enabling recursive zero-knowledge arguments with constant recursion overhead. We present a unifying model of folding-based ZKPs across R1CS, Plonkish/CCS, and AIR; synthesize the state of the art from Nova, SuperNova, HyperNova, and cycle-of-curves instantiations to recent post-quantum lattice-based foldings; provide a rigorous comparison of prover time, verifier work, proof size, setup assumptions, and recursion overhead; and map real deployments—including Lurk/Nova, Sonobe-based light clients, and VIMz-style media proofs—to practical constraints. Finally, we highlight open problems such as hybrid elliptic-curve–lattice designs and engineering targets for memory-bounded provers, showing how this folding-centric view advances both theoretical understanding and real-world deployment of ZKPs.},
  archive      = {J_ISCI},
  author       = {Cyprian Omukhwaya Sakwa and Andrew Omala Anyembe and Fagen Li},
  doi          = {10.1016/j.ins.2025.122698},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122698},
  shortjournal = {Inf. Sci.},
  title        = {A survey of folding-based zero-knowledge proofs},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FGNet: Robust lane detection for autonomous driving via frequency-guided feature enhancement. <em>ISCI</em>, <em>724</em>, 122694. (<a href='https://doi.org/10.1016/j.ins.2025.122694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane detection is a critical component in autonomous driving perception systems. Complex road scenarios featuring varying lane appearances, challenging lighting conditions, and vehicle occlusions pose significant challenges for accurate lane detection. To address these problems, we propose FGNet, a robust lane detection framework that enhances feature representation through frequency-domain analysis and adaptive global-local fusion. We first introduce a Wavelet-enhanced Feature Pyramid Network (WLFPN) that leverages discrete wavelet decomposition and directional convolutions to capture high-frequency geometric features critical for lane structure modeling. Subsequently, a Global-Aware Feature Refinement (GAFR) module is designed to overcome insufficient global context integration in existing anchor-based methods, enabling adaptive feature enhancement through spatially-aware attention and selective fusion mechanisms. Finally, a Dynamic Loss Harmonizer (DLH) employs momentum-based dynamic weight adjustment to optimize multi-loss learning, improving training stability and convergence. Extensive experiments demonstrate that FGNet achieves state-of-the-art performance with F1 scores of 80.64 % and 97.89 % on the challenging CULane and TuSimple datasets, respectively, outperforming existing methods.},
  archive      = {J_ISCI},
  author       = {Zilong Zhou and Xuyang Lu and Ping Liu and Haibo Huang},
  doi          = {10.1016/j.ins.2025.122694},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122694},
  shortjournal = {Inf. Sci.},
  title        = {FGNet: Robust lane detection for autonomous driving via frequency-guided feature enhancement},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-driven aviation safety risk assessment: An integrated framework combining FMEA and quantum probability theory. <em>ISCI</em>, <em>724</em>, 122689. (<a href='https://doi.org/10.1016/j.ins.2025.122689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a complex system with multi-factor coupling, the internal risk mechanism of the aviation system is difficult to be fully analyze using traditional subjective assessment methods. Recent aviation accidents have highlighted the limitations of traditional risk assessment methods, which often assume the independence of failure modes and the scenario-independence of risk factors. To address these limitations, this study proposes an innovative data-driven aviation safety risk assessment framework that integrates Natural Language Processing (NLP), Failure Mode and Effects Analysis (FMEA), and Quantum Probability Theory (QPT). Grounded in aviation safety data from the National Transportation Safety Board (NTSB), the framework leverages NLP to extract potential failure modes and employs QPT to quantify the interference effects between them. The entropy weight method is used to calculate the initial weights of risk factors when failure modes are independent, whereas quantum probabilities based on QPT are applied to update these weights when interactions occur among failure modes. Furthermore, risk prioritization associated with failure modes is conducted using the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS). This framework breaks through the traditional isolated risk assessment framework, advancing aviation safety management from post-incident response to preemptive coupling intervention.},
  archive      = {J_ISCI},
  author       = {Mei Cai and Shaoyue Sun},
  doi          = {10.1016/j.ins.2025.122689},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122689},
  shortjournal = {Inf. Sci.},
  title        = {Data-driven aviation safety risk assessment: An integrated framework combining FMEA and quantum probability theory},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing the number of floorplanning layers for stacked integrated circuits based on spiking variational graph auto-encoders. <em>ISCI</em>, <em>724</em>, 122681. (<a href='https://doi.org/10.1016/j.ins.2025.122681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the complexity of chip design continues to increase, the stacking of multiple device layers in a three-dimensional (3D) architecture has emerged as a promising approach to improve performance, power efficiency and area (PPA). The optimization of macro-module arrangement and inter-tier connections in 3D stacked chip layout is significantly influenced by the selection of the number of layers, which affects both the feasibility of the layout optimization and the final performance of the chips. In this paper, we creatively propose the Spiking Variational Graph Auto-Encoders (S-VGAE), which aim to be applied in several varieties of stacked clustering to partition the data set comprising 22 integrated circuits. By converting graph topology into spatiotemporal pulse patterns, the Spiking Graph Convolution fundamentally enhances the representational capacity of subsequent Graph Auto-Encoders. In the layout stage for all dies, we propose the Memristive-Inspired Bottom-up Left Justified Learning (MBLJL) Strategy to determine the better performance of bi-level or tri-level stacked floorplanning layout.},
  archive      = {J_ISCI},
  author       = {Kaikai Qiao and Ai Chen and Lidan Wang and Shukai Duan},
  doi          = {10.1016/j.ins.2025.122681},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122681},
  shortjournal = {Inf. Sci.},
  title        = {Optimizing the number of floorplanning layers for stacked integrated circuits based on spiking variational graph auto-encoders},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jaim">JAIM - 3</h2>
<ul>
<li><details>
<summary>
(2025). The hitchin fibration for symmetric pairs. <em>JAIM</em>, <em>482</em>, 110560. (<a href='https://doi.org/10.1016/j.aim.2025.110560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and describe the “regular quotient” for the Hitchin fibration for symmetric spaces and explain some basic consequences for Higgs bundles. We include an invariant theoretic approach to spectral covers in this setting for the particular space GL 2 n / GL n × GL n . We also include a study of the regular centralizer group scheme for quasisplit pairs, including a Galois description of a closely related group scheme. We collect some basic consequences for Hitchin systems associated to such pairs.},
  archive      = {J_JAIM},
  author       = {Thomas Hameister and Benedict Morrissey},
  doi          = {10.1016/j.aim.2025.110560},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110560},
  shortjournal = {Adv. Math.},
  title        = {The hitchin fibration for symmetric pairs},
  volume       = {482},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence and collapsing of CAT(0)-lattices. <em>JAIM</em>, <em>482</em>, 110555. (<a href='https://doi.org/10.1016/j.aim.2025.110555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the theory of convergence for CAT(0)-lattices (that is groups Γ acting geometrically on proper, geodesically complete CAT(0)-spaces) and their quotients (CAT(0)-orbispaces). We describe some splitting and collapsing phenomena, explaining precisely how the actions can degenerate to a possibly non-discrete limit action, and prove a compactness theorem for the class of compact CAT(0)-homology orbifolds. Finally, as an application of this theory, we prove an isolation result for flat orbispaces and an entropy-pinching theorem.},
  archive      = {J_JAIM},
  author       = {Nicola Cavallucci and Andrea Sambusetti},
  doi          = {10.1016/j.aim.2025.110555},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110555},
  shortjournal = {Adv. Math.},
  title        = {Convergence and collapsing of CAT(0)-lattices},
  volume       = {482},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A short proof of a conjecture of matsushita. <em>JAIM</em>, <em>482</em>, 110554. (<a href='https://doi.org/10.1016/j.aim.2025.110554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We build on the arguments of van Geemen and Voisin [24] to prove a conjecture of Matsushita that a Lagrangian fibration of an irreducible hyperkähler manifold is either isotrivial or of maximal variation. We also complete a partial result of Voisin [26] regarding the density of torsion points of sections of Lagrangian fibrations.},
  archive      = {J_JAIM},
  author       = {Benjamin Bakker},
  doi          = {10.1016/j.aim.2025.110554},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110554},
  shortjournal = {Adv. Math.},
  title        = {A short proof of a conjecture of matsushita},
  volume       = {482},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jat">JAT - 2</h2>
<ul>
<li><details>
<summary>
(2026). Asymptotics of the humbert functions Ψ1 and Ψ2. <em>JAT</em>, <em>314</em>, 106233. (<a href='https://doi.org/10.1016/j.jat.2025.106233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A compilation of new results on the asymptotic behaviour of the Humbert functions Ψ 1 and Ψ 2 , and also on the Appell function F 2 , is presented. As a by-product, we confirm a conjectured limit which appeared recently in the study of the 1 D Glauber–Ising model. We also propose two elementary asymptotic methods and confirm through some illustrative examples that both methods have great potential and can be applied to a large class of problems of asymptotic analysis. Finally, some directions of future research are pointed out in order to suggest ideas for further study.},
  archive      = {J_JAT},
  author       = {Peng-Cheng Hang and Malte Henkel and Min-Jie Luo},
  doi          = {10.1016/j.jat.2025.106233},
  journal      = {Journal of Approximation Theory},
  month        = {3},
  pages        = {106233},
  shortjournal = {J. Approx. Theory},
  title        = {Asymptotics of the humbert functions Ψ1 and Ψ2},
  volume       = {314},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nevai’s condition for measures with unbounded supports. <em>JAT</em>, <em>314</em>, 106232. (<a href='https://doi.org/10.1016/j.jat.2025.106232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study Nevai’s condition from the theory of orthogonal polynomials on the real line. We prove that a large class of measures with unbounded Jacobi parameters satisfies Nevai’s condition locally uniformly on the support of the measure away from a finite explicit set. This allows us to give applications to relative uniform and weak asymptotics of Christoffel–Darboux kernels on the diagonal and to limit theorems for unconventionally normalized global linear statistics of orthogonal polynomial ensembles.},
  archive      = {J_JAT},
  author       = {Grzegorz Świderski},
  doi          = {10.1016/j.jat.2025.106232},
  journal      = {Journal of Approximation Theory},
  month        = {3},
  pages        = {106232},
  shortjournal = {J. Approx. Theory},
  title        = {Nevai’s condition for measures with unbounded supports},
  volume       = {314},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jde">JDE - 15</h2>
<ul>
<li><details>
<summary>
(2026). Existence and nonlinear stability of stationary solutions to the outflow problem of the one-dimensional full compressible navier-stokes-allen-cahn system. <em>JDE</em>, <em>453</em>, 113803. (<a href='https://doi.org/10.1016/j.jde.2025.113803'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the large-time behavior of solutions toward a stationary solution for the outflow problem of the full compressible Navier-Stokes-Allen-Cahn system in the half-space R + . The model can be used to describe the motion of a mixture of two viscous compressible fluids. First, we give some sufficient conditions for the existence of stationary solution via the manifold theory and the center manifold theory. Second, by using the elementary L 2 -energy method, it is shown that the stationary solution is time-asymptotically stable provided that the initial perturbation and the strength of the stationary solution are sufficiently small. Finally, the convergence rates of solutions towards the stationary one are also established by employing a time and space weighted energy method. Our analysis is based on some new techniques which take into account the effect of the phase field variable.},
  archive      = {J_JDE},
  author       = {Zhengzheng Chen and Dan Lei and Haiyan Yin},
  doi          = {10.1016/j.jde.2025.113803},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113803},
  shortjournal = {J. Diff. Equ.},
  title        = {Existence and nonlinear stability of stationary solutions to the outflow problem of the one-dimensional full compressible navier-stokes-allen-cahn system},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conditions for uniform regularity of compressible MHD system in small alfvén and mach numbers with tangential magnetic fields to the physical boundary. <em>JDE</em>, <em>453</em>, 113801. (<a href='https://doi.org/10.1016/j.jde.2025.113801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the uniform regularity of solutions to the compressible magnetohydrodynamics (MHD) system in the half-space R + 3 in small Alfvén and Mach Numbers. The study focuses on the case where the magnetic field is tangential to the physical boundary, satisfying the perfect conducting boundary condition, while the velocity field adheres to a Navier-slip boundary condition. Under the condition that bounds the normal derivatives of the velocity and magnetic field uniformly in ϵ (the small Alfvén and Mach Numbers), we establish uniform estimates for the solutions in high-order conormal Sobolev norms. The results distinguish the previous works primarily addressing cases where the magnetic field is transversal to the boundary.},
  archive      = {J_JDE},
  author       = {Yingzhi Du and Tao Luo and Xin Xu},
  doi          = {10.1016/j.jde.2025.113801},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113801},
  shortjournal = {J. Diff. Equ.},
  title        = {Conditions for uniform regularity of compressible MHD system in small alfvén and mach numbers with tangential magnetic fields to the physical boundary},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Threshold dynamics for the 3d radial NLS with combined nonlinearity. <em>JDE</em>, <em>453</em>, 113800. (<a href='https://doi.org/10.1016/j.jde.2025.113800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the nonlinear Schrödinger equation with focusing quintic and defocusing cubic nonlinearity in three space dimensions: ( i ∂ t + Δ ) u = | u | 2 u − | u | 4 u . In [18] , the authors classified the dynamics of solutions under the energy constraint E ( u ) < E c ( W ) , where W is the quintic NLS ground state and E c is the quintic NLS energy. In this work we classify the dynamics of H 1 solutions at the threshold E ( u ) = E c ( W ) .},
  archive      = {J_JDE},
  author       = {Alex H. Ardila and Jason Murphy and Jiqiang Zheng},
  doi          = {10.1016/j.jde.2025.113800},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113800},
  shortjournal = {J. Diff. Equ.},
  title        = {Threshold dynamics for the 3d radial NLS with combined nonlinearity},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Internal control of the transition kernel for stochastic lattice dynamics. <em>JDE</em>, <em>453</em>, 113798. (<a href='https://doi.org/10.1016/j.jde.2025.113798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In [4] , we initiated the first study of control problems for kinetic equations arising from harmonic chains. Specifically, we developed impulsive and feedback control mechanisms for harmonic chains coupled with a point thermostat, effectively enabling control over the boundary conditions of the corresponding kinetic equations. However, the more intricate and fundamental challenge of internal control - namely, the design of control strategies that influence the collision operators within the kinetic framework - remained open. In the present work, we address the internal control problem for stochastic lattice dynamics, with the objective of controlling the transition kernel of the limiting kinetic equation. A central innovation of our approach is the development of a novel geometric-combinatorial framework, which enables the systematic construction of control pathways within the microscopic dynamics. This methodology opens a new avenue for the internal control of kinetic equations.},
  archive      = {J_JDE},
  author       = {Amirali Hannani and Minh-Nhat Phung and Minh-Binh Tran and Emmanuel Trélat},
  doi          = {10.1016/j.jde.2025.113798},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113798},
  shortjournal = {J. Diff. Equ.},
  title        = {Internal control of the transition kernel for stochastic lattice dynamics},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonlinear bound states with prescribed angular momentum in the mass supercritical regime. <em>JDE</em>, <em>453</em>, 113796. (<a href='https://doi.org/10.1016/j.jde.2025.113796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the existence, orbital stability/instability and regularity of bound state solutions to nonlinear Schrödinger equations with super-quadratic confinement in two and three spatial dimensions for the mass supercritical case. Such solutions, which are given by time-dependent rotations of a non-radially symmetric spatial profile, correspond to critical points of the underlying energy function restricted on the double constraints consisting of the mass and the angular momentum. The study exhibits new pictures for rotating Bose-Einstein condensates within the framework of Gross-Pitaevskii theory. It is proved that there exist two non-radial symmetric solutions, one of which is local minimizer and the other is mountain pass type critical point of the underlying energy function restricted on the constraints. Moreover, we derive conditions that guarantee that local minimizers are regular, the set of those is orbitally stable and mountain pass type solutions are strongly unstable. The results extend and complement the recent ones in [17] , where the consideration is undertaken in the mass subcritical case.},
  archive      = {J_JDE},
  author       = {Tianxiang Gou and Xiaoan Shen},
  doi          = {10.1016/j.jde.2025.113796},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113796},
  shortjournal = {J. Diff. Equ.},
  title        = {Nonlinear bound states with prescribed angular momentum in the mass supercritical regime},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Wave breaking criteria for a generalized fornberg-whitham equation. <em>JDE</em>, <em>453</em>, 113795. (<a href='https://doi.org/10.1016/j.jde.2025.113795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The blowup features for a generalized Fornberg-Whitham equation are investigated on the line. Using the L 2 conservation law and the method to construct Lyapunov functions, sufficient conditions ensuring that wave breaking occurs for the equation are provided. Under certain assumptions, our wave breaking results improve the wave breaking criteria in Wei (2023) [25] .},
  archive      = {J_JDE},
  author       = {Changtai Zhou and Shaoyong Lai},
  doi          = {10.1016/j.jde.2025.113795},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113795},
  shortjournal = {J. Diff. Equ.},
  title        = {Wave breaking criteria for a generalized fornberg-whitham equation},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Boundedness of weak solutions to degenerate kolmogorov equations of hypoelliptic type in bounded domains. <em>JDE</em>, <em>453</em>, 113794. (<a href='https://doi.org/10.1016/j.jde.2025.113794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish the boundedness of weak subsolutions for a class of degenerate Kolmogorov equations of the hypoelliptic type, compatible with a homogeneous Lie group structure, within bounded product domains using the De Giorgi iteration. We employ the renormalization formula to handle boundary values and provide energy estimates. An L 1 – L p type embedding estimate derived from the fundamental solution is utilized to incorporate lower-order divergence terms. This work naturally extends the boundedness theory for uniformly parabolic equations, with matching exponents for the coefficients.},
  archive      = {J_JDE},
  author       = {Mingyi Hou},
  doi          = {10.1016/j.jde.2025.113794},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113794},
  shortjournal = {J. Diff. Equ.},
  title        = {Boundedness of weak solutions to degenerate kolmogorov equations of hypoelliptic type in bounded domains},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Convergence towards discontinuous patterns for a degenerate reaction-diffusion system with a non-monotone term. <em>JDE</em>, <em>453</em>, 113793. (<a href='https://doi.org/10.1016/j.jde.2025.113793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish new results on the dynamics of a degenerate reaction-diffusion system with hysteresis. Our model determines the evolution of a biological system characterized by the interaction between a sedentary species and a diffusive species. It can be notably applied in forest ecology and in microbiology. We prove the existence of an infinite family of discontinuous stationary solutions using a generalized Mountain Pass Theorem, and analyze the continuity of this family, through an original method based on the convergence of generalized Clarke gradients. We show that the discontinuity interface of the heterogeneous patterns is very sensitive with respect to a variation of the initial condition. Furthermore, we prove a new theorem of convergence towards discontinuous patterns, which shows that the basin of attraction of each pattern contains a non-trivial set of initial conditions.},
  archive      = {J_JDE},
  author       = {Guillaume Cantin},
  doi          = {10.1016/j.jde.2025.113793},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113793},
  shortjournal = {J. Diff. Equ.},
  title        = {Convergence towards discontinuous patterns for a degenerate reaction-diffusion system with a non-monotone term},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gauge transformation for the kinetic derivative nonlinear schrödinger equation on the torus. <em>JDE</em>, <em>453</em>, 113792. (<a href='https://doi.org/10.1016/j.jde.2025.113792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the kinetic derivative nonlinear Schrödinger equation, which is a one-dimensional nonlinear Schrödinger equation with a cubic derivative nonlinear term containing the Hilbert transformation. In our previous work, we proved small-data global well-posedness of the Cauchy problem on the torus in Sobolev space H s for s > 1 / 2 by combining the Fourier restriction norm method with the parabolic smoothing effect, which is available in the periodic setting. In this article, we improve the regularity range to s > 1 / 4 for the global well-posedness by constructing an effective gauge transformation. Moreover, we remove the smallness assumption by making use of the dissipative nature of the equation.},
  archive      = {J_JDE},
  author       = {Nobu Kishimoto and Yoshio Tsutsumi},
  doi          = {10.1016/j.jde.2025.113792},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113792},
  shortjournal = {J. Diff. Equ.},
  title        = {Gauge transformation for the kinetic derivative nonlinear schrödinger equation on the torus},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Smoothness of the inertial manifold via the spatial averaging principle. <em>JDE</em>, <em>453</em>, 113790. (<a href='https://doi.org/10.1016/j.jde.2025.113790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the C n , ε | { n ≥ 2 , ε ∈ ( 0 , 1 ) } -smoothness of the inertial manifold for an abstract semilinear parabolic equation. Compared with the known results, the required spectral gap condition has been relaxed by applying the principle of spatial averaging initially proposed by J. Mallet-Paret and G. Sell in 1988.},
  archive      = {J_JDE},
  author       = {Ziqi Niu and Xinhua Li and Chunyou Sun},
  doi          = {10.1016/j.jde.2025.113790},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113790},
  shortjournal = {J. Diff. Equ.},
  title        = {Smoothness of the inertial manifold via the spatial averaging principle},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The reflection coefficient of a fractional reflector. <em>JDE</em>, <em>453</em>, 113788. (<a href='https://doi.org/10.1016/j.jde.2025.113788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the question of characterizing the behavior of waves reflected by a fractional singularity of the wave speed profile, i.e., of the form c ( x 1 , x 2 , x 3 ) = c 0 ( 1 + ( x 1 ℓ ) + α ) − 1 / 2 , for α > 0 not necessarily integer. We first focus on the case of one spatial dimension and a harmonic time dependence. We define the reflection coefficient R from a limiting absorption principle. We provide an exact formula for R in terms of the solution to a Volterra equation. We obtain the asymptotic limit of this coefficient in the large ℓ ω / c 0 regime as R = Γ ( α + 1 ) ( 2 i ) α + 2 ( c 0 ℓ ω ) α + lower order terms. The amplitude is proportional to ω − α , and the phase rotation behavior is obtained from the i − ( α + 2 ) factor. The proof method does not rely on representing the solution by special functions, since α > 0 is general. In the multi-dimensional layered case, we obtain a similar result where the nondimensional variable ℓ ω / c 0 is modified to account for the angle of incidence. The asymptotic analysis now requires the waves to be non-glancing. The resulting reflection coefficient can now be interpreted as a Fourier multiplier of order − α . In practice, the knowledge of the dependency of both the amplitude and the phase of R on ω and α might be able to inform the kind of signal processing needed to characterize the fractional nature of reflectors, for instance in geophysics.},
  archive      = {J_JDE},
  author       = {Laurent Demanet and Olivier Lafitte},
  doi          = {10.1016/j.jde.2025.113788},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113788},
  shortjournal = {J. Diff. Equ.},
  title        = {The reflection coefficient of a fractional reflector},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traveling motility of actin lamellar fragments under spontaneous symmetry breaking. <em>JDE</em>, <em>453</em>, 113787. (<a href='https://doi.org/10.1016/j.jde.2025.113787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell motility is connected to the spontaneous symmetry breaking of a circular shape. In [8] , Blanch-Mercader and Casademunt performed a nonlinear analysis of the minimal model proposed by Callan and Jones [11] and numerically conjectured the existence of traveling solutions once that symmetry is broken. In this work, we prove analytically that conjecture by means of nonlinear bifurcation techniques.},
  archive      = {J_JDE},
  author       = {Claudia García and Martina Magliocca and Nicolas Meunier},
  doi          = {10.1016/j.jde.2025.113787},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113787},
  shortjournal = {J. Diff. Equ.},
  title        = {Traveling motility of actin lamellar fragments under spontaneous symmetry breaking},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Smooth koopman eigenfunctions. <em>JDE</em>, <em>453</em>, 113786. (<a href='https://doi.org/10.1016/j.jde.2025.113786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any dynamical system, whether it is generated by a differential equation or a transformation map on a manifold, induces a dynamics on functional-spaces. The choice of functional-space may vary, but the induced dynamics is always linear, and codified by the Koopman operator. The eigenfunctions of the Koopman operator are of extreme importance in the study of the dynamics. They provide a clear distinction between the mixing and non-mixing components of the dynamics, and also reveal embedded toral rotations. The usual choice of functional-space is L 2 , a class of square integrable functions. A fundamental problem with eigenfunctions in L 2 is that they are often extremely discontinuous, particularly if the system is chaotic. There are some prototypical systems called skew-product dynamics in which L 2 Koopman eigenfunctions are also smooth. The article shows that under general assumptions on an ergodic system, these prototypical examples are the only possibility. Moreover, the smooth eigenfunctions can be used to create a change of variables which explicitly characterizes the weakly mixing component too.},
  archive      = {J_JDE},
  author       = {Suddhasattwa Das},
  doi          = {10.1016/j.jde.2025.113786},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113786},
  shortjournal = {J. Diff. Equ.},
  title        = {Smooth koopman eigenfunctions},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Existence and approximation of measure attractors and invariant measures for McKean-vlasov stochastic lattice system with lévy noise. <em>JDE</em>, <em>453</em>, 113784. (<a href='https://doi.org/10.1016/j.jde.2025.113784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the existence and approximation of measure attractors and invariant measures for superlinear McKean-Vlasov stochastic reaction-diffusion lattice system driven by Lévy noise. We firstly prove the well-posedness of solutions by the fixed point arguments. Then by the uniform pullback estimates and tail-ends estimates of solutions, we establish the pullback asymptotic compactness of non-autonomous dynamical systems generated by the solution operators in a space of probability measures, and further obtain the existence and upper semicontinuity of measure attractors. Moreover, we yield the existence and uniqueness of invariant measures as well as ergodicity of the solutions under additional conditions. In addition, the convergence rate of invariant measures is provided when distribution dependent stochastic system converges to distribution independent one. Finally, the finite-dimensional approximations of measure attractors and invariant measures are investigated between such lattice system and its finite-dimensional truncated system, which are useful for studying numerical invariant measures.},
  archive      = {J_JDE},
  author       = {Fan Bai and Zhang Chen and Xiaoxiao Sun},
  doi          = {10.1016/j.jde.2025.113784},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113784},
  shortjournal = {J. Diff. Equ.},
  title        = {Existence and approximation of measure attractors and invariant measures for McKean-vlasov stochastic lattice system with lévy noise},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonexistence of solutions to parabolic problems with a potential on weighted graphs. <em>JDE</em>, <em>453</em>, 113782. (<a href='https://doi.org/10.1016/j.jde.2025.113782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate nonexistence of nontrivial nonnegative solutions to a class of semilinear parabolic equations with a positive potential, posed on weighted graphs. Assuming an upper bound on the Laplacian of the distance and a suitable weighted space-time volume growth condition, we show that no global solutions exist. We also discuss the optimality of the hypotheses, thus recovering a critical exponent phenomenon of Fujita type.},
  archive      = {J_JDE},
  author       = {Dario D. Monticelli and Fabio Punzo and Jacopo Somaglia},
  doi          = {10.1016/j.jde.2025.113782},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113782},
  shortjournal = {J. Diff. Equ.},
  title        = {Nonexistence of solutions to parabolic problems with a potential on weighted graphs},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jmaa">JMAA - 16</h2>
<ul>
<li><details>
<summary>
(2026). On the domain and growth rate of the solutions to linear systems of moment differential equations. <em>JMAA</em>, <em>556</em>(1), 130097. (<a href='https://doi.org/10.1016/j.jmaa.2025.130097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The domain of definition of the solutions to linear systems of moment differential equations is provided in terms of the growth of the sequence of moments. The growth rate of the solutions near infinity is described for systems admitting entire solutions: first, in terms of the associated function related to a weight sequence; second in terms of the order and type of an entire function. Further information is detailed when considering logarithmic order and types.},
  archive      = {J_JMAA},
  author       = {Antonio Cáceres and Alberto Lastra},
  doi          = {10.1016/j.jmaa.2025.130097},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130097},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On the domain and growth rate of the solutions to linear systems of moment differential equations},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global analysis on a nonlinear diffusion system with fear effect, protection zone and ivlev functional response. <em>JMAA</em>, <em>556</em>(1), 130096. (<a href='https://doi.org/10.1016/j.jmaa.2025.130096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a novel nonlinear diffusive Ivlev-type predator-prey system that synergistically integrates fear effect and protection zone. By analyzing bifurcation structure of positive steady-states emanating from semi-trivial steady-states, and employing Leray-Schauder degree theory, we characterize how these combined factors dictate the multiplicity, uniqueness and stability of positive steady-states. Additionally, we examine the asymptotic behaviors of positive steady-states induced by the predator growth rate and prey diffusion rate. The long-term dynamical behaviors of the system are finally revealed. The findings reveal that the interplay of fear effect, protection zone and Ivlev-type interaction term generates unprecedented dynamical regimes in traditional models with fewer ecological factors, and offers both theoretical insights into complex ecosystems and practical guidance for conservation strategies. Biologically speaking, such joint effects help to showcase their synergistic roles in shaping population dynamics and ecological stability.},
  archive      = {J_JMAA},
  author       = {Daoxin Qiu and Yunfeng Jia and Shengqiang Liu},
  doi          = {10.1016/j.jmaa.2025.130096},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130096},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Global analysis on a nonlinear diffusion system with fear effect, protection zone and ivlev functional response},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Existence of optimal periodic strategies in a model with nonlocal spatiotemporal dispersal. <em>JMAA</em>, <em>556</em>(1), 130095. (<a href='https://doi.org/10.1016/j.jmaa.2025.130095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a control problem for a nonlinear integro-differential system incorporating both spatial and temporal nonlocal terms, subject to periodic condition in time. The equation, derived from population dynamics, describes the evolution of population density under growth, migration, and memory effects. The control set is feedback-based and spatially nonlocal, depending on a weighted integral of the state. We establish the existence of controlled trajectories that approximate the infimum or supremum of a cost functional with arbitrary precision. Moreover, under additional regularity assumptions on the bounding functions of the control set, we provide the existence of truly optimal controlled trajectories. The analysis employs topological methods in nonlinear analysis and tailored techniques to address temporal nonlocalities.},
  archive      = {J_JMAA},
  author       = {Paola Rubbioni},
  doi          = {10.1016/j.jmaa.2025.130095},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130095},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Existence of optimal periodic strategies in a model with nonlocal spatiotemporal dispersal},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-frequency stability estimates for the inverse boundary value problems for the schrödinger and the biharmonic operator with constant attenuation on certain bounded domains. <em>JMAA</em>, <em>556</em>(1), 130094. (<a href='https://doi.org/10.1016/j.jmaa.2025.130094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore high-frequency stability estimates for the determination of the zeroth-order perturbation of the Schrödinger and the biharmonic operators with constant attenuation from the partial Dirichlet-to-Neumann map when part of the boundary is inaccessible and flat. The results are derived under mild regularity assumptions on the potential and extend the results of [21] and [28] in the presence of attenuation in such domains.},
  archive      = {J_JMAA},
  author       = {Anupam Pal Choudhury and Ajith Kumar T},
  doi          = {10.1016/j.jmaa.2025.130094},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130094},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {High-frequency stability estimates for the inverse boundary value problems for the schrödinger and the biharmonic operator with constant attenuation on certain bounded domains},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-bump solutions of the magnetic p-laplacian schrödinger equations with critical and logarithmic nonlinearities. <em>JMAA</em>, <em>556</em>(1), 130093. (<a href='https://doi.org/10.1016/j.jmaa.2025.130093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the following magnetic p -Laplacian Schrödinger equations with critical and logarithmic nonlinearities in R N : − Δ p , A u + ( λ Z ( x ) + V ( x ) ) | u | p − 2 u = β | u | p − 2 u log ⁡ | u | p + | u | p ⁎ − 2 u , x ∈ R N , where N ≥ 3 , p ∈ [ 2 , N ) , Δ p , A = div ( | ∇ u + i A ( x ) u | p − 2 ( ∇ u + i A ( x ) u ) ) denotes the magnetic p -Laplacian, the magnetic potential A ∈ L l o c p ( R N , R N ) and the parameters λ , β ≥ 1 , Z ( x ) , V ( x ) : R N → R are the nonnegative continuous functions, p ⁎ = N p N − p is the Sobolev critical exponent. Applying variational methods, multiple multi-bump solutions for the above equation have been obtained. More precisely, our findings demonstrate that if the zero set of Z possesses several isolated connected components Ω 1 , ⋯ , Ω k such that the interior of Ω i is not empty and ∂Ω is smooth, then for λ ≥ 1 sufficiently large, a bump solution is confined in a neighborhood of ⋃ j ∈ Γ Ω j for every non-empty subset Γ ⊂ { 1 , ⋯ , k } . Furthermore, let λ ≥ 1 be large enough, we also show that the above equation has at least 2 k − 1 multi-bump solutions. The novelty and characteristic of this paper lie in the simultaneous appearance of critical and logarithmic nonlinearities in this equation, and the results in this paper extend the subcritical case [39] to the critical case.},
  archive      = {J_JMAA},
  author       = {Lulu Wei and Yueqiang Song},
  doi          = {10.1016/j.jmaa.2025.130093},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130093},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Multi-bump solutions of the magnetic p-laplacian schrödinger equations with critical and logarithmic nonlinearities},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New characterizations of muckenhoupt ap distance weights for p > 1. <em>JMAA</em>, <em>556</em>(1), 130091. (<a href='https://doi.org/10.1016/j.jmaa.2025.130091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We characterize the collection of sets E ⊂ R n for which there exists θ ∈ R ∖ { 0 } such that the distance weight w ( x ) = dist ( x , E ) θ belongs to the Muckenhoupt class A p , where p > 1 . These sets exhibit a certain balance between the small-scale and large-scale pores that constitute their complement—a property we show to be more general than the so-called weak porosity condition, which in turn, and according to recent results, characterizes the sets with associated distance weights in the A 1 case. Furthermore, we verify the agreement between this new characterization and the properties of known examples of distance weights, that are either A p weights or merely doubling weights, by means of a probabilistic approach that may be of interest by itself.},
  archive      = {J_JMAA},
  author       = {Ignacio Gómez Vargas},
  doi          = {10.1016/j.jmaa.2025.130091},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130091},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {New characterizations of muckenhoupt ap distance weights for p > 1},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On generalized limits and ultrafilters. <em>JMAA</em>, <em>556</em>(1), 130090. (<a href='https://doi.org/10.1016/j.jmaa.2025.130090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an ideal I on ω , we denote by SL ( I ) the family of positive normalized linear functionals on ℓ ∞ which assign value 0 to all characteristic sequences of sets in I . We show that every element of SL ( I ) is a Choquet average of certain ultrafilter limit functionals. Also, we prove that the diameter of SL ( I ) is 2 if and only if I is not maximal, and that the latter claim can be considerably strengthened if I is meager. Lastly, we provide several applications: for instance, recovering a result of Freedman (1981) [19] , we show that the family of bounded sequences for which all functionals in SL ( I ) assign the same value coincides with the closed vector space of bounded I -convergent sequences.},
  archive      = {J_JMAA},
  author       = {Paolo Leonetti and Cihan Orhan},
  doi          = {10.1016/j.jmaa.2025.130090},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130090},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On generalized limits and ultrafilters},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finsler N-laplace equations with critical exponential nonlinearity. <em>JMAA</em>, <em>556</em>(1), 130089. (<a href='https://doi.org/10.1016/j.jmaa.2025.130089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate some anisotropic equations involving the Finsler N -Laplace operator Δ H , N , with Trudinger-Moser type critical exponential nonlinearity which involves the anisotropic norm. More precisely, we establish the existence of nontrivial solutions to the problem − Δ H , N u = f ( x , u ) , u ≥ 0 in Ω , on a smooth bounded domain Ω ⊂ R N , N ≥ 2 , and to the anisotropic quasilinear Schrödinger problem − Δ H , N u + V ( x ) | u | N − 2 u = g ( x , u ) , u ≥ 0 in R N . Here the nonlinearities f and g exhibit critical exponential-type growth, and the potential V is a continuous function that retains the compactness of the associated Sobolev embedding into a larger class of Lebesgue spaces under suitable assumptions. We obtain the existence results by employing the anisotropic Trudinger-Moser inequality, mountain-pass theorem, and Ekeland's variational principle.},
  archive      = {J_JMAA},
  author       = {Monti Das and Sweta Tiwari},
  doi          = {10.1016/j.jmaa.2025.130089},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130089},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Finsler N-laplace equations with critical exponential nonlinearity},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Killing mean curvature solitons from riemannian submersions. <em>JMAA</em>, <em>556</em>(1), 130088. (<a href='https://doi.org/10.1016/j.jmaa.2025.130088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new general construction of mean curvature flow solitons on manifolds admitting a nowhere-vanishing Killing vector field. Using Riemannian submersion techniques, we reduce the problem from a PDE to an ODE. As an application, we obtain new examples of rotators in hyperbolic space.},
  archive      = {J_JMAA},
  author       = {Diego Artacho and Marie-Amélie Lawn and Miguel Ortega},
  doi          = {10.1016/j.jmaa.2025.130088},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130088},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Killing mean curvature solitons from riemannian submersions},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Boundedness in an attraction-repulsion chemotaxis system with indirect repulsion-signal production. <em>JMAA</em>, <em>556</em>(1), 130087. (<a href='https://doi.org/10.1016/j.jmaa.2025.130087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the following attraction-repulsion chemotaxis system involving nonlinear indirect signal mechanism { u t = Δ u − ξ ∇ ⋅ ( u ∇ v ) + χ ∇ ⋅ ( u ∇ z ) + f ( u ) , x ∈ Ω , t > 0 , 0 = Δ v − v + u γ 1 , x ∈ Ω , t > 0 , z t = Δ z − z + w γ 2 , x ∈ Ω , t > 0 , 0 = Δ w − w + u γ 3 , x ∈ Ω , t > 0 , under homogeneous Neumann boundary conditions, where Ω ⊂ R n ( n ≥ 1 ) is a smoothly bounded domain and ξ , χ , γ 1 , γ 2 , γ 3 > 0 . • When f ≡ 0 , it is shown that the solution of the above system is global and uniformly bounded if max ⁡ { γ 1 , γ 2 γ 3 } < 2 n . Moreover, if max ⁡ { γ 1 , γ 2 γ 3 } = 2 n , the boundedness of solution can be derived provided that the initial mass ∫ Ω u 0 ( x ) d x is small. • When f ( u ) ≤ u ( a − b u k ) with a , b , k > 0 , it is proved that if one of the following conditions holds: (i) k > max ⁡ { γ 1 , γ 2 γ 3 } , (ii) k = max ⁡ { γ 1 , γ 2 γ 3 } , (iii) max ⁡ { γ 1 , γ 2 γ 3 } < 2 n , then the solution is globally bounded in time provided that b is large enough.}},
  archive      = {J_JMAA},
  author       = {Wei Wang and Pan Zheng},
  doi          = {10.1016/j.jmaa.2025.130087},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130087},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Boundedness in an attraction-repulsion chemotaxis system with indirect repulsion-signal production},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of velocities in pipeline flow of blended gas. <em>JMAA</em>, <em>556</em>(1), 130078. (<a href='https://doi.org/10.1016/j.jmaa.2025.130078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the pipeline flow of blended gas. The flow is governed by a coupled system where for each component we have the isothermal Euler equations with an additional velocity coupling term that couples the velocities of the different components. Our motivation is hydrogen blending in natural gas pipelines, which will play a role in the transition to renewable energies. We show that with suitable boundary conditions the velocities of the gas components synchronize exponentially fast, as long as the L 2 -norm of the synchronization error is outside of a certain interval where the size of the interval is determined by the order of the interaction terms. This indicates that in some cases for a mixture of n components it is justified to use a drift-flux model where it is assumed that all components flow with the same velocity. For the proofs we use an appropriately chosen Lyapunov function which is based upon the idea of relative energy.},
  archive      = {J_JMAA},
  author       = {Martin Gugat},
  doi          = {10.1016/j.jmaa.2025.130078},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130078},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Synchronization of velocities in pipeline flow of blended gas},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global solvability and stability of cognitive consumer-resource model with nonlocal usage of memory. <em>JMAA</em>, <em>556</em>(1), 130076. (<a href='https://doi.org/10.1016/j.jmaa.2025.130076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we formulate a consumer-resource system incorporating dynamic cognitive mapping and nonlocal memory integration. The model represents resource perception using a spatial convolution kernel, capturing nonlocal interactions between consumers and their environment. We establish the global existence of classical solutions under periodic boundary conditions in two spatial dimensions and demonstrate the global stability of homogeneous steady states within specific parameter regimes. Additionally, numerical simulations are conducted to explore the influence of the perception radius R on system dynamics. Our results reveal that the perception radius plays a pivotal role in inducing phase transitions from uniform states to complex spatiotemporal patterns, underscoring the significance of cognitive sensing scales in ecological self-organization.},
  archive      = {J_JMAA},
  author       = {Xuebing Zhang and Qi An and Hao Wang},
  doi          = {10.1016/j.jmaa.2025.130076},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130076},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Global solvability and stability of cognitive consumer-resource model with nonlocal usage of memory},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). C⁎-supports and abnormalities of operator systems. <em>JMAA</em>, <em>556</em>(1), 130074. (<a href='https://doi.org/10.1016/j.jmaa.2025.130074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let S be a concrete operator system represented on some Hilbert space H . A C ⁎ -support of S is the C ⁎ -algebra generated (via the Choi–Effros product) by S inside an injective operator system acting on H . By leveraging Hamana's theory, we show that such a C ⁎ -support is unique precisely when C ⁎ ( S ) (the C ⁎ -algebra generated in B ( H ) with the usual product) is contained in every copy of the injective envelope of S that acts on H . Further, we demonstrate how the uniqueness of certain C ⁎ -supports can be used to give new characterizations of the unique extension property for ⁎-representations, as well as the hyperrigidity of S . In another direction, we utilize the collection of all C ⁎ -supports of S to describe the subspace generated by the so-called abnormalities of S , thereby complementing an earlier result of Kakariadis.},
  archive      = {J_JMAA},
  author       = {Raphaël Clouâtre and Colin Krisko},
  doi          = {10.1016/j.jmaa.2025.130074},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130074},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {C⁎-supports and abnormalities of operator systems},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An extension of the spectral fractional laplacian to non-homogeneous boundary condition on rectangular domains, with application to well-posedness for plate equation with structural damping. <em>JMAA</em>, <em>556</em>(1), 130073. (<a href='https://doi.org/10.1016/j.jmaa.2025.130073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let Δ be the Dirichlet Laplacian on a rectangular domain R ⊂ R N . We study the mapping properties of an extension of the spectral fractional Laplacian, ( − Δ ) α , for α ∈ [ 0 , 1 ) , when applied to functions satisfying non-homogeneous boundary conditions. A symmetry formula is proven. As an application, we prove well-posedness results for the structurally damped plate equation u t t + Δ 2 u + ρ ( − Δ ) α u t = 0 , x ∈ R , t > 0 , with non-homogeneous boundary conditions u | ∂ R = f , Δ u | ∂ R = 0 , f ∈ L 2 ( ∂ R × [ 0 , ∞ ) ) . Other non-homogeneous boundary conditions are also considered.},
  archive      = {J_JMAA},
  author       = {Julian Edward},
  doi          = {10.1016/j.jmaa.2025.130073},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130073},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {An extension of the spectral fractional laplacian to non-homogeneous boundary condition on rectangular domains, with application to well-posedness for plate equation with structural damping},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transverse FT-entropy for riemannian foliations. <em>JMAA</em>, <em>556</em>(1), 130070. (<a href='https://doi.org/10.1016/j.jmaa.2025.130070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce an entropy functional on Riemannian foliations, inspired by the work of Perelman. We relate its gradient flow to the transverse Ricci flow via the foliation preserving diffeomorphisms. We show that it is monotonic along the transverse Ricci flow. Moreover, inspired by the work of Fuquan Fang and Yuguang Zhang, we give a sufficient condition for any codimension-4 Riemannian foliation to admit the transverse Einstein metric.},
  archive      = {J_JMAA},
  author       = {Dexie Lin},
  doi          = {10.1016/j.jmaa.2025.130070},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130070},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Transverse FT-entropy for riemannian foliations},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Range-exclusive solutions of almost automorphic differential equations. <em>JMAA</em>, <em>556</em>(1), 130067. (<a href='https://doi.org/10.1016/j.jmaa.2025.130067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a unified approach to establishing the existence of almost automorphic solutions to differential equations in Banach spaces. We introduce the concept of solutions having exclusive ranges for differential equations of the form u ′ = f ( t , u ) in a Banach space X , where f is almost automorphic in time t . The proposed methodology unifies classical techniques, covering cases where nonlinearities are globally Lipschitz with exponentially stable linear parts, as well as differential equations without global Lipschitz nonlinearities. The main result shows that, under certain conditions on f , every solution with an exclusive range is compactly almost automorphic. To illustrate the versatility of the developed approach, we provide several examples and applications, including a Bohr–Neugebauer type theorem and the analysis of differential equations possessing multiple and unique almost automorphic solutions.},
  archive      = {J_JMAA},
  author       = {B. Es-sebbar and Z. Zizi},
  doi          = {10.1016/j.jmaa.2025.130067},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130067},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Range-exclusive solutions of almost automorphic differential equations},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jocs">JOCS - 20</h2>
<ul>
<li><details>
<summary>
(2025). An exploration of the shift work consideration in production scheduling. <em>JOCS</em>, <em>92</em>, 102724. (<a href='https://doi.org/10.1016/j.jocs.2025.102724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling problems predominantly assume that the same operators work fixed shifts during the day and night. Scheduling with a single-shift approach can result in infeasible or suboptimal production planning solutions when a multiple-shift system is implemented. This study introduces a new scheduling extension that incorporates shift work constraints. A new mathematical model based on the Permutation Flowshop Scheduling Problem is proposed, and the Iterated Greedy algorithm is adapted to solve it. The objective is to minimize the maximum completion time (makespan) and thereby improve the system performance while considering shift work constraints. Experiments reveal that the overall response time in 10-hour and 12-hour shifts is better than that of 8-hour shifts, despite the shorter overall active hours on the shop floor. Additional experiments confirm that the proposed Adjusted Iterated Greedy algorithm outperforms the Variable Neighbourhood Search algorithm in solving medium- and large-scale problems.},
  archive      = {J_JOCS},
  author       = {Kuo-Ching Ying and Pourya Pourhejazy and Shih-Cheng Lin},
  doi          = {10.1016/j.jocs.2025.102724},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102724},
  shortjournal = {J. Comput. Sci.},
  title        = {An exploration of the shift work consideration in production scheduling},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An accurate and stable space-time radial basis function collocation method for transient coupled thermo-mechanical analysis. <em>JOCS</em>, <em>92</em>, 102720. (<a href='https://doi.org/10.1016/j.jocs.2025.102720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an accurate and stable space-time radial basis function (STRBF) collocation method is developed to solve two- and three-dimensional dynamic coupled thermo-mechanical problems. The proposed method enhances numerical precision by strategically positioning source points beyond the computational domain through space-time scaling factors. To address the challenge of selecting the optimal shape parameter, a new coupled STRBF is formulated by combining the Multiquadric function with the conical spline. Furthermore, a multiscale computational strategy is implemented to mitigate numerical instability in the resulting linear system. The effectiveness of the developed approach is demonstrated through four numerical examples involving complex geometries and different initial and boundary conditions. Numerical results show that, compared to the traditional RBF collocation method, the developed scheme not only enhances computational accuracy but also significantly reduces the dependence on the choice of shape parameter, making it a promising method for dealing with transient coupled thermo-mechanical problems.},
  archive      = {J_JOCS},
  author       = {Xiaohan Jing and Lin Qiu and Hong Zhao and Zeqian Zhang and Yaoming Zhang and Yan Gu},
  doi          = {10.1016/j.jocs.2025.102720},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102720},
  shortjournal = {J. Comput. Sci.},
  title        = {An accurate and stable space-time radial basis function collocation method for transient coupled thermo-mechanical analysis},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heuristic custom similarity index (HCSI): A novel machine learning approach for link prediction. <em>JOCS</em>, <em>92</em>, 102719. (<a href='https://doi.org/10.1016/j.jocs.2025.102719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is a fundamental task in network analysis, aiming at predicting missing or future connections between nodes in a network. With the growing availability of complex network data in fields like social networks, biological systems, the Internet, and scientific collaboration networks, accurate link prediction methods are becoming increasingly critical. Neighborhood or graph based link prediction algorithms are applied identically to different types of networks so that any differences in their structures are not exploited efficiently. Machine or deep learning based link prediction algorithms apply to each kind of network differently depending on the type of network, due to the unique characteristics of each domain, but frequently, most of them give poor results. In this paper, we propose a novel approach for link prediction, leveraging the power of machine learning and evolutionary algorithms. Our method utilizes local network information by encoding the network topology into link embeddings through a heuristic machine learning architecture. We introduce a novel tool to extract features from network structure effectively and combine them in an effective way through an evolutionary algorithm improving the discriminative power of link embeddings. We evaluate our method on eleven benchmark datasets and demonstrate its superior performance compared to a series (eleven in total) of effective and state-of-the-art algorithms. Our approach advances the state-of-the-art in link prediction yielding better results than other methods in all the networks we have applied it to.},
  archive      = {J_JOCS},
  author       = {Paraskevas Dimitriou and Vasileios Karyotis},
  doi          = {10.1016/j.jocs.2025.102719},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102719},
  shortjournal = {J. Comput. Sci.},
  title        = {Heuristic custom similarity index (HCSI): A novel machine learning approach for link prediction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approach to global path planning and optimization for mobile robots based on multi-local gravitational potential fields bias-P-RRT*. <em>JOCS</em>, <em>92</em>, 102718. (<a href='https://doi.org/10.1016/j.jocs.2025.102718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sampling-based method has strong environmental adaptability and probability completeness, providing an effective solution for mobile robot path planning. However, the conventional rapidly-exploring random trees (RRT) algorithm often presents slow convergence and inefficient search paths. In this sense, this paper proposes a mobile robot path planning and optimization algorithm based on P-RRT* that incorporates multi-local gravitational potential fields and bias sampling, i.e., multi-local gravitational potential fields Bias-P-RRT* (MLGPFB-P-RRT*). The algorithm adds a local gravitational field between the starting point and the target point to better guide the direction of random tree growth, and directly connects the center of the last local gravitational field to the target point to accelerate the convergence of the random tree at the target point. Meanwhile, the introduction of bias sampling based on local potential fields to optimize the generation quality of random points, thereby improving the generation position of new nodes and reducing the randomness of sampling for mobile robots in the workspace. Then, a collision detection method between sampling nodes and obstacles was developed, which can quickly determine the feasibility of the sampling path. Finally, the generated path is optimized and smoothed through pruning optimization and quadratic B-spline function. A series of simulation studies and mobile robot experiments demonstrate the superior performance of the proposed algorithm.},
  archive      = {J_JOCS},
  author       = {Leiwen Yuan and Jingwen Luo},
  doi          = {10.1016/j.jocs.2025.102718},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102718},
  shortjournal = {J. Comput. Sci.},
  title        = {Approach to global path planning and optimization for mobile robots based on multi-local gravitational potential fields bias-P-RRT*},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic deep-ritz for parametric uncertainty quantification. <em>JOCS</em>, <em>92</em>, 102717. (<a href='https://doi.org/10.1016/j.jocs.2025.102717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific machine learning has become an increasingly important tool in materials science and engineering. It is particularly well suited to tackle material problems involving many variables or to allow rapid construction of surrogates of material models, to name just a few. Mathematically, many problems in materials science and engineering can be cast as variational problems. However, handling of uncertainty, ever present in materials, in the context of variational formulations remains challenging for scientific machine learning. In this article, we propose a deep-learning-based numerical method for solving variational problems under uncertainty. Our approach seamlessly combines deep-learning approximation with Monte Carlo sampling. The resulting numerical method is powerful yet remarkably simple. We assess its performance and accuracy on a number of variational problems.},
  archive      = {J_JOCS},
  author       = {Ting Wang and Jaroslaw Knap},
  doi          = {10.1016/j.jocs.2025.102717},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102717},
  shortjournal = {J. Comput. Sci.},
  title        = {Stochastic deep-ritz for parametric uncertainty quantification},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid nutcracker optimization algorithm for multi-objective energy scheduling in grid-connected microgrid systems. <em>JOCS</em>, <em>92</em>, 102716. (<a href='https://doi.org/10.1016/j.jocs.2025.102716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for clean and sustainable energy has driven rapid advancements in hybrid microgrid systems to mitigate climate change and environmental degradation. This paper proposes a novel multi-objective scheduling framework for hybrid microgrids aimed at minimizing operational costs while maximizing environmental benefits. To efficiently solve this complex optimization problem, we introduce a Hybrid Nutcracker Optimization Algorithm (HNOA), which combines the recently developed Nutcracker Optimization Algorithm (NOA) with the Bat Algorithm (BAT). This hybridization enhances NOA’s exploration–exploitation balance and search capability, as demonstrated by rigorous validation on 12 benchmark functions. HNOA achieves superior accuracy and computational efficiency compared to several state-of-the-art metaheuristics. The proposed HNOA is then applied to solve the scheduling of a grid-connected hybrid microgrid under various scenarios to evaluate its performance. Simulation results indicate that the optimal microgrid configuration, consisting of PV/WT/turbine/diesel/battery, achieves an investment cost of 80,789.02 yuan. The findings of this study offer valuable insights for advancing renewable energy integration and promoting environmental sustainability.},
  archive      = {J_JOCS},
  author       = {Yiwei Liu and Yinggan Tang and Changchun Hua},
  doi          = {10.1016/j.jocs.2025.102716},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102716},
  shortjournal = {J. Comput. Sci.},
  title        = {Hybrid nutcracker optimization algorithm for multi-objective energy scheduling in grid-connected microgrid systems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Darcy-scale digital core models for rock properties upscaling and computational domain reduction. <em>JOCS</em>, <em>92</em>, 102715. (<a href='https://doi.org/10.1016/j.jocs.2025.102715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Digital Rock Physics (DRP) requires the elaboration of robust techniques for closing the gaps between different scales of rock studies (upscaling). The upscaling workflows are especially needed to support the applicability of DRP for heterogeneous rocks. Basically, DRP involves two primary stages: model construction and simulation of physical processes on the models created. For heterogeneous rocks, there is an inherent trade-off between the spatial resolution of the data and the representativeness of the model size. The primary objective of this study was to implement and test a technique for upscaling digital core models from microscale to macroscale, enabling the computation of rock properties while accounting for heterogeneity of various scales. The upscaling is based on establishing correlations between tomography data of different resolutions and transforming low-resolution tomography into a multi-class model according to the defined correlation. The convolutional neural network for high-resolution tomography data was considered as the optimal algorithm for transforming low-resolution tomography into a multi-class model. The output of the neural network was an upscaled model of lower resolution than the original tomography image. Each cell in the upscaled model belonged to one of several types of formation, whose generalized characteristics were determined on the basis of the analysis of high-resolution tomography data. To validate the upscaling technique, we constructed a digital model of a complex carbonate reservoir based on data from multi-scale microtomography ( μ CT). A Darcy-scale model has been used and validated as a multi-class model, enabling the computation of flows in pore samples of various scales. By incorporating diverse pore space structures as different classes in the Darcy-scale model, it is possible to preserve the substantial physical size of the model while enhancing its level of complexity.},
  archive      = {J_JOCS},
  author       = {Denis Orlov and Batyrkhan Gainitdinov and Dmitry Koroteev},
  doi          = {10.1016/j.jocs.2025.102715},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102715},
  shortjournal = {J. Comput. Sci.},
  title        = {Darcy-scale digital core models for rock properties upscaling and computational domain reduction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical study of two-dimensional sediment transport using momentum-conserving staggered grid scheme. <em>JOCS</em>, <em>92</em>, 102714. (<a href='https://doi.org/10.1016/j.jocs.2025.102714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sediment transport plays a crucial role in the evolution of bed morphology through deposition and erosion. This study presents numerical simulations of two-dimensional sediment transport induced by fluid flow. The fluid-sediment interaction is governed by a capacity model, i.e., the coupled system of shallow water and Exner equations, a simplification of more physically advanced non-capacity models. The system is solved using a momentum-conserving staggered grid (MCS) scheme. Model validation is performed using the Meyer-Peter and Müller (MPM) bedload transport formula, applied to experimental data from dam-break flows in various channel configurations. The proposed method successfully reproduces trends in the evolution of the water surface and quasi-steady sediment profiles. In general, the MCS scheme provides more accurate water level predictions than the numerical benchmark schemes. Although the predictions of maximum depths of deposition and erosion are less accurate, the overall results are consistent with those obtained from non-capacity models. Furthermore, the model is applied to the Kampar River estuary to simulate sediment transport due to the tidal bore.},
  archive      = {J_JOCS},
  author       = {Riski Kurniawan and Sri Redjeki Pudjaprasetya and Rani Sulvianuri},
  doi          = {10.1016/j.jocs.2025.102714},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102714},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical study of two-dimensional sediment transport using momentum-conserving staggered grid scheme},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cellular automaton towards structural balance—Long cycles of link dynamics. <em>JOCS</em>, <em>92</em>, 102712. (<a href='https://doi.org/10.1016/j.jocs.2025.102712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cellular automaton is defined on a line graph of a fully connected network. The automaton rule drives the system to a structural balance in most cases. Here, we investigate cycles with special symmetries, the so-called ’perfect cycles’ Burda et al. (2022). Two new characteristics of the cycles are investigated, as potential markers of perfect cycles: an equivalence of sets of states attained after external damage of links, and the homogeneity of the distribution of phase shifts between local trajectories. Only the second characteristic works as a criterion of the perfectness of the cycles. The results can be useful for generating pseudorandom numbers.},
  archive      = {J_JOCS},
  author       = {Malgorzata J. Krawczyk and Krzysztof Kułakowski},
  doi          = {10.1016/j.jocs.2025.102712},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102712},
  shortjournal = {J. Comput. Sci.},
  title        = {A cellular automaton towards structural balance—Long cycles of link dynamics},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hamiltonian circuit of virtual sample generation for a small dataset. <em>JOCS</em>, <em>92</em>, 102711. (<a href='https://doi.org/10.1016/j.jocs.2025.102711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small datasets often lead to poor performance of data-driven prediction models due to uneven data distribution and large data spacing. One popular approach to address this issue is to use virtual samples during machine learning (ML) model training. This study proposes a Hamiltonian Circuit Virtual Sample Generation (HCVSG) method to distribute virtual samples generated using interpolation techniques while integrating the K-Nearest Neighbors (KNN) algorithm in model development. The Hamiltonian circuit is chosen because it doesn’t depend on the distribution assumption and provides multiple circuits that allow adaptive sample distribution, allowing the selection of circuits that produce minimum errors. This method supports improving feature-target correlation, reducing the risk of overfitting, and stabilizing error values as model complexity increases. Applying this method to three datasets in material research (MLCC, PSH, and EFD) shows that HCVSG significantly improves prediction accuracy compared to conventional KNN and eight MTD-based methods. The distribution of virtual samples along the Hamiltonian circuit helps fill the information gap and makes the data distribution more even, ultimately improving the predictive model's performance.},
  archive      = {J_JOCS},
  author       = {Totok Sutojo and Supriadi Rustad and Muhamad Akrom and Wahyu Aji Eko Prabowo and De Rosal Ignatius Moses Setiadi and Hermawan Kresno Dipojono and Yoshitada Morikawa},
  doi          = {10.1016/j.jocs.2025.102711},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102711},
  shortjournal = {J. Comput. Sci.},
  title        = {An adaptive hamiltonian circuit of virtual sample generation for a small dataset},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tuning sensitivity of black phosphorene surface doped SnS, SnSe, GeS, and GeSe quantum dots toward water molecule and other small toxic molecules. <em>JOCS</em>, <em>92</em>, 102707. (<a href='https://doi.org/10.1016/j.jocs.2025.102707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, Density Functional Theory (DFT) was employed to investigate the impact of SnS, GeS, SnSe, and GeSe quantum dots doped black phosphorene on the sensitivity of black phosphorene toward various adsorbed gas molecules namely NO 2 and H 2 S. The interaction of H 2 O molecule with doped black phosphorene surface is also investigated to evaluate the impact of humidity on the sensing response. The results revealed the large electronic changes in bands distribution upon exposure to the selected gas molecules, giving rise to a variation in the electronic band nature from hole to electron doping which can promote the electrical conductivity and the sensing properties of the doped phosphorene structures.},
  archive      = {J_JOCS},
  author       = {Mamori Habiba and Moatassim Hajar and El Kenz Abdallah and Benyoussef Abdelilah and Taleb Abdelhafed and Abdel Ghafour El Hachimi and Zaari Halima},
  doi          = {10.1016/j.jocs.2025.102707},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102707},
  shortjournal = {J. Comput. Sci.},
  title        = {Tuning sensitivity of black phosphorene surface doped SnS, SnSe, GeS, and GeSe quantum dots toward water molecule and other small toxic molecules},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CKDTA: A chemical knowledge-enhanced framework for drug–target affinity prediction. <em>JOCS</em>, <em>92</em>, 102706. (<a href='https://doi.org/10.1016/j.jocs.2025.102706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate drug–target affinity (DTA) prediction is a cornerstone of efficient drug discovery, as it directly accelerates the screening of potential therapeutic candidates, reduces the cost of preclinical experiments, and shortens the development cycle of new drugs. However, existing deep learning-based methods face two main challenges: (I) Purely data-driven approaches struggle to capture the functional semantics of molecules, such as the role of specific functional regions and chemical element properties in binding interactions, due to the lack of integration with chemical prior knowledge, leading to unreliable predictions; (II) the integration of topological structure from graphs and long-range dependencies from sequences is insufficient, often failing to capture complementary features, limiting the model’s generalization ability, especially for novel drugs or targets commonly encountered in early drug discovery . To address these issues, we propose CKDTA , a C hemical K nowledge Enhanced framework for D rug- T arget A ffinity prediction. Our framework introduces two key innovations: (1) a chemical knowledge-enhanced molecular modeling approach, which constructs a multi-layer molecular graph incorporating atom-level features, chemical element information, and functional regions, enabling the capture of functional semantics through a hierarchical attention mechanism, while leveraging chemical prior knowledge; (2) a co-attention module designed to optimize sequence interaction information by leveraging graph-based interaction data, compensating for the lack of spatial structural information in sequence data. This module fully exploits the topological structure of graphs and the long-range dependencies in sequences, capturing complementary features. Extensive experiments on benchmark datasets demonstrate that CKDTA outperforms state-of-the-art methods. Furthermore, cold-start experiments validate its generalizability, highlighting its potential for drug discovery applications.},
  archive      = {J_JOCS},
  author       = {Xingran Zhao and Yanbu Guo and Bingyi Wang and Weihua Li},
  doi          = {10.1016/j.jocs.2025.102706},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102706},
  shortjournal = {J. Comput. Sci.},
  title        = {CKDTA: A chemical knowledge-enhanced framework for drug–target affinity prediction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient numerical simulation of variable-order fractional diffusion processes with a memory kernel. <em>JOCS</em>, <em>92</em>, 102705. (<a href='https://doi.org/10.1016/j.jocs.2025.102705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion equations are fundamental in modeling the transport of heat, mass, or contaminants in porous media. However, classical models often fail to capture the anomalous diffusion behavior inherent in heterogeneous and memory-dependent materials. To address this, we investigate a fractional diffusion integro-differential equation involving variable-order derivatives in both time and space, subject to suitable conditions. The solutions are shown to exist and be unique through the rigorous application of fixed-point theorems. A finite difference-based numerical scheme is formulated to handle the variable-order fractional operators and convolution-type integral terms efficiently. Stability analysis confirms the accuracy and robustness of the method. In addition, approximate solutions are computed for three representative cases:(i) constant-order fractional diffusion ( α = constant ), (ii) time-dependent order α ( t ) , and (iii) fully variable-order α ( x , t ) . By incorporating variable order dynamics and integro-differential structures, this work extends conventional models and provides a unified framework for simulating complex transport processes in porous media.},
  archive      = {J_JOCS},
  author       = {Sabita Bera and Mausumi Sen and Sujit Nath},
  doi          = {10.1016/j.jocs.2025.102705},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102705},
  shortjournal = {J. Comput. Sci.},
  title        = {Efficient numerical simulation of variable-order fractional diffusion processes with a memory kernel},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical solution of the biological SIR model for COVID-19 with convergence analysis. <em>JOCS</em>, <em>92</em>, 102704. (<a href='https://doi.org/10.1016/j.jocs.2025.102704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the numerical solution of the biological Susceptible–Infectious–Recovered model for COVID-19 over extended time intervals using the shifted Chebyshev polynomial collocation method. Initially, the original problem is reformulated into a nonlinear Volterra integral equation for the susceptible population. The shifted Chebyshev polynomials are then employed to derive the numerical solution. A comprehensive convergence analysis of the collocation method is conducted to ensure the reliability and accuracy of the proposed approach. Finally, numerical simulations are performed for various parameter configurations that influence the system’s coefficients. Our method is compared with existing approaches, providing insights into the model’s dynamics under different conditions.},
  archive      = {J_JOCS},
  author       = {Walid Remili and Wen-Xiu Ma},
  doi          = {10.1016/j.jocs.2025.102704},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102704},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical solution of the biological SIR model for COVID-19 with convergence analysis},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decomposition based imputation algorithm for long consecutive missing atmospheric pollution data and its application. <em>JOCS</em>, <em>92</em>, 102697. (<a href='https://doi.org/10.1016/j.jocs.2025.102697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the intensification of environmental air pollution, the impact of air pollutants on both the ecological environment and human health has attracted widespread attention. However, due to the relatively late introduction of environmental monitoring systems, there were long consecutive missing values in early pollutant data. In this paper, we propose a decomposition-based imputation method for long consecutive missing pollution data. Firstly, wavelet coherence analysis is employed to investigate the periodic relationship between the pollution data and the relevant air data, decomposing them into periodic and non-periodic components. Then, machine learning and transfer learning are used to impute the periodic and non-periodic components, respectively. Furthermore, the effectiveness of the method is validated on artificially missing NO 2 and SO 2 concentration data from five regions of China. Comparison results show that the proposed method significantly outperforms some other imputation methods in the literature in terms of both mean absolute error and mean absolute percentage error. Finally, the proposed imputation method is applied in the study of accelerated aging of polycarbonate materials. Experimental results show that the predictive accuracy of the aging model is improved when using the imputed pollutant data.},
  archive      = {J_JOCS},
  author       = {Xinyi Wei and Hao Meng and Lizhen Shao and Dongmei Fu and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.jocs.2025.102697},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102697},
  shortjournal = {J. Comput. Sci.},
  title        = {A decomposition based imputation algorithm for long consecutive missing atmospheric pollution data and its application},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Helium focused ion beam damage in silicon: Physics-informed neural network modeling of helium bubble nucleation and early growth. <em>JOCS</em>, <em>92</em>, 102696. (<a href='https://doi.org/10.1016/j.jocs.2025.102696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the time and cost required to obtain large datasets limit the application of data-driven machine learning in nanoscale manufacturing. Here, we focus on predicting the nanoscale damage induced by helium focused ion beams (He-FIBs) on silicon substrates. We briefly review the most relevant atomistic defects and the partial differential equations (PDEs), or rate equations, that describe the mutual creation and annihilation of the defects, eventually leading to the amorphization of the substrate and, the nucleation and early growth of helium bubbles. The novelty comes from the use of a physics-informed neural network (PINN) to simulate quantitatively the evolution of the bubbles, thus bypassing the dataset availability problem. As usual, the proposed PINN learns the underlying physics through the incorporation of the residuals of the PDEs and corresponding Initial Conditions (ICs) and Boundary Conditions (BCs) in the network’s loss function. Meanwhile, the system of PDEs poses some challenges to the PINN modeling strategy. We find that (i) hard constraints need to be imposed on the network output in order to satisfy both BCs and ICs, (ii) all the inputs and outputs of the PINN need to be cautiously normalized to ensure convergence during training, and (iii) customized weights need to be carefully applied to all the PDE loss terms in order to balance their contributions, thus improving the accuracy of the PINN predictions. Once trained, the network achieves good prediction accuracy over the entire space-time domain for various ion beam energies and doses. Comparisons are provided against previous experiments and traditional numerical simulations, which are also implemented in this study using the Finite Difference Method (FDM). While the L2 relative errors for all collocated points remain below 10%, the accuracy of the PINN decreases at lower beam energies and larger ion doses, due to the presence of higher numerical gradients.},
  archive      = {J_JOCS},
  author       = {Shupeng Gao and Qi Li and M.A. Gosalvez and Xi Lin and Yan Xing and Zaifa Zhou and Qianhuang Chen},
  doi          = {10.1016/j.jocs.2025.102696},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102696},
  shortjournal = {J. Comput. Sci.},
  title        = {Helium focused ion beam damage in silicon: Physics-informed neural network modeling of helium bubble nucleation and early growth},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the dopant diffusion dynamics with physics-informed neural networks. <em>JOCS</em>, <em>92</em>, 102695. (<a href='https://doi.org/10.1016/j.jocs.2025.102695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation plays a crucial role in the semiconductor chip manufacturing. In particular, process simulation is primarily used to solve the dopant diffusion dynamics, which describes the temporal evolution of doping profiles during the thermal annealing process. The diffusion dynamics constitutes a multiscale problem, formulated as a set of coupled partial differential equations (PDEs) with respect to the concentration of dopants and point defects. In this paper, we demonstrate that Physics-Informed Neural Networks (PINNs) can accurately predict not only the evolution of the doping profile, but also the unknown physical parameters, specifically the diffusivities appearing as PDE coefficients. Furthermore, we propose a physics-informed calibration method, which performs PDE-constrained optimization by leveraging a pre-trained PINN model. We experimentally verify that this post-processing significantly improves the accuracy of coefficients fine-tuning. To the best of our knowledge, this is the first demonstration of an annealing simulation for the semiconductor diffusion process using a physics-informed machine learning approach. This framework is expected to enable more efficient calibration of simulation parameters based on measurement data.},
  archive      = {J_JOCS},
  author       = {Sungyeop Lee and Jisu Ryu and Young-Gu Kim and Dae Sin Kim and Hiroo Koshimoto and Jaeshin Park},
  doi          = {10.1016/j.jocs.2025.102695},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102695},
  shortjournal = {J. Comput. Sci.},
  title        = {Solving the dopant diffusion dynamics with physics-informed neural networks},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on pest control models based on nonlinear threshold control. <em>JOCS</em>, <em>92</em>, 102694. (<a href='https://doi.org/10.1016/j.jocs.2025.102694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pest number trigger threshold strategy has been widely used in the control of pests in agricultural production. In this study, pest populations are managed by using an integrated nonlinear threshold function and a saturation function. The existence conditions of various equilibrium points and sliding sections in the system are derived. Theoretical analysis and numerical simulation results show the existence of boundary equilibrium bifurcations, tangency bifurcations and limit cycle bifurcations caused by discontinuous boundary. It is worth noting that persistence and non-smooth folding can be observed in the boundary equilibrium bifurcations. At the same time, because the nonlinear threshold control strategy is adopted in this study, the change of the sliding section of the model is more complicated. The numerical simulation results show that if there is an unstable focus in the model, a sliding homoclinic cycle will appear with the occurrence of boundary saddle point bifurcation, and then form a crossing limit cycle. The sensitivity analysis results of the system show that if the threshold level is too low, the control measures do not achieve the desired results. Too high threshold selection will cause unnecessary economic losses. Therefore, our results show that an appropriate threshold should be set to reduce economic losses while ensuring that the number of pests is in a lower stable state.},
  archive      = {J_JOCS},
  author       = {Yongfeng Li and Leyan Liang and Zhong Zhao},
  doi          = {10.1016/j.jocs.2025.102694},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102694},
  shortjournal = {J. Comput. Sci.},
  title        = {A study on pest control models based on nonlinear threshold control},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private linear equation solving: An application to federated learning and extreme learning machines. <em>JOCS</em>, <em>92</em>, 102693. (<a href='https://doi.org/10.1016/j.jocs.2025.102693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, multiple devices compute each a part of a common machine learning model using their own private data. These partial models (or their parameters) are then exchanged in a central server that builds an aggregated model. This sharing process may leak information about the data used to train them. This problem intensifies as the machine learning model becomes simpler, indicating a higher risk for single-hidden-layer feedforward neural networks, such as extreme learning machines. In this paper, we establish a mechanism to disguise the input data to a system of linear equations while guaranteeing that the modifications do not alter the solutions, and propose two possible approaches to apply these techniques to federated learning. Our findings show that extreme learning machines can be used in federated learning with an extra security layer, making them attractive in learning schemes with limited computational resources.},
  archive      = {J_JOCS},
  author       = {Daniel Heinlein and Anton Akusok and Kaj-Mikael Björk and Leonardo Espinosa-Leal},
  doi          = {10.1016/j.jocs.2025.102693},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102693},
  shortjournal = {J. Comput. Sci.},
  title        = {Private linear equation solving: An application to federated learning and extreme learning machines},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BAHA: Binary artificial hummingbird algorithm for feature selection. <em>JOCS</em>, <em>92</em>, 102686. (<a href='https://doi.org/10.1016/j.jocs.2025.102686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Datasets classification accuracy depends on their features. The presence of irrelevant and redundant features in the dataset leads to the reduction of classification accuracy. Identifying and removing such features is the main purpose in feature selection, which is an important step in the data science lifecycle. The objective of the Wrapper feature selection method is to reduce the number of selected feature (NSF) while improving the classification accuracy by working on a set of features. The feature selection is a challenging and computationally expensive problem that falls under the NP-complete category, so it requires computationally cheap and efficient algorithm to solve it. The artificial hummingbird algorithm (AHA) is a biological inspired optimization technique that mimics the unique flight capabilities and intelligent foraging tactics of hummingbirds in nature. Since feature selection is inherently a binary problem. In this paper, the binary form of the AHA meta-heuristic algorithm is proposed to show that binarizing the AHA meta-heuristic algorithm improves its performance for solving feature selection problems. The proposed method is tested on a standard benchmark dataset and compared with four state-of-the-art feature selection algorithms: Automata-based improved equilibrium optimizer with U-shaped transfer function (AIEOU), Whale optimization approaches for wrapper feature selection (WOA-CM), Ring theory-based harmony search (RTHS), and Adaptive switching gray-whale optimizer (ASGW). The results show the effectiveness of the proposed algorithm in searching for optimal features subset. The source code for the algorithm being proposed is accessible to the public on https://github.com/alihamdipour/baha .},
  archive      = {J_JOCS},
  author       = {Ali Hamdipour and Abdolali Basiri and Mostafa Zaare and Seyedali Mirjalili},
  doi          = {10.1016/j.jocs.2025.102686},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102686},
  shortjournal = {J. Comput. Sci.},
  title        = {BAHA: Binary artificial hummingbird algorithm for feature selection},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joe">JOE - 7</h2>
<ul>
<li><details>
<summary>
(2025). Matrix-valued factor model with time-varying main effects. <em>JOE</em>, <em>252</em>, 106105. (<a href='https://doi.org/10.1016/j.jeconom.2025.106105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the matrix-valued time-varying Main Effects Factor Model (MEFM). MEFM is a generalization to the traditional matrix-valued factor model (FM). We give rigorous definitions of MEFM and its identifications, and propose estimators for the time-varying grand mean, row and column main effects, and the row and column factor loading matrices for the common component. Rates of convergence for different estimators are spelt out, with asymptotic normality shown. The core rank estimator for the common component is also proposed, with consistency of the estimators presented. As time series, the row and column main effects { α t } and { β t } can be non-stationary without affecting the estimation accuracy of our estimators. The number of main effects factors contributing to row or column main effects is also consistently estimated by our proposed estimators. We propose a test for testing if FM is sufficient against the alternative that MEFM is necessary, and demonstrate the power of such a test in various simulation settings. We also demonstrate numerically the accuracy of our estimators in extended simulation experiments. A set of NYC Taxi traffic data is analyzed and our test suggests that MEFM is indeed necessary for analyzing the data against a traditional FM.},
  archive      = {J_JOE},
  author       = {Clifford Lam and Zetai Cen},
  doi          = {10.1016/j.jeconom.2025.106105},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106105},
  shortjournal = {J. Econ.},
  title        = {Matrix-valued factor model with time-varying main effects},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonparametric regression under cluster sampling. <em>JOE</em>, <em>252</em>, 106102. (<a href='https://doi.org/10.1016/j.jeconom.2025.106102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a general asymptotic theory for nonparametric kernel regression in the presence of cluster dependence. We examine nonparametric density estimation, Nadaraya–Watson kernel regression, and local linear estimation. Our theory accommodates growing and heterogeneous cluster sizes. We derive asymptotic conditional bias and variance, establish uniform consistency, and prove asymptotic normality. Our findings reveal that under heterogeneous cluster sizes, the asymptotic variance includes a new term reflecting within-cluster dependence, which is overlooked when cluster sizes are presumed to be bounded. We propose valid approaches for bandwidth selection and inference, introduce estimators of the asymptotic variance, and demonstrate their consistency. In simulations, we verify the effectiveness of the cluster-robust bandwidth selection and show that the derived cluster-robust confidence interval improves the coverage ratio. We illustrate the application of these methods using a policy-targeting dataset in development economics.},
  archive      = {J_JOE},
  author       = {Yuya Shimizu},
  doi          = {10.1016/j.jeconom.2025.106102},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106102},
  shortjournal = {J. Econ.},
  title        = {Nonparametric regression under cluster sampling},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inference on model parameters with many L-moments. <em>JOE</em>, <em>252</em>, 106101. (<a href='https://doi.org/10.1016/j.jeconom.2025.106101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies parameter estimation using L-moments, an alternative to traditional moments with attractive statistical properties. The estimation of model parameters by matching sample L-moments is known to outperform maximum likelihood estimation (MLE) in small samples from popular distributions. The choice of the number of L-moments used in estimation remains ad-hoc , though: researchers typically set the number of L-moments equal to the number of parameters, which is inefficient in larger samples. In this paper, we show that, by properly choosing the number of L-moments and weighting these accordingly, one is able to construct an estimator that outperforms MLE in finite samples, and yet retains asymptotic efficiency. We do so by introducing a generalised method of L-moments estimator and deriving its properties in an asymptotic framework where the number of L-moments varies with sample size. We then propose methods to automatically select the number of L-moments in a sample. Monte Carlo evidence shows our approach can provide mean-squared-error improvements over MLE in smaller samples, whilst working as well as it in larger samples. We consider extensions of our approach to the estimation of conditional models and a class semiparametric models. We apply the latter to study expenditure patterns in a ridesharing platform in Brazil.},
  archive      = {J_JOE},
  author       = {Luis A.F. Alvarez and Chang Chiann and Pedro A. Morettin},
  doi          = {10.1016/j.jeconom.2025.106101},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106101},
  shortjournal = {J. Econ.},
  title        = {Inference on model parameters with many L-moments},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural periodic vector autoregressions. <em>JOE</em>, <em>252</em>, 106099. (<a href='https://doi.org/10.1016/j.jeconom.2025.106099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While seasonality inherent to raw macroeconomic data is commonly removed by seasonal adjustment techniques before it is used for structural inference, this may distort valuable information in the data. As an alternative method to commonly used structural vector autoregressions (SVARs) for seasonally adjusted data, we propose to model potential periodicity in seasonally unadjusted (raw) data directly by structural periodic vector autoregressions (SPVARs). This approach does not only allow for periodically time-varying intercepts, but also for periodic autoregressive parameters and innovations variances. As this larger flexibility leads to an increased number of parameters, we propose linearly constrained estimation techniques. Moreover, based on SPVARs, we provide two novel identification schemes and propose a general framework for impulse response analyses that allows for direct consideration of seasonal patterns. We provide asymptotic theory for SPVAR estimators and impulse responses under flexible linear restrictions and introduce a test for seasonality in impulse responses. For the construction of confidence intervals, we discuss several residual-based (seasonal) bootstrap methods and prove their bootstrap consistency under different assumptions. A real data application shows that useful information about the periodic structure in the data may be lost when relying on common seasonal adjustment methods.},
  archive      = {J_JOE},
  author       = {Daniel Dzikowski and Carsten Jentsch},
  doi          = {10.1016/j.jeconom.2025.106099},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106099},
  shortjournal = {J. Econ.},
  title        = {Structural periodic vector autoregressions},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Misspecification-robust bootstrap t-test for irrelevant factor in linear stochastic discount factor models. <em>JOE</em>, <em>252</em>, 106097. (<a href='https://doi.org/10.1016/j.jeconom.2025.106097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the applicability of the bootstrap approach to test for irrelevant risk factors that are potentially useless in misspecified linear stochastic discount factor (SDF) models. In the literature, the misspecification-robust inference with useless factors is known to give rise to nonstandard limiting distributions bounded stochastically to compute critical values. We show how and to what extent the wild bootstrap yields a more accurate approximation of the distribution of t -statistics when testing for an unpriced factor in the context of linear SDF models. Simulation experiments and empirical tests are also used to document the relevance of the bootstrap method.},
  archive      = {J_JOE},
  author       = {Antoine A. Djogbenou and Ulrich Hounyo},
  doi          = {10.1016/j.jeconom.2025.106097},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106097},
  shortjournal = {J. Econ.},
  title        = {Misspecification-robust bootstrap t-test for irrelevant factor in linear stochastic discount factor models},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On-line detection of changes in the shape of intraday volatility curves. <em>JOE</em>, <em>252</em>, 106089. (<a href='https://doi.org/10.1016/j.jeconom.2025.106089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise an on-line detector for temporal instability in the shape of average intraday volatility curves under a general semimartingale setup for the price-volatility dynamics. We adopt a block-based strategy to estimate volatility nonparametrically from the intraday observations over local time windows with asymptotically shrinking size. Our detector then tracks sequential changes in running means of the intraday volatility curve estimates. Asymptotic size and power properties of the detector follow from a weak form invariance principle, which is established under the strong mixing condition aligned with our semimartingale setup. Simulation and empirical results demonstrate good finite-sample performance of the proposed detection method.},
  archive      = {J_JOE},
  author       = {Torben G. Andersen and Yingwen Tan and Viktor Todorov and Zhiyuan Zhang},
  doi          = {10.1016/j.jeconom.2025.106089},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106089},
  shortjournal = {J. Econ.},
  title        = {On-line detection of changes in the shape of intraday volatility curves},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High dimensional factor analysis with weak factors. <em>JOE</em>, <em>252</em>, 106086. (<a href='https://doi.org/10.1016/j.jeconom.2025.106086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the principal components (PC) estimator for high dimensional approximate factor models with weak factors in that the factor loading ( Λ 0 ) scales sublinearly in the number N of cross-section units, i.e., Λ 0 ⊤ Λ 0 / N α is positive definite in the limit for some α ∈ ( 0 , 1 ) . While the consistency and asymptotic normality of these estimates are by now well known when the factors are strong, i.e., α = 1 , the statistical properties for weak factors remain less explored. Here, we show that the PC estimator maintains consistency and asymptotic normality for any α ∈ ( 0 , 1 ) , provided suitable conditions regarding the dependence structure in the noise are met. This complements earlier result by Onatski (2012) that the PC estimator is inconsistent when α = 0 , and the more recent work by Bai and Ng (2023) who established the asymptotic normality of the PC estimator when α ∈ ( 1 / 2 , 1 ) . Our proof strategy integrates the traditional eigendecomposition-based approach for factor models with leave-one-out analysis similar in spirit to those used in matrix completion and other settings. This combination allows us to deal with factors weaker than the former and at the same time relax the incoherence and independence assumptions often associated with the later.},
  archive      = {J_JOE},
  author       = {Jungjun Choi and Ming Yuan},
  doi          = {10.1016/j.jeconom.2025.106086},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106086},
  shortjournal = {J. Econ.},
  title        = {High dimensional factor analysis with weak factors},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joma">JOMA - 8</h2>
<ul>
<li><details>
<summary>
(2026). A novel martingale difference correlation via data splitting with applications in feature screening. <em>JOMA</em>, <em>211</em>, 105508. (<a href='https://doi.org/10.1016/j.jmva.2025.105508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel sample martingale difference correlation via data splitting to measure the departure of conditional mean independence between a response variable Y and a vector predictor X . The proposed correlation converges to zero and has an asymptotically symmetric sampling distribution around zero when Y and X are conditionally mean independent. In contrast, it converges to a positive value when Y and X are conditionally mean dependent. Leveraging these properties, we develop a new model-free feature screening method with false discovery rate (FDR) control for ultrahigh-dimensional data. We demonstrate that this screening method achieves FDR control and the sure screening property simultaneously. We also extend our approach to conditional quantile screening with FDR control. To further enhance the stability of the screening results, we implement multiple splitting techniques. We evaluate the finite sample performance of our proposed methods through simulations and real data analyses, and compare them with existing methods.},
  archive      = {J_JOMA},
  author       = {Zhengyu Zhu and Jicai Liu and Riquan Zhang},
  doi          = {10.1016/j.jmva.2025.105508},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105508},
  shortjournal = {J. Multi. Anal.},
  title        = {A novel martingale difference correlation via data splitting with applications in feature screening},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tree pólya splitting distributions for multivariate count data. <em>JOMA</em>, <em>211</em>, 105507. (<a href='https://doi.org/10.1016/j.jmva.2025.105507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop a new class of multivariate distributions adapted for count data, called Tree Pólya Splitting. This class results from the combination of a univariate distribution and singular multivariate distributions along a fixed partition tree. Known distributions, including the Dirichlet-multinomial, the generalized Dirichlet-multinomial and the Dirichlet-tree multinomial, are particular cases within this class. As we will demonstrate, these distributions offer some flexibility, allowing for the modeling of complex dependence structures (positive, negative, or null) at the observation level. Specifically, we present theoretical properties of Tree Pólya Splitting distributions by focusing primarily on marginal distributions, factorial moments, and dependence structures (covariance and correlations). A dataset of abundance of Trichoptera is used, on one hand, as a benchmark to illustrate the theoretical properties developed in this article, and on the other hand, to demonstrate the interest of these types of models, notably by comparing them to other approaches for fitting multivariate data, such as the Poisson-lognormal model in ecology or singular multivariate distributions used in microbial analysis.},
  archive      = {J_JOMA},
  author       = {Samuel Valiquette and Jean Peyhardi and Éric Marchand and Gwladys Toulemonde and Frédéric Mortier},
  doi          = {10.1016/j.jmva.2025.105507},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105507},
  shortjournal = {J. Multi. Anal.},
  title        = {Tree pólya splitting distributions for multivariate count data},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficiency of markov chains for bayesian linear regression models with heavy-tailed errors. <em>JOMA</em>, <em>211</em>, 105506. (<a href='https://doi.org/10.1016/j.jmva.2025.105506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider posterior simulation for a linear regression model when the error distribution is given by a scale mixture of multivariate normals. We first show that a sampler given in the literature for the case of the conditionally conjugate normal-inverse Wishart prior continues to be geometrically ergodic even when the error density is heavier-tailed. Moreover, we prove that the ergodicity is uniform by verifying the minorization condition. In the second half of this note, we treat an improper case and, using a simple energy function, show that a data augmentation algorithm in the literature is geometrically ergodic under a significantly different condition.},
  archive      = {J_JOMA},
  author       = {Yasuyuki Hamura},
  doi          = {10.1016/j.jmva.2025.105506},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105506},
  shortjournal = {J. Multi. Anal.},
  title        = {Efficiency of markov chains for bayesian linear regression models with heavy-tailed errors},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified selection consistency theorem for information criterion-based rank estimators in factor analysis. <em>JOMA</em>, <em>211</em>, 105498. (<a href='https://doi.org/10.1016/j.jmva.2025.105498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, numerous rank estimators for factor models have been proposed in the literature. This article focuses on information criterion-based rank estimators and investigates their consistency in rank selection. The gap conditions serve as necessary and sufficient conditions for rank estimators to achieve selection consistency under the general assumptions of random matrix theory. We establish a unified theorem on selection consistency, presenting the gap conditions for information criterion-based rank estimators with a unified formulation. To validate the theorem’s assertion that rank selection consistency is solely determined by the gap conditions, we conduct extensive numerical simulations across various settings. Additionally, we undertake supplementary simulations to explore the strengths and limitations of information criterion-based estimators by comparing them with other types of rank estimators.},
  archive      = {J_JOMA},
  author       = {Toshinari Morimoto and Hung Hung and Su-Yun Huang},
  doi          = {10.1016/j.jmva.2025.105498},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105498},
  shortjournal = {J. Multi. Anal.},
  title        = {A unified selection consistency theorem for information criterion-based rank estimators in factor analysis},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On nonparametric functional data regression with incomplete observations. <em>JOMA</em>, <em>211</em>, 105497. (<a href='https://doi.org/10.1016/j.jmva.2025.105497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider the problem of nonparametric estimation of a regression function m ( χ ) = E ( Y | χ = χ ) with the functional covariate χ when the response Y may be missing according to a missing-not-at-random (MNAR) setup, i.e., when the underlying missing probability mechanism can depend on both χ and Y . Our proposed estimator is based on a particular representation of the regression function m ( χ ) in terms of four associated conditional expectations that can be estimated nonparametrically. To assess the theoretical performance of our estimators, we study their convergence properties in general L p norms where we also look into their rates of convergence. Our numerical results show that the proposed estimators have good finite-sample performance. We also explore the applications of our results to the problem of statistical classification with missing labels and establish a number of convergence results for new kernel-type classification rules.},
  archive      = {J_JOMA},
  author       = {Majid Mojirsheibani},
  doi          = {10.1016/j.jmva.2025.105497},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105497},
  shortjournal = {J. Multi. Anal.},
  title        = {On nonparametric functional data regression with incomplete observations},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Matérn and generalized wendland correlation models that parameterize hole effect, smoothness, and support. <em>JOMA</em>, <em>211</em>, 105496. (<a href='https://doi.org/10.1016/j.jmva.2025.105496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A huge literature in statistics and machine learning is devoted to parametric families of correlation functions, where the correlation parameters are used to understand the properties of an associated spatial random process in terms of smoothness and global or compact support. However, most of current parametric correlation functions attain only non-negative values. This work provides two new families of correlation functions that can have some negative values (aka hole effects), along with smoothness, and global or compact support. They generalize the celebrated Matérn and Generalized Wendland models, respectively, which are obtained as special cases. A link between the two new families is also established, showing that a specific reparameterization of the latter includes the former as a special limit case. Their performance in terms of estimation accuracy and goodness of best linear unbiased prediction is illustrated through synthetic and real data.},
  archive      = {J_JOMA},
  author       = {Xavier Emery and Moreno Bevilacqua and Emilio Porcu},
  doi          = {10.1016/j.jmva.2025.105496},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105496},
  shortjournal = {J. Multi. Anal.},
  title        = {Matérn and generalized wendland correlation models that parameterize hole effect, smoothness, and support},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust semi-functional censored regression. <em>JOMA</em>, <em>211</em>, 105491. (<a href='https://doi.org/10.1016/j.jmva.2025.105491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a robust methodological framework for analyzing randomly censored responses within the semi-functional partial linear regression models, utilizing the exponential squared loss criterion. The proposed methodology capitalizes on the robustness of the exponential squared loss function against outliers and heavy-tailed error distributions, while preserving the flexibility and interpretability of semi-functional regression, which accommodates scalar and functional predictors in a unified framework. To account for the divergent convergence rates of the parametric and nonparametric components, we introduce a novel three-step estimation procedure designed to enhance computational efficiency, ensure model robustness, and achieve asymptotically optimal estimation performance. The parametric component is estimated through a quasi-Newton algorithm, for which we establish global convergence under standard regularity conditions using a Wolfe-type line search strategy. Additionally, we suggest a cross-validation criterion based on the exponential squared loss function to guide the data-driven selection of tuning parameters. The theoretical properties, including consistency and asymptotic normality of the proposed estimators, are established under mild conditions. The efficacy and robustness of the method are demonstrated through a series of simulation studies and an empirical application to Alzheimer’s disease progression, highlighting its practical applicability in addressing complex and censored data structures.},
  archive      = {J_JOMA},
  author       = {Tao Wang},
  doi          = {10.1016/j.jmva.2025.105491},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105491},
  shortjournal = {J. Multi. Anal.},
  title        = {Robust semi-functional censored regression},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical structure-guided high-dimensional multi-view clustering. <em>JOMA</em>, <em>211</em>, 105488. (<a href='https://doi.org/10.1016/j.jmva.2025.105488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data clustering is pivotal for comprehending the heterogeneous structure of data by integrating information from diverse aspects. Nevertheless, practical challenges arise due to the differences in the granularity from different views, resulting in a hierarchical clustering structure within these distinct data types. In this work, we consider such structure information and propose a novel high-dimensional multi-view clustering approach with a hierarchical structure across views. The proposed non-convex problem is effectively tackled using the Alternating Direction Method of Multipliers algorithm, and we establish the statistical properties of the estimator. Simulation results demonstrate the effectiveness and superiority of our proposed method. In the analysis of the histopathological imaging data and gene expression data related to lung adenocarcinoma, our method unveils a hierarchical clustering structure that significantly diverges from alternative approaches.},
  archive      = {J_JOMA},
  author       = {Jiajia Jiang and Kuangnan Fang and Shuangge Ma and Qingzhao Zhang},
  doi          = {10.1016/j.jmva.2025.105488},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105488},
  shortjournal = {J. Multi. Anal.},
  title        = {Hierarchical structure-guided high-dimensional multi-view clustering},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jomp">JOMP - 3</h2>
<ul>
<li><details>
<summary>
(2025). Experiment-based calibration in psychology: Foundational and data-generating model. <em>JOMP</em>, <em>127</em>, 102950. (<a href='https://doi.org/10.1016/j.jmp.2025.102950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experiment-based calibration is a novel method for measurement validation, which – unlike classical validity metrics – does not require stable between-person variance. In this approach, the latent variable to be measured is manipulated by an experiment, and its predicted scores – termed standard scores – are compared against the measured scores. Previous work has shown that under plausible boundary conditions, the correlation between standard and measured scores – termed retrodictive validity – is informative about measurement accuracy, i.e. combined trueness and precision. Here, I expand these findings in several directions. First, I formalise the approach in a probability-theoretic framework with the concept of a standardised calibration space. Second, I relate this framework to classical validity theory and show that the boundary conditions in fact apply to any form of criterion validity, including classical convergent validity. Thus, I state precise and empirically quantifiable boundary conditions under which criterion validity metrics are informative on validity. Third, I relate these boundary conditions to confounding variables, i.e. correlated latent variables. I show that in the limit, calibration will converge on the latent variable that is most closely related to the standard. Finally, I provide a framework for modelling the data-generating process with Markov kernels, and identify sufficient conditions under which the data generation model results in a calibration space. In sum, this article provides a formal probability-theoretic framework for experiment-based calibration and facilitates modelling and empirical assessment of the data generating processes.},
  archive      = {J_JOMP},
  author       = {Dominik R. Bach},
  doi          = {10.1016/j.jmp.2025.102950},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102950},
  shortjournal = {J. Math. Psychol.},
  title        = {Experiment-based calibration in psychology: Foundational and data-generating model},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On iverson’s law of similarity. <em>JOMP</em>, <em>127</em>, 102943. (<a href='https://doi.org/10.1016/j.jmp.2025.102943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iverson (2006b) proposed the law of similarity ξ s ( λ x ) = γ ( λ , s ) ξ η ( λ , s ) ( x ) for the sensitivity functions ξ s ( s ∈ S ) . Compared to the former models, the generality of this one lies in that here γ and η can also depend on the variables λ and s . In the literature, this model (or its special cases) is usually considered together with a given psychophysical representation (e.g. Fechnerian, subtractive, or affine). Our goal, however, is to study at first Iverson’s law of similarity on its own. We show that if certain mild assumptions are fulfilled, then ξ can be written in a rather simple form containing only one-variable functions. The obtained form proves to be very useful when we assume some kind of representation. Motivated by Hsu and Iverson (2016) , we then study the above model assuming that the mapping η is multiplicatively translational. First, we show how these mappings can be characterized. Later we turn to the examination of Falmagne’s power law. According to our results, the corresponding function ξ can have a Fechnerian representation, and also it can have a subtractive representation. We close the paper with the study of the shift invariance property.},
  archive      = {J_JOMP},
  author       = {Eszter Gselmann and Christopher W. Doble and Yung-Fong Hsu},
  doi          = {10.1016/j.jmp.2025.102943},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102943},
  shortjournal = {J. Math. Psychol.},
  title        = {On iverson’s law of similarity},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal analysis of absolute and relative risk reductions. <em>JOMP</em>, <em>127</em>, 102942. (<a href='https://doi.org/10.1016/j.jmp.2025.102942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any medical innovation must first prove its benefits with reliable evidence from clinical trials. Evidence is commonly expressed using two metrics, summarizing treatment benefits based on either absolute risk reductions (ARRs) or relative risk reductions (RRRs). Both metrics are derived from the same data, but they implement conceptually distinct ideas. Here, we analyze these risk reductions measures from a causal modeling perspective. First, we show that ARR is equivalent to Δ P , while RRR is equivalent to causal power, thus clarifying the implicit causal assumptions. Second, we show how this formal equivalence establishes a relationship with causal Bayes nets theory, offering a basis for incorporating risk reduction metrics into a computational modeling framework. Leveraging these analyses, we demonstrate that under dynamically varying baseline risks, ARRs and RRRs lead to strongly diverging predictions. Specifically, the inherent assumption of a linear parameterization of the underlying causal graph can lead to incorrect conclusions when generalizing treatment benefits (e.g, predicting the effect of a vaccine in new populations with different baseline risks). Our analyses highlight the shared principles underlying risk reduction metrics and measures of causal strength, emphasizing the potential for explicating causal structure and inference in medical research.},
  archive      = {J_JOMP},
  author       = {Björn Meder and Charley M. Wu and Felix G. Rebitschek},
  doi          = {10.1016/j.jmp.2025.102942},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102942},
  shortjournal = {J. Math. Psychol.},
  title        = {Causal analysis of absolute and relative risk reductions},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jpdc">JPDC - 1</h2>
<ul>
<li><details>
<summary>
(2026). A scalable tensor-based MDTW approach for multi-modal time series patterns clustering. <em>JPDC</em>, <em>207</em>, 105173. (<a href='https://doi.org/10.1016/j.jpdc.2025.105173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal Time Series (MTS) is a vital ingredient to Predictive Multi-modal Artificial Intelligence (PMAI). MTS systems capture varying temporal modalities and their inherent dependencies for their accurate analytics. However, efficiently exploring these cross-modalities relationships is a challenging research due to their complexity facets and information redundancies. MTS patterns' pairwise similarity measures precede PMAI. Multi-modal Dynamic Time Warping (MDTW) is frequently explored to quantify similar MTS. Yet, it's reliant on the orthogonal conditioned local similarity measures that ignore the contributions of MTS' underlying structural relationships in the warping process and, hence, susceptible to unrealistic matching. This paper addresses the setbacks by recommending a scalable MTS recognition model, named Tensor-Slices Distance (TSD)-based MDTW (TSD-MDTW), that's subsequently advanced to two more distinct models termed Weighted modality and TSD (WmTSD-MDTW) and TSD-Mahalanobis (TSDMaha-MDTW). To quantify an alignment's cost, TSD-MDTW incorporates intrinsic spatial dependencies between modalities' coordinates, while WmTSD-MDTW relaxes information redundancies through weighing modalities based on information richness, whereas TSDMaha-MDTW embodies modalities dependencies and their coordinates' innate spatial dependencies. Besides, it proposes a scalable Tensor-based DTW (TDTW) model that re-formulates MDTW into multiple dimensions that are found paralleling warping processes. Theoretical and empirical experimental results on MTS multi-modal datasets encompassing load patterns and meteorological modalities reveal TDTW's efficiency and proposals' superior performances in terms of cluster compactness and separation over MDTW employing the state-of-the-art local similarity measures.},
  archive      = {J_JPDC},
  author       = {Bahati Alam Sanga and Laurence T. Yang and Shunli Zhang and Zecan Yang and Nicholaus Gati},
  doi          = {10.1016/j.jpdc.2025.105173},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {1},
  pages        = {105173},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {A scalable tensor-based MDTW approach for multi-modal time series patterns clustering},
  volume       = {207},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jtb">JTB - 11</h2>
<ul>
<li><details>
<summary>
(2026). Adaptive dynamic resource allocation can cause tragedy of the commons in plants with nutrient competition. <em>JTB</em>, <em>616</em>, 112279. (<a href='https://doi.org/10.1016/j.jtbi.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plants exhibit plastic responses to the absence or presence of competitors. When competing for soil nutrients, plants often show root overproliferation compared to when they grow without competitors. This excessive investment in roots to acquire more nutrients can reduce reproductive yield (e.g., seed mass), a phenomenon known as the tragedy of the commons (TOC). The mechanisms of this phenomenon have been investigated theoretically, focusing on resource allocation strategies between the aboveground (shoot) and the belowground (roots) parts. The previous studies have primarily considered these strategies in terms of sizes of those parts or static allocation rates to those over the season, overlooking dynamic change of allocation within the season. In this study, we introduced a concept of dynamic resource allocation into the plant competition game and investigate the optimal resource allocation strategy using Pontryagin’s maximum principle. Based on the solutions of schedules, we explored the mechanism causing TOC in nutrient competition. Our findings reveal that plants adopt the singular control (i.e., simultaneous allocation to shoot and root), where the control trajectory is identical regardless of the presence or absence of competitors, although the period of simultaneous allocation become longer in the presence of competitors. This trend associates with increasing the root size and decreasing the shoot size at the end of season in the competitive case. Our analysis demonstrates that TOC in plant nutrient competition arises from differences in the allocation period to roots in the competitive scenario.},
  archive      = {J_JTB},
  author       = {Bo-Moon Kim and Atsushi Yamauchi},
  doi          = {10.1016/j.jtbi.2025.112279},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112279},
  shortjournal = {J. Theor. Biol},
  title        = {Adaptive dynamic resource allocation can cause tragedy of the commons in plants with nutrient competition},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gaussian process modelling of infectious diseases using the greta software package and GPUs. <em>JTB</em>, <em>616</em>, 112278. (<a href='https://doi.org/10.1016/j.jtbi.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian process are a widely-used statistical tool for conducting non-parametric inference in applied sciences, with many computational packages available to fit to data and predict future observations. We study the use of the Greta software for Bayesian inference to apply Gaussian process regression to spatio-temporal data of infectious disease outbreaks and predict future outbreaks. Greta builds on Tensorflow, making it comparatively easy to take advantage of the significant gain in speed offered by GPUs. In these complex spatio-temporal models, we show a reduction of up to 70% in computational time relative to fitting the same models on CPUs. We show how the choice of covariance kernel impacts the ability to infer spread and extrapolate to unobserved spatial and temporal units. The inference pipeline is applied to weekly incidence data on tuberculosis in the East and West Midlands regions of England over a period of two years.},
  archive      = {J_JTB},
  author       = {Eva Gunn and Nikhil Sengupta and Ben Swallow},
  doi          = {10.1016/j.jtbi.2025.112278},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112278},
  shortjournal = {J. Theor. Biol},
  title        = {Gaussian process modelling of infectious diseases using the greta software package and GPUs},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Effective decoupling of mutations and the resulting loss of biodiversity caused by environmental change. <em>JTB</em>, <em>616</em>, 112277. (<a href='https://doi.org/10.1016/j.jtbi.2025.112277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many biological populations exhibit diversity in their strategy for survival and reproduction in a given environment, and microbes are an example. We explore the fate of different strategies under sustained environmental change by considering a mathematical model for a large population of asexual organisms. Fitness is a bimodal function of a quantitative trait, with two local optima, separated by a local minimum, i.e., a mixture of stabilising and disruptive selection. The optima represent two locally ‘best’ trait values. We consider regimes where, when the environment is unchanging, the equilibrium distribution of the trait is bimodal. A bimodal trait distribution generally requires, for its existence, mutational coupling between the two peaks, and it indicates two coexisting clones with distinct survival and reproduction strategies. When subject to persistent environmental change, the population adapts by utilising mutations that allow it to track the changing environment. The faster the rate of change of the environment, the larger the effect of the mutations that are utilised. Under persistent environmental change, the distribution of trait values takes two different forms. At low rates of change, the distribution remains bimodal. At higher rates, the distribution becomes unimodal. This loss of a clone/biodiversity is driven by a novel mechanism where environmental change decouples a class of mutations.},
  archive      = {J_JTB},
  author       = {Ruixi Huang and David Waxman},
  doi          = {10.1016/j.jtbi.2025.112277},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112277},
  shortjournal = {J. Theor. Biol},
  title        = {Effective decoupling of mutations and the resulting loss of biodiversity caused by environmental change},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A kinetic study of multi-substrate uniporters. <em>JTB</em>, <em>616</em>, 112267. (<a href='https://doi.org/10.1016/j.jtbi.2025.112267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transporters play key roles in regulating the movement of molecules into and out of cells. Uniporters, the simplest class of transporters, use facilitated diffusion to translocate molecules across membranes down their concentration gradient. This process can be affected by the presence of additional substrates in the intra- and extracellular environment, which can either increase the net transport rate of a molecule via trans acceleration or decrease it via competitive inhibition. In this study, we derived mathematical models to describe the net transport rate of uniporters in the presence of multiple extracellular substrates or inhibitors. Analyses of these models identified four possible states for the system when two substrates are present, with two states leading to trans acceleration and the other two states resulting in inhibition. Finally, we found that the relation between kinetic constants that controls the fraction of transporters in the inward-facing open state is responsible for these behaviors. Our theoretical results provide a mathematical framework for understanding the dynamic response of uniporters in the presence of multiple substrates and inhibitors, which could have implications for various processes, from nutrient utilization to metabolic engineering.},
  archive      = {J_JTB},
  author       = {Ana S. de Pereda and Jihyun Park and Lily S. Cheung},
  doi          = {10.1016/j.jtbi.2025.112267},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112267},
  shortjournal = {J. Theor. Biol},
  title        = {A kinetic study of multi-substrate uniporters},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Drug-loaded nanoparticles for cancer therapy: A high-throughput multicellular agent-based modeling study. <em>JTB</em>, <em>616</em>, 112266. (<a href='https://doi.org/10.1016/j.jtbi.2025.112266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactions between biological systems and engineered nanomaterials have become an important area of study due to their application in medicine. In particular, the opportunity to apply nanomaterials for cancer diagnosis and treatment presents a challenge due to the complex biology of this disease, which spans multiple time and spatial scales. A systems-level analysis from mathematical modeling and computational simulation to explore the interactions between anticancer drug-loaded nanoparticles (NPs), cells, and tissues, and the associated system parameters and patient response would be of benefit. Although a number of models have explored these interactions in the past, few have focused on simulating individual cell-NP interactions. This study develops a multicellular agent-based model of cancer nanotherapy that simulates NP internalization, drug release within the cell cytoplasm, inheritance of NPs by daughter cells at cell division, cell pharmacodynamic response to intracellular drug levels, and overall drug effect on tumor growth. A large-scale parallel computational framework is used to investigate the impact of pharmacokinetic design parameters (NP internalization rate, NP decay rate, anticancer drug release rate) and therapeutic strategies (NP doses and injection frequency) on tumor growth. In particular, through the exploration of NP inheritance at cell division, the results indicate that cancer treatment may be improved when NPs are inherited at cell division for cytotoxic chemotherapy. Moreover, smaller dose of cytostatic chemotherapy may also improve inhibition of tumor growth when cell division is not completely inhibited. This work suggests that slow delivery by heritable NPs can drive new dimensions of nanotherapy design for more sustained therapeutic response.},
  archive      = {J_JTB},
  author       = {Yafei Wang and John Metzcar and Elmar Bucher and Heber L. Rocha and Vikram Jadhao and Randy Heiland and Hermann B. Frieboes and Paul Macklin},
  doi          = {10.1016/j.jtbi.2025.112266},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112266},
  shortjournal = {J. Theor. Biol},
  title        = {Drug-loaded nanoparticles for cancer therapy: A high-throughput multicellular agent-based modeling study},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stably encoding phylogenetic trees with folios of leaf addresses. <em>JTB</em>, <em>616</em>, 112265. (<a href='https://doi.org/10.1016/j.jtbi.2025.112265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As genome sequencing data continue to expand, a persistent research challenge is to accommodate the growth of a phylogeny. This situation arises in molecular epidemiology, for example, where new taxonomic groups can appear in real time as pathogen isolates are sequenced. Efficient computational methods have been developed to place new leaves in existing trees, which removes the need to reconstruct trees from scratch. But for these tree extensions to be fully integrated with classification schemes requires a stable encoding of trees that keeps existing tree structures intact as new branches appear. Here, we propose a tree encoding, which we call a folio , that records the path from a reference vertex to each leaf, giving each leaf an address . We present a simple set of rules to assign new addresses to added leaves. The encoding is stable in the sense that it does not change as further leaf addresses are added to the folio. The tree can be uniquely recovered from a folio of addresses. We illustrate the methods using Salmonella genome data. Due to the properties of our encoding framework, we anticipate that it can be used for a range of different phylogenetic analyses.},
  archive      = {J_JTB},
  author       = {Mark M. Tanaka and Ruiting Lan and Andrew R. Francis},
  doi          = {10.1016/j.jtbi.2025.112265},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112265},
  shortjournal = {J. Theor. Biol},
  title        = {Stably encoding phylogenetic trees with folios of leaf addresses},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Phenomenological modeling of gene transcription by approximating cooperativity of transcription factors improves prediction and reduces complexity in gene regulatory network models. <em>JTB</em>, <em>616</em>, 112264. (<a href='https://doi.org/10.1016/j.jtbi.2025.112264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several computational models are available for representing the gene expression process, with each having their advantages and disadvantages. Phenomenological models are widely used as they make appropriate simplifications that aim to find a middle ground between accuracy and complexity. The existing phenomenological models compete in terms of how the transcription initiation process is approximated, to achieve high accuracy while having the lowest complexity possible. However, most current models still suffer from high parameter complexity in the case of complex promoters. Herein, we formally derive a phenomenological approach to model RNA polymerase recruitment, stating approximations on cooperativity between transcription factors that are applicable to promoters requiring multifactorial input, which reduces parameter complexity. We then apply this method to biologically relevant networks of varying complexities to show that the approximations improved predictive ability compared to existing models. In summary, our reduced parameter model (RPM) had lower complexity while maintaining high accuracy, which leads to better scalability for complex networks.},
  archive      = {J_JTB},
  author       = {Thiruvickraman Jothiprakasam and Siddharth Jhunjhunwala},
  doi          = {10.1016/j.jtbi.2025.112264},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112264},
  shortjournal = {J. Theor. Biol},
  title        = {Phenomenological modeling of gene transcription by approximating cooperativity of transcription factors improves prediction and reduces complexity in gene regulatory network models},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mathematical model suggests current CAR-macrophage dosage is efficient to low pre-infusion tumour burden but refractory to high tumour burden. <em>JTB</em>, <em>616</em>, 112263. (<a href='https://doi.org/10.1016/j.jtbi.2025.112263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chimeric antigen receptor (CAR)-macrophage therapy is a promising approach for tumour treatment due to antigen-specific phagocytosis and tumour clearance. However, the precise impact of tumour burden, dose and dosing regimens on therapeutic outcomes remains poorly understood. We developed ordinary differential equation (ODE) mathematical modelling and utilised parameter inference to analyse in vitro FACS-based phagocytosis assay data testing CD19-positive Raji tumour cell against CAR-macrophage, and revealed that phagocytosing efficiency of CAR-macrophage increases but saturates as both Raji cell and CAR-macrophage concentrations increase. This interaction resulted in bistable Raji cell kinetics; specifically, within a particular range of CAR-macrophage concentration, low tumour burdens are effectively inhibited, while high tumour burdens remain refractory. Furthermore, our model predicted that CAR-macrophage dosages typically suggested by current clinical trials yield favourable therapeutic outcomes only when tumour burden is low. For split CAR-macrophage infusion with fixed total dosage, the first infusion with high CAR-macrophage dose delivers superior treatment outcomes. Finally, we identified alternative infusion regimens: five billion cells administered monthly for three months, or seven billion cells every two months for six months, can efficiently suppress Raji cell replication irrespective of tumour burden. Our findings highlight CAR-macrophage therapeutic outcomes are strongly influenced by both tumour burden and different dosing regimens. This work underscores that reducing tumour burden, increasing CAR-macrophage dose in the first infusion and prolonging CAR-macrophage persistence are key strategies for achieving durable responses.},
  archive      = {J_JTB},
  author       = {Shilian Xu and Maoxuan Liu},
  doi          = {10.1016/j.jtbi.2025.112263},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112263},
  shortjournal = {J. Theor. Biol},
  title        = {Mathematical model suggests current CAR-macrophage dosage is efficient to low pre-infusion tumour burden but refractory to high tumour burden},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergent microtubule properties in a model of filament turnover and nucleation. <em>JTB</em>, <em>616</em>, 112254. (<a href='https://doi.org/10.1016/j.jtbi.2025.112254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microtubules (MTs) are dynamic protein filaments essential for intracellular organization and transport, particularly in long-lived cells such as neurons. The plus and minus ends of neuronal MTs switch between growth and shrinking phases, and the nucleation of new filaments is believed to be regulated in both healthy and injury conditions. We propose stochastic and deterministic mathematical models to investigate the impact of filament nucleation and length-regulation mechanisms on emergent properties such as MT lengths and numbers in living cells. We expand our stochastic continuous-time Markov chain model of filament dynamics to incorporate MT nucleation and capture realistic stochastic fluctuations in MT numbers and tubulin availability. We also propose a simplified partial differential equation (PDE) model, which allows for tractable analytical investigation into steady-state MT distributions under different nucleation and length-regulating mechanisms. We find that the stochastic and PDE modeling approaches show good agreement in MT length distributions, and that both MT nucleation and the catastrophe rate of large-length MTs regulate MT length distributions. In both frameworks, multiple mechanistic combinations achieve the same average MT length. The models proposed can predict parameter regimes where the system is scarce in tubulin, the building block of MTs, and suggest that low filament nucleation regimes are characterized by high variation in MT lengths, while high nucleation regimes drive high variation in MT numbers. These mathematical frameworks have the potential to improve our understanding of MT regulation in both healthy and injured neurons.},
  archive      = {J_JTB},
  author       = {Anna C. Nelson and Scott A. McKinley and Melissa M. Rolls and Maria-Veronica Ciocanel},
  doi          = {10.1016/j.jtbi.2025.112254},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112254},
  shortjournal = {J. Theor. Biol},
  title        = {Emergent microtubule properties in a model of filament turnover and nucleation},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modelling phylogeny in 16S rRNA gene sequencing datasets using string-based kernels. <em>JTB</em>, <em>616</em>, 112249. (<a href='https://doi.org/10.1016/j.jtbi.2025.112249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bacterial microbiome is increasingly being recognised as a key factor in human health, driven in large part by datasets collected using 16S rRNA (ribosomal ribonucleic acid) gene sequencing, which enable cost-effective quantification of the composition of an individual’s bacterial community. One of the defining characteristics of 16S rRNA datasets is the evolutionary relationships that exist between taxa (phylogeny). Here, we demonstrate the utility of modelling these phylogenetic relationships in two statistical tasks (the two sample test and host trait prediction) and propose a novel family of kernels for analysing microbiome datasets by leveraging string kernels from the natural language processing literature. We show via simulation studies that a kernel two-sample test using the proposed kernel is sensitive to the phylogenetic scale of the difference between the two populations. In a second set of simulations we also show how Gaussian process modelling with string kernels can infer the distribution of bacterial-host effects across the phylogenetic tree and apply this approach to a real host-trait prediction task. The results in the paper can be reproduced by running the code at https://github.com/jonathanishhorowicz/modelling_phylogeny_in_16srrna_using_string_kernels .},
  archive      = {J_JTB},
  author       = {Jonathan Ish-Horowicz and Sarah Filippi},
  doi          = {10.1016/j.jtbi.2025.112249},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112249},
  shortjournal = {J. Theor. Biol},
  title        = {Modelling phylogeny in 16S rRNA gene sequencing datasets using string-based kernels},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Approximate bayesian computation for markovian binary trees in phylogenetics. <em>JTB</em>, <em>616</em>, 112246. (<a href='https://doi.org/10.1016/j.jtbi.2025.112246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phylogenetic trees describe the relationships between species in the evolutionary process, and provide information about the rates of diversification. To understand the mechanisms behind macroevolution, we consider a class of multitype branching processes called Markovian binary trees (MBTs). MBTs allow for trait-based variation in diversification rates, and provide a flexible and realistic probabilistic model for phylogenetic trees. We develop an approximate Bayesian computation (ABC) scheme to infer the rates of MBT parameters by exploiting the information in the shapes of phylogenetic trees. We evaluate the accuracy of this inference method using simulation studies, and find that our method is able to detect variation in the diversification rates, with accuracy comparable to, and generally better than, likelihood-based methods. In an application to a real-life phylogeny of squamata, we reinforce conclusions drawn from earlier studies, in particular supporting the existence of ovi-/viviparity transitions in both directions. Our method demonstrates the potential for more complex models of evolution to be employed in phylogenetic inference, in conjunction with likelihood-free schemes.},
  archive      = {J_JTB},
  author       = {Mingqi He and Sophie Hautphenne and Yao-ban Chan},
  doi          = {10.1016/j.jtbi.2025.112246},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112246},
  shortjournal = {J. Theor. Biol},
  title        = {Approximate bayesian computation for markovian binary trees in phylogenetics},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="kbs">KBS - 77</h2>
<ul>
<li><details>
<summary>
(2025). Heterogeneous graph collaborative representation learning for drug-related microbe prediction with attentive fusion and reciprocal distillation. <em>KBS</em>, <em>330</em>, 114548. (<a href='https://doi.org/10.1016/j.knosys.2025.114548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microbes are microorganisms with biological molecules and have significant therapeutic potential for treating diseases, underscoring the need for computational methods to screen microbes targeting disease-associated drugs. However, the computational methods often consider node embedding or structure features between microbes and drugs, and have a severe class imbalance problem inherent in sparse association data. In this work, we proposed a heterogeneous graph collaborative representation learning model that combines the merits of attentive fusion and reciprocal distillation for drug-related microbe prediction. First, we constructed the heterogeneous biological information and meta-path-induced graphs of microbes and drugs. Then, a topological structure feature encoder is devised to extract complex topological and semantic interaction patterns from heterogeneous biological graphs with microbes and drugs, while an efficient transformer concurrently extracts discriminative semantic and structural information based on the graph position information of nodes. Next, a reciprocal distillation schema is developed to mitigate the adverse effects of the data imbalance problem, and enable the distribution consistency of the model between topological and semantic information extraction. Moreover, we devised a dual collaborative feature fusion schema that combines graph topological and dual meta-path-based semantic features to obtain the discriminative features of microbes and drugs. Through reciprocal distillation, an efficient optimization function focuses on hard-to-classify samples of drug-related microbes via discriminative features. Extensive experiments demonstrate that our model could deal with the association sparsity problem and extract more semantics and structure. Meanwhile, case studies indicate that our model could discover reliable candidate microbes associated with a special drug.},
  archive      = {J_KBS},
  author       = {Yanbu Guo and Quanming Guo and Shengli Song and Yihan Wang and Jinde Cao},
  doi          = {10.1016/j.knosys.2025.114548},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114548},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterogeneous graph collaborative representation learning for drug-related microbe prediction with attentive fusion and reciprocal distillation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic pick-up point recommendation with multi-modal deep forest and incentive-based adaptive kuhn-munkres algorithm. <em>KBS</em>, <em>330</em>, 114543. (<a href='https://doi.org/10.1016/j.knosys.2025.114543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendations for optimal pick-up points significantly enhance service efficiency, reduce economic and temporal costs, and alleviate traffic congestion. However, spatiotemporal imbalance between ride-hailing supply and passenger demand presents significant challenges. Current models often overlook critical influencing factors such as passenger satisfaction, travel environment, and travel cost factors. Moreover, solution algorithms, including exact algorithms and heuristics, struggle to achieve global optimality and computational efficiency in large-scale scenarios. This study introduces a comprehensive mathematical model that incorporates four key influencing factors: passenger walking distance, passenger waiting time, traffic conditions, and estimated ride-hailing fare. The solution approach consists of a novel pick-up point evaluation algorithm and an incentive-based adaptive Kuhn-Munkres matching algorithm. The evaluation algorithm employs a multi-modal decision tree structure, enhanced by deep learning techniques to improve the accuracy of pick-up point evaluations. The matching algorithm features a multi-scenario adaptive mechanism that dynamically adjusts edge weights and selects optimal edges for augmentation under various conditions and strategies, thereby ensuring globally optimal matching of passengers and pick-up points. Extensive experiments on large-scale real-world datasets validate the superior performance of the evaluation and matching algorithms, especially in handling large-scale instances. The developed model and algorithms assist ride-hailing platforms in optimizing operations, enhancing service quality, increasing profitability, and improving cost management.},
  archive      = {J_KBS},
  author       = {Yuhan Guo and Rushi Zhu and Wenhua Li and Youssef Boulaksil and Hamid Allaoui},
  doi          = {10.1016/j.knosys.2025.114543},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114543},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic pick-up point recommendation with multi-modal deep forest and incentive-based adaptive kuhn-munkres algorithm},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multi-modal document distillation with energy-weighted supervision. <em>KBS</em>, <em>330</em>, 114542. (<a href='https://doi.org/10.1016/j.knosys.2025.114542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As large multi-modal document models (e.g. LayoutLMv3) grow increasingly complex, knowledge distillation (KD) has become essential for practical deployment. EnergyKD enhances conventional logit-based KD by adjusting temperature per sample using energy scores. However, it still misleads students when teacher predictions are incorrect on high energy (i.e. low confidence) inputs. Although High-Energy Data Augmentation (HE- DA) is introduced to address this issue, it adds significant training overhead. In this work, we propose Energy-Weighted Supervision (EWS), a general-purpose supervision augmentation framework that builds upon an energy-based sample stratification mechanism. EWS dynamically adjusts the balance between hard-label and soft-label losses according to each sample’s energy score, thereby increasing the likelihood that the student model receives accurate and corrective supervision, without requiring additional data augmentation or training overhead. Our experiments demonstrate that EWS effectively improves the performance of various KD methods. On the harder FUNSD benchmark, EWS yields the largest gains (+2.35 F1), while on CORD and SROIE the improvements are smaller but consistently positive (up to +0.84 and +0.11 F1, respectively), confirming broad applicability across KD paradigms. Especially, when applied to EnergyKD, EWS addresses its core limitation, namely, the misleading influence of sharpened teacher outputs on high energy samples, by allocating greater weight to hard-label signals. Conversely, for low energy samples, EWS preserves soft-label emphasis to fully exploit the teacher’s informative predictions. Compared to conventional logit-based KD, EnergyKD, and even HE-DA, our energy-guided loss modulation approach consistently improves student performance across multiple documents understanding benchmarks, without additional training cost. To the best of our knowledge, this is the first framework in multi-modal document distillation that simultaneously integrates energy-aware temperature scaling and dynamic supervision weighting, offering a promising direction for future research and deployment on resource-limited devices.},
  archive      = {J_KBS},
  author       = {Jen-Chun Chang and Chia-Cheng Lee and Chung-Fu Lu and Victor R.L. Shen},
  doi          = {10.1016/j.knosys.2025.114542},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114542},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing multi-modal document distillation with energy-weighted supervision},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A topology-aware multiscale feature fusion network for EEG-based motor imagery decoding. <em>KBS</em>, <em>330</em>, 114540. (<a href='https://doi.org/10.1016/j.knosys.2025.114540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery electroencephalography (MI-EEG) decoding is a crucial component of brain-computer interface (BCI) systems, serving as a valuable tool for motor function rehabilitation and fundamental neuroscience research. However, the strong nonlinearity and non-stationarity of MI-EEG signals make achieving high-precision decoding a challenging task. Current deep learning methods primarily extract the spatiotemporal features of MI-EEG signals while neglecting their potential association with spectral-topological features, thereby limiting the ability to integrate multidimensional information. To address these limitations, this paper proposes a Topology-Aware Multiscale Feature Fusion network (TA-MFF network) for MI-EEG signal decoding. Specifically, we designed a Spectral-Topological Data Analysis-Processing (S-TDA-P) module that leverages persistent homology features to analyze the spatial topological relationships between EEG electrodes and the persistent patterns of neural activity. Then, the Inter Spectral Recursive Attention (ISRA) mechanism is employed to model the correlations between different frequency bands, enhancing critical spectral features while suppressing irrelevant noise. Finally, the Spectral-Topological and Spatio-Temporal Feature Fusion (SS-FF) Unit is employed to progressively integrate topological, spectral, and spatiotemporal features, capturing dependencies across different domains. The experimental results show that the classification accuracy of the proposed model in BCIC-IV-2a, BCIC-IV-2b, and BCIC-III-Iva is 85.87 %, 90.2 %, and 80.5 %, respectively, outperforming the most advanced methods.},
  archive      = {J_KBS},
  author       = {Chaowen Shen and Akio Namiki},
  doi          = {10.1016/j.knosys.2025.114540},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114540},
  shortjournal = {Knowl. Based Syst.},
  title        = {A topology-aware multiscale feature fusion network for EEG-based motor imagery decoding},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective embedding for deep learning. <em>KBS</em>, <em>330</em>, 114535. (<a href='https://doi.org/10.1016/j.knosys.2025.114535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has revolutionized many industries by enabling models to automatically learn complex patterns from raw data, reducing dependence on manual feature engineering. However, deep learning algorithms are sensitive to input data, and performance often deteriorates under nonstationary conditions and across dissimilar domains, especially when using time-domain data. Conventional single-channel or parallel multi-source data loading strategies either limit generalization or increase computational costs. This study introduces selective embedding, a novel data loading strategy, which alternates short segments of data from multiple sources within a single input channel. Drawing inspiration from cognitive psychology, selective embedding mimics human-like information processing to reduce model overfitting, enhance generalization, and improve computational efficiency. Validation is conducted using six time-domain datasets, demonstrating that the proposed method consistently achieves high classification accuracy for many deep learning architectures while significantly reducing training times. Across multiple datasets, selective embedding consistently improves test accuracy by 20 to 30 percent compared to traditional single-channel loading strategies, while also matching or exceeding the performance of parallel multi-source loading methods. Importantly, these gains are achieved while significantly reducing training times, demonstrating both efficiency and scalability across simple and complex architectures. The approach proves particularly effective for complex systems with multiple data sources, offering a scalable and resource-efficient solution for real-world applications in healthcare, heavy machinery, marine, railway, and agriculture, where robustness and adaptability are critical.},
  archive      = {J_KBS},
  author       = {Mert Sehri and Zehui Hua and Francisco de Assis Boldt and Patrick Dumond},
  doi          = {10.1016/j.knosys.2025.114535},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114535},
  shortjournal = {Knowl. Based Syst.},
  title        = {Selective embedding for deep learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequence-aware adaptive graph convolutional recurrent networks for traffic forecasting. <em>KBS</em>, <em>330</em>, 114533. (<a href='https://doi.org/10.1016/j.knosys.2025.114533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is a crucial task for the Intelligent Transportation System (ITS). A promising research direction for improving traffic prediction is to learn dynamic graph structures incorporating the hidden dependencies from the training sequence data. However, existing works optimize these dynamic graph structures only for the training data, regarding them as static when testing with new input sequences. This constrains the forecasting model’s ability to address potential discrepancies between training and testing sequences, which may arise from unforeseen changes in the traffic environment. To address this challenge, we propose a new encoder-decoder framework for traffic forecasting, S equence-aware Adaptive Graph Convolutional Recurrent Networks ( SAGCRN ). The encoder augments an input sequence by exploiting spatio-temporal contexts and traffic pattern storage. Then, the decoder adaptively learns a new graph structure reflecting the augmented input sequence and uses it for prediction. To further enhance the sequence-specialized graph structure, SAGCRN optimizes the stored traffic patterns to be more discriminative. We demonstrate the superior performance of SAGCRN on three real-world benchmark datasets, comparing it with nine baseline models. The additional sensitivity and qualitative analyses substantiate the effectiveness of our model. For reproducibility, the source code is available at https://github.com/gooriiie/SAGCRN .},
  archive      = {J_KBS},
  author       = {Seunghoon Han and Hyewon Lee and Daniel Y. Lee and Sung-Soo Kim and Susik Yoon and Sungsu Lim},
  doi          = {10.1016/j.knosys.2025.114533},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114533},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequence-aware adaptive graph convolutional recurrent networks for traffic forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The parallel visual perception network based on nonlinear spiking neural p systems for camouflaged object detection. <em>KBS</em>, <em>330</em>, 114532. (<a href='https://doi.org/10.1016/j.knosys.2025.114532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous species have evolved camouflage through morphological adaptations that mimic environmental colors and textures, posing significant challenges for visual detection systems. Current camouflaged object detection (COD) methods remain limited in simulating biological visual mechanisms due to inadequate multi-stage cognitive modeling and weak biological correspondence in neural computations. To address these limitations, a parallel visual perception network (NSNPVPNet) based on nonlinear spiking neural P (NSNP) systems is proposed, simulating biological visual processes through three core modules: scene perception, cognitive reasoning, and decision inference module. A bio-inspired convolutional block reconstructed through NSNP systems enhances biological-computational mapping relationships. Experimental evaluations across four benchmark datasets demonstrate superior performance over twenty state-of-the-art COD methods, achieving average metric improvements of 3.2% ( S m ), 2.5% ( a E m ), 5.4% ( F β w ), and 1.2% ( M ). These advancements validate NSNP systems’ potential in COD applications and pioneer new bio-inspired approaches for bionic visual computing. The implementation is available at: https://github.com/Williamzhounan/NSNPVPNet .},
  archive      = {J_KBS},
  author       = {Nan Zhou and Hong Peng and Zhicai Liu},
  doi          = {10.1016/j.knosys.2025.114532},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114532},
  shortjournal = {Knowl. Based Syst.},
  title        = {The parallel visual perception network based on nonlinear spiking neural p systems for camouflaged object detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot hyperspectral image classification with mamba and manifold convolution fusion network. <em>KBS</em>, <em>330</em>, 114531. (<a href='https://doi.org/10.1016/j.knosys.2025.114531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient modeling of global-local features is crucial for hyperspectral image (HSI) classification. The mamba network demonstrates strong capability in capturing global dependencies in HSI classification tasks, primarily utilizing a state-space model to extract first-order statistical features of spectral-spatial information in euclidean space, providing an initial representation of data characteristics. However, under few-shot conditions, fully exploiting effective features from limited samples and overcoming challenges such as class overlap and feature space sparsity caused by the insufficient extraction of second-order statistical features in riemannian space remain major research challenges. Therefore, we propose a dual branch manifold convolution-mamba network (DBMCMamba) for HSI classification. Specifically, it adaptively fuses forward and backward information through the vision mamba (Vim) block and utilizes the S6 module to extract global information, thereby enhancing global feature extraction capability. Meanwhile, the manifold convolution module extracts first-order statistical features of spectral-spatial information through convolutional layers and learns second-order statistics via the SPD manifold to strengthen DBMCMamba’s local feature representation under few-shot conditions. Finally, global and local features are fused for classification, effectively improving the accuracy and performance of HSI classification. On the Indian Pines, Pavia University, HongHu, and HanChuan datasets, DBMCMamba achieved classification accuracies of 95.23 %, 95.80 %, 95.58 %, and 94.93 %, respectively. Experimental results show that DBMCMamba demonstrates significant performance improvements compared to the state-of-the-art classification models. The code will be available online at https://github.com/ASDFFGG121EAA/DBMCMamba .},
  archive      = {J_KBS},
  author       = {Heling Cao and Yanlong Guo and Yonghe Chu and Yun Wang and Junyi Duan and Peng Li},
  doi          = {10.1016/j.knosys.2025.114531},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114531},
  shortjournal = {Knowl. Based Syst.},
  title        = {Few-shot hyperspectral image classification with mamba and manifold convolution fusion network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NPMFF-net: A training-free unified framework for point cloud classification and segmentation. <em>KBS</em>, <em>330</em>, 114529. (<a href='https://doi.org/10.1016/j.knosys.2025.114529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-parametric networks have shown promise for understanding point clouds due to their training-free nature and low computational cost. However, existing methods such as Point-NN and Seg-NN underutilize geometric and frequency information. Although these methods demonstrate superior accuracy, we found that the potential features of point clouds can still be explored in depth. In this work, we revisit non-parametric networks and propose the Non-Parametric Multi-scale Feature Fusion Network (NPMFF-Net), a model designed to unify spatial and frequency information in point cloud analysis, featuring training-free components. The key is Plücker coordinates Encoding and Fourier Feature Mapping, combining geometric information with high-frequency features. We propose a non-parametric attention module to integrate contextual information and k-adaptive normal pooling to aggregate multi-scale features. Extensive experiments on the ModelNet10/40, ScanObjectNN, ShapeNetPart, S3DIS, and ScanNet datasets demonstrate the superiority of NPMFF-Net in point classification and segmentation tasks. We surpass Point-NN by 8.2 % OA and Seg-NN by 5.8 % OA on ModelNet40 for classification, while also achieving a 2.7 % improvement in mean IoU over Point-NN on ShapeNetPart for part segmentation.},
  archive      = {J_KBS},
  author       = {Hualong Zeng and Haijiang Zhu and Huaiyuan Yu and Mengting Liu and Ning An},
  doi          = {10.1016/j.knosys.2025.114529},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114529},
  shortjournal = {Knowl. Based Syst.},
  title        = {NPMFF-net: A training-free unified framework for point cloud classification and segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering novel scientific insights with a synergistic GNN-LLM framework. <em>KBS</em>, <em>330</em>, 114527. (<a href='https://doi.org/10.1016/j.knosys.2025.114527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of scientific literature demands intelligent systems capable of uncovering emerging knowledge associations and fostering creativity. While graph neural networks (GNNs) excel at modeling literature structures, their static temporal modeling and lack of semantic awareness limit the discovery of interpretable signals. Conversely, large language models (LLMs) offer deep semantic reasoning but struggle to find non-obvious, structurally-grounded patterns without structured input. To address these limitations, this paper proposes a multi-stage GNN-LLM framework that integrates structural pattern recognition and semantic interpretation for scientific knowledge discovery. The framework begins with a Semantic-Enhanced Temporal Graph Network (SE-TGN), which embeds paper-level semantic information into an event-based temporal GNN to identify emerging keyword associations. These structurally grounded candidates are refined through the Contextual Re-ranking and Evaluation Framework (CREF), which leverages LLM capabilities to assess contextual novelty and relevance. Finally, the Generative Interpretation and Contextualization (GIC) produces human-readable explanations and research prompts to support innovation. Experiments in two scientific domains demonstrate the effectiveness of the framework in discovering semantically rich, contextually grounded, and forward-looking knowledge associations, illustrating its potential to support interpretable and creativity-driven scientific exploration.},
  archive      = {J_KBS},
  author       = {Qingqing Wang and Derui Lyu and Qiuju Chen},
  doi          = {10.1016/j.knosys.2025.114527},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114527},
  shortjournal = {Knowl. Based Syst.},
  title        = {Uncovering novel scientific insights with a synergistic GNN-LLM framework},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSDiagnosis: A benchmark and framework for evaluating large language models in multi-step clinical diagnosis. <em>KBS</em>, <em>330</em>, 114524. (<a href='https://doi.org/10.1016/j.knosys.2025.114524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical diagnosis is critical in clinical decision-making, typically requiring a continuous and evolving process that includes primary, differential, and final diagnoses. However, most existing clinical diagnostic tasks are single-step processes, which do not align with the complex multi-step diagnostic procedures found in real clinical scenarios. In this paper, we propose MSDiagnosis, a Chinese multi-step clinical diagnostic benchmark consisting of 2225 cases from 12 departments, covering primary, differential, and final diagnosis tasks. Conventional approaches often rely on large language models (LLMs) to perform these tasks sequentially, which can lead to error propagation. To address this, we propose a two-stage diagnostic framework consisting of a forward inference module and a backward reasoning and refinement module. This framework is applied at each diagnostic stage to effectively mitigate error propagation across steps. The forward module retrieves similar cases to assist the LLM in generating an initial diagnosis. In the backward inference and refinement module, we first perform backward inference to infer the diagnostic criteria associated with the initially identified potential diseases. These criteria are then compared with the patient’s records to identify and eliminate possible misdiagnoses. Finally, the diagnostic conclusion is further refined and confirmed. Based on the MSDiagnosis, we evaluate medical LLMs (e.g., OpenBioLLM, PULSE, and Apollo2), general LLMs (e.g., DeepSeek-V3, OpenAI-O1, and GLM4), and our proposed framework. Experimental results show that our framework achieves state-of-the-art performance, demonstrating its effectiveness in multi-step diagnostic tasks. We also provide a detailed analysis and suggest future research directions for this task. Our code and data are publicly available at https://github.com/nlper-hou/MSDiagnosis .},
  archive      = {J_KBS},
  author       = {Ruihui Hou and Shencheng Chen and Yongqi Fan and Guangya Yu and Lifeng Zhu and Jing Sun and Jingping Liu and Tong Ruan},
  doi          = {10.1016/j.knosys.2025.114524},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114524},
  shortjournal = {Knowl. Based Syst.},
  title        = {MSDiagnosis: A benchmark and framework for evaluating large language models in multi-step clinical diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe and effective post-fine-tuning alignment in large language models. <em>KBS</em>, <em>330</em>, 114523. (<a href='https://doi.org/10.1016/j.knosys.2025.114523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning is critical to customizing Large Language Models (LLMs) in various applications, but it inevitably disrupts the safety alignment of the models. Current alignment methods tackle harmful fine-tuning challenges but frequently compromise model usefulness, resulting in unsatisfactory downstream task performance. To address this issue, we propose a S afe and E ffective post-fine-tuning A lignment ( SEA ) from a knowledge disentanglement perspective. SEA introduces a novel two-level pruning process that surgically removes harmful functionalities. We first propose a differential importance score to isolate harmful pathways at the parameter level, and then introduce a module-wise analysis to protect entangled modules, thereby robustly balancing safety and utility. Experimental results on Llama2, Gemma and Mistral demonstrate that SEA effectively mitigates safety risks while maintaining optimal fine-tuning accuracy. This work provides a practical solution to the safety-performance dilemma associated with harmful fine-tuning of LLMs.},
  archive      = {J_KBS},
  author       = {Minrui Jiang and Yuning Yang and Xiurui Xie and Pei Ke and Guisong Liu},
  doi          = {10.1016/j.knosys.2025.114523},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114523},
  shortjournal = {Knowl. Based Syst.},
  title        = {Safe and effective post-fine-tuning alignment in large language models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward customized model discrepancies in personalized federated learning on non-IID data. <em>KBS</em>, <em>330</em>, 114522. (<a href='https://doi.org/10.1016/j.knosys.2025.114522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a traditional framework comprising a central server and multiple local clients. In FL, a shared global model is trained for resource-constrained computing devices while preserving data privacy. However, in certain practical applications, the shared global model may exhibit poor inference performance in local clients owing to nonindependent and nonidentically distributed (non-IID) characteristics of data. To address this issue, researchers have proposed personalized FL (PFL), which involves learning a customized model for each client to mitigate the impact of weight divergences when the training datasets are non-IID. Unfortunately, existing studies fail to reveal the inherent connection between model discrepancies and non-IID data. Herein, we focus on demonstrating the relationship between weight divergences among customized models and non-IID data, and we provide a proposition to reveal the root cause of such divergences. Additionally, based on our theoretical analysis, we introduce two novel personalized FL methods, namely, PFL with neighbor clients (PFedNC) and PFL with neighbor layers (PFedNL), to address the issue of non-IID data scenarios. Theoretical convergence analysis and extensive experiments indicate that our proposed methods outperform state-of-the-art personalized algorithms in non-IID scenarios. Specifically, PFedNC achieves up to 4 % improvement in customized model accuracy, while PFedNL yields 8 %–10 % gains over multiple baselines.},
  archive      = {J_KBS},
  author       = {Fengrui Hao and Taihang Zhi and Tianlong Gu and Xuguang Bao},
  doi          = {10.1016/j.knosys.2025.114522},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114522},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward customized model discrepancies in personalized federated learning on non-IID data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node importance estimation leveraging LLMs for semantic augmentation in knowledge graphs. <em>KBS</em>, <em>330</em>, 114521. (<a href='https://doi.org/10.1016/j.knosys.2025.114521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node Importance Estimation (NIE) is a task that quantifies the importance of nodes in a graph. Recent research has investigated to exploit various information from Knowledge Graphs (KGs) to estimate node importance scores. However, the semantic information in KGs could be insufficient, missing, and inaccurate, which would limit the performance of existing NIE models. To address these issues, we leverage Large Language Models (LLMs) for semantic augmentation thanks to the LLMs’ extra knowledge and ability of integrating knowledge from both LLMs and KGs. To this end, we propose the LLMs Empowered Node Importance Estimation (LENIE) method to enhance the semantic information in KGs for better supporting NIE tasks. To our best knowledge, this is the first work incorporating LLMs into NIE. Specifically, LENIE employs a novel clustering-based triplet sampling strategy to extract diverse knowledge of a node sampled from the given KG. After that, LENIE adopts the node-specific adaptive prompts to integrate the sampled triplets and the original node descriptions, which are then fed into LLMs for generating richer and more precise augmented node descriptions. These augmented descriptions finally initialize node embeddings for boosting the downstream NIE model performance. Extensive experiments demonstrate LENIE’s effectiveness in addressing semantic deficiencies in KGs, enabling more informative semantic augmentation and enhancing existing NIE models to achieve the state-of-the-art performance. The source code of LENIE is freely available at https://github.com/XinyuLin-FZ/LENIE .},
  archive      = {J_KBS},
  author       = {Xinyu Lin and Tianyu Zhang and Chengbin Hou and Jinbao Wang and Jianye Xue and Hairong Lv},
  doi          = {10.1016/j.knosys.2025.114521},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114521},
  shortjournal = {Knowl. Based Syst.},
  title        = {Node importance estimation leveraging LLMs for semantic augmentation in knowledge graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards robust infrared small target detection: A feature-enhanced and sensitivity-tunable framework. <em>KBS</em>, <em>330</em>, 114519. (<a href='https://doi.org/10.1016/j.knosys.2025.114519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, single-frame infrared small target (SIRST) detection technology has attracted widespread attention. Different from most existing deep learning-based methods that focus on improving network architectures, we propose a feature-enhanced and sensitivity-tunable (FEST) framework, which is compatible with existing SIRST detection networks and further enhances their detection performance. The FEST framework improves the model’s robustness from two aspects: feature enhancement and target confidence regulation. For feature enhancement, we employ a multi-scale fusion strategy to improve the model’s perception to multi-scale features of multi-size targets, and design an edge enhancement difficulty mining (EEDM) loss to guide the network to continuously focus on challenging target regions and edge features during training. For target confidence regulation, an adjustable sensitivity (AS) strategy is proposed for network post-processing. This strategy enhances the model’s adaptability in complex scenarios and significantly improves the detection rate of infrared small targets while maintaining segmentation accuracy. Extensive experimental results show that our FEST framework can effectively enhance the performance of existing SIRST detection networks. The code is available at https://github.com/YuChuang1205/FEST-Framework .},
  archive      = {J_KBS},
  author       = {Jinmiao Zhao and Zelin Shi and Chuang Yu and Yunpeng Liu and Yimain Dai},
  doi          = {10.1016/j.knosys.2025.114519},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114519},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards robust infrared small target detection: A feature-enhanced and sensitivity-tunable framework},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure distributor data storage and retrieval of unstructured data in blockchain enabled edge computing. <em>KBS</em>, <em>330</em>, 114518. (<a href='https://doi.org/10.1016/j.knosys.2025.114518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern IoT applications, managing large volumes of unstructured data securely and efficiently is a growing challenge, especially within blockchain-enabled edge computing environments. Traditional data storage and retrieval methods often fall short in terms of error detection, indexing efficiency, and secure data handling. To address these limitations, this research proposes a secure and intelligent distributor framework for the storage and retrieval of unstructured data using a blockchain-supported edge computing model. The system architecture is composed of three layers, such as the IoT network layer for data collection, the blockchain-based edge computing layer for secure data handling, and the cloud layer for scalable storage. The proposed framework introduces a novel indexing mechanism, the Optimal Cluster Inverted Index (OCII), which is computed using a newly designed Taylor Fire Hawk Optimizer (Taylor FHO), which is the hybridization of the Taylor series and Fire Hawk Optimizer (FHO). The data handling framework involves five key processes, like KeyGeneration, OCII Generation, AuthGen, Check, and Dynamics, ensuring secure indexing, authentication, and data validation. Experimental evaluation demonstrates that the Taylor FHO achieves a better precision of 86.067%, recall of 87.080%, F-measure of 87.748%, and indexing time of 0.401 sec. This research provides a scalable and secure solution for real-time unstructured data processing in IoT systems.},
  archive      = {J_KBS},
  author       = {S. Premkumar and S. Sivakumar and TS. Arthi and N. Partheeban},
  doi          = {10.1016/j.knosys.2025.114518},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114518},
  shortjournal = {Knowl. Based Syst.},
  title        = {Secure distributor data storage and retrieval of unstructured data in blockchain enabled edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploitability prediction of vulnerabilities based on heterogeneous graphs. <em>KBS</em>, <em>330</em>, 114517. (<a href='https://doi.org/10.1016/j.knosys.2025.114517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vulnerability exploitability prediction is the process predicting the likelihood of being exploited in real attacks by the assessment of known software vulnerabilities. Many methods have been proposed to solve the problem of exploitability prediction. However, they generally suffer from two problems. First, they only extract features from a single vulnerability, ignoring the impact of associated vulnerabilities. Second, they usually adopt simple methods (such as concatenation) to aggregate different information, which may overlook important relationships between features. In this paper, we propose a novel exploitability prediction method based on heterogeneous graphs, called ExPreHet. First, ExPreHet defines nodes and edges to construct a heterogeneous graph. Following a series of preprocessing steps, ExPreHet generates multiple attribute vectors for each node. By implementing a restart random walk strategy, ExPreHet ensures that each node can sample all categories of neighboring nodes and group them by node category. Then, ExPreHet aggregates all the attributes of each node to generate the content vector, and each category of neighboring nodes of this node to generate a category vector. After that, the content vector and all the category vectors are aggregated to generate the final representation of the node. Finally, these final representations are input into random forest (RF) for training the classifier. To effectively assess ExPreHet, this paper conducts experiments on a dataset, which contains 66,877 vulnerabilities. The experimental results show that ExPreHet achieves 83.24 %, 83.22 %, 83.28 %, 83.25 %, and 83.24 % in terms of accuracy, precision, recall, F1-score, and area under curve (AUC), respectively. ExPreHet performs significantly better than the baseline methods.},
  archive      = {J_KBS},
  author       = {Guo Xu and Xin Chen and Xinxin Cai and Dongjin Yu},
  doi          = {10.1016/j.knosys.2025.114517},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114517},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exploitability prediction of vulnerabilities based on heterogeneous graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep cognitive network for battlefield situation awareness in wargaming. <em>KBS</em>, <em>330</em>, 114516. (<a href='https://doi.org/10.1016/j.knosys.2025.114516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an innovative approach to supporting wargaming, computer-based wargames have been well received by military researchers. The battlefield situation in wargames is complex and rapidly evolving, and analysing a single scenario is insufficient to capture the full scope of the battlefield. To address the challenge of identifying trends in situational changes, this study proposes a value network model for battlefield situational awareness in wargaming based on deep learning techniques. Focusing on the Army Tactical Wargame as the research object, this study analyses key elements of battlefield situations using feature engineering methods. It introduces a hierarchical, grid-based model for representing battlefield situation features within wargames and develops a value tagging system that integrates system scores with distance-based rewards. A convolutional neural network-based value network model for situational awareness is then constructed, and the influence of key battlefield characteristics on the model is examined. Experimental results demonstrate that the proposed value network can more accurately predict the situation value at each stage of the wargame. The prediction accuracy exhibits a hump-shaped trend from the beginning to the end of the simulation. During the attack phase, the prediction accuracy exceeds 70 %, reaching a peak of 72.98 %. These findings offer a reliable new method for supporting agents in situation recognition and intelligent decision-making.},
  archive      = {J_KBS},
  author       = {Chenhui Pan and Yong Xian and Peiyang Ma and Leliang Ren and Wancheng Ni},
  doi          = {10.1016/j.knosys.2025.114516},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114516},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel deep cognitive network for battlefield situation awareness in wargaming},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization. <em>KBS</em>, <em>330</em>, 114514. (<a href='https://doi.org/10.1016/j.knosys.2025.114514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern autonomous driving systems rely heavily on deep learning-based perception models for object detection; yet, their computational and energy demands remain critical bottlenecks. The existing adaptive-perception strategies often lack the ability to dynamically balance the detection accuracy and energy consumption, in real-time, particularly under varying environmental conditions. To address this challenge, we first construct a large-scale autonomous driving dataset based on the CARLA simulator. Then, we propose a novel metric—the balanced efficiency index—to annotate each image with the most suitable you-only-look-once version 8 (YOLOv8) model size (i.e., n, s, m, l, or x). This index is governed by two critical parameters, which are efficiently optimized using our proposed constrained stochastic DIviding RECTangles (DIRECT) algorithm. Finally, we propose a lightweight dynamic mixed receptive field transformer (DynaMixFormer), which is trained using the labelled dataset, to select the appropriate YOLOv8 model adaptively. Our results show that: (1) the constrained stochastic DIRECT algorithm determines cost-effective parameters with very limited simulation overhead; (2) DynaMixFormer achieves a high classification accuracy of 96.56 % with only 0.017 M parameters, outperforming the state-of-the-art image-classification networks; and (3) the well-trained DynaMixFormer effectively extracts real-time contextual features, such as traffic density, weather conditions, and road complexity, to intelligently select the optimal model from various YOLOv8 variants. Extensive simulations demonstrate that our approach achieves up to 70.20 % reduction in the energy consumption, compared to the static deployment of the YOLOv8x model, with only a marginal decrease of approximately 2 % in the mean average precision. Taking China as an example, this translates to an estimated energy saving of 2.73 × 10 14 W. This work not only advances energy-efficient autonomous perception but also provides a generalizable framework for adaptive model selection in resource-constrained edge-computing systems. For ease of comprehension, some key nomenclature used in this paper are summarized in Table 1.},
  archive      = {J_KBS},
  author       = {Yanzhan Chen and Fan Yu and Qian Zhang and Mahardhika Pratama},
  doi          = {10.1016/j.knosys.2025.114514},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114514},
  shortjournal = {Knowl. Based Syst.},
  title        = {Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-kNN-MT: Enhancing domain adaptability of neural machine translation via target language data. <em>KBS</em>, <em>330</em>, 114513. (<a href='https://doi.org/10.1016/j.knosys.2025.114513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Neural Machine Translation (NMT) has recently achieved remarkable performance improvements, it still faces challenges in domain adaptation. Previous research has focused on mitigating this issue by integrating translation knowledge from bilingual domain data. However, the limited availability of bilingual translation resources has constrained these methods in real world application. To address this inadequacy, solutions based on monolingual data, such as back-translation, have been proposed. Nevertheless, these methods often incur additional training costs due to the necessity of training reverse models to generate pseudo data. In light of this, we propose Pseudo- k NN-MT, which does not require additional training. This method creates pseudo-bilingual data pairs by retrieving semantically similar sentences from target language data and subsequently builds the k NN datastore. To effectively reduce the noise introduced by the pseudo-data, we incorporate cross-lingual retrieval distances into the k NN probability construction process. Experiments in both high-resource and low-resource machine translation scenarios across multiple domains demonstrate that our method significantly improves the domain adaptation capabilities of NMT in both settings, yielding average improvements of 6.08 and 7.70 SacreBLEU points and 0.66 and 1.62 COMET scores on the multi-domain dataset, respectively.},
  archive      = {J_KBS},
  author       = {Abudurexiti Reheman and Yingfeng Luo and Junhao Ruan and Hongyu Liu and Tong Xiao and Jingbo Zhu},
  doi          = {10.1016/j.knosys.2025.114513},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114513},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pseudo-kNN-MT: Enhancing domain adaptability of neural machine translation via target language data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the performance of power distribution systems through integrated network reconfiguration and distributed generation design. <em>KBS</em>, <em>330</em>, 114512. (<a href='https://doi.org/10.1016/j.knosys.2025.114512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfiguration of networks and distributed generation (DG) together leads to better performance of a network. To ensure system enactment, it is therefore necessary to determine appropriate size and placement of DG. However, there is a huge solution search space for sizing and situating of demand generation with Network Reconfiguration (NR), which makes it a complicated problem. Throughout the optimization process, removing these non-radial choices adds computational burden and lead to a local optimal solution. To reduce complexity of searching, Modified Chaotic Particle Swarm Optimization (MCPSO) algorithm is adopted to obtain a near optimal solution of designing, sizing, and placing the network with improved voltage profiles and minimized power loss. It introduces a combination of chaotic inertia adaptation, uniform initialization and a stochastic personal learning strategy contributing to improved search diversity and convergence stability. For the purpose of demonstrating efficacy of a simultaneous approach taking changeable power factor, the proposed approach is assessed using IEEE-33 and 69 bus using MATLAB. The findings demonstrate that discretizing reconfiguration search space implemented by encoding the network configuration as a discrete set of switching states prevents MCPSO from getting trapped in local optimums. On contrasting with conventional Particle Swarm Optimization (PSO), the proposed MCPSO algorithm results in active and reactive power loss reduction of 27.78 % and 76.36 % respectively for 33 bus system and 6.67 % and 25.5 % respectively for 69 bus system. The outcomes reveal that suggested algorithm provides optimal solution contrasted to state of art approaches.},
  archive      = {J_KBS},
  author       = {K. Dharani Sree and P. Karpagavalli},
  doi          = {10.1016/j.knosys.2025.114512},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114512},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing the performance of power distribution systems through integrated network reconfiguration and distributed generation design},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multi-view discrete clustering with unified graph learning. <em>KBS</em>, <em>330</em>, 114510. (<a href='https://doi.org/10.1016/j.knosys.2025.114510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based multi-view clustering (GMVC) has garnered significant attention due to its ability to overcome sample space shape constraints. However, existing GMVC methods encounter two major challenges: (1) Their effectiveness diminishes because they solely rely on sample-constructed graphs and the two-stage mismatch caused by additional discretization; (2) Their robustness deteriorates substantially when applied to real-world datasets that contain complex noise. To address these limitations, we propose a robust multi-view discrete clustering model with unified graph learning (RCUGL). This model integrates richer graph structural information and accommodates complex noise clustering tasks. Specifically, we incorporated low-rank approximation graphs reconstructed from spectral embeddings and graphs constructed by samples into a unified graph to provide enriched structural insights. Subsequently, within the framework of the correntropy, discrete spectral analysis was performed directly on the unified graph to derive cluster assignments. Given the non-convex and discrete nature of the proposed RCUGL model, we developed a half-quadratic-based coordinate descent optimisation algorithm to ensure rapid and reliable convergence. Extensive experiments demonstrate that RCUGL substantially improves clustering effectiveness, comparable to state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jiaqi Nie and Rankun Chen and Jingxiang Huang and Ben Yang and Xuetao Zhang},
  doi          = {10.1016/j.knosys.2025.114510},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114510},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust multi-view discrete clustering with unified graph learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph-based CLIP hashing for unsupervised cross-modal retrieval. <em>KBS</em>, <em>330</em>, 114508. (<a href='https://doi.org/10.1016/j.knosys.2025.114508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the surge of multi-modal data, how to effectively and efficiently find similar information has become an urgent and important need. Among the existing solutions, unsupervised cross-modal hashing can learn from unlabeled data and provide fast and satisfactory retrieval performance, making it a viable solution. However, existing unsupervised cross-modal hashing methods often inadequately model intricate cross-modal semantic relationships. To bridge this gap, this paper proposes a novel Hypergraph-based CLIP Hashing (HCH). Specifically, HCH utilizes the large-scale visual-language pre-trained model CLIP to extract visual and textual features, and employs a cross-modal Transformer to further enhance semantic fusion among these features. Then, to fully capture the semantic relevance among multi-modal data, we construct a semantic-enhanced similarity matrix and design a mean-based weighting scheme to adjust this matrix. Additionally, we compose a hypergraph convolutional network to further explore high-order semantic information within the input data, leading to more compact and high-quality hash codes. To substantiate HCH’s efficacy, we conducted experiments on three commonly used datasets, confirming its superiority over leading baselines.},
  archive      = {J_KBS},
  author       = {Qian Zhang and Jia-Rui Zhao and Xiao-Qian Liu and Yu-Wei Zhan and Zhen-Duo Chen and Xin Luo and Xin-Shun Xu},
  doi          = {10.1016/j.knosys.2025.114508},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114508},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hypergraph-based CLIP hashing for unsupervised cross-modal retrieval},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph. <em>KBS</em>, <em>330</em>, 114507. (<a href='https://doi.org/10.1016/j.knosys.2025.114507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As language models are used in more applications, a key problem has become clear: their numerical embeddings are hard to interpret because it is unclear how each part of the vector relates to real-world meanings in specific fields. The prevailing embedding methods are inadequate in their current state, as they are unable to effectively bridge the gap between mathematical representations and human-understandable knowledge structures. The present study proposes a novel framework that explicitly links ontology classes to specific embedding dimensions through a dual-component architecture combining a text encoder that produces the target embedding dimensions with domain knowledge graphs. The Area Under the Interpretability Curve (AUIC) metric is introduced as a means to systematically evaluate model-alignment with ontological concepts. The analysis reveals that targeted dimensional mapping enables direct interpretation of individual vector components through ontological terms. The practical applications of this framework are illustrated through case studies in biomedical contexts, demonstrating enhanced model transparency without compromising performance. This approach establishes a measurable pathway for reconciling statistical language representations with structured domain knowledge, particularly benefiting fields requiring precise concept alignment like biomedicine. The implementation is publicly available at: https://github.com/Mellandd/DEIBO .},
  archive      = {J_KBS},
  author       = {Jose L. Mellina-Andreu and Alejandro Cisterna-García and Juan A. Botía},
  doi          = {10.1016/j.knosys.2025.114507},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114507},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient network intrusion detection model based on beta mixture models. <em>KBS</em>, <em>330</em>, 114506. (<a href='https://doi.org/10.1016/j.knosys.2025.114506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer networks and network applications, ensuring network security has become a critical concern and has garnered significant attention from both academia and industry. Network intrusion detection (NID) plays a pivotal role in safeguarding cybersecurity and maintaining system stability. Most existing NID approaches rely on traditional machine learning (ML) or deep learning (DL) techniques to identify threats and potential attacks based on network traffic data. However, these methods often suffer from high computational complexity and large model sizes, which significantly impede their deployment in resource-constrained environments such as the Internet of Things (IoT), edge computing infrastructures, and wireless sensor networks. In this study, we propose an efficient NID framework based on the Beta Mixture Model (BMM) classifier. The proposed method integrates the BMM with the recently introduced Extended Stochastic Variational Inference (ESVI) framework to effectively characterize both normal and intrusive behavior patterns. The ESVI framework enables simultaneous parameter estimation and model complexity control in a principled and computationally efficient manner. Experimental evaluations show that, compared to NID methods utilizing established finite mixture models, traditional ML, or state-of-the-art DL techniques, our approach substantially reduces computational overhead while achieving comparable detection performance.},
  archive      = {J_KBS},
  author       = {Yuping Lai and Zidong Wang and Ziqing Lin and Yuhan Cao and Zihao Li and Qing Ye},
  doi          = {10.1016/j.knosys.2025.114506},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114506},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient network intrusion detection model based on beta mixture models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic learning in the PAC framework: A new perspective. <em>KBS</em>, <em>330</em>, 114504. (<a href='https://doi.org/10.1016/j.knosys.2025.114504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monotone learning describes learning processes in which expected error consistently decreases as the amount of training data increases. However, recent studies challenge this conventional wisdom, revealing significant gaps in the understanding of generalization in machine learning. Addressing these gaps is crucial for advancing the theoretical foundations of the field. In this work, we utilize Probably Approximately Correct (PAC) learning theory to construct a theoretical error distribution that approximates a learning algorithm’s actual performance. We rigorously prove that this theoretical distribution exhibits monotonicity as sample sizes increase. We identify two scenarios under which deterministic algorithms based on Empirical Risk Minimization (ERM) are monotone: (1) the hypothesis space is finite, or (2) the hypothesis space has finite VC-dimension. Experiments on three classical learning problems validate our findings by demonstrating that the monotonicity of the algorithms’ generalization error is guaranteed, as its theoretical error upper bound monotonically converges to the minimum generalization error.},
  archive      = {J_KBS},
  author       = {Ming Li and Chenyi Zhang and Qin Li},
  doi          = {10.1016/j.knosys.2025.114504},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114504},
  shortjournal = {Knowl. Based Syst.},
  title        = {Monotonic learning in the PAC framework: A new perspective},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Truncated MobileNetV2 sparse vision graph attention model for explainable monkeypox disease classification. <em>KBS</em>, <em>330</em>, 114503. (<a href='https://doi.org/10.1016/j.knosys.2025.114503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current outbreak of monkeypox (mpox) presents challenges for timely and accurate diagnosis due to the disease’s diverse and unusual skin lesion patterns. Traditional deep learning models, such as Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), struggle with these irregular features because they rely on rigid, grid-based methods. To address this, we introduce the Truncated MobileNetV2 Sparse Vision Graph Attention (TMSVGA) model. TMSVGA combines components of MobileNetV2, which focuses on identifying smaller details, with a Sparse Vision Graph Attention block enhanced by a Squeeze-and-Excitation (SE) mechanism to improve channel-wise attention. This approach enhances the understanding of complex and long-distance relationships, emphasizing diagnostically significant regions and improving classification precision. We optimized TMSVGA using the Optuna framework for automated hyperparameter tuning. Additionally, Gradient-weighted Class Activation Mapping (Grad-CAM) and Local Interpretable Model-Agnostic Explanations (LIME) provided interpretable visualizations, highlighting influential regions in decision-making. The TMSVGA model was validated on the Monkeypox Skin Images Dataset (MSID), achieving 96.79 % accuracy, 96.90 % precision, 95.34 % recall, 96.08 % F1-score, and 95.37% Matthews Correlation Coefficient (MCC). These results demonstrate that TMSVGA outperforms existing models, particularly in handling irregular lesion patterns. By achieving high diagnostic accuracy and precision, our study showcases the potential of Vision Graph Neural Networks (ViGNNs) in advancing medical image analysis for diseases with non-uniform spatial patterns. Furthermore, the lightweight architecture of TMSVGA ensures suitability for mobile and resource-constrained diagnostic applications.},
  archive      = {J_KBS},
  author       = {Mehdhar S.A.M. Al-Gaashani and Abduljabbar S. Ba Mahel and Ammar Muthanna},
  doi          = {10.1016/j.knosys.2025.114503},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114503},
  shortjournal = {Knowl. Based Syst.},
  title        = {Truncated MobileNetV2 sparse vision graph attention model for explainable monkeypox disease classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity facial aesthetic evaluation model based on image-text modality. <em>KBS</em>, <em>330</em>, 114502. (<a href='https://doi.org/10.1016/j.knosys.2025.114502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Beauty Prediction (FBP) is an emerging research direction at the intersection of artificial intelligence and aesthetics, which has attracted increasing attention in recent years. However, most existing methods rely solely on unimodal data and fail to comprehensively capture the multi-dimensional information of facial aesthetics. To address this challenge, we propose a multigranularity facial aesthetic evaluation model based on image-text modality (ITM-MGFA). By incorporating multi-granularity cognitive theory into the FBP task, the model effectively integrates both coarse-grained and fine-grained aesthetic features extracted from the CLIP encoder through a multigranularity representation module, a task-oriented dynamic alignment module, and a hierarchical interaction optimization module. This facilitates deep cross-modal interaction and fusion, significantly enhancing the model’s capability to model complex aesthetic attributes. Experimental results demonstrate that ITM-MGFA, leveraging the fusion of cross-modal information, achieves higher accuracy in facial aesthetic assessment task compared to traditional unimodal methods, offering a new direction for FBP research. Furthermore, the model can be applied in various scenarios, such as: simulation postoperative assessment of personalized cosmetic surgery in the medical aesthetics; selection of optimal facial aesthetic enhancement solutions on social media; and recommendation of matching solutions in cosmetic recommendation.},
  archive      = {J_KBS},
  author       = {Huanyu Chen and Yong Wang and Weisheng Li and Bin Xiao},
  doi          = {10.1016/j.knosys.2025.114502},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114502},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-granularity facial aesthetic evaluation model based on image-text modality},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments. <em>KBS</em>, <em>330</em>, 114501. (<a href='https://doi.org/10.1016/j.knosys.2025.114501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking plays a critical role in airborne autonomous systems, supporting applications such as disaster response, agricultural monitoring, and military surveillance. However, existing tracking methods often exhibit poor generalization in real-world deployments due to domain shifts between the training and target environments. We propose DGTrack, a novel single-source domain generalization framework for UAV visual tracking. DGTrack integrates a Frequency-Aware Learning (FAL) module that separates and adaptively modulates low- and high-frequency components to reduce stylistic interference while enhancing content representation. In addition, a Target-Aligned Augmentation (TAA) module is introduced to improve source domain diversity through multi-level transformations and to align predictions between original and augmented frames by maximizing mutual information. Extensive experiments on the UAVDT and VisDrone2019 datasets demonstrate that DGTrack achieves superior generalization to unseen domains and consistently outperforms state-of-the-art UAV trackers in single-source settings.},
  archive      = {J_KBS},
  author       = {Erfeng Liu and Xinde Li and Heqing Li and Guoliang Wu and Tao Shen},
  doi          = {10.1016/j.knosys.2025.114501},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114501},
  shortjournal = {Knowl. Based Syst.},
  title        = {A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data. <em>KBS</em>, <em>330</em>, 114500. (<a href='https://doi.org/10.1016/j.knosys.2025.114500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a feature-augmented multivariate LSTM model for real-time Forex market forecasting. By incorporating engineered financial indicators—such as Close_Change, RSI, and gold price—alongside traditional OHLCV data, the model captures nonlinear temporal dynamics and macro-financial interactions. A sliding window approach structures input sequences for a stacked LSTM network optimized for short-term prediction. Experimental results on major currency pairs demonstrate that the proposed model outperforms baseline LSTM, GRU, and classical machine learning methods in RMSE, MAE, and MAPE metrics. Statistical validation using the Wilcoxon signed-rank test confirms the improvements are significant. The model's robustness under volatility stress and noisy inputs highlights its practical relevance for real-time decision-making. Potential extensions include incorporating news-based sentiment and multimodal signals to enhance adaptability.},
  archive      = {J_KBS},
  author       = {Duong Thi Kim Chi and Ho Ngoc Trung Kien and Thanh Q. Nguyen},
  doi          = {10.1016/j.knosys.2025.114500},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114500},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision-based heterogenous graph attention network for multi-class fake news detection. <em>KBS</em>, <em>330</em>, 114499. (<a href='https://doi.org/10.1016/j.knosys.2025.114499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A promising tool for addressing fake news detection is Graph Neural Networks (GNNs). However, most existing GNN-based methods rely on binary classification, categorizing news as either real or fake. Additionally, traditional GNN models use a static neighborhood for each node, making them susceptible to issues like over-squashing. In this paper, we introduce a novel model named Decision-based Heterogeneous Graph Attention Network (DHGAT) for fake news detection in a semi-supervised setting. DHGAT effectively addresses the limitations of traditional GNNs by dynamically optimizing and selecting the neighborhood type for each node in every layer. It represents news data as a heterogeneous graph where nodes (news items) are connected by various types of edges. The architecture of DHGAT consists of a decision network that determines the optimal neighborhood type and a representation network that updates node embeddings based on this selection. As a result, each node learns an optimal and task-specific computational graph, enhancing both the accuracy and efficiency of the fake news detection process. We evaluate DHGAT on the LIAR dataset, a large and challenging dataset for multi-class fake news detection, which includes news items categorized into six classes. Our results demonstrate that DHGAT outperforms existing methods, improving accuracy by approximately 4% and showing robustness with limited labeled data.},
  archive      = {J_KBS},
  author       = {Batool Lakzaei and Mostafa Haghir Chehreghani and Alireza Bagheri},
  doi          = {10.1016/j.knosys.2025.114499},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114499},
  shortjournal = {Knowl. Based Syst.},
  title        = {A decision-based heterogenous graph attention network for multi-class fake news detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReCAP2: Rectified and context-aware polarization prompting for robust depth enhancement. <em>KBS</em>, <em>330</em>, 114498. (<a href='https://doi.org/10.1016/j.knosys.2025.114498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate depth perception is fundamental for numerous computer vision applications, yet depth maps acquired from commodity sensors often suffer from artifacts and inaccuracies, necessitating effective enhancement techniques. Polarization imaging, capturing rich geometric cues robust to illumination variations, offers a promising modality to guide this process. However, effectively integrating these cues within learning-based depth enhancement frameworks remains challenging. Existing methods often overlook the inherent representational gap between depth and polarization features and employ context-agnostic fusion mechanisms, incapable of generating prompts adaptive to cross-modal relationships and local context. To address these limitations, we propose a novel Rectified and Context-Aware Polarization Prompting (ReCAP 2 ) framework for depth enhancement models. The ReCAP 2 first performs initial feature rectification across both channel and spatial dimensions to bridge the modality gap. Subsequently, it generates fine-grained polarization prompts by leveraging dual-level context: utilizing cross-modal context ensures the prompts encode pertinent inter-modality relationships, while processing spatial neighborhood context yields prompts spatially tailored to regional content. Consequently, these dual-context aware prompts provide precise, adaptive guidance for the foundation model, facilitating more robust depth enhancement. Extensive experiments demonstrate the effectiveness of our method. On the multi-modal HAMMER dataset, our method shows superior accuracy and robustness across diverse sensor types in indoor scenes under both full fine-tuning and prompt tuning settings. Furthermore, cross-domain evaluations on the challenging CroMo dataset validate its strong generalization to outdoor environments.},
  archive      = {J_KBS},
  author       = {Zhenyu Liu and Jiatong Xu and Daxin Liu and Qide Wang and Jin Cheng and Jianrong Tan},
  doi          = {10.1016/j.knosys.2025.114498},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114498},
  shortjournal = {Knowl. Based Syst.},
  title        = {ReCAP2: Rectified and context-aware polarization prompting for robust depth enhancement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-generalized token linking in vision foundation models for semantic segmentation. <em>KBS</em>, <em>330</em>, 114497. (<a href='https://doi.org/10.1016/j.knosys.2025.114497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {[S U M M A R Y] Vision Foundation Models (VFMs) achieve remarkable performance compared with traditional methods based on convolutional neural networks and vision transformer networks in Domain-Generalized Semantic Segmentation (DGSS). These VFM-based DGSS methods focus on adopting efficient parameter fine-tuning strategies that use a set of learnable tokens to fine-tune VFMs to the downstream DGSS task, yet struggle to mine domain-invariant information from VFMs since the backbone of VFMs is frozen during the fine-tuning stage. To address this issue, a Domain-Generalized Token Linking (DGTL) approach is proposed to mine domain-invariant information from VFMs for improving the performance in unseen target domains, which contains a Text-guided Dual Token Linking (TDTL) module and a Text-guided Distribution Normalization (TDN) strategy. For the TDTL module, first, a set of learnable tokens is linked to the text embeddings for building the relations between the learnable tokens and text embeddings, which is beneficial for learning domain-invariant tokens since the text embeddings generated from the CLIP model are domain-invariant. Second, the feature-level and mask-level linking strategies are proposed to link the learned domain-invariant tokens to the features and masks to guide the mining of domain-invariant information from the VFM. For the TDN strategy, the pairwise similarity between the predictive masks associated with the learnable tokens and the text embeddings is utilized to explicitly align the semantic distribution of visual features in the learnable tokens with the text embeddings. Extensive experiments demonstrate that the DGTL approach achieves superior performance to recent methods across multiple DGSS benchmarks. The code is released on GitHub: https://github.com/seabearlmx/DGTL .},
  archive      = {J_KBS},
  author       = {Muxin Liao and Jiayang Wang and Hong Deng and Yingqiong Peng and Hua Yin and Yinglong Wang and Guoguang Hua},
  doi          = {10.1016/j.knosys.2025.114497},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114497},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain-generalized token linking in vision foundation models for semantic segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive exploration for few-shot incremental learning. <em>KBS</em>, <em>330</em>, 114496. (<a href='https://doi.org/10.1016/j.knosys.2025.114496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) poses a challenging problem in computer vision, where conventional deep models suffer from catastrophic forgetting and overfitting to novel classes. Inspired by the dynamic learning processes observed in human cognition when adapting to unfamiliar scenarios, we propose a deep exploratory incremental learning framework that incrementally refines the classifier model through a trial-and-error decision making process. A joint distribution-aware reward function is introduced to guide learning, incorporating three key factors: intra-class compactness, inter-class dispersion, and cross-session consistency, enabling balanced knowledge retention and acquisition. Furthermore, we design a dynamic gradient guidance module that adaptively adjusts gradient updates within a Gaussian-derived policy space, enhancing training stability and mitigating overfitting risks in the few shot regime. Extensive experiments conducted on three publicly available datasets demonstrate the effectiveness of the proposed method, achieving state-of-the-art performance in the FSCIL setting.},
  archive      = {J_KBS},
  author       = {Cao Han and Ziqi Gu and Chunyan Xu and Zhen Cui},
  doi          = {10.1016/j.knosys.2025.114496},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114496},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive exploration for few-shot incremental learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings. <em>KBS</em>, <em>330</em>, 114495. (<a href='https://doi.org/10.1016/j.knosys.2025.114495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the thermomechanical responses of refractory linings in steel ladles is critical to optimizing production efficiency and ensuring safety in the iron and steel smelting industry. However, traditional numerical simulation methods suffer challenges of high computational costs and insufficient generalizability, while data-driven models are limited by a lack of physical rationality and poor interpretability. Aiming at overcoming these challenges, an artificial intelligence (AI) model, named the steel ladle Kolmogorov–Arnold network (SLKAN), is designed to predict the thermomechanical behavior of ladle linings. Based on the Kolmogorov–Arnold theorem and material constitutive equations, SLKAN precisely predicts the thermomechanical behavior of ladle linings. The model offers substantial advantages in predicting the maximum tensile stress in the steel shell and the maximum compressive stress at the working lining hot face: the coefficient of determination (R 2 ) value for compressive stress prediction reaches 0.9942, with a mean absolute error (MAE) of 9.4136 and a root mean squared error (RMSE) of 0.0192; the R 2 value for tensile stress prediction is 0.9578, with an MAE of 41.4855 and an RMSE of 0.0385. Further analysis indicates that the function expressions of SLKAN hold clear physical significance. This study provides an interpretable, efficient AI solution for multiphysics coupling modeling in complex industrial scenarios and offers theoretical guidance for the application of AI in predicting the lifespan of steel-smelting equipment.},
  archive      = {J_KBS},
  author       = {Yi Yin and Zongxian Long and Shengli Jin and Yawei Li and Fang Wang and Xin Xu},
  doi          = {10.1016/j.knosys.2025.114495},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114495},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedCleanse: Cleanse the backdoor attacks in federated learning system. <em>KBS</em>, <em>330</em>, 114494. (<a href='https://doi.org/10.1016/j.knosys.2025.114494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables multiple clients to collaboratively train an efficient deep-learning model without sharing their local data. However, due to its privacy-preserving nature, FL is vulnerable to backdoor attack, which manipulates the model behaviors on the adversary-chosen input. Existing defense methods are ineffective against sophisticated stealthy backdoors, suffering from either a low benign performance or being too specific to certain assumptions and attacks. To handle the aforementioned issues, we present FedCleanse, a novel defense mechanism to address the backdoor attack in federated learning. In this work, we study the pruning-based approach, which has been proven effective but with the need for additional data for validation and suffers from high non-IID scenarios. This paper proposes a post-aggregation approach, namely FedCleanse, to neutralize backdoor effects without needing additional clean data. Our approach identifies suspicious neurons using “neuron conductance” and subsequently suppresses them after the aggregation operation, which imposes minimal impact on benign neurons. Additionally, FedCleanse is complemented by strategic perturbations to prevent backdoor transfer. Through extensive experiments, our method demonstrates superior defense capabilities across various attack types and non-IID settings, surpassing the state-of-the-art by a large margin without compromising the main task’s performance.},
  archive      = {J_KBS},
  author       = {Siquan Huang and Yijiang Li and Chong Chen and Leyu Shi and Wentian Cai and Ying Gao},
  doi          = {10.1016/j.knosys.2025.114494},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114494},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedCleanse: Cleanse the backdoor attacks in federated learning system},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CQSA-KT: Research on personalized knowledge tracing based on quantum-constructivism in sparse learning environments. <em>KBS</em>, <em>330</em>, 114493. (<a href='https://doi.org/10.1016/j.knosys.2025.114493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT), as a key technology to enable personalized instruction, faces the challenges of data sparsity and insufficient personalization modeling in large-scale instructional environments. To this end, this paper proposes a constructivist-inspired quantum self-attention knowledge tracing model (CQSA-KT). The deep mapping relationship between Constructivist Learning Theory (CLT) and Quantum Computing (QC) is established by characterizing the multilevel nature of learning states through quantum states, modeling knowledge associations through quantum entanglement, and simulating the assessment process through quantum measurements. The model contains four core modules: The quantum knowledge representation embedding module (QKREM) utilizes quantum complex embedding to achieve a high-dimensional representation of knowledge states; the quantum attention interaction module (QAIM) applies quantum entanglement to model the non-local nature of knowledge associations; the quantum measurement module (QMM) introduces the quantum measurement theory for learning assessment; and the hybrid cognitive feature fusion module (HCFFM) integrates classical and quantum features. Experiments on three publicly available datasets show that CQSA-KT maintains better performance under high sparsity (>98 %) conditions, significantly outperforming ten existing benchmark models. Especially in extremely sparse scenarios (only 20 % training data), the model’s AUC improves by 8.5 percentage points over the benchmark models. This theory-driven technological innovation validates the application potential of QC in education and provides a new theoretical framework for the development of intelligent education.},
  archive      = {J_KBS},
  author       = {Chengke Bao and Zhiliang Xu and Weidong Ji},
  doi          = {10.1016/j.knosys.2025.114493},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114493},
  shortjournal = {Knowl. Based Syst.},
  title        = {CQSA-KT: Research on personalized knowledge tracing based on quantum-constructivism in sparse learning environments},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransPhyX: A data-driven method for dynamic physical field prediction in stochastic load time-series. <em>KBS</em>, <em>330</em>, 114492. (<a href='https://doi.org/10.1016/j.knosys.2025.114492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic prediction of in-service physical fields (e.g. stress, strain, and temperature fields) constitutes a cornerstone technology for digital governance of mechanical equipment. The stochasticity and time-varying characteristics of external excitation loads (e.g. thermal, vibrational, and impact loads) introduce significant complexity in physical field prediction. Online monitoring of physical fields at the assembly interfaces of mechanical systems is critical for ensuring structural safety, extending service life, and optimizing design. This study proposes TransPhyX (Transformer-Based Physical Field Prediction with XGBoost Precoder), a hybrid data-driven framework designed to overcome these challenges. The novelty of TransPhyX lies in: (1) a recursive stochastic load generation and parametric dataset construction method tailored for dynamic prediction tasks; (2) a modular hybrid architecture that decouples transient load encoding (via XGBoost) and dynamic sequence modeling (via Transformer), improving spatiotemporal continuity and generalization; and (3) an Outlier Removal Ensemble (ORE) algorithm that fuses multi-scale predictions to eliminate anomalies and enhance robustness. Validated on flip-chip thermal management and flange-bolt stress prediction, TransPhyX achieves 99.79 % prediction fidelity with a 97.79 % reduction in computational costs compared to FEM, outperforming AutoGAN and TransUNet baselines in both accuracy and stability. These contributions establish TransPhyX as a rapid, high-fidelity solution for real-time structural health monitoring and digital twin implementation in stochastic loading environments.},
  archive      = {J_KBS},
  author       = {Qiyin Lin and Feiyu Gu and Mingjun Qiu and Chen Wang and Jian Zhuang and Jun Hong},
  doi          = {10.1016/j.knosys.2025.114492},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114492},
  shortjournal = {Knowl. Based Syst.},
  title        = {TransPhyX: A data-driven method for dynamic physical field prediction in stochastic load time-series},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation. <em>KBS</em>, <em>330</em>, 114490. (<a href='https://doi.org/10.1016/j.knosys.2025.114490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation Systems (RSs) aim to provide personalized recommendations by modeling user-item interaction patterns. Current attribute-enhanced RSs leverage user archival attributes to improve predictive performance. However, the use of attribute information introduces two critical challenges: 1) the risk of privacy leakage, as sensitive user attributes can be inferred from learned representations, and 2) high computational complexity, primarily due to the quadratic complexity of attention mechanisms. To address the accuracy-privacy-efficiency trilemma, we propose an Archive Knowledge Graph-enhanced Native Sparse Attention network (AKG-NSA) for privacy-preserving lightweight recommendation. Specifically, AKG-NSA introduces a two-stage privacy protection mechanism. First, we pseudonymize user identities in the archive knowledge graph, breaking the direct linkage between users and their attributes. Second, we design a Multi-channel Native Sparse Attention (MNSA) network that utilizes compressed user representations as queries to retrieve attribute patterns from the archive knowledge graph in a privacy-preserved manner. Moreover, we also construct a parallel user-item bipartite graph and operate graph convolutions to learn the representations for users and items. By employing the native sparse attention mechanism, AKG-NSA refines the learned representations while maintaining a low computational complexity. Extensive experiments on three real-world datasets demonstrate that AKG-NSA outperforms nine state-of-the-art baselines in terms of prediction accuracy, privacy preservation, and computational efficiency. The data and source codes of this work are available at https://github.com/juandu113/AKG-NSA .},
  archive      = {J_KBS},
  author       = {Juan Du and Chenxi Ma and Yaobin Wang and Limei Sun},
  doi          = {10.1016/j.knosys.2025.114490},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114490},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions. <em>KBS</em>, <em>330</em>, 114488. (<a href='https://doi.org/10.1016/j.knosys.2025.114488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online chatter detection is a critical technology in intelligent manufacturing systems, essential for ensuring high-quality and efficient milling operations. Although artificial intelligence models have been developed to automatically identify chatter, the accuracy improvement is limited by the use of single sensor signals. Therefore, a multi-source heterogeneous sensor information fusion framework is proposed for intelligent online chatter detection in this paper. To effectively mitigate noise and eliminate interference from milling parameters, a heterogeneous sensor signal processing strategy is proposed based on wavelet packet decomposition and successive variational mode decomposition. Next, a multi-source, multi-stage, and multi-scale spatial-temporal fusion attention network is proposed for extracting chatter features and achieving high-precision chatter detection. It is noteworthy that multi-source signals are fused at the feature level, and comprehensive chatter features are extracted through the multi-source information fusion module, the multi-stage spatial-temporal feature extraction and fusion module, and the multi-scale gated channel attention module. In milling experiments across different conditions, the chatter detection performance of the proposed framework is evaluated in three scenarios. The results indicate that this framework can provide more accurate and reliable detection results compared to other methods.},
  archive      = {J_KBS},
  author       = {Liangshi Sun and Xianzhen Huang and Zhiyuan Jiang and Jiatong Zhao and Xu Wang},
  doi          = {10.1016/j.knosys.2025.114488},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114488},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-conditional image synthesis with intra-class relation preservation. <em>KBS</em>, <em>330</em>, 114487. (<a href='https://doi.org/10.1016/j.knosys.2025.114487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling class-conditional data distributions remains challenging, since the intra-class variation may be very large. Different from generic class-conditional Generative Adversarial Networks (GANs), we take inspiration from the observation that there may exist multiple modes with diverse visual appearances in a single class, and propose an Intra-class Prototype-based Relation Preservation (IPRP) approach to improve class-conditional image synthesis. Toward this end, a generator is designed to learn class-specific data distribution, conditioned on intra-class prototype-based relation. To associate label embeddings with the cluster prototypes, we incorporate an auxiliary prototypical network to perform adversarial interpolation, and the synthesized data are required to encapsulate their relation to the corresponding prototypes in the form of interpolation coefficients. The prototypical network can be further leveraged to improve the class-conditional real-fake identification performance by injecting semantics-aware features into a discriminator. This design allows the generator to better capture intra-class modes We conduct extensive experiments to demonstrate that IPRP outperforms the competing class-conditional GANs in terms of data diversity and semantic accuracy.},
  archive      = {J_KBS},
  author       = {Yunfei Zhang and Xiaoyang Huo and Tianyi Chen and Si Wu and Hau-San Wong},
  doi          = {10.1016/j.knosys.2025.114487},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114487},
  shortjournal = {Knowl. Based Syst.},
  title        = {Class-conditional image synthesis with intra-class relation preservation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems. <em>KBS</em>, <em>330</em>, 114485. (<a href='https://doi.org/10.1016/j.knosys.2025.114485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of new-generation artificial intelligence technologies, machines can process and analyze large-scale data more accurately and efficiently and for more complex tasks. Enhancing the usability and value of the information derived from various information systems across multiple dimensions is essential. However, traditional data dominance relationships cannot reflect people’s different levels of attention to antithetic features, leading to higher complexity and lower classification accuracy. Therefore, it is necessary to consider the weight relationships between attributes in the data, which refers to the degree of correlation between each attribute and the decision in multi-source information systems. Based on these weights and dominance relationships, we consider an entropy-based weighted information fusion method for processing supervised data in multi-source ordered decision systems. We intend four incremental fusion mechanisms to adjust information sources and attribute changes to save running time. Furthermore, experiments are conducted on nine real datasets to demonstrate our method’s effectiveness. The results show that the inevitable accuracy comparisons by the proposed method are superior to most fusion methods. In addition, the dynamic mechanisms, compared to static mechanisms, can significantly reduce running time.},
  archive      = {J_KBS},
  author       = {Xiaoyan Zhang and Jiajia Lin},
  doi          = {10.1016/j.knosys.2025.114485},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114485},
  shortjournal = {Knowl. Based Syst.},
  title        = {A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature reduction causal network (FRCN): A novel approach for analyzing coupling relationships in radar system. <em>KBS</em>, <em>330</em>, 114484. (<a href='https://doi.org/10.1016/j.knosys.2025.114484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To evaluate radar performance in complex electromagnetic environments, a compact and efficient causal model is required to model such a complex, nonlinear high-stakes problem. Hence, in this paper, we propose a feature reduction causal network (FRCN). Firstly, to determine the number of hidden layer features in the FRCN, a feature extraction strategy is designed using the intrinsic dimension (ID) of raw data as key prior knowledge, thereby reducing modeling complexity and improving computational efficiency. Then, to further reveal the causal relationships between features and the final objective, a Bayesian network (BN) is constructed in the task layer, intuitively showing the coupling relationships through a directed graph and providing interpretability for decisions on high-stakes problems. Moreover, we extend the layer-wise relevance propagation to the BN in the FRCN, enabling bidirectional reasoning throughout the entire process, which is beneficial to understand the model and its behavior in a human-understandable way. In experiments, it is proved that ID plays a significance role in feature number selection. Next, we design a new interpretable evaluation indicator, called decision-specific average edge relevance, to quantify interpretability. Compared to eight representative models, FRCN not only achieves higher accuracy but also provides stronger interpretability in terms of relevance, informativeness, and trustworthiness. A detailed analysis of a radar system enhances the understanding of coupling relationships among various factors, thereby validating the effectiveness of FRCN in feature reduction, interpretability, and trustworthiness for high-dimensional, complex, and nonlinear data.},
  archive      = {J_KBS},
  author       = {Chenfeng Wang and Xiaoguang Gao and Zidong Wang and Bo Li and Kaifang Wan and Xinyu Li and Chuchao He},
  doi          = {10.1016/j.knosys.2025.114484},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114484},
  shortjournal = {Knowl. Based Syst.},
  title        = {Feature reduction causal network (FRCN): A novel approach for analyzing coupling relationships in radar system},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning. <em>KBS</em>, <em>330</em>, 114483. (<a href='https://doi.org/10.1016/j.knosys.2025.114483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop knowledge graph reasoning aims to leverage the relations between multiple nodes in a knowledge graph to reason information about an event or entity. This reasoning process requires traversing multiple interconnected facts or knowledge points, which aids in understanding the model’s decision-making process. Multi-hop knowledge graph reasoning has driven the development of knowledge-based technologies, such as question-answering systems and recommendation systems. However, multi-hop reasoning relies on the connectivity between different entities in the knowledge graph. This characteristic makes multi-hop reasoning lack robustness when dealing with sparse data. To address the challenges of sparsity, recent studies pre-train knowledge graph embedding models to complete potential triples. The completion methods introduce noisy triples, which increases the risk of model selection errors and spurious paths. In this work, we propose a framework based on potential subgraph rule and reasoning context enhancement to mitigate the challenges of sparsity. On one hand, we leverage reasoning context to enhance state information and the reasoning process; on the other hand, we design an action perceptron based on the importance of reasoning context to reduce the introduction of noisy triples. Additionally, we analyze the phenomenon of data augmentation introducing spurious paths, and further utilize data augmentation-based potential subgraph rules to guide the reasoning process. This dual mechanism demonstrates stronger robustness in addressing sparsity challenges and spurious paths. Diverse experiments demonstrate that our model outperforms the existing multi-hop reasoning models across five datasets. Our implementations will be publicly available at: https://github.com/jianruichen/PreKGR .},
  archive      = {J_KBS},
  author       = {Congcong Sun and Jianrui Chen and Deguang Chen and Junjie Huang},
  doi          = {10.1016/j.knosys.2025.114483},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. <em>KBS</em>, <em>330</em>, 114482. (<a href='https://doi.org/10.1016/j.knosys.2025.114482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful self-supervised approach for learning generalized graph representations, achieving remarkable advancements in recent years. However, most existing GCL methods ignore the noise of the augmented global structure and the dynamic change in training, and lack detailed consideration in calculating local structural homogeneity. These limitations may lead to the model’s insufficient performance in capturing fine-grained semantic features at the node level, making it difficult to fully explore the potential semantic associations between adjacent nodes. Meanwhile, on a global scale, there is also a lack of the ability to model complex topological structures. To this end, we propose a new multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. This method dynamically adjusts the global structure via graph reconstruction and adaptively learns node representations; Meanwhile, a mutual rectification module is designed to predict the support scores of neighbors relative to anchors and quantify each neighbor’s contribution to view agreement. Both reconstruction and rectification are integrated into the training objective and effectively capture the graph structure information from both global and local scales, improving the quality and robustness of graph representations. We conduct extensive experiments on three downstream tasks: node classification, node clustering, and link prediction. The experimental results demonstrate that our method outperforms existing GCL methods across multiple tasks and datasets, validating the effectiveness and generalizability of the proposed model.},
  archive      = {J_KBS},
  author       = {Dengdi Sun and Zhixiang Wu and Mingwei Cao and Zhifu Tao and Zhuanlian Ding},
  doi          = {10.1016/j.knosys.2025.114482},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114482},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P-EVFL: Efficient verifiable federated learning with privacy. <em>KBS</em>, <em>330</em>, 114480. (<a href='https://doi.org/10.1016/j.knosys.2025.114480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has recently become popular and widely used in various areas. However, it still faces challenges like the leakage of the client’s local model updates and the server forging aggregation results. To address these issues, we propose an efficient verifiable federated learning scheme with privacy (P-EVFL), which seeks to ensure privacy and verifiability with a lower overhead. Specifically, we first design a lightweight masking technique to protect the honest clients’ local model updates. Next, we introduce homomorphic hash functions to develop a verifiable method to ensure the integrity of the aggregation results. Besides, to reduce the overhead of the verification process, a verification algorithm based on a Merkle tree is proposed. We also conduct comprehensive experiments and compare our scheme with other state-of-the-art schemes. The experimental results show that in a scenario with 100 clients, our scheme reduces the computational overhead by up to 8.15 % and the communication overhead by up to 67.38 %.},
  archive      = {J_KBS},
  author       = {Juan Ma and Xiangshen Ma and Yuling Chen},
  doi          = {10.1016/j.knosys.2025.114480},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114480},
  shortjournal = {Knowl. Based Syst.},
  title        = {P-EVFL: Efficient verifiable federated learning with privacy},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to extract and aggregate contexts for link prediction in heterogeneous graphs. <em>KBS</em>, <em>330</em>, 114478. (<a href='https://doi.org/10.1016/j.knosys.2025.114478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many diverse real-world graph datasets are heterogeneous graphs, and link prediction on these graphs is a fundamental task. The current trends of link prediction on heterogeneous graphs emphasize leveraging contextual information from either a path between a source node and a target node, or a sub-graph sampled around these two nodes. However, these approaches face limitations in identifying only beneficial contextual nodes around source and target and then effectively aggregating the representations of these nodes for improving overall prediction accuracy. To address these limitations, we claim that carefully-extracted context nodes can aid in accurate link prediction, and these context nodes should be similar to a source node or a target node in a representation space. To this end, we propose a new link prediction framework LEACH which learns to extract the beneficial context nodes and to aggregate their representations in heterogeneous graphs. Specifically, our approach involves three steps to learn: (i) generating heterogeneity-aware representations of nodes in the heterogeneous graph, (ii) selecting the context nodes based on the relatedness to the source and target nodes; and (iii) aggregating the representations of the context nodes to obtain the source and target representations. Extensive experiments demonstrate that LEACH significantly outperforms existing baselines on three publicly available heterogeneous graph datasets. We provide analytical insights into the rationale behind the superior performance of LEACH on link prediction.},
  archive      = {J_KBS},
  author       = {Jimin Woo and Minbae Park and Hyunjoon Kim},
  doi          = {10.1016/j.knosys.2025.114478},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114478},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning to extract and aggregate contexts for link prediction in heterogeneous graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation. <em>KBS</em>, <em>330</em>, 114477. (<a href='https://doi.org/10.1016/j.knosys.2025.114477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the integration of advanced data analytics techniques within People Analytics and Human Resource Information Systems (HRIS), emphasizing their application in both organizational and sports performance contexts. By synthesizing Tournament Theory, Human Capital Theory, and Social Network Theory, this research provides a comprehensive framework for understanding skill dissemination, performance evaluation, and wage determination. Utilizing the NBA 2 K dataset, this study quantifies both tangible and intangible player attributes, incorporating digital engagement and social media metrics to enhance traditional performance metrics. Employing community detection algorithms and the Independent Cascade Model, the research uncovers hidden competencies and their influence on team dynamics and organizational effectiveness. The results contest established HRIS approaches, suggesting a holistic talent management strategy that takes into account the multifacetedness of skills propagation through networks. This work offers significant implications for HR professionals, providing novel insights into strategic HR planning, talent acquisition, and performance management in the digital age.},
  archive      = {J_KBS},
  author       = {Tianzi Zheng and Riyaz Sikora},
  doi          = {10.1016/j.knosys.2025.114477},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114477},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bias-in-debias-out: Hierarchical channel-spatial bias calibration for cross-domain few-shot classification. <em>KBS</em>, <em>330</em>, 114475. (<a href='https://doi.org/10.1016/j.knosys.2025.114475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge of cross-domain few-shot learning (CD-FSL) stems from models’ inability to generalize source-domain inductive biases to target domains under significant distribution shifts. While existing methods predominantly employ strategies like auxiliary target data adaptation, feature disentanglement, or metric space alignment, they overlook two inherent biases entrenched during source-domain training: (1) channel-wise dependency on source-specific feature patterns and (2) spatial-wise preference for source-typical structures, both of which hinder cross-domain transfer. We propose the first unified C hannel- S patial D ual-dimensional B ias C alibration (CSDBC) framework to systematically address these biases through progressive dilution, recomposition, and alignment. Our approach integrates three key innovations: (1) a parameter-free S tatic B ase-class B ias D ilution (SBBD) module that dilutes source-specific channel-spatial biases through layer-wise and point-wise modulation, effectively suppressing overfitting to source-specific patterns; (2) a D ynamic N ovel-class B ias R ecomposition (DNBR) module that generates target-adaptive channel-spatial soft masks via meta-optimized lightweight depthwise separable convolutions, enabling target-domain channel reweighting and spatial preference adjustment; and (3) a N ovel-class C ross-image S emantic A lignment (NCSA) module that establishes channel correlations and spatial correspondences between support-query pairs, significantly enhancing both discriminability and semantic consistency of target-domain features. Extensive experiments across eight CD-FSL benchmarks demonstrate consistent improvements, outperforming SOTA methods by 1.35 % (5-way 1-shot) and 2.00 % (5-way 5-shot) in average accuracy under varying domain shifts.},
  archive      = {J_KBS},
  author       = {Minghui Li and Hongxun Yao},
  doi          = {10.1016/j.knosys.2025.114475},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114475},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bias-in-debias-out: Hierarchical channel-spatial bias calibration for cross-domain few-shot classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer. <em>KBS</em>, <em>330</em>, 114471. (<a href='https://doi.org/10.1016/j.knosys.2025.114471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied in optimization because of their flexibility and ability to address complex and high-dimensional problems. Nevertheless, they face persistent challenges, including susceptibility to local optima, limited parameter adaptability, and premature convergence. Leadership-based metaheuristics, in which leaders guide the search process, encounter additional difficulties such as limited exploration capacity, leader stagnation, and reduced diversity, often stemming from underutilization of data generated during the search. To overcome these limitations, this study proposes a reinforcement learning–based approach, RL-LGWO, which enhances the Grey Wolf Optimizer (GWO) by integrating multi-agent reinforcement learning. In RL-LGWO, agents share experiences to improve decision-making, and reinforcement learning is employed to decouple and adapt the leader update mechanism, thereby improving the exploration–exploitation balance and enabling leaders to dynamically escape local optima. The proposed method was evaluated against two GWO-enhancing algorithms, three RL-based GWO variants, PSO, WOA, and the original GWO across 23 well-known benchmark functions, in addition to the recent CEC2022 benchmark suite. Experimental results show that RL-LGWO achieved the best solutions on 17 of the 23 benchmark functions, with superior convergence speed and improved stability, while incurring only a minor runtime increase compared with the original GWO. Furthermore, on the CEC2022 suite, RL-LGWO outperformed competing algorithms on 10 of 12 test functions, underscoring its robustness and adaptability to recent and challenging benchmarks. Overall, the findings indicate that RL-LGWO delivers a substantive improvement over state-of-the-art alternatives and holds strong potential to advance leadership-based metaheuristics for a wide range of optimization problems.},
  archive      = {J_KBS},
  author       = {Afifeh Maleki and Mehdy Roayaei and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.114471},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment. <em>KBS</em>, <em>330</em>, 114470. (<a href='https://doi.org/10.1016/j.knosys.2025.114470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large language models (LLMs) has advanced natural language processing by improving contextual understanding and generalization abilities. However, despite these advances, determining event causality remains a challenging task. When LLMs are applied to this task, they frequently exhibit significant inconsistencies in recognizing causal representations, resulting in the phenomenon known as causal hallucinations. Specifically, LLMs perform well in predicting events with causal relationships but struggle with events without such relationships, frequently failing to achieve balanced performance across different causal scenarios. In this study, we propose MRBalance, a novel framework that uses role-based multi-agent debates to improve event causality identification. Our method transforms the task into a single-choice question-answering task, prompting LLM-based agents to engage in structured debates and justify their answers using their unique role-based perspectives. In addition, we introduce a mechanism for optimizing team members that selects the best agents to participate in the next debate when the debate rounds are lengthy. Extensive experiments on two benchmark datasets demonstrate significant performance improvements, highlighting the effectiveness of MRBalance in reducing causal hallucinations and increasing robustness.},
  archive      = {J_KBS},
  author       = {Xiang Zou and Xuanhong Li and Po Hu and Ming Dong},
  doi          = {10.1016/j.knosys.2025.114470},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114470},
  shortjournal = {Knowl. Based Syst.},
  title        = {MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIAFEx: An attention-based feature extraction method for medical image classification. <em>KBS</em>, <em>330</em>, 114468. (<a href='https://doi.org/10.1016/j.knosys.2025.114468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction techniques are crucial in medical image classification; however, classical feature extractors, in addition to traditional machine learning classifiers, often exhibit significant limitations in providing sufficient discriminative information for complex image sets. While Convolutional Neural Networks (CNNs) and Vision Transformer (ViT) have shown promise in feature extraction, they are prone to overfitting due to the inherent characteristics of medical imaging data, including small sample sizes or high intra-class variance. In this work, the Medical Image Attention-based Feature Extractor (MIAFEx) is proposed, a novel method that employs a learnable refinement mechanism to enhance the classification token within the Transformer encoder architecture. This mechanism adjusts the token based on learned weights, improving the extraction of salient features and enhancing the model’s adaptability to the challenges presented by medical imaging data. The MIAFEx output feature quality is compared against classical feature extractors using traditional and hybrid classifiers. Also, the performance of these features is compared against modern CNN and ViT models in classification tasks, demonstrating their superiority in accuracy and robustness across multiple complex medical imaging datasets. This advantage is particularly pronounced in scenarios with limited training data, where traditional and modern models often struggle to generalize effectively. The source code of this proposal can be found at github.com/Oscar-RamosS/Medical-Image-Attention-based-Feature-Extractor-MIAFEx .},
  archive      = {J_KBS},
  author       = {Oscar Ramos-Soto and Jorge Ramos-Frutos and Ezequiel Pérez-Zarate and Diego Oliva and Sandra E. Balderas-Mata},
  doi          = {10.1016/j.knosys.2025.114468},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114468},
  shortjournal = {Knowl. Based Syst.},
  title        = {MIAFEx: An attention-based feature extraction method for medical image classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic domain information modulation algorithm for multi-domain sentiment analysis. <em>KBS</em>, <em>330</em>, 114465. (<a href='https://doi.org/10.1016/j.knosys.2025.114465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidomain sentiment classification aims to improve model performance constrained by limited labeled data in a single domain by utilizing labeled data from multiple domains. Models that simultaneously train domain classifiers and sentiment classifiers have shown benefits. In this framework, domain classification serves as an auxiliary task, supplying crucial information for sentiment analysis. It is generally assumed that the importance of sentiment classification tasks remains consistent across all domains. By contrast, domain classification tasks exhibit variability because the impact of domain information on sentiment analysis differs among fields. This variability can be managed through adjustable weights or hyperparameters. However, as the number of domains grows, existing hyperparameter optimization algorithms face several challenges, including (1) high computational requirements, (2) convergence difficulties, and (3) increased algorithmic complexity. To efficiently generate the domain-specific information required for sentiment classification, we propose a dynamic information modulation algorithm. Specifically, the training process is divided into two phases. In the first phase, a global modulation factor that controls the proportion of domain classification tasks across all domains is established. In the second phase, we introduce an innovative cross-domain balancing modulation algorithm to refine the domain information embedded in the input text. This refinement is achieved using a gradient- and loss-based method. Experimental results show that our approach consistently enhances performance across most domains, achieving improvements of 0.3–1.0 % on 10 of 16 Amazon domains and 0.5–1.5 % on 3 of 5 Yelp domains, while maintaining performance comparable to baseline models in other domains.},
  archive      = {J_KBS},
  author       = {Chunyi Yue and Ang Li},
  doi          = {10.1016/j.knosys.2025.114465},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114465},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic domain information modulation algorithm for multi-domain sentiment analysis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intention-guided imitation learning methods under limited expert demonstration data. <em>KBS</em>, <em>330</em>, 114455. (<a href='https://doi.org/10.1016/j.knosys.2025.114455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation Learning has achieved significant results in various fields, such as robot control, autonomous driving, and unmanned vessel decision-making. This technology aims to mimic human behavior in specific tasks by learning the mapping between states and actions, enabling agents to execute tasks based on demonstrations. However, these methods rely on the acquisition of high-quality demonstration data, facing challenges such as difficulties in collecting expert samples, high costs, and low efficiency in policy learning. Particularly under limited sample conditions, imitation learning can easily get trapped in local optima, leading to lower success rates and accuracy in decision-making. Researchers have used data augmentation and transfer learning to tackle limited data. However, in complex scenarios, these methods are less effective due to a lack of domain-specific knowledge, which affects the interpretability of the model. To address these challenges, we propose an Intention-guided Imitation Learning method under limited expert demonstration data (ITIL), which extracts deep intent features from a small number of samples to enhance the agent’s understanding of the scene and improve the accuracy of the mapping from states to actions during Imitation Learning. Specifically, the core method consists of three modules: (1) Semantic Enhancement Module, which extracts spatiotemporal feature maps from a small number of raw trajectories to enrich the semantic information of expert data; (2) Intention Expression Module, which constructs an intention tree network to establish connections between different levels, effectively expressing and capturing expert intent; (3) Strategy Generation Module, which integrates the outputs of the first two modules as input to form efficient decision-making, creating a closed-loop architecture of cognitive understanding-knowledge expression-decision optimization. Experimental results show that our model outperforms baseline methods in navigation, capture, and formation tasks, with an average success rate improvement of approximately +6 % compared to the baseline method (ValueDICE).},
  archive      = {J_KBS},
  author       = {Yilin Liu and Xiangfeng Luo and Shaorong Xie},
  doi          = {10.1016/j.knosys.2025.114455},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114455},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intention-guided imitation learning methods under limited expert demonstration data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling. <em>KBS</em>, <em>330</em>, 114454. (<a href='https://doi.org/10.1016/j.knosys.2025.114454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of supervised medical image segmentation models, relying on a large amount of labeled data is impractical in real-world situations. Semi-supervised learning approaches aim to alleviate this challenge using unlabeled data through pseudo-label generation. Yet, existing semi-supervised segmentation methods still suffer from noisy pseudo-labels and insufficient supervision within the feature space. To solve these challenges, this paper proposes a novel semi-supervised 3D medical image segmentation framework based on a dual-network architecture. Specifically, we investigate a Cross Consistency Enhancement module using both cross pseudo and entropy-filtered supervision to reduce the noisy pseudo-labels, while we design a dynamic weighting strategy to adjust the contributions of pseudo-labels using an uncertainty-aware mechanism (i.e., Kullback–Leibler divergence). In addition, we use a self-supervised contrastive learning mechanism to align uncertain voxel features with reliable class prototypes by effectively differentiating between trustworthy and uncertain predictions, thus reducing prediction uncertainty. Extensive experiments are conducted on three 3D segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed approach consistently exhibits superior performance across various settings (e.g., 89.95 % Dice score on left Atrial with 10 % labeled data) compared to the state-of-the-art methods. Furthermore, the usefulness of the proposed modules is further validated via ablation experiments. The code repository is available at https://github.com/AIPMLab/Semi-supervised-Segmentation .},
  archive      = {J_KBS},
  author       = {Yunyao Lu and Yihang Wu and Ahmad Chaddad and Tareef Daqqaq and Reem Kateb},
  doi          = {10.1016/j.knosys.2025.114454},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. <em>KBS</em>, <em>330</em>, 114452. (<a href='https://doi.org/10.1016/j.knosys.2025.114452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of transfer learning strategies to solve cross-domain fault diagnosis problems has achieved significant results. However, most existing multi-source domain generalization fault diagnosis methods use a single classifier or introduce auxiliary classifiers, focusing on learning domain-invariant features or global feature distribution matching. Furthermore, since the data distributions of different source domains may be significantly different, this may lose the data distribution information specific to each source domain. In addition, how to reduce the variation in risk between samples within the same domain training is also a challenging issue. Finally, it is also crucial to balance the predictive outputs of multiple classifiers to adapt them to the data distribution of the target domain. Based on the above challenges, this paper proposes a multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. Feature weakly decoupled mechanism is achieved by employing multiple classifiers and incorporating the variance of samples within the same sample domain as a penalty term. This reduces the model’s sensitivity to changes in the extreme distribution of samples within the domain. Classifier weakly decoupled mechanism, on the other hand, reduces the inter-domain risk variance by minimizing the loss of variance in the predicted output of the source domain classifiers. This improves the robustness of the model to inter-domain distributional changes and covariate changes. Experimental results on three datasets validate the effectiveness and general applicability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Yawei Sun and Hongfeng Tao and Vladimir Stojanovic},
  doi          = {10.1016/j.knosys.2025.114452},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114452},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing large language models for bitcoin time series forecasting. <em>KBS</em>, <em>330</em>, 114449. (<a href='https://doi.org/10.1016/j.knosys.2025.114449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.},
  archive      = {J_KBS},
  author       = {Owen Chaffard and Pablo Mollá and Marc Cavazza and Helmut Prendinger},
  doi          = {10.1016/j.knosys.2025.114449},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing large language models for bitcoin time series forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction. <em>KBS</em>, <em>330</em>, 114447. (<a href='https://doi.org/10.1016/j.knosys.2025.114447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality identification and extraction are crucial in understanding causal relationships in text. Current studies heavily rely on datasets annotated with causal relationships. However, acquiring such datasets poses a challenge due to substantial costs, hindering progress in this research field. To address this, we introduce CausalEnhance, a novel approach designed to bridge this gap by combining weakly-guided pre-training with external causal knowledge. Our method starts with a rule-based system that automates causal annotation, enriching external data with explicit causal knowledge and creating pseudo labels. These pseudo-labels are then incorporated into a weakly supervised pre-training framework. We introduce three innovative pre-training tasks: the Pre-training Causal Clues Fill-Mask task (PCM) to pinpoint causality origins, the Pre-training Causality Identification task (PCI) to capture general causal patterns, and the Pre-training Causality Extraction task (PCE) for understanding explicit causal pairs and inferring implicit ones. Our experiments, conducted across eight datasets in two languages, English and Chinese, demonstrate CausalEnhance’s effectiveness in both identifying and extracting causality, highlighting its potential as a robust method for textual causality analysis in different linguistic contexts.},
  archive      = {J_KBS},
  author       = {Meiyun Wang and Kiyoshi Izumi and Hiroki Sakaji},
  doi          = {10.1016/j.knosys.2025.114447},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114447},
  shortjournal = {Knowl. Based Syst.},
  title        = {CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis. <em>KBS</em>, <em>330</em>, 114446. (<a href='https://doi.org/10.1016/j.knosys.2025.114446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated domain generalization (FDG) as a solution to address the cross-client data heterogeneity problem in privacy-sensitive scenarios has drawn extensive attention in the field of intelligent fault diagnosis of industrial equipment in recent years. Nevertheless, most of the existing FDG-based diagnosis methods rely on client feature distribution alignment or data augmentation strategies, risking data leakage caused by the transmission of deep features and statistical information. To overcome the above-mentioned issues, a margin-guided parameter decoupling-consensus (MGPDC) framework is proposed to decouple the dependence of conventional federated domain generalization methods on features and data distributions and realize the extraction of common knowledge across clients. This framework initially employs a federated meta-learning-driven universal feature extractor to create a transferable shared feature space amidst heterogeneous client data, effectively enhancing the generalization ability of the model for unknown working conditions. Next, a parameter decoupling-consensus synergy (PDCS) mechanism is proposed. In this mechanism, an isolation module is established based on the consistency of parameter updates for parameter decoupling, effectively suppressing model update conflict. Subsequently, an implicit alignment mapping approach is devised for the screened parameters with strong consistency to achieve the extraction of cross-domain common knowledge. Then, an adaptive global margin guidance (AGMG) strategy is proposed to mitigate the interference of the blurred class boundaries during the federated process on common knowledge extraction. Finally, extensive experiments using real wind turbine gearbox data demonstrate the effectiveness and advancement of the MGPDC framework.},
  archive      = {J_KBS},
  author       = {Linhan Gou and Qikang Li and Baoping Tang and Xiaolong Zhang and Zihao Li and Yonggang Liu},
  doi          = {10.1016/j.knosys.2025.114446},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114446},
  shortjournal = {Knowl. Based Syst.},
  title        = {Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network to surrogate computational bone remodelling in the calcaneus. <em>KBS</em>, <em>330</em>, 114445. (<a href='https://doi.org/10.1016/j.knosys.2025.114445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a data-driven approach using surrogate models based on Multi-Layer Perceptrons to predict bone remodelling outcomes in the calcaneus, both with and without fractures. The objective is to develop and train a neural network that accurately captures the biomechanical factors influencing the problem and predicts the resulting bone density distribution in the calcaneus. Given the complexity of bone healing processes, a comprehensive dataset was collected to train and validate the models under two distinct scenarios: an intact calcaneus and a fractured calcaneus treated with a surgical screw. Key parameters of the surrogate model, namely, the number of hidden layers, hidden layer size, and activation function, were optimized to enhance model performance. Additionally, training parameters such as learning rate and batch size were tuned. The hyperbolic tangent activation function was found to yield a lower mean squared error compared to the rectified linear units. Larger batch sizes and learning rates were found to improve model performance. The neural network designed to predict bone density in the intact model outperformed the one used for the fractured calcaneus with a screw, largely due to the increased variability in the fractured data. When the fracture did not significantly alter the trabecular distribution, prediction accuracy improved. Finally, the structural response of the models was evaluated, and it was observed that the trabecular arrangement inferred by the neural network tended to produce less stiff responses compared to those from the finite element method, likely due to the smoother density field predicted by the network.},
  archive      = {J_KBS},
  author       = {Ana Pais and Jorge Lino Alves and Jorge Belinha},
  doi          = {10.1016/j.knosys.2025.114445},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114445},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network to surrogate computational bone remodelling in the calcaneus},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAT: Federated causal adversarial training. <em>KBS</em>, <em>330</em>, 114440. (<a href='https://doi.org/10.1016/j.knosys.2025.114440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference has been proven to be a crucial technique for improving the efficacy and explainability of adversarial training (AT). However, its applicability in the decentralized adversarial training paradigm has not been fully explored. Where one potential challenge is to apply the causal inference in the settings of non-independent and identically distributed (Non-IID) federated learning. In particular, the imbalanced data distributions among various clients will unavoidably hinder the efficacy and adaptability of causal inference. To address this issue, this paper proposes a novel yet practical method dubbed Federated Causal Adversarial Training (FCAT), which seeks to improve causal models via calibrated correction information. Additionally, we introduce a lightweight slack aggregation method aimed at addressing client model disparities and minimizing the communication overhead in each iteration. Extensive experimental results demonstrate that FCAT significantly improves the efficacy of causal models in federated adversarial training, and remarkably outperforms the current state-of-the-art (SOTA) competitors on multiple widely-adopted benchmarks.},
  archive      = {J_KBS},
  author       = {Yunhao Feng and Yanming Guo and Mingrui Lao and Yulun Wu and Yishan Li and Yuxiang Xie},
  doi          = {10.1016/j.knosys.2025.114440},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114440},
  shortjournal = {Knowl. Based Syst.},
  title        = {FCAT: Federated causal adversarial training},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem. <em>KBS</em>, <em>330</em>, 114439. (<a href='https://doi.org/10.1016/j.knosys.2025.114439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The polynomial robust knapsack problem (PRKP) is a variant of the classic knapsack problem by incorporating uncertain costs and benefits from item combinations, leading to a nonlinear objective function and exponential solution space. These complexities make the PRKP suitable for real-world scenarios where interactions between items unpredictably impact outcomes. However, existing algorithms struggle to efficiently solve large instances of the PRKP due to its computational complexity. Therefore, this paper presents an iterative heuristic algorithm leveraging a neural network (NN) to address the PRKP, reducing the solution space and enabling efficient resolution of subproblems. The framework integrates an NN trained in two steps: general training and fine-tuning. The trained model is then embedded in the iterative heuristic algorithm to tackle the PRKP. A synthetic dataset comprising 2500 instances, ranging from 100 to 1500 items, is created to train the NN. Comparative evaluations are conducted using 1600 benchmark instances from the literature and 140 larger instances containing between 2000 and 15,000 items. We compare our approach against two state-of-the-art algorithms for the PRKP: a genetic algorithm and a random forest-based heuristic. Computational results demonstrate that the proposed algorithm outperforms the genetic algorithm, providing superior solution quality with significantly reduced computing times. Meanwhile, against random forest-based heuristic, it delivers better solution quality with only a moderate increase in computing time. For larger instances, it maintains its advantage in solution quality while remaining computationally efficient. These results highlight the algorithm’s scalability, effectiveness, and potential to address the PRKP.},
  archive      = {J_KBS},
  author       = {José González-Cortés and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114439},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114439},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interplay between bayesian neural networks and deep learning: A survey. <em>KBS</em>, <em>330</em>, 114438. (<a href='https://doi.org/10.1016/j.knosys.2025.114438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning models have seen significant success across various domains, their black-box learning nature and lack of interpretability affect their reliability in safety-critical applications like medical diagnostics and autonomous vehicles. In an attempt to address these limitations, Bayesian neural networks (BNNs) offer a promising alternative by incorporating uncertainty estimation into model predictions, enhancing transparency and decision-making. However, BNN development has primarily focused on efficient, high-fidelity approximate inference and guaranteed convergence in asymptotic settings. These are unsuitable for modern high-dimensional, multi-modal, and non-asymptotic deep learning applications, undermining their theoretical advantages. To bridge this gap, this paper provides in-depth reviews on how approximate Bayesian inference leverages deep learning optimization to achieve high efficiency and fidelity in high-dimensional spaces and multi-modal loss landscapes. It also reconciles Bayesian consistency with generalization objectives in non-asymptotic settings and investigates the generalization capabilities of BNNs. Additionally, this survey examines the often-overlooked expressiveness of BNNs, emphasizing how weight uncertainty and the absence of in-between uncertainty affect their performance. This survey aims to inspire BNN practitioners to adopt a deep learning perspective and offer valuable insights to propel further advancements in the field.},
  archive      = {J_KBS},
  author       = {Yinsong Chen and Samson S. Yu and Zhong Li and Jason K. Eshraghian and Chee Peng Lim},
  doi          = {10.1016/j.knosys.2025.114438},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114438},
  shortjournal = {Knowl. Based Syst.},
  title        = {Interplay between bayesian neural networks and deep learning: A survey},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TWDT: Training-free word-level controllable diffusion model for text generation. <em>KBS</em>, <em>330</em>, 114437. (<a href='https://doi.org/10.1016/j.knosys.2025.114437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controlled text generation (CTG) methods typically require the training of additional components, whereas diffusion models have already achieved fine control in image generation by adjusting latent feature information during the inference process. However, existing diffusion models still face issues such as “attribute leakage” and “overgeneration” when applied to text generation, leading to generated texts lacking precise control. To address these problems, we propose a training-free word-level controllable diffusion language network (TWDT). This network achieves fine-grained control of text generation by adjusting latent space features during the inference process. Specifically, TWDT introduces an Alignment and Word Evaluation (AWE) module, which ensures accurate mapping of the text to a predefined set of feature words through syntactic segmentation and multi-level semantic alignment. At the same time, a similarity threshold filtering mechanism is applied to inject Gaussian noise into low-consistency nodes, ensuring semantic consistency and stability during generation. To evaluate the rigor and accuracy of the model, we have developed a high-quality multi-disease dental diagnostic dataset, all of which are annotated by experienced dental experts, serving as the benchmark for model evaluation. Experimental results show that TWDT outperforms existing diffusion models in terms of generation accuracy and rigor.},
  archive      = {J_KBS},
  author       = {Nan Gao and Yangjie Lu and Peng Chen and Guodao Sun and Ronghua Liang and Yilong Zhang},
  doi          = {10.1016/j.knosys.2025.114437},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114437},
  shortjournal = {Knowl. Based Syst.},
  title        = {TWDT: Training-free word-level controllable diffusion model for text generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network. <em>KBS</em>, <em>330</em>, 114436. (<a href='https://doi.org/10.1016/j.knosys.2025.114436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern vehicles depend on the Controller Area Network (CAN) for electronic control unit (ECU) communication, but its inherent vulnerabilities necessitate robust intrusion detection systems (IDS). Current machine learning and deep learning IDS solutions struggle with limited labeled data, class imbalances, and costly data collection processes. Few-shot learning, effective with few labeled samples, remains underexplored for in-vehicle networks (IVNs) despite its potential in data-scarce automotive cybersecurity scenarios. To bridge this gap, we introduce the first few-shot learning approach for multi-class intrusion detection in IVNs, leveraging a novel, lightweight Convolutional Anomaly Transformer. By integrating a 1D convolutional layer with an Anomaly Transformer, our model effectively classifies diverse attack types with minimal training data, mitigating class imbalance. Experiments on the widely-used real-world Car Hacking dataset, the complex ROAD dataset, and the distinct CAN-ML dataset validate its efficacy. On the Car Hacking dataset, we achieve an exceptional F1 score of 0.9994 with only 2 % of training data, improving to 0.9999 with 10 %. On the challenging ROAD dataset, characterized by diverse attacks and high variability, the model achieves an F1 score of up to 0.9980 using just 10 % of training data. Demonstrating strong generalization capabilities, the model also attains an impressive F1 score of 0.9918 on the CAN-ML dataset, which features entirely different vehicles and attack distributions. Furthermore, the lightweight architecture of our proposed IDS enables practical deployment in resource-constrained automotive environments.},
  archive      = {J_KBS},
  author       = {Nguyen Thanh Minh Duy and Truong Hoang Bao Huy and Pham Van Phu and Tien-Dat Le and Daehee Kim},
  doi          = {10.1016/j.knosys.2025.114436},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterophily-aware dynamic hypergraph for semi-supervised classification. <em>KBS</em>, <em>330</em>, 114435. (<a href='https://doi.org/10.1016/j.knosys.2025.114435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph neural networks, as high-order graph neural networks, excel in handling intricate relationships within non-Euclidean infinite-dimensional spaces. However, conventional homophily assumption-based hypergraph methods exhibit limited effectiveness in semi-supervised classification scenarios involving heterophily problem, where neighboring nodes often belong to dissimilar categories. To address this challenge, this paper proposes a Heterophily-Aware Dynamic Hypergraph (HADHG) framework grounded in heterophily assumption through label domain analysis. The framework comprises three key components: a hypergraph-oriented label propagation method for deriving class-specific label features, a label tensor construction approach characterizing node-level heterophily intensity via 2D tensors, and a center attention mechanism that dynamically optimizes hypergraph structures. By enabling nodes to dynamically reconfigure the local graph structure based on microscopic heterophily intensity, HADHG effectively mitigates heterophily interference. Comprehensive experiments using real-flight data from Unmanned Aerial Vehicles and the public Gear dataset highlight the framework’s superiority over state-of-the-art methods. The codes and datasets are openly available at https://github.com/DL-LEO/HADHG .},
  archive      = {J_KBS},
  author       = {Shaojun Liang and Ying Zheng and Housheng Su and Lei Zhang and Yi Yang},
  doi          = {10.1016/j.knosys.2025.114435},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114435},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterophily-aware dynamic hypergraph for semi-supervised classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining. <em>KBS</em>, <em>330</em>, 114434. (<a href='https://doi.org/10.1016/j.knosys.2025.114434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have displayed their effectiveness in predicting sequence modelling compared to various systems. Nevertheless, some limitations of existing methods are the demand for enormous databases, computational expense, and the risk of overfitting. To address these problems, this study proposes a novel DL technique using knowledge distillation and sequence illness pattern recognition from medical databases. Firstly, the input data is pre-processed using the data cleaning method. The size of the sequence dataset and the duration of the sequential patterns are both considered during the process of using PREFIXSPAN to manage long sequential patterns. In the proposed strategy, a lightweight student network is employed to train a strong teacher network, which is produced by a Knowledge Distillation framework. A teacher network is assessed by the Attention Based Densely Connected Capsule Model (Attention-DC). An efficient, low-weight Depthwise Separable Convolutional Neural Network (DSCNN) model is then chosen as the student network. This study uses three datasets to solve enormous database issues. The KD helps prevent the student model from overfitting to noise or specific patterns in the training data. The Improved Coot Optimization Algorithm (ICOA) is applied to adjust the parameter. The hyperparameters used to optimize the performance of the proposed model are Epochs (300), learning rate (0.001), and batch size (32), respectively. The experiments use the resources of three different datasets, and Python is employed to analyze the results. The proposed technique achieves accuracy of 99.512 %, 99.329 % and 99.351 % for the heart disease, cardiovascular disease, and Diabetes dataset.},
  archive      = {J_KBS},
  author       = {Dinesh Kumar Bhawnani and Sunita Soni and Arpana Rawal},
  doi          = {10.1016/j.knosys.2025.114434},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural chain of thoughts for radiology education. <em>KBS</em>, <em>330</em>, 114433. (<a href='https://doi.org/10.1016/j.knosys.2025.114433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology education requires trainees to develop both perceptual and interpretive expertise. However, refinement of these skills is often impeded by the limited availability of mentorship, a consequence of the demanding schedules of experienced radiologists. This lack of personalized guidance makes it difficult for learners to recognize the mistakes they make, understand why those errors occurred and how to refine their perceptual processes. Many of these errors arise from subtle differences in visual attention, such as failing to fixate on an abnormality, allocating an insufficient fixation time, or overlooking an abnormality despite scanning the correct region. Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been explored for radiology tasks, they often struggle to detect such fine-grained multimodal variations, particularly when comparing gaze behavior between experts and trainees. To address these limitations, we introduce Structural Chain of Thoughts (SCoT), a novel framework that enhances LLMs and LMMs sensitivity to nuanced multimodal differences by structuring gaze data and radiology report into a thought graph. By leveraging a structural prior, SCoT systematically identifies key perceptual and interpretive discrepancies, allowing models to provide targeted, context-aware feedback. This structured approach not only highlights missed findings but also explains the reasoning behind perceptual errors, turning them into learning opportunities. Applied within radiology education, SCoT bridges the gap between expert and novice performance, offering a scalable solution for AI-driven diagnostic training. We further contribute a simulated dataset of perceptual errors in chest X-ray (CXR) interpretation, facilitating future research into multimodal reasoning and AI-driven medical education. Unlike conventional Chain-of-Thought approaches, SCoT explicitly integrates gaze and textual information into a structured reasoning process, yielding interpretable, fine-grained, and personalized feedback tailored to the unique needs of radiology training. The code and data will be available here: GitHub Repository .},
  archive      = {J_KBS},
  author       = {Akash Awasthi and Brandon Chung and Anh Mai Vu and Saba Khan and Ngan Le and Zhigang Deng and Rishi Agrawal and Carol C. Wu and Hien Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114433},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural chain of thoughts for radiology education},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing. <em>KBS</em>, <em>330</em>, 114431. (<a href='https://doi.org/10.1016/j.knosys.2025.114431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables the efficient execution of compute-intensive tasks by offloading them to edge servers. However, frequent user mobility in 5 G urban networks leads to increased latency, energy consumption, and resource wastage due to continuous handovers. To address these challenges, Energy Efficient Communication and Optimal Offloading Network, a framework is proposed that combines user mobility prediction and hybrid optimization for task offloading. Energy Efficient Communication and Optimal Offloading Network utilizes a modified Long Short-Term Memory model to predict user movement with high accuracy, achieving an accuracy improvement from 65 % to 95 % over ten iterations. Additionally, a Hybrid Grey Wolf Optimization Algorithm optimizes task allocation, resulting in a 30 % reduction in energy consumption and a 25 % improvement in server utilization compared to baseline methods. The framework achieves latency as low as 5 milliseconds for augmented reality tasks while maintaining scalability in high-traffic 5 G environments. The proposed model also outperforms baseline approaches in terms of task completion time, throughput, and communication efficiency, and it achieves a 94.5 % offloading success rate and 98 % augmented reality delay compliance. The proposed model provides a scalable and useful solution for real-time Augmented Reality by combining energy-constrained task allocation with mobility-aware predictions.},
  archive      = {J_KBS},
  author       = {Anitha Jebamani Soundararaj and Godfrey Winster Sathianesan},
  doi          = {10.1016/j.knosys.2025.114431},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified multi-subgraph pre-training framework for spatio-temporal graph. <em>KBS</em>, <em>330</em>, 114428. (<a href='https://doi.org/10.1016/j.knosys.2025.114428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph (STG) learning has shown great potential in capturing complex spatio-temporal dependencies and has achieved significant success in various fields such as traffic flow prediction, climate forecasting, and epidemiological spread research. By learning general features from spatio-temporal graphs, pre-trained graph models can capture hidden semantic information in the data, thereby enhancing the learning effect of downstream tasks and improving overall model performance. However, most existing spatio-temporal graph learning methods use the entire graph for training, which may not fully capture local structure and feature information. In addition, existing methods usually adopt sequence modeling techniques without fully considering the time decay effect, i.e., the need to apply decaying attention to distant time steps. To address these issues, this paper proposes a u nified dual-phase m ulti- s ubgraph pre-training s patio- t emporal graph framework (UMSST). Specifically, in the first phase, the framework learns the global representation of the spatio-temporal graph and locates key graph nodes, while learning the “unit representations” of these key nodes. In the second phase, multiple spatio-temporal subgraphs are constructed based on these “unit representations” to further capture the implicit encoding information of more general features around the corresponding subgraphs, thereby helping the model make full use of general features. Experimental results on real datasets show that the proposed pre-trained spatio-temporal graph framework significantly improves the performance of downstream tasks and demonstrates its effectiveness in comparison with recent strong baseline models.},
  archive      = {J_KBS},
  author       = {Mingze Zhong and Zexuan Long and Xinglei Wang and Tao Cheng and Meng Fang and Ling Chen},
  doi          = {10.1016/j.knosys.2025.114428},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114428},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified multi-subgraph pre-training framework for spatio-temporal graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provide explainable clues: A generative traceable method for knowledge graph completion. <em>KBS</em>, <em>330</em>, 114426. (<a href='https://doi.org/10.1016/j.knosys.2025.114426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a G enerative T raceable M ethod, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.},
  archive      = {J_KBS},
  author       = {Ziqi Ma and Jinpeng Li and Hang Yu},
  doi          = {10.1016/j.knosys.2025.114426},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114426},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provide explainable clues: A generative traceable method for knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability. <em>KBS</em>, <em>330</em>, 114405. (<a href='https://doi.org/10.1016/j.knosys.2025.114405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents xLLMBench, a transparent, decision-centric benchmarking framework that empowers decision-makers to rank large language models (LLMs) based on their preferences across diverse, potentially conflicting performance and non-performance criteria, e.g., domain accuracy, model size, energy consumption, CO 2 emissions. Existing LLM benchmarking methods often rely on individual performance criteria (metrics) or human feedback, so methods systematically combining multiple criteria into a single interpretable ranking lack. Methods considering human preferences typically rely on direct human feedback to determine rankings, which can be resource-intensive and not fully aligned with application-specific requirements. Motivated by current limitations of LLM benchmarking, xLLMBench leverages multi-criteria decision-making methods to provide decision-makers with the flexibility to tailor benchmarking processes to their requirements. It focuses on the final step of the benchmarking process (robust analysis of benchmarking results) which in LLMs’ case often involves their ranking. The framework assumes that the selection of datasets, metrics, and LLMs involved in the experiment is conducted following established best practices. We demonstrate xLLMBench’s usefulness in two scenarios: combining LLM results for one metric across different datasets and combining results for multiple metrics within one dataset. Our results show that while some LLMs maintain stable rankings, others exhibit significant changes when correlated datasets are removed, when the focus shifts to contamination-free datasets or fairness metrics. This highlights that LLMs have distinct strengths/weaknesses, going beyond overall performance. Our sensitivity analysis reveals robust rankings, while the diverse visualizations enhance transparency. xLLMBench can be used with existing platforms to support transparent, reproducible, and contextually-meaningful LLM benchmarking.},
  archive      = {J_KBS},
  author       = {Ana Gjorgjevikj and Ana Nikolikj and Barbara Koroušić Seljak and Tome Eftimov},
  doi          = {10.1016/j.knosys.2025.114405},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114405},
  shortjournal = {Knowl. Based Syst.},
  title        = {User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-ViTabQA: A novel benchmark for vietnamese question answering on open domain wikipedia table. <em>KBS</em>, <em>330</em>, 114391. (<a href='https://doi.org/10.1016/j.knosys.2025.114391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Open-ViTabQA, the first Vietnamese dataset for Table Question Answering (Table QA), addressing the lack of resources for Vietnamese natural language processing. The dataset was meticulously constructed and rigorously validated to ensure high quality. A comprehensive analysis of the structural characteristics of the dataset, including table structure, question types, and answer patterns, is presented. We also introduce BIF, a novel metric combining PhoBERT embeddings within BERTScore for semantic similarity and ViNLI for logical consistency, effectively capturing Vietnamese-specific linguistic nuances and logical coherence. The rigorously validated dataset, accompanied by an analysis of its structural characteristics, provides a robust framework for evaluating Table QA systems. Experiments with pre-trained models and large language models (LLMs) show that ViT5 achieves an F1-score of 45.22 %, an Exact Match (EM) score of 45.13 %, and a BIF score of 0.562. Among large language models, Gemini 2.0 Flash Experimental achieves 60.50 % F1 and 60.20 % EM, while Gemini 1.5 Pro-leads with a BIF score of 0.649, slightly outperforming Gemini 2.0 Flash Experimental (0.644 BIF), indicating more stable reasoning capabilities. However, a significant gap persists compared to human performance (86.49 % F1, 83.43 % EM, 0.781 BIF), highlighting challenges in capturing Vietnamese linguistic subtleties and logical intricacies. These findings underscore opportunities for advancing model performance and addressing data scarcity in Vietnamese Table QA. To facilitate reproducibility and further research, the Open-ViTabQA dataset is publicly accessible for research purposes.},
  archive      = {J_KBS},
  author       = {Dung Hoang Dao and Ngan Thi-Kim Huynh and Khanh Quoc Tran and Kiet Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114391},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114391},
  shortjournal = {Knowl. Based Syst.},
  title        = {Open-ViTabQA: A novel benchmark for vietnamese question answering on open domain wikipedia table},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRTF: A new tensor factorization for irregular multidimensional data recovery. <em>KBS</em>, <em>330</em>, 114372. (<a href='https://doi.org/10.1016/j.knosys.2025.114372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorizations, although serving as paramount tools for exploiting prior knowledge of multidimensional data, are unsuitable for emerging irregular multidimensional data with the arbitrary shape spatial domain (i.e., spatial-irregular tensor), such as superpixels and spatial transcriptomics. Developing new tensor factorizations suitable for spatial-irregular tensors poses a compelling challenge. To meet this challenge, we introduce a novel Irregular Tensor Factorization (IRTF), which can fully capture the intrinsic spatial and channel information behind the spatial-irregular tensor. Concretely, a spatial-irregular tensor can be decomposed into the product of an intrinsic regular tensor, learnable channel transform matrices, and a learnable spatial transform matrix. Accompanying IRTF, we suggest the Total Variation on Channel and Spatial Transforms (TV-CST) to exploit the local information of spatial-irregular tensors, which is hardly excavated by traditional total variation methods. Combining the proposed IRTF and TV-CST, we built a spatial-irregular tensor recovery model. Extensive experiments on real-world spatial-irregular tensors demonstrate the promising performance of our IRTF and its significant advantages on downstream tasks.},
  archive      = {J_KBS},
  author       = {Jin-Yu Xie and Hao Zhang and Xi-Le Zhao and Yi-Si Luo},
  doi          = {10.1016/j.knosys.2025.114372},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114372},
  shortjournal = {Knowl. Based Syst.},
  title        = {IRTF: A new tensor factorization for irregular multidimensional data recovery},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Creative style transfer for image stylization via learning neural permutation. <em>KBS</em>, <em>330</em>, 114368. (<a href='https://doi.org/10.1016/j.knosys.2025.114368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating novel artistic styles from a single style poses a significant challenge for traditional style transfer techniques, which typically focus on emulating the given style without introducing novel, surprising and value elements—fundamental criteria for evaluating creativity. In this paper, we propose Creative Style transFer (CSFer), a new style transfer approach for producing creative artistic styles. We first introduce a neural permutation network (PerNet) to rearrange the feature maps of a single-style image, thus producing new style features. These features are then transferred to the feature maps of a content image, yielding stylized outputs. To evaluate creativity, we employ metrics encompassing style perception distance and artistic aesthetics to assess novelty, surprise, and aesthetic value, respectively. Using this evaluation, we select the most creative style from various stylized results generated via random permutation matrices and an input style. Finally, we effectively train PerNet using both the original and selected creative styles. Extensive experimental results demonstrate that CSFer can generate creative stylized results. Furthermore, CSFer exhibits robust generalization capabilities by seamlessly inserting PerNet into existing style transfer methods.},
  archive      = {J_KBS},
  author       = {Shimin Li and Zedong Zhang and Gan Sun and Li-Wei H. Lehman and Jian Yang and Jun Li},
  doi          = {10.1016/j.knosys.2025.114368},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114368},
  shortjournal = {Knowl. Based Syst.},
  title        = {Creative style transfer for image stylization via learning neural permutation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-driven deep learning network for image splicing forgery detection. <em>KBS</em>, <em>330</em>, 114365. (<a href='https://doi.org/10.1016/j.knosys.2025.114365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image splicing is a widely used technique for manipulating images in various social activities. Detecting splicing forgery is crucial in digital forensics to identify malicious image manipulation and protect information security. However, existing methods for detecting splicing forgery typically learn features in the spatial domain and struggle to effectively capture subtle features indicative of forgery, resulting in insufficient image splicing forgery detection accuracy. To address this challenge, we propose a novel deep-learning network named the frequency-driven deep-learning network (FreNet). Specifically, FreNet comprises three innovative modules: the frequency learnable module (FLM), the spatial-aware frequency learning module (SFLM), and the high-level feature-enhancement module (HFEM). The FLM effectively extracts high- and low-frequency features, thus enhancing frequency-domain representation and capturing subtle tampered features in splicing forgery images. The SFLM utilizes spatial information to guide frequency feature learning, thus enabling spatial-aware frequency feature learning. The HFEM enhances rich contextual and high-level semantic information through multilevel and multipath extraction and fusion. Extensive experiments on five benchmark datasets indicate that FreNet can achieve superior performance. Additionally, robustness experiments demonstrate the superior robustness of FreNet against various common attacks.},
  archive      = {J_KBS},
  author       = {Enji Liang and Kuiyuan Zhang and Zhongyun Hua and Xiaohua Jia},
  doi          = {10.1016/j.knosys.2025.114365},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114365},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-driven deep learning network for image splicing forgery detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-level sentiment analysis in social media using a hybrid deep transfer learning approach. <em>KBS</em>, <em>330</em>, 114125. (<a href='https://doi.org/10.1016/j.knosys.2025.114125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers have become interested in aspect-level sentiment analysis. In the traditional sentiment analysis of documents or sentences, a label was assigned to the entire sentence or document. Whereas a sentence or document can have aspects with different sentiments. Although deep learning models have succeeded in aspect-level sentiment analysis, these models require rich labeled datasets in different domains to extract text features and sentiment analysis. This paper uses deep transfer learning for sentiment analysis of aspect-level sentiment analysis (AHDT) of social network data. The backbone of the AHDT model is a version of RoBERTa’s pre-trained deep neural network specially trained to work on social data. The features extracted from the pre-trained RoBERTa network for sentiment analysis are injected into the Bi-GRU deep neural network and then the attention layer. BI-GRU can process sequences from both sides (left to right and vice versa) and extract hidden relationships. In addition, the attention layer allows the model to pay attention to the more influential aspects of the text and provide a better interpretation. Also, this article uses the Class imbalance method to balance for training the model with almost the same polarities. The test results of the AHDT model on four SemEval datasets for the aspect-sentiment analysis task show that the model has improved the F1-score value in Resturan2014, 2015, and 2016 datasets by 0.63, 27.01, and 15.93, respectively. Also, this model has increased the accuracy value in Resturan2015 and 2016 datasets to 9.21 and 0.54, respectively. In addition, the results of experimental tests in all datasets show that the obtained values of accuracy and F1-score are close to each other, which indicates the stability of the AHDT model.},
  archive      = {J_KBS},
  author       = {Kia Jahanbin and Mohammed Ali Zare Chahooki},
  doi          = {10.1016/j.knosys.2025.114125},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114125},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aspect-level sentiment analysis in social media using a hybrid deep transfer learning approach},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="matdes">MATDES - 117</h2>
<ul>
<li><details>
<summary>
(2025). Generation of high-aspect-ratio 3C-SiC nanowires and evaluation of their potential as battery materials. <em>MATDES</em>, <em>259</em>, 114872. (<a href='https://doi.org/10.1016/j.matdes.2025.114872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Waste Silicon (Si) powder generated during semiconductor manufacturing has attracted attention as a potential anode material for lithium-ion batteries. This study proposes a novel method to fabricate high-aspect-ratio cubic silicon carbide (3C-SiC) nanowires using a mixture of waste Si and graphite powders through laser processing. The mixture is placed between two plates to sandwich the laser-induced plume. This confinement promotes nanowire growth, increases the aspect ratio, shortens the lithium-ion diffusion length, and enables the fabrication of flexible electrodes. High-speed camera observations confirmed that the sandwiched plume was compressed and remained in air for nearly 10 s. Consequently, nanowires approximately 100–1200 nm in length and 15–60 nm in diameter (aspect ratio greater than 25) were generated. Electron diffraction and XRD analyses revealed that the nanostructures mainly comprised 3C-SiC. Battery performance evaluation tests of the generated nanowires showed that after 10 charge–discharge cycles at a current density of 50  mA/g, the SiC nanowires exhibited a specific capacity of 455 mAh/g, significantly higher than that of Si nanoparticles (291 mAh/g) and comparable to that of C-coated SiC nanoparticles (477 mAh/g). The SiC nanowires outperformed both Si nanoparticles and graphite anodes, demonstrating the potential of the proposed method in next-generation lithium-ion battery (LIB) anode fabrication.},
  archive      = {J_MATDES},
  author       = {Kanon Minami and Kentaro Shimazu and Yoshiyuki Hattori and Jiwang Yan},
  doi          = {10.1016/j.matdes.2025.114872},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114872},
  shortjournal = {Mater. Des.},
  title        = {Generation of high-aspect-ratio 3C-SiC nanowires and evaluation of their potential as battery materials},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Study on the tribological performance of cr-V alloy steel assisted by the random forest algorithm. <em>MATDES</em>, <em>259</em>, 114869. (<a href='https://doi.org/10.1016/j.matdes.2025.114869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The factors influencing the tribological performance of wear-resistant alloy steel are characterized by multiple variables, strong interactions, and nonlinearity. Traditional qualitative empirical analysis has limitations in addressing this complexity. This study introduced an Random Forest prediction model that integrates microstructure analysis, tribological experiments, and machine learning. It quantitatively analyzed the relationship between microstructure and performance in Cr-V alloy steel using feature importance weights generated by the model. The analysis revealed that external loads had the most significant impact on the friction coefficient, with the highest weight (0.246). This effect was attributed to changes in surface contact and plastic deformation mechanisms. VC (weight: 0.204) and Cr 23 C 6 (weight: 0.148) followed, showing a stronger influence compared to other carbides. The wear rate was primarily governed—by approximately 80 %—by the internal microstructure, with Cr 7 C 3 (weight: 0.431) and VC (weight: 0.381) being critical factors. Cr 7 C 3 , as the main wear-resistant phase, directly improved spalling resistance, while VC at lower content helped suppress crack initiation by refining the microstructure and enhancing the interface. The new paradigm based on feature weight-assisted analysis had demonstrated the practical value of machine learning in optimizing tribological performance.},
  archive      = {J_MATDES},
  author       = {Shuaiwu Tong and Shizhong Wei and Shuaijun Zhang and Chong Chen and Liujie Xu},
  doi          = {10.1016/j.matdes.2025.114869},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114869},
  shortjournal = {Mater. Des.},
  title        = {Study on the tribological performance of cr-V alloy steel assisted by the random forest algorithm},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-bulk forming of thin-walled hollow components based on the self-consistency of internal pressure and shell deformation. <em>MATDES</em>, <em>259</em>, 114865. (<a href='https://doi.org/10.1016/j.matdes.2025.114865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instable metal flow easily occurs during the forming of thin-walled hollow components due to inappropriate control of forming load in conventional forming processes, thereby leading to forming failure. Accordingly, a Pseudo-Bulk Forming (PBF) method was proposed in this work, aiming at achieving the self-consistency of internal pressure and tubular blank’s deformation in a simple and stable way. In this process, Low-Melting-Point Alloy (LMPA) was solidified inside of tubular blank to constitute a composite rod and deformed simultaneously under compression. Then forming of thin-walled hollow component was converted to pseudo-bulk plastic deformation of a composite rod. PBF of a rectangular tube was taken as an example to study the loading conditions, stress state, and deformation behavior of tubular blank during this process experimentally and numerically. The results showed that PBF exhibited the advantages in preventing excessive thinning of shell thickness in hydroforming and inward buckling during roll-forming. The strong stability of LMPA’s plastic flow stress, which was caused by its low strain hardening behavior, could induce self-adaptive inner pressure on tubular blank, thereby resulting in the balanced metal flow in sidewall and corner regions. Besides, due to tangential friction generated by LMPA at LMPA/tubular blank interface and along metal flow direction, circumferential metal flow towards the corner region could be enhanced, and thereby leading to the conversion of stress states from tension-tension to tension–compression. The risk of fracture was then reduced and forming stability was improved in the case of forming structures with sharp corners.},
  archive      = {J_MATDES},
  author       = {Nan Xiang and Yan-lei Tian and Yi-quan Shu and Hai-rui Zhang and Tao Huang and Peng-yi Wang and Rui Zhang and Wan-ting Sun and Fei-yang Cheng},
  doi          = {10.1016/j.matdes.2025.114865},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114865},
  shortjournal = {Mater. Des.},
  title        = {Pseudo-bulk forming of thin-walled hollow components based on the self-consistency of internal pressure and shell deformation},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustained oxygen release Organic/Inorganic composite scaffold delivers BMSCs to promote spinal cord injury repair. <em>MATDES</em>, <em>259</em>, 114864. (<a href='https://doi.org/10.1016/j.matdes.2025.114864'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clinical repair of spinal cord injury (SCI) has long been constrained by the twin challenges of a persistent hypoxic microenvironment at the injury site and the low survival rate of transplanted cells. This study innovatively constructs a three-dimensional (3D) oxygen-releasing scaffold Poly(lactic-co-glycolic acid (PLGA)-Calcium Peroxide (CPO)/Gelatin Methacryloyl (PLGA-CPO/GelMA) featuring a core–shell structure achieved via emulsification-photocrosslinking technology. PLGA-CPO microspheres provide sustained oxygen release for over 14 days, while the GelMA hydrogel establishes a biomimetic microenvironment. In vitro experiments confirmed that under hypoxic conditions, the hydrogel composite scaffold maintained the proliferative activity of the bone marrow mesenchymal stem cells during 3D co-culture. Furthermore, when co-cultured with neurons in a 2D system simulating the in vivo SCI environment, the scaffold significantly promoted neuronal survival and proliferation. In a T9 complete transection SCI rat model, the scaffold transplantation group exhibited significantly improved Basso, Beattie, Bresnahan locomotor scores compared to control groups. Histological analysis revealed increased axonal regeneration, reduced glial scarring, and high survival rates of transplanted mesenchymal stem cells at the implantation site in the scaffold-treated group. Mechanistic studies demonstrated that the composite scaffold exerted a triple synergistic effect, encompassing promotion of angiogenesis and neural regeneration, alongside suppression of apoptotic responses. The developed Organic/Inorganic Composite scaffold sustainably ameliorates the injury microenvironment and synergistically enhances stem cell-mediated repair efficacy, providing a promising tissue engineering solution with significant potential for clinical translation in spinal cord injury.},
  archive      = {J_MATDES},
  author       = {Jun Hu and Xiqiang Zhong and Jiacheng Wang and Minghai Dai and Liangle Liu and Xiaofu Pan},
  doi          = {10.1016/j.matdes.2025.114864},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114864},
  shortjournal = {Mater. Des.},
  title        = {Sustained oxygen release Organic/Inorganic composite scaffold delivers BMSCs to promote spinal cord injury repair},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiC wire-mesh structured packing for chemical rectification: Structural design for optimizing mechanical properties and acid corrosion resistance. <em>MATDES</em>, <em>259</em>, 114862. (<a href='https://doi.org/10.1016/j.matdes.2025.114862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wire-mesh structured packings are essential mass-transfer components in chemical rectification/separation processes. However, their inherent high-porosity design and delicate thin-structure characteristic typically result in compromised mechanical properties. Furthermore, conventional metallic structured packings exhibit quite limited corrosion resistance when exposed to either oxidizing or reducing acidic environments. In this study, a hybrid process combining template replication and reaction sintering was developed, enabling the fabrication of SiC wire-mesh structured packings. A synergistic approach combining finite element analysis (FEM) and experimental validation was applied to optimize the traditional wire-mesh structural parameters. Mechanical performance was further enhanced by strategically inserting planar SiC sheets between adjacent corrugated layers, resulting in a remarkable 12-fold increase in compressive strength (from 1.8 MPa to 21.4 MPa). The fabricated wire-mesh SiC also exhibited superior anti-acid corrosion ability compared with the metallic counterparts. The corresponding industrial products have been commercialized and operated stably for over 3 years.},
  archive      = {J_MATDES},
  author       = {Yichen Xu and Shihao Sun and Yong Gao and Chong Tian and Zhenming Yang and Xiaodan Yang and Jinsong Zhang},
  doi          = {10.1016/j.matdes.2025.114862},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114862},
  shortjournal = {Mater. Des.},
  title        = {SiC wire-mesh structured packing for chemical rectification: Structural design for optimizing mechanical properties and acid corrosion resistance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of cold sintering temperatures on the microstructure and mechanical properties of BaZr0.7Ce0.2Y0.1O3-δ proton conductors. <em>MATDES</em>, <em>259</em>, 114857. (<a href='https://doi.org/10.1016/j.matdes.2025.114857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional sintering of barium zirconate cerates for proton-conducting ceramic membranes requires high temperatures (1500–1600 °C) and long dwell times (>24 h), leading to Ba evaporation that negatively impacts conductivity. This study adapted the cold sintering process (CSP) to consolidate BaZr 0.7 Ce 0.2 Y 0.1 O 3-δ (BZCY721) ceramics at 150–350 °C, followed by post-thermal treatment at 1300 °C. The cold sintered specimens were characterized for mechanical properties and compared to a specimen sintered conventionally at 1600 °C. The cold sintered materials exhibited a Zr-rich BZY phase (BaZr 0.9 Y 0.1 O 2.68 ) with smaller grain and pore sizes. The highest density and elastic modulus were found in the specimen cold sintered at 150 °C. Additionally, the hardness of the cold sintered samples was higher than that of the conventional reference due to finer grain size and reduced porosity. Fracture toughness measurements by the Vickers indentation test indicated a value of 1.26 MPa·m 0.5 for cold sintered specimens, compared to 0.93 MPa·m 0.5 for the conventionally sintered specimen. The specimen cold sintered at 150 °C yielded the highest fracture toughness value of 1.48 MPa·m 0.5 by micro-pillar splitting test, along with the total conductivity of 1.48 × 10 −4 S/cm at 400 °C, which is comparable to the conventionally processed reference.},
  archive      = {J_MATDES},
  author       = {Syed Ali Afzal and Moritz Kindelmann and Jürgen Peter Gross and Jürgen Malzbender and Ruth Schwaiger and Olivier Guillon and Martin Bram},
  doi          = {10.1016/j.matdes.2025.114857},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114857},
  shortjournal = {Mater. Des.},
  title        = {Effect of cold sintering temperatures on the microstructure and mechanical properties of BaZr0.7Ce0.2Y0.1O3-δ proton conductors},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cu-TCPP-mn nanozymes composite platelet-rich plasma hydrogel for infected wound healing. <em>MATDES</em>, <em>259</em>, 114854. (<a href='https://doi.org/10.1016/j.matdes.2025.114854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The management of infectious wounds is still a critical clinical challenge. This study introduces a multifunctional hydrogel composed of oxidized hyaluronic acid (OHA) and carboxymethyl chitosan (CMCS), enhanced with platelet-rich plasma (PRP) and copper-tetra(4-carboxyphenyl)porphyrin-manganese (Cu-TCPP-Mn) nanozymes for advanced wound-healing applications. The hydrogel was synthesized via a Schiff base reaction, crosslinking the aldehyde groups of OHA with the carboxymethyl groups of CMCS to create a dynamic network with tunable rheological properties and excellent biocompatibility. Incorporation of PRP enriched the hydrogel with growth factors, markedly promoting tissue regeneration, whereas Cu-TCPP-Mn nanozymes effectively scavenged reactive oxygen species by mimicking superoxide dismutase and catalase activities. Furthermore, the hydrogel modulated macrophage polarization, and the synergistic effects of PRP and Cu-TCPP-Mn helped to alleviate persistent inflammation in infected wounds. A series of experiments showed that the CHPM hydrogel enhanced cell proliferation, migration, and differentiation, modulated inflammatory responses, and accelerated wound healing. The hydrogel also exhibited superior swelling capacity, self-healing behavior, and shape-memory functionality. These results underscore the potential of this hydrogel to be an innovative bioactive dressing for infectious wound healing with substantial promise for clinical antibacterial applications.},
  archive      = {J_MATDES},
  author       = {Han Chen and Pu Yang and Yikun Ju and Songjie Li and Xin Dan and Ping Xue and Xuanji Huang and Lanjie Lei and Xing Fan and Yang Li},
  doi          = {10.1016/j.matdes.2025.114854},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114854},
  shortjournal = {Mater. Des.},
  title        = {Cu-TCPP-mn nanozymes composite platelet-rich plasma hydrogel for infected wound healing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microscopic characterization of the anisotropic mechanical behavior of human linea alba and anterior rectus sheath: Contributions of collagen and elastin. <em>MATDES</em>, <em>259</em>, 114853. (<a href='https://doi.org/10.1016/j.matdes.2025.114853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abdominal wall tissues, including the linea alba (LA) and anterior rectus sheath (ARS), exhibit pronounced structural and mechanical heterogeneity that critically influences function and surgical outcomes. Current hernia repair meshes often fail to replicate this complexity, highlighting the need for a mechanistic understanding linking microarchitecture to tissue mechanics. This study combines uniaxial tensile testing with two-photon confocal microscopy to quantify collagen fiber orientation and elastin distribution in ARS and LA samples from eight human donors. Mechanical testing in longitudinal and transverse directions revealed pronounced anisotropy in ARS, with collagen alignment strongly predicting tissue stiffness (R 2 = 0.79–0.88) and explaining inter- and intra-individual mechanical variability. LA displayed a layered collagen network with higher elastin content, consistent with its role in strain accommodation. By directly correlating microstructural organization with mechanical performance, this work uncovers key design principles for bioinspired implants: anisotropic collagen fiber orientation and elastin distribution must be considered to replicate native tissue mechanics. Specifically, the findings demonstrate that replicating the anisotropic collagen–elastin architecture is essential for achieving biomechanical compatibility in surgical meshes. This study provides a novel framework for engineering heterogeneous materials that faithfully reproduce native tissue mechanics, bridging fundamental biomechanics and translational biomaterials design.},
  archive      = {J_MATDES},
  author       = {Laure Astruc and Frédéric Turquier and Mathias Brieu and Thierry Hoc},
  doi          = {10.1016/j.matdes.2025.114853},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114853},
  shortjournal = {Mater. Des.},
  title        = {Microscopic characterization of the anisotropic mechanical behavior of human linea alba and anterior rectus sheath: Contributions of collagen and elastin},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strong dependence of martensite morphology in low-carbon dual-phase steel on initial microstructure. <em>MATDES</em>, <em>259</em>, 114851. (<a href='https://doi.org/10.1016/j.matdes.2025.114851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates how heat treatments modify the initial microstructure of Fe–0.07C steel and how these changes affect martensite morphology and the resulting mechanical behavior of dual-phase (DP) steels after intercritical annealing (IA). For this purpose, full-annealed, normalized, martensitic, and spheroidized samples were produced and then intercritical-annealed at 830 °C for 15 min, followed by water quenching to produce ferrite-martensite DP microstructures. The full-annealed sample with the highest average ferrite grain size (D f ) of 8.66 µm before IA, yielded a banded ferrite-martensite structure (successive hard and soft domains) with superior performance after IA. A chain-like morphology developed in the initial and normalized specimens, while the martensitic sample exhibited a lath morphology after IA. Also, grain boundary martensite was formed in the spheroidized microstructure after IA. The hardness values for the DP initial, full-annealed, and normalized steel sheets with 0.34–0.37 martensite volume fraction (V m ) were almost 226 HV, while the lowest hardness for DP samples was observed in the DP spheroidized sample with almost 143 HV, and only 0.14 V m ; also, the DP martensitic sample showed a moderate hardness of ∼197 HV and 0.27 V m . All DP samples exhibited superior properties, accompanied by the disappearance of the yield point phenomenon after IA. The highest yield and tensile strength values were achieved for the DP full-annealed sample (413.4 MPa and 661.5 MPa, respectively); whereas the lowest values were observed in the DP spheroidized sample with 308.3 MPa and 499 MPa, respectively. The full-annealed sample after IA revealed the best combination of ductility and strength. The occurrence of recovery of the strain hardening rate (RSHR) mechanism led to higher strength and ductility in the full-annealed sample after IA compared to other DP samples. All DP samples exhibited a perfect ductile fracture. The dominant void initiation in the DP samples was ferrite/martensite decohesion.},
  archive      = {J_MATDES},
  author       = {Alireza Shaabani and Roohollah Jamaati and Seyed Jamal Hosseinipour},
  doi          = {10.1016/j.matdes.2025.114851},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114851},
  shortjournal = {Mater. Des.},
  title        = {Strong dependence of martensite morphology in low-carbon dual-phase steel on initial microstructure},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and mechanism research of online control and monitoring system for laser welding quality. <em>MATDES</em>, <em>259</em>, 114849. (<a href='https://doi.org/10.1016/j.matdes.2025.114849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of appropriate protective gas is essential for achieving superior quality in the laser welding of titanium alloys. This research focuses on optimizing the protective environment of the welding zone by varying the precharge duration of the protective gas. A systematic investigation was conducted to assess the impact of these adjustments on the quality of weld formation. By employing a combination of multi-scale characterization techniques, including macro-morphological analysis of the weld, plasma spectroscopy assessments, and microstructural evaluations, the fundamental physical phenomena occurring during the welding process and the patterns of weld quality evolution were elucidated. Additionally, a real-time monitoring approach utilizing plasma spectroscopy diagnostics was developed. This method allows for the reverse inference of the welding process state through the interpretation of plasma spectral characteristics, thereby establishing connections with the oxidation behavior of titanium alloys and facilitating a comprehensive analysis of the factors contributing to disturbances in the molten pool fluid dynamics. Furthermore, a numerical model grounded in thermodynamic principles was created to simulate the dynamic evolution of the molten pool, offering a quantitative explanation of the mechanisms by which the state of the protective gas influences the fluid behavior and thermal stability of the molten pool.},
  archive      = {J_MATDES},
  author       = {Qianqian Song and Miao He and Tengfei Li and Jinghua Han and Changtao He and Xiaoshuai Guo and Guoying Feng and Lingling Xiong},
  doi          = {10.1016/j.matdes.2025.114849},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114849},
  shortjournal = {Mater. Des.},
  title        = {Design and mechanism research of online control and monitoring system for laser welding quality},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of low melting point alloy with high latent heat based on predictive models and standardized experiments. <em>MATDES</em>, <em>259</em>, 114848. (<a href='https://doi.org/10.1016/j.matdes.2025.114848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses discrepancies in existing literature by implementing standardized sample preparation procedures and characterization methods, thereby establishing the most comprehensive phase change point database for eutectic low-melting-point alloy (LMPA) to date. A machine learning-based (random forest) phase change point prediction model was developed, effectively overcoming the practical limitations of traditional activity coefficient-based approaches. Furthermore, a latent heat prediction model incorporating melting entropy, mixing entropy, and the solid–liquid heat capacity difference was proposed, demonstrating superior accuracy for quaternary and quinary systems. Guided by these models, two high-performance LMPA (HLHD65 and HLHD76) were designed: HLHD65 achieves 10.31 % and 10.54 % higher mass and volumetric latent heat density, respectively, than Indalloy 140, while HLHD76 demonstrates improvements of 20.13 % and 20.07 % over Wood’s metal. This work provides a robust foundation and establishes a paradigm for developing advanced thermal energy storage materials.},
  archive      = {J_MATDES},
  author       = {Tianrui Hou and Yuming Xing and Zixian Wang and Jianbao Yin},
  doi          = {10.1016/j.matdes.2025.114848},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114848},
  shortjournal = {Mater. Des.},
  title        = {Development of low melting point alloy with high latent heat based on predictive models and standardized experiments},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing multi-level heterogeneous structures in multi-principal element alloys for superior cryogenic tensile properties. <em>MATDES</em>, <em>259</em>, 114845. (<a href='https://doi.org/10.1016/j.matdes.2025.114845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-level heterogeneous structures, consisting of heterogeneous grain structure, B2 nanoprecipitates, and chemical short-range ordering (CSROs), were designed and fabricated in the (CoNiV) 95 Al 5 multi-principal element alloy. The material exhibits superior tensile properties at 298 K, with simultaneous enhancement of yield strength and uniform elongation at 77 K. Specifically, it achieves ∼1.65 GPa yield strength and ∼19 % uniform elongation at room temperature, improving to ∼2.0 GPa and 22 % under cryogenic conditions (77 K). Under identical tensile strain, the average density of geometrically necessary dislocations (GNDs) increases more significantly at 77 K than at 298 K, enhancing hetero-deformation-induced hardening and improving tensile ductility. Uniformly dispersed nano-scale B2 nanoprecipitates provide strong precipitation hardening, while dense chemical short-range ordering (CSRO) imparts precipitation-like hardening through dislocation pinning. The strengthening at each level and the synergistic hardening effects among different levels are responsible for the excellent tensile properties in the multi-level heterogeneous structures, especially at 77 K.},
  archive      = {J_MATDES},
  author       = {Luke Xu and Yan Ma and Guohao Qin and Ping Jiang and Xiaolei Wu and Fuping Yuan},
  doi          = {10.1016/j.matdes.2025.114845},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114845},
  shortjournal = {Mater. Des.},
  title        = {Constructing multi-level heterogeneous structures in multi-principal element alloys for superior cryogenic tensile properties},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selection of key alloying elements for improving the elastic modulus of titanium alloys based on feature screening methods. <em>MATDES</em>, <em>259</em>, 114844. (<a href='https://doi.org/10.1016/j.matdes.2025.114844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the background of modern industrial lightweighting and high performance, the low elastic modulus of titanium alloys has become a key issue restricting their structural efficiency and load-bearing capacity. This study conducted feature screening on a small sample dataset, identifying the mean of atomic energy of the ground state (Fm1), the mean of a-lattice constant (Fm29), the mean of nuclear charge number (Fm40), and the variance of melting enthalpy (Fv43) as the four key features affecting the elastic modulus. The prediction accuracy R 2 of the best model reached 0.96, and a mathematical expression linking the modulus to these four key alloy factors was established using symbolic regression algorithms, achieving a direct correlation between input and target performance. Experimental verification revealed that, in addition to B and Si enhancing the modulus of titanium alloys, the element Ga can also significantly improve the modulus of titanium alloys. Alloys with elastic modulus exceeding 135 GPa were successfully prepared, achieving an increase of over 25 % in elastic modulus compared to TC4 alloy. Further research indicates that the high modulus properties of titanium alloys are primarily attributed to the precipitation of high-modulus second phases α 2 , TiB, and Ti 5 Si 3 in the microstructure.},
  archive      = {J_MATDES},
  author       = {Qingguo Huang and Dejun Song and Yameng Liu and Xinming Feng and Huadong Fu and Zhihao Zhang},
  doi          = {10.1016/j.matdes.2025.114844},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114844},
  shortjournal = {Mater. Des.},
  title        = {Selection of key alloying elements for improving the elastic modulus of titanium alloys based on feature screening methods},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Targeting rectal cancer using fluorescent nanoparticles conjugated to a novel GRPR-binding peptide for tumor imaging applications. <em>MATDES</em>, <em>259</em>, 114841. (<a href='https://doi.org/10.1016/j.matdes.2025.114841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical treatment of rectal cancer is difficult due to anatomical complexity. To improve tumor resection, fluorescence-guided surgery (FGS) has been developed using near-infrared fluorescence (NIRF, approximately 800 nm) and a dedicated camera system. Indocyanine green (ICG), an FDA-approved NIRF probe, enables optical imaging. The gastrin-releasing peptide receptor (GRPR), a member of the G protein-coupled receptor family, is widely expressed in rectal cancer cells. This abundant expression makes GRPR an ideal biomarker for molecular targeting and imaging of rectal cancer. In this study, the location and expression levels of GRPR were measured by immunofluorescence, immunohistochemistry and western blot. Our data confirmed significant overexpression of GRPR in rectal cancer cells and tissue samples, providing a significant indication for GRPR targeting evaluation. We designed the novel GRPR-targeting peptide, GRP-derived peptide (GRP-DP) derived from the natural GRPR-binding gastrin-releasing peptide (GRP). The newly developed GRP-DP demonstrated strong in vitro GRPR-targeting capabilities for rectal cancer imaging, potentially aiding surgeons in achieving complete tumor resection. Additionally, we investigated the use of ICG encapsulated within poly(lactic-co-glycolic acid)-polyethylene glycol (ICG/PLGA-PEG) nanoparticles (NPs) as a vehicle for fluorescent tumor imaging in rectal cancer. The ICG-NPs were functionalized with GRP-DP, exhibiting favorable physicochemical properties, including controlled ICG release kinetics and biocompatibility.},
  archive      = {J_MATDES},
  author       = {Somayeh Rezaei and Mark Fonteyne and Luis J. Cruz and Nada Badr and Ajinkya Manelkar and Mahin Saberi and Ronald L.P. van Vlierberghe and Alexander L. Vahrmeijer and Christina Eich and Fernando Albericio and Louise. van der Weerd and Peter J.K. Kuppen},
  doi          = {10.1016/j.matdes.2025.114841},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114841},
  shortjournal = {Mater. Des.},
  title        = {Targeting rectal cancer using fluorescent nanoparticles conjugated to a novel GRPR-binding peptide for tumor imaging applications},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Antibacterial NIR responsive targeted nanocomposite hydrogels loaded with taxifolin for bone repair. <em>MATDES</em>, <em>259</em>, 114840. (<a href='https://doi.org/10.1016/j.matdes.2025.114840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone defects have long posed a challenge in trauma orthopedics. Despite advancements in bone tissue engineering, there remains a bottleneck in developing bone implants that are less toxic, more effective, and reduce the need for secondary surgeries. To address this, we devised a light-responsive bone-targeted smart nano-delivery system. This system integrates polydopamine (PDA)-coated TAX-loaded ZIF-8 nanoparticles into a hydrogel with strong bioadhesion and biocompatibility (TAX@ZIF-8@PDA/ODEX-HD, TZPG). When exposed to near-infrared light, TZPG + NIR demonstrated a high photothermal conversion efficiency of 51.79 %. It exhibited a 99 % inhibition rate against Staphylococcus aureus, while also enhancing the proliferation and differentiation of osteoblasts (MC3T3-E1), thereby accelerating bone defect repair in a rat cranial bone defect model. Additionally, TZPG + NIR accelerates bone tissue repair by upregulating osteogenic-related proteins (ALP, RUNX2, OSX, OCN) while enhancing the expression of COL-I and PDGFA proteins to promote angiogenesis. Overall, TZPG + NIR created an antimicrobial microenvironment in vitro , enabled intelligent controlled release, and programmed degradation during the bone repair cycle, achieving a one-time therapeutic effect. This study highlights the promising applications of near-infrared light-responsive material TZPG in regenerative medicine, offering a novel approach to developing multifunctional bone scaffolds for repairing bone defects as a viable alternative to autografts.},
  archive      = {J_MATDES},
  author       = {Hewei Wei and Feifei Feng and Qiteng Ding and Junran Yang and Taojing Yu and Xiaoyu Wu and Xiaohang Sun and Chuanbo Ding and Yupeng Song},
  doi          = {10.1016/j.matdes.2025.114840},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114840},
  shortjournal = {Mater. Des.},
  title        = {Antibacterial NIR responsive targeted nanocomposite hydrogels loaded with taxifolin for bone repair},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Carbonization driven magnetic domain evolution in Ni@C nanocomposites: Impact on magnetic anisotropy and heating efficiency. <em>MATDES</em>, <em>259</em>, 114838. (<a href='https://doi.org/10.1016/j.matdes.2025.114838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid nanocomposites of nickel nanoparticles (Ni NPs) embedded in a carbon matrix hold significant promise for environmental remediation by integrating the adsorption capacity of carbon with the antimicrobial effects induced by localized heating of Ni NPs under magnetic hyperthermia. In this work, we investigate the evolution of the structural, magnetic and thermal properties of Ni@C nanocomposites as a function of the carbonization temperature. Samples within the magnetic single domain and multidomain regimes have been used to explore their potential for magnetic hyperthermia-assisted water remediation. To assess the influence of these different regimes on the tranverse suscepbility (TS) and magnetic heating performance, two representative samples, S600 and S1000, were selected to span the single-domain to multi-domain particle regimes. TS measurements show that S1000 exhibits a higher effective anisotropy field ( H Keff ) , attributed to its larger particle size and enhanced magnetic anisotropy. However, calorimetric magnetic heating studies reveal that S600 demonstrates significantly higher specific absorption rate (SAR) and intrinsic loss power (ILP) values, especially at lower concentrations. This enhanced heating efficiency is linked to its smaller particle size, reduced dipolar interactions, and magnetically soft behavior at room temperature. Consequently, more effective magnetic relaxation under moderate fields is enabled, highlighting the importance of optimizing nanoparticle size, anisotropy, and matrix dispersion to improve magnetic heating performance, offering design strategies for non-biomedical applications such as water purification and microbial inactivation.},
  archive      = {J_MATDES},
  author       = {M. Fadel and P. Álvarez-Alonso and M. Rivas and A. Adawy and J.L. Sánchez Llamazares and R. López-Antón and Shah Qasim Jan and Rajeswari Roy Chowdhury and Darío A. Arena and Hariharan Srikanth and Jesús A. Blanco and F. Suarez-García and Pedro Gorria},
  doi          = {10.1016/j.matdes.2025.114838},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114838},
  shortjournal = {Mater. Des.},
  title        = {Carbonization driven magnetic domain evolution in Ni@C nanocomposites: Impact on magnetic anisotropy and heating efficiency},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-plane bidirectional quasi-static compression behavior of a novel multi-step star-isosceles triangular honeycomb. <em>MATDES</em>, <em>259</em>, 114836. (<a href='https://doi.org/10.1016/j.matdes.2025.114836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-stage plateau stress structures have recently attracted increasing attention for impact protection and energy absorption. However, most existing designs either provide limited in-plane energy absorption or exhibit multi-stage features only in one loading direction. To address the above-mentioned limitations, this research proposes a novel star-isosceles triangular honeycomb (SITH) structure. It combines the tunability of star-shaped geometries with the stability of triangular frameworks. The mechanical performance of SITH was systematically investigated through quasi-static experiments and numerical simulations. The results show that SITH provides excellent energy absorption in both directions under in-plane biaxial loading. Uniquely, it achieves three plateau stages in the Y direction. A theoretical model was formulated based on the deformation mechanisms that were observed. This model accurately predicts plateau stresses and critical strains. Parametric analyses of the key geometric angles further reveal their influence on the mechanical response. These insights support the optimization of structural performance. Compared with previously reported hybrid honeycombs, the proposed SITH structure demonstrates superior stability, tunable multi-stage energy absorption, and effectiveness in both loading directions. This work establishes a theoretical basis for design of star-shaped hybrid honeycombs. It also offers a promising strategy for impact protection in complex engineering environments.},
  archive      = {J_MATDES},
  author       = {Qipeng Zhang and Jie Jia and Lin Dong and Guoliang Zhi},
  doi          = {10.1016/j.matdes.2025.114836},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114836},
  shortjournal = {Mater. Des.},
  title        = {In-plane bidirectional quasi-static compression behavior of a novel multi-step star-isosceles triangular honeycomb},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart near-infrared manganese-doped carbon dot-microneedle assemblies for tumor microenvironment-activated photodynamic-chemodynamic combined therapy. <em>MATDES</em>, <em>259</em>, 114833. (<a href='https://doi.org/10.1016/j.matdes.2025.114833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photodynamic therapy (PDT) that utilizes photosensitizers to induce reactive oxygen species (ROS) generation has become an important option in cancer clinical treatment due to its spatiotemporal controllability and non-invasive treatment characteristics. However, the inherent characteristics of the tumor microenvironment limit oxidative stress. In addition, traditional photosensitizers have problems such as poor water solubility, poor photostability and complex synthesis, which hinder the clinical application efficacy of PDT. To further enhance the efficacy of PDT, this study constructed a manganese-doped carbon dots (Mn-CDs) nanosystem with a dual-functional synergistic mechanism. It can catalyze endogenous H 2 O 2 to undergo a Fenton-like reaction in response to the weakly acidic microenvironment of tumors, continuously generating OH. Under laser irradiation, it can accelerate the Fenton like reaction to produce 1 O 2 (quantum yield of 0.39), deplete glutathione (GSH) to disrupt the intracellular redox balance, and the apoptosis rate can reach 86.14 %. The tumor-bearing mouse model showed that the tumor growth inhibition rate could reach 95.5 %. Notably, the treatment dose was precisely delivered through hyaluronic acid dissolved microneedles for transdermal delivery, ensuring a local effective drug concentration while reducing systemic toxicity, providing a new solution that is both highly efficient and safe for targeted treatment of oral squamous cell carcinoma.},
  archive      = {J_MATDES},
  author       = {Xiaofang Lv and Yongzhi Xu and Yuanping Hao and Beibei Cong and Yingjie Xu and Meihua Gao and Wanchun Wang},
  doi          = {10.1016/j.matdes.2025.114833},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114833},
  shortjournal = {Mater. Des.},
  title        = {Smart near-infrared manganese-doped carbon dot-microneedle assemblies for tumor microenvironment-activated photodynamic-chemodynamic combined therapy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An investigation of in situ observation and phase transformation mechanism in cyclic heat treatment of post-rolling ti-44Al-4Nb-1.5Mo-0.1B alloys. <em>MATDES</em>, <em>259</em>, 114830. (<a href='https://doi.org/10.1016/j.matdes.2025.114830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {TiAl alloys are promising for aerospace structures but limited by poor high-temperature deformability. β-phase solidified TiAl alloys exhibit improved HT formability but suffer β-induced brittleness and coarse lamellae, affecting serviceability. We developed a cyclic heat treatment protocol for Ti-44Al-4Nb-1.5Mo-0.1B alloy sheets that concurrently eliminates β-phase and refines lamellar colonies, achieving β-free full lamellar structure. The cycling process led to β-phase reduction, lamellar colonies coarsening, lamellae orientation fixing, and lamellar spacing was first densified then sparsened. The above phenomena are attributed to two phase transition processes: β → α and α → α 2 + γ. In the β → α stage, only a diffusive phase transformation occurred. Extended cycling alleviated Nb/Mo segregation, raising β-phase lattice constant and lowering its content. The α → α 2 + γ transformation involves martensitic (α → L1 2 ) and diffusion (L1 2 → γ) transformation stages. The difference in transformation rates between these two processes during the cyclic heat treatment leads to the residual presence of L1 2 phases within the lamellar colonies. During lamellae formation, the L1 2 phase acts as a “guide”, influencing the extension direction of the lamellae and playing a role in fixing lamellae orientation. This heat treatment resolves the processability-service performance trade-off, advancing TiAl alloys for aerospace engine components.},
  archive      = {J_MATDES},
  author       = {Siyuan Zhang and Haitao Jiang and Jiangping Xin and Yangjie Gao and Chunhui Wang and Zhichao Zhu and Feida Chen and Shiwei Tian},
  doi          = {10.1016/j.matdes.2025.114830},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114830},
  shortjournal = {Mater. Des.},
  title        = {An investigation of in situ observation and phase transformation mechanism in cyclic heat treatment of post-rolling ti-44Al-4Nb-1.5Mo-0.1B alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible thermoelectric energy harvesting devices via aerosol jet printed bismuth telluride (Bi2Te3) nanowires and intense pulsed light sintering. <em>MATDES</em>, <em>259</em>, 114828. (<a href='https://doi.org/10.1016/j.matdes.2025.114828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible thermoelectric devices offer great promise in converting waste energy into electrical energy for wearable electronics, soft robotics, and bendable sensor systems. In this work, we report the scalable fabrication of flexible thermoelectric films by aerosol jet printing of Bi 2 Te 3 -based nanowires onto a PLA nanofiber-based substrate, followed by optimized intense pulsed light (IPL) sintering. We optimized atomizer, ink, and sheath flows, as well as print speed, to ensure uniform and precise pattern deposition. Optical and SEM analyses revealed that the as-printed films form an intertwined, agglomerated network. This network is distinct from the aligned nanowires observed in drop-cast samples. The difference likely arises from the high shear forces and rapid solvent evaporation inherent to the aerosol jet process. Subsequent IPL sintering, performed at an optimized sintering distance and number of pulses, effectively densified the films without damaging the underlying PLA nanofiber on the substrate. These enhancements in film morphology and densification are crucial for minimizing interparticle resistance and promoting efficient carrier transport, ultimately boosting the thermoelectric performance. This study demonstrates a promising approach for the fabrication of high-resolution, flexible thermoelectric devices suitable for powering next-generation flexible Internet of things (IoT) devices by tapping on waste heat energy.},
  archive      = {J_MATDES},
  author       = {Guo Liang Goh and Haisheng Li and Xiang Yun Debbie Soo and Guanbo Chen and Seng Ann Sia and Samantha Faye Duran Solco and Dorsasadat Safanama and Samuel Lee and Yefei Li and Danwei Zhang and Wai Yee Yeong},
  doi          = {10.1016/j.matdes.2025.114828},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114828},
  shortjournal = {Mater. Des.},
  title        = {Flexible thermoelectric energy harvesting devices via aerosol jet printed bismuth telluride (Bi2Te3) nanowires and intense pulsed light sintering},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compressive response of concave negative poisson’s ratio cylindrical shell/TPMS core composite structures. <em>MATDES</em>, <em>259</em>, 114827. (<a href='https://doi.org/10.1016/j.matdes.2025.114827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional concave cylindrical shells, though lightweight, are prone to early failure under compression due to instability, limiting their energy absorption potential. This study introduces a hybrid shell–core design by integrating three types of concave shells with a Gyroid-based triply periodic minimal surfaces (TPMS) core to form a hierarchical structure that enhances both compressive stability and energy dissipation. Compression tests were conducted to examine mechanical performance and deformation behavior. Results show that alternating positive–negative units (NAP) consist of alternating positive and negative Poisson’s ratio units. Their peak load is ∼ 16 % higher than negative Poisson’s ratio units (NPR) and ∼ 60 % higher than positive ones (PPR), though specific energy absorption (SEA) is reduced.With TPMS integration, the NPR-based composite achieves 47 % improvement in both peak load and SEA, while the NAP composite attains a 63 % SEA increase. The failure modes of the three types of composite structures were different, with the PPR structure producing a peeling of the inner core and outer shell during failure, the NPR structure fracturing due to the extrusion of the inner and outer structures, and the NAP structure maintaining high loads due to the coupling of the first two deformations. This work demonstrates the effectiveness of shell-core synergistic mechanisms in optimizing structural properties and opens new avenues for designing lightweight, impact-resistant protective metamaterials in fields such as aerospace and automotive engineering.},
  archive      = {J_MATDES},
  author       = {Junjie Gong and Zhihao Ma and Yuanyuan Wei and Guoqian Song and Wenfeng Hao},
  doi          = {10.1016/j.matdes.2025.114827},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114827},
  shortjournal = {Mater. Des.},
  title        = {Compressive response of concave negative poisson’s ratio cylindrical shell/TPMS core composite structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing solidification cracking resistance in high-strength al-li alloys via strategic light rare earth alloying: An integrated experiment-simulation approach. <em>MATDES</em>, <em>259</em>, 114826. (<a href='https://doi.org/10.1016/j.matdes.2025.114826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Al-Li alloys possess advantages of low density and high stiffness, their severe hot cracking susceptibility (HCS) limits practical applications. Herein, we attempted to decrease HCS without sacrificing mechanical performance by replacing Sc with cost-effective light rare earth (LRE) elements. Results showed that the introduction of La, Ce, Nd, and Pr reduces the HCS to half that of the Base alloy due to grain refinement and melt purification. Finite element analysis (FEA) revealed that compared to elongated LRE phases characterized by high aspect ratios and interfacial curvature, blocky LRE phases with lower aspect ratios and interfacial curvature hinder crack propagation, leading to improved cracking resistance. Among the low-HCS variants, Pr-modified alloy shows remarkable yield strength of 398 MPa, exhibiting competitiveness compared to existing Sc-containing alloys. More importantly, Pr-modified alloy achieves a significant cost reduction of ∼27 %. The narrowed δʹ-Al 3 Li precipitation free zone (PFZ) and the uniformly distributed fine T 1 precipitates contribute to the promising mechanical properties of Pr-modified alloy. First-principles calculations indicated that the higher vacancy binding energies of Nd and Pr atoms suppress δʹ-PFZ coarsening, while their doping increases the coarsening energy barrier of T 1 precipitates. These benefits mitigate stress concentration and enhance deformation compatibility.},
  archive      = {J_MATDES},
  author       = {Youjie Guo and Yihao Wang and Fangzhou Qi and Liang Zhang and Song Pang and Ming Chen and Qi Li and Junmin Zhan and Quande Li and Jiawei Sun and Yuchuan Huang and Bo Ma and Yixiao Wang and Guohua Wu},
  doi          = {10.1016/j.matdes.2025.114826},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114826},
  shortjournal = {Mater. Des.},
  title        = {Enhancing solidification cracking resistance in high-strength al-li alloys via strategic light rare earth alloying: An integrated experiment-simulation approach},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling microstructure evolution and mechanical properties of silicide-strengthened (TiZrHfNb)100-xSix (x = 0, 1, 5, 7, 10 and 15) refractory high-entropy alloys. <em>MATDES</em>, <em>259</em>, 114825. (<a href='https://doi.org/10.1016/j.matdes.2025.114825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ductile TiZrHfNb refractory high-entropy alloy is selected to form silicide-strengthened (TiZrHfNb) 100-x Si x (x = 0, 1, 5, 7, 10 and 15, in at. %) alloys, and the influence of Si content on the microstructure and mechanical properties was systematically investigated. The solidification microstructure and the type of silicide show strong dependence on Si content from 1 % to 15 %, with the former changing from hypoeutectic to hypereutectic structure, and the latter evolving from M 3 Si-type to tetragonal-M 5 Si 3 -type silicide, and finally to the co-existence of both tetragonal- and hexagonal- M 5 Si 3 -type silicide. The formation of silicide phase enhances the strength both at the ambient and elevated temperatures, and a significant improvement of peak compressive strength from 221.3 MPa to 511.59 MPa at 800℃ was obtained after alloying 15 % Si to the prototype TiZrHfNb alloy. It was found that heterodeformation-induced strengthening, resulting from dislocation pile-ups at phase boundaries, was responsible for the enhancement in the strength. During hot deformation, the flow stress begins to decrease after reaching the peak value due to the presence of the dynamic recovery and dynamic recrystallization, which becomes more pronounced at higher Si content.},
  archive      = {J_MATDES},
  author       = {Xiaolei Han and Binbin Liu and Shuyi Xie and Cong Zhang and Li Huang and Wei Liu and Huaping Xiong and Feng Ye},
  doi          = {10.1016/j.matdes.2025.114825},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114825},
  shortjournal = {Mater. Des.},
  title        = {Unveiling microstructure evolution and mechanical properties of silicide-strengthened (TiZrHfNb)100-xSix (x = 0, 1, 5, 7, 10 and 15) refractory high-entropy alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polyphenol crosslinked carboxymethyl chitosan fibrous membrane for rapid hemostasis and infected wound healing. <em>MATDES</em>, <em>259</em>, 114824. (<a href='https://doi.org/10.1016/j.matdes.2025.114824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing advanced hemostatic materials that both facilitate more efficient haemostasis and anti-bacterial wound healing is essential for the treatment of severe trauma. Herein, we present a unique polyphenol crosslinked carboxymethyl chitosan (CMC) fibrous membrane (CMC/TA-FM), which was synthesized by converting commercial chitosan fibrous membranes into CMC and crosslinking them with tannic acid. This design not only enhances hemostatic efficacy but also introduces strong antibacterial and antioxidant capabilities. CMC/TA-FM achieves rapid haemostasis with minimal blood loss in both rat and pig liver injury models, outperforming clinically used hemostatic materials such as CELOX and other CMC-based products. In infected wound models, CMC/TA-FM significantly reduces bacterial load and accelerates wound closure, with results comparable to or even better than antibiotic-loaded gelatin sponges. CMC/TA-FM represents a promising hemostatic material that combines rapid bleeding control with strong antibacterial properties and promotes effective healing of infected wounds, positioning it as a potential next-generation hemostatic wound dressing for emergency trauma and infected wound management.},
  archive      = {J_MATDES},
  author       = {Feng Rao and Kuan Chen and Zhuo Wan and Ziting Liu and Fang Li and Yi Wang and Zuoying Yuan},
  doi          = {10.1016/j.matdes.2025.114824},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114824},
  shortjournal = {Mater. Des.},
  title        = {Polyphenol crosslinked carboxymethyl chitosan fibrous membrane for rapid hemostasis and infected wound healing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanics of bio-based uniaxially thermoformed polyurethane foams with zero and negative poisson’s ratio. <em>MATDES</em>, <em>259</em>, 114823. (<a href='https://doi.org/10.1016/j.matdes.2025.114823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uniaxial thermoforming compression is a promising technique for producing Zero and Negative Poisson’s Ratio (ZPR/NPR) open-cell foams. It allows for faster, easier, and more scalable production. The sustainability credentials of this method can be further improved by exploiting bio-based (i.e., from vegetable oils) open-cell polyurethane foams to generate porous and sustainable metamaterials. This work investigates the effect of manufacturing parameters (compression ratio, heating temperature and time) and compression direction on bio-based foam’s quasi-static and dynamic mechanical performance, converted through uniaxial thermoforming. ZPR behaviour was observed independently of processing parameters when thermoforming along the foam’s rise direction. NPR foams were, however, obtained when thermoforming occurred perpendicularly to the rise direction and the processing parameters were minimised. A two-level, three-factor full factorial experimental design was implemented for thermoforming along the foam’s rise direction. Results showed that the compression ratio mainly affected the material stiffness, whereas quasi-static energy dissipation strongly depended on heating temperature and time. NPR and ZPR foams presented suitable properties for tissue engineering and cushioning applications, further highlighting the potential of this manufacturing technique for use in bio-based porous substrates.},
  archive      = {J_MATDES},
  author       = {Jacopo Lavazza and Qicheng Zhang and Charles de Kergariou and Gianni Comandini and Wuge H. Briscoe and Jemma L. Rowlandson and Tulio Hallak Panzera and Fabrizio Scarpa},
  doi          = {10.1016/j.matdes.2025.114823},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114823},
  shortjournal = {Mater. Des.},
  title        = {Mechanics of bio-based uniaxially thermoformed polyurethane foams with zero and negative poisson’s ratio},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fabrication and response testing of a hybrid cellular structure with the ability to transform cells formed into diamond-shaped silhouettes. <em>MATDES</em>, <em>259</em>, 114822. (<a href='https://doi.org/10.1016/j.matdes.2025.114822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development, production and application of an active hybrid cell structure are presented. The composite structure is built from two very different materials, the combination of which enables changing the external geometry of the product with a temperature variation. The base (matrix) is a biodegradable polymer produced using additive manufacturing, to which wires made of high-strength material with a shape memory effect are subsequently added. The two materials are built into specially designed cell shapes with progressively increasing cell sizes. Since the wires are made of NiTinol alloy, this enables temperature activation of the wire network, which triggers controlled changes of the structure’s geometry. For this purpose, three implementations of cell structures were made with an objective to find the most effective backward transformation of the cellular structure after the activation of the wires. The activation of the structure was tested both in hot air and in hot water. Numerical simulations confirmed experimental tests and showed the strong regeneration ability of the hybrid especially in the third version of the structure.},
  archive      = {J_MATDES},
  author       = {Dejan Tomažinčič and Jure Kajbič and Jernej Klemenc},
  doi          = {10.1016/j.matdes.2025.114822},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114822},
  shortjournal = {Mater. Des.},
  title        = {Fabrication and response testing of a hybrid cellular structure with the ability to transform cells formed into diamond-shaped silhouettes},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A biomimetic bilayer fibrous scaffold for repair of massive rotator cuff tear via minimally invasive delivery. <em>MATDES</em>, <em>259</em>, 114821. (<a href='https://doi.org/10.1016/j.matdes.2025.114821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Therapeutic arthroscopy is a common minimally invasive procedure, yet repairing massive rotator cuff tears remains challenging due to difficulties in delivering patches and replicating the complex tendon–bone interface. Herein, a clinical treatment strategy integrating customizable biomimetic structural scaffold with a novel minimally invasive delivery technique is proposed. First, inspired by the collagen fiber network of rotator cuff, a biomimetic bilayer heterogeneous fibrous scaffold was designed and fabricated. The tendon layer combines aligned and crimped fibers to replicate natural tendon collagen and guide tendon cell migration, while the bone repair layer features randomly-oriented crimped fibers to provide osteogenic topological cues. Results demonstrated that crimped (36.17 % porosity, 30-μm pore diameter) and parallel-fibered (50-μm spacing) scaffolds enhanced tendon stem cell adhesion and directional alignment compared to control groups. Second, a specialized minimally invasive delivery system was pioneered to transport a 50 × 30 mm scaffold to the intra-articular target site through a minimal incision (≤10 mm), while preserving structural integrity and spatial orientation. Finally, arthroscopic simulations and implantation experiments validated the efficacy of this minimally invasive delivery strategy. This integrated solution for rotator cuff repair combines structural biomimetics, functional compatibility, and clinical feasibility, demonstrating strong translational potential.},
  archive      = {J_MATDES},
  author       = {Zhongfei Zou and Kai Liu and Fangyuan Cai and Xingke Huang and Zhen Shen and Yong He and Li Shen and Yuewei Chen},
  doi          = {10.1016/j.matdes.2025.114821},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114821},
  shortjournal = {Mater. Des.},
  title        = {A biomimetic bilayer fibrous scaffold for repair of massive rotator cuff tear via minimally invasive delivery},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HPV VLPs-based RNA-delivery system for synergistic BCL-2 silencing and mitochondrial apoptosis in NSCLC cells. <em>MATDES</em>, <em>259</em>, 114820. (<a href='https://doi.org/10.1016/j.matdes.2025.114820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-small cell lung cancer (NSCLC) resists apoptosis and lacks targeted therapies. We developed a tetra-functional assembly, siRNA_D-pep@VLP-SP5-2, integrating BCL-2 siRNA and a cationic mitochondrial destabilization D-peptide within the SP5-2-modified HPV virus-like particle (VLP). This multifunctional assembly integrate: (1) SP5-2-driven tumor targeting precision, (2) VLP-improved cellular uptake, (3) siRNA-induced BCL-2 silencing (70 % knockdown), and (4) D-peptide-triggered Cyt c release and mitochondrial apoptosis. In cells , siRNA_D-pep@VLP-SP5-2 induced 91 % apoptosis of A549 cells, while in A549 tumor-bearing mice, it reduced 78.2 % tumor growth without systemic toxicity. This multifunctional assembly pioneer’s co-delivery of gene and therapeutical peptide synergistically, overcoming key barriers in NSCLC precision therapy. In particular, the thoroughly revealed apoptotic kinetics for the RNAi therapeutics and peptide-mediated cytotoxicity, together with the modular design using VLP opens new avenues for multimodal cancer therapeutics, expecting to transition from “limit-target inhibition” toward “dynamic network-level regulation”, thereby establishing a paradigm-shifting framework for solid tumor treatment.},
  archive      = {J_MATDES},
  author       = {Meng-Fan Feng and Jinyu Zhu and Li-Miao Qin and Xianghui Yu and Haihong Zhang and Xiao-Xia Han and Yuqing Wu},
  doi          = {10.1016/j.matdes.2025.114820},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114820},
  shortjournal = {Mater. Des.},
  title        = {HPV VLPs-based RNA-delivery system for synergistic BCL-2 silencing and mitochondrial apoptosis in NSCLC cells},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties evaluation of MMCs via multi-scale nanoindentation and GMM: A case study on induction-cladded in-situ TiC/Ti coatings. <em>MATDES</em>, <em>259</em>, 114819. (<a href='https://doi.org/10.1016/j.matdes.2025.114819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inhomogeneous spatial distribution and size effect of multi-scale reinforced phases makes it challenging to characterize and analyze the surface mechanical properties of metal matrix composites (MMCs). Therefore, a multi-scale hybrid nanoindentation testing strategy integrated with the Gaussian mixture model (GMM) was developed to evaluate the surface mechanical properties of induction-cladded in-situ TiC/Ti multi-phase composite coating in this study. The coating consisted of α-Ti, a small amount of β-Ti and a diffusely distributed TiC reinforced phase. The microhardness stabilized at ∼ 600 HV 0.2 , and the TiC phase exhibited a “shallow hard − deep soft” behavior. The mechanical properties of within the TiC region (WTR) were between those of TiC and the matrix phase, and the β-Ti matrix phase exhibited superior performance to that of α-Ti. A correlation model between microhardness and single nanoindentation hardness was constructed using the modified rule of mixtures (ROM) method, revealing the evolution of the phase structure with an increase in the TiC volume fraction. GMM-based decoupling of nanoindentation data indicated that hardness and elastic modulus followed a three-peak Gaussian distribution, corresponding to TiC, WTR, and matrix phases. This study provides a theoretical foundation for the optimization of MMCs properties.},
  archive      = {J_MATDES},
  author       = {Jiangtao Gong and Helong Yu and Yanli Yin and Hongmei Wang and Zhe Yang and Xiang Xiao and Haiqing Li},
  doi          = {10.1016/j.matdes.2025.114819},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114819},
  shortjournal = {Mater. Des.},
  title        = {Mechanical properties evaluation of MMCs via multi-scale nanoindentation and GMM: A case study on induction-cladded in-situ TiC/Ti coatings},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigation on indentation scaling relationships of ITO thin films considering the indenter tip rounding defect. <em>MATDES</em>, <em>259</em>, 114818. (<a href='https://doi.org/10.1016/j.matdes.2025.114818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the applications of indium tin oxide (ITO) films, higher measurement requirements are implemented due to the significant effects of more complicated stress states and limitations of testing conditions on the mechanical properties. In this work, the effect of the tip bluntness on indentation responses and scaling relationships for film/substrate composite systems is investigated via finite-element (FE) simulations and dimensional analysis. A novel indentation method is proposed to measure the intrinsic elastic modulus of thin films based on the scaling relationship among the curvature of the loading segment in P - h curves and material properties. FE simulations indicate the significant effect of tip bluntness on indentation responses. However, the curvature is essentially independent of the dimensionless parameter of h m / t . Furthermore, the tilt effect during the direct calibration procedure is corrected through spatial mapping transformation of atomic force microscopy data. Herein, the measured tip rounding radius fitted by 2D profile and 3D topography are 70 ± 4.8 nm and ∼72.83 nm, respectively. The indentation data acquired with the actual Berkovich indenter are used to verify the scaling relationships. The elastic modulus of ITO films is calculated as ∼135.26 GPa, and the measured error is only ∼3.59 %.},
  archive      = {J_MATDES},
  author       = {Zhaoxin Wang and Lijia Li and Zongyang Zhang and Wei Ji and Ming Li and Xiangyu Zong and Cong Li and Han Wang and Jibing Wang},
  doi          = {10.1016/j.matdes.2025.114818},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114818},
  shortjournal = {Mater. Des.},
  title        = {Investigation on indentation scaling relationships of ITO thin films considering the indenter tip rounding defect},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructure evolution and the corresponding mechanical properties of fe-mn-al-C-nb low-density steel under aging treatment. <em>MATDES</em>, <em>259</em>, 114817. (<a href='https://doi.org/10.1016/j.matdes.2025.114817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop high-strength, low-density steels applicable for automotive field, the study systematically investigated Fe-28Mn-10Al-C-0.5Nb steel after aging at 450 °C-550 °C in terms of its microstructure evolution, mechanical properties, and deformation and strengthening mechanisms. Electron backscatter diffraction (EBSD) method served for examining the austenite grain morphology and the orientation of annealing twins at different aging temperatures. Transmission electron microscopy (TEM) served for elucidating the precipitation behavior and spatial distribution of NbC, κ-carbides, and other secondary phases. Furthermore, the deformation mechanisms under different tensile strains were explored using TEM and EBSD, with particular attention to the evolution of dislocations and other substructures in the deformed specimens. Quantitative evaluation was conducted on the yield strength variation under varying strengthening mechanisms through theoretical modeling. According to relevant results, with rising aging temperature, the finely dispersed spherical κ-carbides gradually transform into a uniformly distributed rectangular morphology. The strength and toughness of the experimental steel both increase with aging temperature, and the steel aged at 500 °C exhibits an outstanding overall property, with a tensile strength of 1199  MPa and an elongation of 37 %. Planar dislocation slip is the primary deformation mode, and the favorable strength-ductility balance results from the microband-induced plasticity. Calculations confirm dislocation strengthening as the primary strengthening mechanism in the experimental steel.},
  archive      = {J_MATDES},
  author       = {Litu Huo and Tao Ma and Weimin Gao and Yungang Li and Jianxin Gao},
  doi          = {10.1016/j.matdes.2025.114817},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114817},
  shortjournal = {Mater. Des.},
  title        = {Microstructure evolution and the corresponding mechanical properties of fe-mn-al-C-nb low-density steel under aging treatment},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ZnO@MXene nanoplatform for near infrared induced elimination of drug resistant bacteria and acceleration of infected wound healing. <em>MATDES</em>, <em>259</em>, 114816. (<a href='https://doi.org/10.1016/j.matdes.2025.114816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-resistant bacterial wound infections, especially those caused by methicillin-resistant Staphylococcus aureus (MRSA), pose a critical clinical challenge with limited effective therapeutic options. Here, we report a photothermally responsive nanoplatform, (ZWMx), engineered via hydrothermal synthesis to integrate efficient photothermal conversion, reactive oxygen species generation, and bacterial membrane disruption. The composite leverages the broad absorption in the near infrared region and excellent electrical conductivity of tungsten carbide MXene to overcome the photoinstability of ZnO, achieving a photothermal conversion efficiency of approximately 29.78 % and strong catalytic activity through reactive oxygen species. Upon irradiation at 808 nm, ZWMx rapidly eliminates over 90 % of MRSA in vitro within five minutes and disrupts established biofilms, indicating a synergistic and multifaceted bactericidal mechanism. In vivo , ZWMx promotes near-complete healing of MRSA-infected wounds within twelve days, with minimal thermal damage to surrounding tissues, high biocompatibility, and increased expression of vascular endothelial growth factor receptor one, suggesting enhanced angiogenesis. These findings establish a light-responsive therapeutic strategy for the targeted elimination of drug-resistant infections and effective stimulation of wound repair, providing a promising alternative to conventional antibiotic therapies.},
  archive      = {J_MATDES},
  author       = {Ruofeng Yin and Enoch Obeng and Zhixing Li and Akmal Ergashev and Wei Wang and Rongbing Chen and Wei Wu and Da Sun and Qingqing Yao and Wencan Wu and Yunzhong Zhan},
  doi          = {10.1016/j.matdes.2025.114816},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114816},
  shortjournal = {Mater. Des.},
  title        = {ZnO@MXene nanoplatform for near infrared induced elimination of drug resistant bacteria and acceleration of infected wound healing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of novel non-periodic biomimetic bone scaffolds using the moving morphable components method. <em>MATDES</em>, <em>259</em>, 114815. (<a href='https://doi.org/10.1016/j.matdes.2025.114815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone scaffolds are widely used in orthopedics for tissue repair and regeneration, yet achieving optimal bone growth through porous scaffolds remains a significant challenge. In this study, the Moving Morphable Components (MMC) method was employed to design novel non-periodic biomimetic bone scaffolds. Four types of scaffolds were created to mimic different human bone tissues. Their average elastic moduli were evaluated, and found to closely match with those of the corresponding bone tissues. Compared to triply periodic minimal surface (TPMS) structures, the novel scaffolds exhibited significantly higher permeability − up to 3.70 × 10 −8 m 2 at a porosity of 62 %. These scaffolds demonstrated not only suitable mechanical properties but also enhanced permeability. Furthermore, they showed a good manufacturability, making them practical for fabrication. Overall, the MMC-designed scaffolds present a promising solution with matched mechanical properties and superior permeability, potentially reducing stress shielding and promoting bone cell growth and regeneration in tissue engineering applications.},
  archive      = {J_MATDES},
  author       = {Hao Wang and Jiongyi Wu and Yuhang Chen and Michael Zhuravkov and Sergei Bosiakov and Youwei Zhang and Mohammed Rafiq Abdul Kadir and Jian Jiang and Yongtao Lyu},
  doi          = {10.1016/j.matdes.2025.114815},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114815},
  shortjournal = {Mater. Des.},
  title        = {Design of novel non-periodic biomimetic bone scaffolds using the moving morphable components method},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Photosensitive virus-like mesoporous silica for enhanced uveal melanoma internalization and photodynamic therapy. <em>MATDES</em>, <em>259</em>, 114814. (<a href='https://doi.org/10.1016/j.matdes.2025.114814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uveal melanoma (UM) is the primary form of intraocular malignancy, presenting major clinical challenges with its asymptomatic onset and high metastatic potential, which complicate early diagnosis and treatment. In this study, we have developed a localized photosensitive virus-like mesoporous silica nanoparticles (VSP) based photodynamic therapy (PDT) for dual-modal imaging and UM therapy. The spiky surface topography of the nanoparticles enhanced cellular penetration, while their hollow-tubular and porous structure allowed for high-capacity loading of photosensitizers. This dual-functional design enhanced tumor uptake and increased the generation of reactive oxygen species (ROS) within cells, thereby boosting PDT efficacy. By integrating photoacoustic imaging (PAI) and optical coherence tomography (OCT), we were able to visualise tumor location and margins, which improved treatment precision in the orthotopic UM model. The nanoparticles also demonstrated remarkable tumor-specific accumulation, achieving efficient retention and deep penetration within hours post-administration. VSP-mediated PDT effectively inhibited tumor progression while preserving ocular integrity. This study presents a versatile nanoplatform with excellent tumor penetration and theranostic capabilities, offering a promising approach for minimally invasive treatment of UM.},
  archive      = {J_MATDES},
  author       = {Pengyan Zhao and Shuyue Zhang and Peiyuan Wang and Houli Zhong and Yuming Chen and Da Zhang and Zhongjiang Chen},
  doi          = {10.1016/j.matdes.2025.114814},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114814},
  shortjournal = {Mater. Des.},
  title        = {Photosensitive virus-like mesoporous silica for enhanced uveal melanoma internalization and photodynamic therapy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing supercritical CO2 immersion resistance of aramid pulp-filled ethylene propylene diene monomer rubber composites through reinforced interfacial bonding. <em>MATDES</em>, <em>259</em>, 114812. (<a href='https://doi.org/10.1016/j.matdes.2025.114812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of supercritical carbon dioxide(sCO 2 )-resistant sealing rubbers is a key solution to addressing the critical challenges in the application of sCO 2 -related industries. This study focused on enhancing the sCO 2 immersion resistance of aramid fiber-reinforced ethylene propylene diene monomer (EPDM) rubber composites through strengthened interfacial bonding. Combined modification with coupling agents and polyisocyanate was applied to the surfaces of phosphoric acid-etched aramid fibers. H pull-out tests revealed that after modification, the interfacial bonding strength between the fibers and rubber significantly increased from 12.9 to 51.1 N. Scanning electron microscopy analysis further confirmed this enhanced interfacial bonding. Notably, the modified interface had minimal impact on the high-temperature compression set, thermal aging resistance, thermal decomposition temperature, or low-temperature performance. However, sCO 2 immersion tests (165 °C, 17 MPa, 3 days) revealed that interface reinforcement improved the tensile strength retention of EPDM composites containing phosphoric acid-treated aramid fibers modified with coupling agents and polyisocyanate. Specifically, this modification reduced tensile strength loss from 41 % to 33 %. This study provides a simple and effective surface impregnation-based interfacial reinforcement strategy to enhance the sCO 2 resistance of rubber composites.},
  archive      = {J_MATDES},
  author       = {Qi Wang and Jianxiong Gu and Ping Tao and Liangyan Wang and Chunming Wang and Yongliang Zhu and Yiwu Quan},
  doi          = {10.1016/j.matdes.2025.114812},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114812},
  shortjournal = {Mater. Des.},
  title        = {Enhancing supercritical CO2 immersion resistance of aramid pulp-filled ethylene propylene diene monomer rubber composites through reinforced interfacial bonding},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Patterned preparation of high-quality graphene film based on solution coating. <em>MATDES</em>, <em>259</em>, 114811. (<a href='https://doi.org/10.1016/j.matdes.2025.114811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphene has excellent electronic mobility, high electrical conductivity, and strong thermal conductivity. These properties make it suitable for use in electronic devices, sensors, and energy storage systems. However, current methods for producing graphene films face several problems. They are often expensive, require specific substrates, and have low success rates during transfer. These issues limit the large-scale use of graphene films. In this study, we propose a low-cost method to prepare graphene films. The method uses a flexible polyimide (PI) mask. Laser etching is used to create specific patterns on the PI mask. Then, a printing technique is applied to deposit graphene films onto quartz substrates. Compared to traditional approaches, this method is cheaper, works with various substrates. We used systematic characterization to evaluate the method. The results show that it can produce uniform and high-quality graphene films. We also studied the effects of film thickness, substrate treatment, and vacuum annealing on film performance. Hydrophilic treatment improves the dispersion of the graphene slurry. This helps the film become more uniform and improves its adhesion to the substrate. Vacuum annealing removes some dopants and makes the film cleaner. This method provides a promising solution for low-cost and large-scale production of graphene films.},
  archive      = {J_MATDES},
  author       = {Junwei Yin and Shuai Deng and Yuchang Zhang and Yunxian Cui and Mingfeng E},
  doi          = {10.1016/j.matdes.2025.114811},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114811},
  shortjournal = {Mater. Des.},
  title        = {Patterned preparation of high-quality graphene film based on solution coating},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel composite polydopamine-based hydrogel dressing that heals diabetic ulcers. <em>MATDES</em>, <em>259</em>, 114810. (<a href='https://doi.org/10.1016/j.matdes.2025.114810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current treatment of diabetic foot ulcers remains a great challenge due to the persistent chronic inflammatory trauma microenvironment caused by oxidative stress, elevated levels of inflammatory factors, impaired angiogenesis, and bacterial infection. However, current therapeutic strategies primarily focus on wound closure rather than addressing the underlying pathophysiology of diabetic wounds. Therefore, there is an urgent need for advanced wound dressings that not only promote wound closure but also modulate the wound microenvironment to accelerate tissue regeneration. Here, we report a multifunctional hydrogel dressing that can be conveniently fabricated through copolymerization of a complex formed by a polydopamine–polyethyleneimine hybrid coating (PDA–PEI) and GelMA. This hydrogel exhibits excellent mechanical strength, tissue adhesion, and self-healing capacity. It demonstrates antibacterial activity, alleviates oxidative stress and inflammation, promotes angiogenesis, regulates macrophage polarization, and enhances full-thickness skin regeneration in MRSA-infected diabetic mice. The article highlights the potential of this hydrogel as a promising therapeutic strategy for improving the clinical management of diabetic foot ulcers.},
  archive      = {J_MATDES},
  author       = {Shuxin Shi and Mei Yang and Tuohao Jiang and Yiran Liu and Jiaying Yang and Dhan V. Kalvakolanu and Jun Tang and Ling Zhang and Hui Ren and Baofeng Guo},
  doi          = {10.1016/j.matdes.2025.114810},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114810},
  shortjournal = {Mater. Des.},
  title        = {A novel composite polydopamine-based hydrogel dressing that heals diabetic ulcers},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-based multiphase CFD framework integrating DPM and CIEM for predicting dynamic cell adhesion in porous scaffolds. <em>MATDES</em>, <em>259</em>, 114808. (<a href='https://doi.org/10.1016/j.matdes.2025.114808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The architecture of porous scaffolds significantly influences the adhesion of seeded cells, which determines the scaffold’s final performance. However, how scaffold structure affects this process remains poorly understood. In this study, we aimed to address this challenge from the perspective of the hydromechanical microenvironment. We employed Computational Fluid Dynamics (CFD) method to simulate dynamic cell seeding in porous scaffolds with varying structures, using the Discrete Phase Model (DPM) to model seeded cells. A novel Cell Impingement Energy Model (CIEM) was implemented to capture cell-scaffold interactions, where adhesion was determined by impingement energy. The simulation results were validated through in vitro dynamic seeding and in vivo animal experiments. The results showed that despite comparable morphological parameters, TPMS and Voronoi scaffolds presented lower overall cell adhesion but a more uniform spatial distribution, while Diamond scaffolds exhibited higher cell adhesion, primarily localized on the surface. Adjusting the morphological parameters can improve the uniformity of cell distribution in Diamond scaffold. More importantly, the computational and experimental results were highly consistent, suggesting that CFD combining DPM and CIEM can effectively simulate dynamic cell seeding. This study presents a reliable approach for predicting cell adhesion in porous scaffolds, offering valuable insights for scaffold design and optimization.},
  archive      = {J_MATDES},
  author       = {Qinghua Tan and Ning Ji and Qiongchi Zhang and Bo Chen and Haoyu Wang and Bo Zhao and Dong Wang and Xijing He and Pengrong Ouyang},
  doi          = {10.1016/j.matdes.2025.114808},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114808},
  shortjournal = {Mater. Des.},
  title        = {Energy-based multiphase CFD framework integrating DPM and CIEM for predicting dynamic cell adhesion in porous scaffolds},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive framework to study the influence of beam shaping in laser metal fusion processes. <em>MATDES</em>, <em>259</em>, 114805. (<a href='https://doi.org/10.1016/j.matdes.2025.114805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beam shaping is considered a technology capable of dramatically improving quality and robustness of Laser Metal Fusion (LMF) processes. However, systematic investigations of its effects on melt-pool dynamics, temperature field and microstructure are still required. In this work, we propose an integrated approach combining a Computational Fluid Dynamics (CFD) model, in-situ temperature measurements and metallographic analysis to explore programmable ring beam profiles, ranging from Gaussian-dominant to ring-dominant configurations. This method, initially proposed on Ti-6Al-4V bead-on-plate tracks, validates melt-pool temperatures measured in-process by a dual-wavelength pyrometer against CFD predictions, which are in turn validated with metallographic cross-sections. Ring modes lowered peak temperature by up to 35 %, transforming deep-narrow pools (aspect ratio ≈0.9) into shallow-wide ones (≈0.4). This suppressed humping at line energies ≥ 0.28 J mm − 1, whereas lower energies produced only superficial melting. Simulations matched pyrometer data within 5 % whenever pool width equalled the pyrometers’ sensing spot; all tracks solidified into ultrafine α with retained β, independent of beam mode. Therefore, the combination of in-situ, ex-situ and CFD tools offers a practical workflow for assisting data-driven process optimization and can be easily extended to other LMF processes, with its potential implementation in industrial Laser Powder Bed Fusion.},
  archive      = {J_MATDES},
  author       = {Marida Pontrandolfi and Linda Squillaci and Jonas Olsson and Pradip Aryal and Robert Pederson and Isabelle Choquet and Antonio Ancona},
  doi          = {10.1016/j.matdes.2025.114805},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114805},
  shortjournal = {Mater. Des.},
  title        = {A comprehensive framework to study the influence of beam shaping in laser metal fusion processes},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electrospun P(VDF-TrFE)/ceria nanoparticle scaffolds for skeletal muscle regeneration. <em>MATDES</em>, <em>259</em>, 114804. (<a href='https://doi.org/10.1016/j.matdes.2025.114804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volumetric muscle loss (VML) presents a significant clinical challenge due to the limited regenerative capacity of skeletal muscle. Piezoelectric scaffolds have shown promise in enhancing muscle repair by converting mechanical cues into bioelectric signals. In this study, we investigate the regenerative potential of electrospun scaffolds composed of poly(vinylidene fluoride-trifluoroethylene) [P(VDF-TrFE)] and polycaprolactone (PCL), with or without cerium dioxide nanoparticles (Ce NPs), in a VML mouse model. Hyaluronic acid functionalization was employed to improve scaffold biocompatibility. In vitro experiments confirmed the biocompatibility of these scaffolds, while in vivo assessments over eight weeks demonstrated significant efficacy in restoring muscle function. Compared with PCL-Ce scaffolds, mice implanted with piezoelectric scaffolds exhibited faster grip strength recovery, more mature muscle regeneration, a more hierarchical arrangement of muscle fibers, and increased fiber diameter. Additionally, the antioxidant properties of Ce NPs reduced adipocyte infiltration and excessive collagen deposition and were associated with enhanced angiogenesis. Grip strength measurements further highlighted the superior regenerative performance of P(VDF-TrFE) scaffolds combined with Ce NPs. Overall, these findings underscore the potential of piezoelectric scaffolds integrated with antioxidants in promoting structural and functional muscle regeneration following VML.},
  archive      = {J_MATDES},
  author       = {Shengjing Xu and Muge Gu and Yihui Zhang and Yuanye Guan and Wei Yu and Xiangqi Zhang and Liyuan Kang and Zhen Zeng and Yanjie He and Wei-En Yuan},
  doi          = {10.1016/j.matdes.2025.114804},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114804},
  shortjournal = {Mater. Des.},
  title        = {Electrospun P(VDF-TrFE)/ceria nanoparticle scaffolds for skeletal muscle regeneration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crashworthiness of antiprism thin-walled structures under quasi-static and dynamic loading. <em>MATDES</em>, <em>259</em>, 114802. (<a href='https://doi.org/10.1016/j.matdes.2025.114802'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the quasi-static and dynamic crushing behavior of a novel antiprism thin-walled structure designed to enhance energy absorption for crashworthiness applications. Unlike conventional cylindrical, polygonal, and origami-inspired tubes, which do not fully exploit wall folding to generate plastic hinges, the antiprism configuration promotes the formation and propagation of multiple plastic hinge lines, enabling stable progressive collapse and extended plateau stages. The structures were fabricated from 316L stainless steel using laser powder bed fusion and evaluated through quasi-static compression, Split Hopkinson Pressure Bar tests, and finite element simulations with the Johnson–Cook model. Compared with conventional counterparts of equal mass and thickness, the antiprism tubes achieved 6.4–14 % higher specific energy absorption (SEA), 7–79 % higher crushing force efficiency (CFE), and 7–68 % lower undesired load-carrying capacity (ULC). Under dynamic impact, they also exhibited the lowest initial peak crushing force. These results highlight the antiprism design as a lightweight and efficient solution for energy-absorbing components in sandwich panels and protective liners.},
  archive      = {J_MATDES},
  author       = {Bin Xu and Wenjun Bai},
  doi          = {10.1016/j.matdes.2025.114802},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114802},
  shortjournal = {Mater. Des.},
  title        = {Crashworthiness of antiprism thin-walled structures under quasi-static and dynamic loading},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of oxygen content on elastic properties of an oxygen-graded titanium: Experimental and computational analyses. <em>MATDES</em>, <em>259</em>, 114801. (<a href='https://doi.org/10.1016/j.matdes.2025.114801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed nanoindentation mapping (HSNM), electron backscatter diffraction (EBSD), electron microprobe analyses (EPMA), and high resolution – microscale laser induced breakdown spectroscopy (HR– μ LIBS), were used to characterize the evolution of the elastic anisotropy of a commercially pure titanium (CP-Ti) having a gradient of oxygen concentration. CP-Ti samples were pre-oxidized in air at 655 ∘ C for 120 h to create a 35 μ m -deep gradient of oxygen within Ti, the oxygen-rich layer (ORL). Wedge-cut samples were prepared to spread the ORL over hundreds of micrometers instead of tens of micrometers for cross-sections. EPMA and HR– μ LIBS were used to quantify the oxygen distribution within the ORL in a relative and absolute manner, respectively. The Vlassak-Nix theory was used for inverse identification of the stiffness matrix terms as a function of the oxygen content. The stiffness matrix as a function of the oxygen concentration was used to simulate the stress–strain distribution at the sub-grain level in the ORL under tensile macroscopic loading. Configurations with and without external oxide were numerically tested to investigate the role of the oxide layer on the stress distribution within the ORL as well as the crystallographic texture.},
  archive      = {J_MATDES},
  author       = {Ayyoub Dziri and Kais Ammar and Samuel Forest and Henry Proudhon and Quentin Sirvin and Thiebaud Richeton and Damien Texier},
  doi          = {10.1016/j.matdes.2025.114801},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114801},
  shortjournal = {Mater. Des.},
  title        = {Effect of oxygen content on elastic properties of an oxygen-graded titanium: Experimental and computational analyses},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based multimodal learning for predicting mechanical properties in heat-treated stainless steel. <em>MATDES</em>, <em>259</em>, 114800. (<a href='https://doi.org/10.1016/j.matdes.2025.114800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting mechanical properties of heat-treated materials is critical for intelligent process control and advanced manufacturing. This study proposes a Transformer-based multimodal learning framework for predicting the hardness and wear behavior of carburized steel after vacuum carburizing. By integrating microstructural images, material compositions, and process parameters, the proposed model effectively captures complex cross-modal relationships. Experimental results show that the multimodal model achieves high prediction accuracy, with an R 2 of 0.98 and MAE of 5.23 HV for hardness prediction. Furthermore, Variational Mode Decomposition (VMD) is introduced to preprocess the wear curve, reducing noise and improving the robustness of friction performance prediction. The results demonstrate the effectiveness and generalizability of the proposed approach, offering a practical AI-based solution for intelligent material property evaluation and process optimization.},
  archive      = {J_MATDES},
  author       = {Xuefei Wang and Shijie Zhang and Di Jiang and Wei Yu and Yihao Zheng and Chunyang Luo and Haojie Wang and Zhaodong Wang},
  doi          = {10.1016/j.matdes.2025.114800},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114800},
  shortjournal = {Mater. Des.},
  title        = {Transformer-based multimodal learning for predicting mechanical properties in heat-treated stainless steel},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ai-driven optimization of woven composite via integrated deep and reinforcement learning. <em>MATDES</em>, <em>259</em>, 114798. (<a href='https://doi.org/10.1016/j.matdes.2025.114798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Woven carbon fiber composites are increasingly adopted in advanced structural applications due to their exceptional strength-to-weight ratio and tunable design features. However, high-fidelity simulations of their complex woven architecture are computationally intensive. This study presents a hybrid deep learning framework that combines a dual-input Convolutional Neural Network (CNN) for mechanical property prediction with a Deep Q-Network (DQN) for reinforcement learning-based optimization. The CNN achieves R 2 values above 0.96 for elastic deformation, plastic deformation, and strain energy density prediction. Using the DQN, the optimized design achieves a 2.37-fold improvement in strain energy density, increasing from 3590.78 J/m 3 to 8527.85 J/m 3 . Furthermore, by replacing the original woven geometry with a reduced model using stress–strain behavior, simulation time is reduced from 534 min to 2 min, a 267-fold speedup. This approach significantly enhances efficiency in composite design and optimization workflows, enabling rapid exploration of high-performance configurations.},
  archive      = {J_MATDES},
  author       = {Mao-Ken Hsu and Bo-Yu Huang and Chi-Hua Yu},
  doi          = {10.1016/j.matdes.2025.114798},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114798},
  shortjournal = {Mater. Des.},
  title        = {Ai-driven optimization of woven composite via integrated deep and reinforcement learning},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyclic etching of SiO2 contact holes using heptafluoropropyl methyl ether having low global-warming potential. <em>MATDES</em>, <em>259</em>, 114797. (<a href='https://doi.org/10.1016/j.matdes.2025.114797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SiO 2 contact holes having high aspect ratios were etched using a cyclic-etching process employing heptafluoropropyl methyl ether (HFE-347mcc3) which exhibits a low global-warming potential (GWP ≈530) compared with conventional perfluorocarbons (PFCs) and hydrofluorocarbons (HFCs). In this cyclic process, the etching steps involving HFE-347mcc3/O 2 /Ar plasmas were alternated with deposition steps involving HFE-347mcc3/Ar plasmas to precisely control the fluorocarbon passivation films on the sidewalls. The effects of the deposition- and etching-step durations on the contact-hole profiles were systematically investigated. Increasing the duration of the deposition step initially improved sidewall protection, thereby significantly reducing bowing and enhancing anisotropy; however, excessively long deposition-step durations caused narrowing. Similarly, the duration of the etching step was optimized to achieve sufficient fluorocarbon-film hardening to prevent bowing while avoiding excessive narrowing. The degree of exposure to fluorocarbon plasma was introduced as a critical parameter to optimize the anisotropy. Under optimized conditions, a nearly vertical and highly anisotropic SiO 2 contact hole having a diameter of 100 nm and an aspect ratio of 24 was successfully obtained with minimal bowing (1 nm). The results revealed that HFE-347mcc3 is a viable and environmentally sustainable alternative to high-GWP PFCs or HFCs and provide both environmental benefits and excellent etching performance.},
  archive      = {J_MATDES},
  author       = {Sanghyun You and Minuk Kim and Inkyoung Cho and Junyoung Kim and Sangheon Lee and Chang-Koo Kim},
  doi          = {10.1016/j.matdes.2025.114797},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114797},
  shortjournal = {Mater. Des.},
  title        = {Cyclic etching of SiO2 contact holes using heptafluoropropyl methyl ether having low global-warming potential},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accurate analytical post-buckling solutions for simply supported square plates under biaxial compression with varying stress ratios. <em>MATDES</em>, <em>259</em>, 114796. (<a href='https://doi.org/10.1016/j.matdes.2025.114796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenge of obtaining accurate analytical post-buckling solutions for simply supported square plates under biaxial compression, a long-standing problem in nonlinear plate mechanics. The research question focuses on how to rigorously capture large deflections and bending–membrane interactions to establish reliable benchmarks beyond the critical load. A series expansion method within the von Kármán framework is employed to derive analytical solutions with high numerical accuracy. Compared with existing analytical and numerical approaches, the present solutions achieve five to six significant digits of accuracy, representing a substantial improvement in precision and reliability. A comprehensive parametric study demonstrates how varying the biaxial compression ratio influences post-buckling responses, providing deeper insight into boundary-sensitive and load-dependent behaviors. The results establish new analytical benchmarks that can be directly used to validate approximate and numerical methods, thereby improving the robustness of computational models. In addition, they offer practical guidance for the safe and efficient design of thin-walled plate structures in aerospace, civil, and mechanical engineering. This work highlights both the novelty of deriving truly accurate, verifiable analytical solutions and their dual value as theoretical milestones and engineering tools.},
  archive      = {J_MATDES},
  author       = {Da-Guang Zhang},
  doi          = {10.1016/j.matdes.2025.114796},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114796},
  shortjournal = {Mater. Des.},
  title        = {Accurate analytical post-buckling solutions for simply supported square plates under biaxial compression with varying stress ratios},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Magnetic topological insulator MnBi2Te4 enabled triboelectric nanogenerators for wearable energy harvesting and motion sensing. <em>MATDES</em>, <em>259</em>, 114795. (<a href='https://doi.org/10.1016/j.matdes.2025.114795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of topological materials has enabled new strategies to improve triboelectric performance in self-powered wearable electronics. Here, a MnBi 2 Te 4 -based triboelectric nanogenerator (M-TENG) is developed for efficient biomechanical energy harvesting and motion sensing. MnBi 2 Te 4 , as the positive triboelectric layer, is paired with a PTFE film and integrated onto flexible substrates via hot-pressing. Its layered structure and surface electronic properties enhance charge trapping and interfacial transfer, boosting electrical output. The M-TENG achieves a peak open-circuit voltage ( V OC ) of 133.3 V, short-circuit current ( I SC ) of 21.6 μA, and transfer charge ( Q SC ) of 64.1 nC at 6 Hz, delivering a maximum power of 1.6 mW. It powers small devices such as light-emitting −diode (LEDs) and sensors, and when integrated into wearables, enables self-powered monitoring of motions like walking, running, and basketball, demonstrating the promise of magnetic topological insulators for future energy harvesting and smart wearable systems.},
  archive      = {J_MATDES},
  author       = {Sisi Wang and Yongwei Huang},
  doi          = {10.1016/j.matdes.2025.114795},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114795},
  shortjournal = {Mater. Des.},
  title        = {Magnetic topological insulator MnBi2Te4 enabled triboelectric nanogenerators for wearable energy harvesting and motion sensing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring structure–property relations in dual phase steels using crystal plasticity and variance based global sensitivity analysis. <em>MATDES</em>, <em>259</em>, 114794. (<a href='https://doi.org/10.1016/j.matdes.2025.114794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel framework to quantify the relationships between microstructural features and damage mechanisms in DP800 steel through high-fidelity three-dimensional sRVE simulations with novel damage indicators, which were integrated with variance-based global sensitivity analysis for the calculation of Sobol indices. The developed methodology suggests that the martensite-to-ferrite phase ratio has a stronger impact on damage tolerance than martensite strength, while the elongation of martensite is the dominant parameter for martensite fracture. For the newly introduced phase boundary decohesion indicator, the grain sizes of both phases exhibit the highest influence. A homogenized indicator for overall damage resistance and a trade-off for the two damage mechanisms further revealed the importance of phase morphology, providing insights into additional influencing factors not captured by individual mechanisms. Convergence analyses confirmed that 200–250 datapoints suffice for stable determination of the Sobol indices, confirmed by different surrogate modeling approaches. Radar chart analyses indicated that optimal microstructures for enhanced damage tolerance consist of smaller fractions of strong martensite combined with fine, spheroidal grains in both phases, aligning with established knowledge on DP steels. This approach establishes a validated basis for future optimization of microstructures and loading paths to improve damage tolerance under complex forming conditions.},
  archive      = {J_MATDES},
  author       = {Niklas C. Fehlemann and Irene Biermann and Sebastian Münstermann},
  doi          = {10.1016/j.matdes.2025.114794},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114794},
  shortjournal = {Mater. Des.},
  title        = {Exploring structure–property relations in dual phase steels using crystal plasticity and variance based global sensitivity analysis},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How austenite improves the fatigue behavior of high-speed steels. <em>MATDES</em>, <em>259</em>, 114793. (<a href='https://doi.org/10.1016/j.matdes.2025.114793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the fatigue performance of tool materials, such as high-speed steels, is crucial for increasing the service life of parts and metalworking tools. An important property in this respect is a material’s resistance to the propagation of short cracks, evident in cyclic R-curve behavior. The potential to improve the fatigue crack propagation resistance by transformation-induced crack closure was studied for a high-speed steel grade in which significant fractions of metastable austenite were retained. The austenite’s resistance to martensitic transformation under cyclic thermal loads was evaluated. Transformation-induced plasticity was studied using tensile tests with in situ determination of austenite content by X-ray diffraction using synchrotron radiation. The cyclic R–curve behavior and the threshold for fatigue crack propagation were determined for stress ratios of R = 0.1, −1, and −5. Critical parameters regarding fatigue behavior, such as the slope of the cyclic R-curve and the long crack threshold of the stress intensity factor range, were significantly improved relative to comparable industry-relevant material states.},
  archive      = {J_MATDES},
  author       = {L. Walch and T. Klünsner and A. Hohenwarter and R. Pippan and M.J. Cordill and M. Hausbauer and S. Marsoner and A. Hackl and H. Leitner and G. Ressel},
  doi          = {10.1016/j.matdes.2025.114793},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114793},
  shortjournal = {Mater. Des.},
  title        = {How austenite improves the fatigue behavior of high-speed steels},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stress-constrained topology optimization of heterogeneous lattice structures for additive manufacturing. <em>MATDES</em>, <em>259</em>, 114792. (<a href='https://doi.org/10.1016/j.matdes.2025.114792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a topology optimization method for heterogeneous lattice structures subject to stress constraints. The proposed approach extends the ordered SIMP (Solid Isotropic Material with Penalization) framework to incorporate a composite material failure criterion. Specifically, a modified Tsai–Hill yield criterion is employed to characterize the anisotropic yielding behavior of the heterogeneous lattice, which is subsequently integrated into the optimization as a stress constraint. To address the variation in yield strength across different lattice configurations, a normalization strategy is applied to the stress field. Additionally, a P-norm aggregation scheme is introduced to efficiently handle local stress constraints while reducing computational cost. The equivalent elastic tensor and yield strength of each lattice configuration are obtained using a representative volume element (RVE) based on homogenization theory. The effectiveness of the proposed method is demonstrated through a series of 2D cases, achieving lightweight structural designs that satisfy stress constraints. Finally, full-scale mechanical analysis and 3D printing experimental validation further confirm the strength reinforcement of the optimized results.},
  archive      = {J_MATDES},
  author       = {Zixin Yang and Jikai Liu and Shuzhi Xu and Yifan Guo},
  doi          = {10.1016/j.matdes.2025.114792},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114792},
  shortjournal = {Mater. Des.},
  title        = {Stress-constrained topology optimization of heterogeneous lattice structures for additive manufacturing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metastability matters: Exploring hardness and conductivity in bell bronze alloys. <em>MATDES</em>, <em>259</em>, 114791. (<a href='https://doi.org/10.1016/j.matdes.2025.114791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cu-Sn alloy system exhibits diverse stable and metastable phases with complex phase transformations, making it attractive for applications requiring tailored mechanical and electrical performance. This study investigates the mechanical response of individual phases during ongoing phase transformations in a Cu-20 m.% Sn alloy. Heat treatments produced large-grained microstructures containing distinct phase combinations in equilibrium and non-equilibrium states. The evolving microstructure was characterized using light optical and scanning electron microscopy. Phase-specific hardness, Young’s modulus, and strain rate sensitivity were determined through room-temperature and high-temperature nanoindentation combined with electron back-scattered diffraction phase mapping, alongside compression testing. This method enables direct quantification of phase properties under phase transformation, separating the contributions of stable and metastable phases. Results reveal how transformation kinetics and solute interactions govern the phase-specific deformation bulk performance, offering new insights into structure–property relationships in Cu-Sn alloys. The methodology provides a framework for phase-specific property characterization in transforming systems, supporting the design of materials with transformation-informed properties optimization.},
  archive      = {J_MATDES},
  author       = {Lea A. Lumper-Wimler and Leon Ruess and Johann Kappacher and Wolfram Schillinger and Verena Maier-Kiener},
  doi          = {10.1016/j.matdes.2025.114791},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114791},
  shortjournal = {Mater. Des.},
  title        = {Metastability matters: Exploring hardness and conductivity in bell bronze alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical nanocomposite formation and strengthening mechanisms in a phase-separated CrFeCoNiCu high-entropy alloy. <em>MATDES</em>, <em>259</em>, 114790. (<a href='https://doi.org/10.1016/j.matdes.2025.114790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates a CrFeCoNiCu high-entropy alloy (HEA) exhibiting hierarchical phase separation into Cu-rich low-entropy (LE) and CrFeCoNi-rich high-entropy (HE) regions, driven by a miscibility gap and monotectic reaction. A CALPHAD-based pseudo-binary diagram guided the optimization of solidification and annealing conditions, promoting nanoscale coherent precipitate (NCP) formation within each phase. Multiscale analysis (SEM, EPMA, TEM, 3D APT) revealed a dual FCC-phase composite where each region contains NCPs of the other phase. During annealing, secondary NCPs grow more slowly than primary phase-separated regions, enabling effective control through heat treatment. Mechanical testing via nanoindentation and micropillar compression showed that coherent NCPs enhance strength via a shearing mechanism. In particular, LE NCPs in the HE matrix effectively distribute the applied strain and suppress dislocation motion and slip band formation, resulting in stable strain hardening without stress drops. Upon coarsening beyond the size applicable for shearing, transition to the Orowan bypass mechanism resulting in a decrease in nano-hardness. These findings highlight the importance of coherent phase-separated nanostructures in strengthening and deformation control, and present a thermodynamically guided microstructural design strategy for fabricating HEA-based hierarchical nanocomposites with tunable mechanical performance, offering a promising approach for developing next-generation high-strength, ductile structural materials.},
  archive      = {J_MATDES},
  author       = {Jinyeon Kim and Jinwoo Kim and Wan Kim and Jeong Won Yeh and Jae-Hyeok Shim and Hye Jung Chang and Eun Soo Park},
  doi          = {10.1016/j.matdes.2025.114790},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114790},
  shortjournal = {Mater. Des.},
  title        = {Hierarchical nanocomposite formation and strengthening mechanisms in a phase-separated CrFeCoNiCu high-entropy alloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dispersion strategies development for high-performance carbon nanomaterials-reinforced cementitious composites − critical review on properties and future challenges. <em>MATDES</em>, <em>259</em>, 114789. (<a href='https://doi.org/10.1016/j.matdes.2025.114789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon nanomaterials (CNMs) including carbon nanotubes (CNTs), graphene nanosheets (GNS), carbon nanofibers (CNFs), graphene oxide (GO), with their excellent physical and chemical properties, have drawn widespread attention in the cement industry. This review introduces the dispersion strategies of CNMs in cementitious composites fabrication procedures before providing a comprehensive summary of the corresponding principles, advantages, limitations, and critical considerations. We also reviewed the latest CNMs dispersion characterization techniques and the dispersion effectiveness evaluation methods. Furthermore, the properties of cementitious composites incorporating CNMs, including workability, mechanical strength, durability, electrical conductivity and thermal conductivity, are summarized. The impact of dispersion strategies on these properties is analyzed, and potential causes behind performance inconsistencies are discussed. This review found that the current research faces several challenges: the lack of standardized mix proportions and dispersion protocols hinders result comparison, and inconsistent characterization methods, insufficient cost/lifecycle analyses, combined with unclear links between CNMs’ properties and enhancement, collectively limit practicality. Therefore, future works should focus on establishing unified guidelines for production and characterization, conducting cost-sustainability assessments, and clarifying CNMs’ property-performance relations to advance engineering applications.},
  archive      = {J_MATDES},
  author       = {Yuan Gao and Fufu Zou and Hao Sui and Jiajing Xu and Siyao Wang and Shuaijie Lu and Jiajian Yu and Weiqiang Chen and Yanming Liu and Jing Chen and Lilin Zhao},
  doi          = {10.1016/j.matdes.2025.114789},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114789},
  shortjournal = {Mater. Des.},
  title        = {Dispersion strategies development for high-performance carbon nanomaterials-reinforced cementitious composites − critical review on properties and future challenges},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven prediction and inverse design of optical asymmetry in gold nanorod-helical assemblies. <em>MATDES</em>, <em>259</em>, 114788. (<a href='https://doi.org/10.1016/j.matdes.2025.114788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of optical asymmetry in gold nanorod- (Au NR-) helical assemblies is of paramount importance for the development of functional nanomaterials in optoelectronics, catalysis, and biomedicine. However, such assemblies frequently proceed without adequate theoretical guidance on structure–property relationships, hindering precise control and rational design of tailored optical activity. The present study explores automated, data-driven workflows to investigate geometry-dependent optical asymmetry, with the aim of predicting the asymmetry factor (g-factor) of Au NR-helical assemblies and retrieving their geometric features. A forward artificial neural network (ANN) has been developed to predict the g-factor from geometric inputs. Conversely, a combination of ANN with particle swarm optimisation (PSO) has been demonstrated to retrieve geometric parameters necessary to achieve a target g-factor. The findings demonstrate that the forward ANN attains a high level of prediction accuracy ( r = 0.9833), and the inverse ANN-PSO workflow effectively identifies geometries that yield g-factors with a high degree of proximity to the target values. This demonstrates the significant value of these automated workflows for the fundamental geometric design and optical asymmetry prediction of Au NR-helical assemblies.},
  archive      = {J_MATDES},
  author       = {Yang Liu and Yongguang Chen and Bo Yang and Lina Zhao},
  doi          = {10.1016/j.matdes.2025.114788},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114788},
  shortjournal = {Mater. Des.},
  title        = {Data-driven prediction and inverse design of optical asymmetry in gold nanorod-helical assemblies},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling the SLM process-structure-property relationship of a moderate mg content al-mg-si-sc-zr-mn alloy. <em>MATDES</em>, <em>259</em>, 114787. (<a href='https://doi.org/10.1016/j.matdes.2025.114787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selective Laser Melting (SLM) holds great promise for fabricating high-precision aluminum alloy components with complex geometries and lightweight structures. However, producing high-strength aluminum alloys with excellent mechanical properties remains hindered by poor printability and complex microstructural control. In this study, an Al-4.79 Mg-1.3Si-0.51Sc-0.27Zr-0.47Mn (wt.%) alloy was developed and processed via SLM. The SLM process-structure-property relationship of this alloy was investigated. Crack-free samples were achieved across a broad process window, indicating excellent crack resistance and adaptability. Good printability and high relative density over 99.5 % can be achieved at a laser power of 200-230 W and scanning speed of 1050 and 1150 mm/s, corresponding to a volumetric energy density (VED) of 60 J/mm 3 -73 J/mm 3 . The increase in the laser energy density promoted the formation of columnar grains and the widening of subgrain structures, and made the Mg 2 Si phase transformed from continuous to discontinuous morphology. The as-printed alloy exhibited 439 MPa tensile strength and 11.3 % elongation, attributed to grain refinement, reduced porosity, and the formation of the high dislocation density, 9R phase, and nanotwin. After aging, strength increased to 483 MPa and elongation decreased to 6.5 %. This study defines the process window and demonstrates a balance between high specific strength and cost efficiency.},
  archive      = {J_MATDES},
  author       = {Rui Liu and Junquan Yu and Wenyou Zhang and Xiebin Wang and Jun Lin and Guoqun Zhao},
  doi          = {10.1016/j.matdes.2025.114787},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114787},
  shortjournal = {Mater. Des.},
  title        = {Unveiling the SLM process-structure-property relationship of a moderate mg content al-mg-si-sc-zr-mn alloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multifunctional chitosan–graphene composites for drug, gene, and protein delivery: Promises, challenges, and outlook. <em>MATDES</em>, <em>259</em>, 114786. (<a href='https://doi.org/10.1016/j.matdes.2025.114786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chitosan–graphene oxide (CS–GO) nanocomposites have been investigated as hybrid platforms for drug delivery because they combine the biodegradability of chitosan with the high surface functionality of graphene oxide. However, their clinical translation is still at an early stage, and a systematic overview of their design strategies and biological performance is needed. Publications were classified according to carrier responsiveness to pH, redox environments, and near-infrared (NIR) light, as well as approaches for co-delivery of multiple agents. Reported findings indicate that CS–GO systems can improve drug loading efficiency and enable controlled release, although results vary depending on fabrication method, surface modification, and drug type. Applications have been explored in cancer treatment, antimicrobial therapy, and delivery to tissues such as bone, brain, and the gastrointestinal tract. In vitro and in vivo studies generally demonstrate therapeutic potential, but limitations such asincomplete toxicity evaluation, lack of standardized synthesis protocols, and variability in biological outcomes remain major obstacles. Unlike other chitosan-based nanocarriers, the application of artificial intelligence in CS–GO design is still limited and has not been systematically assessed. Overall, this review synthesizes current knowledge, identifies gaps between experimental findings and translational requirements, and highlights directions for future work, including long-term safety assessment, reproducible large-scale fabrication, and integration with computational optimization tools.},
  archive      = {J_MATDES},
  author       = {Yasaman Rezaeian and Seyed Morteza Naghib},
  doi          = {10.1016/j.matdes.2025.114786},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114786},
  shortjournal = {Mater. Des.},
  title        = {Multifunctional chitosan–graphene composites for drug, gene, and protein delivery: Promises, challenges, and outlook},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-responsive injectable dECM hydrogel for sustained doxycycline delivery in osteoarthritis therapy. <em>MATDES</em>, <em>259</em>, 114785. (<a href='https://doi.org/10.1016/j.matdes.2025.114785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoarthritis (OA) is the most prevalent degenerative joint disease worldwide. Current therapeutic approaches are limited by rapid drug clearance from the joint cavity, necessitating frequent administrations and failing to provide sustained therapeutic effects. Injectable hydrogels that can persistently remain within the joint space represent a promising strategy for comprehensive OA treatment. Herein, an injectable hydrogel system based on dermal-derived decellularized extracellular matrix (dECM) engineered with N-isopropylacrylamide, tannic acid, and sodium tetraborate was developed to achieve superior lubrication and strong tissue adhesion. The hydrogel exhibits exceptional lubrication properties and robust tissue adhesion, enabling prolonged retention within the joint cavity while providing continuous cartilage protection. Its excellent shear-thinning behavior and rapid self-healing capability facilitate minimally invasive injection and ensure conformal coverage of defect sites. In vitro and in vivo evaluations demonstrated that the hydrogel promotes cell proliferation, modulates anti-inflammatory responses, and significantly preserves cartilage integrity with enhanced proteoglycan and type II collagen (COL-2) expression. The sustained therapeutic efficacy was attributed to the hydrogel’s ability to maintain prolonged residence time while continuously delivering bioactive components and providing mechanical lubrication. These findings demonstrate that this multifunctional dECM-based injectable hydrogel represents a promising therapeutic platform for OA treatment suitable for clinical translation.},
  archive      = {J_MATDES},
  author       = {Ximing Wang and Ting Zheng and Luyao Cai and Clara Chen and Junjie Xu and Jinzhong Zhao},
  doi          = {10.1016/j.matdes.2025.114785},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114785},
  shortjournal = {Mater. Des.},
  title        = {Multi-responsive injectable dECM hydrogel for sustained doxycycline delivery in osteoarthritis therapy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards understanding the design principle and rotation deformation mechanics of 3D chiral NPR structure with tunable mechanical responses. <em>MATDES</em>, <em>259</em>, 114784. (<a href='https://doi.org/10.1016/j.matdes.2025.114784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an innovative three-dimensional Negative Poisson’s ratio (NPR) chiral structure was designed based on a 2D staggered rib architecture. This design integrates horizontally oriented chiral alternating ribs and vertically oriented Z-shaped configurations. Two optimized architectures, namely the wave-optimized structure (W-NPR) and the node-enhanced structure (N-NPR), were proposed and compared with the original folded structure (F-NPR). Characterization analysis revealed that the N-NPR structure exhibited superior formability, making it suitable for Digital Light Processing (DLP) fabrication. A parametric study on the mechanical performance of the N-NPR structure demonstrated that an increased volume fraction enhances the mechanical properties at the expense of structural compliance. Uniaxial tensile testing along the XY-plane and Z-axis confirmed the anisotropic Young’s modulus. Experimental and finite element simulations further revealed anisotropic behavior and a unique two-stage rotation-torsion compressive deformation mechanism of N-NPR, which enables advanced mechanical designs by enhancing the degree of freedom for deformation mode conversion. This work proposes a novel method for designing 3D NPR structures and elucidates its mechanical deformation mechanism, enabling transformative advances in aerospace, personalized healthcare, and adaptive wearable technologies.},
  archive      = {J_MATDES},
  author       = {Ruiqi Pan and Ruiying Luo and Wei Xiong and Qiaoyu Chen and Jiafeng Wu and Chunze Yan and Liang Hao and Jie Yin and Zheng Li and Ronghong Zhang and Lei Yang and Yan Li},
  doi          = {10.1016/j.matdes.2025.114784},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114784},
  shortjournal = {Mater. Des.},
  title        = {Towards understanding the design principle and rotation deformation mechanics of 3D chiral NPR structure with tunable mechanical responses},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of irradiation temperature on the microstructure and hardness of W-0.3Cr alloy after irradiation with 6.4 MeV fe ions. <em>MATDES</em>, <em>259</em>, 114783. (<a href='https://doi.org/10.1016/j.matdes.2025.114783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The W-0.3 at.% Cr alloy samples were irradiated with 6.4 MeV Fe ions at 773, 1073 and 1273 K, and the damage peak was 0.26 dpa. The evolution of the microstructure, defects, and hardness was investigated using grazing-incidence X-ray diffraction (GIXRD), transmission electron microscopy (TEM) and nanoindentation tests. The GIXRD results showed that diffraction peaks shifted towards lower 2θ values, indicating that lattice swelling was caused by irradiation-induced defects after irradiation at elevated temperatures. According to the TEM observations, the size of the dislocation loops remained nearly constant, while their number density decreased with an increase in irradiation temperature. The precipitation of Cr was not observed in the W-0.3Cr alloy after irradiation at 773 K. In contrast, it was significant in the samples irradiated at temperatures of 1073 and 1273 K, showing increases in both the size and number density of the precipitates. Irradiation hardening was observed in all samples, primarily attributed to the presence of dislocation loops. The hardness change was estimated with the dispersion barrier hardening model by taking into account the contributions of dislocation loops and Cr precipitates. The values evaluated with the model were significantly larger than those obtained with the nanoindentation tests. This difference was ascribed to the depletion of solute Cr atoms from the W matrix by precipitation.},
  archive      = {J_MATDES},
  author       = {Jing Wang and Jingxian Sun and Yingying Jia and Yifan Zhang and Yuji Hatano and Diancheng Geng and Katsuya Suzuki and Chang Chen and Laima Luo and Kiyohiro Yabuuchi and Ryuta Kasada},
  doi          = {10.1016/j.matdes.2025.114783},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114783},
  shortjournal = {Mater. Des.},
  title        = {Effect of irradiation temperature on the microstructure and hardness of W-0.3Cr alloy after irradiation with 6.4 MeV fe ions},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel in-situ gas-phase alloying approach in wire arc additive manufacturing for controlling solidification mode and designing hybrid stainless steels. <em>MATDES</em>, <em>259</em>, 114781. (<a href='https://doi.org/10.1016/j.matdes.2025.114781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a thermodynamically guided in-situ gas-phase alloying approach in wire arc additive manufacturing (WAAM) to enhance duplex stainless steels by shifting the primary solidification mode from δ-ferrite to γ-austenite, producing a nitrogen-enriched alloy with a continuous austenitic matrix that combines duplex-grade strength with superior ductility. Thermodynamic calculations guided nitrogen adjustment in the shielding gas to control solidification and develop high-performance microstructures. Thermodynamic–kinetic modeling predicted nitrogen uptake from the arc plasma, enabling gas composition selection to promote a shift from δ-ferrite to γ-austenite as the primary solidification phase. Nitrogen content analysis and Scheil simulations confirmed a transition to austenite-first solidification at approximately 0.7 wt% nitrogen. Electron Backscatter Diffraction and optical microscopy revealed that nitrogen-enriched (HN) samples exhibited a continuous γ-austenitic matrix with finely dispersed δ-ferrite, whereas nitrogen-lean (LN) samples had a δ-ferritic matrix with isolated γ-austenite islands. HN samples showed greater grain orientation spread, indicating increased internal misorientation. Despite pronounced crystallographic texture, the HN samples demonstrated nearly isotropic tensile behavior along with enhanced yield strength, tensile strength, ∼11 % higher hardness, and improved elongation. These findings demonstrate that melt chemistry control via gas-phase alloying enables phase-engineered microstructures with superior mechanical performance without modifying the filler wire.},
  archive      = {J_MATDES},
  author       = {Elina Akbarzadeh Chiniforoush and Mohammad Reza Jandaghi and Johan Moverare and Tohid Saeid and Koray Yurtışık},
  doi          = {10.1016/j.matdes.2025.114781},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114781},
  shortjournal = {Mater. Des.},
  title        = {A novel in-situ gas-phase alloying approach in wire arc additive manufacturing for controlling solidification mode and designing hybrid stainless steels},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influencing the draping behaviour of solid epoxy prepregs by applying 3D-printed resin patterns. <em>MATDES</em>, <em>259</em>, 114780. (<a href='https://doi.org/10.1016/j.matdes.2025.114780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel strategy to overcome the limitations of solid resin prepregs (SRPs) − namely the inability to drape at room temperature and hindered gas evacuation during vacuum-bag-only (VBO) processing − by 3D-printing a regular, uncured solid epoxy resin (SR) pattern on a dry woven textile. The locally patterned resin distribution preserves dry textile regions, enabling room temperature drapeability and more robust VBO-processing due to improved gas evacuation. By adjusting pattern parameters such as element geometry and coverage, the draping behaviour can be controlled to adapt to a desired draping condition. In order to be able to design the right pattern for given draping conditions, the influence of these parameters on bending and shearing was studied. Manual draping showed that bending radii down to 4 mm were achievable, governed only by the element length in bending direction, while coverage had no significant effect. In contrast, picture-frame-tests showed that the shearing is mainly influenced by the coverage and that a maximal shearing angle of 30° can be achieved. These results show that the SRPs bending and shearing can be independently influenced through pattern design. The derived structure–drapeability relationships enable targeted design of SRPs for robust, autoclave-free composite manufacturing.},
  archive      = {J_MATDES},
  author       = {Jan Philipp Janzen and Hendrik Schäfer and Murat Çelik and Colin Robert and Conchúr M. Ó Brádaigh and David May and Thomas Neumeyer},
  doi          = {10.1016/j.matdes.2025.114780},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114780},
  shortjournal = {Mater. Des.},
  title        = {Influencing the draping behaviour of solid epoxy prepregs by applying 3D-printed resin patterns},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser powder bed fusion of pure silver sputtering target: Process, microstructure, and sputtering performance. <em>MATDES</em>, <em>259</em>, 114779. (<a href='https://doi.org/10.1016/j.matdes.2025.114779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silver (Ag) sputtering targets are crucial in electronic information materials, particularly with the rapid advancement of Artificial Intelligence (AI), which has further increased their demand. However, the extremely high reflectivity and poor laser absorption of pure Ag in the infrared range make it challenging to process using conventional laser-based Additive Manufacturing (AM) systems, limiting its wide application. In this study, a novel hatch spacing-to-scanning speed ratio ( h / v )-centered low-energy–density strategy was proposed to overcome this challenge and enable high-quality additive manufacturing of pure Ag. By optimizing the ( h / v ) value to 1.0E-04, we successfully fabricated dense, low-defect Ag sputtering targets without increasing energy input. The results demonstrated that this method significantly shortened the manufacturing cycle and produced high-performance Ag targets with refined grains (3–7 μm), high density (≥99.8 %), a smooth surface (Ra = 11.5 μm), and stable sputtering performance (sputtering rate = 31.8 nm/min). Furthermore, the hardness increased by 45.1 % compared to Ag targets prepared by traditional methods. This work offers a practical pathway for applying laser-based AM in the production of highly reflective metal sputtering targets, advancing their industrialization in thin-film electronics, while also contributing to the understanding of AM process–structure relationships in metallic materials.},
  archive      = {J_MATDES},
  author       = {Zheda Ning and Yipei He and Qi Tang and Yunxiu Chao and Yue Shen and Haozhang Zhong and Ming Wen and Jianfeng Gu},
  doi          = {10.1016/j.matdes.2025.114779},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114779},
  shortjournal = {Mater. Des.},
  title        = {Laser powder bed fusion of pure silver sputtering target: Process, microstructure, and sputtering performance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the performance of organic photodetectors by low-temperature electron beam annealing. <em>MATDES</em>, <em>259</em>, 114778. (<a href='https://doi.org/10.1016/j.matdes.2025.114778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organic photodetectors (OPDs) are promising candidates for next-generation optoelectronic devices due to their flexibility, low cost, and scalability. Enhancing OPD performance requires optimizing key layers such as the electron transport layer (ETL) using low-temperature processes to prevent thermal degradation. This study explores the use of low-temperature electron beam annealing (EBA) to improve the performance of Al-doped ZnO (AZO)-based ETLs. The impact of EBA irradiation time (1–8 min) on the structural, morphological, and electrical properties of AZO films was systematically analyzed. EBA effectively modulated oxygen vacancies and reduced surface roughness, lowering trap density and leakage current while enhancing charge transport. An OPD with an ETL treated by 8 min of EBA exhibited superior detectivity (2.22 × 10 13 Jones at 0 V) and significantly reduced leakage current compared to a device with conventionally annealed ETLs. Importantly, the low-temperature EBA process preserved the amorphous state of AZO, making it suitable for heat-sensitive and flexible substrates. These findings demonstrate that EBA is a powerful, scalable method for ETL optimization in OPDs and offers a pathway toward high-performance, energy-efficient, and flexible optoelectronic devices.},
  archive      = {J_MATDES},
  author       = {Jaebum Jeong and Gun woong Kim and Eun Jin Park and Seong Woo Jeong and Seok Hwan Jang and Jae Yeong Jeong and Soo Won Heo and Jun Young Kim},
  doi          = {10.1016/j.matdes.2025.114778},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114778},
  shortjournal = {Mater. Des.},
  title        = {Improving the performance of organic photodetectors by low-temperature electron beam annealing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable biopolymer design: Extraction of chitin and chitosan using natural deep eutectic solvents with improved antibacterial features. <em>MATDES</em>, <em>259</em>, 114775. (<a href='https://doi.org/10.1016/j.matdes.2025.114775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of biopolymers using natural deep eutectic solvents (NADES) offers a promising approach for developing sustainable and biocompatible materials for biomedical applications. In this study, a novel and environmentally friendly process has been developed for extracting chitin and chitosan from organic Agaricus bisporus ( A. bisporus ) mushrooms, which serves as a readily available and renewable resource. NADES not only enhances the extraction efficiency but also preserves the structural integrity of the biopolymers. The characteristics of these biopolymers were analyzed by X-ray diffraction (XRD), Fourier transform infrared spectroscopy (FT-IR), thermogravimetric (DTG/TGA) analysis, scanning electron microscopy (SEM), atomic force microscopy (AFM), and nuclear magnetic resonance ( 1 H NMR) techniques. By optimizing the NADES extraction conditions, high-purity chitin (98.58 %) and chitosan (98.69 %) were achieved, surpassing the purity levels achieved by traditional chemical methods. NADES-extracted chitosan exhibited a remarkable degree of deacetylation (DD) of up to 94.22 %, and a crystallinity index (CrI) of up to 61.77 %, highlighting its enhanced functionality for biomedical applications. Moreover, the NADES-derived biopolymers showed excellent biocompatibility with L929 fibroblast cells. They exhibited dose-dependent antibacterial activity against Staphylococcus aureus (S. aureus) and Escherichia coli (E. coli) and exhibited promising antioxidant and biodegradability properties.},
  archive      = {J_MATDES},
  author       = {Issam Thamer and Magdalena Mazurek-Budzyńska and Vignesh Kumaravel},
  doi          = {10.1016/j.matdes.2025.114775},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114775},
  shortjournal = {Mater. Des.},
  title        = {Sustainable biopolymer design: Extraction of chitin and chitosan using natural deep eutectic solvents with improved antibacterial features},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic effect of interfacial silane film and laser texturing on joining characteristics of pretreated Al/CFRTP friction stir welded joints. <em>MATDES</em>, <em>259</em>, 114774. (<a href='https://doi.org/10.1016/j.matdes.2025.114774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by lightweight requirements in the low-altitude economy, a synergistic laser ablation‒silane coupling process was developed to optimize friction stir welded joints between Al alloys and carbon fiber-reinforced thermoplastics (CFRTPs), with a focus on elucidating the sequence-dependent gradient interfacial joining mechanism. A sequence involving silane coupling prior to laser ablation was employed, enabling dual-mode enhancement of the interfacial geometric configuration and chemical bonding. Mechanical interlocking was ensured in laser-ablated zones, whereas the chemical bonding capacity in unablated regions was enhanced. The tensile–shear strength and cross-tension strength of the joints were measured at 32.6 MPa and 3.2 MPa, respectively. Detailed microstructural characterization revealed that mechanical interlocking occurred in the laser-ablated zones of the PA66 resin and that synergistic physicochemical reinforcement was achieved via covalent Al‒O‒Si bonds coupled with molecular chain entanglement/hydrogen bonding in unablated regions. Defect-free continuous interfacial transitions were confirmed through the penetration of nanolamellar structures by amorphous silane films. This synergistic strategy provides new insights for the high-performance joining of dissimilar metal and polymer materials.},
  archive      = {J_MATDES},
  author       = {Suyu Wang and Wenquan Wang and Yuhua Chen and Xinge Zhang and Shanlin Wang and Timing Zhang and Yuxin Xu},
  doi          = {10.1016/j.matdes.2025.114774},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114774},
  shortjournal = {Mater. Des.},
  title        = {Synergistic effect of interfacial silane film and laser texturing on joining characteristics of pretreated Al/CFRTP friction stir welded joints},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High voltage rotary freestanding triboelectric nanogenerator with novel electrode pair relative position: Theoretical and experimental studies. <em>MATDES</em>, <em>259</em>, 114773. (<a href='https://doi.org/10.1016/j.matdes.2025.114773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Triboelectric nanogenerators (TENGs) are widely used as ideal high-voltage sources in high-voltage equipment. However, there are still some high-voltage application demands that exceed the voltage range of traditional TENG. Here, we propose a high-voltage rotary freestanding TENG (HRF-TENG) with a simple structure. The HRF-TENG device is obtained by changing the relative positions of the electrode pairs (reducing the capacitance) in the traditional RF-TENG, which is inspired by the finite element (FEM) calculation of the traditional RF-TENG. The high-voltage mechanism is initially studied through FEM calculation and experiments, and the calculated output voltage can reach over 30 kV at 500 rpm. In addition, the current direction remains unchanged regardless of the rotation direction. The ultrahigh voltage from HRF-TENG is sufficient to break down the air gap to generate ozone, which achieves the ozone drinking water sterilization system. Drinking water containing 10 7 CFU/ml of E. coli and S. aureus can be completely sterilized within 24 min and 28 min, respectively. Meanwhile, the electrospinning system can be directly driven by HRF-TENG without any circuit. All of these demonstrations prove the feasibility of HRF-TENG in the field of high-voltage applications. In summary, this work provides useful guidance for designing TENGs for high-voltage applications.},
  archive      = {J_MATDES},
  author       = {Ming Li and Tianyi Jiang and Liangyu Cao and Haoxiu Sun and Shanguo Zhang and Jiachao Tang and Yu Li and Hongyuan Jiang},
  doi          = {10.1016/j.matdes.2025.114773},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114773},
  shortjournal = {Mater. Des.},
  title        = {High voltage rotary freestanding triboelectric nanogenerator with novel electrode pair relative position: Theoretical and experimental studies},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microcellular TLCP/SiO2 for high-frequency communication design. <em>MATDES</em>, <em>259</em>, 114772. (<a href='https://doi.org/10.1016/j.matdes.2025.114772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of high-frequency and high-speed communication technologies, especially in microwave/millimeter-wave applications, electronic devices face increased performance demands. Developing low dielectric materials with exceptional properties for these devices has become a significant challenge. Thermotropic liquid crystal polymers (TLCP) are promising due to their excellent high-frequency performance, while microcellular foaming technology is commonly used to enhance dielectric properties. In this study, TLCP was modified with ADR and nano-SiO 2 . The synergistic modification introduces long-chain branched structures and nucleation sites, improving matrix performance and optimizing foaming behavior. In addition, long-chain branched TLCP/SiO 2 foam has highly compressive properties, excellent dimensional stability, ultra-low dielectric stability at high frequencies, great flame retardant and wonderful high-temperature infrared thermal stealth performance. It is also found by simulation that the patch antenna with long-chain branched TLCP/SiO 2 foam substrate has excellent signal transmission performance. The transmission distance up to 4793 m, which is 5.8 times higher than pure TLCP before foaming, which presents a novel solution for high-frequency and high-speed communication. Furthermore, the long-chain branched TLCP/SiO 2 foams with significant performance is expected to be used in sophisticated technology fields such as wide-ranging applications in military, extreme conditions, aviation, microelectronic and other fields.},
  archive      = {J_MATDES},
  author       = {Jiayang Sun and Wenyu Zhong and Yichong Chen and Kuikui Fan and Dongdong Hu and Zhenhao Xi and Tao Gu and Ling Zhao},
  doi          = {10.1016/j.matdes.2025.114772},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114772},
  shortjournal = {Mater. Des.},
  title        = {Microcellular TLCP/SiO2 for high-frequency communication design},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nutrient-enriched soil inks for 3D-printed mycelium-based living building materials. <em>MATDES</em>, <em>259</em>, 114770. (<a href='https://doi.org/10.1016/j.matdes.2025.114770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops nutrient-enriched soil composite inks for 3D printing, followed by mycelium colonization to create large-scale, mycelium-based living building materials (LBMs). The research focuses on enhancing the properties of 3D-printed soil composites by utilizing mycelial hyphal networks to create sustainable construction solutions. A primary challenge lies in calibrating the nutrient levels to support mycelium growth while ensuring the admixture remains printable and suitable for sustaining mycelial development. The study assesses the effects of malt extract agar (MEA) as an additive in soil composites, examining its impact on mycelium growth, water-related properties, and self-regenerative capabilities. Findings indicate that soil composites containing 10 wt% MEA supports balanced mycelium growth across aerial, surface, and penetrative levels. Mycelial networks within the soil composite ink improve water-related properties, enhance structural integrity, and reduce shrinkage compared to composites without mycelium. Furthermore, the mycelium-soil composite demonstrates self-regenerative capabilities by bridging gaps created within the samples. This research contributes to the advancement of LBMs for sustainable earth-based construction, utilizing the inert properties of mycelium to enhance soil characteristics for 3D printing.},
  archive      = {J_MATDES},
  author       = {Ehsan Baharlou},
  doi          = {10.1016/j.matdes.2025.114770},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114770},
  shortjournal = {Mater. Des.},
  title        = {Nutrient-enriched soil inks for 3D-printed mycelium-based living building materials},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent progress of manipulating microenvironment for spinal cord injury therapy using nanoparticles. <em>MATDES</em>, <em>259</em>, 114769. (<a href='https://doi.org/10.1016/j.matdes.2025.114769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spinal cord injury (SCI) is a severe traumatic condition that profoundly compromises patients’ health and quality of life. While various therapeutic strategies, including pharmacotherapy, have been developed and demonstrate some efficacy, however their clinical application is significantly limited by challenges, such as low drug bioavailability and undesirable side effects. Moreover, a critical limitation is their frequently neglect the SCI microenvironment, which serves as the essential foundation for nerve regeneration. In contrast, intelligent nanoparticles-based delivery systems, owing to their excellent biocompatibility and high drug-loading capacity, they can modulate the SCI microenvironment on demand, hold great promise for improving SCI therapy. However, how to design intelligent nanoparticles to achieve precise microenvironment regulation for SCI therapy is still lack of a systematic summary. Therefore, this review summarizes recent advances in advances in modulating the microenvironment for treating SCI using targeted nano drug delivery system, hope provide a theoretical basis for the further development of nano-drug to treatment of SCI.},
  archive      = {J_MATDES},
  author       = {Linfeng Xiao and Chunping Tian and Yinshan Hong and Jiajun Wu and Jiani Du and Yanling Yang and Xiaowei Chang},
  doi          = {10.1016/j.matdes.2025.114769},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114769},
  shortjournal = {Mater. Des.},
  title        = {Recent progress of manipulating microenvironment for spinal cord injury therapy using nanoparticles},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances and challenges of targeted protein degradation in ophthalmology: Future directions and therapeutic potential. <em>MATDES</em>, <em>259</em>, 114767. (<a href='https://doi.org/10.1016/j.matdes.2025.114767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of targeted protein degradation technologies, particularly proteolysis-targeting chimeras (PROTACs) and lysosome-targeting chimeras (LYTACs), is poised to revolutionize therapeutic strategies in ophthalmology. This review presents the first systematic analysis of these protein degradation platforms to address ’undruggable’ targets in ocular pathologies. Harnessing distinct cellular machinery through the engagement of the ubiquitin–proteasome system and the lysosomal pathway with PROTACs and LYTACs, respectively, these heterobifunctional molecules enable the targeted elimination of disease-driving proteins implicated in ocular surface diseases, such as dry eye, and fundus diseases, including age-related macular degeneration, diabetic retinopathy, and glaucoma. We review the mechanistic basis of these technologies, their translational potential in overcoming the limitations of conventional therapies, and ocular-specific challenges such as optimizing bioavailability and intraocular target selectivity. Central to this discussion is the role of advanced linker engineering in achieving spatio-temporal control of degradation activity. While barriers to ocular biodistribution and sustained delivery remain, targeted protein degradation represents a paradigm shift in ophthalmology, offering durable therapeutic effects that could significantly improve clinical outcomes and patient compliance through reduced dosing frequency.},
  archive      = {J_MATDES},
  author       = {Ke Feng and Mingyan Wei and Panqin Ma and Jiaoyue Hu and Caihong Huang and Yi Han and Zuguo Liu},
  doi          = {10.1016/j.matdes.2025.114767},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114767},
  shortjournal = {Mater. Des.},
  title        = {Advances and challenges of targeted protein degradation in ophthalmology: Future directions and therapeutic potential},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In situ observation of the dynamic precipitation of Mg2Sn in mg-sn binary alloy processed by controlled aging treatment. <em>MATDES</em>, <em>259</em>, 114766. (<a href='https://doi.org/10.1016/j.matdes.2025.114766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic precipitation and growth of Mg 2 Sn in a binary Mg-9.76wt.%Sn alloy aged in the temperature range of 180 °C-330 °C were observed in real time by applying in situ transmission electron microscopy techniques, showing the details where and how precipitates nucleate, grow, or dissolve. The dispersive nanoparticles were observed in the Mg matrix at 180 °C, then gradually grew to a lath-like shape on the basal plane at 240 °C-250 °C. The dynamic re-dissolution process of precipitates at the appropriate temperature of 300 °C-330 °C was observed, which was also found to mainly be related to temperature, aging time, surface tension, and vacancies. Meanwhile, a new orientation relationship between the stable precipitates and the Mg matrix was revealed. The results will give a significant insight into the microstructural factors regarding the formation of the orientation relationships, and provide a theoretical guidance for the optimization of alloy performance.},
  archive      = {J_MATDES},
  author       = {Shujing Wu and Chong Cao and Qingjun Zhang},
  doi          = {10.1016/j.matdes.2025.114766},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114766},
  shortjournal = {Mater. Des.},
  title        = {In situ observation of the dynamic precipitation of Mg2Sn in mg-sn binary alloy processed by controlled aging treatment},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bioadhesive sustained-release films for in situ therapy of oral ulcers. <em>MATDES</em>, <em>259</em>, 114765. (<a href='https://doi.org/10.1016/j.matdes.2025.114765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oral ulcers affect more than 25 % of the global population and are driven by complex pathological mechanisms, including bacterial infection, oxidative stress, and dysregulated inflammation, all of which impede healing. To address the limitations of therapies that target only a single aspect of ulcer pathology, this study developed a multifunctional electrospun film by combining 45S5 bioactive glass (BG) with hydroxypropyl methyl cellulose (HPMC). The BG/HPMC films, fabricated by electrospinning with 5 wt% BG incorporated into HPMC matrices, were thoroughly characterized for their structural and bioactive properties. In a rat oral ulcer model, the BG/HPMC films significantly accelerated re-epithelialization and reduced ulcer size compared to both control and chitosan-treated groups. The films also exhibited strong antibacterial activity against Staphylococcus aureus. In vitro, BG extracts promoted the viability and migration of human oral epithelial cells (HOECs) and human umbilical vein endothelial cells (HUVECs), mitigated hydrogen peroxide-induced oxidative stress, and suppressed the expression of pro-inflammatory cytokines—interleukin-1 alpha (IL-1α), tumor necrosis factor alpha (TNF-α), and interleukin-6 (IL-6)—in lipopolysaccharide-stimulated macrophages.},
  archive      = {J_MATDES},
  author       = {Hongping Ge and Jing Yu and Li Pan and Lifang Zhang and Xiaohang Yin and Jie Cai and Chenghu Wu and Chen Wang and Shisheng Chen},
  doi          = {10.1016/j.matdes.2025.114765},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114765},
  shortjournal = {Mater. Des.},
  title        = {A bioadhesive sustained-release films for in situ therapy of oral ulcers},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bioactive nerve conduit enhance peripheral nerve regeneration through dual functions of ion-regulated dedifferentiation and particle-anchored migration. <em>MATDES</em>, <em>259</em>, 114764. (<a href='https://doi.org/10.1016/j.matdes.2025.114764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The regeneration of long-segment peripheral nerve defects remains a critical and challenging clinical problem. The key step in nerve regeneration involves the dedifferentiation of Schwann cells into a repair phenotype, followed by their orderly migration to form Büngner bands that guide axonal elongation. However, due to the lack of bioactive factors for stimulation, the repair of current nerve conduits is generally slow. In this study, we designed a bioactive glass microspheres-embedded nerve conduit. The ions released from these microspheres activate c-Jun to induce Schwann cell dedifferentiation. Meanwhile, the microspheres coated onto the conduit surface provide physical anchoring sites, which accelerate integrin- β 1-mediated Schwann cell adhesion and orderly migration to facilitate Büngner bands assembly. This study confirms that dual-function bioactive glass microspheres promote nerve regeneration through ion-regulated dedifferentiation and particle-anchored migration, offering a novel approach for the design of nerve conduits.},
  archive      = {J_MATDES},
  author       = {Haohui Huang and Shijing Xu and Yulian Yang and Yonghao Qiu and Yujuan Liu and Xiaofeng Chen and Huichang Gao and Fujian Zhao},
  doi          = {10.1016/j.matdes.2025.114764},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114764},
  shortjournal = {Mater. Des.},
  title        = {Bioactive nerve conduit enhance peripheral nerve regeneration through dual functions of ion-regulated dedifferentiation and particle-anchored migration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of dielectric properties, radiation shielding, and electrical resistivity of alkali-activated blast furnace slag and portland cement binders. <em>MATDES</em>, <em>259</em>, 114763. (<a href='https://doi.org/10.1016/j.matdes.2025.114763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alkali-activated materials (AAMs) are increasingly explored for sustainable construction, yet their electromagnetic and radiation-related properties remain largely unknown. This study explored the radio wave propagation, gamma-ray shielding efficiency, and electrical resistivity of alkali-activated blast furnace slag (BFS-AAM) compared to hydrated Portland cement (PC). BFS-AAM demonstrated superior relative permittivity (ε r ≈ 7.6 at 2.4 GHz) and loss tangent (∼0.33) at lower radio frequencies (0.02–10 GHz), leading to enhanced signal attenuation compared to PC (ε r ≈ 5.6, loss tangent ≈ 0.07). BFS-AAM showed similar performance to PC at frequencies between 10–20 GHz, while its characteristics below 10 GHz make it suitable for secure signal environments. In terahertz spectrum (0.2–2 THz), relevant for 6G wireless communication, both materials displayed comparable permittivity (∼5.3 and ∼4.2) and loss tangent (∼0.09 and ∼0.04), indicating compatibility with residential and commercial applications. Simulations at 0.7, 2.4, and 6.0 GHz confirmed higher signal attenuation by BFS-AAM. Additionally, BFS-AAM exhibited higher resistivity (26–110 Ω·m), greater compressive strength (60 MPa), and lower porosity (∼11 %), contributing to its favorable dielectric properties. Although BFS-AAM demonstrated slightly lower gamma-ray shielding efficiency (at 0.661 MeV) than PC, its multifunctional properties position it as promising material for advanced electromagnetic and radiation shielding technologies.},
  archive      = {J_MATDES},
  author       = {Mehedi Rabbil and Mikko Kokkonen and Elijah Adesanya and Otto Mankinen and Mohammad Bhuyan and Sherif Hegazy and Sami Myllymäki and Juho Yliniemi and Tero Luukkonen},
  doi          = {10.1016/j.matdes.2025.114763},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114763},
  shortjournal = {Mater. Des.},
  title        = {Comparison of dielectric properties, radiation shielding, and electrical resistivity of alkali-activated blast furnace slag and portland cement binders},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anisotropic electrospun poly(ε-caprolactone)/polycarbonate urethane scaffolds with improved fatigue performance for tissue-engineered heart valves. <em>MATDES</em>, <em>259</em>, 114762. (<a href='https://doi.org/10.1016/j.matdes.2025.114762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, poly(ε-caprolactone) (PCL) and polycarbonate urethane (PCU) were used to fabricate electrospun scaffolds for tissue-engineered heart valves (TEHVs). The PCL/PCU scaffold containing 25 % PCU (named as 75%PCL-O) with oriented fibers exhibited pronounced anisotropy, with elastic moduli of 53.47 ± 0.93 MPa (X-axis) and 4.19 ± 0.70 MPa (Y-axis), and tensile strength of 14.21 ± 1.16 MPa (X-axis) and 1.59 ± 0.09 MPa (Y-axis), respectively, close to native heart valves. The 75%PCL-O scaffold showed good cell viability and guided cell alignment along the fibers, and no obvious hemolysis or thrombus formation. Hydrodynamic tests showed an effective orifice area ( EOA ) of 2.42 ± 0.12 cm 2 and a regurgitant fraction ( RF ) of 5.98 ± 2.31 % for a 25 mm surgical pulmonary valve, meeting the ISO 5840-2 standard. The accelerated fatigue testing demonstrated that the EOA and RF remained stable throughout 50 million cycles. Additionally, finite element analysis (FEA) revealed that mechanical stress concentrated at the free edge for the 75%PCL-O valve leaflet during the opening-closing cycles, correlating well with the observed fiber degradation in these regions during fatigue tests. In summary, the 75%PCL-O scaffold exhibits favorable mechanical performance, good biocompatibility and improved durability, showing great potential for TEHV applications.},
  archive      = {J_MATDES},
  author       = {Zeping Zhang and Rizheng Han and Caihao Huang and Yueen Liu and Guixue Wang and Yun Bai and Rui Yang and Tao Jin and Xing Zhang},
  doi          = {10.1016/j.matdes.2025.114762},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114762},
  shortjournal = {Mater. Des.},
  title        = {Anisotropic electrospun poly(ε-caprolactone)/polycarbonate urethane scaffolds with improved fatigue performance for tissue-engineered heart valves},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven design for additive manufacturing of energy absorption lattice structures with variable density. <em>MATDES</em>, <em>259</em>, 114761. (<a href='https://doi.org/10.1016/j.matdes.2025.114761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) lattice structures have garnered significant attention in aerospace, architecture, automotive, and medical applications due to their lightweight and superior energy absorption capabilities. Additive manufacturing (AM) enables the fabrication of complex lattice geometries with customized mechanical properties, making them ideal structures for energy absorption scenarios. However, optimizing these structures to achieve spatially varying density distributions for enhanced performance remains a significant challenge. In this study, a data-driven design framework has been proposed for the AM of energy absorption lattice structures with spatially graded densities. The approach enables the tailoring of geometric parameters, including cell arrangement and strut diameters, to realize variable-density architectures optimized for specific performance requirements. The proposed framework is validated through experimental testing of 3D-printed lattice specimens. Compared to the lattices with uniformly distributed cells, the variable-density structures evidence a 218 % increase in maximum load and a 246 % improvement in specific energy absorption. The finite element analysis and experimental comparisons are used to investigate the influence of relative density gradients on energy absorption performance, peak stress mitigation, and deformation. The results highlight the effectiveness of the data-driven design approach in enabling the fabrication of functionally graded lattice structures with enhanced mechanical performance.},
  archive      = {J_MATDES},
  author       = {Yuxin Zhang and Nanya Li},
  doi          = {10.1016/j.matdes.2025.114761},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114761},
  shortjournal = {Mater. Des.},
  title        = {Data-driven design for additive manufacturing of energy absorption lattice structures with variable density},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of γ′ phase on the microstructural evolution and compressive properties of ni-based single crystal superalloys. <em>MATDES</em>, <em>259</em>, 114760. (<a href='https://doi.org/10.1016/j.matdes.2025.114760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate the evaluation and prediction of hot-end component performance, scanning electron microscopy and quasi-static compression tests were carried out on Ni-based single crystal superalloys, and the influence of γ′ phase on microstructural evolution and compressive properties was systematically investigated. Results show that γ′ phases exhibit spherical, cubic, or lath-like morphologies, and their average size increases from ∼ 180  nm to ∼ 450  nm after thermal exposure; and superalloys with higher volume fraction of γ′ phase gradually precipitate topologically close-packed (TCP) phase. The compressive properties display pronounced anisotropy, governed by both microstructure and loading direction. For superalloys with lower volume fraction of γ′ phase, yield strength decreases from 670  MPa to 505 MPa and ultimate compressive strength from 4690  MPa to 4240 MPa as the γ′ phase coarsens. In contrast, for superalloys with higher volume fraction of γ′ phase, ultimate compressive strength initially decreases and then increases, accompanied by rise in failure strain from 22 % to 46 % after thermal exposure. With increasing loading angle, ultimate compressive strength initially decreases and then rises, whereas yield strength, failure strain and hardening modulus exhibit more complex trends. These variations are closely related to γ′ and TCP phase, and microstructure and loading direction collectively affect mechanical behavior.},
  archive      = {J_MATDES},
  author       = {Shunyong Zhang and Bin Zhang and Fengpeng Zhao and Jicheng Li and Dong Jia and Xicheng Huang},
  doi          = {10.1016/j.matdes.2025.114760},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114760},
  shortjournal = {Mater. Des.},
  title        = {Influence of γ′ phase on the microstructural evolution and compressive properties of ni-based single crystal superalloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impact of thermoplastic polyurethane (TPU) as a plasticiser-free binder on additive manufacturing of magnesium alloys: A comparison with polypropylene-polyethylene copolymers. <em>MATDES</em>, <em>259</em>, 114759. (<a href='https://doi.org/10.1016/j.matdes.2025.114759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a breakthrough in screw-based material extrusion (SBME) of magnesium (Mg) alloys by introducing a plasticiser-free thermoplastic polyurethane (TPU) binder system that achieves a 70 vol% powder loading, the highest reported for material extrusion of any solid material. TPU performance was compared with polypropylene–polyethylene copolymer (PPcoPE), the current state-of-the-art binder for Mg alloys. Unlike conventional multi-component systems, the single-backbone TPU eliminates plasticisers, preventing phase separation and enabling stable extrusion at high powder fractions. The absence of plasticisers also suggests that solvent debinding can be bypassed, saving time, cost, and energy while avoiding solvent reactions with Mg. Rheological analysis revealed a unique viscosity-reduction mechanism in TPU, where powder particles disrupt polymer chain entanglements. This effect improves flow at high loadings, while TPU’s cohesive melting profile ensures uniform extrusion and prevents nozzle clogging, unlike the four-step melting of PPcoPE. Preliminary sintering studies between 500 and 700 °C for up to 64 h showed no densification for both binders, probably due to carbonate and oxide surface layers (detected via EDS, XRD, and OPTIR) on Mg-5Ca after debinding, suggesting a change in Mg alloy composition for higher sinterability. These findings highlight TPU’s potential for record-high powder loadings in next-generation powder-based additive manufacturing.},
  archive      = {J_MATDES},
  author       = {Hyeonseok Kim and Tom McKenna and Ramesh Raghavendra and Eoin O’Cearbhaill and Mert Celikin},
  doi          = {10.1016/j.matdes.2025.114759},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114759},
  shortjournal = {Mater. Des.},
  title        = {Impact of thermoplastic polyurethane (TPU) as a plasticiser-free binder on additive manufacturing of magnesium alloys: A comparison with polypropylene-polyethylene copolymers},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-assembly of bortezomib nanofibers for solid tumor and bone metastasis therapy. <em>MATDES</em>, <em>259</em>, 114758. (<a href='https://doi.org/10.1016/j.matdes.2025.114758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome challenges including insufficient drug loading capacity, limited targeting accuracy, and the complex preparation of conventional nanomedicine, self-assembled nanomaterials have emerged as a viable solution. To explore the peptide self-assembly theory and overcome limitations, this study used bortezomib (BTZ) as the base material, and a novel peptide self-assembly strategy utilizing Zn(II) coordination was employed to prepare cancer cell-targeting nanofiber drugs (cRGD-BTZNDs). The therapeutic efficacy was evaluated in different types of tumors. The results demonstrated that cRGD-BTZNDs effectively entered cancer cells and exhibited enhanced cytotoxic effects against cancer cells compared to BTZ. Moreover, cRGD-BTZNDs exhibited excellent therapeutic efficacy against solid tumors, significantly inhibiting 4 T1 tumor growth while reducing biological toxicity. Additionally, in the treatment of bone metastases, cRGD-BTZNDs demonstrated excellent therapeutic potency, effectively alleviating bone damage in mice with high biocompatibility. This study not only self-assembled nanomaterials with great potential in cancer therapy, but also affirmed the correctness and universality of the Zn(II) coordination peptide self-assembly theory, providing a theoretical basis for the improvement of peptide-based nanomedicine.},
  archive      = {J_MATDES},
  author       = {Dongjie Fu and Yuerong Wang and Jiaqi Xuan and Dingchang Liu and Jiawei Zhao and Yang Lei and Tianwen Xi and Hui Yang and Leming Sun},
  doi          = {10.1016/j.matdes.2025.114758},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114758},
  shortjournal = {Mater. Des.},
  title        = {Self-assembly of bortezomib nanofibers for solid tumor and bone metastasis therapy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wire-arc directed energy deposition of metastable-β alloy ti-15 V-3Cr-3Sn-3Al using thick wire feedstock: Microstructure and mechanical response. <em>MATDES</em>, <em>259</em>, 114757. (<a href='https://doi.org/10.1016/j.matdes.2025.114757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ti-15V-3Cr-3Sn-3Al is a metastable-β alloy initially developed to improve cold formability and reduce downstream processing costs compared to hot-forming Ti-6Al-4V. It is primarily used in sheet and welded forms, with secondary applications in castings and forgings. However, high formulation costs and strict process windows reduce expected cost benefits. This study explores an alternative manufacturing route for large-scale components using the available thick wire format (Ø3.0 mm). Ti-15V-3Cr-3Sn-3Al was deposited via plasma-based wire-arc directed energy deposition. Samples were evaluated in two conditions: (1) solution-treated (2) solution-treated and aged. Mechanical testing included tensile and hardness measurements, while microstructural analysis used a broad range of techniques. Deformation behaviour and fracture surfaces were also examined. The β-phase microstructure in the as-built condition contained α GB at grain boundaries, which dissolved during solution treatment, leaving a fully β-phase matrix. Aging resulted in the precipitation of fine α-laths, providing expected strengthening. In this condition, the material achieved an ultimate tensile strength > 1150 MPa and failure strain > 6 %, with anisotropy observed only in ductility. In the solution-treated condition, continuous softening was observed during tensile testing. This study provides insight into properties of Ti-15V-3Cr-3Sn-3Al in additive manufacturing, laying the groundwork for alternative processing routes for titanium alloys.},
  archive      = {J_MATDES},
  author       = {José L. Neves and Tomasz Wojcik and David Obersteiner and Johann Grillitsch and David Holec and Daniel Kiener and Thomas Klein},
  doi          = {10.1016/j.matdes.2025.114757},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114757},
  shortjournal = {Mater. Des.},
  title        = {Wire-arc directed energy deposition of metastable-β alloy ti-15 V-3Cr-3Sn-3Al using thick wire feedstock: Microstructure and mechanical response},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming the challenges of fusion-based brass additive manufacturing through solid-state additive friction-stir deposition. <em>MATDES</em>, <em>259</em>, 114756. (<a href='https://doi.org/10.1016/j.matdes.2025.114756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing Cu-Zn alloys (brass) using fusion-based additive manufacturing (AM) techniques presents significant challenges due to volatile elements and the inherently high thermal conductivity of these alloys. Addressing these issues often demands increased energy input, modifications to laser systems, and compositional adjustments to mitigate zinc loss. However, such solutions are complex and remain in the early stages of development. In contrast, Additive friction stir deposition (AFSD), a solid-state AM technique, offers a promising alternative to overcome these limitations. This study represents a pioneering effort to deposit dual-phase brass (Cu-40Zn) using a closed-loop temperature-controlled AFSD. The influence of processing temperature (ranging from 0.38 to 0.61 T p /T m ) on microstructural evolution and mechanical performance was systematically investigated along the build and longitudinal direction. The resulting microstructure was predominantly governed by dynamic recrystallization and post-dynamic recrystallization (P-DRX) due to repeated thermal cycles. The as-deposited brass exhibited a balanced strength-ductility combination, with yield strength ranging from 215 to 437 MPa and elongation from 34 % to 67 %. Tensile properties in longitudinal and build directions revealed that grain boundary strengthening was the primary mechanism for improving the mechanical performance. The as-deposited properties were comparable to those of wrought counterparts, thus highlighting the potential of AFSD for fabricating high-performance brass components.},
  archive      = {J_MATDES},
  author       = {Meet Gor and Matthew Barnett and Pinaki Bhattacharjee and Daniel Fabijanic},
  doi          = {10.1016/j.matdes.2025.114756},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114756},
  shortjournal = {Mater. Des.},
  title        = {Overcoming the challenges of fusion-based brass additive manufacturing through solid-state additive friction-stir deposition},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-temperature viscoelastic mechanism for SiC fibers to elucidate creep and recovery behaviors. <em>MATDES</em>, <em>259</em>, 114755. (<a href='https://doi.org/10.1016/j.matdes.2025.114755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mastering the high-temperature creep behavior of SiC fibers plays pivotal role in designing reinforced ceramic matrix composites. Creep viscoelastic behavior is activated at higher temperatures due to complicated interactive coordination between grain interiors and grain boundaries. This study investigated the tensile creep behaviors at different generations of SiC fibers under conditions of various stress and temperatures. The creep recovery behaviors after unloading exhibits the viscoelastic nature, which comes from the possible motion of amorphous phase near massive grain boundaries. It is driven by the release of elastic energy of the grain boundary, evidenced by frequency shifts in Raman spectroscopy. Then classical diffusion creep theory is modified to a viscoelastic model incorporating physical parameters such as the elasticity, viscosity, and threshold stress for SiC fibers. The proposed equations have been well supported by creep test results. The viscosity and elasticity parameters decrease with increasing temperature, the latter being more sensitive. 3rd generation fiber exhibits higher viscosity and elasticity, explaining better creep resistance. The model can evaluate the elastic and plastic contributions and predict creep results at higher temperatures. This work helps to understand high-temperature SiC fiber creep, and to guide optimizing fiber-reinforced composites.},
  archive      = {J_MATDES},
  author       = {Wenguo Jiang and Yi Ru and Jundong Shi and Haozhang Hou and Zexu Sun and Weiwei Qu and Xiaotian Hu and Guoquan Ma and Lianyi Wang and Yanling Pei and Shusuo Li and Shengkai Gong},
  doi          = {10.1016/j.matdes.2025.114755},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114755},
  shortjournal = {Mater. Des.},
  title        = {High-temperature viscoelastic mechanism for SiC fibers to elucidate creep and recovery behaviors},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aqua-powered hybrid solar cell using amorphous conformal Ga2O3 thin-film. <em>MATDES</em>, <em>259</em>, 114754. (<a href='https://doi.org/10.1016/j.matdes.2025.114754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clean energy generation is a primary demand to neutralise carbon emissions. Photovoltaics are the best candidates for clean energy. Water is a reliable and sufficient resource for future clean energy generation, as it can be used to enhance photovoltaic performance in a hybrid system. This study designs and investigates a novel aqua-voltaic hybrid solar cell by integrating an ultra-thin gallium oxide layer (2.3 nm) with a polycrystalline silicon solar cell under water-based conditions. The amorphous Ga 2 O 3 layer grown by sputtering enhances optical absorption, reduces surface reflectance in the ultraviolet (UV) region, and serves as a protective barrier against environmental degradation. Photovoltaic characterisations reveal an efficiency enhancement from 19.04 % to 21.56 % in Si solar cell when Ga 2 O 3 and water are introduced. Under illumination, electrochemical impedance spectroscopy (EIS) exhibits capacitance and resistance, indicating strong interfacial charge dynamics. These phenomena are attributed to electronic double-layer capacitance, quantum capacitance modulation, and charge redistribution at the Ga 2 O 3 -water interface. The results illustrate the dual role of water in enhancing charge transport while influencing surface-state interactions, leading to improved solar cell performance. This work provides insights into the interaction of semiconductor-liquid interfaces and offers an efficient hybrid energy harvesting technologies.},
  archive      = {J_MATDES},
  author       = {Md Arifur Rahman Barno and Malkeshkumar Patel and Shubham Umeshkumar Gupta and Sourov Hossain and Sanh Vo Thi and Cho Seung Hee and Joondong Kim},
  doi          = {10.1016/j.matdes.2025.114754},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114754},
  shortjournal = {Mater. Des.},
  title        = {Aqua-powered hybrid solar cell using amorphous conformal Ga2O3 thin-film},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Direct joining of sapphire and invar alloy by nanosecond laser. <em>MATDES</em>, <em>259</em>, 114753. (<a href='https://doi.org/10.1016/j.matdes.2025.114753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The direct joining of single-crystal sapphire and Invar alloy using a nanosecond laser is demonstrated for the first time in this study. The macro- and microstructures of the sapphire/Invar alloy joints were analyzed, along with an investigation of their compositional characteristics. Based on this, the effects of nanosecond laser processing parameters on the joint’s macro- and microstructures and its mechanical performance were explored. The typical fracture morphologies of the sapphire/Invar alloy joints were examined, revealing the fracture mechanisms involved. The laser-irradiated area exhibited a conical molten zone, predominantly composed of sapphire with a small amount of Invar alloy particles. No new phases were detected in the joint region, and the primary joining mechanism was identified as mechanical interlocking and embedding. After optimizing the nanosecond laser welding parameters, the joint’s shear strength reached 123.2 MPa. Additionally, the sealed sapphire/Invar alloy samples welded by nanosecond laser passed a 336-hour water resistance test without any leakage. The mechanical interlocking effect generated by the conical weld seam structure in the laser-irradiated area played a key role in enhancing shear strength.},
  archive      = {J_MATDES},
  author       = {Rui Pan and Yinghao Feng and Pei Chen and Lizhong Wang and Shujun Chen},
  doi          = {10.1016/j.matdes.2025.114753},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114753},
  shortjournal = {Mater. Des.},
  title        = {Direct joining of sapphire and invar alloy by nanosecond laser},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructured Y3Al5O12 single-crystal fibers for high-sensitivity quasi-distributed ultrasonic thermometry based on acoustic anisotropy engineering. <em>MATDES</em>, <em>259</em>, 114751. (<a href='https://doi.org/10.1016/j.matdes.2025.114751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of aerospace, nuclear energy, and advanced manufacturing has created a growing demand for temperature sensing in extreme environments. Ultrasonic temperature sensors (UTS) are widely used in high-temperature sensing due to their extreme operating temperature close to the melting point of the waveguide materials. In this work, YAG single-crystal fibers (SCF) with spatially distributed acoustic reflection microstructures have been successfully fabricated via the laser-heated pedestal growth (LHPG) method and employed as acoustic waveguides. Herein, anisotropic acoustic waveguide behaviors were revealed in YAG SCF, where the [110]-oriented YAG SCF demonstrates enhanced unit sensitivity with the S-wave polarization direction of [ 1 1 ¯ 0 ], primarily attributed to the lower acoustic velocity and the more substantial velocity variations with temperature. Furthermore, quasi-distributed ultrasonic temperature sensing in the range of 30-1800℃ has been achieved based on the [110]-oriented YAG SCF with two discrete sensing units, reaching the maximum unit sensitivities of 47.18 ns·℃ -1 ·m - 1 and an optimal temperature resolution of 5.04℃ at 1800℃. Superior acoustic waveguide characteristics, a wide working temperature range, and the positive temperature-dependent sensor performance suggest that the [110]-oriented microstructured YAG SCF is an ideal candidate for distributed high-temperature sensing in harsh environments.},
  archive      = {J_MATDES},
  author       = {Kaihui Zhang and Tao Wang and Mingji Zhang and Xin Guan and Zhengmin Wang and Wenchang Zhuang and Liang Zhang and Jian Zhang and Zhitai Jia},
  doi          = {10.1016/j.matdes.2025.114751},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114751},
  shortjournal = {Mater. Des.},
  title        = {Microstructured Y3Al5O12 single-crystal fibers for high-sensitivity quasi-distributed ultrasonic thermometry based on acoustic anisotropy engineering},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Static recrystallization characteristics and kinetics of austenitic stainless steels under development for LH2 storage applications. <em>MATDES</em>, <em>259</em>, 114750. (<a href='https://doi.org/10.1016/j.matdes.2025.114750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing high-strength austenitic stainless steel (ASS) grades for lightweight cryogenic storage tanks, particularly for liquefied hydrogen (LH 2 ), demands precise microstructure control achievable via optimized thermomechanically controlled processing (TMCP). In recrystallization–controlled regime of TMCP, successive rolling passes facilitate microstructural refinement through dynamic and static restoration mechanisms. This work illustrates static recrystallization (SRX) characteristics and kinetics in three ASS alloys designed by varying N, Mn and Nb contents. Interrupted (double–hit) compression tests were conducted to characterize the flow behaviour and microstructural evolution across different deformation conditions. SRX kinetics were formulated using a fractional–softening framework, where the time to 50 % recrystallization was correlated with strain, strain rate, temperature, and initial grain size. While the exponents of strain (−3.1) and strain rate (−0.3) were consistent across all compositions, the apparent activation energies of SRX varied in the range 251.5–298 kJ·mol −1 , with 7 wt% Mn showing a more noticeable effect in comparison with 0.1 wt% Nb. Detailed metallographic analysis confirmed the accuracy of the derived models. Suitable semi-empirical relations were established enabling prediction of statically recrystallised grain size across various processing conditions. These results define the processing windows needed to design TMCP schedules for advanced ASSs for LH 2 and cryogenic environments.},
  archive      = {J_MATDES},
  author       = {Mahesh Somani and Sumit Ghosh and Juha Uusitalo and Frank Hoffmann and Marta Muratori and Ali Smith and Ahmed W. Abdelghany},
  doi          = {10.1016/j.matdes.2025.114750},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114750},
  shortjournal = {Mater. Des.},
  title        = {Static recrystallization characteristics and kinetics of austenitic stainless steels under development for LH2 storage applications},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bonding of vanadium- and iron-based alloys as interlayers for plasma-facing and structural materials in fusion systems. <em>MATDES</em>, <em>259</em>, 114749. (<a href='https://doi.org/10.1016/j.matdes.2025.114749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vanadium alloys and FeCrAl were investigated as interlayers between tungsten and reduced activation ferritic martensitic steel for fusion system components to avoid formation of intermetallic phase at operating temperatures between 550 and 1100 °C, while maintaining a body centered cubic phase throughout the interface. Physical and mechanical properties need to be graded between tungsten and steel, but recent results showed a significant hardness increase at the FeCrAl to vanadium alloy interface. Here, a sintered sample of these alloys was annealed for extended time, and the microstructure was investigated to provide a better understanding of the phenomena. A comparison with an additively manufactured interface of the same material is provided. An unexpected L2 1 intermetallic phase formation has been revealed using microscopy and synchrotron techniques and will inform future additive manufacturing approaches of the interface. A Cr layer interface as a preliminary solution was proposed between the Vanadium alloy and FeCrAl alloy interface.},
  archive      = {J_MATDES},
  author       = {Tim Gräning and Deniz Ebeperi and Ibrahim Karaman and Ishtiaque Robin and Mobashera Saima Haque and Akhil Kolanti and David Sprouster and Lance Snead and Yutai Katoh},
  doi          = {10.1016/j.matdes.2025.114749},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114749},
  shortjournal = {Mater. Des.},
  title        = {Bonding of vanadium- and iron-based alloys as interlayers for plasma-facing and structural materials in fusion systems},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic strength and conductivity enhancement via induced 〈0 0 1〉-textured ultrafine grains in Al2O3/Cu composites. <em>MATDES</em>, <em>259</em>, 114748. (<a href='https://doi.org/10.1016/j.matdes.2025.114748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overcoming the strength–conductivity trade-off in Al 2 O 3 /Cu composites remains a key challenge. Here, we propose a microstructural design strategy that combines 〈0 0 1〉 texture with elongated ultrafine grains. Room-temperature rotary swaging (RS), assisted by the pinning effect of Al 2 O 3 particles, promotes the selective formation of 〈0 0 1〉-oriented grains through compressive–shear deformation and enhances grain aspect ratios. The resulting structure provides texture-dominated conductive paths while reducing transverse grain boundary density. Consequently, the composite achieves a yield strength of 342 MPa and an electrical conductivity of 95.3 % IACS—representing a 56.8 % strength increase over the Cu matrix without sacrificing conductivity. This work demonstrates a scalable, room-temperature route to high-performance Cu-based composites with an exceptional strength–conductivity balance for advanced electrical applications.},
  archive      = {J_MATDES},
  author       = {Song Liu and Shaolin Li and Kexing Song and Xiaowen Peng and Xiuhua Guo and Zhenhan Zhou and Shuaibin Li and Fuxiao Chen},
  doi          = {10.1016/j.matdes.2025.114748},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114748},
  shortjournal = {Mater. Des.},
  title        = {Synergistic strength and conductivity enhancement via induced 〈0 0 1〉-textured ultrafine grains in Al2O3/Cu composites},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D-printed barriers with machine learning powered image analysis for enhanced wound healing assays. <em>MATDES</em>, <em>259</em>, 114746. (<a href='https://doi.org/10.1016/j.matdes.2025.114746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wound healing assay is a standard method enabling investigation of cell proliferation and migration through a cell-free gap in a cell monolayer. Despite very common, it shows several weaknesses: lack of reproducibility and manual and time-based image analysis. Based on novel approach founded on innovative materials and AI-assisted processing of biological images, a promising automated barrier-wound healing assay is realized, achieving consistent results while retaining cells integrity. To increase assay accuracy, biocompatible 3D-printed resin inserts have been developed, facilitating precise control over shape and size of the wound. In parallel, a new image-detection algorithm powered by Deep Learning models was developed to identify cell-free area during the healing process, exceeding limitations of manual analysis. 3D-resin inserts combined with automated image analysis allowed the elimination of subjective errors and provided reproducible quantification of cell-free areas across multiple experiments. Moreover, a dataset to train a Convolutional Neural Network for monitor healing over time was developed. As proof of concept, this algorithm was tested on a cancer cell line stimulated by TGF-β, a drug stimulating cell migration. Innovative design of biocompatible materials combined with Deep Learning for automatically processing high-throughput data enables standardized wound healing assay, increasing efficiency, reliability, and accuracy of results.},
  archive      = {J_MATDES},
  author       = {Alfredo De Cillis and Valeria Garzarelli and Alessia Foscarini and Giuseppe Gigli and Antonio Turco and Elisabetta Primiceri and Maria Serena Chiriacò and Francesco Ferrara},
  doi          = {10.1016/j.matdes.2025.114746},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114746},
  shortjournal = {Mater. Des.},
  title        = {3D-printed barriers with machine learning powered image analysis for enhanced wound healing assays},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced morphology and conductivity in aerosol jet printing via optimization of print speed range under various deposition rate. <em>MATDES</em>, <em>259</em>, 114745. (<a href='https://doi.org/10.1016/j.matdes.2025.114745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerosol Jet (AJ) printing is becoming increasingly attractive for printed conformal electronics due to its non-contact capability. However, the impact of deposition rate and print speed on the morphology and electrical properties of printed traces remains unclear. In this study, AJ printed traces with different print speed (0.3–20 mm/s) under commonly used deposition rate values (0.0002, 0.0004 and 0.0006 mm 3 /s) were examined. After evaluating the corresponding morphology and conductivity of the printed traces, the optimal print speed range of each deposition rate was determined as follows: deposition rate of 0.0002 mm 3 /s as 0.3–1.5 mm/s, 0.0004 mm 3 /s as 0.7–4 mm/s, and 0.0006 mm 3 /s as 1–6 mm/s, respectively. A three-dimensional computational fluid dynamics (CFD) model is proposed to elucidate the fundamental aerodynamic behaviors of AJ printed traces under different deposition rate, and its trends align with experimental observations. The mechanism by which print speed influences conductivity was analyzed, revealing that internal porosity is the primary factor reducing conductivity at low print speed. The analysis of morphology, conductivity, and printing efficiency across various print modes revealed that the morphology of printed traces under the respective deposition rate and print speed combination remained consistent in single-layer printing. Notably, printing efficiency is substantially enhanced at elevated deposition rate and high print speed. Compared to multi-layer printing at low deposition rate, high deposition rate single-layer printing emerges as the optimal method for achieving superior efficiency and conductivity. Ultimately, a correlation was established between resistance, print speed, and deposition rate, that enabling the successful printing of 15 resistors with specific resistance values (20 Ω) for different geometries, within an average error of 5.9 %, thereby broadening the applicability of AJ printing in printed electronics.},
  archive      = {J_MATDES},
  author       = {Xuanbo Jiang and Zijun Yan and Yingjie Niu and Xuan Zhang and Teng Ma and Hui Cheng and Kaifu Zhang and Chenglin Yi},
  doi          = {10.1016/j.matdes.2025.114745},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114745},
  shortjournal = {Mater. Des.},
  title        = {Enhanced morphology and conductivity in aerosol jet printing via optimization of print speed range under various deposition rate},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multichannel hollow carbon fiber reinforcement in an epoxy resin matrix for direct ink writing of high-performance composites. <em>MATDES</em>, <em>259</em>, 114744. (<a href='https://doi.org/10.1016/j.matdes.2025.114744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon-fiber reinforced polymers are widely used in additive manufacturing for high-performance composites. However, the aerospace and automotive sectors seek lighter materials compatible with practical processing methods. This study introduces hollow carbon fibers (HCFs) with a honeycomb cross-section as lightweight reinforcements in composites, fabricated via direct ink writing. The printability, mechanical performance, and microstructural features of HCF-based composites were systematically evaluated. Rheological testing showed that HCF-based inks exhibit similar pre-printing properties to conventional, densified carbon fiber (DCF) inks. However, mechanical tests revealed superior strength in traditional DCF composites due to differences in fiber morphology, density, and diameter. Microstructural analysis using small-angle X-ray scattering (SAXS) and optical microscopy indicated comparable fiber alignment, while scanning electron microscopy (SEM) showed complete epoxy infiltration in HCF channels, evidenced by the pullout of cured epoxy strands. While fiber–matrix interlocking was expected to enhance strength, weak bonding within HCF interiors contributed to reduced mechanical strength. Despite lower strength, HCFs offer advantages for applications prioritizing weight reduction, thermal insulation, or fluid permeability, such as lightweight aerospace and automotive components, thermal management systems, and filtration media. The hollow structure also enables integration with functional materials for smart materials and energy storage.},
  archive      = {J_MATDES},
  author       = {Olivia K. Meyer and Roneisha Haney and Tyler Bauder and Kishor Gupta and Hellen Stephanie and Jefferson Bordeau and Cliff Wood and Keenan Mintz and Satish Kumar and Hilmar Koerner and Harshita Kumari},
  doi          = {10.1016/j.matdes.2025.114744},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114744},
  shortjournal = {Mater. Des.},
  title        = {Multichannel hollow carbon fiber reinforcement in an epoxy resin matrix for direct ink writing of high-performance composites},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultralight pt-ALD-modified graphene aerogel achieving aluminum-class thermal resistance at 12% mass. <em>MATDES</em>, <em>259</em>, 114742. (<a href='https://doi.org/10.1016/j.matdes.2025.114742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphene aerogels (GAs), a class of three-dimensional porous structures, are limited by a fundamental challenge: low thermal conductivity stemming from high interfacial resistance between constituent layers and structural defects. This study systematically investigates a strategy to enhance thermal transport properties by engineering the interlayer bonding via platinum atomic layer deposition (Pt-ALD) and compares it with conventional high-temperature annealing (1873 K). The Pt-ALD-modified graphene aerogel (GA-ALD) exhibited a 199 % increase in thermal conductivity, significantly surpassing the 113 % enhancement from heat treatment. SEM, Raman, XRD, XPS, and FTIR data explicitly indicate that Pt-ALD forms covalent Pt O C bonds that bridge adjacent graphene layers while preserving the original porous morphology. Owing to the synergistic effect of enhanced solid-phase thermal conductivity and efficient convective heat transfer through the preserved porous structure, the GA-ALD sample achieved a total thermal resistance comparable to that of an equal-sized aluminum heat sink under identical forced-convection conditions, while weighing only ∼12 % of its aluminum counterpart. Moreover, cyclic compressive tests confirmed GA-ALD durability, retaining 99.5 % height and 94.7 % stress after 1000 cycles. These findings demonstrate that interfacial bond engineering via ALD is a powerful route to ultralight, high-performance carbon aerogels for weight-sensitive thermal-management applications.},
  archive      = {J_MATDES},
  author       = {Jiho Kang and Viet Phuong Nguyen and Seung-Mo Lee and Duckjong Kim},
  doi          = {10.1016/j.matdes.2025.114742},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114742},
  shortjournal = {Mater. Des.},
  title        = {Ultralight pt-ALD-modified graphene aerogel achieving aluminum-class thermal resistance at 12% mass},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser powder bed fusion of a novel CoNi-based high entropy superalloy. <em>MATDES</em>, <em>259</em>, 114741. (<a href='https://doi.org/10.1016/j.matdes.2025.114741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser powder bed fusion (L-PBF) is poised to revolutionize the manufacturing of high-value metallic materials, allowing for intricate, geometrically complex designs while minimizing material waste. The primary challenge lies in formulating alloys compatible with L-PBF that also maintain properties suitable for the demanding conditions encountered in energy, space, and nuclear applications. We introduce a category of high strength, defect-resistant octonary CoNi-based high entropy superalloy (CoNi-HESA), comprising roughly equal parts of Co and Ni, along with Cr, Al, V, Ti, Ta, and W. This alloy exhibits as-printed tensile strength exceeding 1 GPa and tensile ductility exceeding 30 % at room temperature. Furthermore, compression tests demonstrate that the as-printed parts maintain a yield strength of about 1 GPa at room temperature up to 700 °C, which decreases to 0.9 GPa and 0.7 GPa as the test temperature reaches 800 °C and 900 °C, respectively. With a careful combination of laser powder and scan speed, the developed HESA is well-suited for crack-resistant, high-density component production through L-PBF. Alloy design principles are elucidated through CALPHAD calculations based on the high entropy alloy (HEA) database, including the structure and properties of L-PBF processed CoNi-HESA.},
  archive      = {J_MATDES},
  author       = {Alessandro De Nardi and Ahad Mohammadzadeh and Amir Mostafaei and Jose Manuel Torralba},
  doi          = {10.1016/j.matdes.2025.114741},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114741},
  shortjournal = {Mater. Des.},
  title        = {Laser powder bed fusion of a novel CoNi-based high entropy superalloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Al alloying-driven spinodal decomposition enables ultra-strong cast refractory high-entropy alloys. <em>MATDES</em>, <em>259</em>, 114736. (<a href='https://doi.org/10.1016/j.matdes.2025.114736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strengthening in refractory high-entropy alloys (RHEAs) can be achieved through the formation of “compositional heterogeneity” at the atomic scale. Here, we chose Zr 45 Ti 15 Nb 20 Ta 20 alloy with a single-phase body-centered cubic (BCC) structure as a matrix and added a small amount of Al to promote a unique spinodal decomposition. The results show that the introduction of Al-X negative mixing enthalpy induces the RHEAs spinodal decomposition to form a nanocubic structure in the form of a basket-like fabric morphology with a characteristic periodicity of 12 nm. Nanocubic structures consist of (Nb, Ta)-rich cubes and Zr-rich channels as well as generate strong localized strain fields at the interfaces. Spinodal decomposition strengthening enables the as-cast RHEA to achieve a yield strength of 1405 MPa. Periodically distributed nanostructures make dislocations move slowly, causing plugging and cross-slip, facilitating dislocation interactions, multiplication, and accumulation. In summary, the chemical heterostructure produced by spinodal decomposition has been remarkably effective in improving the strength of RHEAs.},
  archive      = {J_MATDES},
  author       = {Yongkang Zhou and Ziyan Zhao and Yuanyuan Wang and Hong Li and Haifeng Zhang and Zhengwang Zhu},
  doi          = {10.1016/j.matdes.2025.114736},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114736},
  shortjournal = {Mater. Des.},
  title        = {Al alloying-driven spinodal decomposition enables ultra-strong cast refractory high-entropy alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving synergistic strength-ductility enhancement in a hierarchical hetero-lamellar AlCoCrFeNi2.1 eutectic high-entropy alloy via facile hot-rolling strategy. <em>MATDES</em>, <em>259</em>, 114734. (<a href='https://doi.org/10.1016/j.matdes.2025.114734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eutectic high-entropy alloys (EHEAs) have attracted considerable interest due to their superior multifunctional performance. However, the inherent tendency of stress concentration at irregular phase boundaries frequently leads to premature fracture. This study presents a facile hot-rolling strategy to achieve synergistic strength-ductility enhancement in AlCoCrFeNi 2.1 EHEA via constructing a hierarchical hetero-lamellar structure (HHLS). Through controlled per-pass rolling reduction (PPRD), we induce strain-partitioning-mediated microstructural refinement in the hot-rolled EHEA and activate synergistic deformation mechanisms including stacking faults, Lomer-Cottrell locks, and deformation twinning. The resultant HHLS (aligned FCC/B2 lamellae, partially recrystallized FCC regions, and intragranular B2 precipitates) triggers pronounced hetero-deformation-induced (HDI) strengthening. Consequently, the EHEA with HHLS exhibits exceptional properties: yield strength of 1202 MPa, ultimate tensile strength of 1489 MPa, and uniform elongation of 11.5 %, which are 112 %, 45 %, and 6 % higher than those of the as-cast alloy, respectively. The superior properties originate from HDI effect and FCC phase-mediated deformation mechanisms, which enable the EHEA to maintain exceptional work-hardening rate despite high dislocation density, effectively delaying plastic instability. These findings not only establish a readily implementable thermomechanical processing strategy for EHEAs, but also provide a novel paradigm for improving mechanical properties, paving the way for their application in high-performance structural materials.},
  archive      = {J_MATDES},
  author       = {Qidong Ren and Tianxin Li and Hengke Xie and Yuhao Jia and Mingpan Wan and Chaowen Huang and Chaoyi Chen and Junqi Li and Yiping Lu},
  doi          = {10.1016/j.matdes.2025.114734},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114734},
  shortjournal = {Mater. Des.},
  title        = {Achieving synergistic strength-ductility enhancement in a hierarchical hetero-lamellar AlCoCrFeNi2.1 eutectic high-entropy alloy via facile hot-rolling strategy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of electroplating current density and post-annealing on the warpage and reliability of redistribution layer for advanced semiconductor package. <em>MATDES</em>, <em>259</em>, 114732. (<a href='https://doi.org/10.1016/j.matdes.2025.114732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the warpage and thermal fatigue reliability of the redistribution layer (RDL) were improved by optimizing the electroplating current density and post-annealing process to control residual stress. The residual stress of the electroplated copper layer and the cure shrinkage of the photo-imageable dielectric (PID) were evaluated using bi-layer beam specimens designed based on Timoshenko beam theory. To analyze the mechanism of residual stress generation in the copper layer, the grain size was quantified using X-ray diffraction (XRD) and the coefficient of thermal expansion (CTE) was measured using a thermomechanical analyzer (TMA). Warpage and thermal fatigue reliability were evaluated under varying electroplating current densities and post-annealing conditions. These experimental results were validated by comparing them with stress analysis data obtained through finite element analysis (FEA). In the RDL structure, the optimized current density condition effectively reduced the residual tensile stress in the electroplated copper layer and improved both warpage and thermal fatigue life. In addition, the post-annealing relieved cure shrinkage-induced stress in the PID, enhancing the reliability of the RDL structure. The results of this study are expected to contribute to improved yield and thermomechanical reliability in advanced semiconductor packages.},
  archive      = {J_MATDES},
  author       = {Taek-Hyeon Kim and Jeong-Hyeon Baek and Sang-Il Kim and Tae-Hoon Kim and Ji-Hye Shim and Hak-Sung Kim},
  doi          = {10.1016/j.matdes.2025.114732},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114732},
  shortjournal = {Mater. Des.},
  title        = {Effect of electroplating current density and post-annealing on the warpage and reliability of redistribution layer for advanced semiconductor package},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In vitro antibacterial and in vivo osteogenesis of 3D-printed magnesium peroxide–doped calcium phosphate silicate scaffolds for revision total knee arthroplasty. <em>MATDES</em>, <em>259</em>, 114731. (<a href='https://doi.org/10.1016/j.matdes.2025.114731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revision total knee arthroplasty (RTKA) often encounters tibial bone defects and high infection risk, especially from methicillin-resistant Staphylococcus aureus (MRSA). Current strategies rely on bone grafts with antibiotics, but prolonged use promotes resistance. Here, we developed a 3D-printed magnesium peroxide (MgO 2 )–doped calcium phosphate silicate (CSP) scaffold to address both structural and antibacterial demands. The MgO 2 –CSP scaffold exhibited cancellous bone-like strength (∼7.95 MPa) and an interconnected macroporous structure conducive to cell migration and healing. In vitro , the 14 wt% MgO 2 scaffold (B14M) inhibited 80.4 % of Gram-negative bacteria and 74.6 % of MRSA via Mg 2+ and H 2 O 2 release, while both B0M (no MgO 2 ) and B14M promoted BMSC proliferation and osteogenic differentiation. In vivo , the B14M scaffold markedly enhanced bone regeneration in rat tibial defects, achieving a BV/TV of ∼73.09 % versus ∼29.84 % for B0M at 8 weeks. These findings highlight MgO 2 –CSP scaffolds as a promising strategy to promote osteogenesis while combating MRSA-associated infections in RTKA.},
  archive      = {J_MATDES},
  author       = {Lisha Meng and Hao Li and Xujia Hao and Tao Wu and Jingqiu Zhou and Yadong Chen and Qiang Zheng and Xiuhong Cao and Juan Wang and Xinwei Liu and Tongmeng Jiang and Tianxing Gong and Wei Yuan},
  doi          = {10.1016/j.matdes.2025.114731},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114731},
  shortjournal = {Mater. Des.},
  title        = {In vitro antibacterial and in vivo osteogenesis of 3D-printed magnesium peroxide–doped calcium phosphate silicate scaffolds for revision total knee arthroplasty},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of synthesis routes on oxygen content, crystallography, and thermal stability of Ti3AlC2 MAX phases and resulting MXenes. <em>MATDES</em>, <em>259</em>, 114729. (<a href='https://doi.org/10.1016/j.matdes.2025.114729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current MXene research focuses on synthesising high-quality MAX phases with minimal O substitution in the C sublattice. This study provides insights into how different ball milling techniques and elemental compositions used in Ti 3 AlC 2 MAX phase synthesis affect the O incorporation into the lattice structure, which directly impacts the MAX phases’ and the resulting MXenes’ thermal stability. The unit cell lattice parameters (LPs) of a MAX phase are well-established indicators in determining the degree of O substitution. The presence of O reduced the a and c LPs of the MAX phase unit cell. However, the corresponding MXenes exhibited similar a LP ( a = 3.05 Å) values regardless of the LP values of their MAX phases. The LP observations are validated by correlative thermogravimetric analysis (TGA) carried out in air atmosphere. With the decreasing O incorporation in the MAX phase, an increase in the oxidation temperature was observed from 450 °C to 780 °C. However, the corresponding MXenes showed an average oxidation onset around 460 °C. Thus, this study reveals an important structure–property relationship between the Ti 3 AlC 2 MAX phase and the resulting Ti 3 C 2 MXenes.},
  archive      = {J_MATDES},
  author       = {Chathushka D. Hettige Dharmasiri and Konstantin L. Firestein and Joseph F.S. Fernando and Xiaodong Wang and Zhenhuan Chen and Dasun P.W. Guruge and Courtney-Elyce Lewis and Dmitri V. Golberg},
  doi          = {10.1016/j.matdes.2025.114729},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114729},
  shortjournal = {Mater. Des.},
  title        = {Influence of synthesis routes on oxygen content, crystallography, and thermal stability of Ti3AlC2 MAX phases and resulting MXenes},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ex vivo porcine urethral model for investigating intermittent catheter-associated urethral microtrauma. <em>MATDES</em>, <em>259</em>, 114727. (<a href='https://doi.org/10.1016/j.matdes.2025.114727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catheter-associated urethral microtrauma is a significant complication of intermittent catheterisation, compromising patient quality of life (QOL) and increasing urinary tract infection risk. Current research is hindered by the lack of robust physiological models to evaluate the mechanical interactions between catheter materials and urethral tissue during intermittent catheterisation. This study introduces the first ex vivo porcine urethral model to investigate tribological performance and material-tissue interactions during intermittent catheter (IC) use, enabling more informed catheter design. We examined four commercial hydrophilic polyvinylpyrrolidone (PVP)-coated ICs and a coating-free integrated amphiphilic surfactant (IAS) IC. ICs were inserted into porcine urethras using a texture analyser, held for two minutes, and withdrawn while measuring force and work done. Post-catheterisation, urethras were examined for microtrauma. Three of four PVP-coated catheters required significantly greater withdrawal force compared to the IAS catheter, correlating with increased urethral transitional membrane damage post-catheterisation. Ex vivo findings suggest that IAS catheters may lower the risk of complications compared with PVP-coated catheters in intermittent catheterisation. This study provides a new platform for comprehensive evaluation of IC-tissue interactions. It underscores the importance of tribological design in medical devices, aiding future innovation in device design and ultimately improve the QOL of patients undergoing intermittent catheterisation.},
  archive      = {J_MATDES},
  author       = {Jane Burns and Robyn N. Irwin and James Quinn and Jessica V. Moore and David Pollard and Ased Ali and James Hands and Colin P. McCoy and Louise Carson and Matthew P. Wylie},
  doi          = {10.1016/j.matdes.2025.114727},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114727},
  shortjournal = {Mater. Des.},
  title        = {An ex vivo porcine urethral model for investigating intermittent catheter-associated urethral microtrauma},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNN-based shape optimization of gradient-index phononic crystals with sensitivity analysis for tunable focal position and robust energy harvesting. <em>MATDES</em>, <em>259</em>, 114723. (<a href='https://doi.org/10.1016/j.matdes.2025.114723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-index (GRIN) phononic crystals (PnCs) enable energy harvesting (EH) by focusing elastic waves into electrical energy. Efficient EH requires maximizing focused wave intensity, typically achieved by tuning the GRIN PnCs unit-cell shape. However, existing designs often exhibit energy concentration near the GRIN lens boundary and incorporate narrow gaps and sharp corners, making them susceptible to manufacturing errors and limiting their practical applicability. Understanding the potential performance changes caused by manufacturing errors is important because geometrical alterations can compromise wave-focusing performance. Therefore, this study aims to optimize the unit-cell shape toward maximum focused intensity at the desired locations for EH devices. To assess manufacturability, the effects of minor geometric variations on the focal position and focused intensity are evaluated via a sensitivity analysis. The optimal shape is derived using a deep neural network (DNN) surrogate model trained to predict focal position and focused intensity. This model accelerates a genetic algorithm (GA) used to perform the optimization. Our optimized designs exhibit 1.5 to 2.0 times higher focused intensity across the target focal positions compared with the conventional design. Thus, these optimal shapes, along with their sensitivity analysis results, provide practical guidelines for defining manufacturing tolerances and achieving consistent, efficient EH performance.},
  archive      = {J_MATDES},
  author       = {Mary Kim and Sangryun Lee},
  doi          = {10.1016/j.matdes.2025.114723},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114723},
  shortjournal = {Mater. Des.},
  title        = {DNN-based shape optimization of gradient-index phononic crystals with sensitivity analysis for tunable focal position and robust energy harvesting},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving high oxygen tolerance in Ti6Al4V: Copper-oxygen co-doping strategy for ultrahigh strength-ductility balance. <em>MATDES</em>, <em>259</em>, 114719. (<a href='https://doi.org/10.1016/j.matdes.2025.114719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional α + β Ti6Al4V alloys lack sufficient strengthening mechanisms, limiting strength. While oxygen (O) offers a cost-effective strengthening route, exceeding ∼ 0.33 wt% causes significant embrittlement. Here, we explored how to efficiently utilize interstitial oxygen to enhance the mechanical properties of Ti6Al4V. The copper oxide (CuO) was innovatively employed as a precursor to completely dissolve into Ti6Al4V matrix, interstitial O and substitutional Cu atoms were simultaneously utilized to strengthen the primary α-phase (α p ) while inducing the abundant secondary-α (α s ) nanoprecipitates. Surprisingly, the introduction of Cu element facilitated control of lattice distortion and redistributed oxygen between α p and β-transformed (β trans ) structure, resulting in the Ti6Al4V-2.5CuO (wt.%) alloy with high oxygen tolerance (0.62 wt%) and an ultra-high ultimate strength of ∼ 1635 MPa and a favorable ductility of ∼ 5.3 %. The dual effect of interstitial solid solution strengthening and α s precipitation strengthening were achieved under the Cu/O interaction. Additionally, the addition of Cu promoted the oxygen redistribution and activation of the basal < a > and pyramidal < c + a > slip systems, thereby ensuring improved ductility. This study presented a novel strategy for high-strength Ti alloys using interstitial oxygen, maximizing strengthening while mitigating embrittlement.},
  archive      = {J_MATDES},
  author       = {Hongqiang Duan and Hongmei Zhang and Xingwang Cheng and Xiaonan Mu and Qunbo Fan and Ying Zhang and Ni Xiong and Ke Feng and Yu Wang and Xuexia Li and Taotao Cai and Kefan Zheng},
  doi          = {10.1016/j.matdes.2025.114719},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114719},
  shortjournal = {Mater. Des.},
  title        = {Achieving high oxygen tolerance in Ti6Al4V: Copper-oxygen co-doping strategy for ultrahigh strength-ductility balance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crack deflection by design – Utilizing the material inhomogeneity effect on miniaturized additively manufactured structures. <em>MATDES</em>, <em>259</em>, 114718. (<a href='https://doi.org/10.1016/j.matdes.2025.114718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A natural crack exhibits a surrounding stress field, which may overlap considerably with a stress field caused by any material inhomogeneity, influencing the crack driving force and extension direction. To utilize this effect for potentially increasing the apparent toughness, a defined pore is introduced near a potential crack path, whereby upon interaction, the crack tip can be deflected or trapped, depending on the intermediate distance. Since fundamental mechanics is well-known, a miniaturized notched bending specimen geometry incorporating a pore was selected to investigate the application potential for parts manufactured via multi-photon lithography. The size regime is representative of the smallest available objects and requires in situ SEM testing, which was completed with finite element modeling based on crack path prediction through analyzing the local crack driving force. The high dimensional repeatability of the process allowed for testing reliably reproduced specimens with variation of crack to pore distance only. The prediction represented the actual crack paths well, underlining successfully facilitated crack path alteration. The toughness was mainly increased by crack trapping within the pore, where deflection had a quantitatively negligible effect.},
  archive      = {J_MATDES},
  author       = {Alexander Jelinek and Markus Alfreider and Dražen Breščaković and Otmar Kolednik and Daniel Kiener},
  doi          = {10.1016/j.matdes.2025.114718},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114718},
  shortjournal = {Mater. Des.},
  title        = {Crack deflection by design – Utilizing the material inhomogeneity effect on miniaturized additively manufactured structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refined sub-region nanoindentation and FEM modeling of solvent-modified sintered silver joints for enhanced reliability prediction in power electronics. <em>MATDES</em>, <em>259</em>, 114716. (<a href='https://doi.org/10.1016/j.matdes.2025.114716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mechanical reliability of sintered silver joints, widely used in power electronics packaging, is critical for long-term applications such as electric vehicle converters. However, conventional homogeneous modeling often oversimplifies internal microstructural variations and limits the accuracy of stress prediction, especially under thermal cycling. In this study, a region-refined modeling framework is proposed to account for epoxy-regulated porosity and mechanical inhomogeneity across the joint. Pressureless die-attach joints were prepared using submicron silver pastes with varying epoxy contents (0∼4 wt%). The joint was divided into five sub-regions from the center to the fillet for localized characterization. Nanoindentation, SEM, and EDS analyses were conducted to assess region-specific mechanical properties and microstructure. Power-law constitutive models were extracted for each region and implemented into finite element simulations of thermal cycling (−55 ∼ 150 °C, 2 cycles/h, 250 h). The sub-region FEM model more accurately captured local stress concentrations and identified failure-prone areas, particularly near the fillet, compared to conventional homogeneous models. Experimental validation confirmed a good correlation between simulated stress zones and observed degradation. This sub-region strategy provides a robust framework for reliability prediction and design optimization of sintered silver joints in high-performance, large-area packaging applications.},
  archive      = {J_MATDES},
  author       = {Xinyue Wang and Letao Bian and Zhoudong Yang and Haixue Chen and Yiping Sun and Wenting Liu and Guoqi Zhang and Jing Zhang and Pan Liu},
  doi          = {10.1016/j.matdes.2025.114716},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114716},
  shortjournal = {Mater. Des.},
  title        = {Refined sub-region nanoindentation and FEM modeling of solvent-modified sintered silver joints for enhanced reliability prediction in power electronics},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Elastic modulus engineering in β-titanium alloys: Tuning the precipitation kinetics using sn. <em>MATDES</em>, <em>259</em>, 114711. (<a href='https://doi.org/10.1016/j.matdes.2025.114711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design strategies for β -Ti alloys either aim at the suppression of the diffusion-assisted, isothermal ω i s o precipitation or at the controlled transformation of these precipitates into α phase by an ω -assisted route, with the kinetics of ω i s o formation playing an essential role in both cases. Therefore, controlling the ω i s o formation is pivotal in the design of β -Ti alloys with targeted properties. We propose that by controlling the Sn content added to β -Ti alloys a wide range of achievable microstructures for modulus engineering is accessible. Upon Sn addition, we observe an exponentially slowed down ω i s o formation based on blocking of diffusion pathways for the β -stabiliser atoms without the transformation being thermodynamically inhibited. This suppression of ω i s o formation allows the β -Ti alloys to maintain a lower elastic modulus necessary for biomedical applications. Furthermore, as byproduct, reducing the number density of ω i s o precipitates upon Sn addition also impedes the ω -assisted α -formation, while the Sn-free forms fine, acicular intragranular α plates and α G B side-plates with similar morphology after low temperature pre-ageing. These results provide solid evidence for the previously proposed Sn-induced kinetic deceleration and suggest that the mechanical properties can be tailored as required by the application by tuning the ω i s o precipitation kinetics using Sn.},
  archive      = {J_MATDES},
  author       = {Florian Brumbauer and Norihiko L. Okamoto and Philipp Materna and Glen J. Smales and Tetsu Ichitsubo and Wolfgang Sprengel and Martin Luckabauer},
  doi          = {10.1016/j.matdes.2025.114711},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114711},
  shortjournal = {Mater. Des.},
  title        = {Elastic modulus engineering in β-titanium alloys: Tuning the precipitation kinetics using sn},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Damping properties of single-material and bi-material lattice structures. <em>MATDES</em>, <em>259</em>, 114710. (<a href='https://doi.org/10.1016/j.matdes.2025.114710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice structure is widely used to achieve lightweight while damping is an indispensable property for evaluating the dynamic properties of lattice structures. This paper studies the damping performance of the lattice structures by experiments and analysis. A series of lattice specimens including single-material and bi-material lattices are prepared. The bi-material lattice is designed by filling the metal lattice with epoxy material. By this way, the stiffness of the bi-material lattice is guaranteed, and the effect of vibration absorption is realized at the same time. Different from the traditional proportional damping method of single-material structure, the non-proportional damping model is used for the bi-material lattice structure. The homogenization method is used to calculate the equivalent complex modulus of the lattice. An inverse method is proposed in this paper to obtain the loss factor of in-situ epoxy material filled in the metal lattice. Finally, lattice specimens with local damping are prepared and tested, and the experimental and simulation data are compared.},
  archive      = {J_MATDES},
  author       = {Haotian Wang and Bin Niu and Rui Yang},
  doi          = {10.1016/j.matdes.2025.114710},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114710},
  shortjournal = {Mater. Des.},
  title        = {Damping properties of single-material and bi-material lattice structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adenosine-loaded adhesive microfluidic hydrogel microspheres stimulate acupoint activation for pain management. <em>MATDES</em>, <em>259</em>, 114708. (<a href='https://doi.org/10.1016/j.matdes.2025.114708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pain represents a significant public health challenge with substantial clinical and economic burdens. While pharmacotherapy remains a mainstay of pain management, its utility is limited by adverse side effects and the potential for dependency. Acupuncture has shown great potential in pain management through its ability to induce analgesic effects via acupoint stimulation. However, its poor specificity and ill-defined stimulation parameters compromise therapeutic specificity and reproducibility. Herein, we developed a biomaterial-based acupoint activation strategy for pain management. Adhesive polydopamine-coated hydrogel microspheres were fabricated using microfluidic techniques for accurate attachment and activation of acupoints. Adhesive hydrogel microspheres loaded with adenosine can slowly release exogenous adenosine at the ST36 acupoint to simulate the analgesic effect of acupuncture. In vitro and in vivo studies demonstrated that single-dose administration of adhesive microspheres can effectively target acupoints, elevate mechanical pain thresholds, and provide systemic anti-inflammatory effects for up to 7 days. Overall, the proposed adhesive hydrogel microsphere system offers a new perspective on acupuncture practice and pain management.},
  archive      = {J_MATDES},
  author       = {Xiujuan Li and Zehao Chen and Songgen Chen and Han Wang and Lin Fu and Ban Feng and Hui Chen and Lize Xiong},
  doi          = {10.1016/j.matdes.2025.114708},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114708},
  shortjournal = {Mater. Des.},
  title        = {Adenosine-loaded adhesive microfluidic hydrogel microspheres stimulate acupoint activation for pain management},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Study and characterization of recycled ABS-GF in large format additive manufacturing to enhance mechanical properties of printed structures. <em>MATDES</em>, <em>259</em>, 114707. (<a href='https://doi.org/10.1016/j.matdes.2025.114707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large format additive manufacturing (LFAM) has proven its ability to produce high-performance components for competitive markets. By depositing material only where it's needed, it drastically reduces waste material and energy use, obtaining a sustainability advantage that is further enhanced on larger scale. However, a deeper understanding of material recycling is critical to achieving the next milestone in sustainability. In this work, a methodology was proposed that uses both molds and final parts, manufactured in acrylonitrile-butadiene-styrene reinforced with short glass fibers (ABS-GF), which had reached the end of their useful life to be used as feedstock. It is observed that recycling reduces fiber length by 47.3%, which directly impacts the mechanical properties in the longitudinal printing direction, resulting in around a 9% decrease in maximum tensile stress. However, this reduction falls to 5.1% in the transverse direction to the printing, and in some cases, the recycled material even surpasses the virgin material due to improved interlayer adhesion. An analysis on the adhesion reveals that the shorter monomer chains obtained during recycling allow better interlacing between layers. These results suggest that the reuse of the molds is viable and by adjusting the printing parameters we can obtain properties suitable for demanding applications.},
  archive      = {J_MATDES},
  author       = {Javier Bas-Bolufer and Pablo Castelló-Pedrero and Cesar García-Gascón and Juan Antonio García-Manrique},
  doi          = {10.1016/j.matdes.2025.114707},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114707},
  shortjournal = {Mater. Des.},
  title        = {Study and characterization of recycled ABS-GF in large format additive manufacturing to enhance mechanical properties of printed structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology optimization of 3D-printed material architectures: Testing toolpath consideration in design. <em>MATDES</em>, <em>259</em>, 114700. (<a href='https://doi.org/10.1016/j.matdes.2025.114700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology Optimization (TO) methods applied to the design of material architectures allow for a wider exploration of the possible design space when compared to common geometry parameter controlled design methods. These optimal designs are often realized using Direct Ink Writing methods which exhibit characteristic features of discrete bead sizes and weak bead bonding. The resultant lack of design fidelity and toolpath dependent anisotropy has been found to negatively impact structural performance if not accounted for in the design. This paper addresses both characteristics in the design process of cellular material architectures by expanding upon the Nozzle Constrained Topology Optimization algorithm and experimentally validating the results against a typical baseline. An experimental method of deriving bond region material properties is detailed. A direct toolpath generation method from topology optimized results is proposed. Comparisons are made with conventional topology optimization design methods and performance is measured both experimentally and numerically against theoretical bounds. At relative densities ≤ 70 % , designs with nozzle constraints were able to more closely align numerical and experimental results for both performance and design fidelity (measured by relative density). In contrast, conventional topology optimized designs had higher overall performance, but little alignment between intended design and resultant experimental result. Typical designs consistently overdeposited material and inconsistently predicted performance.},
  archive      = {J_MATDES},
  author       = {Hajin Kim-Tackowiak and Josephine V. Carstensen},
  doi          = {10.1016/j.matdes.2025.114700},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114700},
  shortjournal = {Mater. Des.},
  title        = {Topology optimization of 3D-printed material architectures: Testing toolpath consideration in design},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forming-induced thickness effects on structural response of arched thin-shell metal alloys. <em>MATDES</em>, <em>259</em>, 114692. (<a href='https://doi.org/10.1016/j.matdes.2025.114692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical influence of forming-induced thickness variations on arched thin-shell metal components' structural response and rupture behavior, a key challenge in safety-critical applications. An integrated predictive framework combines classical plate theory for initial deformation estimates, explicit dynamic finite element simulations for elastic-plastic analysis, and Kriging-based response surface modeling to map geometric, material, and process parameters to performance metrics. A large-scale simulation campaign across eight isotropic material models and 42,669 configurations identifies the arch rise-to-radius ratio as the dominant factor in post-forming thickness evolution, with non-uniform profiles causing up to deviations in rupture pressures and altering failure modes compared to uniform assumptions. Modal, buckling, and rupture analyses highlight significant impacts on natural frequencies, critical loads, and mechanisms. Experimental validation on 36 Monel Alloy 400 rupture discs achieves high accuracy, with thickness root-mean-square error of (maximum mean absolute percentage error ) and rupture pressure errors below , supported by uncertainty analysis (expanded uncertainties at confidence). The generalizable framework, extensible to non-metallic isotropic shells and non-arched geometries, enables enhanced prediction, optimization, and reliability by linking forming outcomes to structural integrity.},
  archive      = {J_MATDES},
  author       = {Shilin Chen and Qingxi Yang and Qingzhou Yu and Genmu Shi and Haotian Yin},
  doi          = {10.1016/j.matdes.2025.114692},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114692},
  shortjournal = {Mater. Des.},
  title        = {Forming-induced thickness effects on structural response of arched thin-shell metal alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond diameters: Decoding fabrication patterns of hierarchical micro-nano titanium implants via anodization and their geometries on region-specific soft-tissue integration. <em>MATDES</em>, <em>259</em>, 114691. (<a href='https://doi.org/10.1016/j.matdes.2025.114691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrochemical anodization creates titania nanopores (TNPs) on Ti implants with distinctive micro-nano geometries to enhance their surface bioactivity, showing the potential to improve soft-tissue integration at varied transmucosal regions. However, understanding how topography regulates TNP dimensions under voltage, and the clinical feasibility of diverse TNP geometries was limited. More crucially, existing research predominantly focused on nanopore diameter, neglecting other geometric characteristics (alignment, texture/roughness) on soft-tissue cells that impeded optimized TNPs design for ideal soft-tissue integration. This study showed nanopore dimensions were voltage-dependent on micro-patterned Ti but remain stable on smooth counterparts. Varied TNPs with similar diameters but different alignment/roughness were selected and identified with similar chemistry/hydrophilicity, but their protein adhesion and stability were length-dependent, showing their feasibility as implant devices. Finally, human gingival fibroblasts (HGFs) and HaCaT epithelial cells functions on varied selected TNPs reflected that nanopores inherently promoted cell responses, but hybrid microgroove-nanopores dramatically enhanced HGF’s collagen and fibronectin secretion, while irregular textured nanopores significantly improved HaCaT adhesion. By addressing the gaps in understanding topographical regulation and the influence of overlooked geometric features beyond diameter, this work advances spatially optimized implant designs for improved epithelial sealing and connective tissue integration at different transmucosal zones for improved implant health.},
  archive      = {J_MATDES},
  author       = {Tianqi Guo and Miaoxuan Dai and Xinxin Ding and Xiaomeng Zhang and Yingxin Gu and Hongchang Lai},
  doi          = {10.1016/j.matdes.2025.114691},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114691},
  shortjournal = {Mater. Des.},
  title        = {Beyond diameters: Decoding fabrication patterns of hierarchical micro-nano titanium implants via anodization and their geometries on region-specific soft-tissue integration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Micro-scale shale fracture wear under normal stress: 3D point cloud-coupled experiments/simulations study. <em>MATDES</em>, <em>259</em>, 114690. (<a href='https://doi.org/10.1016/j.matdes.2025.114690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive understanding of frictional interactions and wear mechanisms in rough fractures is critical for advancing research in earthquake dynamics and associated geological hazards. Systematic loading experiments were performed on unconfined shale fractures using a six-dimensional rock pressure detection and displacement monitoring system. High-resolution three-dimensional point cloud datasets of fracture surfaces were acquired via laser profilometry, while pressure-sensitive films were employed to quantitatively map contact behavior under varying normal stresses. Spatial integration of point cloud data with pressure-sensitive film measurements demonstrated that initial contact occurs preferentially at asperities with elevated heights. A wear distribution model was constructed by computationally aligning and subtracting pre- and post-loading topographic datasets. Mesh-based analytical methods identified a robust correspondence between extreme wear loci and regions of concentrated contact stress. The steady-state wear rate of shale fractures followed a power-law relationship with normal stress, consistent with micromechanical wear theories. Statistical evaluation of 3D surface topography parameters revealed that the root-mean-square height ( S q ) displayed significant correlations (Pearson’s r > 0.85, p < 0.01) with mechanical metrics. These findings advocate for S q as a robust 3D geomechanical index for characterizing contact wear evolution in fractured media.},
  archive      = {J_MATDES},
  author       = {Haichun Ma and Jian Wang and Jiazhong Qian and Yang Xu and Chenglong Xie and Lei Ma},
  doi          = {10.1016/j.matdes.2025.114690},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114690},
  shortjournal = {Mater. Des.},
  title        = {Micro-scale shale fracture wear under normal stress: 3D point cloud-coupled experiments/simulations study},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Water-responsive hydroplastic 4D printing with programmable shape morphing and locking. <em>MATDES</em>, <em>259</em>, 114688. (<a href='https://doi.org/10.1016/j.matdes.2025.114688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydroplastic materials undergo reversible mechanical changes upon water absorption, transitioning between soft and rigid states. Leveraging this characteristic promotes environmentally friendly shape-morphing technologies, recently attracting significant research interest. This study aims to develop a method for inducing non-uniform curing along the thickness of a hydroplastic photocurable resin by applying frontal photopolymerization (FPP) using a commercial projector, and for achieving shape-morphing behavior through water absorption. The 3D-printed structures deform according to a predefined design, soften upon water absorption, and harden upon drying while retaining a stable deformed shape. Materials that deform in response to water or humidity are typically ductile, making it difficult to maintain their deformed shape after stimulus removal. However, this study demonstrates that a single material can programmable self-assembly while retaining its deformed shape even after water removal. This hydroplastic shape-morphing structure can be used for fabricating microfluidic channels on glass surfaces, which are difficult to process.},
  archive      = {J_MATDES},
  author       = {Sun Hye Yoon and Seo Rim Park and Myung Seo Kim and Kwang Min Lee and Seong Hyeon Park and Seok Kim and Young Tae Cho},
  doi          = {10.1016/j.matdes.2025.114688},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114688},
  shortjournal = {Mater. Des.},
  title        = {Water-responsive hydroplastic 4D printing with programmable shape morphing and locking},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of particle size on powder velocity distribution at the nozzle outlet in directed energy deposition. <em>MATDES</em>, <em>259</em>, 114680. (<a href='https://doi.org/10.1016/j.matdes.2025.114680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal-based Directed Energy Deposition (DED) is considered one of the variations of additive manufacturing with the highest potential, particularly for space industry and in-orbital manufacturing. The technology however still faces various challenges, many of which can be traced back to poor control and understanding of the powder delivery. Velocity distribution of powder particles at the DED nozzle outlet has a key influence on the results of any predictive model of powder stream and yet remains largely disputed. Certain numerical studies highlighted a possible influence of powder particle size on the velocity condition at the nozzle exit, yet no experimental studies confirmed this effect. The experimental campaign described in this paper quantifies this relation between powder particle size and velocity distribution at the nozzle outlet and a strong decrease of particle speed with particle size is observed. Moreover, smaller particles are observed to travel at speeds higher than the mean carrier gas speed suggesting powder particle segregation within the nozzle as one of the mechanisms driving speed differences at the nozzle outlet.},
  archive      = {J_MATDES},
  author       = {Tijan Mede and Andrej Jeromen and Edvard Govekar and Michael Mallon and Matjaž Godec},
  doi          = {10.1016/j.matdes.2025.114680},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114680},
  shortjournal = {Mater. Des.},
  title        = {Influence of particle size on powder velocity distribution at the nozzle outlet in directed energy deposition},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse design of two-dimensional architected materials with desired uniaxial polynomial nonlinear constitutive responses aided by stiffness normalization. <em>MATDES</em>, <em>259</em>, 114677. (<a href='https://doi.org/10.1016/j.matdes.2025.114677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of specified nonlinear mechanical responses into a structure or material is a highly sought after capability, with significant potential impacts in areas such as wave tailoring in metamaterials, impact mitigation, soft robotics, and biomedicine. Here, we present a topology optimization approach to design two-dimensional structures for desired uniaxial polynomial nonlinear behavior, wherein we formulate the objective function to match nonlinear coefficient ratios, such that the linear stiffness is decoupled from the desired nonlinearity of the response. We suggest that such linear stiffness decoupling can help aid convergence for problems with fixed, but poorly matched, constituent materials and design volumes. This benefit can be understood by considering, if large absolute force values and stiffnesses are targeted, thicker structures with less open space generally result. Such high volume ratio structures reduce the kinematic freedom (available to, e.g. , long thin structures) which is needed for strong geometrically nonlinear responses. We show designs achieved using this approach that match a range of qualitatively different polynomial behaviors with high precision, which are of interest, in particular, within the domain of dynamical systems where nonlinear elasticity of relatively simple polynomial forms can confer greater analytical tractability.},
  archive      = {J_MATDES},
  author       = {Brianna MacNider and Ian Frankel and Kai Qian and Alan Pozos and Luz Estrella Aketzali Santos-Salazar and H. Alicia Kim and Nicholas Boechler},
  doi          = {10.1016/j.matdes.2025.114677},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114677},
  shortjournal = {Mater. Des.},
  title        = {Inverse design of two-dimensional architected materials with desired uniaxial polynomial nonlinear constitutive responses aided by stiffness normalization},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of orifice geometry in determining fibre production efficiency in pressurized gyration. <em>MATDES</em>, <em>259</em>, 114670. (<a href='https://doi.org/10.1016/j.matdes.2025.114670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pressurized gyration allows the scaled-up production of polymeric fibre under the simultaneous application of pressure and rotation. This study investigates the influence of orifice design on fibre formation and production rate in pressurized gyration, aiming to optimize the technique for industrial-scale applications. Transparent vessels with varying orifice heights (7.5 mm, 15 mm, and 22.5 mm), orifice numbers (24 and 48), and dual-level orifice distributions were fabricated and tested under pressures of 0.1, 0.2, and 0.3 MPa. Morphological analysis showed that fibre diameter decreased from 2.2 µm to 1.8 µm when pressure was raised from 0.1 to 0.3 MPa when increasing the number of orifices to 48. Two-level orifice designs yielded mixed diameter distributions, enabling tunable fibre architectures. High-speed imaging revealed that the 7.5 mm orifice height achieved fluid ejection 7.5 % faster than 22.5 mm at 0.1 MPa and increasing pressure from 0.1 to 0.2 MPa reduced ejection time by up to 33 %. Production rate increased with more orifices (48 compared to 24), by 9.8 % at 0.2 MPa, and declined at higher pressure for vessels with dual-level designs. Overall, the findings provide quantitative insights into how vessel geometry influences fibre morphology and throughput in pressurized gyration systems.},
  archive      = {J_MATDES},
  author       = {Ahmed Alneyadi and Alexander Smith and Anthony Harker and Mohan Edirisinghe},
  doi          = {10.1016/j.matdes.2025.114670},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114670},
  shortjournal = {Mater. Des.},
  title        = {The role of orifice geometry in determining fibre production efficiency in pressurized gyration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying the impact of oxidation on the mechanical properties of alloy 718 using local mechanical testing techniques. <em>MATDES</em>, <em>259</em>, 114669. (<a href='https://doi.org/10.1016/j.matdes.2025.114669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite excellent oxidative properties of the Alloy 718 Ni-based superalloy, long-term exposure to oxidative environments in service creates a chemical gradient in the sub-surface affected by oxidation. Its characterization is key to assessing the evolving mechanical behavior of such affected materials. The present study focuses on the γ '- γ ” precipitation depletion induced by the chemical gradient and benchmarks micro-mechanical testing techniques to assess local mechanical properties. Local techniques such as nanoindentation and micro-pillar compression were used to measure both elastic and plastic properties of a pre-oxidized Alloy 718 Ni-based superalloy, having a chemical gradient. These results were compared to a global approach by tensile testing and high resolution-digital image correlation (HR-DIC) on model materials corresponding to regions of the chemical gradient: the solid-solution and the precipitation-hardened Alloy 718. The plastic behavior was investigated in terms of macroscopic yield strength and slip activity. Results obtained by the local and global techniques were found to be different but complementary. The relevance of the association of multiple micro-mechanical tests and sample preparation techniques to probe chemical gradients is discussed and technique advantages and drawbacks are exposed based on the single crystalline or polycrystalline nature of the micro-mechanical testing.},
  archive      = {J_MATDES},
  author       = {Malo Jullien and Marc Legros and Mathieu Calvat and Jean-Charles Stinville and Damien Texier},
  doi          = {10.1016/j.matdes.2025.114669},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114669},
  shortjournal = {Mater. Des.},
  title        = {Quantifying the impact of oxidation on the mechanical properties of alloy 718 using local mechanical testing techniques},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-lightweight multi-functional gyroid-based metamaterial for simultaneous sound insulation, vibration suppression, and impact mitigation in all directions. <em>MATDES</em>, <em>259</em>, 114652. (<a href='https://doi.org/10.1016/j.matdes.2025.114652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-functional materials are increasingly essential in many applications due to their ability to serve multiple purposes, simultaneously. Metamaterials can offer tailored functionality based on carefully designed tessellating basic building blocks, or unit cells, in space. These unit cells are most commonly designed for a single objective, for example, to mitigate an impact, insulate sound, or dampen vibrations. However, a metamaterial that can mitigate impact, attenuate elastic vibrations, insulate airborne sound, while being ultra-light and ultra-stiff remains elusive. Here, we present three gyroid-based metamaterial designs, which are numerically and experimentally examined, that can simultaneously serve all these functions in all directions. Our designs have band gaps reaching 60 % with as low as 367 Hz starting band gap frequency, while being up to 77 % lighter than a homogeneous block of the same material. Our findings highlight the potential of metamaterials for applications that require wave manipulation, mechanical resilience, and impact mitigation with limited mass and volume, simultaneously.},
  archive      = {J_MATDES},
  author       = {Evan Kluge and Osama R. Bilal},
  doi          = {10.1016/j.matdes.2025.114652},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114652},
  shortjournal = {Mater. Des.},
  title        = {Ultra-lightweight multi-functional gyroid-based metamaterial for simultaneous sound insulation, vibration suppression, and impact mitigation in all directions},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="mla">MLA - 15</h2>
<ul>
<li><details>
<summary>
(2025). Evaluating the impact of model scale and prompting strategies on corruption allegation classification using thai-specialized typhoon2 language models. <em>MLA</em>, <em>22</em>, 100743. (<a href='https://doi.org/10.1016/j.mlwa.2025.100743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corruption complaint classification is a critical yet resource-intensive task in public sector governance, particularly in low-resource linguistic environments. This study assesses the capacity of Thai-specialized large language models (LLMs) from the Typhoon2 family to automate the classification of corruption complaints submitted to Thailand’s National Anti-Corruption Commission (NACC). Three variants—Typhoon2–3B (base), Typhoon2–3B (fine-tuned), and Typhoon2–7B (base)—were evaluated under zero-shot, one-shot, and two-shot prompting strategies and benchmarked against strong traditional machine learning models (Random Forest, XGBoost) trained on TF-IDF features. Results reaffirm the competitiveness of tree-based classifiers, which delivered consistently high and stable performance. Among the LLMs, the Typhoon2–7B model with two-shot prompting achieved the most balanced performance (Macro F1 = 0.514), highlighting emergent few-shot reasoning capabilities and improved handling of class imbalance. By contrast, fine-tuning the smaller 3B model induced severe overfitting and significant degradation on minority classes. These outcomes emphasize that model scale and prompt design are more reliable drivers of performance than direct fine-tuning in small, imbalanced settings. The study contributes practical guidance for deploying scalable and ethically aligned AI in governance, demonstrating that while traditional models remain robust benchmarks, large-scale prompted LLMs represent a promising complement for future public sector innovation.},
  archive      = {J_MLA},
  author       = {Patipan Sriphon and Pattrawut Khunwipusit and Bamisaye Mayowa Emmanuel and Issara Sereewatthanawut},
  doi          = {10.1016/j.mlwa.2025.100743},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100743},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Evaluating the impact of model scale and prompting strategies on corruption allegation classification using thai-specialized typhoon2 language models},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance evaluation of complex-valued neural networks on real and complex-valued classification and reconstruction tasks. <em>MLA</em>, <em>22</em>, 100742. (<a href='https://doi.org/10.1016/j.mlwa.2025.100742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex-Valued Neural Networks (CVNNs) are reported to be more efficient in different applications than Real-Valued Neural Networks (RVNNs) in many papers. In this study, we aim to characterize the cases when it holds true in order to assist the selection of proper tools for two specific tasks: classification and reconstruction. Among the various ways to compare CVNNs and RVNNs, we apply the one based on the number of parameters of the respective Neural Networks (NNs), assuming that a complex parameter is composed of two real ones. The performed experimentation revealed many surprising differences in the performance of CVNNs and RVNNs compared to the ones discussed in the preceding literature. This drives us to the general conclusion that the performance of RVNNs is similar or better than the performance of CVNNs in the majority of the cases, and the seldom cases when CVNNs achieve better performance are hard to characterize.},
  archive      = {J_MLA},
  author       = {Mahmood K.M. Almansoori and Miklos Telek},
  doi          = {10.1016/j.mlwa.2025.100742},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100742},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Performance evaluation of complex-valued neural networks on real and complex-valued classification and reconstruction tasks},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting political voting: A high dimensional machine learning approach. <em>MLA</em>, <em>22</em>, 100739. (<a href='https://doi.org/10.1016/j.mlwa.2025.100739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel machine learning approach to predict voting patterns in Brazil’s Chamber of Deputies. Using a high-dimensional dataset and a time-series methodology, our models aim to accurately forecast legislative decisions. Unlike prior studies that often focus on single ideological dimensions, our approach integrates a broad feature set, including party guidelines, proposition characteristics, and deputy voting history, to improve predictive power. We train time-series models for each legislature, comparing ensembles like Random Forests and Gradient Boosting, which are validated using three-fold chronological splits to ensure temporal integrity. Our analysis highlights the significant influence of party guidelines and pork-barrel politics on voting behavior. Additionally, we identify key predictors, including the theme and source of the legislative proposition, as well as the deputies’ voting history. This work demonstrates the feasibility of accurately forecasting legislative votes, offering a valuable tool for stakeholders to anticipate legislative outcomes and enhancing the transparency of the political process.},
  archive      = {J_MLA},
  author       = {Pedro Caiua Campelo Albuquerque and Daniel Oliveira Cajueiro},
  doi          = {10.1016/j.mlwa.2025.100739},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100739},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Forecasting political voting: A high dimensional machine learning approach},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing IDS performance through a comparative analysis of random forest, XGBoost, and deep neural networks. <em>MLA</em>, <em>22</em>, 100738. (<a href='https://doi.org/10.1016/j.mlwa.2025.100738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion Detection Systems (IDS) face major challenges in network security, notably the need to combine a high detection rate with reliable performance. This reliability is often affected by class imbalances and inadequate hyperparameter optimization. This article addresses the issue of improving the detection rate of IDS by evaluating and comparing three machine learning algorithms: Random Forest (RF), XGBoost, and Deep Neural Networks (DNN), using the NSL-KDD dataset. In our methodology, we integrate SMOTE (Synthetic Minority Oversampling Technique) to tackle the unbalanced nature of the data, ensuring a more balanced representation of the different classes. This approach helps optimize model performance, reduce bias, and enhance robustness. Additionally, hyperparameter optimization is performed using Optuna, ensuring that each algorithm operates at its optimal level. The results show that our model, using the Random Forest algorithm, achieves an accuracy of 99.80%, surpassing the performance of XGBoost and Deep Neural Networks (DNN). This makes our approach a true asset for intrusion detection methods in computer networks.},
  archive      = {J_MLA},
  author       = {Sow Thierno Hamidou and Adda Mehdi},
  doi          = {10.1016/j.mlwa.2025.100738},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100738},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Enhancing IDS performance through a comparative analysis of random forest, XGBoost, and deep neural networks},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source plume tracing via multi-agent reinforcement learning under common UAV-faults. <em>MLA</em>, <em>22</em>, 100737. (<a href='https://doi.org/10.1016/j.mlwa.2025.100737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazardous airborne gas releases from accidents, leaks, or wildfires require rapid localization of emission sources under uncertain and turbulent conditions. Traditional gradient-based or biologically inspired strategies struggle in multi-source environments where odor cues are intermittent, aliased, and partially observed. We address this challenge by formulating multi-source plume tracing in three-dimensional fields as a cooperative partially observable Markov game. To solve it, we introduce an Action-Specific Double Deep Recurrent Q-Network (ADDRQN) that conditions on action–observation pairs to improve latent-state inference, and integrates teammate information through a permutation-invariant set encoder. Training follows a randomized centralized-training and decentralized-execution regime with host randomization, team-size variation, and noise injection. This yields a policy that is robust to agent failures (hardware malfunction, battery depletion, etc.), resilient to intermittent communication blackouts, and tolerant of sensor noise. Empirical evaluation in simulated Gaussian plume environments shows that ADDRQN achieves higher success rates and shorter localization times than non-action baselines, maintains strong performance under mid-mission disruptions, and scales predictably with team size.},
  archive      = {J_MLA},
  author       = {Pedro Antonio Alarcon Granadeno and Theodore Chambers and Jane Cleland-Huang},
  doi          = {10.1016/j.mlwa.2025.100737},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100737},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Multi-source plume tracing via multi-agent reinforcement learning under common UAV-faults},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure-aware stable diffusion for traditional architectural decoration design. <em>MLA</em>, <em>22</em>, 100735. (<a href='https://doi.org/10.1016/j.mlwa.2025.100735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent generation of traditional architectural styles faces significant challenges in structural integrity and style consistency. While existing methods can generate numerous realistic images, they lack a deep understanding of structural elements in traditional architectural decorative design. This paper proposes a Structure-aware Stable Diffusion (SSD) model, which enhances the model's comprehension of architectural features through three key innovations. First, we design a structure-aware feature injection module that adaptively fuses extracted architectural structural information with original features during the U-net upsampling phase, enhancing the model's understanding of geometric structures. Second, we introduce a dual-path text enhancement strategy that combines structural descriptions with original descriptions to provide richer textual guidance signals for the generation process. Finally, we design a progressive injection strategy that dynamically controls the injection intensity of structural information through cosine scheduling, ultimately achieving effective internalization of structural knowledge. Experimental results show that compared to existing methods, our model effectively improves both the diversity of generated traditional architectural decorations and the rationality of their structures, thus providing an effective new technical approach for traditional architectural decorative design.},
  archive      = {J_MLA},
  author       = {Jianhong Yang and Guoyong Wang},
  doi          = {10.1016/j.mlwa.2025.100735},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100735},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Structure-aware stable diffusion for traditional architectural decoration design},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines. <em>MLA</em>, <em>22</em>, 100734. (<a href='https://doi.org/10.1016/j.mlwa.2025.100734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer experience is crucial in the airline industry, as understanding passenger satisfaction helps airlines improve service quality. This study evaluates hyperparameter optimization and feature interpretability in machine learning models for predicting airline passenger satisfaction. Support Vector Machine (SVM) and Multilayer Perceptron (MLP) models were tested for binary classification, labeling passengers as ‘Satisfied’ or ‘Neutral or Dissatisfied’ using a Kaggle dataset with ∼104,000 training and ∼26,000 test records. Hyperparameter tuning used grid search with 10-fold cross-validation. For SVM, the optimal setup included the RBF kernel, C = 10, and gamma = ‘auto’, achieving a mean score of 0.9606. For MLP, the best configuration used no regularization, "he" initialization, ReLU activation, 30 epochs, batch size of 32, two hidden layers with 32 neurons each, and a learning rate of 0.001, yielding a mean score of 0.9556. Performance metrics included accuracy, precision, recall, and F1-Score, with SVM achieving a test accuracy of 0.96, precision of 0.97, and F1-Score of 0.95, slightly outperforming MLP by <1 %, though MLP was faster at 0.3 s versus SVM’s 18 s. Both models surpassed baseline models and prior studies, benefiting from robust preprocessing and a large dataset. Permutation importance analysis identified Type of Travel, Inflight Wi-Fi Service, Customer Type, and Online Boarding as key predictors, emphasizing passenger needs for digital connectivity and personalized services. These insights guide airlines to prioritize reliable Wi-Fi and efficient online boarding to enhance satisfaction, loyalty, and competitive positioning.},
  archive      = {J_MLA},
  author       = {Hamid Mirzahossein and Soheil Rezashoar},
  doi          = {10.1016/j.mlwa.2025.100734},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100734},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation. <em>MLA</em>, <em>22</em>, 100733. (<a href='https://doi.org/10.1016/j.mlwa.2025.100733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validating performance is a key challenge facing the adoption of machine learning models in high risk applications. Current validation methods assess performance marginally over the entire testing dataset, which can fail to identify regions in the distribution with insufficient performance. In this paper, we propose Conformal Validation, a systems-based approach with a calibrated form of uncertainty quantification using a conformal prediction framework as a part of the validation process to reduce performance gaps. Specifically, the policy defers a subset of observations for which the predictive model is most uncertain and provides a human with informative prediction sets to make the ancillary decision. We evaluate this policy on an image classification task where images are distorted with varying levels of gaussian blur for a quantifiable measure of added difficulty. The model is compared to human performance on the most difficult observations, i.e., those where the model is most uncertain, to simulate the scenario when a human is the alternative decision-maker. We evaluate performance on three arms: the model independently, humans with access to a set of classes the model is most confident in, and humans independently. The deferral policy is simple to understand, applicable to any predictive model, and easy to implement while, in this case, keeping humans in the loop for improved trustworthiness. Conformal Validation incorporates a risk assessment that is conditioned on the prediction set length and can be tuned to the needs of the application.},
  archive      = {J_MLA},
  author       = {Paul Horton and Alexandru Florea and Brandon Stringfield},
  doi          = {10.1016/j.mlwa.2025.100733},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100733},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining style and semantics for robust authorship verification. <em>MLA</em>, <em>22</em>, 100732. (<a href='https://doi.org/10.1016/j.mlwa.2025.100732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Authorship Verification is a key task in Natural Language Processing, essential for applications like plagiarism detection and content authentication. This paper analyzes the use of deep learning models for Authorship Verification, focusing on combining semantic and style features to enhance model performance. We propose three models: the Feature Interaction Network, Pairwise Concatenation Network, and Siamese Network, which aim to determine if two texts are written by the same author. Each model uses RoBERTa embeddings to capture semantic content and incorporates style features such as sentence length, word frequency, and punctuation to differentiate authors based on writing style. Our results confirm that incorporating style features consistently improves model performance, with the extent of improvement varying by architecture. This demonstrates the value of combining semantic and stylistic information for Authorship Verification. While limitations such as RoBERTa’s fixed input length and the use of predefined style features exist, they do not hinder model effectiveness and point to clear opportunities for future enhancement through extended input handling and dynamic style feature extraction. In contrast to prior studies such as Bevendorff et al., (2020) and Kestemont, et al., (2022), which relied on balanced and homogeneous datasets with consistent topics and well-formed language, our work evaluates models on a more challenging, imbalanced, and stylistically diverse dataset, better reflecting real-world Authorship Verification conditions. Despite the increased difficulty, our models achieve competitive results, underscoring their robustness and practical applicability. These findings support the value of combining semantic and style features for real-world Authorship Verification.},
  archive      = {J_MLA},
  author       = {Britt van Leeuwen and Sandjai Bhulai and Rob van der Mei},
  doi          = {10.1016/j.mlwa.2025.100732},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100732},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Combining style and semantics for robust authorship verification},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of machine learning technologies in construction maintenance: A strategic analysis. <em>MLA</em>, <em>22</em>, 100731. (<a href='https://doi.org/10.1016/j.mlwa.2025.100731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current predictive maintenance systems in construction rely on static machine learning approaches that fail to adapt to evolving operational environments, achieving only 3%–7% performance improvements over individual models and suffering 15%–25% performance degradation when transferred across domains. This research develops and validates an Adaptive Ensemble Framework that dynamically optimizes algorithm selection through real-time data assessment and performance feedback. The framework’s meta-learning architecture continuously adapts ensemble weights using data complexity measures, temporal pattern analysis, and uncertainty quantification metrics. Unlike static approaches, the system integrates scikit-learn and TensorFlow models through dynamic optimization algorithms that respond to changing conditions without manual reconfiguration. The framework provides uncertainty-aware predictions with confidence intervals essential for safety-critical construction decisions. Comprehensive evaluation across four industries using 50,000+ maintenance records from major construction firms demonstrates substantial improvements. The adaptive ensemble achieves F1-score of 0.934 in construction delay prediction, representing 15.3% improvement over individual models and 8.7% enhancement over static ensembles. Cross-industry validation reveals successful knowledge transfer with minimal performance degradation ( < 5%). This research contributes three scholarly advances: (i) the first real-time adaptive ensemble framework eliminating manual hyperparameter tuning, (ii) uncertainty quantification mechanisms for safety-critical applications, and (iii) robust cross-industry transferability through systematic domain adaptation. The framework extends beyond construction to manufacturing, energy, and transportation sectors, demonstrating computational efficiency with sub-100ms latency and linear scaling characteristics. These contributions establish new benchmarks for adaptive machine learning in industrial predictive maintenance.},
  archive      = {J_MLA},
  author       = {Assane Lo and Aysha Alshehhi},
  doi          = {10.1016/j.mlwa.2025.100731},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100731},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Implementation of machine learning technologies in construction maintenance: A strategic analysis},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating deep learning and econometrics for stock price prediction: A comprehensive comparison of LSTM, transformers, and traditional time series models. <em>MLA</em>, <em>22</em>, 100730. (<a href='https://doi.org/10.1016/j.mlwa.2025.100730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive empirical comparison between state-of-the-art deep learning models including Long Short-Term Memory (LSTM) networks, Transformer architectures, and traditional econometric models (ARIMA and VAR) for stock price prediction, with particular focus on performance during the COVID-19 pandemic crisis. Using daily S&P 500 data from 2015 to 2020, we rigorously evaluate model performance across multiple metrics including Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). Our findings demonstrate that while Transformer models achieve the best overall performance with an RMSE of 41.87 and directional accuracy of 69.1 %, LSTM networks provide an optimal balance between performance (RMSE: 43.25) and computational efficiency. Both deep learning approaches significantly outperform traditional econometric methods, with LSTM achieving a 53.3 % reduction in RMSE compared to ARIMA models. During the COVID-19 crisis period, deep learning models demonstrated exceptional robustness, with Transformers showing only 45 % performance degradation compared to over 100 % degradation in traditional models. Through comprehensive attention analysis, we provide insights into model interpretability, revealing adaptive behavior across market regimes. The study contributes to the growing literature on artificial intelligence applications in finance by providing rigorous empirical evidence for the superiority of modern deep learning approaches, while addressing the critical need for comparison with cutting-edge Transformer architectures that have revolutionized machine learning in recent years.},
  archive      = {J_MLA},
  author       = {Eyas Gaffar A. Osman and Faisal A. Otaibi},
  doi          = {10.1016/j.mlwa.2025.100730},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100730},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Integrating deep learning and econometrics for stock price prediction: A comprehensive comparison of LSTM, transformers, and traditional time series models},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning based li-ion cell state prediction using impedance spectroscopy. <em>MLA</em>, <em>22</em>, 100729. (<a href='https://doi.org/10.1016/j.mlwa.2025.100729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable monitoring of battery state parameters is crucial for ensuring optimal battery performance, safety, and lifetime. Existing methods have limitations, such as requiring modeling of each degradation mechanism involved or relying on direct measurement techniques that impose restrictions on field studies or end-user use. In this paper, we propose a machine learning-based approach that combines the strengths of electrochemical impedance spectroscopy (EIS) and machine learning algorithms to predict battery state parameters. We have developed an efficient prediction system that can learn from EIS data and accurately predict battery state parameters. Our approach is trained on an open dataset comprising of over 30,000 spectra, generated using an automated measurement technique that outperforms current machine learning-based models, particularly in terms of generalization across different cells and measurement setups.},
  archive      = {J_MLA},
  author       = {Carl Philipp Klemm and Till Frömling},
  doi          = {10.1016/j.mlwa.2025.100729},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100729},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine-learning based li-ion cell state prediction using impedance spectroscopy},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auxiliary evaluation of marginal ridge discrepancy in periodontal disease using deep learning on periapical radiographs. <em>MLA</em>, <em>22</em>, 100727. (<a href='https://doi.org/10.1016/j.mlwa.2025.100727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background/Objectives : Marginal Ridge Discrepancy (MRD) is an important early indicator of periodontal disease, often resulting from tooth inclination or alveolar bone loss, leading to uneven interproximal ridge height. Although periapical radiographs commonly observe bone and root structures, image overlap and angle variation often hinder accurate clinical interpretation. This study proposes a deep learning-based system integrating image segmentation and angular evaluation to assist dentists in objectively classifying MRD severity and improving diagnostic efficiency. Methods : We adopted a Mask R-CNN model with ResNet-101 as the backbone, incorporating warm-up and learning rate scheduling strategies to ensure stable convergence. Moreover, Mask R-CNN localized the cemento-enamel junction and alveolar crest by overlapping the mask image. We also introduced a novel angular measurement method to quantify the MRD between adjacent ridges and categorize periodontal disease severity. Results : ResNet-101 achieved the best segmentation performance among tested backbones with 98.11 % pixel-wise accuracy. Recall scores reached 97.60 % for teeth, 97.24 % for crowns, and 97.53 % for bone structures. The MRD classification model achieved 93.41 % accuracy with a mean angular error of only 0.85°, demonstrating strong clinical reliability. Conclusions : The proposed method effectively addresses challenges in evaluating ridge loss on periapical radiographs. Providing accurate and objective assessment enhances early periodontal diagnosis, reduces clinical workload, and supports improved medical quality and treatment planning.},
  archive      = {J_MLA},
  author       = {Yuan-Jin Lin and Chiung-An Chen and Yi-Cheng Mao and Chin-Hao Liang and Tsung-Yi Chen and Kuo-Chen Li and Shih-Lun Chen and Wei-Chen Tu},
  doi          = {10.1016/j.mlwa.2025.100727},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100727},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Auxiliary evaluation of marginal ridge discrepancy in periodontal disease using deep learning on periapical radiographs},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the cost of equity for insurance companies in the world: Evidence from machine learning approaches. <em>MLA</em>, <em>22</em>, 100726. (<a href='https://doi.org/10.1016/j.mlwa.2025.100726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the determinants of the WACC for insurance firms, integrating both financial and non-financial factors through advanced machine learning techniques. Analyzing data from 2012 to 2022 for a large sample of 190 insurance companies in the world, we compare nine ML models, revealing that XGBoost and LightGBM outperform traditional methods. Key drivers of WACC include beta, dividend yield, and earnings per share, with Emission score also showing significant influence. This study fills gaps in insurance finance literature by introducing ML-based WACC modeling, enhancing predictive accuracy, and providing policy recommendations for regulatory reporting and Emission score disclosures. From a policy perspective, the global insurance sector is at a crucial turning point, where ESG integration in granular form is found to be vital for financial stability. By mandating standardized ESG disclosures in alignment with the ISSB and TCFD frameworks, regulators can reduce insurers’ cost of equity, enabling a balance between financial sustainability and environmental responsibility, while promoting long-term value creation for both investors and society.},
  archive      = {J_MLA},
  author       = {Indranarain Ramlall and Dineshwar Ramdhony},
  doi          = {10.1016/j.mlwa.2025.100726},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100726},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Exploring the cost of equity for insurance companies in the world: Evidence from machine learning approaches},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets. <em>MLA</em>, <em>22</em>, 100712. (<a href='https://doi.org/10.1016/j.mlwa.2025.100712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistic regression is a simple yet widely used classification model in spectroscopic profiling analysis. Considering the model’s output represents a probability, this paper will investigate its latent distribution assumption, i.e., its inner linear regressor unit follows a standard logistic distribution. An empirical study on five spectroscopic profiling open datasets, i.e., wine, coffee, olive oil, cheese, and milk powder, was conducted to verify this latent distribution assertion. This paper measured the GoF (Goodness of Fit) of each dataset’s latent variable from three aspects, i.e., curve fitting, P–P and Q–Q plots, and K–S test. After hyper-parameter optimization and proper training, the latent variable, as a weighted sum of the original features, has demonstrated a high level of GoF on all the five datasets. This study verifies the suitability of logistic regression in spectroscopic profiling analysis and answers why the model output can be interpreted as a conditional probability.},
  archive      = {J_MLA},
  author       = {Yinsheng Zhang and Mingming He and Haiyan Wang},
  doi          = {10.1016/j.mlwa.2025.100712},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100712},
  shortjournal = {Mach. Learn. Appl.},
  title        = {On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="neucom">NEUCOM - 81</h2>
<ul>
<li><details>
<summary>
(2025). Joint entropy search for multi-objective bayesian optimization with constraints and multiple fidelities. <em>NEUCOM</em>, <em>657</em>, 131674. (<a href='https://doi.org/10.1016/j.neucom.2025.131674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) methods can be used to solve efficiently problems with several objectives and constraints. Each objective and constraint is considered a black-box function that is expensive to evaluate, lacking a closed-form expression. BO methods use a model of each black-box to guide the search for the problem’s solution. Specifically, they make intelligent decisions about where each black-box function should be evaluated next with the goal of finding the solution using a few evaluations only. Sometimes, however, the black-boxes may be evaluated at different fidelity levels. A lower fidelity is simply a cheap proxy for the corresponding black-box. These lower fidelities correlate with the actual black-boxes to optimize and can, therefore, be used to reduce the overall cost of solving the optimization problem. Here, we propose Multi-fidelity Joint Entropy Search for Multi-objective Bayesian Optimization with Constraints (MF-JESMOC), a BO method for solving the aforementioned problems. MF-JESMOC chooses the next point, and fidelity level at which to evaluate the black-boxes, as the combination that is expected to reduce the most the joint entropy of the Pareto set and the Pareto front, normalized by the fidelity’s evaluation cost. We use Deep Gaussian processes to model each black-box and the dependencies between fidelities. These are powerful probabilistic models that can learn the dependency structure among fidelity levels of each black-box. Several experiments show that MF-JESMOC outperforms other state-of-the-art methods for multi-objective BO with constraints and different fidelity levels in both synthetic and real-world problems.},
  archive      = {J_NEUCOM},
  author       = {Daniel Fernández-Sánchez and Daniel Hernández-Lobato},
  doi          = {10.1016/j.neucom.2025.131674},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131674},
  shortjournal = {Neurocomputing},
  title        = {Joint entropy search for multi-objective bayesian optimization with constraints and multiple fidelities},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COTA-motion: Controllable image-to-video synthesis with dense semantic trajectories. <em>NEUCOM</em>, <em>657</em>, 131671. (<a href='https://doi.org/10.1016/j.neucom.2025.131671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion transfer, which aims to animate an object in a static image by transferring motion from a reference video, remains a fundamental yet challenging task in content creation. While recent diffusion-based image-to-video models offer fine-grained control over visual appearance, most existing methods rely on ambiguous text prompts or coarse drag-based motion cues, making it difficult to achieve accurate and consistent motion synthesis. To address these limitations, we propose COTA-Motion, a general framework for controllable image-to-video motion transfer. Our method leverages a dense trajectory-based semantic representation extracted from the driving video to provide explicit motion guidance. Specifically, we segment the salient object and extract its point-wise trajectories across frames. These trajectories are enriched with semantic embeddings and reprojected into a spatial-temporal tensor, forming the motion embedding. To utilize this motion representation, we introduce the COTA Adapter, which integrates image content with semantic trajectories via cross-attention, enabling accurate and flexible control over the generated motion. At inference, we further incorporate an alignment module to address discrepancies between the input image and motion cues, ensuring spatial consistency. Built upon a pre-trained video diffusion model, COTA-Motion only requires lightweight fine-tuning on a small set of videos, and it enables high-quality, controllable motion transfer from video to image. Extensive experiments demonstrate the effectiveness of our approach in generating visually coherent and motion-aligned video outputs.},
  archive      = {J_NEUCOM},
  author       = {Yirui Chen and Wenqing Chu and Ye Wu and Jie Yang and Xiaonan Mao and Wei Liu},
  doi          = {10.1016/j.neucom.2025.131671},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131671},
  shortjournal = {Neurocomputing},
  title        = {COTA-motion: Controllable image-to-video synthesis with dense semantic trajectories},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance-barrier-based event-triggered leader–follower consensus control for nonlinear multi-agent systems. <em>NEUCOM</em>, <em>657</em>, 131664. (<a href='https://doi.org/10.1016/j.neucom.2025.131664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the leader–follower consensus issue for a class of nonlinear multi-agent systems (MASs) by putting forth a novel performance-barrier-based event-triggered control mechanism. First, a leader–follower consensus control law is proposed with a derived stability condition for the MASs, and a performance-barrier-based event-triggering mechanism is integrated to reduce control updates while guaranteeing the desired convergence of the Lyapunov function. Subsequently, the presence of the minimum inter-event time (MIET) is analytically established, reinforcing the practical feasibility of the proposed approach in real-world scenarios. In addition, a dynamic average consensus algorithm is incorporated to extend the strategy to distributed MASs. Finally, simulation results verify that the developed control protocol effectively achieves the prescribed convergence performance with strong robustness.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Shun-Yan Ren and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131664},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131664},
  shortjournal = {Neurocomputing},
  title        = {Performance-barrier-based event-triggered leader–follower consensus control for nonlinear multi-agent systems},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Both reliable and unreliable predictions matter: Domain adaptation for bearing fault diagnosis without source data. <em>NEUCOM</em>, <em>657</em>, 131661. (<a href='https://doi.org/10.1016/j.neucom.2025.131661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing fault diagnosis is crucial for maintaining the reliability and safety of industrial systems. Recently, it has attracted increasing attention to transferring a diagnosis model from the source domain to the target domain without source data in real-world diagnosis scenarios due to confidentiality and efficiency concerns. However, existing approaches are sub-optimal as they simply exploit confidently pseudo-labeled target samples, and simultaneously overlook the intrinsic structural characteristics of the feature space. Besides, the reliability of fault pseudo-labels is always estimated with entropy, whose accuracy could be improved through more sophisticated strategies. To address these issues, we propose to explore the correlation between features and pseudo-labels in the target domain to maintain the balance between feature discriminability and feature diversity. In addition, we develop a voting-based strategy associated with data augmentation for more accurate reliability estimation of fault pseudo-labels. The proposed method is able to utilize both the reliable samples and unreliable samples for diagnosis model transfer via self-supervised training and distribution structure discovering respectively. Extensive experiments on two bearing fault benchmarks demonstrate the effectiveness and superiority of our proposed method. The source code is publicly available at: https://github.com/BdLab405/SDALR .},
  archive      = {J_NEUCOM},
  author       = {Wenyi Wu and Hao Zhang and Zhisen Wei and Xiao-Yuan Jing and Qinghua Zhang and Songsong Wu},
  doi          = {10.1016/j.neucom.2025.131661},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131661},
  shortjournal = {Neurocomputing},
  title        = {Both reliable and unreliable predictions matter: Domain adaptation for bearing fault diagnosis without source data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neuromorphic binocular framework fusing directional and depth motion cues towards precise collision prediction. <em>NEUCOM</em>, <em>657</em>, 131660. (<a href='https://doi.org/10.1016/j.neucom.2025.131660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological studies have significantly advanced our understanding of collision detection, driving improvements in visual systems for safer navigation of mobile intelligent machines. Directionally selective neurons (DSNs), extensively studied in insects like locusts and flies, have inspired computational models that effectively detect specific directional motion cues with low computational demands, making them suitable for real-time applications. Despite these advancements, there remains a gap between biological systems and current computational models. Typically, monocular computational approaches project the three-dimensional world onto two-dimensional representations, resulting in the loss of critical depth information essential for accurately detecting looming objects, i.e., those directly approaching the observer. Consequently, such methods often suffer interference from background motion distractors and nearby translating objects. To address these limitations, we developed a binocular visual framework integrating neuromorphic components, including directionally selective neural networks and depth-disparity computing pathway. This binocular approach enhances looming detection accuracy and improves collision prediction capabilities. Additionally, evolutionary learning techniques were employed to optimize network structures and parameters, prioritizing robustness across diverse real-world scenarios. The resulting binocular model selectively responds to imminent collision trajectories while effectively suppressing peripheral distractors such as near-miss and passing movements. We conducted comprehensive evaluations comparing our proposed framework against a latest binocular neural model across various complex scenarios. Systematic ablation studies further validated the effectiveness and robustness of our approach. The results confirm its potential for deployment in mobile robots and autonomous vehicles, assisting their collision avoidance in real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Chuankai Fang and Haoting Zhou and Renyuan Liu and Qinbing Fu},
  doi          = {10.1016/j.neucom.2025.131660},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131660},
  shortjournal = {Neurocomputing},
  title        = {A neuromorphic binocular framework fusing directional and depth motion cues towards precise collision prediction},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic prediction based on spatio-temporal feature embedding fusion and gate operation optimization. <em>NEUCOM</em>, <em>657</em>, 131658. (<a href='https://doi.org/10.1016/j.neucom.2025.131658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world traffic prediction problems, there are often complex spatio-temporal features and patterns. To enhance the accuracy and performance of traffic prediction and address these complexities, it is essential to employ effective models and methods to capture spatio-temporal features and patterns of change. For this purpose, we propose a network model that integrates spatio-temporal feature embeddings with gate operation optimization(TSGO). In our model, we design a novel module: the spatio-temporal feature embedding fusion module, which combines input data to strengthen the model’s ability to extract spatio-temporal correlation features, particularly in enhancing temporal features. To further bolster the capture of spatial features, we design an adaptive graph structure learning method based on a node repository, dynamically capturing non-Euclidean spatial correlations within the traffic network. Additionally, to better capture long-term dependence and short-term variations in sequential data, we adopt a new strategy in the Gated Recurrent Unit (GRU): treating the even and odd positions in the input sequence as two separate input streams to generate corresponding update gates and reset gates. This approach enables the model to utilize data more evenly, achieving complementarity between the two sets of features and allowing it to adapt to information at different time scales within the sequential data. In short-term, medium-term, and long-term predictions across three real-world traffic datasets, the TSGO model achieved average MAE reductions of 8.76 %, 10.12 %, and 11.86 %, respectively, compared to the baseline. This demonstrates its capability to generalize across different time scales and significantly improve prediction performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Geng and Fan Zhang and Mingli Zhang and Hua Wang},
  doi          = {10.1016/j.neucom.2025.131658},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131658},
  shortjournal = {Neurocomputing},
  title        = {Traffic prediction based on spatio-temporal feature embedding fusion and gate operation optimization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional plane-based multi-scene representation for novel view synthesis. <em>NEUCOM</em>, <em>657</em>, 131657. (<a href='https://doi.org/10.1016/j.neucom.2025.131657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing explicit and implicit-explicit hybrid neural representations for novel view synthesis are scene-specific. In other words, they represent only a single scene and require retraining for every novel scene. Implicit scene-agnostic methods rely on large multilayer perception (MLP) networks conditioned on learned features. They are computationally expensive during training and rendering times. In contrast, we propose a novel plane-based representation that learns to represent multiple static and dynamic scenes during training and renders per-scene novel views during inference. The method consists of a deformation network, explicit feature planes, and a conditional decoder. Explicit feature planes are used to represent a time-stamped view space volume and a shared canonical volume across multiple scenes. The deformation network learns the deformations across shared canonical object space and time-stamped view space. The conditional decoder estimates the color and density of each scene constrained by a scene-specific latent code. We evaluated and compared the performance of the proposed representation on static (NeRF) and dynamic (Plenoptic videos) datasets. The results show that explicit planes combined with tiny MLPs can efficiently train multiple scenes simultaneously. The project page: https://anonpubcv.github.io/cplanes/ .},
  archive      = {J_NEUCOM},
  author       = {Uchitha Rajapaksha and Hamid Laga and Dean Diepeveen and Mohammed Bennamoun and Ferdous Sohel},
  doi          = {10.1016/j.neucom.2025.131657},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131657},
  shortjournal = {Neurocomputing},
  title        = {Conditional plane-based multi-scene representation for novel view synthesis},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of neural signal decoding based on domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131653. (<a href='https://doi.org/10.1016/j.neucom.2025.131653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important objective in brain-computer interfaces (BCIs) is to develop robust and reliable neural signal decoders. However, the decoders will encounter challenges under cross-subject or cross-session conditions due to the randomness, non-stationarity, and individual variability of brain electrical activity. Reducing distributional differences is an exceptionally intuitive way to eliminate inter-subject/session differences and enhance decoder generalizability. In this context, domain adaptation (DA) emerges as a valuable technique, enabling the rapid transfer of knowledge acquired from large datasets with labeled data to new subjects or sessions. This paper provides a comprehensive survey of DA research in neural decoding from 2014 to the present. We categorize neural decoding methods related to DA by considering instance-based, feature-based, and model-based, which is motivated by three fundamental challenges in DA: How can one effectively select suitable source domains or samples for transfer? How can inter-domain distributional differences be minimized through feature space transformation? And how can decoder parameters be optimally shared? Additionally, several decoding methods that combine deep learning with DA are highlighted, given the significant advantages of deep learning over traditional feature extraction techniques. Furthermore, our paper explores the application of DA in complex scenarios, such as multiple source domains and low-resource settings. In summary, we have reviewed domain-adaptive decoding algorithms and their application considerations, while identifying various challenges that need to be addressed in future research.},
  archive      = {J_NEUCOM},
  author       = {Suchen Li and Zhuo Tang and Mengmeng Li and Lifang Yang and Zhigang Shang},
  doi          = {10.1016/j.neucom.2025.131653},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131653},
  shortjournal = {Neurocomputing},
  title        = {A survey of neural signal decoding based on domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An 80/20 cortical balance stabilizes information-rich dynamics. <em>NEUCOM</em>, <em>657</em>, 131651. (<a href='https://doi.org/10.1016/j.neucom.2025.131651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cortex maintains a remarkably consistent 4:1 ratio between excitatory and inhibitory neurons, yet the computational advantages of such an architecture remain poorly understood. Here, we demonstrate that this ratio optimally stabilizes a dynamical regime characterized by intermittent, burst-like activity, a state associated with maximal information capacity. Using a balanced spiking network model, we show that near the 80:20 ratio, this intermittent regime emerges robustly across a wide range of parameters and with low energy cost. These findings suggest that the canonical cortical E/I ratio is not arbitrary, but that it is functionally tuned to support efficient and flexible computation. Our results provide a dynamical explanation for a long-standing anatomical observation, bridging structural organization and information processing in neural circuits.},
  archive      = {J_NEUCOM},
  author       = {Mozhgan Khanjanianpak and Maryam Pakpour and Matjaž Perc and Alireza Valizadeh},
  doi          = {10.1016/j.neucom.2025.131651},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131651},
  shortjournal = {Neurocomputing},
  title        = {An 80/20 cortical balance stabilizes information-rich dynamics},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on generalization of random weight network with flat loss. <em>NEUCOM</em>, <em>657</em>, 131650. (<a href='https://doi.org/10.1016/j.neucom.2025.131650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the scheme of learning which adjusts model parameters by minimizing a loss function, there is a conjecture that the loss function with flatter minimum may correlate with better stability and generalization of the model. This paper provides experimental evidence within the Random Weight Network (RWN)/Extreme Learning Machine (ELM) framework and further develops a theoretical analysis linking flatness to the local generalization error upper bound by deriving the RWN loss as a quadratic polynomial with respect to random weights and representing the flatness as the maximum eigenvalue of a semi-positive definite matrix. By adjusting the random weights using a genetic algorithm, where the fitness function is defined as the flatness, we validate on 10 benchmark datasets within the ELM framework that flatter loss indeed improves the model’s generalization ability. The improvement size depends on the specific characteristics of datasets, particularly, on the relative decrease of maximum eigenvalues. This study shows that RWN generalization performance can be improved by optimizing random weight selection.},
  archive      = {J_NEUCOM},
  author       = {Chao Liu and Qiang Liu and Rihao Li and Xinlei Zhou and Mustafa Servet Kiran and Xizhao Wang},
  doi          = {10.1016/j.neucom.2025.131650},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131650},
  shortjournal = {Neurocomputing},
  title        = {A study on generalization of random weight network with flat loss},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view least squares support vector classifiers with the principles of complementarity and consensus. <em>NEUCOM</em>, <em>657</em>, 131647. (<a href='https://doi.org/10.1016/j.neucom.2025.131647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the multi-view learning framework, which adheres to the principles of complementarity and consensus. Despite significant advances in various support vector machine (SVM)-based multi-view learning methods, many focus exclusively on one of these principles. To bridge this gap, we first introduce the multi-view least squares support vector classifier (MvLSSVC-2C), which effectively minimizes the squares of the differences in decision functions across diverse views while also integrating information from multiple views through a coupling term. Furthermore, we propose a structural information-based model, termed SMvLSSVC-2C, which leverages hierarchical agglomerative clustering to enhance information exchange among views, thereby promoting complementarity and consensus. Meanwhile, by incorporating a weight allocation strategy, adaptive learning is conducted, and the importance of each view is adjusted to adhere to the principle of complementarity. We adopt the alternating optimization method to solve it. The two proposed methods exhibit superior performance, which is demonstrated by theoretical and numerical analysis. Our experimental results demonstrate the effectiveness of the proposed models on diverse datasets, highlighting their enhanced performance in multi-view learning tasks.},
  archive      = {J_NEUCOM},
  author       = {Siyuan Zhang and Qianfei Liu and Mengyang Fan and Weisong Mu and Jianying Feng},
  doi          = {10.1016/j.neucom.2025.131647},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131647},
  shortjournal = {Neurocomputing},
  title        = {Multi-view least squares support vector classifiers with the principles of complementarity and consensus},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KING: An efficient optimization approach. <em>NEUCOM</em>, <em>657</em>, 131645. (<a href='https://doi.org/10.1016/j.neucom.2025.131645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world engineering optimization problems are often highly challenging due to narrow feasible regions, numerous local optima, and intricate constraints. Metaheuristic algorithms (MAs) have shown promise in addressing these issues owing to their global search capability, flexibility, and adaptability. However, a critical challenge with MAs is effectively balancing the global search (exploration) and local search (exploitation) phases, which significantly influences the efficiency and precision of convergence. Many MAs require problem-specific adjustments to control convergence behavior, thereby increasing computational cost and implementation effort. Moreover, existing improvements are often tailored to specific problems, lacking comprehensive validation in terms of generality, robustness, and scalability. To overcome these limitations, this paper proposes a novel high-performance optimization algorithm with enhanced adaptability, named the Three Kingdoms Optimization Algorithm (KING), inspired by historical dynamics of the Three Kingdoms period in China. We establish an analogy between key components of MAs—such as population initialization, exploration, and exploitation—and four historical phases: the ascent of the might, joint confrontation, three-legged tripod, and whole country united. KING incorporates a new reinforcement convergence mechanism to systematically guide the search process while maintaining an effective balance between exploration and exploitation, enabling rapid and efficient convergence. Additionally, a dynamic, tolerance-based constraint-handling technique is introduced to strengthen its capability in solving complex constrained problems. The performance of KING is extensively evaluated on the IEEE CEC 2017 and IEEE CEC 2022 benchmark test suites, comparing it with classical algorithms, high-performance variants, and state-of-the-art methods across problems of varying scales. Experimental results demonstrate that KING outperforms the compared algorithms in convergence speed, solution accuracy, and stability. Its superiority is further validated through applications to four real-world engineering problems. The proposed algorithm proves to be an effective and reliable tool for engineering optimization. Its source code will be made publicly available at https://aliasgharheidari.com/KING.html and other websites.},
  archive      = {J_NEUCOM},
  author       = {Dong Zhao and Zhen Wang and Yupeng Li and Ali Asghar Heidari and Zongda Wu and Yi Chen and Huiling Chen},
  doi          = {10.1016/j.neucom.2025.131645},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131645},
  shortjournal = {Neurocomputing},
  title        = {KING: An efficient optimization approach},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sensitivity-propagated dual-frequency graph neural network for multivariate time series forecasting. <em>NEUCOM</em>, <em>657</em>, 131644. (<a href='https://doi.org/10.1016/j.neucom.2025.131644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have become one of the mainstream frameworks in multivariate time series (MTS) forecasting due to their powerful spatio-temporal dependency modeling capability. The process of extracting spatio-temporal features can be summarized into three stages: graph generation, graph convolution, and node updating. However, existing works recognize that the quality of the generated graph significantly impacts model performance, while overlooking that effective node updating can produce richer series representations. Furthermore, existing GNNs exhibit a pronounced bias toward capturing low-frequency temporal patterns, with inadequate attention to high-frequency components. Therefore, we propose SensGCN, a novel dynamic graph spatio-temporal network by introducing the concept of series sensitivity features to optimize the node updating process. Built upon a graph convolutional Gated Recurrent Unit (GRU) framework, SensGCN derives sensitivity features from series volatility patterns under non-autocorrelation conditions. These features subsequently guide node updating after aggregating external series information through graph convolution. Additionally, a novel dynamic graph estimation method is developed that extracts high-frequency components via series decomposition to jointly model time-varying spatial dependencies in MTS data, thereby enhancing GNNs’ capability in learning high-frequency features. Extensive evaluations across five public datasets show that our SensGCN achieves competitive or state-of-the-art performance in both multi-step and single-step forecasting tasks. Notably, in multi-step forecasting with a predefined graph structure, SensGCN achieves the best performance in four out of six cases and consistently attains the lowest MAE, outperforming the best baselines by up to approximately 1.3 %.},
  archive      = {J_NEUCOM},
  author       = {Yaling Xun and Shuo Han and Jianghui Cai and Haifeng Yang and Jifu Zhang},
  doi          = {10.1016/j.neucom.2025.131644},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131644},
  shortjournal = {Neurocomputing},
  title        = {Sensitivity-propagated dual-frequency graph neural network for multivariate time series forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining and interpreting hyperdimensional computing classifiers on tabular data. <em>NEUCOM</em>, <em>657</em>, 131643. (<a href='https://doi.org/10.1016/j.neucom.2025.131643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the rise in the usage of artificial intelligence models and machine learning approaches in our day-to-day lives, it has become increasingly important to explain these models to increase user trust. Hyperdimensional Computing (HDC) has been introduced as a powerful, energy-efficient algorithmic framework that is intrinsically less opaque than (deep) neural networks. Nevertheless, the possibility of explaining and interpreting the HDC-based classification model has not yet been explored explicitly. Therefore, this work proposes an explanation method and an interpretation method for the HDC-based classification model working with tabular data. The proposed methods have been successfully evaluated on three tabular data sets with a diverse number of samples, features, and classes. Their faithfulness is validated with coherence checks, the deletion and insertion metrics, and a feature ablation study. The results of the proposed explanation method align well with the well-studied LIME explanations.},
  archive      = {J_NEUCOM},
  author       = {Laura Smets and Werner Van Leekwijck and Steven Latré and José Oramas},
  doi          = {10.1016/j.neucom.2025.131643},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131643},
  shortjournal = {Neurocomputing},
  title        = {Explaining and interpreting hyperdimensional computing classifiers on tabular data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The generative adversarial network combined with noise guidance and global features generates high quality defect samples. <em>NEUCOM</em>, <em>657</em>, 131639. (<a href='https://doi.org/10.1016/j.neucom.2025.131639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous improvement of industrial production intelligence and automation, surface defect detection has become a critical aspect of industrial quality control. However, due to the significantly reduced frequency of surface defects, obtaining sufficient defect data becomes extremely difficult, which limits the performance of deep learning models. To address this challenge, we propose a generative adversarial network (GAN) with noise guidance and global information to generate high-quality defect sample images, thereby enhancing strip detection accuracy. First, the Patch method is used to divide images into blocks, and the feature context of real samples is captured through encoded information. This allows the learning of the potential spatial distribution of real samples, guiding the generator toward directional learning. Second, an adaptive simulated annealing attenuation algorithm is designed to find the global optimal solution of the training process by constraining the minimum temperature stability. Third, a denoising module is introduced to generate high-quality samples by leveraging deep multi-scale feature extraction and residual structures. Experimental results show that, compared to existing advanced models, the proposed method performs well in terms of structural similarity (SSIM) and peak signal-to-noise ratio (PSNR). The method is evaluated on two industrial small sample datasets (GC10-DET and NEU-DET), where it demonstrates particularly strong performance in generating normal images. Furthermore, the generated images are added to the training set as augmented data, improving the performance of three advanced target detection models. Overall, this research offers an effective solution for small sample defect detection in industrial scenarios and holds significant application potential.},
  archive      = {J_NEUCOM},
  author       = {Meishun Wu and Jinmin Peng and Xinyi Yu and Liulu Zhang and Chaoqi Jiang and Wenkai Dong and Liangshen Chen},
  doi          = {10.1016/j.neucom.2025.131639},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131639},
  shortjournal = {Neurocomputing},
  title        = {The generative adversarial network combined with noise guidance and global features generates high quality defect samples},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing continual semantic segmentation with visual explanations and model adaptations. <em>NEUCOM</em>, <em>657</em>, 131637. (<a href='https://doi.org/10.1016/j.neucom.2025.131637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Semantic Segmentation (CSS) faces challenges such as catastrophic forgetting, background shift, and limited interpretability, which hinder its real-world deployment. Existing approaches mainly rely on knowledge distillation mechanisms and adaptive pseudo-labeling but struggle with efficiency and generalization. To address these gaps, we propose a novel framework that enhances segmentation accuracy while reducing computational overhead. Our contributions include the use of replay mechanisms with augmented pseudo labels that leverage the unknown class to tackle background shift and mitigate forgetting, as well as the use of modified Atrous Spatial Pyramid Pooling (ASPP) blocks to improve feature extraction without increasing the number of parameters. Additionally, we integrate a visual model explanation loss to enhance interpretability and trust in segmentation decisions. Experimental results on the PASCAL VOC and Cityscapes datasets show that our approach outperforms prior CSS methods by more than 10 % in mIoU score while significantly reducing model size, making it more suitable for real-world applications such as autonomous driving. Further validation in the CARLA simulator demonstrates its feasibility for deployment. The source code is available at https://github.com/daoducmanh194/RRR-CISS .},
  archive      = {J_NEUCOM},
  author       = {Manh Dao and Tuan Linh Dang},
  doi          = {10.1016/j.neucom.2025.131637},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131637},
  shortjournal = {Neurocomputing},
  title        = {Enhancing continual semantic segmentation with visual explanations and model adaptations},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label webpage text classification based on feature segmentation and attention mechanism. <em>NEUCOM</em>, <em>657</em>, 131635. (<a href='https://doi.org/10.1016/j.neucom.2025.131635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the natural distribution differences of webpage content, multi-label webpage text datasets suffer from the long-tailed label problem. Moreover, the length of multi-label webpage text varies, making it difficult for sequence based deep learning models to set the sequence length. In order to solve the above problems, a feature self segmentation strategy is proposed in this paper, which executes different segmentation strategies for webpage texts of different lengths based on the sequence length of the deep learning model, so as to preserve long webpage texts without introducing too much noisy data for short webpage texts. In addition, by calculating the attention of adjacent segments, calculating the attention of labels and different segments, and constructing the co-attention networks, not only can important content in the document be highlighted, but also content related to labels can be highlighted, which can effectively extract features associated with low-frequency labels and solve the long-tailed label problem. The comparative experimental results on the manually annotated Energy Website Multi-Label Webpage Text dataset and three benchmark multi-label text classification datasets demonstrate that the method constructed in this paper outperforms all baseline methods. The main codes are available at https://github.com/sgysgywaityou/MLWT-FSAM/tree/main/MLWT-FSAM .},
  archive      = {J_NEUCOM},
  author       = {Yanan Cheng and Wenling Li and Zhichao Zhang and Hao Chen and Zhaoxin Zhang},
  doi          = {10.1016/j.neucom.2025.131635},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131635},
  shortjournal = {Neurocomputing},
  title        = {Multi-label webpage text classification based on feature segmentation and attention mechanism},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering via only new upward distance on sub-cluster shared neighbors space without setting cluster centers manually. <em>NEUCOM</em>, <em>657</em>, 131634. (<a href='https://doi.org/10.1016/j.neucom.2025.131634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) algorithm is widely applied in data analysis field due to its efficiency and simplicity. However, most improvements to DPC depend on human experience and prior knowledge to identify cluster centers, leading to subjective and inaccurate results. Existing non-prior DPC methods select cluster centers based on the maximum value of the product between local density and upward distance, which ignores the cluster centers of tiny or sparse clusters and identifies the noise and outlier points as cluster centers, resulting in misclassification. In order to address these challenges and provide an accurate method for defining the cluster centers, we propose a DPC algorithm that automatically determines the cluster centers using only new upward distance (NUD) within the sub-cluster shared neighbors space (SSNS). First, sub-clusters are constructed by defining neighbor density and shared neighbor distance. Next, the distance between sub-cluster centers based on shared neighbors is utilized to build the SSNS, reflecting the interconnected nature of sub-clusters. Then, we redefine the upward distance based on SSNS and automatically select cluster centers according to the maximum value of NUD. Furthermore, adaptive threshold filter is applied to adjust parameters and mitigate the effects of noise and outlier points. Finally, sub-clusters are merged based on SSNS similarity, which significantly enhances computational efficiency. Experimental results on synthetic and real datasets show that NUD-SSNS DPC outperforms state-of-the-art methods, achieving improvements of 28 % and 63 % in Fowlkes–Mallows index (FMI) and adjusted rand index (ARI), respectively, while offering computational speed advantage for large-size datasets.},
  archive      = {J_NEUCOM},
  author       = {Jinglong Wang and Jintao Tao and Yu Zhang and Changju Liu and Jiangtao Xu},
  doi          = {10.1016/j.neucom.2025.131634},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131634},
  shortjournal = {Neurocomputing},
  title        = {Density peak clustering via only new upward distance on sub-cluster shared neighbors space without setting cluster centers manually},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid neural network adaptive fuzzy sliding mode online compensatory control for robots with global stability. <em>NEUCOM</em>, <em>657</em>, 131632. (<a href='https://doi.org/10.1016/j.neucom.2025.131632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to parameter variations, joint friction, and external disturbances, nonlinear robot system models may suffer from modeling inaccuracies or parameter identification difficulties. In addition, traditional control methods make it difficult to estimate the uncertainty of the system model accurately, and the uncertainty of the internal model parameters of the system will also seriously affect the tracking control accuracy of the robot. To solve the above problems, this paper proposes a hybrid neural network adaptive fuzzy sliding mode online compensation control method for robots with global stability. The technique uses an RBF neural network to estimate the uncertainty and dynamically compensates for it by introducing it into an adaptive fuzzy sliding mode controller. Compared to the traditional approximation network, the method ensures the stability of the global consistent final boundedness of the system signals. Also, it achieves the convergence of the neural network weights to the ideal values. To effectively suppress the system jitter, this paper proposes a scheme based on the combination of hyperbolic tangent function sliding mode and fuzzy control. The focus of this paper is on the simulation verification of the proposed control method. The simulation experiment results verify the effectiveness of the proposed method. The accuracy of the integral squared error of the technique in the presence of internal uncertainty and maximum friction moment disturbance is 3.24e-5 rad, which greatly improves the dynamic tracking performance of the robot.},
  archive      = {J_NEUCOM},
  author       = {Guocheng Xiao and Bei Liu and Yufeng Li and Haibin Yin},
  doi          = {10.1016/j.neucom.2025.131632},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131632},
  shortjournal = {Neurocomputing},
  title        = {Hybrid neural network adaptive fuzzy sliding mode online compensatory control for robots with global stability},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grade: Generative graph contrastive learning for multimodal recommendation. <em>NEUCOM</em>, <em>657</em>, 131630. (<a href='https://doi.org/10.1016/j.neucom.2025.131630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommender systems based on graph convolutional networks have made significant progress by integrating multiple modal data for item recommendation. While most existing approaches learn user and item representations through modality-related interaction graphs, these approaches still encounter challenges inherent to graph convolutional networks: over-smoothing. To address this challenge, we propose a model named Grade, G enerative G r aph Contr a stive Learning for Multimo d al R e commendations. It combines generative models and contrastive learning and design four task losses. In particular, the generative graph contrastive task generates contrastive views inter-modal through variational graph reconstruction, effectively aligning modal features to improve user and item representations. In addition, the feature perturbation contrastive task generates multimodal noisy views with interference for intra-modal contrast through noise-based self-supervised learning, effectively enhancing the robustness of modality-specific representations. Finally, we incorporate the Variational Graph Autoencoders (VGAE) task and the Bayesian Personalized Ranking (BPR) task. The combination of these four task losses effectively mitigates the issues of over-smoothing. Extensive experiments conducted on three publicly available datasets confirm the superiority of our model. The related code is available on https://github.com/Ricardo-Ping/Grade .},
  archive      = {J_NEUCOM},
  author       = {Yu-Chao Ping and Shu-Qin Wang and Zi-Yi Yang and Yong-Quan Dong and Meng-Xiang Hu and Pei-Lin Zhang},
  doi          = {10.1016/j.neucom.2025.131630},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131630},
  shortjournal = {Neurocomputing},
  title        = {Grade: Generative graph contrastive learning for multimodal recommendation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GDViT: Group-level decorrelation-based vision transformer for domain generalization. <em>NEUCOM</em>, <em>657</em>, 131624. (<a href='https://doi.org/10.1016/j.neucom.2025.131624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality-inspired domain generalization aims to improve model generalization by removing correlations between relevant and irrelevant features. However, a key challenge lies in effectively distinguishing the two. Existing methods, lacking explicit feature grouping, often eliminate all feature correlations indiscriminately, which disrupts the internal structure of relevant features and degrades generalization performance. In this work, we propose a group-level decorrelation-based vision Transformer that explicitly separates features (tokens) into relevant and irrelevant groups. This design preserves the internal correlations within relevant features while removing the correlations between the two groups. To achieve this, we introduce a feature grouping module that guides the separation process, followed by a grouping Transformer encoder that performs inter-group decorrelation, enabling the model to focus more on task-relevant information. Additionally, a supervised contrastive loss is employed to further enhance generalization. Extensive experiments demonstrate that our method significantly improves out-of-distribution performance. Visual analysis further shows that our model suppresses attention to irrelevant features, mitigating spurious correlations and resulting in more stable predictions. Our approach achieves strong performance in both multi-source and single-source domain generalization settings.},
  archive      = {J_NEUCOM},
  author       = {Wenqiang Tang and Zhouwang Yang and Yanzhi Song},
  doi          = {10.1016/j.neucom.2025.131624},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131624},
  shortjournal = {Neurocomputing},
  title        = {GDViT: Group-level decorrelation-based vision transformer for domain generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design. <em>NEUCOM</em>, <em>657</em>, 131623. (<a href='https://doi.org/10.1016/j.neucom.2025.131623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of distributed generalized Nash equilibrium (GNE) seeking in aggregative games, it is challenging yet interesting to design fast GNE seeking algorithms using energy-efficient communication strategy. However, most existing distributed GNE seeking algorithms can only achieve asymptotic convergence under continuous-time communication setting, resulting in a slower convergence rate and greater consumption of communication resources. In this paper, by exploiting two time-varying gain feedback functions, we present a new kind of distributed GNE seeking algorithm by integrating predefined-time control law with event-triggered communication strategy. It is theoretically shown that the proposed algorithm can solve the predefined-time GNE seeking problem for aggregative games with Zeno behavior being avoided during the seeking process. Compared with the existing algorithms, the present one exhibits several salient features: 1) the convergence time can be preset according to task requirements; 2) the communication resources can be significantly saved by the event-triggered mechanism; and 3) the proposed algorithms exhibit simplicity in their structures and possess the advantage of easy implementability.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Guo and Lingwei Zeng and Jinlei Cheng and Pengwen Xiong and Qian Li},
  doi          = {10.1016/j.neucom.2025.131623},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131623},
  shortjournal = {Neurocomputing},
  title        = {Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FACET–VLM: Facial emotion learning with text-guided multiview fusion via vision-language model for 3D/4D facial expression recognition. <em>NEUCOM</em>, <em>657</em>, 131621. (<a href='https://doi.org/10.1016/j.neucom.2025.131621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) in 3D and 4D domains presents a significant challenge in affective computing due to the complexity of spatial and temporal facial dynamics. Its success is crucial for advancing applications in human behavior understanding, healthcare monitoring, and human-computer interaction. In this work, we propose FACET–VLM, a vision–language framework for 3D/4D FER that integrates multiview facial representation learning with semantic guidance from natural language prompts. FACET–VLM introduces three key components: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion, Multiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions, and a multiview consistency loss to enforce structural coherence across views. Our model achieves state-of-the-art accuracy across multiple benchmarks, including BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extend FACET–VLM to 4D micro-expression recognition (MER) on the 4DME dataset, demonstrating strong performance in capturing subtle, short-lived emotional cues. FACET–VLM achieves up to 99.41 % accuracy on BU-4DFE and outperforms prior methods by margins as high as 15.12 % in cross-dataset evaluation on BP4D. The extensive experimental results confirm the effectiveness and substantial contributions of each individual component within the framework. Overall, FACET–VLM offers a robust, extensible, and high-performing solution for multimodal FER in both posed and spontaneous settings.},
  archive      = {J_NEUCOM},
  author       = {Muzammil Behzad},
  doi          = {10.1016/j.neucom.2025.131621},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131621},
  shortjournal = {Neurocomputing},
  title        = {FACET–VLM: Facial emotion learning with text-guided multiview fusion via vision-language model for 3D/4D facial expression recognition},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection. <em>NEUCOM</em>, <em>657</em>, 131620. (<a href='https://doi.org/10.1016/j.neucom.2025.131620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke lesion detection in brain MRI remains challenging as existing deep learning methods process single modalities and ignore anatomical boundaries, limiting clinical adoption. We develop a graph-based framework that integrates neuroanatomical priors and multi-modal imaging for automated stroke lesion detection. Our approach uses anatomically-constrained supervoxel generation and graph attention networks with probabilistic attention attribution for interpretable lesion detection. Evaluated on the SOOP dataset (1715 subjects including 1461 stroke patients), our method achieves a Dice coefficient, sensitivity, and ROC-AUC of 0.85 ± 0.03, 0.88, and 0.94, respectively, outperforming CNN baselines by 15 %. The framework provides clinically meaningful attention maps and accurate automated stroke analysis.},
  archive      = {J_NEUCOM},
  author       = {Luis R. Mercado-Diaz and Derek Aguiar and Hugo F. Posada-Quintero},
  doi          = {10.1016/j.neucom.2025.131620},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131620},
  shortjournal = {Neurocomputing},
  title        = {Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios. <em>NEUCOM</em>, <em>657</em>, 131619. (<a href='https://doi.org/10.1016/j.neucom.2025.131619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated significant potential in addressing decision-making problems in the field of autonomous driving due to their strong reasoning capabilities. However, deploying LLMs in real-world driving scenarios often encounters challenges such as high computational requirements, elevated costs, and increased latency. On the other hand, Deep Reinforcement Learning (DRL) exhibits strong adaptability to decision-making tasks in autonomous driving with a relatively smaller parameter scale. Nevertheless, DRL agents often suffer from low exploration efficiency and high sensitivity to parameter variations. To address the above issues, we propose an LLM-Enhanced Autonomous Driving (LEAD) training framework, which integrates a high-level agent based on LLMs into the training process of DRL models, effectively improving the policy learning efficiency and generalization capability of DRL models. During the early stage of training, a dynamic intervention mechanism is introduced to identify key decision points within the DRL model, and a predefined expert guidance algorithm is utilized to integrate high-level decision strategies from LLMs into these critical nodes. During the later stage of training, the DRL model transitions into an autonomous optimization phase, where the agent, enhanced with LLM priors, continuously interacts with the environment to further refine the policy network, ultimately surpassing the performance of the LLM-based agent. Experimental results demonstrate that the LEAD-PPO model, built upon the proposed framework, reduces collision rates by 49.49 % and 59.4 % in low-density and high-density scenarios, respectively, during training compared to the baseline model. In the testing phase, the DRL model optimized through LEAD achieves task completion rates that are 9.60 %, 35.94 %, and 65.63 % higher than those of the baseline model in simple, moderate, and difficult scenarios, respectively. Overall, the proposed LEAD framework significantly improves the robustness, sample efficiency, and generalization ability of DRL models.},
  archive      = {J_NEUCOM},
  author       = {Dongwei Xu and Enwen Qiao and Tongcheng Gu and Hongda Fu and Chengju Sun and Haifeng Guo and Yuqing Liu},
  doi          = {10.1016/j.neucom.2025.131619},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131619},
  shortjournal = {Neurocomputing},
  title        = {LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms. <em>NEUCOM</em>, <em>657</em>, 131618. (<a href='https://doi.org/10.1016/j.neucom.2025.131618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively handle the synchronization of reaction–diffusion fuzzy memristive neural networks (MNNs) and shorten their synchronization time has become a worthwhile and meaningful issue to study. This paper mainly studies fixed-time synchronization (FXTS) and preassigned-time synchronization (PATS) problems for delayed fuzzy memristive neural networks (DFMNNs) with reaction–diffusion terms. First, a DFMNNs model with reaction–diffusion terms is introduced, which can effectively describe the spatial distribution characteristics of the network. Second, through the Lyapunov stability theory, the FXTS criterion and the upper limit of the settling-time (ST) are obtained. Subsequently, a state feedback controller is proposed to ensure that the system achieves synchronization within a specified time, and the synchronization time is independent of initial conditions and control parameters, which gives the designed controller a wider range of applications. Finally, two examples are presented to illustrate the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Hanrui Chen and Dongbing Tong and Qiaoyu Chen},
  doi          = {10.1016/j.neucom.2025.131618},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131618},
  shortjournal = {Neurocomputing},
  title        = {Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond sparsity: An empirical study of structured collaboration in modular AI. <em>NEUCOM</em>, <em>657</em>, 131616. (<a href='https://doi.org/10.1016/j.neucom.2025.131616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mixture-of-Experts (MoE) architectures, the prevailing paradigm emphasizes sparse expert activation for computational efficiency. This paper explores an alternative architectural approach centered on structured collaboration, hypothesizing that the quality and nature of inter-module interactions are as significant as computational cost. We present a series of targeted proof-of-concept experiments to validate three distinct principles of structured interaction, inspired by cognitive science. First, we demonstrate that a hierarchical fusion mechanism, modeled on the brain's segregated visual pathways, enhances compositional reasoning on the VQA v2.0 benchmark. Second, by employing a redesigned reinforcement learning task in MiniGrid, we demonstrate that a system-wide differentiated credit assignment (SDCA) mechanism, with conflict detection learned end-to-end, facilitates more robust policy learning. Third, we ascertain that integrating reasoning "tools" as co-adaptive modules offers superior out-of-distribution robustness on the DROP dataset compared to a more powerful baseline agent utilizing external LLM-based tools. Our work provides concrete validation for these principles, highlighting a series of trade-offs between performance, robustness, and efficiency, and suggesting that prioritizing cognitive synergy over simple sparsity offers a promising direction for future research in modular AI.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Zhou and Soohong Kim and Yiru Wang and Kailin Zhang},
  doi          = {10.1016/j.neucom.2025.131616},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131616},
  shortjournal = {Neurocomputing},
  title        = {Beyond sparsity: An empirical study of structured collaboration in modular AI},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes. <em>NEUCOM</em>, <em>657</em>, 131614. (<a href='https://doi.org/10.1016/j.neucom.2025.131614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key nodes in complex networks play a crucial role in maintaining the stability, functionality, and robustness of networked systems. Accordingly, the accurate identification of such nodes is of fundamental importance. Their significance spans multiple domains, including communication systems, transportation infrastructures, life sciences, and social networks. Existing algorithms for key node identification typically rely on heuristic measures or standard deep reinforcement learning frameworks. However, these approaches often suffer from limited feature extraction capabilities, high computational complexity, and insufficient generalizability, and a lack of dynamic adaptability. To overcome these limitations, this study proposes a novel architecture, GTRP (Graph Transformer-Driven Reinforcement Learning Based on Popularity). GTRP extends Epidemic-aware Heterogeneous Graph Transformer (GT) by introducing distinct attention mechanisms for both nodes and edges, enabling the integration of local structural features and global propagation properties. In addition, GTRP incorporates Dual-dynamics Reward Optimization (DR) to identify key nodes based on a network disintegration strategy. The model is trained on randomly generated Barabási–Albert (BA) networks and evaluated on synthetic networks of varying scales as well as multiple real-world network scenarios. Comparative experiments with six representative algorithms demonstrate that GTRP achieves substantial performance improvements—outperforming existing methods by 6.30 % in unweighted networks and 15.90 % in weighted networks. These results underscore the potential of GTRP to advance key node detection in complex network analysis.},
  archive      = {J_NEUCOM},
  author       = {Kaili Wang and Muqing Wu and Min Zhao},
  doi          = {10.1016/j.neucom.2025.131614},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131614},
  shortjournal = {Neurocomputing},
  title        = {A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CCINet: A cascaded consensus interaction network for co-saliency object detection. <em>NEUCOM</em>, <em>657</em>, 131613. (<a href='https://doi.org/10.1016/j.neucom.2025.131613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-saliency object detection imitates human attention behavior, with the aim of identifying common salient objects in a set of related images. Previous approaches generally suffer from a lack of interaction among the extracted co-saliency information. As a result, the detection maps often turn out to be incomplete or redundant. In this paper, we propose a Cascaded Consensus Interaction Network (CCINet) for co-saliency object detection. This network improves the fusion and interaction among features, thus making full use of the co-saliency information. In the encoding stage, we introduce an Edge Semantic Consensus (ESC) module. It effectively integrates low-level and high-level encoding information. In this way, it is able to capture both fine edge details and rich semantics. Meanwhile, the ESC module refines the co-saliency features, which enhances the detection of co-saliency regions. During the up-sampling stage, the Cascaded Contextual Aggregation (CCA) module employs attention mechanisms, adaptive pooling, and separated-dilated convolution for comprehensive feature extraction. This approach effectively reduces background noise and controls the number of parameters. Extensive experiments indicate that our model outperforms many excellent CoSOD methods in recent years on the three most popular benchmark datasets. Source code is available at: https://github.com/JoeLAL24/CCINet.git .},
  archive      = {J_NEUCOM},
  author       = {Longsheng Wei and Xu Pei and Jiu Huang and Fan Xu},
  doi          = {10.1016/j.neucom.2025.131613},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131613},
  shortjournal = {Neurocomputing},
  title        = {CCINet: A cascaded consensus interaction network for co-saliency object detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-core-guided adaptive learning and policy optimization for targeted influence maximization in complex networks. <em>NEUCOM</em>, <em>657</em>, 131612. (<a href='https://doi.org/10.1016/j.neucom.2025.131612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing information propagation in complex networks is essential for shaping public discourse, optimizing marketing strategies, and driving social change. Traditional influence maximization approaches often emphasize network topology, neglecting the critical need to align strategies with user semantics to influence specific user groups effectively. To address this issue, we introduce the Targeted Core-based Q-learning framework (TCQ), a hybrid optimization approach that draws inspiration from evolutionary network structures derived from K-core decomposition, tailored to tackle the problem of targeted influence maximization (TIM). TCQ integrates semantic insights (e.g., interests, demographics, or topical categories) with the network structure by combining a target-based probabilistic scoring function with K-core evolutionary hierarchies, enabling the efficient identification of key influential candidates within the network. Leveraging reinforcement learning, TCQ dynamically optimizes its seed selection policy through a process of exploration and exploitation in order to minimize influence overlap among selected seeds while maintaining adaptability across diverse network scenarios. Extensive experiments on real-world and synthetic networks demonstrate that TCQ not only maximizes targeted influence effectively but also achieves computational efficiency, showcasing its potential for optimizing influence propagation in complex networks.},
  archive      = {J_NEUCOM},
  author       = {Waseem Ahmad and Bang Wang},
  doi          = {10.1016/j.neucom.2025.131612},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131612},
  shortjournal = {Neurocomputing},
  title        = {K-core-guided adaptive learning and policy optimization for targeted influence maximization in complex networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter. <em>NEUCOM</em>, <em>657</em>, 131611. (<a href='https://doi.org/10.1016/j.neucom.2025.131611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostics and Health Management (PHM) is critical for industrial equipment maintenance, whose core task is to predict the Remaining Useful Life (RUL) of a system or component accurately. However, traditional deep learning-based approaches often demand significant computational and memory resources, limiting their feasibility for edge deployment. As an effective model compression technique, Knowledge Distillation (KD) has emerged as a core strategy for enabling edge intelligence by transferring knowledge from a teacher model to a lightweight student model. However, traditional KD methods exhibit a high dependency on the teacher model's output. This dependency limits the student model's capacity for autonomous error correction, impairing its distillation performance. To solve these problems, this paper proposes a novel Classification and Error Correction Knowledge Distillation (CEKD) framework. The framework employs Gaussian kernel-based feature entropy to dynamically evaluate teacher models' predictive capabilities, facilitating comprehensive assessment and sample differentiation. Furthermore, the knowledge self-reflection learning strategy extends error correction to continuous dynamic adjustment, enabling deep optimization of complex data. Experimental results on the air turbine starter bearing datasets show that CEKD surpasses KD methods by improving MAE and RMSE by 79.8 % and 78.6 % on average, while reducing memory consumption and inference time by nearly 10 × and 8 × , respectively, enabling deployment on resource-constrained devices.},
  archive      = {J_NEUCOM},
  author       = {Runxia Guo and Jingxu Yi and Xianfeng Luo},
  doi          = {10.1016/j.neucom.2025.131611},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131611},
  shortjournal = {Neurocomputing},
  title        = {An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power-law-based preassigned-time bipartite output consensus for heterogeneous multi-agent systems under event-triggered control. <em>NEUCOM</em>, <em>657</em>, 131610. (<a href='https://doi.org/10.1016/j.neucom.2025.131610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the preassigned-time (PST) bipartite output consensus problem for heterogeneous multi-agent systems (HMASs) using distributed dynamic event-triggered control (DETC). Firstly, based on PST stability lemma, a simpler PST dynamic compensator is developed to attain a novel consensus criterion, which does not require the satisfaction of the Hurwitz stability condition. Subsequently, to reduce the computational burden and the influence of control parameters, through the dynamic compensator, a novel PST control strategy with distributed dynamic event-triggered control is proposed. This control scheme not only removes the limitations of traditional control in terms of infinite control gain but also ensures error dynamics approach zero within preset time. Furthermore, the paper excludes Zeno behavior through a proof by contradiction. Finally, a numerical example is provided to demonstrate the practicality of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Wanli Jin and Huaguang Zhang and Yapeng Yang and Juan Zhang},
  doi          = {10.1016/j.neucom.2025.131610},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131610},
  shortjournal = {Neurocomputing},
  title        = {Power-law-based preassigned-time bipartite output consensus for heterogeneous multi-agent systems under event-triggered control},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay. <em>NEUCOM</em>, <em>657</em>, 131609. (<a href='https://doi.org/10.1016/j.neucom.2025.131609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the finite-time lag consensus (FTLC) and finite-time H ∞ lag consensus (FTHLC) problems for first-order multi-agent systems (MASs) are studied. On the one hand, a new state feedback controller considering the communication delay between agents is proposed. Besides, based on several inequality scaling techniques and finite-time stability theory, a sufficient criterion is derived to guarantee the FTLC of MASs. On the other hand, an adaptive state feedback controller and the corresponding adaptive law are put forward, which can also help MASs realize lag consensus in finite time without any additional conditions. Moreover, to address inevitable external disturbances in practice, the proposed control strategies are further enhanced to achieve FTHLC, which further expands the application range of the research results. Finally, the effectiveness of these provided FTLC and FTHLC control schemes in different scenarios is manifested through some numerical simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Kun Ling and Shun-Yan Ren and Ming-Zhu Wei and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131609},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131609},
  shortjournal = {Neurocomputing},
  title        = {Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks. <em>NEUCOM</em>, <em>657</em>, 131608. (<a href='https://doi.org/10.1016/j.neucom.2025.131608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the computation of generalized Nash equilibrium in aggregative games with coupling constraints over time-varying networks. The player’s cost objective comprises a differentiable function dependent on the aggregate of all players’ decisions and a possibly non-smooth term with a linear mapping. In this context, designing solution methods for such game formulation is relatively scarce. We thus develop a fully distributed equilibrium-seeking algorithm that accommodates time-varying communication networks while circumventing the need for global decision information. The proposed algorithm synergistically embeds dynamic tracking of aggregate decisions through a consensus-based mechanism with projected pseudo-gradient updates, augmented by a proximal splitting scheme to handle non-smooth components. Theoretically, we establish convergence guarantees to the variational equilibrium through a new operator splitting framework. Finally, numerical experiments are conducted to substantiate the validity of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Liang Ran and Huaqing Li and Zheng Wang and Lifeng Zheng and Jun Li and Zhe Li},
  doi          = {10.1016/j.neucom.2025.131608},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131608},
  shortjournal = {Neurocomputing},
  title        = {Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking spatial textures: Gradient-guided pansharpening for enhancing multispectral imagery. <em>NEUCOM</em>, <em>657</em>, 131607. (<a href='https://doi.org/10.1016/j.neucom.2025.131607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pansharpening aims to integrate the high spatial resolution of panchromatic images (PAN) with the spectral richness of multispectral images (MSI), producing high-resolution multispectral outputs. While deep learning-based approaches have achieved remarkable performance in pansharpening, most methods primarily focus on developing advanced model architectures, often overlooking the potential of manually crafted features. Unlike previous works where gradient information has been primarily utilized in model-based optimization methods, we demonstrate that gradient features derived from the gradient magnitude can provide complementary information that guides the fusion process of PAN and MSI, significantly enhancing pansharpening performance. Specifically, we propose a gradient-guided pansharpening network, termed GGPNet, which consists of two branches: a guidance feature extraction branch that captures gradient features from the gradient magnitude, and a gradient-guided fusion branch that integrates the PAN and MSI with the additional information from gradient features. Within the fusion branch, a multi-image cross-attention block is designed to facilitate the gradual integration of features from images with varying spectral bands and resolutions. Moreover, a gradient loss is introduced to guarantee the effectiveness of the extracted gradient feature information, which is then combined with the widely-used spectral image loss. Extensive experiments on the GaoFen-2 (GF2), QuickBird (QB), and WorldView-3 (WV3) datasets validate the efficacy of our approach, demonstrating its superiority over state-of-the-art methods with substantial improvements in PSNR, ERGAS, and other commonly adopted metrics. The source code will be made publicly available at: https://github.com/sevenzero70/GGPNet_code .},
  archive      = {J_NEUCOM},
  author       = {Lanyue Liang and Tianyu Li and Guoqing Wang and Lin Mei and Xiongxin Tang and Chaofan Qiao and Dongyu Xie},
  doi          = {10.1016/j.neucom.2025.131607},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131607},
  shortjournal = {Neurocomputing},
  title        = {Unlocking spatial textures: Gradient-guided pansharpening for enhancing multispectral imagery},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling. <em>NEUCOM</em>, <em>657</em>, 131604. (<a href='https://doi.org/10.1016/j.neucom.2025.131604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the synchronization control for multi-weighted complex networks (MWCNs) with unknown disturbances and aperiodic intermittent coupling. Firstly, an adaptive neural network strategy is used to approximate the unknown components derived from nonlinear function, while a novel continuous function is proposed by utilizing the idea of time-varying boundary layer technique to deal with the influence of approximation errors. Secondly, different from the continuous coupling and periodic intermittent coupling mechanisms in existing works, an aperiodic intermittent coupling mechanism is taken into consideration in MWCNs. Thirdly, to synchronize MWCNs under aperiodic intermittent coupling, adaptive strategies are developed to adjust coupling strengths and coupling gains based on all edges and partial edges, respectively. Note that these two strategies are fully distributed, i.e., they do not require any global information. Finally, some numerical simulations are provided to verify the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhang and Dan Liu and Binrui Wang and Kaibo Shi},
  doi          = {10.1016/j.neucom.2025.131604},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131604},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective framework with hybrid augmentation for visual reinforcement learning generalization. <em>NEUCOM</em>, <em>657</em>, 131602. (<a href='https://doi.org/10.1016/j.neucom.2025.131602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current studies in Visual Reinforcement Learning focus on developing policies to acclimate to unknown environments through data augmentation. This paper aims to develop a new methodology to improve upon existing results. To this end, we first categorize existing methods into three groups based on the focus of augmentation: Task-Aware Augmentation, Image-Processing Augmentation, and Image-Scene Augmentation. Subsequently, we establish a unified framework that integrates these three augmentation categories. The core of our framework is hybrid data augmentation, which enhances data diversity. In this framework, we employ hyperspherical space and regularization techniques to address the side effects of such augmentation, specifically the discrepancy between augmented and original data, as well as the instability associated with hybrid augmentation. Finally, we evaluate the proposed framework across three benchmarks, demonstrating its significant advantages over current state-of-the-art methods. Notably, our framework outperforms existing approaches by an average of 4.59 % across 10 tasks in DMC-GB, 28.81 % across 6 tasks in Robosuite, and 20.50 % across 4 tasks in Adroit. The code for our framework will be released at https://github.com/csufangyu/MuHA .},
  archive      = {J_NEUCOM},
  author       = {Yu Fang and Xuehe Zhang and Haoshu Cheng and Xizhe Zang and Changle Li and Jie Zhao},
  doi          = {10.1016/j.neucom.2025.131602},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131602},
  shortjournal = {Neurocomputing},
  title        = {An effective framework with hybrid augmentation for visual reinforcement learning generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robust generalization through appropriate adversarial example attack intensity. <em>NEUCOM</em>, <em>657</em>, 131599. (<a href='https://doi.org/10.1016/j.neucom.2025.131599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are notoriously susceptible to adversarial examples. To mitigate the impact of well-designed adversarial attacks on network models, researchers have developed various defense mechanisms, among which adversarial training has emerged as one of the most effective strategies to date. Adversarial training aims to augment training data with adversarial examples, thus giving DNNs a certain degree of robustness to defend against adversarial attacks. However, while obtaining adversarial robustness, this method comes at the cost of reducing the generalization performance, manifested in the reduced classification effect of clean test datasets. Researchers have been actively seeking to counter the balance between adversarial robustness and model generalization. We believe that the key to balancing these two aspects lies in identifying appropriate adversarial examples. Overly potent examples can lead to a decline in clean accuracy, whereas weaker examples may offer limited robustness. Based on our analysis, a new adversarial example generation algorithm called Denoising Projection Gradient Descent (DPGD) was proposed. DPGD adds a purification module and a constraint in generating adversarial examples, the former is used to limit the influence of too strong adversarial examples on model training and the latter is used to ensure the necessary attack intensity. Combining DPGD with the framework of traditional adversarial training, we obtain the Diffusion Adversarial Training (DifAT) approach. To verify the effectiveness of our proposed method, we conducted extensive experiments on benchmark datasets, including CIFAR-10, CIFAR-100, and Tiny-Imagenet. Our results demonstrate the effectiveness of DifAT in improving the robustness of DNNs while maintaining or even improving their generalization performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaoguo Ding and Liangjian Zhang and Qiqi Bao and Yaguan Qian and Bin Wang and Zhaoquan Gu and Yanchun Zhang},
  doi          = {10.1016/j.neucom.2025.131599},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131599},
  shortjournal = {Neurocomputing},
  title        = {Enhancing robust generalization through appropriate adversarial example attack intensity},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User identification based on the topology consistency of cross-layer common neighbors in social network. <em>NEUCOM</em>, <em>657</em>, 131591. (<a href='https://doi.org/10.1016/j.neucom.2025.131591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it has become a common practice to create multiple accounts on various social networks for online recreation. When accounts in different networks share similar structural features, i . e . , they have topology consistency, they may belong to the same individual. However, having multiple accounts for the same person across different networks can be inconvenient and uncertain, leading to difficulties in accurate recommendations. Therefore, some researchers have focused on identifying users within single network layers, but without involving the information from various network platforms, resulting in identification confusion and reduced algorithm accuracy. This paper proposes a novel topology consistency-based link prediction algorithm (Topology Consistency: TC) for user identification, combining separate layers of a multilayer network into a single-layer network to include more layer information. TC applies topology information from the cross-layer common neighbors produced in layer combination to distinguish target node pairs and utilizes matrix computation to reduce complexity. Furthermore, to address controversial identification situations appearing after layer combination, the edges between the cross-layer common neighbors are innovatively considered. Finally, experimental results in real-world and artificial networks show that TC has superior performance to state-of-the-art algorithms and has applicability and practicality.},
  archive      = {J_NEUCOM},
  author       = {Yujie Yang and Shuai Cao and Long Wang and Dong Liu and Marcus Kaiser},
  doi          = {10.1016/j.neucom.2025.131591},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131591},
  shortjournal = {Neurocomputing},
  title        = {User identification based on the topology consistency of cross-layer common neighbors in social network},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states. <em>NEUCOM</em>, <em>657</em>, 131588. (<a href='https://doi.org/10.1016/j.neucom.2025.131588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear optics neural networks or optical neural networks offer potential advantages over traditional electronic neural networks in terms of speed, energy efficiency, scalability, and improved parallelism, particularly for high-bandwidth applications. The use of photonics allows for more compact and integrated neural network designs, potentially enabling the development of larger and more complex networks. A linear optics network is developed to implement a quantum classifier. Indeed, the designed network is a quantum circuit consisting of some Gaussian gates such as displacement, noiseless linear amplification (NLA), squeezer and Green machine. At first, the classical inputs are encoded with the help of position-displacement operator to prepare single-mode coherent states. Then, the amplitudes of the coherent states are amplified by passing through NLA elements followed by squeezer gates that may transform classical coherent states into nonclassical ones. Finally, the transformed coherent states are fed into the Green machine which provides entangled states as the outcome of the network. As a primary goal of this work, the network generates a multi-mode entangled state by applying the displacement operator on the vacuum state encoded classical data. Besides, it is shown that the output state of the circuit may possess squeezing characteristics as another nonclassical feature. In the continuation, as a practical application, the network is implemented to perform some pattern recognition tasks. At first, the Bayes theorem is employed to define discriminant functions to perform a general classification task, then the outcome distribution of the network is utilized to classify some corrupted LEDs that display English letters. Finally, we show that the outcome of the circuit may be manipulated to embed classical neural networks into a continuous-variable variational quantum circuit (VQC). The network is trained via the logistic regression algorithm with the MNIST database. The results show that the digits can be recognized with relatively high accuracy. Ongoing research is focused on developing new linear optical techniques for machine learning, improving the efficiency and scalability of optical networks, and exploring new applications of linear optics in machine learning and quantum computing. Hence, such a quantum circuit may also be used to design novel high-accuracy pattern recognition devices.},
  archive      = {J_NEUCOM},
  author       = {Ebrahim Ghasemian and Mohammad Kazem Tavassoly and Habib Rostami},
  doi          = {10.1016/j.neucom.2025.131588},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131588},
  shortjournal = {Neurocomputing},
  title        = {Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding. <em>NEUCOM</em>, <em>657</em>, 131586. (<a href='https://doi.org/10.1016/j.neucom.2025.131586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning has emerged as a crucial research direction in the field of computer vision, offering improved performance and efficiency across multiple tasks. Recent studies have incorporated prompt learning into multi-task learning to enhance the interaction between prompt vectors and image representations. However, these studies fail to consider the inter-task and intra-task relations of prompt vectors under multi-task scenarios. To address this issue, we propose learning Generic and Specific Prompts (GSPrompt) with contrastive constraints for multi-task visual scene understanding. Our approach assumes that each task possesses both commonality and individuality, leading us to design two distinct types of prompt vectors: task-generic prompts and task-specific prompts. By constraining the prompt vectors through pulling task-generic prompts and pushing task-specific prompts, we enable multi-task models to learn prompts capable of adapting to multiple tasks simultaneously. Extensive experiments on NYUD-v2, PASCAL-Context, and Cityscapes show that GSPrompt learns effective prompts and achieves state-of-the-art performance. The code is publicly available at https://github.com/teeyohan/GSPrompt-main .},
  archive      = {J_NEUCOM},
  author       = {Tianyu Han and Zhimin Xu and Wanying Li and Haohao Hu and Xinxin He and Song He and Peng Zan and Xiaochen Bo},
  doi          = {10.1016/j.neucom.2025.131586},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131586},
  shortjournal = {Neurocomputing},
  title        = {Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based passenger head detection for carriage crowd density estimation. <em>NEUCOM</em>, <em>657</em>, 131584. (<a href='https://doi.org/10.1016/j.neucom.2025.131584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carriage crowd density monitoring is a key component in developing intelligent transportation systems, such as maglev transportation system. Surveillance images captured by sensors, such as carriage monitoring cameras, serve as a new solution for estimating crowd density inside the carriage due to their wide coverage and real-time updates. In this study, a passenger head detection dataset (PHD) is developed using 3717 images acquired from carriage surveillance. Based on these images, over 67,215 head instances are precisely annotated manually. To address the issue of insufficient feature fusion in existing detection algorithms, an efficient cross-scale feature enhancement (CFE) module is proposed and introduced into the advanced YoloX model. The PHD dataset is, to the best of our knowledge, the first public dataset of surveillance images for carriage crowd density estimation. To prove the usability of the PHD dataset and the validity of the proposed method, 12 different versions of detectors are applied and compared. The results demonstrate the performance of these algorithms in the detection of passenger heads. Our research offers a new approach for carriage crowd density estimation. The dataset is publicly available at: https://github.com/Xujiajing111/PHD .},
  archive      = {J_NEUCOM},
  author       = {Jiajing Xu and Mingda Zhai and Yuan Tian and Jun Wu},
  doi          = {10.1016/j.neucom.2025.131584},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131584},
  shortjournal = {Neurocomputing},
  title        = {Vision-based passenger head detection for carriage crowd density estimation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WaterBox: Weakly supervised underwater instance segmentation and a new benchmark. <em>NEUCOM</em>, <em>657</em>, 131582. (<a href='https://doi.org/10.1016/j.neucom.2025.131582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Box-supervised instance segmentation has gained increasing attention due to its reliance on weak box annotations, which are considerably less expensive than pixel-wise mask annotations. Despite the advantage, existing methods in this category often struggle in complex underwater scenes, where degraded image quality causes foreground objects to become heavily entangled with the background. To address this issue, we propose WaterBox, a cost-effective box-supervised underwater instance segmentation method. Considering the intrinsic characteristics of underwater imaging, we introduce a novel pairwise loss function that leverages a mixed color affinity map with a dynamic threshold to effectively disambiguate foreground and background boundaries. Additionally, we devise a bounding box refinement strategy that generates tight and accurate bounding boxes for each instance, alleviating the negative impact of imprecise box annotations on segmentation performance. Furthermore, to fill in the gaps caused by data scarcity, we construct the first diver instance segmentation dataset, DSeg, which consists of 2000 underwater images with high-quality instance masks. Extensive experiments on two underwater datasets demonstrate the superiority of our approach over the state-of-the-art (SOTA) weakly supervised methods. The code and dataset will be made publicly available.},
  archive      = {J_NEUCOM},
  author       = {Meng Wu and Yifeng Cui and Rong Min and Shanghang Jiang and Lei Zhang and Jing Yu},
  doi          = {10.1016/j.neucom.2025.131582},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131582},
  shortjournal = {Neurocomputing},
  title        = {WaterBox: Weakly supervised underwater instance segmentation and a new benchmark},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-client GAN-based backdoor attacks for asynchronous federated learning. <em>NEUCOM</em>, <em>657</em>, 131580. (<a href='https://doi.org/10.1016/j.neucom.2025.131580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables distributed collaborative training while preserving data privacy; however, it demonstrates significant vulnerability to backdoor attacks. Existing attack methodologies predominantly require control of numerous malicious clients to achieve efficacy and largely neglect asynchronous FL scenarios. In response to these limitations, we propose a novel GAN-based backdoor attack framework capable of injecting effective and covert backdoors with minimal malicious client participation, functioning efficiently across both synchronous and asynchronous environments. Our framework operates effectively with a single malicious client, eliminating the need for coordination among multiple adversarial participants or prior knowledge of benign client data distributions. This reduction in resource requirements enhances the framework's practicality in real-world FL implementations. The malicious client employs a Generative Adversarial Network to synthesize adversarial samples containing predefined triggers, which are subsequently incorporated into local training datasets. The concurrent training on legitimate and triggered data enhances attack effectiveness, while gradient injection—manipulating differences between local and global gradients to introduce strategic noise—facilitates backdoor embedding with improved stealth characteristics. Empirical evaluations demonstrate that in a configuration of 200 clients with a single attacker, our framework achieves attack success rates of 98.66 % on MNIST and 86.29 % on CIFAR-10 datasets. Comprehensive experimentation across both datasets substantiates the framework's effectiveness, imperceptibility, and resilience in synchronous and asynchronous FL environments. This research contributes significant insights into backdoor attack strategies in FL, particularly within asynchronous contexts, and underscores the imperative for developing robust defensive countermeasures.},
  archive      = {J_NEUCOM},
  author       = {Siyu Guan and Chunguang Huang and Hai Cheng},
  doi          = {10.1016/j.neucom.2025.131580},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131580},
  shortjournal = {Neurocomputing},
  title        = {Single-client GAN-based backdoor attacks for asynchronous federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UA-PDFL: A personalized approach for decentralized federated learning. <em>NEUCOM</em>, <em>657</em>, 131579. (<a href='https://doi.org/10.1016/j.neucom.2025.131579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy preserving machine learning paradigm designed to collaboratively learn a global model without data leakage. Specifically, in a typical FL system, the central server solely functions as a coordinator to iteratively aggregate the collected local models trained by each client, potentially introducing single-point transmission bottleneck and security threats. To mitigate this issue, decentralized federated learning (DFL) has been proposed, where all participating clients engage in peer-to-peer communication without a central server. Nonetheless, DFL still suffers from training degradation as FL does due to the non-independent and identically distributed (non-IID) nature of client data. And incorporating personalization layers into DFL may be one of the most effective solutions to alleviate the side effects caused by non-IID data. Therefore, in this paper, we propose a novel unit representation aided personalized decentralized federated learning framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By adaptively adjusting the level of personalization layers through the guidance of the unit representation, UA-PDFL is able to address the varying degrees of data skew. Based on this scheme, client-wise dropout and layer-wise personalization are proposed to further enhance the learning performance of DFL. Extensive experiments empirically prove the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Zhu and Yuxiang Fan and Zhenping Xie},
  doi          = {10.1016/j.neucom.2025.131579},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131579},
  shortjournal = {Neurocomputing},
  title        = {UA-PDFL: A personalized approach for decentralized federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning interpretable dynamics: Influence-based clustering of energy consumption time series. <em>NEUCOM</em>, <em>657</em>, 131578. (<a href='https://doi.org/10.1016/j.neucom.2025.131578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption is governed by dynamic temporal patterns, context, and user behavior. Traditional clustering methods, often operating on raw data, struggle to capture evolving feature relationships and provide interpretable subgroup definitions. To overcome these limitations, we propose a novel framework, Dynamic Influence-Based Clustering , that leverages explainable machine learning (XML) to transform time-series data into an interpretable influence space. Unlike existing approaches that apply XML post-hoc or treat clustering and explanation separately, our framework is the first to jointly optimize influence representation generation and dynamic clustering within a unified mathematical framework. In this space, each data point is represented by a vector of feature contributions to an energy usage prediction, estimated using robust attribution methods such as SHAP or Integrated Gradients applied to predictive models like gradient boosting machines or neural networks. We then introduce a dynamic clustering algorithm that optimizes a composite objective balancing cluster cohesion in the influence space with novel constraints for temporal continuity and contextual alignment—capabilities entirely absent from existing clustering methods. This integrated design enables the robust detection of evolving consumer subgroups and facilitates subgroup transition analysis and anomaly detection. Extensive experiments on two real-world energy datasets demonstrate that our framework produces demonstrably more interpretable, stable, and coherent clusters compared to both standard clustering on raw features and state-of-the-art time-series clustering baselines. The proposed framework provides actionable insights into dynamic energy usage and offers a rigorous foundation for developing interpretable learning systems in time-sensitive domains.},
  archive      = {J_NEUCOM},
  author       = {Binbin Li and Xiufeng Liu and Rongfei Ma and Yuhao Ma},
  doi          = {10.1016/j.neucom.2025.131578},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131578},
  shortjournal = {Neurocomputing},
  title        = {Learning interpretable dynamics: Influence-based clustering of energy consumption time series},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Face clustering using a novel density peaks clustering algorithm. <em>NEUCOM</em>, <em>657</em>, 131576. (<a href='https://doi.org/10.1016/j.neucom.2025.131576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face clustering remains a challenging task due to the high intra-class variability and uneven density distributions inherent in real-world face datasets. These characteristics often undermine the performance of conventional clustering algorithms. To address these limitations, this paper introduces a novel density-based clustering method, termed DPC-MK (Density Peak Clustering with Mixed k-Nearest Neighbor strategy). Initially, the reverse nearest neighbors and shared nearest neighbors of each sample are identified based on the k-nearest neighbor (KNN) method, and their counts are quantitatively assessed. Subsequently, the distances between each sample and its k-nearest neighbors are computed to evaluate their respective contributions to the local density. The quantified reverse and shared neighbor counts are then integrated with the distance-based density metric to yield an enhanced local density estimate. Using this refined density, the relative distance between each sample and any other point with higher density is computed. A decision graph is then constructed from the modified local density and relative distance values to identify cluster centers. Finally, non-center points are assigned to clusters by following density gradients toward their nearest higher-density neighbors. The results of the ablation study clearly demonstrate the complementary roles of each component as well as the effectiveness of the method we proposed. The efficacy of DPC-MK is further validated on multiple UCI benchmark datasets and public face clustering datasets. Comparative evaluations against baseline and state-of-the-art algorithms—including K-means, DBSCAN, FCM, DPC, DPC-KNN, DPC-NN, DPC-FWSN, and LPMNN-DPC—demonstrate that DPC-MK achieves superior clustering performance and maintains robustness across diverse clustering scenarios and varying cluster counts, highlighting its strong generalization capability.},
  archive      = {J_NEUCOM},
  author       = {Yu Zhou and Jiaoyang Cheng and Jianqiao Long and Jiguang Li and Jiaqing Li and Jichun Li},
  doi          = {10.1016/j.neucom.2025.131576},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131576},
  shortjournal = {Neurocomputing},
  title        = {Face clustering using a novel density peaks clustering algorithm},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups. <em>NEUCOM</em>, <em>657</em>, 131574. (<a href='https://doi.org/10.1016/j.neucom.2025.131574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) has emerged as an important data pre-processing technology to solve the challenging task of data mining. However, most existing FS methods primarily focus on exploiting the independent contributions provided by individual features, while neglecting the critical contributions inherent in ubiquitous intrinsic feature groups. As a result, they may fail to fully capture the potentially valuable information embedded in data. This issue becomes more pronounced in modern large-scale data environments, such as JointCloud, where cross-organizational collaborative data analysis over non-shared datasets is often required. To address this issue, this paper proposes a N ovel T wo- S tage H ybrid FS approach (NTSHFS) that jointly considers the informative contributions of both individual features and collaborative feature groups, enabling a comprehensive evaluation of feature relevance, redundancy and discriminative capability. In the first stage, the correlation coefficient-based co-association matrix (CC-CAM) is developed to ensemble the results obtained by different univariate and structured regularization techniques. Then, a CC-CAM-based embedded FS is proposed to select and rank representative features, achieving strong relevance prioritization and redundancy elimination. In the second stage, a quasi fuzzy-rough set (QFRS) model is designed by integrating the similarity relations at both individual-feature level and multi-feature level through the intersection operation. Based on this model, a QFRS-based filter FS is presented to determine the final feature subset with stronger discriminative capability using internal rankings of feature groups. Experimental results on 24 datasets demonstrate that the proposed approach typically outperforms the compared methods (i.e., achieving an average classification accuracy improvement ranging from 1.77 % to 7.69 %), highlighting its effectiveness, robustness and generalization in data mining.},
  archive      = {J_NEUCOM},
  author       = {Lin Qiu and Xingwei Wang and Bo Yi and Yanpeng Qu and Min Huang and Kaimin Zhang},
  doi          = {10.1016/j.neucom.2025.131574},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131574},
  shortjournal = {Neurocomputing},
  title        = {A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view semi-supervised feature selection with multi-order similarity and tensor learning. <em>NEUCOM</em>, <em>657</em>, 131573. (<a href='https://doi.org/10.1016/j.neucom.2025.131573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data has attracted extensive attention because it can better characterize samples, and multi-view semi-supervised feature selection can not only effectively improve multi-view performance, but also maintain the original real structure of the data. To this end, many scholars have proposed various models to achieve this goal. However, most of the existing methods rely on the graph structure constructed from the original data and use the constructed graph as a guide for feature selection. This not only ignores multi-order domain knowledge, but also ignores the high-order relations between views. Therefore, this study effectively integrates multi-order domain information with graph learning, and performs tensor low-rank learning on the graph structure between multiple views. A multi-view semi-supervised feature selection method based on multi-order similarity and tensor learning is proposed, which not only integrates multi-order domain information, but also takes into account the relationship between views. Based on this, we propose an iterative method to solve the objective function and prove the superiority of our method on multiple basic datasets.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Chen and Xijiong Xie and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131573},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131573},
  shortjournal = {Neurocomputing},
  title        = {Multi-view semi-supervised feature selection with multi-order similarity and tensor learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection via risk-bound utility maximization. <em>NEUCOM</em>, <em>657</em>, 131572. (<a href='https://doi.org/10.1016/j.neucom.2025.131572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate goal of supervised feature selection is to identify a feature subset that minimizes classification risk. Contemporary methods, however, often rely on heuristic or model-dependent proxy criteria that lack a direct theoretical connection to this fundamental objective. To bridge this gap, we introduce a new feature selection framework that directly optimizes a model-agnostic utility function grounded in statistical learning theory. Our approach defines the utility of a feature subset based on the 1-Wasserstein distance between class-conditional distributions. This metric is theoretically powerful as it can be used to construct an upper bound on the Bayes classification error, allowing us to construct a utility function that is a direct surrogate for this risk bound. We instantiate this framework with a subset search strategy that effectively captures feature interactions by maximizing this risk-bound utility. Extensive experiments on real-world datasets demonstrate that our method not only achieves state-of-the-art classification performance but also demonstrates superior robustness and interpretability, providing a principled and powerful alternative to traditional feature selection methods, confirming our framework’s theoretical soundness.},
  archive      = {J_NEUCOM},
  author       = {Chunxu Cao and Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131572},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131572},
  shortjournal = {Neurocomputing},
  title        = {Feature selection via risk-bound utility maximization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training. <em>NEUCOM</em>, <em>657</em>, 131568. (<a href='https://doi.org/10.1016/j.neucom.2025.131568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning optimization faces a fundamental trade-off between convergence efficiency and generalization. First-order methods such as stochastic gradient descent (SGD) and adaptive moment estimation (Adam) tend to find flatter minima but converge slowly, while higher-order methods converge rapidly but are often drawn to sharp minima that generalize poorly. To address this, we introduce the projected variable three-term conjugate gradient (PVTTCG) algorithm. Motivated by the geometric instabilities in modern networks that use techniques such as batch normalization (BN), PVTTCG integrates an orthogonal projection into the higher-order optimization framework. This mechanism eliminates radial components from the search direction, inherently guiding the optimization toward flatter regions without requiring additional regularization terms or hyperparameters. The effectiveness of PVTTCG is validated across diverse tasks, including language modeling, large-scale image classification, and a real-world engineering application. In complex scenarios, PVTTCG consistently improves upon its higher-order baseline, achieving up to a 3.92 percentage point gain on CIFAR-100 while remaining competitive with leading first-order methods. A systematic analysis reveals that PVTTCG demonstrates superior robustness to batch size variations, particularly excelling at larger batch sizes. This robustness enables the algorithm to process batch sizes up to 2,048 in engineering applications, achieving a 35.9% test loss reduction compared to Adam. These findings establish PVTTCG as an effective solution for bridging the convergence-generalization trade-off.},
  archive      = {J_NEUCOM},
  author       = {Sanghyuk Kim and Hansu Kim and Namwoo Kang and Tae Hee Lee},
  doi          = {10.1016/j.neucom.2025.131568},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131568},
  shortjournal = {Neurocomputing},
  title        = {Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVC2: Deep video cascade clustering from video structures. <em>NEUCOM</em>, <em>657</em>, 131565. (<a href='https://doi.org/10.1016/j.neucom.2025.131565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video clustering is a critical unsupervised learning task, where category labels are unavailable, unlike in supervised video classification. The primary challenge is learning meaningful video representations without annotations to effectively group similar videos. Most existing methods extract frame-level features and apply standard clustering algorithms such as K-means, but they often fail to capture temporal relationships inherent in video data. In this paper, we introduce Deep Video Cascade Clustering ( DVC 2 ), a novel unsupervised video learning paradigm. Unlike image-based clustering methods, DVC 2 first learns an initial video representation through frame clustering, which serves as guidance, and then aligns video clustering results with both long-term and short-term structures as well as nearest neighbors. We evaluate DVC 2 on benchmark datasets, including UCF101 and Kinetics-400, achieving state-of-the-art results. Notably, even in annotation-free scenarios where self-supervised learning with K-means already yields reasonable clustering, DVC 2 demonstrates significantly superior performance.},
  archive      = {J_NEUCOM},
  author       = {Zihua Wang and Siya Mi and Yu Zhang},
  doi          = {10.1016/j.neucom.2025.131565},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131565},
  shortjournal = {Neurocomputing},
  title        = {DVC2: Deep video cascade clustering from video structures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting. <em>NEUCOM</em>, <em>657</em>, 131563. (<a href='https://doi.org/10.1016/j.neucom.2025.131563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion forecasting is a fundamental component of the autonomous driving system and plays an important role in ensuring safety. While supervised learning methods have achieved promising performance in many domains, their model capacity is typically limited by the availability of annotated data. Some previous works have tried to introduce this paradigm into motion forecasting. However, these early studies neglect the task-specific characteristics. To address this, we incorporate two key insights into motion forecasting tasks within the self-supervised paradigm and propose a novel self-supervised motion forecasting framework. First, we design a Frequency Information Harmonization pretext task that explicitly encourages the model to integrate frequency domain features with their time domain counterparts, making them work harmoniously. Second, we introduce an Implicit Scene Alignment task, which enables the model to learn scene-level semantics by aligning masked and unmasked views through shared prototypes. By jointly optimizing these objectives, the model is encouraged to leverage abundant unlabeled data and capture rich spatio-temporal representations. Extensive experiments conducted on the challenging Argoverse 2 and Argoverse 1 benchmarks demonstrate that our proposed model outperforms previous state-of-the-art baselines and can produce more accurate and reliable predictions.},
  archive      = {J_NEUCOM},
  author       = {Chunyu Liu and Zeyu Liu and Tiechui Yao and Shijie Li},
  doi          = {10.1016/j.neucom.2025.131563},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131563},
  shortjournal = {Neurocomputing},
  title        = {SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal. <em>NEUCOM</em>, <em>657</em>, 131559. (<a href='https://doi.org/10.1016/j.neucom.2025.131559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, mental stress is emerging as a common social problem triggering different health disorders, including nervousness, heart attacks, strokes, and depression. Specifically, the Electroencephalography (EEG) signal, capable of reflecting the variations in brain activity, is highly used for mental state detection. Despite their promising performance, the existing EEG-based detection methods fail to capture the inherent characteristics of highly intricate and nonstationary EEG signals. In order to address the drawbacks of existing methods, this research proposes the Deep Learning model namely, Rosmarus Migrative Search Optimized Efficient channel attention enabled Distributed Bi-directional Long Short-Term Memory (RosMS-ECDBTM) model for precise mental state detection. More specifically, the efficient channel attention facilitates the proposed model to dynamically highlight the important parts of the signal characteristics while suppressing the irrelevant regions. Besides, the distributed DL architecture improves the learning capability and scalability of the proposed model to process the large datasets, through the parallel processing of sequential data. Further, the proposed approach exploits the Rosmarus Migrative Search Optimization (RosMS) algorithm for optimizing the RosMS-ECDBTM architecture, resulting in improving the training process. Ultimately, the proposed model, combining efficient channel attention and distributed learning mechanism, captures the intricate patterns and reduces the computational complexity of mental state detection. In addition, the Hybrid Discrete Wavelet transform (DWT) approach decomposes the EEG signal into several frequency components for capturing the hidden patterns and anomalous states in the EEG signal, providing key insights for improving the mental state detection. Extensive experiments show that the RosMS-ECDBTM method provides superior performance, achieving a high accuracy of 96.78 %, precision of 98.99 %, recall of 95.91 %, and F1-score of 97.42 % for the Mental Stress Detection dataset compared to other state-of-the-art methods. Ultimately, these findings reveal the high learning efficiency of the proposed deep learning approach in enhancing the mental state detection accuracy, significantly contributing to advancing the field of mental health monitoring.},
  archive      = {J_NEUCOM},
  author       = {Mandar Nitin Kakade},
  doi          = {10.1016/j.neucom.2025.131559},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131559},
  shortjournal = {Neurocomputing},
  title        = {RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion. <em>NEUCOM</em>, <em>657</em>, 131555. (<a href='https://doi.org/10.1016/j.neucom.2025.131555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has shown promising applications in integrating information from different modalities. However, existing multimodal fusion approaches in remote sensing face two main challenges: First, multimodal fusion models relying on Convolutional Neural Networks (CNNs) or Visual Transformers (ViTs) have limitations in terms of remote modeling capabilities and computational complexity, while state-space model (SSM)-based fusion models are prone to feature redundancy due to the use of multiple scanning paths, and similarly suffer from high computational complexity. Second, existing methods do not fully address inter-modal heterogeneity, leading to poor multimodal data fusion. To address these issues, we propose an efficient multimodal fusion network, AFMamba, based on the state-space model (SSM) for semantic segmentation of remote sensing images. Specifically, we design the Efficient Dynamic Visual State Space (EDVSS) module, which enhances the efficiency of the standard Mamba model by dynamically improving local features and reducing channel redundancy. Furthermore, we introduce the Cross Attention Alignment Fusion (CAAFM) module, which combines cross-image attention fusion and channel interaction alignment to effectively improve the accuracy and efficiency of cross-modal feature fusion and mitigate feature inconsistency. Experimental results demonstrate that in multimodal hyperspectral image semantic segmentation, the proposed model reduces computational complexity, measured in GFLOPs, by at least 61 % while maintaining a low parameter count, achieving optimal overall accuracy (OA) of around 92 %, and effectively balancing performance and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Wenqian Chen and Wendie Yue and Kai Chang and Hongzhi Wang and Kaijun Tan and Xinyu Liu and Xiaoyi Cao},
  doi          = {10.1016/j.neucom.2025.131555},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131555},
  shortjournal = {Neurocomputing},
  title        = {Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-step minimax Q-learning algorithm for two-player zero-sum markov games. <em>NEUCOM</em>, <em>657</em>, 131552. (<a href='https://doi.org/10.1016/j.neucom.2025.131552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interesting iterative procedure is proposed to solve two-player zero-sum Markov games. Under suitable assumptions, the boundedness of the proposed iterates is obtained theoretically. Using results from stochastic approximation, the almost sure convergence of the proposed multi-step minimax Q-learning is obtained theoretically. More specifically, the proposed algorithm converges to the game theoretic optimal value with probability one, when the model information is not known. Numerical simulations authenticate that the proposed algorithm is effective and easy to implement.},
  archive      = {J_NEUCOM},
  author       = {Shreyas S.R. and Antony Vijesh},
  doi          = {10.1016/j.neucom.2025.131552},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131552},
  shortjournal = {Neurocomputing},
  title        = {A multi-step minimax Q-learning algorithm for two-player zero-sum markov games},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-agent evasion using deep reinforcement learning. <em>NEUCOM</em>, <em>657</em>, 131550. (<a href='https://doi.org/10.1016/j.neucom.2025.131550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective evasion strategies in pursuit–evasion scenarios is challenging, particularly when the pursuer’s model is unknown and inaccessible. This limitation hinders the application of conventional evasion policy design methods. To overcome this challenge, especially when evaders have constrained maneuverability against unrestricted pursuers, we propose a novel multi-agent evasion algorithm based on deep reinforcement learning. Our approach employs a staged learning framework, progressively guiding evaders from simpler to more complex tasks to refine their evasion strategies. Crucially, our algorithm enables evaders to infer pursuers’ intentions even without prior knowledge of pursuers’ objectives, allowing for optimal decision-making despite mobility constraints. Simulation results demonstrate that our method significantly enhances evasion success, validating the effectiveness of learning-based strategies. Additionally, the algorithm exhibits strong adaptability to environmental changes, ensuring reliable performance across diverse pursuit–evasion scenarios.},
  archive      = {J_NEUCOM},
  author       = {Bowei Yan and Runle Du and Xiaojun Ban and Di Zhou},
  doi          = {10.1016/j.neucom.2025.131550},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131550},
  shortjournal = {Neurocomputing},
  title        = {Constrained multi-agent evasion using deep reinforcement learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation. <em>NEUCOM</em>, <em>657</em>, 131539. (<a href='https://doi.org/10.1016/j.neucom.2025.131539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph convolutional networks utilize an alternating combination of one-dimensional ordinary convolution and graph convolution to extract spatio-temporal features. This alternation intertwines temporal and spatial features closely, leading to a tight coupling between them. The presence of spatio-temporal coupling complicates the analysis of spatio-temporal data, posing challenges for existing explainability algorithms to effectively separate and interpret these intertwined features. Therefore, we propose STD-Explain, an explainable algorithm based on spatio-temporal decoupled perturbation, which employs a two-stage perturbation approach considering subgraph and node-level explanations. Firstly, targeting the spatio-temporal coupling issue in spatio-temporal graph convolutional networks, the algorithm proposes a temporal perturbation algorithm based on Slice Graph and a spatial perturbation algorithm aimed at important subgraph node features. Secondly, to avoid introducing additional semantic information when extracting temporal subgraphs, we propose a method for generating temporal subgraphs in spatio-temporal decoupling, slicing human skeleton sequences with discrete masks to ensure each subsequence maintains spatial structure integrity without introducing additional edges. Furthermore, to ensure the maximum correlation between the interpreted subgraphs and model predictions, we propose a temporal important subgraph discrimination strategy to select the most relevant subgraphs to model predictions. Experimental results demonstrate that STD-Explain performs well in qualitative and quantitative analysis.},
  archive      = {J_NEUCOM},
  author       = {Yanshan Li and Ting Shi and Suixuan He and Zhiyuan Chen and Li Zhang and Rui Yu and Weixin Xie},
  doi          = {10.1016/j.neucom.2025.131539},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131539},
  shortjournal = {Neurocomputing},
  title        = {STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment. <em>NEUCOM</em>, <em>657</em>, 131534. (<a href='https://doi.org/10.1016/j.neucom.2025.131534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision–language pretraining (VLP) models have demonstrated exceptional performance across a wide range of image–text multimodal tasks. Despite their prominence, research confirms that these systems retain significant susceptibility to adversarial manipulation. Existing multimodal adversarial attack methods often fail to fully exploit sample-specific semantic structures, resulting in suboptimal cross-modal alignment and limited transferability of adversarial examples. To overcome this limitation, we propose MGSA—a Multi-Granularity Semantic Alignment Attack framework that enhances adversarial perturbation transferability by jointly disrupting cross-modal semantics at both global and fine-grained levels. MGSA captures coarse-grained alignment using overall representations and fine-grained correspondence by selectively aggregating key image regions and words based on importance. This dual-level joint optimization effectively perturbs both holistic consistency and detailed correspondences, thereby significantly enhancing attack effectiveness in white-box scenarios and transferability to black-box models. Extensive experiments conducted across diverse model architectures and multimodal tasks demonstrate that our method achieves strong performance in white-box settings while significantly improving black-box attack success rates. The results highlight the vulnerability of current VLP models and the effectiveness of our approach in generating transferable and semantically grounded adversarial examples.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Liu and Haohua Zhou and Zhidong Shen and Hui Sun},
  doi          = {10.1016/j.neucom.2025.131534},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131534},
  shortjournal = {Neurocomputing},
  title        = {MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StrongerCenter: Enhancing TransCenter for robust multi-object tracking. <em>NEUCOM</em>, <em>657</em>, 131527. (<a href='https://doi.org/10.1016/j.neucom.2025.131527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based multi-object tracking (MOT) research has made significant progress. The typical representative TransCenter method performs well by combining transformers and center-based object tracking. However, it only focuses on predicting object center coordinates, ignoring scale prediction and ReID. To address these limitations, a novel StrongerCenter framework incorporating motion prediction and ReID is proposed in this paper. To enhance spatial contextual feature representation, we first propose an Enhanced Multi-scale Attention Track Memory (EMATM) module. This module incorporates Convolutional Block Attention Module (CBAM) and deformable convolution for improved feature extraction. Then, a Kalman-Guided Motion Prediction module is designed to estimate the state of objects in scenarios involving non-linear motion, scale variations, or occlusion. To ensure robust long-term tracking under occlusion, we develop a ReID module with detail enhancement that captures both local and global features. Finally, a data association strategy that incorporates awareness of occlusion and cascade matching is designed to further improve the robustness of tracking. Extensive experimental results confirm the advantages of our method on the MOT17 and MOT20 datasets. The comparative results demonstrate that the proposed model outperforms comparable methods. Especially on the MOT17 dataset, our method has improved by 9.5 % in IDF1 and 5.2 % in HOTA.},
  archive      = {J_NEUCOM},
  author       = {Xiangzeng Liu and Heng Liu and Kailai Wang and Bocheng Zhao and Qiguang Miao},
  doi          = {10.1016/j.neucom.2025.131527},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131527},
  shortjournal = {Neurocomputing},
  title        = {StrongerCenter: Enhancing TransCenter for robust multi-object tracking},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation. <em>NEUCOM</em>, <em>657</em>, 131526. (<a href='https://doi.org/10.1016/j.neucom.2025.131526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D semantic maps generated from Light Detection and Ranging (LiDAR) point clouds enable scene understanding in diverse applications such as autonomous driving and urban planning. However, existing deep learning models struggle when tested on different domains, worsened by limited labeled data. Unsupervised Domain Adaptation (UDA) can bridge this gap, but existing UDA methods often face adaptation challenges due to domain shifts arising from variations in the physical environment, data sparsity, and sensor differences. To address these limitations, we propose UMDMix , a novel UDA architecture that operates on the mixing of multiple labeled source domains with unlabeled target domains to make the predictive model robust to cross-domain variations. UMDMix integrates a teacher–student learning scheme to produce a robust teacher model and an adaptable student model. The performance of the teacher model in the source domain is further strengthened by a position-aware loss that assigns greater significance to semantically rich neighborhoods. A combination of entropy regularization and KL-divergence loss in the target domain updates the knowledge of the teacher model to the student model during adaptation. Our extensive experiments across diverse environments show that UMDMix achieves an average improvement of 13 % on minor classes such as bicycle, traffic sign, and person in target domain datasets, outperforming previous State-Of-The-Art (SOTA) UDA methods.},
  archive      = {J_NEUCOM},
  author       = {Anurag Nihal and Pyare Lal and Vaibhav Kumar},
  doi          = {10.1016/j.neucom.2025.131526},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131526},
  shortjournal = {Neurocomputing},
  title        = {Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixtures of posterior and prior variational autoencoders for representation learning and cluster analysis in latent space. <em>NEUCOM</em>, <em>657</em>, 131524. (<a href='https://doi.org/10.1016/j.neucom.2025.131524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster analysis aims to identify groups of similar items within an unlabelled dataset. This is particularly challenging in high-dimensional data, necessitating the finding of hidden or latent structure within the data, for which variational methods have proven to be successful. We introduce a generative model based on the variational autoencoder (VAE) that uses a mixture distribution for both the prior and variational posterior components over the latent variables. This pair of distributions means that the algorithm can better capture the underlying structure of the data. We evaluated clustering performance on a set of benchmark datasets. Our proposed model demonstrates superior clustering performance compared with state-of-the-art deep clustering algorithms, as well as demonstrating reasonable reconstruction performance and generation of realistic examples from the latent space.},
  archive      = {J_NEUCOM},
  author       = {Mashfiqul Huq Chowdhury and Yuichi Hirose and Stephen Marsland and Yuan Yao},
  doi          = {10.1016/j.neucom.2025.131524},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131524},
  shortjournal = {Neurocomputing},
  title        = {Mixtures of posterior and prior variational autoencoders for representation learning and cluster analysis in latent space},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure. <em>NEUCOM</em>, <em>657</em>, 131521. (<a href='https://doi.org/10.1016/j.neucom.2025.131521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a prescribed performance control algorithm with asymmetric boundary for Unmanned Surface Vehicle (USV) formation to achieve cooperative navigation under marine disturbances. The proposed algorithm consists of a guidance switching mechanism and a robust adaptive control method. In the improved guidance principle, a velocity correction rule is provided to generate accurate reference signals for USVs during path following. Combined with the guidance term, the communication load between controller and actuator is significantly reduced by employing the Dynamic Event-Triggered Mechanism (DETM) with adaptive updating of threshold parameters. By integrating the initial errors into the performance boundary function, the controller can effectively adapt to different initial states. In addition, due to the smooth property of the shifting function, the error oscillation of the system before steady state is effectively suppressed. The Radial Basis Function Neural Networks (RBF-NNs) are utilized to design damping terms, enhancing the anti-interference capability in marine environments and mitigating the effects of nonlinearities in the model. Through the Lyapunov theorem, the Semi-Globally Uniformly Ultimately Bounded (SGUUB) stability of all state variables is guaranteed. Finally, quantitative validation of the algorithm is performed through numerical simulations and comparative analysis. The results demonstrate a control accuracy within 0.5 meters while showing that, compared to Static Event-Triggering Mechanisms (SETM), the DETM reduces control update frequency for surge force and yawing moment by 12.32 % and 18.78 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Guoqing Zhang and Junji Feng and Shilin Yin and Matthew Montebello},
  doi          = {10.1016/j.neucom.2025.131521},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131521},
  shortjournal = {Neurocomputing},
  title        = {Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding neural networks with logarithm determinant entropy estimator. <em>NEUCOM</em>, <em>657</em>, 131520. (<a href='https://doi.org/10.1016/j.neucom.2025.131520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring entropy and entropy-based informative functionals plays a vital role in many aspects of modern machine learning. However, recent practices find that the commonly used entropy estimators are often ineffective in handling samples with high dimensions. Meanwhile, many of them are expensive in computation and storage. These challenges have severely limited the design of information theory-based methods in machine learning. To address this, we proposed the L o g D e t estimator – a reliable matrix-based entropy estimator based on the logarithm determinant of the statistical quantities. We construct informative functionals of multivariate samples and design tests to ensure they are free from saturation problems in high dimensions. Besides, our method scales linearly in storage with the same computational complexity as the recently proposed α - R e ´ n y i entropy, which makes it more suitable for real-world practices of modern machine learning, such as neural network analysis, feature selection and design optimisation objectives. For application, we utilise this method to analyse the informative behaviour of neural networks, which provides a novel empirical interpretation of neural networks’ Information Bottleneck Theory.},
  archive      = {J_NEUCOM},
  author       = {Zhanghao Zhouyin and Ding Liu},
  doi          = {10.1016/j.neucom.2025.131520},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131520},
  shortjournal = {Neurocomputing},
  title        = {Understanding neural networks with logarithm determinant entropy estimator},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines. <em>NEUCOM</em>, <em>657</em>, 131507. (<a href='https://doi.org/10.1016/j.neucom.2025.131507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient 3D object detection is essential for ensuring both safety and operational efficiency in open-pit mines. Due to complex scene structures, broad perception ranges, and significant object size variations, existing point-based 3D detection methods face challenges that limit their applicability in open-pit mines. To address these issues, Mine-SSD, a single-stage 3D object detection method, is developed with dual-threshold set abstraction (DT-SA) and a radius-adaptive grouping mechanism. Specifically, a dual-head self-correlation module is introduced to calculate comprehensive importance scores for each point, enhancing the model’s ability to prioritize key features. Using these importance scores, a dual-threshold self-correlative farthest point sampling (DTSC-FPS) method is applied to retain key non-local information points during downsampling in set abstraction (SA). Additionally, a radius-adaptive grouping mechanism is designed to dynamically adjust the candidate point aggregation radius, capturing critical features of unconventional objects and supporting multi-scale feature processing. Finally, a novel regression loss function is constructed to improve prediction accuracy and balanced performance across objects of different sizes, ensuring reliable performance of Mine-SSD in multi-scale detection. Extensive experiments on an open-pit mine dataset validate the effectiveness of Mine-SSD.},
  archive      = {J_NEUCOM},
  author       = {Zhongyu Xie and Yuqian Zhao and Fan Zhang and Biao Luo and Wenliu Hu and Tenghai Qiu},
  doi          = {10.1016/j.neucom.2025.131507},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131507},
  shortjournal = {Neurocomputing},
  title        = {Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multimodal fault diagnosis for rod pumping systems via temporal convolutional network and multi-task learning. <em>NEUCOM</em>, <em>657</em>, 131499. (<a href='https://doi.org/10.1016/j.neucom.2025.131499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rod pumping systems (RPSs) are crucial components in oil extraction processes, where accurate automatic fault diagnosis, including both fault detection and fault prediction, plays a pivotal role in ensuring operational efficiency. Existing diagnostic approaches often exhibit limited adaptability to complex and varying operating conditions. To address this limitation, a novel method is proposed based on a multimodal multitask temporal fusion model (MMTF). This approach integrates multimodal information and uses a temporal convolutional network (TCN), effectively capturing long-range temporal dependencies while improving continuity. The model is constructed under a multitask learning framework, featuring a cascaded structure that enables joint learning of detection and prediction tasks. Validation on archival data from the Daqing oil field demonstrates that the MMTF model achieves leading performance in both diagnostic tasks and maintains high stability under adversarial scenarios.},
  archive      = {J_NEUCOM},
  author       = {Shichao Li and Peng Zeng and Dongliang Zheng and Liting Zhang and Haibo Cheng},
  doi          = {10.1016/j.neucom.2025.131499},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131499},
  shortjournal = {Neurocomputing},
  title        = {Robust multimodal fault diagnosis for rod pumping systems via temporal convolutional network and multi-task learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131498. (<a href='https://doi.org/10.1016/j.neucom.2025.131498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although large-scale pre-trained vision–language models (VLMs) exhibit significant potential for cross-domain visual tasks, existing prompt-learning-based unsupervised domain adaptation (UDA) methods suffer from source domain overfitting and target domain performance degradation. This paper experimentally demonstrates that conventional prompt learning exhibits insufficient cross-domain generalization due to optimization being heavily biased toward the source distribution. To address this challenge, we propose a Self-regulating Distribution Alignment (SRDA) framework. Its core innovation is a dual-branch collaborative optimization mechanism that dynamically balances cross-domain semantic alignment with pre-trained knowledge preservation. Specifically, the self-regulating multimodal prompt branch incorporates three constraints: semantic consistency regularization, dual-domain collaborative contrastive regularization, and text semantic diversity enhancement. This design suppresses prompt overfitting to the source domain while preserving CLIP’s zero-shot generalization capability. The cross-domain alignment branch introduces dynamic dual-domain feature bank and Cross-domain Collaborative Dual Attention module, achieving fine-grained local semantic calibration through moving average prototypes and a dual-layer attention mechanism. Extensive experiments validate SRDA’s effectiveness on downstream UDA tasks. The code is available at https://github.com/QYw12/SRDA .},
  archive      = {J_NEUCOM},
  author       = {Yang Qu and Jinlong Shi and Yun Cui and Ao Zhang and Suqin Bai and Ye Lu},
  doi          = {10.1016/j.neucom.2025.131498},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131498},
  shortjournal = {Neurocomputing},
  title        = {SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures. <em>NEUCOM</em>, <em>657</em>, 131489. (<a href='https://doi.org/10.1016/j.neucom.2025.131489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the synchronization of drive-response memristive competitive neural networks (MCNNs) under multiple actuator failures is studied through implementing fault-tolerant control scheme. Unlike previous studies, the actuator failures considered in this paper include both bias and effectiveness failures. To address these challenges, a proper mathematical model is first established to capture the impact of actuator failures on control inputs. Subsequently, several sufficient conditions are deduced by designing an appropriate bilayer fault-tolerant controller and constructing a Lyapunov functional to achieve the global exponential synchronization, finite-time synchronization, fixed-time synchronization and predefined-time synchronization respectively. Additionally, the settling time upper bounds for the proposed synchronization methods are determined. In the end, numerical simulations with analysis and comparison are performed to confirm the validity of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Duan and Yanli Huang and Quang Dan Le and Tse Chiu Wong},
  doi          = {10.1016/j.neucom.2025.131489},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131489},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging hyper-interval granules labeling and local mixed neighborhood entropy for semi-supervised feature selection. <em>NEUCOM</em>, <em>657</em>, 131482. (<a href='https://doi.org/10.1016/j.neucom.2025.131482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real scenarios, most datasets contain only a small number of labeled instances and partial features may be missing. Feature selection based on local neighborhood rough set has received much attention for applications on partially labeled data. However, local neighborhood rough set is susceptible to parameterization and only considers labeled data when evaluating upper and lower approximations. Moreover, training label prediction models and labeling unlabeled instances inevitably introduce labeling errors, which subsequently bias the feature selection results. Based on these topics, in order to fully utilize the unlabeled instances and data with missing features and minimize the negative impact of labeling errors, this paper aims at selecting the informative feature subset from partially labeled data. Firstly, the local neighborhood dependency of partially labeled data is computed based on the local neighborhood rough set. Secondly, an improved hyper-interval granulation and label recovery algorithm based on adaptive local density peak for predicting unlabeled instances is proposed, which is a granular computing-based labeling method, and then the global conditional neighborhood entropy is computed on the completely labeled data. Finally, we develop a semi-supervised feature selection algorithm that combines the local neighborhood dependency and the global conditional neighborhood entropy. Comparative dataset experiments demonstrate superior accuracy of our method with fewer features versus existing semi-supervised algorithms.},
  archive      = {J_NEUCOM},
  author       = {Wenhao Shu and Guojing Liao and Wenbin Qian},
  doi          = {10.1016/j.neucom.2025.131482},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131482},
  shortjournal = {Neurocomputing},
  title        = {Leveraging hyper-interval granules labeling and local mixed neighborhood entropy for semi-supervised feature selection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution learning with structured manifold subspace. <em>NEUCOM</em>, <em>657</em>, 131481. (<a href='https://doi.org/10.1016/j.neucom.2025.131481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, label distribution learning (LDL) has been proposed to solve the label ambiguity problem. To alleviate the overwhelming output space of LDL, most of the existing methods explore label correlations at a global or local level through common low-rank assumptions. However, the real-valued label description degrees have more complex correlations, making the low-rank assumption usually not hold. To tackle this issue, the proposed method leverages the label distribution manifold with structured subspaces, aiming for a more compact and accurate output space while preserving the high rank of the label distribution matrix. Specifically, a robust high-order correlation measure for label distributions is defined. Then, we simultaneously infer model parameters and conduct the label subspace clustering through the maximum correlation entropy (MCE) regularization to achieve mutual enhancement. It is further proven that the resulting label correlation matrix exhibits a block-diagonal structure under the assumption of independent subspaces. Extensive experiments on widely used benchmark datasets demonstrate the clear advantages of our proposed algorithm over state-of-the-art LDL methods. The code is accessible at https://github.com/yan-yp/LDL-MCE .},
  archive      = {J_NEUCOM},
  author       = {Yaping Yan and Yunlong Tang and Yongxin Jiang and Songlin Du},
  doi          = {10.1016/j.neucom.2025.131481},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131481},
  shortjournal = {Neurocomputing},
  title        = {Label distribution learning with structured manifold subspace},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-boundary awareness of shared categories for source-free universal domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131473. (<a href='https://doi.org/10.1016/j.neucom.2025.131473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Universal Domain Adaptation (SF-UniDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data or prior knowledge of cross-domain category shifts. Existing methods focus on distinguishing target-private unknown samples and assigning pseudo-labels to known samples across the entire label space, including both shared and source-private categories as pseudo-labels, for self-training. However, this data-aware pseudo-labeling approach could mistakenly assign known samples to either source-private or target-private categories, making it sensitive to category shifts and potentially introducing errors or mislabeling. In this paper, we propose Double-boundary Awareness Domain Adaptation (DADA), a class-aware framework that partitions the target domain pseudo-label space into shared, potential source-private, and target-private categories. By labeling target-private samples as unknown and filtering out misassigned source-private samples, DADA enhances the quality of target samples and the reliability of pseudo-labels. To achieve this, we introduce Double-bounded Shared Categories Refinement (DSCR) module, which refines shared classes by identifying both source- and target-private categories based on prior class probabilities and the entropy distribution. Additionally, we incorporate Class-Aware Discriminative Learning (CADL) to enhance discrimination between shared and target-private samples across domains. Experiments on four benchmarks demonstrate the effectiveness of DADA, with overall H-score gains of 8.2 % in the OPDA scenario on Digit dataset and accuracy gains of 10.6 % in the PDA scenario on VisDA dataset. Code is available at: https://github.com/W2Wzj/DADA .},
  archive      = {J_NEUCOM},
  author       = {Zhijing Wang and Ji Guo and Xu Sun and Yi Luo and Aiguo Chen},
  doi          = {10.1016/j.neucom.2025.131473},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131473},
  shortjournal = {Neurocomputing},
  title        = {Double-boundary awareness of shared categories for source-free universal domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGN: Stochastic guidance network for sim-to-real generalization. <em>NEUCOM</em>, <em>657</em>, 131468. (<a href='https://doi.org/10.1016/j.neucom.2025.131468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant domain differences between synthetic data and real data are a challenging problem for current domain generalized segmentation networks. Therefore, this paper proposes a stochastic guidance network (SGN) for sim-to-real generalization that includes the category reweighting strategy, Multi-scale Feature Fusion Guidance (MSFFG) module and multiple style perturbation modules, which improves the issues caused by the imbalance of the source domain’s sample categories as well as large domain gap. Experimental results show that our SGN can effectively enhance the model’s generalization ability to unseen data. In terms of mean intersection over union (mIoU) metric, compared with SOTA, the SGN improves by 3.86 % and 2.05 % respectively on two real scene-enhanced datasets(Rain_Cityscapes, Foggy_Cityscapes), and an average improvement of 1.48 % on four conventional datasets (BDD100k, Cityscapes, Mapillary, Synthia). Our project can be found at https://githubcom/leo-lab-511/SGN.},
  archive      = {J_NEUCOM},
  author       = {Yao Li and Jinlong Shi and Yun Cui and Dan Xu and Wei Teng and Yan Jiang},
  doi          = {10.1016/j.neucom.2025.131468},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131468},
  shortjournal = {Neurocomputing},
  title        = {SGN: Stochastic guidance network for sim-to-real generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IncGridDBC: Incremental density-based clustering with grid partitioning on streaming data. <em>NEUCOM</em>, <em>657</em>, 131460. (<a href='https://doi.org/10.1016/j.neucom.2025.131460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is a well-established algorithm, recognized for its ability to discover arbitrarily shaped clusters and detect noise. However, it suffers from a fundamental computational bottleneck in dynamic environments, as new object insertions require reprocessing the entire dataset. This paper proposes a novel method, Incremental Density-Based Clustering with a Grid Graph Structure (IncGridDBC), to address this limitation. The key idea is a grid graph structure, where nodes correspond exclusively to non-empty grid cells that contain objects. This grid graph structure abstracts complex object-level relationships into efficient cell-level connections, enabling IncGridDBC to rapidly identify a minimal subset of potentially affected regions upon a new object insertion. The cluster update process is thereby confined exclusively to this minimal subset, an approach that avoids full dataset scans and significantly reduces computational costs. Importantly, this efficiency gain is not based on approximation; the proposed method guarantees that the final clustering results are identical to those produced by a full re-execution of the standard DBSCAN algorithm. In extensive experiments on six real-world datasets with up to 78 dimensions, IncGridDBC achieved a speedup factor of up to 60 times compared to competing state-of-the-art incremental density-based clustering methods. This experimental validation establishes IncGridDBC as a practical and robust solution for high-performance, real-time analytics in dynamic environments such as the Internet of Things (IoT) and manufacturing.},
  archive      = {J_NEUCOM},
  author       = {Tserenpurev Chuluunsaikhan and Jeong-Hun Kim and Fei Hao and Jong-Hyeok Choi and Aziz Nasridinov},
  doi          = {10.1016/j.neucom.2025.131460},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131460},
  shortjournal = {Neurocomputing},
  title        = {IncGridDBC: Incremental density-based clustering with grid partitioning on streaming data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disjointed representation learning for better fall recognition. <em>NEUCOM</em>, <em>657</em>, 131451. (<a href='https://doi.org/10.1016/j.neucom.2025.131451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preprocessing video frames to extract the human ROIs has been widely adopted in many fall recognition tasks, demonstrating improved results compared to approaches that use raw frames. Nonetheless, these methods have limitations because the preprocessing is not optimized alongside the fall events classifier. This leads to high dependence on the quality of preprocessed results and consequently, limited generalization for the classifier in complex environments. In this study, we introduce Disjointed Representation Networks (DisJRNet) as a unified method that is capable of learning a general strategy for separating human and background components. We note that our method only needs raw frames without additional preprocessing steps to obtain human ROIs. DisJRNet first explicitly disjoints convolutional feature maps into two independent components “human” and “background”, and then reassembles them. This enables the model to learn the human-background separation process to obtain a balanced representation, which is useful for recognizing fall events as a result. Also, as the proposed model optimizes feature-level human ROI localization along with the classifier, our model learns more general representations about fall-related movements than existing approaches that use preprocessed data. In experiments, we applied our method to R(2+1)D, which is one of the variants of 3D convolutional neural networks, and achieved state-of-the-art performance on fall video benchmark datasets. Furthermore, by comparing Grad-CAMs, we observe that our model effectively separates the two components while paying more attention to the actual movements related to fall events and reducing background influence as intended.},
  archive      = {J_NEUCOM},
  author       = {Hosang Yu and Sangwook Kim and Byungeun Shon and Jungrae Cho and Dongwon Woo and Ho Young Chung and Sungmoon Jeong},
  doi          = {10.1016/j.neucom.2025.131451},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131451},
  shortjournal = {Neurocomputing},
  title        = {Disjointed representation learning for better fall recognition},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers. <em>NEUCOM</em>, <em>657</em>, 131449. (<a href='https://doi.org/10.1016/j.neucom.2025.131449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oblivious Transfer (OT) is crucial in various security protocols, as it serves as a privacy-preserving and secure communication protocol. However, traditional OT protocols often necessitate complex encryption algorithms and involve intricate steps. Given the rapid advancements in artificial intelligence, it is imperative to explore the potential of artificial neural networks in simplifying OT protocols while still meeting stringent security and privacy requirements. To this need, we introduce the Adv ersarial O blivious T ransfer (AdvOT) protocol, which integrates OT with the adversarial learning mechanism of Generative Adversarial Network (GAN). Our approach involves training a neural network model to learn encryption techniques through end-to-end adversarial training, thereby eliminating the reliance on specific algorithms. The AdvOT protocol comprises two phases. Firstly, a Random Oblivious Transfer (ROT) protocol is employed to generate and distribute keys based on the CKKS homomorphic encryption algorithm. Subsequently, neural networks are introduced to replace specific symmetric encryption algorithms and encrypt the messages to be transferred. These neural networks undergo training using the adversarial learning mechanism to develop a symmetric encryption algorithm. Furthermore, to enhance the model, attack networks with varying capabilities are created, resulting in a more secure encryption algorithm capable of withstanding multiple attackers. Experimental results demonstrate that the execution speed of the CKKS-based ROT algorithm is significantly faster compared to the BFV and Paillier algorithms. Moreover, in adversarial network models with multiple attackers, the decryption accuracy for the recipient approaches 100 %, while the accuracy or classification error rate for attackers is approximately 50 %. These findings indicate that the proposed method effectively safeguarded communication between parties from interception.},
  archive      = {J_NEUCOM},
  author       = {Yuke Wang and Zhentian Zhong and Ninghao Liu and Xiaohui Li and Junfeng Wang},
  doi          = {10.1016/j.neucom.2025.131449},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131449},
  shortjournal = {Neurocomputing},
  title        = {AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study. <em>NEUCOM</em>, <em>657</em>, 131440. (<a href='https://doi.org/10.1016/j.neucom.2025.131440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving partial differential equations (PDEs) with discontinuous solutions—such as shock waves in multiphase viscous flow in porous media—is critical for a wide range of scientific and engineering applications, as they represent sudden changes in physical quantities. Physics-Informed Neural Networks (PINNs), an approach proposed for solving PDEs, encounter significant challenges when applied to such systems. Accurately solving PDEs with discontinuities using PINNs requires specialized techniques to ensure effective solution accuracy and numerical stability. Various methods have been developed to address the challenges of modeling discontinuities within the PINNs framework. This work reviews and benchmarks these approaches across problems of varying complexity, categorizing them into three broad groups, influencing solution accuracy differently. (1) Physics-modification (PM) methods improve accuracy by modifying the system’s physics, such as adding artificial viscosity or enforcing entropy constraints. (2) Loss and training modification (LM) techniques focus on regularizing the loss landscape, often by refining the loss term in high-error regions. (3) Architecture-modification (AM) approaches, on the other hand, propose advanced network designs to handle discontinuities better. A benchmarking study was conducted on two multiphase flow problems in porous media: the classic Buckley-Leverett (BL) problem and a fully coupled system of equations involving shock waves but with varying levels of solution complexity. The findings show that PM and LM approaches can provide accurate solutions for the BL problem by effectively addressing the infinite gradients associated with shock occurrences. In contrast, AM methods failed to effectively resolve the shock waves. When applied to fully coupled PDEs (with more complex loss landscapes), the generalization error in the solutions quickly increased, highlighting the need for ongoing innovation. This study provides a comprehensive review of existing techniques for managing PDE discontinuities using PINNs, offering information on their strengths and limitations. The results underscore the necessity for further research to improve PINNs’ ability to handle complex discontinuities, particularly in more challenging problems with complex loss landscapes. This includes problems involving higher dimensions or multiphysics systems, where current methods often struggle to maintain accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jassem Abbasi and Ameya D. Jagtap and Ben Moseley and Aksel Hiorth and Pål Østebø Andersen},
  doi          = {10.1016/j.neucom.2025.131440},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131440},
  shortjournal = {Neurocomputing},
  title        = {Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting. <em>NEUCOM</em>, <em>657</em>, 131422. (<a href='https://doi.org/10.1016/j.neucom.2025.131422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose SparseSCIGaussian, a novel method for achieving high-quality novel view synthesis under sparse input conditions. Previous methods often rely heavily on depth or neural priors, which can lead to generalization challenges and significant quality degradation on complex datasets. These limitations arise primarily from the insufficient scene information available in sparse regular images. To overcome these issues, our approach utilizes images captured through Snapshot Compressive Imaging (SCI) as input. SCI-captured images inherently encode richer scene information compared to regular images, thereby substantially improving the quality of novel view synthesis under sparse input conditions. Moreover, SCI images can be conveniently captured using a software-implemented encoder, making them as accessible as traditional images. Experimental results demonstrate that our method improves 2.65 dB (13.04 %) in PSNR compared to previous methods, and further exhibits the inherent advantages of using SCI images for sparse input novel view synthesis.},
  archive      = {J_NEUCOM},
  author       = {Haoyuan He and Xuan Wang and Nanning Zheng and Caigui Jiang},
  doi          = {10.1016/j.neucom.2025.131422},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131422},
  shortjournal = {Neurocomputing},
  title        = {SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RehearMixup: Improving rehearsal-based continual learning. <em>NEUCOM</em>, <em>657</em>, 131404. (<a href='https://doi.org/10.1016/j.neucom.2025.131404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks often suffer from catastrophic forgetting when learning new tasks, leading to the loss of previously acquired knowledge. To address this issue, rehearsal-based methods have emerged, which involve storing a subset of data from previous tasks and accessing it during the learning of new tasks. Current rehearsal-based methods focus on selecting representative samples to store in memory. However, there is a considerable lack of exploration of how to exploit the data at hand and consider the correlation between tasks or between past and new knowledge to improve performance. Therefore, we propose a simple yet effective approach named RehearMixup that adapts the Mixup technique into rehearsal-based methods, which synthesizes new samples for learning by interpolating data from past or current tasks. Specifically, we introduce three strategies, namely Cross-Mixup , Intra-Memory-Mixup , and Intra-Current-Mixup , based on the inherent characteristics of rehearsal-based methods - involving the memory and new tasks. Through empirical evaluations under various benchmark scenarios, we compare our approach against different rehearsal-based baselines. The results demonstrate that ours, particularly Intra-Current-Mixup , improves accuracy, backward transfer, forward transfer, and enhances the model’s robustness.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Kaiyuan Qi and Dong Wu and Guoqiang Wu and Yilong Yin},
  doi          = {10.1016/j.neucom.2025.131404},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131404},
  shortjournal = {Neurocomputing},
  title        = {RehearMixup: Improving rehearsal-based continual learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A zero-shot high-performance fire detection framework based on large language models. <em>NEUCOM</em>, <em>657</em>, 131403. (<a href='https://doi.org/10.1016/j.neucom.2025.131403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire detection is crucial for minimizing economic damage and safeguarding human lives. Existing methods, including advanced AI and ML techniques, face challenges such as detecting small fires in complex environments and relying on extensive labeled data for training. This paper proposes a novel zero-shot fire detection framework leveraging large language models (LLMs) and contrastive learning-based image–text pre-training models. The framework introduces an enhanced self-attention mechanism for optimizing image embeddings, diverse prompt generation using GPT-3.5 for improved generalization, and a dynamic threshold calculation method based on statistical analysis to enhance detection accuracy and reliability. The proposed method is tested on the public FLAME dataset and a self-collected dataset. Experimental results demonstrate that the proposed method outperforms state-of-the-art models in detecting small fires within complex backgrounds, achieving better detection performance without the need for any training data. This study highlights the potential of zero-shot learning in fire detection and provides a promising solution for real-world fire detection applications.},
  archive      = {J_NEUCOM},
  author       = {Hongyang Zhao and Yi Liu and Yuhang Han and Xingdong Li and Yanan Guo and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131403},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131403},
  shortjournal = {Neurocomputing},
  title        = {A zero-shot high-performance fire detection framework based on large language models},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hetero-MoE by attention: Three-plus tasks learning solver. <em>NEUCOM</em>, <em>657</em>, 131333. (<a href='https://doi.org/10.1016/j.neucom.2025.131333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) stands as a promising sub-field of machine learning, aiming to simultaneously tackle multiple tasks. By leveraging shared representations and structures across diverse tasks, MTL models often exhibit higher data efficiency compared to single-task models across various domains, including recommender system applications, multi-label classification and other AI applications. However, the efficacy of MTL models is sometimes hindered by the multi-causal task conflict problem. To address this challenge, existing research predominantly focuses on enhancing structural designs and the underlying optimizers. Nevertheless, these approaches often fall short in comprehensively mitigating task conflicts, especially in scenarios involving three or more tasks, such as recommender systems. When shared experts contend with excessive task-related information simultaneously, the effective filtration of potentially harmful knowledge becomes challenging. To this end, we propose a novel Heterogeneous Multi-Expert model with an attention layer, termed HMEA. HMEA introduces Heterogeneous Experts as shared experts to decompose signal connections among three or more tasks. Additionally, it integrates an attention layer to further decouple conflicts among mini-tasks within shared experts. The experiments and ablation studies on various standard and synthetic datasets illustrate the effectiveness of HMEA in alleviating the task conflict problem inherent in three-plus task learning systems.},
  archive      = {J_NEUCOM},
  author       = {Dandan Zhang and Guanqi Zeng and Haotian Wu and Hongwen Zhang and Zheng Ye and Yao Yang},
  doi          = {10.1016/j.neucom.2025.131333},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131333},
  shortjournal = {Neurocomputing},
  title        = {Hetero-MoE by attention: Three-plus tasks learning solver},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). T2-cGAN: A new modeling paradigm for joint DEM spatial interpolation and super-resolution reconstruction. <em>NEUCOM</em>, <em>657</em>, 131181. (<a href='https://doi.org/10.1016/j.neucom.2025.131181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital elevation model (DEM) has important application value in the fields of geographic information systems, earth sciences, and path planning. However, due to the limitations of high sampling costs and complex terrain, the acquired DEM data often have the problems such as missing sampling points and low resolution. Current solutions treat these issues as highly dependent linear series tasks, and sequentially perform spatial interpolation and super-resolution reconstruction operations, ignoring the correlation and complementarity between them, which leads to a significant difference between the super-resolution reconstruction results and the real terrain. To solve this problem, we proposed the end-to-end T2-cGAN (task transformer conditional generative adversarial network) by combining DEM spatial interpolation and super-resolution reconstruction tasks, which can directly generate high-quality and high-resolution reconstruction results from low-resolution DEM data that are undersampled and contain missing values. This model can make full use of the shared information in the process of spatial interpolation and super-resolution reconstruction, achieve efficient interaction and collaborative optimization of information, and provide a brand-new idea and method for solving the super-resolution reconstruction task of DEM data. Moreover, the experimental results demonstrate that our proposed T2-cGAN can interpolate and complete the DEM data without adding additional information, while also improving the spatial resolution by 4 times. This research not only provides a practical method for high-resolution DEM modeling in resource-constrained areas, but also offers a new idea for the intelligent processing of DEM data, which is of great value for applications such as geological disaster early warning and urban layout planning.},
  archive      = {J_NEUCOM},
  author       = {Ziqiang Huo and Jiabao Wen and Desheng Chen and Meng Xi and Jiachen Yang},
  doi          = {10.1016/j.neucom.2025.131181},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131181},
  shortjournal = {Neurocomputing},
  title        = {T2-cGAN: A new modeling paradigm for joint DEM spatial interpolation and super-resolution reconstruction},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="nn">NN - 66</h2>
<ul>
<li><details>
<summary>
(2026). Cascading size-dependent deep propagation (CADP): Addressing over-smoothing in graph few-shot dermatology classification. <em>NN</em>, <em>194</em>, 108154. (<a href='https://doi.org/10.1016/j.neunet.2025.108154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs play a critical role in capturing complex data relationships, particularly in few-shot learning tasks. However, one of the major challenges in graph-based models, such as Graph Neural Networks (GNNs), is the issue of over-smoothing, which diminishes the discriminative power of node representations. This problem arises when GNNs aggregate information from too large a neighborhood, leading to homogenization of node features. To overcome this limitation, we propose Cascading Size-Dependent Deep Propagation (CADP) , a novel approach designed to mitigate over-smoothing in graph-based few-shot learning, with a particular focus on improving skin disease classification. The model constructs the graph by employing a convolutional neural network (CNN) to extract feature representations from a small set of support and query images, where the nodes represent the extracted features, and the edges reflect the similarity between them. To improve feature representation and prevent over-smoothing, the model decouples the feature propagation process from the neural network to avoid repeated nonlinear transformations that lead to over-smoothing, enabling deeper information flow while preserving discriminative features. Then the initial support labels are integrated with the early prediction labels of query images, which are generated by a Multi-Layer Perceptron (MLP). Furthermore, this aggregated data is optimized through deep label propagation, which leverages the underlying graph structure to enhance classification accuracy. The propagation depths are controlled by the hyperparameters K 1 and K 2 , which are determined based on graph size, to regulate how extensively features and labels are propagated. We evaluate our approach on three dermatology datasets: ISIC 2018, Derm7pt, and SD-198, achieving 78.3 %, 79.29 %, and 91.92 % accuracy, respectively, in the 2-way 5-shot setting. CADP outperforms existing methods on all datasets, demonstrating its effectiveness in skin disease classification.},
  archive      = {J_NN},
  author       = {Abdulrahman Noman and Zou Beiji and Chengzhang Zhu and Mohammed Al-Habib and Ahmed Alasri},
  doi          = {10.1016/j.neunet.2025.108154},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108154},
  shortjournal = {Neural Netw.},
  title        = {Cascading size-dependent deep propagation (CADP): Addressing over-smoothing in graph few-shot dermatology classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-spectral multi-order gated aggregation network with bidirectional interactive fusion for hyperspectral image classification. <em>NN</em>, <em>194</em>, 108152. (<a href='https://doi.org/10.1016/j.neunet.2025.108152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks (CNNs) have made significant strides in hyperspectral image classification (HSIC) tasks by contextualizing the convolutional kernels as global as possible. However, as the kernel sizes increase, encoding multi-order feature interactions becomes less efficient. Furthermore, self-attention mechanisms and convolutional operations can only handle global and local features independently, resulting in overly complex or simplified interactions. To overcome these limitations, in this work, we propose a novel HSIC framework called the Spatial-Spectral Multi-order Gated Aggregation Network with Bidirectional Interaction Fusion (SS-MoGAN). The proposed SS-MoGAN method integrates simple yet powerful convolutions and gated aggregations into a compact module, facilitating efficient feature extraction and adaptive contextual processing. Specifically, the spatial aggregation (SpaAg) and spectral aggregation (SpeAg) blocks guide the model to explicitly capture the interactions between low- and high-order features within the spatial and spectral dimensions. The bidirectional interaction fusion (BIF) blocks further integrate structural information through a bidirectional cross-attention mechanism, enhancing the representation of fine-grained details. Extensive experiments on three hyperspectral benchmark datasets demonstrate that the proposed SS-MoGAN method outperforms other state-of-the-art methods in HSIC applications. The source code for this work is available at https://github.com/szq0816/SS-MoGAN_HSIC .},
  archive      = {J_NN},
  author       = {Mingzhu Tai and Zhenqiu Shu and Songze Tang and Zhengtao Yu},
  doi          = {10.1016/j.neunet.2025.108152},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108152},
  shortjournal = {Neural Netw.},
  title        = {Spatial-spectral multi-order gated aggregation network with bidirectional interactive fusion for hyperspectral image classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep adaptive fusion network with multimodal neuroimaging information for MDD diagnosis: An open data study. <em>NN</em>, <em>194</em>, 108151. (<a href='https://doi.org/10.1016/j.neunet.2025.108151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroimaging offers powerful evidence for the automated diagnosis of major depressive disorder (MDD). However, discrepancies across imaging modalities hinder the exploration of cross-modal interactions and the effective integration of complementary features. To address this challenge, we propose a supervised Deep Adaptive Fusion Network (DAFN) that fully leverages the complementarity of multimodal neuroimaging information for the diagnosis of MDD. Specifically, high- and low-frequency features are extracted from the images using a customized convolutional neural network and multi-head self-attention encoders, respectively. A modality weight adaptation module dynamically adjusts the contribution of each modality during training, while a progressive information reinforcement training strategy reinforces multimodal fusion features. Finally, the performance of the DAFN is evaluated on both the open-access dataset and the recruited dataset. The results demonstrate that DAFN achieves competitive performance in multimodal neuroimaging fusion for the diagnosis of MDD. The source code is available at: https://github.com/TTLi1996/DAFN .},
  archive      = {J_NN},
  author       = {Tongtong Li and Kai Li and Ziyang Zhao and Qi Sun and Xinyan Zhang and Zhijun Yao and Jiansong Zhou and Bin Hu},
  doi          = {10.1016/j.neunet.2025.108151},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108151},
  shortjournal = {Neural Netw.},
  title        = {Deep adaptive fusion network with multimodal neuroimaging information for MDD diagnosis: An open data study},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSA-LR: Enhancing multi-scale temporal dynamics in multivariate time series forecasting with low-rank self-attention. <em>NN</em>, <em>194</em>, 108150. (<a href='https://doi.org/10.1016/j.neunet.2025.108150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting multivariate time series requires effectively capturing intricate temporal dependencies across diverse scales. Existing deep learning models, while promising, often fall short in this regard. Recurrent architectures like LSTMs struggle with long-range dependencies crucial for multi-scale modeling, while standard Transformers, despite employing attention mechanisms, fail to explicitly differentiate the importance of distinct periodicities, treating all time steps within a fixed window with similar relevance. This limitation hinders their ability to leverage the rich hierarchical structure of real-world time series, particularly in long-term forecasting scenarios. This paper introduces MSA-LR (Multi-Scale Self-Attention with Low-Rank Approximation), a novel architecture explicitly designed to capture multi-scale temporal dynamics. MSA-LR leverages a learnable scale weight matrix and low-rank approximations to directly model the influence of different temporal granularities (e.g., hourly, daily, weekly). This approach not only allows for fine-grained control over multi-scale interactions but also significantly reduces computational complexity compared to standard self-attention, enabling efficient processing of long time series. Empirical evaluations on diverse datasets, including electricity load, traffic flow, and air quality, demonstrate that MSA-LR achieves competitive performance compared to state-of-the-art methods, exhibiting notable improvements in long-term forecasting accuracy. Further analysis reveals MSA-LR's ability to discern and leverage periodic patterns at various resolutions, confirming its effectiveness in capturing the rich multi-scale temporal structure of real-world time series data.},
  archive      = {J_NN},
  author       = {Jie Sun and Zhilin Sun and Zhongshan Chen and Mengyang Dong and Xiaozheng Wang and Changwei Chen and Hao Zheng and Xiangjun Zhao},
  doi          = {10.1016/j.neunet.2025.108150},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108150},
  shortjournal = {Neural Netw.},
  title        = {MSA-LR: Enhancing multi-scale temporal dynamics in multivariate time series forecasting with low-rank self-attention},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforcement learning with formation energy feedback for material diffusion models. <em>NN</em>, <em>194</em>, 108146. (<a href='https://doi.org/10.1016/j.neunet.2025.108146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models are emerging as foundation tools for the discovery of new materials with remarkable efficiency. Existing works introduce physical constraints during the generation process of diffusion models to improve the quality of the generated crystals. However, it is difficult to accurately capture the distribution of stable crystal material structures, given the complex periodic crystal structure and the limited available crystal material data, even with the incorporation of symmetries and other domain-specific knowledge. Thus, these models still struggle to achieve a high success rate in producing stable crystal materials. To further improve the stability of generative crystal materials, we propose a novel fine-tuning framework RLFEF. We formulate the material diffusion process as a Markov Decision Process with formation energy serving as rewards. Moreover, we prove that optimizing the expected return in reinforcement learning is equivalent to applying policy gradient updates to a diffusion model. Additionally, we prove that the fine-tuned model adheres to the unique symmetry of crystal materials. Extensive experiments are conducted on three real-world datasets. The results show that our model achieves state-of-the-art performance on most tasks related to property optimization, ab initio generation, crystal structure prediction, and material generation.},
  archive      = {J_NN},
  author       = {Jiao Huang and Qianli Xing and Jinglong Ji and Bo Yang},
  doi          = {10.1016/j.neunet.2025.108146},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108146},
  shortjournal = {Neural Netw.},
  title        = {Reinforcement learning with formation energy feedback for material diffusion models},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hölder network for improved adversarial robustness. <em>NN</em>, <em>194</em>, 108145. (<a href='https://doi.org/10.1016/j.neunet.2025.108145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A small Lipschitz constant can help improve robustness and generalization by restricting the sensitivity of the model to input perturbations. However, overly aggressive constraints may also limit the network’s ability to approximate complex functions. In this paper, we propose the Hölder network, a novel architecture utilizing α -rectified power units ( α -RePU). This framework generalizes Lipschitz-constrained networks by enforcing α -Hölder continuity. We theoretically prove that α -RePU networks are universal approximators of Hölder continuous functions, thereby offering greater flexibility than models with hard Lipschitz constraints. Empirical results show that the Hölder network achieves comparable accuracy and superior adversarial robustness against a wide range of attacks (e.g., PGD and l ∞ ) on both image classification and tabular data benchmarks.},
  archive      = {J_NN},
  author       = {Dazhi Zhao and Haiyan Li and Qin Luo and Wenguang Hu},
  doi          = {10.1016/j.neunet.2025.108145},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108145},
  shortjournal = {Neural Netw.},
  title        = {Hölder network for improved adversarial robustness},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A one-layer recurrent neural network for robust linear programming subject to l∞ norm uncertainty. <em>NN</em>, <em>194</em>, 108144. (<a href='https://doi.org/10.1016/j.neunet.2025.108144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization problems subject to norm uncertainty appear in numerous applications in various fields such as engineering, logistics, and finance. Despite its importance, robust optimization algorithms face significant computational challenges for solving high-dimensional problems, limiting their practical use. This paper presents a neurodynamic approach to mitigate these challenges by transforming the robust linear programming to a non-smooth convex optimization through parameter elimination. A one-layer projection neural network with proven stability and convergence is proposed to solve the non-smooth optimization problem. The effectiveness of this approach is validated based on simulations of numerical examples and applications in reactor design and wastewater treatment.},
  archive      = {J_NN},
  author       = {Jin Hu and Keying Zhou and Jun Wang},
  doi          = {10.1016/j.neunet.2025.108144},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108144},
  shortjournal = {Neural Netw.},
  title        = {A one-layer recurrent neural network for robust linear programming subject to l∞ norm uncertainty},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Implicit graph neural networks with flexible propagation operators. <em>NN</em>, <em>194</em>, 108143. (<a href='https://doi.org/10.1016/j.neunet.2025.108143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the capability to capture high-order information of nodes and reduce memory consumption, implicit graph neural networks have become an explored hotspot in recent years. However, these implicit graph neural networks are limited by the static topology, which makes it difficult to handle heterophilic graph-structured data. Furthermore, the existing methods inspired by optimization problem are limited by the explicit structure of graph neural networks, which makes it difficult to set an appropriate number of network layers to solve optimization problems. To address these issues, we propose an implicit graph neural network with flexible propagation operators in this paper. From the optimization objective function, we derive an implicit message passing formula with flexible propagation operators. Compared to the static operator, the proposed method that joints the dynamic semantic and topology of data is more applicable to heterophilic graphs. Moreover, the proposed model performs a fixed-point iterative process for the optimization of the objective function, which implicitly adjusts the number of network layers without requiring sufficient prior knowledge. Extensive experiment results demonstrate the superiority of the proposed model.},
  archive      = {J_NN},
  author       = {Yueyang Pi and Yang Huang and Yongquan Shi and Fuhai Chen and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108143},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108143},
  shortjournal = {Neural Netw.},
  title        = {Implicit graph neural networks with flexible propagation operators},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph-patchformer: Patch interaction transformer with adaptive graph learning for multivariate time series forecasting. <em>NN</em>, <em>194</em>, 108140. (<a href='https://doi.org/10.1016/j.neunet.2025.108140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) forecasting plays a pivotal role in the digitalization and intelligent development of modern society, while previous MTS forecasting methods based on deep learning often rely on capturing intra-series dependencies for modeling, neglecting the structural information within MTS and failing to consider inter-series local dynamic dependencies. Although some approaches utilize multi-scale representation learning to capture inter-series dynamic dependencies at different time scales, they still require additional multi-scale feature fusion modules to output the multi-scale representation of final forecasting results. In this paper, we propose a novel deep learning framework called Graph-Patchformer, which leverages structural encodings to reflect the structural information within MTS while capturing intra-series dependencies and inter-series local dynamic dependencies using the Patch Interaction Blocks we proposed. Specifically, Graph-Patchformer embeds structural encodings into MTS to reflect the inter-series relationships and temporal variations within the MTS. The embedded data is subsequently fed into the Patch Interaction Blocks through a patching operation. Within the Patch Interaction Blocks, the multi-head self-attention mechanism and adaptive graph learning module are employed to capture intra-series dependencies and inter-series local dynamic dependencies. In this way, Graph-Patchformer not only facilitates interactions between different patches within a single series but also enables cross-time-window interactions between patches of different series. The experimental results show that the Graph-Patchformer outperforms the state-of-the-art approaches and exhitits significant forecasting performance compared to several state-of-the-art methods across various real-world benchmark datasets. The code will be available at this repository: https://github.com/houchunyiPhd/Graph-Patchformer/tree/main},
  archive      = {J_NN},
  author       = {Chunyi Hou and Yongchuan Yu and Jinquan Ji and Siyao Zhang and Xumeng Shen and Jianzhuo Yan},
  doi          = {10.1016/j.neunet.2025.108140},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108140},
  shortjournal = {Neural Netw.},
  title        = {Graph-patchformer: Patch interaction transformer with adaptive graph learning for multivariate time series forecasting},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-augmented entity alignment: An unsupervised and training-free framework. <em>NN</em>, <em>194</em>, 108139. (<a href='https://doi.org/10.1016/j.neunet.2025.108139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment (EA) is a fundamental task in knowledge graph (KG) integration, aiming to identify equivalent entities across different KGs for a unified and comprehensive representation. Recent advances have explored pre-trained language models (PLMs) to enhance the semantic understanding of entities, achieving notable improvements. However, existing methods face two major limitations. First, they rely heavily on human-annotated labels for training, leading to high computational costs and poor scalability. Second, some approaches use large language models (LLMs) to predict alignments in a multi-choice question format, but LLM outputs may deviate from expected formats, and predefined options may exclude correct matches, leading to suboptimal performance. To address these issues, we propose LEA, an LLM-augmented entity alignment framework that eliminates the need for labeled data and enhances robustness by mitigating information heterogeneity at both embedding and semantic levels. LEA first introduces an entity textualization module that transforms structural and textual information into a unified format, ensuring consistency and improving entity representations. It then leverages LLMs to enrich entity descriptions, enhancing semantic distinctiveness. Finally, these enriched descriptions are encoded into a shared embedding space, enabling efficient alignment through text retrieval techniques. To balance performance and computational cost, we further propose a selective augmentation strategy that prioritizes the most ambiguous entities for refinement. Experimental results on both homogeneous and heterogeneous KGs demonstrate that LEA outperforms existing models trained on 30 % labeled data, achieving a 30 % absolute improvement in Hit@1 score. As LLMs and text embedding models advance, LEA is expected to further enhance EA performance, providing a scalable and robust paradigm for practical applications. The code and dataset can be found at https://github.com/Longmeix/LEA .},
  archive      = {J_NN},
  author       = {Meixiu Long and Jiahai Wang and Junxiao Ma and Jianpeng Zhou and Siyuan Chen},
  doi          = {10.1016/j.neunet.2025.108139},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108139},
  shortjournal = {Neural Netw.},
  title        = {LLM-augmented entity alignment: An unsupervised and training-free framework},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Image restoration driven by dual-scale prior. <em>NN</em>, <em>194</em>, 108138. (<a href='https://doi.org/10.1016/j.neunet.2025.108138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of advanced imaging technologies, the demand for high quality images in various fields has increased. However, image degradation due to noise, data loss, and other factors persistently hinder image quality. Image restoration (IR) is a critical task in computer vision, aiming to recover original images from degraded observations. Traditional non-learning prior based methods offer flexibility and interpretability but often yield sub-optimal results due to limited representational capacity. In contrast, learning prior based counterparts produce superior performance but suffer from over-fitting and poor generalization to unseen degradations. In this paper, we introduce a novel dual-scale prior (DSP) model that integrates the flexibility strength of non-learning prior with the representation power of learning-based prior. Specifically, the DSP model employs a group-scale physical prior, leveraging non-local self-similarity (NSS) for jointly sparse and low-rank approximation. And an image-scale bias-free deep denoising prior for capturing external characteristics. These dual-scale priors complement each other by effectively preserving edges and removing noise, demonstrating robustness across various types of degradation. We then present DSPIR, an effective IR method by incorporating DSP into existing maximum a posteriori (MAP) principle. DSPIR is solved by alternating minimization and alternating direction method of multipliers. Extensive evaluations on both synthetic and real data demonstrate that DSPIR achieves better performance in image denoising and inpainting compared to state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Weimin Yuan and Cai Meng and Xiangzhi Bai},
  doi          = {10.1016/j.neunet.2025.108138},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108138},
  shortjournal = {Neural Netw.},
  title        = {Image restoration driven by dual-scale prior},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WideTopo: Improving foresight neural network pruning through training dynamics preservation and wide topologies exploration. <em>NN</em>, <em>194</em>, 108136. (<a href='https://doi.org/10.1016/j.neunet.2025.108136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foresight neural network pruning methods have garnered significant attention due to their potential to save computational resources. Recent advancements in this field are predominantly categorized into saliency score-based and graph theory-based methods. The former assesses the sensitivity of pruning parameter connections concerning specific metrics, while the latter aims to identify sub-networks characterized by sparse yet highly connected graph structures. However, recent research suggests that relying exclusively on saliency scores may result in deep but narrow sub-networks, while graph theory-based methods may be unsuitable for neural networks requiring pre-trained parameters for initialization, particularly in transfer learning scenarios. We hypothesize that preserving the training dynamics of sub-networks during pruning, along with exploring network structures with wide topology, can facilitate the identification of structurally stable sub-networks with improved post-training performance. Motivated by this, we propose WideTopo, which integrates Neural Tangent Kernel (NTK) theory with Implicit Target Alignment (ITA) in neural networks to capture the training dynamics of sub-networks. Furthermore, it employs a density-aware saliency score decay strategy and a repeated mask restoration strategy to retain more effective nodes, thereby sustaining the width of each layer within the sub-networks. We conducted extensive validations using CNN-based and ViT-based models on representative image classification and semantic segmentation datasets under both random and pre-trained initialization settings. The effectiveness and applicability of our method have been validated on diverse network architectures at various model density rates, showing competitive post-training performance compared with other existing baselines. Our code is publicly available at https://github.com/Memoristor/WideTopo .},
  archive      = {J_NN},
  author       = {Changjian Deng and Jian Cheng and Yanzhou Su and Zeyu An and Zhiguo Yang and Ziying Xia and Yijie Zhang and Shiguang Wang},
  doi          = {10.1016/j.neunet.2025.108136},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108136},
  shortjournal = {Neural Netw.},
  title        = {WideTopo: Improving foresight neural network pruning through training dynamics preservation and wide topologies exploration},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DePoint: Improving rotation robustness of 3D point cloud analysis via decreasing entropy. <em>NN</em>, <em>194</em>, 108135. (<a href='https://doi.org/10.1016/j.neunet.2025.108135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, achieving rotation robustness in point cloud analysis is crucial due to the unpredictable orientations of 3D objects. While recent advancements in rotation robustness typically rely on auxiliary modules to align rotated objects, precisely aligning object orientations remains challenging given the vast space of possible rotations. In this work, we investigate the impact of rotation on point clouds, revealing that random rotations significantly increase the joint entropy of point clouds and semantic labels—a key factor leading to degraded model performance on rotated datasets. To address this issue, we introduce DePoint, a simple yet effective rotation enhancement method that decreases entropy by aligning the spatial distribution of rotated point cloud representations with semantic information. Specifically, a Siamese point cloud encoder processes differently oriented views of an object with a shared task head, ensuring semantic consistency in the learned representations. A minimal auxiliary classifier enforces linear separability into these representations. Notably, DePoint can be seamlessly integrated into existing point cloud models without introducing additional parameters during inference. Experimental results demonstrate that DePoint significantly enhances the rotation robustness of various point cloud models in 3D object classification and segmentation.},
  archive      = {J_NN},
  author       = {Lu Shi and Gaoyun An and Yigang Cen and Yansen Huang and Fei Gan},
  doi          = {10.1016/j.neunet.2025.108135},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108135},
  shortjournal = {Neural Netw.},
  title        = {DePoint: Improving rotation robustness of 3D point cloud analysis via decreasing entropy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression. <em>NN</em>, <em>194</em>, 108134. (<a href='https://doi.org/10.1016/j.neunet.2025.108134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have demonstrated remarkable performance in the field of novel view synthesis (NVS). However, their high computational cost limits practical applicability. The 3D Gaussian Splatting (3DGS) method offers a significant improvement in rendering efficiency, enabling real-time rendering through its explicit representations. Nevertheless, its substantial storage requirements pose challenges for complex scenes and resource-constrained devices. Existing methods aim to achieve storage compression through redundant point pruning, spherical harmonics adjustment, and vector quantization. However, point pruning methods often compromise geometric details in complex structures, while vector quantization approaches fail to capture feature relationships effectively, resulting in texture degradation and geometric boundary blurring. Although anchor point representations partially address storage concerns, their sparse representation limits compression efficiency. These limitations become particularly evident in scenes with intricate textures and complex lighting conditions. To ensure optimal compression ratios while maintaining high fidelity in Gaussian scenarios, this paper proposes an Attention-Aware Adaptive Codebook Gaussian Splatting (AAC-GS) method for efficient storage compression. The approach dynamically adjusts the size of the codebook to optimize storage efficiency and incorporates an attention mechanism to capture feature contextual relationships, thereby enhancing reconstruction quality. Additionally, a Generative Adversarial Network (GAN) is employed to mitigate quantization losses, achieving a balance between compression rate and visual fidelity. Experimental results demonstrate that AAC-GS achieves an average compression ratio of approximately 40× while maintaining high reconstruction quality, showcasing its potential for multi-scene applications.},
  archive      = {J_NN},
  author       = {Fang Wan and Jianhang Zhang and Tianyu Li and Guangbo Lei and Li Xu and Zhiwei Ye},
  doi          = {10.1016/j.neunet.2025.108134},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108134},
  shortjournal = {Neural Netw.},
  title        = {AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive knowledge selection in dialogue systems: Accommodating diverse knowledge types, requirements, and generation models. <em>NN</em>, <em>194</em>, 108133. (<a href='https://doi.org/10.1016/j.neunet.2025.108133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective knowledge-grounded dialogue systems rely heavily on accurate knowledge selection. This paper begins with an innovative new perspective that categorizes research on knowledge selection based on when knowledge is selected in relation to response generation: pre-, joint-, and post-selection. Among these, pre-selection is of great interest nowadays because they endeavor to provide sufficiently relevant knowledge inputs for downstream response generation models in advance. This reduces the burden of learning, adjusting, and interpreting for the subsequent response generation models, particularly for Large Language Models. Current knowledge pre-selection methods, however, still face three significant challenges: how to cope with different types of knowledge, adapt to the various knowledge requirements in different dialogue contexts, and adapt to different generation models. To resolve the above challenges, we propose ASK, an adaptive knowledge pre-selection method. It unifies various types of knowledge, scores their relevance and contribution to generating desired responses, and adapts the knowledge pool size to ensure the optimal amount is available for generation models. ASK is enhanced by leveraging rewards for selecting appropriate knowledge in both quality and quantity, through a reinforcement learning framework. We perform exhaustive experiments on two benchmarks (WoW and OpenDialKG) and get the following conclusions: 1) ASK has excellent knowledge selection capabilities on diverse knowledge types and requirements. 2) ASK significantly enhances the performance of various downstream generation models, including ChatGPT and GPT-4o. 3) The lightweight improvement of ASK saves 40 % of the computational consumption. Code is available at https://github.com/AnonymousCode32213/ASK .},
  archive      = {J_NN},
  author       = {Yao Zhang and Lang Qin and Zhongtian Bao and Hongru Liang and Jun Wang and Zhenglu Yang and Zhe Sun and Andrzej Cichocki},
  doi          = {10.1016/j.neunet.2025.108133},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108133},
  shortjournal = {Neural Netw.},
  title        = {Adaptive knowledge selection in dialogue systems: Accommodating diverse knowledge types, requirements, and generation models},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints. <em>NN</em>, <em>194</em>, 108130. (<a href='https://doi.org/10.1016/j.neunet.2025.108130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a fixed-time learning-based dynamic event-triggered control framework to address the optimal tracking control problem in robotic systems with the prescribed performance constraints. In many practical scenarios, the states of robotic systems are often subject to performance constraints imposed by structural characteristics and task requirements. To address this issue, prescribed performance control (PPC) theory is employed to ensure performance state constraints and construct an unconstrained tracking error system. Subsequently, a critic-only adaptive dynamic programming (ADP) control framework is designed to approximate the optimal control law for the transformed unconstrained system. Furthermore, in the design of critic neural network (NN), a novel fixed-time convergence (FTC) weight update law based on concurrent learning (CL) techniques is proposed, which guarantees the fixed-time convergence of weight estimation error under relaxed persistent excitation (PE) condition. Throughout the controller design, a dynamic event-triggered mechanism is adopted to reduce the number of sampling instances and computational resources. Meanwhile, the stability of the closed-loop system under this mechanism is rigorously proven. Finally, the effectiveness of the proposed method is demonstrated through simulation results and comparative analysis.},
  archive      = {J_NN},
  author       = {Zhinan Peng and Xingyu Zhang and Zhuo Xia and Lin Hao and Linpu He and Hong Cheng},
  doi          = {10.1016/j.neunet.2025.108130},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108130},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CSTSINR: Improving temporal continuity via convolutional structured implicit neural representations for time series anomaly detection. <em>NN</em>, <em>194</em>, 108129. (<a href='https://doi.org/10.1016/j.neunet.2025.108129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection plays a crucial role in identifying significant deviations from expected behavior. Implicit Neural Representation (INR) has been explored for time series modeling due to its ability to learn continuous functions. The inherent spectral bias of INRs, which prioritizes low-frequency signal fitting, further enables the detection of high-frequency anomalies. However, current INR-based approaches demonstrate limited capability in representing complex temporal patterns, particularly when the normal data itself contains significant high-frequency components. To address these challenges, we propose CSTSINR, a novel anomaly detection model that integrates the structured feature map and convolutional mechanisms with the INR continuous function. By leveraging a structured feature map and convolutional layers, CSTSINR addresses the limitations of directive prediction of all parameters and point-wise query processing, providing improved modeling of temporal continuity and enhanced anomaly detection. Our extensive experiments demonstrate that CSTSINR outperforms existing state-of-the-art methods across ten benchmark datasets, highlighting its superior ability to detect anomalies, particularly in high-frequency or complex time series data.},
  archive      = {J_NN},
  author       = {Ke Liu and Mengxuan Li and Jiajun Bu and Hongwei Wang and Haishuai Wang},
  doi          = {10.1016/j.neunet.2025.108129},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108129},
  shortjournal = {Neural Netw.},
  title        = {CSTSINR: Improving temporal continuity via convolutional structured implicit neural representations for time series anomaly detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation. <em>NN</em>, <em>194</em>, 108128. (<a href='https://doi.org/10.1016/j.neunet.2025.108128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal analysis can provide complementary information and significantly aid in the early diagnosis and intervention of Alzheimer’s Disease (AD). However, the issue of missing modalities presents a major challenge, as most methods that rely on complete multi-modal data become infeasible. The most advanced approaches to addressing missing modalities typically use generative models, but these often neglect the importance of modality-specific features, leading to biased predictions and poor performance. Inspired by this limitation, we propose a Modality Disentanglement and Specific Features Distillation Network (MDSFD-Net) for AD diagnosis with missing modality, which consists of a disentanglement-based imputation module (DI module) and a specific features distillation module (SFD module). In the DI module, we introduce a novel spatial-channel modality disentanglement learning scheme that is first used to disentangle modality-specific features, along with a shared constrain objective to learn modality-shared features, which are used for imputing missing modality features. To address the specific features of the missing modality, the SFD module is designed to transfer the specific features from complete modality in the teacher network to the incomplete modality in the student network. A regularized knowledge distillation (R-KD) mechanism is incorporated to mitigate the impact of incorrect predictions from the teacher network. By leveraging modality-shared features imputation and modality-specific features distillation, our model can effectively learn sufficient information for classification even if some modalities are missing. Extensive experiments on ADNI dataset demonstrate the superiority of our proposed MDSFD-Net over state-of-the-art methods in missing modality situations.},
  archive      = {J_NN},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neunet.2025.108128},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108128},
  shortjournal = {Neural Netw.},
  title        = {MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spiking neural networks for EEG signal analysis: From theory to practice. <em>NN</em>, <em>194</em>, 108127. (<a href='https://doi.org/10.1016/j.neunet.2025.108127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate and efficient information processing of the human brain, driven by spiking neural interactions, has led to the development of spiking neural networks (SNNs) as a cutting-edge neural network paradigm. Unlike traditional artificial neural networks (ANNs) that use continuous values, SNNs emulate the brain’s spiking mechanisms, offering enhanced temporal information processing and computational efficiency. This review addresses the critical gap between theoretical advancements and practical applications of SNNs in EEG signal analysis. We provide a comprehensive examination of recent SNN methodologies and their application to EEG signals, highlighting their potential benefits over conventional deep learning approaches. The review encompasses foundational knowledge of SNNs, detailed implementation strategies for EEG analysis, and challenges inherent to SNN-based methods. Practical guidance is provided through step-by-step instructions and accessible code available on GitHub, aimed at facilitating researchers’ adoption of these techniques. Additionally, we explore emerging trends and future research directions, emphasizing the potential of SNNs to advance brain-computer interfaces and neurofeedback systems. This paper serves as a valuable resource for bridging the gap between theoretical developments in SNNs and their practical implementation in EEG signal analysis.},
  archive      = {J_NN},
  author       = {Siqi Cai and Zheyuan Lin and Xiaoli Liu and Wenjie Wei and Shuai Wang and Malu Zhang and Tanja Schultz and Haizhou Li},
  doi          = {10.1016/j.neunet.2025.108127},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108127},
  shortjournal = {Neural Netw.},
  title        = {Spiking neural networks for EEG signal analysis: From theory to practice},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-based diffusion generator for efficient sampling of boltzmann distributions. <em>NN</em>, <em>194</em>, 108126. (<a href='https://doi.org/10.1016/j.neunet.2025.108126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sampling from Boltzmann distributions, particularly those tied to high dimensional and complex energy functions, poses a significant challenge in many fields. In this work, we present the Energy-Based Diffusion Generator (EDG), a novel approach that integrates ideas from variational autoencoders and diffusion models. EDG uses a decoder to generate Boltzmann-distributed samples from simple latent variables, and a diffusion-based encoder to estimate the Kullback-Leibler divergence to the target distribution. Notably, EDG is simulation-free, eliminating the need to solve ordinary or stochastic differential equations during training. Furthermore, by removing constraints such as bijectivity in the decoder, EDG allows for flexible network design. Through empirical evaluation, we demonstrate the superior performance of EDG across a variety of sampling tasks with complex target distributions, outperforming existing methods.},
  archive      = {J_NN},
  author       = {Yan Wang and Ling Guo and Hao Wu and Tao Zhou},
  doi          = {10.1016/j.neunet.2025.108126},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108126},
  shortjournal = {Neural Netw.},
  title        = {Energy-based diffusion generator for efficient sampling of boltzmann distributions},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck. <em>NN</em>, <em>194</em>, 108125. (<a href='https://doi.org/10.1016/j.neunet.2025.108125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are prominent for their effectiveness in processing graph-structured data for semi-supervised node classification tasks. Most existing GNNs perform message passing directly based on the observed graph structure. However, in real-world scenarios, the observed structure is often suboptimal due to multiple factors, significantly degrading the performance of GNNs. To address this challenge, we first conduct an empirical analysis showing that different graph structures significantly impact empirical risk and classification performance. Motivated by our observations, we propose a novel method named T rade-off G raph S tructure L earning (TGSL), guided by the multifaceted Graph Information Bottleneck (GIB) principle based on Mutual Information (MI). The key idea behind TGSL is to learn a minimal sufficient graph structure that minimizes empirical risk while maintaining performance. Specifically, we introduce global feature augmentation to capture the structural roles of nodes, and global structure augmentation to uncover global relationships between nodes. The augmented graphs are then processed by structure estimators with different parameters for refinement and redefinition, respectively. Additionally, we innovatively leverage multifaceted GIB as the optimization objective by maximizing the MI between the labels and the representation derived from the final structure, while constraining the MI between this representation and that based on the redefined structures. This trade-off helps avoid capturing irrelevant information from the redefined structures and enhances the final representation for node classification. We conduct extensive experiments across a range of datasets under clean and attacked conditions. The results demonstrate the outstanding performance and robustness of TGSL over state-of-the-art baselines.},
  archive      = {J_NN},
  author       = {Shuangjie Li and Baoming Zhang and Jianqing Song and Gaoli Ruan and Chongjun Wang and Junyuan Xie},
  doi          = {10.1016/j.neunet.2025.108125},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108125},
  shortjournal = {Neural Netw.},
  title        = {TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving few-shot relation classification with multi-scale hierarchical prototype learning. <em>NN</em>, <em>194</em>, 108124. (<a href='https://doi.org/10.1016/j.neunet.2025.108124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot relation classification aims to distinguish different relation classes from extremely limited annotated data. Most existing methods primarily use prototype networks to construct a prototypical representation, classifying the instance by comparing its similarity to each prototype. Despite achieving promising results, the prototypes derived solely from limited support instances are often inaccurate due to constraints in feature extraction capabilities. Moreover, they ignore the different hierarchical levels of relational information, which can provide more effective guidance for classification. In this paper, we propose a novel m ulti-sc a le hie r arch i cal pr o totype (Mario) learning method that captures relational interaction information at three levels: inter-set, inter-class and intra-class, enhancing the model’s understanding of global semantic information and helping it distinguish subtle differences between classes. Additionally, we incorporate relational descriptive information to reduce the impact of textual expression diversity, enabling the model to emulate the human cognitive process in understanding variation. Extensive experiments conduct on the FewRel dataset demonstrate the effectiveness of our proposed model. In particular, it achieves accuracy rates of 92.52 %/95.33 %/85.46 %/91.33 % under four common few-shot settings. Notably, in the critical 5-way and 10-way 1-shot settings, it outperforms the strongest baseline by 2.87 % and 4.29 %.},
  archive      = {J_NN},
  author       = {Haijia Bi and Lu Liu and Hai Cui and Shengyue Liu and Ridong Han and Jiayu Han and Tao Peng},
  doi          = {10.1016/j.neunet.2025.108124},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108124},
  shortjournal = {Neural Netw.},
  title        = {Improving few-shot relation classification with multi-scale hierarchical prototype learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Planning forward: Deep incremental hashing by gradually defrosting bits. <em>NN</em>, <em>194</em>, 108123. (<a href='https://doi.org/10.1016/j.neunet.2025.108123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep incremental hashing can generate hash codes incrementally for new classes, while keeping the existing ones unchanged. Existing methods typically allocate fixed code lengths to all classes, causing the entire Hamming space occupied by existing classes, thus failing to prepare models for future extensions. This significantly limits the ability to effectively accommodate new classes. Beyond that, it is inefficient in computation and storage to use all bits for encoding a few classes in the early sessions. This paper presents B it D efrosting Deep I ncremental H ashing (BDIH) to tackle these problems. Our key insight is to map the classes into a small subspace by freezing most hash bits during the first session, which reserves adequate space for future classes. This allows subsequent sessions to map new classes into progressively expanding subspaces by defrosting a portion of the frozen bits. Specifically, we propose a bit-defrosting code learning framework, which includes a bit-defrosting center generation part and a center-based bit-defrosting code learning part. The former part generates hash centers as learning objectives in expanding subspaces while the latter part learns globally discriminative hash codes with the guidance of hash centers and preserves the backward compatibility between the updated model and previously stored codes. As a result, our method achieves comparable performance on old classes using fewer bits while reserving more space for new ones. Extensive experiments demonstrate that BDIH outperforms existing methods regarding retrieval accuracy and storage efficiency in long-sequence incremental learning scenarios.},
  archive      = {J_NN},
  author       = {Qinghang Su and Dayan Wu and Chenming Wu and Bo Li and Weiping Wang},
  doi          = {10.1016/j.neunet.2025.108123},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108123},
  shortjournal = {Neural Netw.},
  title        = {Planning forward: Deep incremental hashing by gradually defrosting bits},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning unlocks geometric insights for dataset pruning. <em>NN</em>, <em>194</em>, 108122. (<a href='https://doi.org/10.1016/j.neunet.2025.108122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset pruning aims at selecting a subset of the data so that the model trained on the subset performs comparably to the one trained on the full dataset. In the era of big data, unsupervised pruning of the dataset can alleviate the issue of the expensive labeling process from the beginning. Existing methods sort and select instances by well-designed importance metrics, while the unsupervised ones commonly regard representation learning as a black box employed to get embeddings, with its properties remaining insufficiently explored for dataset pruning. In this study, we revisit self-supervised Contrastive Learning by observing the learned embedding manifold, introducing Curvature Estimation to characterize the geometrical properties of the manifold. The statistical results reveal that the embedding distribution of instances on manifold surfaces is not uniform. Based on this observation, we propose an unsupervised dataset pruning strategy by performing downsampling in geometric areas with high instance density, namely KITTY sampling. Extensive experiments demonstrate that our proposed methods have achieved leading performances on CV dataset pruning compared to the baselines. Code is available at https://github.com/Frostland12138/KITTY .},
  archive      = {J_NN},
  author       = {Hongjia Xu and Sheng Zhou and Zhuonan Zheng and Ning Ma and Jiawei Chen and Jiajun Bu},
  doi          = {10.1016/j.neunet.2025.108122},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108122},
  shortjournal = {Neural Netw.},
  title        = {Contrastive learning unlocks geometric insights for dataset pruning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Offline-to-online reinforcement learning with efficient unconstrained fine-tuning. <em>NN</em>, <em>194</em>, 108120. (<a href='https://doi.org/10.1016/j.neunet.2025.108120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning provides the capability to learn a policy only from pre-collected datasets, but its performance is often limited by the quality of the offline dataset and the coverage of the state-action space. Offline-to-online reinforcement learning is promising to address these limitations and achieve high sample efficiency by integrating the advantages of both offline and online learning paradigms. However, existing methods typically struggle to adapt to online learning and improve the performance of pre-trained policies due to the distributional shift and conservative training. To address these issues, we propose an efficient unconstrained fine-tuning framework that removes conservative constraints on the policy during fine-tuning, allowing thorough exploration of state-action pairs not covered by the offline data. This framework leverages three key techniques: dynamics representation learning, layer normalization, and increasing the update frequency of the value network to improve sample efficiency and mitigate value function estimation bias caused by the distributional shift. Dynamics representation learning accelerates fine-tuning by capturing meaningful features, layer normalization bounds Q -value to suppress catastrophic value function divergence, and increasing the update frequency of the value network enhances the sample efficiency and reduces value function estimation bias. Extensive experiments on the D4RL benchmark demonstrate that our algorithm outperforms state-of-the-art offline-to-online reinforcement learning algorithms across various tasks with minimal online interactions.},
  archive      = {J_NN},
  author       = {Jun Zheng and Runda Jia and Shaoning Liu and Ranmeng Lin and Dakuo He and Fuli Wang},
  doi          = {10.1016/j.neunet.2025.108120},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108120},
  shortjournal = {Neural Netw.},
  title        = {Offline-to-online reinforcement learning with efficient unconstrained fine-tuning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AutoSGRL: Automated framework construction for self-supervised graph representation learning. <em>NN</em>, <em>194</em>, 108119. (<a href='https://doi.org/10.1016/j.neunet.2025.108119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated machine learning (AutoML) is a promising solution for building a machine learning framework without human assistance and has attracted significant attention throughout the computational intelligence research community. Although there has been an emerging interest in graph neural architecture search, current research focuses on the specific design of semi-supervised or supervised graph neural networks. Motivated by this, we propose a novel method that enables the automatic construction of flexible self-supervised graph representation learning frameworks for the first time as far as we know, referred to as AutoSGRL. Based on existing self-supervised graph contrastive learning methods, AutoSGRL establishes a framework search space for self-supervised graph representation learning, which encompasses data augmentation strategies and proxy tasks for constructing graph contrastive learning frameworks, and the hyperparameters required for model training. Then, we implement an automatic search engine based on genetic algorithms, which constructs multiple self-supervised graph representation learning frameworks as the initial population. By simulating the process of biological evolution including selection, crossover, and mutation, the search engine iteratively evolves the population to identify high-performed frameworks and optimal hyperparameters. Empirical studies demonstrate that our AutoSGRL achieves comparative or even better performance than state-of-the-art manual-designed self-supervised graph representation learning methods and semi-supervised graph neural architecture search methods.},
  archive      = {J_NN},
  author       = {Yu Xie and Yu Chang and Ming Li and A.K. Qin and Xialei Zhang},
  doi          = {10.1016/j.neunet.2025.108119},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108119},
  shortjournal = {Neural Netw.},
  title        = {AutoSGRL: Automated framework construction for self-supervised graph representation learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation. <em>NN</em>, <em>194</em>, 108118. (<a href='https://doi.org/10.1016/j.neunet.2025.108118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vascular morphology plays a crucial role in diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and stylistic augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to apply random photometric augmentations and introduce uncertainty perturbations, enriching the stylistic diversity of fundus images and further improving the model’s robustness and generalization across varying imaging conditions. Our framework, which employs a DeepLabv3+ model with a MobileNetV2 backbone as its segmentation network, has been rigorously evaluated on four challenging datasets—DRIVE, CHASEDB1, HRF, and STARE—achieving Dice Similarity Coefficient (DSC) of 78.45%, 78.62%, 72.66% and 82.17%, respectively, with an average DSC of 77.98%. These results demonstrate that our method surpasses existing approaches, validating its effectiveness and highlighting its potential for clinical application in automated retinal vessel analysis.},
  archive      = {J_NN},
  author       = {Bo Liu and Yudong Zhang and Shuihua Wang and Siyue Li and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108118},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108118},
  shortjournal = {Neural Netw.},
  title        = {DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ToBaFu: Topology-based fusion model for classification of two-dimensional cancer images. <em>NN</em>, <em>194</em>, 108117. (<a href='https://doi.org/10.1016/j.neunet.2025.108117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical images play a pivotal role in disease diagnosis. Numerous studies on cancer image analysis focus on end-to-end deep neural networks, neglecting the analysis of global topological features in images. In cancer diagnosis, pathological images frequently display structures like holes or loops that are absent in healthy images, highlighting the benefits of topological analysis of images. In our study, we employ persistent homology (PH) to extract topological features from two-dimensional cancer images. Then, we propose a topology-based model (Topo) for image classification by implementing a shallow neural module following the feature extraction. More importantly, we integrate the Topo model with an end-to-end enhanced ResNet architecture to develop a novel topology-based fusion model (ToBaFu), aimed at enhancing diagnostic performance and model robustness. The proposed ToBaFu model achieves remarkable performance across three cancer image datasets: 99.98 % accuracy and F1-score on the LC-25000 lung and colon cancer histopathological dataset, 99.60 % accuracy and F1-score on the CRC-5000 colorectal cancer histological dataset, and 99.80 % accuracy with 99.83 % F1-score on the BUS-250 breast ultrasound dataset.},
  archive      = {J_NN},
  author       = {Yuqing Xing and Haodong Chen and Quan Zheng},
  doi          = {10.1016/j.neunet.2025.108117},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108117},
  shortjournal = {Neural Netw.},
  title        = {ToBaFu: Topology-based fusion model for classification of two-dimensional cancer images},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution. <em>NN</em>, <em>194</em>, 108116. (<a href='https://doi.org/10.1016/j.neunet.2025.108116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data distribution discrepancy across datasets is one of the major obstacles hindering the improvement of the accuracy of cross-domain adaptive detection of medical images. To address this challenge, we propose a novel lightweight cross-modal adaptive detection module named LCA-Med (LCaM). The proposed module boasts a lightweight structure and a minimalistic parameter count, thereby facilitating its integration into the anterior segment of a diverse array of foundational and downstream networks. It is adept at serving as a feature preprocessor, proficiently extracting pertinent information regrading pathologies from a array of images (image modality) produced through varied medical imaging techniques, all guided by the input of prompts (text modality). We also propose a novel cross-modal medical image adaptive detection method, LCA-Med CNX (LCaM-CNX), and a novel cross-domain adaptive detection training paradigm that incorporates generated dataset groups, an attention module, and a meta-heuristic algorithm. Experimental results on six medical image datasets compared with ten state-of-the-art methods demonstrate that the LCaM-CNX trained following the proposed paradigm achieves the best performance on five datasets and competitive performance on the other dataset. Notably, our method outperforms the state-of-the-art methods more when the data distribution is more imbalanced.},
  archive      = {J_NN},
  author       = {Xiang Li and Long Lan and Husam Lahza and Shaowu Yang and Shuihua Wang and Yong Liang and Hudan Pan and Wenjing Yang and Hengzhu Liu and Yudong Zhang},
  doi          = {10.1016/j.neunet.2025.108116},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108116},
  shortjournal = {Neural Netw.},
  title        = {LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual causal inference for robust visual question answering. <em>NN</em>, <em>194</em>, 108115. (<a href='https://doi.org/10.1016/j.neunet.2025.108115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) systems have seen remarkable progress with the incorporation of multimodal data. However, their performance is still hampered by biases ingrained in language and vision modalities, frequently resulting in subpar generalization. In this study, we introduce a novel counterfactual causal framework (CC-VQA). This framework utilizes Counterfactual Sample Synthesis (CSS) and causal inference to tackle cross-modality biases. Our approach innovatively employs a strategy based on causal graphs, which effectively disentangles spurious correlations in multimodal data. This ensures a balanced and precise multimodal reasoning process, enabling the model to make more accurate and unbiased decisions. Moreover, we propose a contrastive loss mechanism. By contrasting the embeddings of positive and negative samples, this mechanism significantly enhances the robustness of VQA models. Additionally, we develop a robust training strategy that improves both the visual-explainable and question-sensitive capabilities of these models. Our experimental evaluations on benchmark datasets, such as VQA-CP v2 and VQA v2, demonstrate substantial improvements in bias mitigation and overall accuracy. The proposed CC-VQA framework outperforms state-of-the-art methods, highlighting its effectiveness in enhancing the performance of VQA systems.},
  archive      = {J_NN},
  author       = {Wei Li and Zhixin Li and Fuyun Deng and Kun Zeng and Canlong Zhang},
  doi          = {10.1016/j.neunet.2025.108115},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108115},
  shortjournal = {Neural Netw.},
  title        = {Counterfactual causal inference for robust visual question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A domain-specific cross-lingual semantic alignment learning model for low-resource languages. <em>NN</em>, <em>194</em>, 108114. (<a href='https://doi.org/10.1016/j.neunet.2025.108114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual semantic alignment models facilitate the sharing and utilization of multilingual domain-specific data (e.g., medical, legal), offering cost-effective solutions for improving low-resource language tasks. However, existing methods are challenged by parallel data scarcity, semantic space heterogeneity, morphological complexity, and weak robustness-particularly for agglutinative languages. Therefore, this paper proposes CLWKD, a cross-lingual mapping and knowledge distillation framework. CLWKD leverages domain-specific pretrained models from high-resource languages as teachers and integrates multi-granularity alignment matrices with limited parallel data to guide cross-lingual knowledge transfer. CLWKD jointly learns multi-granularity semantic alignment mapping matrices at the token, word, and sentence levels from general-domain data. It eases domain data scarcity and helps bridge structural gaps caused by morphological and syntactic differences. To alleviate data sparsity and out-of-vocabulary issues in agglutinative languages, multilingual embedding sharing and morphological segmentation strategies are introduced. To improve the stability of unsupervised mapping training, generator pretraining is introduced and further combined with high-confidence word and sentence pairs to optimize the mapping matrix.To preserve alignment with fewer parameters, a parameter recycling and embedding bottleneck design is adopted. Experiments across the medical, legal, and educational domains on Mongolian-Chinese and Korean-Chinese language pairs demonstrate the effectiveness of CLWKD in three cross-lingual tasks.},
  archive      = {J_NN},
  author       = {Yurong Wang and Min Lin and Qitu Hu and Shuangcheng Bai and Yanling Li and Longjie Bao},
  doi          = {10.1016/j.neunet.2025.108114},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108114},
  shortjournal = {Neural Netw.},
  title        = {A domain-specific cross-lingual semantic alignment learning model for low-resource languages},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inference of hidden common driver dynamics by anisotropic self-organizing neural networks. <em>NN</em>, <em>194</em>, 108113. (<a href='https://doi.org/10.1016/j.neunet.2025.108113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the Anisotropic Self-Organizing Map (ASOM), a novel neural network-based approach for inferring hidden common drivers in nonlinear dynamical systems from observed time series. Grounded in topological theorems, our method integrates time-delay embedding, intrinsic dimension estimation, and a new anisotropic training scheme for Kohonen’s self-organizing map, enabling the precise decomposition of attractor manifolds into autonomous and shared components of the dynamics. We validated ASOM through simulations involving chaotic maps, where two driven systems were influenced by a hidden nonlinear driver. The inferred time series showed a strong correlation with the actual hidden common driver, unlike the observed systems. We further compared our reconstruction performance against several established methods for identifying shared features in time series, including PCA, kernel PCA, ICA, dynamical component analysis, canonical correlation analysis, deep canonical correlation analysis, traditional self-organizing map, and recent recurrence-based approaches. Our results demonstrate ASOM’s superior accuracy and robustness in recovering latent dynamics, providing a powerful tool for unsupervised learning of hidden causal structures in complex systems.},
  archive      = {J_NN},
  author       = {Zsigmond Benkő and Marcell Stippinger and Attila Bencze and Fülöp Bazsó and András Telcs and Zoltán Somogyvári},
  doi          = {10.1016/j.neunet.2025.108113},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108113},
  shortjournal = {Neural Netw.},
  title        = {Inference of hidden common driver dynamics by anisotropic self-organizing neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the theoretical expressive power of graph transformers for solving graph problems. <em>NN</em>, <em>194</em>, 108112. (<a href='https://doi.org/10.1016/j.neunet.2025.108112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformers have become the dominant neural architecture in the fields of natural language processing and computer vision. The generalization of Transformers to graphs, so-called Graph Transformers, have recently emerged as a promising alternative to the successful message passing Graph Neural Networks (MPNNs). While the expressive power of MPNNs has been intensively studied in the past years, that of Graph Transformers is still underexplored. Existing results mostly rely on the employed structural/positional encodings and not on the pure architecture itself. However, gaining an understanding of the strengths and limitations of Graph Transformers would be very useful both for the scientific community and the practitioners. In this paper, we derive a connection between Graph Transformers and the Congested clique , a popular model in distributed computing. This connection allows us to translate theoretical results for different graph problems from the latter to the former. We show that under certain conditions, Graph Transformers with depth 2 are Turing universal. We also show that there exist Graph Transformers that can solve problems which cannot be solved by MPNNs. We empirically investigate whether Graph Transformers and MPNNs with depth 2 can solve graph problems on some molecular datasets. Our results demonstrate that Graph Transformers can generally address the underlying tasks, while MPNNs are incapable of learning any information about the graph.},
  archive      = {J_NN},
  author       = {Giannis Nikolentzos and Dimitrios Kelesis and Michalis Vazirgiannis},
  doi          = {10.1016/j.neunet.2025.108112},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108112},
  shortjournal = {Neural Netw.},
  title        = {On the theoretical expressive power of graph transformers for solving graph problems},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A biologically plausible model of astrocyte-neuron networks in random and hub-driven connectivity. <em>NN</em>, <em>194</em>, 108111. (<a href='https://doi.org/10.1016/j.neunet.2025.108111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research studies in brain neural networks are highlighting the involvement of glial cells, in particular astrocytes, in synaptic modulation, memory formation, and neural synchronization, a role that has often been overlooked. Thus, theoretical models have begun incorporating astrocytes to better understand their functional impact. Additionally, the structural organization of neuron-neuron, astrocyte-neuron and astrocyte-astrocyte connections plays a crucial role in network dynamics. Starting from a recently published astrocyte-neuron network model with neuron-neuron random connectivity, we provide an extensive evaluation of this same model, focusing on astrocytic dynamics, neuron-astrocyte connectivity, and spatial distribution of inhibitory neurons. We propose refinements to the model with the aim of improving the biological plausibility of the above described characteristics of the model. To assess the interplay between astrocytes and network topology, we compare four configurations: neural networks with and without astrocytes, each under random and hub-driven connectivity. Simulations are conducted using the Brian2 simulator, providing insights into how astrocytes and structural heterogeneity jointly influence neural dynamics. Our findings contribute to a deeper understanding of neuron-glia interactions and the impact of network topology on astrocyte-neuron network dynamics. In particular, while finding an expected decrease of neural firing activity due to astrocyte calcium dynamics, we also found that hub-driven topology trigger a much higher firing rate with respect to the random topology, even having this last one a much higher number of neuron-neuron connections.},
  archive      = {J_NN},
  author       = {Giulia Salzano and Paolo Paradisi and Enrico Cataldo},
  doi          = {10.1016/j.neunet.2025.108111},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108111},
  shortjournal = {Neural Netw.},
  title        = {A biologically plausible model of astrocyte-neuron networks in random and hub-driven connectivity},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders. <em>NN</em>, <em>194</em>, 108110. (<a href='https://doi.org/10.1016/j.neunet.2025.108110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodevelopmental disorders exhibit highly similar behavioral characteristics in clinical assessments, heavily relying on subjective behavioral reports, leading to insufficient understanding of the neurobiological mechanisms behind inter-patient heterogeneity and symptom overlap between diseases. To address this issue, this study proposes a graph neural network framework that integrates neuroimaging data, focusing on three key problems: Firstly, enhance the nonlinear features in brain neural activity by introducing the Neurodynamics Rössler system. Transform raw static neural signals into simulated signals with nonlinear, temporal, and dynamic features, thereby more accurately reflecting the process of brain neural activity. Secondly, improve feature discrimination by integrating the spatial adjacency characteristics of local brain regions with the topological structure information of the global brain network to highlight key features. Thirdly, improve noise resistance and generalization ability. Introducing adaptive controllers and cross-site adversarial learning mechanisms, the interference of heterogeneous noise is effectively reduced. This study conducted experimental validation on data from neurodevelopmental disorders such as ADHD and ASD. The results indicate that this framework not only has advantages in classification accuracy but also possesses good interpretability, making it a promising tool for imaging biomarker research and auxiliary diagnosis.},
  archive      = {J_NN},
  author       = {Qiulei Han and Hongbiao Ye and Miaoshui Bai and Lili Wang and Yan Sun and Ze Song and Jian Zhao and Lijuan Shi and Zhejun Kuang},
  doi          = {10.1016/j.neunet.2025.108110},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108110},
  shortjournal = {Neural Netw.},
  title        = {MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State-flipped control design for the stabilization of probabilistic boolean control networks. <em>NN</em>, <em>194</em>, 108109. (<a href='https://doi.org/10.1016/j.neunet.2025.108109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilization is a fundamental issue in modern control theory. In the past decades, significant efforts have been invested in deriving necessary and sufficient conditions for verifying the global stabilization of probabilistic Boolean control networks (PBCNs). However, systematic methods and general criteria for exploring the local stabilization and determining the domain of attraction of PBCNs are still lacking in the existing literature. Motivated by this research gap, this paper investigates the local state feedback stabilization of PBCNs, including local finite-time state feedback stabilization with probability one (FTSFS) and local state feedback stabilization in distribution (SFSD). Firstly, a sequence of reachable sets with probability one is constructed, based on which, the largest domain of attraction is derived for the FTSFS of PBCNs by designing the state feedback controllers. Secondly, by constructing a sequence of reachable sets with positive probability, the largest domain of attraction is determined for the SFSD of PBCNs. Finally, when the largest domain of attraction is not the whole state space, the state-flipped control is designed to achieve the global FTSFS or SFSD of PBCNs via the largest domain of attraction.},
  archive      = {J_NN},
  author       = {Xinrong Yang and Haitao Li},
  doi          = {10.1016/j.neunet.2025.108109},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108109},
  shortjournal = {Neural Netw.},
  title        = {State-flipped control design for the stabilization of probabilistic boolean control networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability of large-scale probabilistic boolean networks via network aggregation. <em>NN</em>, <em>194</em>, 108108. (<a href='https://doi.org/10.1016/j.neunet.2025.108108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale probabilistic Boolean networks (LSPBNs) are a modeling tool used to simulate and analyze the dynamics of complex systems with uncertainty. However, due to its high computational complexity, previous research methods cannot be directly applied to study such systems. Inspired by network aggregation, this paper conducts network aggregation on LSPBNs to investigate its global stability with probability 1. It is worth mentioning that the stability conclusion proposed in this article holds for any form of network aggregation. First, the entire network is partitioned and the algebraic expressions for each subnetwork are given through the semi-tensor product of matrices. And then, a set of iterative formulas is constructed to describe and reflect the input-output coordination relationship among the subnetworks, and based on which, a sufficient condition for the global stability of LSPBNs is derived, greatly reducing computational complexity. The feasibilities of the proposed method and results are verified through examples.},
  archive      = {J_NN},
  author       = {Wen Liu and Shihua Fu and Jianjun Wang and Renato De Leone and Jianwei Xia},
  doi          = {10.1016/j.neunet.2025.108108},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108108},
  shortjournal = {Neural Netw.},
  title        = {Stability of large-scale probabilistic boolean networks via network aggregation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPC: Self-supervised point cloud completion. <em>NN</em>, <em>194</em>, 108107. (<a href='https://doi.org/10.1016/j.neunet.2025.108107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape incompleteness is a common issue in point clouds acquired by depth sensors. Point cloud completion aims to restore partial point clouds to their complete form. However, most existing point cloud completion methods rely on complete point clouds or multi-view information of the same object during training, which is not practical for real-world scenarios with high information acquisition costs. To overcome the above limitation, a self-supervised point cloud completion (SPC) method is proposed, which uses the training set consisting of only a single partial point cloud for each object. Specifically, an autoencoder-like network architecture that includes a two-step strategy is developed. First, a compression-reconstruction strategy is proposed to enable the network to learn the representation of complete point clouds from existing knowledge. Then, considering the potential problem of overfitting in self-supervised training, a global enhancement strategy is further designed to maintain the positional coherence of predicted points. Comprehensive experiments are conducted on the ScanNet, MatterPort3D, KITTI, and ShapeNet datasets. On real-world datasets, the unidirectional Chamfer distance (UCD) and the unidirectional Hausdorff distance (UHD) of the method are reduced by an average of 2.3 and 2.4, respectively, compared to the state-of-the-art method. In addition to its excellent completion capabilities, the proposed method has a positive impact on downstream tasks. In point cloud classification, applying the proposed method improves classification accuracy by an average of 14 %. Extensive experimental results demonstrate that the proposed SPC has a high practical value.},
  archive      = {J_NN},
  author       = {Jie Song and Xing Wu and Junfeng Yao and Qi Zhang and Chenhao Shang and Quan Qian and Jun Song},
  doi          = {10.1016/j.neunet.2025.108107},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108107},
  shortjournal = {Neural Netw.},
  title        = {SPC: Self-supervised point cloud completion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition. <em>NN</em>, <em>194</em>, 108106. (<a href='https://doi.org/10.1016/j.neunet.2025.108106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) integrates complementary information from both text and images to identify named entities within text. However, existing methods face three key issues: imbalanced handling of modality noise, the cascading effect of semantic mismatch, and information loss resulting from the lack of text dominance. To address these issues, this paper proposes a M ulti-stage I nteraction N etwork I nspired by G ene E diting for MNER (MINIGE-MNER). The core innovations of this method include: A gene knockout module based on the variational information bottleneck, which removes inferior genes (modality noise) from the text, raw image, and generated image features. This approach retains the superior genes, achieving balanced filtering of modality noise. A determination of gene recombination sites module that maximizes the mutual information between superior genes across modalities, reducing the spatial distance between them and ensuring precise, fine-grained semantic alignment. This helps to prevent the cascading effect of semantic mismatch. A text-guided gene recombination module that implements a “text-dominant, vision-supplementary” cross-modal fusion paradigm. This module dynamically filters out visual noise unrelated to the text while avoiding excessive reliance on visual information that could obscure the unique contextual information of the text, effectively mitigating information loss. Experimental results show that MINIGE-MNER achieves F1 scores of 76.45 % and 88.67 % on the Twitter-2015 and Twitter-2017 datasets, respectively, outperforming existing state-of-the-art methods by 0.83 % and 0.42 %. In addition, this paper presents comprehensive experiments that demonstrate the superiority of MINIGE-MNER and the effectiveness of its individual modules.},
  archive      = {J_NN},
  author       = {Bo Kong and Shengquan Liu and Liruizhi Jia and Yi Liang and Dongfang Han and Xu Zhang},
  doi          = {10.1016/j.neunet.2025.108106},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108106},
  shortjournal = {Neural Netw.},
  title        = {MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deceiving question-answering models: A hybrid word-level adversarial approach. <em>NN</em>, <em>194</em>, 108105. (<a href='https://doi.org/10.1016/j.neunet.2025.108105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning underpins most of the currently advanced natural language processing (NLP) tasks such as textual classification, neural machine translation (NMT), abstractive summarization and question-answering (QA). However, the robustness of the models, particularly QA models, against adversarial attacks is a critical concern that remains insufficiently explored. This paper introduces QA-Attack (Question Answering Attack), a novel word-level adversarial strategy that fools QA models. Our attention-based attack exploits the customized attention mechanism and deletion ranking strategy to identify and target specific words within contextual passages. It creates deceptive inputs by carefully choosing and substituting synonyms, preserving grammatical integrity while misleading the model to produce incorrect responses. Our approach demonstrates versatility across various question types, particularly when dealing with extensive long textual inputs. Extensive experiments on multiple benchmark datasets demonstrate that QA-Attack successfully deceives baseline QA models and surpasses existing adversarial techniques regarding success rate, semantics changes, BLEU score, fluency and grammar error rate.},
  archive      = {J_NN},
  author       = {Jiyao Li and Mingze Ni and Yongshun Gong and Wei Liu},
  doi          = {10.1016/j.neunet.2025.108105},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108105},
  shortjournal = {Neural Netw.},
  title        = {Deceiving question-answering models: A hybrid word-level adversarial approach},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified gradient regularization method for heterogeneous graph neural networks. <em>NN</em>, <em>194</em>, 108104. (<a href='https://doi.org/10.1016/j.neunet.2025.108104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks (HGNNs) are advanced deep learning methods widely applied for learning representations of heterogeneous graphs. However, they face challenges such as over-smoothing and non-robustness. Existing methods can mitigate these issues by applying gradient regularization to one of the three information dimensions: node, edge, or propagation message. However, these methods have problems such as unstable training, difficulty in parameter convergence, and inadequate utilization of heterogeneous information. We propose a novel gradient regularization method called Grug, which iteratively applies regularization to the gradients derived from both node type and message matrix during the message-passing process. A detailed theoretical analysis demonstrates its advantages in Stability and Diversity. Notably, Grug potentially exceeds the theoretical upper bounds set by DropMessage. In addition, Grug offers a unified gradient regularization framework that integrates the existing dropping and adversarial training methods, and provides theoretical guidance for their further optimization in different data and tasks. We validate Grug through extensive experiments on six public datasets, showing significant improvements in performance and effectiveness.},
  archive      = {J_NN},
  author       = {Xiao Yang and Xuejiao Zhao and Zhiqi Shen},
  doi          = {10.1016/j.neunet.2025.108104},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108104},
  shortjournal = {Neural Netw.},
  title        = {A unified gradient regularization method for heterogeneous graph neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-level graph contrastive learning for community value prediction. <em>NN</em>, <em>194</em>, 108103. (<a href='https://doi.org/10.1016/j.neunet.2025.108103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Value Prediction (CVP) is an important emerging task in the field of social commerce, which aims to predict the community values. However, due to the complex structure of communities and individuals, previous graph machine learning methods have struggled to adequately address this task. This study endeavors to bridge this gap by introducing a cross-level graph contrastive learning method called Cross-level Community Contrastive Learning (CCCL) to handle such subgraph-level tasks. Specifically, we generate two views that describe different levels of social connections, the augmented node-level graph and the community-level graph that is produced by graph coarsening. Subsequently, CCCL captures the mutual information between the two views through a cross-view contrastive loss. The learned embeddings utilize community and node information at various levels, making them capable of handling subgraph-level regression problems. To the best of our knowledge, CCCL is the first graph contrastive learning method that addresses the CVP problem. We theoretically show that CCCL maximizes a lower bound of the mutual information shared between node-view and community-view representations. Experimental results demonstrate that our proposed approach is highly effective for the CVP task, outperforming both end-to-end and self-supervised baselines. Furthermore, our model also exhibits robust resistance to edge perturbation attacks.},
  archive      = {J_NN},
  author       = {Wenjie Yang and Shengzhong Zhang and Zengfeng Huang},
  doi          = {10.1016/j.neunet.2025.108103},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108103},
  shortjournal = {Neural Netw.},
  title        = {Cross-level graph contrastive learning for community value prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training. <em>NN</em>, <em>194</em>, 108102. (<a href='https://doi.org/10.1016/j.neunet.2025.108102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation, which aims to provide accurate descriptions of both normal and abnormal regions, has been attracting growing research attention. Recently, despite considerable progress, data-driven deep-learning based models still face challenges in capturing and describing the abnormalities, due to the data bias problem. To address this problem, we propose to generate radiology reports via the Visual-Semantic Ambivalence-Aware Network (VSANet) and the Focal Self-Critical Sequence Training (FSCST). In detail, our VSANet follows the encoder-decoder framework. In the encoder part, we first deploy a multi-grained abnormality extractor and a visual extractor to capture both semantic and visual features from given images, and then introduce a Parameter Shared Dual-way Encoder (PSDwE) to delve into the inter- and intra-relationships among these features. In the decoder part, we propose the Visual-Semantic Ambivalence-Aware (VSA) module to generate the abnormality-aware visual features to mitigate the data bias problem. In implementation, our VSA introduces three sub-modules: Dual-way Attention (DwA), introduced to generate both the word-related visual and semantic features; Dual-way Attention on Attention (DwAoA), designed to mitigate redundant information; Score-based Feature Fusion (SFF), constructed to fuse the visual and semantic features in an ambivalence way. We further introduce the FSCST to enhance the overall performance of our VSANet by allocating more attention toward difficult samples. Experimental results demonstrate that our proposal achieves superior performance on various evaluation metrics. Source code have released at https://github.com/SKD-HPC/VSANet .},
  archive      = {J_NN},
  author       = {Xiulong Yi and You Fu and Enxu Bi and Jianguo Liang and Hao Zhang and Jianzhi Yu and Qianqian Li and Rong Hua and Rui Wang},
  doi          = {10.1016/j.neunet.2025.108102},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108102},
  shortjournal = {Neural Netw.},
  title        = {Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative representation learning via attention-enhanced contrastive learning for short text clustering. <em>NN</em>, <em>194</em>, 108101. (<a href='https://doi.org/10.1016/j.neunet.2025.108101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has gained significant attention in short text clustering, yet it has an inherent drawback of mistakenly identifying samples from the same category as negatives and separating them in the feature space (i.e., the false negative separation problem). To generate discriminative representations for short text clustering, we propose a novel clustering method, called Discriminative Representation learning via A ttention- E nhanced C ontrastive L earning for Short Text Clustering ( AECL ). The AECL consists of two modules which are the contrastive learning module and the pseudo-label assisting module. Both modules utilize a sample-level attention mechanism to extract similarities between samples, based on which cross-sample features are aggregated to form a consistent representation for each sample. The contrastive learning module explores the similarity relationships and the consistent representations to form positive samples, effectively addressing the false negative separation issue, and the pseudo-label assisting module utilizes the consistent representations to produce reliable supervision information to assist the clustering task. Experimental results demonstrate that AECL outperforms state-of-the-art methods. The code is available at https://github.com/YZH0905/AECL-STC .},
  archive      = {J_NN},
  author       = {Zhihao Yao and Bo Li and Yufei Liao},
  doi          = {10.1016/j.neunet.2025.108101},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108101},
  shortjournal = {Neural Netw.},
  title        = {Discriminative representation learning via attention-enhanced contrastive learning for short text clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects. <em>NN</em>, <em>194</em>, 108100. (<a href='https://doi.org/10.1016/j.neunet.2025.108100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fixed-time synchronization (FXTS) and prescribed-time synchronization (PSTS) problems of state-dependent switching neural networks (SDSNNs) with stochastic disturbances and impulsive effects. By leveraging the average impulsive interval, comparison principle, and interval matrix methodology, this study advances a novel analytical framework. Departing from conventional approaches, we reformulate stochastic disturbed and impulsive SDSNNs as interval-parameter systems through rigorous interval matrix transformation. Consequently, we derive some sufficient conditions in the form of linear matrix inequalities (LMIs) to ensure the realization of FXTS and PSTS. Since impulsive effects can potentially compromise synchronization stability, careful controller design becomes critical. To address this challenge, we develop a unified proportional integral (PI) control framework. Through proper adjustment of its control parameters, this framework enables the system to achieve both FXTS and PSTS. Moreover, by reasonably configuring the relationship between the impulsive intensity and the prescribed time, the synchronization performance can be balanced. Finally, we demonstrate the effectiveness of the theoretical results through two examples.},
  archive      = {J_NN},
  author       = {Guici Chen and Houxuan Zhang and Shiping Wen and Junhao Hu and Leimin Wang},
  doi          = {10.1016/j.neunet.2025.108100},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108100},
  shortjournal = {Neural Netw.},
  title        = {Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories. <em>NN</em>, <em>194</em>, 108099. (<a href='https://doi.org/10.1016/j.neunet.2025.108099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of long-tail visual recognition, the imbalance in data distribution leads to a significant performance gap between head and tail classes. Improving the tail-class performance and alleviating the decline in head class are two critical questions. Although many methods have proposed solutions for the former, most of them fall short in the latter. Introducing additional knowledge is a novel view to address the problem, however, how to attain useful knowledge and further transfer the knowledge to the target model is the core. This paper proposes a novel method called Expert Knowledge Distillation for Specific Categories (EKDSC). Firstly, we propose a kind of well-trained teacher model ensuring each expert concentrates on its specialized field while being less affected by other interference. Furthermore, the teacher model including three categories of experts: head, mid, and tail classes, is utilized to distill their specialized knowledge to the student model. Experimental results demonstrate that EKDSC effectively improves the accuracy of tail classes, and mitigates the common decreases of head classes’ performance. Our proposed method achieves a high accuracy, exceeding the current state-of-the-art (SOTA) by 1–5 % on benchmark datasets including the small-scale CIFAR-10 LT and CIFAR-100 LT. Furthermore, it demonstrates outstanding performance on large-scale datasets such as ImageNet-LT, iNaturalist 2018, and Places-LT.},
  archive      = {J_NN},
  author       = {Yaping Bai and Jinghua Li and Dehui Kong and Suqiao Yang and Baocai Yin},
  doi          = {10.1016/j.neunet.2025.108099},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108099},
  shortjournal = {Neural Netw.},
  title        = {EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations. <em>NN</em>, <em>194</em>, 108098. (<a href='https://doi.org/10.1016/j.neunet.2025.108098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal imitation learning enables the agent to learn demonstrations of multiple modes at the same time. However, as expert demonstrations in practice tend to have incomplete labels for behavior modes, most methods are inefficient. To address this issue, an approach capable of imitation learning from incompletely labeled expert demonstrations, referred to as Weakly Supervised Multi-modal Imitation Learning (WSMIL), is proposed. WSMIL incorporates weakly supervised learning into multi-modal imitation learning by adding a behavior mode classifier to the adversarial network, thus forming adversaries among three players (generator, classifier and discriminator). Both labeled and unlabeled data are fully utilized in this adversarial process where fake state-action-label pairs generated by the generator and the classifier try to deceive the discriminator that tries to identify them and limited labeled expert demonstrations. Additionally, in order to ensure the data distribution of classifier and generator individually to converge to the expert’s real distribution, three extra losses are employed, where simulated annealing behavioral cloning is also added to the generator network to improve the generalization of policy. Experiments show that WSMIL accurately distinguishes modes with incomplete modal labels in demonstrations, learns close to the expert standard for each mode, and is more stable than other multi-modal methods.},
  archive      = {J_NN},
  author       = {Sijia Gu and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108098},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108098},
  shortjournal = {Neural Netw.},
  title        = {Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection. <em>NN</em>, <em>194</em>, 108097. (<a href='https://doi.org/10.1016/j.neunet.2025.108097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight salient object detection (SOD) is widely used in various downstream applications due to its low resource requirements and fast inference speed. The use of hybrid encoders offers the potential to achieve a better balance between efficiency and accuracy for SOD task. However, the aggregation of features from convolutional neural networks (CNNs) and transformers remains challenging, and most existing lightweight SOD models rarely explore the efficient aggregation of cross-architecture features derived from hybrid encoders. In this paper, we propose a hybrid aggregation strategy network (HASNet) that balances accuracy and efficiency for lightweight SOD by grouping and aggregating features to leverage salient information across different architectures. Specifically, the features obtained after hybrid encoder processing are divided into convolutional and transformer features for shallow and deep aggregation respectively. Deep aggregation uses the global inverted residual block (GIRB) to facilitate the transfer of salient information encoded within transformer features across various levels. Meanwhile, shallow aggregation uses the lightweight inverted residual block (LIRB) to efficiently integrate the spatial information inherent in convolutional features. The GIRB incorporates an efficient global operation to extract channel semantic information from the high-dimensional transformer features. The LIRB fuses low-level features by efficiently exploiting the spatial information in features at extremely low computational cost. Comprehensive experiments conducted across five datasets demonstrate that our HASNet significantly outperform existing methods in a thorough evaluation encompassing parameter sizes, inference speed, and accuracy. The source code will be publicly available at https://github.com/LitterMa-820/HASNet .},
  archive      = {J_NN},
  author       = {Jianhua Ma and Mingfeng Jiang and Xian Fang and Jiatong Chen and Yaming Wang and Guang Yang},
  doi          = {10.1016/j.neunet.2025.108097},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108097},
  shortjournal = {Neural Netw.},
  title        = {Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing image restoration through learning context-rich and detail-accurate features. <em>NN</em>, <em>194</em>, 108096. (<a href='https://doi.org/10.1016/j.neunet.2025.108096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover high-quality images from their degraded counterparts, necessitating a delicate balance between preserving spatial details and capturing contextual information. Although some methods attempt to address this trade-off, they tend to focus primarily on spatial features while overlooking the importance of understanding frequency variations. Moreover, these approaches commonly utilize skip connections–implemented via addition or concatenation–to fuse encoder and decoder features for improved restoration. However, since encoder features may still carry degradation artifacts, such direct fusion strategies risk introducing implicit noise, ultimately hindering restoration performance. In this paper, we present a multi-scale design that optimally balances these competing objectives, seamlessly integrating spatial and frequency domain knowledge to selectively recover the most informative information. Specifically, we develop a hybrid scale frequency selection block (HSFSBlock), which not only captures multi-scale information from the spatial domain, but also selects the most informative components for image restoration in the frequency domain. Furthermore, to mitigate the inherent noise introduced by skip connections employing only addition or concatenation, we introduce a skip connection attention mechanism (SCAM) to selectively determines the information that should propagate through skip connections. The resulting tightly interlinked architecture, named as LCDNet. Extensive experiments conducted across diverse image restoration tasks showcase that our model attains performance levels that are either superior or comparable to those of state-of-the-art algorithms. The code and the pre-trained models are released at https://github.com/Tombs98/LCDNet .},
  archive      = {J_NN},
  author       = {Hu Gao and Xiaoning Lei and Depeng Dang},
  doi          = {10.1016/j.neunet.2025.108096},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108096},
  shortjournal = {Neural Netw.},
  title        = {Enhancing image restoration through learning context-rich and detail-accurate features},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation. <em>NN</em>, <em>194</em>, 108095. (<a href='https://doi.org/10.1016/j.neunet.2025.108095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) has emerged as a critical paradigm for adapting large pre-trained models to downstream tasks, offering a balance between computational efficiency and model performance. Among these methods, Low-Rank Adaptation (LoRA) has gained significant popularity due to its efficiency; it freezes the pre-trained weights and decomposes the incremental matrices into two trainable low-rank matrices. However, a critical limitation of LoRA lies in its uniform rank assignment across all layers, which fails to account for the heterogeneous importance of different layers in contributing to task performance, potentially resulting in suboptimal adaptation. To address this limitation, we propose Layer-wise Adaptive Low-Rank Adaptation (La-LoRA), a novel approach that dynamically allocates rank to each layer based on Dynamic Contribution-Driven Parameter Budget (DCDPB) and Truncated Norm Weighted Dynamic Rank Allocation (TNW-DRA) during training. By treating each layer as an independent unit and progressively adjusting its rank allocation, La-LoRA ensures optimal model performance while maintaining computational efficiency and adapting to the complexity of diverse tasks. We conducted extensive experiments across multiple tasks and models to evaluate the effectiveness of La-LoRA. The results demonstrate that La-LoRA consistently outperforms existing benchmarks, validating its effectiveness in diverse scenarios.},
  archive      = {J_NN},
  author       = {Jiancheng Gu and Jiabin Yuan and Jiyuan Cai and Xianfa Zhou and Lili Fan},
  doi          = {10.1016/j.neunet.2025.108095},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108095},
  shortjournal = {Neural Netw.},
  title        = {La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-level dynamic heterogeneous graph network for video question answering. <em>NN</em>, <em>194</em>, 108094. (<a href='https://doi.org/10.1016/j.neunet.2025.108094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Video Question Answering (VideoQA) has garnered considerable research interest as a pivotal task within the realm of vision-language understanding. However, existing Video Question Answering datasets often lack sufficient entity and event information. Thus, the Vision Language Models (VLMs) struggle to complete intricate grounding and reasoning among multi-modal entities or events and heavily rely on language short-cut or irrelevant visual context. To address these challenges, we make improvements from both data and model perspectives. In terms of VideoQA data, we focus on supplementing the missing specific entities and events with the proposed event and entity augmentation strategies. Based on the augmented data, we propose a Dual-Level Dynamic Heterogeneous Graph Network (DDHG) for Video Question Answering. DDHG incorporates transformer layers to capture the dynamic temporal-spatial changes of visual entities. Then, DDHG establishes multi-modal semantic grounding ability between vision and text with entity-level and event-level heterogeneous graphs. Finally, the Dual-level Cross-modal Interaction Module integrates the dual-level features to predict correct answers. Our method not only significantly outperforms existing VideoQA models on two complex event-based benchmark datasets (Causal-VidQA and NExT-QA) but also demonstrates superior event content prediction ability over several state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Zefan Zhang and Yanhui Li and Weiqi Zhang and Tian Bai},
  doi          = {10.1016/j.neunet.2025.108094},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108094},
  shortjournal = {Neural Netw.},
  title        = {Dual-level dynamic heterogeneous graph network for video question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction. <em>NN</em>, <em>194</em>, 108093. (<a href='https://doi.org/10.1016/j.neunet.2025.108093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction plays a crucial role in drug discovery and repurposing by efficiently and accurately identifying potential therapeutic targets. Existing methods face challenges in capturing high-order semantic relationships in heterogeneous graphs and effectively integrating multi-meta-path information while also suffering from low computational efficiency. To address these challenges, a pre-computation-style hierarchical meta-path learning framework named HMT-DTI is proposed. HMT-DTI can effectively capture rich semantic information about drugs and targets while ensuring high computational efficiency. Specifically, during the pre-collection stage, HMT-DTI employs a Transformer-based message passing mechanism to evaluate neighbors’ importance and adaptively collect meta-path information. The incorporation of even-relation propagation reduces redundant iterations and improves efficiency. During training, HMT-DTI adopts a hierarchical knowledge extraction strategy to evaluate the importance of multi-hop neighbors and different meta-path patterns, capturing fine-grained semantic representations of drugs and targets. HMT-DTI is evaluated on three heterogeneous biological datasets and compared with several state-of-the-art methods. The results demonstrate the superiority of HMT-DTI in DTI prediction.},
  archive      = {J_NN},
  author       = {Dianlei Gao and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108093},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108093},
  shortjournal = {Neural Netw.},
  title        = {HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On training networks of monostable multivibrator timer neurons. <em>NN</em>, <em>194</em>, 108092. (<a href='https://doi.org/10.1016/j.neunet.2025.108092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important bottleneck in present-day neuromorphic hardware is its reliance on synaptic addition, which limits the achievable degree of parallelization and thus processing throughput. We present a network of monostable multivibrator timers, whose synaptic inputs are simply OR-ed together, thus mitigating the synaptic addition bottleneck. Monostable multivibrators are simple timers which are easily implemented using counters in digital hardware and can be interpreted as non biologically-inspired spiking neurons. We show how fully binarized event-driven recurrent networks of monostable multivibrators can be trained to solve classification tasks. Our training algorithm resolves temporally overlapping input events. We demonstrate our approach on the MNIST handwritten digits, Google Soli radar gestures, IBM DVS128 gestures and Yin-Yang classification tasks. The estimated energy consumption for the MNIST handwritten digits task, excluding the final linear readout layer, is 855pJ per inference for a test accuracy of 98.61 % for a reconfigurable network of 500 units, when mapped to the TSMC HPC+ 28 nm process.},
  archive      = {J_NN},
  author       = {Lars Keuninckx and Matthias Hartmann and Paul Detterer and Ali Safa and Wout Mommen and Ilja Ocket},
  doi          = {10.1016/j.neunet.2025.108092},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108092},
  shortjournal = {Neural Netw.},
  title        = {On training networks of monostable multivibrator timer neurons},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis. <em>NN</em>, <em>194</em>, 108091. (<a href='https://doi.org/10.1016/j.neunet.2025.108091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal neuroimaging techniques are widely employed for the accurate diagnosis of Alzheimer’s Disease (AD). Existing fusion methods typically focus on capturing semantic correlations between modalities through feature-level interactions. However, they fail to suppress redundant cross-modal information, resulting in sub-optimal multi-modal representation. Moreover, these methods ignore subject-specific differences in modality contributions. To address these challenges, we propose a novel Multi-modal Orthogonal Fusion Network via cross-layer guidance (MOFNet) to effectively fuse multi-modal information for AD diagnosis. We first design a Cross-layer Guidance Interaction module (CGI), leveraging high-level features to guide the learning of low-level features, thereby enhancing the fine-grained representations on disease-relevant regions. Then, we introduce a Multi-modal Orthogonal Compensation module (MOC) to realize bidirectional interaction between modalities. MOC encourages each modality to compensate for its limitations by learning orthogonal components from other modalities. Finally, a Feature Enhancement Fusion module (FEF) is developed to adaptively fuse multi-modal features based on the contributions of different modalities. Extensive experiments on the ADNI dataset demonstrate that MOFNet achieves superior performance in AD classification tasks.},
  archive      = {J_NN},
  author       = {Yumiao Zhao and Bo Jiang and Yuan Chen and Ye Luo and Jin Tang},
  doi          = {10.1016/j.neunet.2025.108091},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108091},
  shortjournal = {Neural Netw.},
  title        = {Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ClickAttention: Click region similarity guided interactive segmentation. <em>NN</em>, <em>194</em>, 108090. (<a href='https://doi.org/10.1016/j.neunet.2025.108090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive segmentation algorithms based on click points have attracted significant attention from researchers in recent years. However, most existing methods rely on sparse click maps as model inputs to segment specific target objects. These clicks primarily affect local regions, limiting the model’s ability to focus on the entire target object and often resulting in a higher number of required clicks. Additionally, many current algorithms struggle to balance performance and efficiency effectively. To address these challenges, we propose a click attention algorithm that expands the influence of positive clicks by leveraging the similarity between positively-clicked regions and the entire input. We further introduce a discriminative affinity loss to reduce attention coupling between positive and negative click regions, minimizing accuracy degradation caused by mutual interference. On the DAVIS dataset, our method achieves a 2 % performance gain (NoC@90) over the state-of-the-art SimpleClick-ViT-L, while using only 15.6 % of its parameters. Extensive experiments demonstrate that our approach outperforms existing methods and achieves state-of-the-art performance with fewer parameters. Data and code are published.},
  archive      = {J_NN},
  author       = {Long Xu and Yongquan Chen and Shanghong Li and Junkang Chen and Ziyuan Tang},
  doi          = {10.1016/j.neunet.2025.108090},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108090},
  shortjournal = {Neural Netw.},
  title        = {ClickAttention: Click region similarity guided interactive segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language model for multitask classification of memes. <em>NN</em>, <em>194</em>, 108089. (<a href='https://doi.org/10.1016/j.neunet.2025.108089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of social media and online memes has led to an increasing demand for automated systems that can analyse and classify multimodal data, particularly in online forums. Memes blend text and graphics to express complicated ideas, sometimes containing emotions, satire, or inappropriate material. Memes often represent cultural prejudices such as objectification, sexism, and bigotry, making it difficult for artificial intelligence to classify these components. Our solution is the vision-language model ViT-BERT CAMT (cross-attention multitask), which is intended for multitask meme categorization. Our model uses a linear self-attentive fusion mechanism to combine vision transformer (ViT) features for image analysis and bidirectional encoder representations from transformers (BERT) for text interpretation. In this way, we can see how text and images relate to space and meaning. We tested the ViT-BERT CAMT on two difficult datasets: the SemEval 2020 Memotion dataset, which contains a multilabel classification of sentiment, sarcasm, and offensiveness in memes, and the MIMIC dataset, which focuses on detecting sexism, objectification, and prejudice. The findings show that the ViT-BERT CAMT achieves good accuracy on both datasets and outperforms many current baselines in multitask settings. These results highlight the importance of combined image-text modelling for correctly deciphering nuanced meanings in memes, particularly when spotting abusive and discriminatory content. By improving multimodal categorization algorithms, this study helps better monitor and comprehend online conversation.},
  archive      = {J_NN},
  author       = {Md. Mithun Hossain and Md. Shakil Hossain and M.F. Mridha and Nilanjan Dey},
  doi          = {10.1016/j.neunet.2025.108089},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108089},
  shortjournal = {Neural Netw.},
  title        = {A vision-language model for multitask classification of memes},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view learning meets state-space model: A dynamical system perspective. <em>NN</em>, <em>194</em>, 108088. (<a href='https://doi.org/10.1016/j.neunet.2025.108088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning exploits the complementary nature of multiple modalities to enhance performance across diverse tasks. While deep learning has significantly advanced these fields by enabling sophisticated modeling of intra-view and cross-view interactions, many existing approaches still rely on heuristic architectures and lack a principled framework to capture the dynamic evolution of feature representations. This limitation hampers interpretability and theoretical understanding. To address these challenges, this paper introduces the Multi-view State-Space Model (MvSSM), which formulates multi-view representation learning as a continuous-time dynamical system inspired by control theory. In this framework, view-specific features are treated as external inputs, and a shared latent representation evolves as the internal system state, driven by learnable dynamics. This formulation unifies feature integration and label prediction within a single interpretable model, enabling theoretical analysis of system stability and representational transitions. Two variants, MvSSM-Lap and MvSSM-iLap, are further developed using Laplace and inverse Laplace transformations to derive system dynamics representations. These solutions exhibit structural similarities to graph convolution operations in deep networks, supporting efficient feature propagation and theoretical interpretability. Experiments on benchmark datasets such as IAPR-TC12, and ESP demonstrate the effectiveness of the proposed method, achieving up to 4.31 % improvement in accuracy and 4.27 % in F1-score over existing state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Weibin Chen and Ying Zou and Zhiyong Xu and Li Xu and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108088},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108088},
  shortjournal = {Neural Netw.},
  title        = {Multi-view learning meets state-space model: A dynamical system perspective},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph convolutional network with adaptive grouping aggregation strategy. <em>NN</em>, <em>194</em>, 108086. (<a href='https://doi.org/10.1016/j.neunet.2025.108086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph convolutional networks (GCNs) with naive aggregation functions on nodes has reached the bottleneck, rendering a gap between practice and theoretical expressity. Some learning-based aggregation strategies have been proposed to improve the performance. However, few of them focus on how these strategies affect the expressity and evaluate their performance in an equal experimental setting. In this paper, we point out that the generated features lack discrimination because naive aggregation functions cannot retain sufficient node information, largely leading to the performance gap. Accordingly, a novel Adaptive Grouping Aggregation (AGA) strategy is proposed to remedy this drawback. Inspired by the label histogram in the Weisfeiler-Lehman (WL) Test, this strategy assigns each node to a unique group to retain more node information, which is proven to have a strictly more powerful expressity. In this work setting, the nodes are grouped according to a modified Student’s t-Distribution between node features and a set of learnable group labels, where the Gumbel Softmax is employed to implement this strategy in an end-to-end trainable pipeline. As a result, such a design can generate more discriminative features and offer a plug-in module in most architectures. Extensive experiments have been conducted on several benchmarks to compare our method with other aggregation strategies. The proposed method improves the performance in all control groups of all benchmarks and achieves the best result in most cases. Additional ablation studies and comparisons with state-of-the-art methods on the large-scale benchmark also indicate the superiority of our method.},
  archive      = {J_NN},
  author       = {Ruixiang Wang and Chunxia Zhang and Chunhong Pan},
  doi          = {10.1016/j.neunet.2025.108086},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108086},
  shortjournal = {Neural Netw.},
  title        = {Graph convolutional network with adaptive grouping aggregation strategy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-driven optimization of collaborative multi-agent via case learning and curiosity. <em>NN</em>, <em>194</em>, 108083. (<a href='https://doi.org/10.1016/j.neunet.2025.108083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Deep Reinforcement Learning(MADRL) faces significant challenges in exploration-exploitation trade-off during training, particularly when learning collaborative behaviors through continuous environment interactions. Current exploration methods generally rely on unbiased randomized policy, which makes the policy optimization process lack of goal-directed, resulting in a large number of low signal-to-noise ratio transitions collected in the experience replay buffer, which seriously affects the learning efficiency and policy convergence stability of MADRL. To address the above research challenges, We propose the Case-Enhanced Random Network Distillation Exploration for Centralized Training and Decentralized Execution(CERE-CTDE) paradigm. Our innovation lies in the novel integration of Random Network Distillation(RND) and Case-Based Reasoning(CBR): RND provides intrinsic motivation to enhance exploration and overcome sparse rewards, while CBR enables goal-directed exploitation by leveraging historical case to guide agent action selection. This dual mechanism creates a dynamic equilibrium between exploring novel policy and exploiting proven case, effectively preventing premature convergence. We incorporate the CERE into two categories of MADRL methods based on the CTDE paradigm. The performance of us is assessed and validated with 2 methods focused on exploration using 13 confrontation scenarios in the StarCraft Multi-Agent Challenge(SMAC). The experimental results demonstrate: a 17.97 % statistically significant improvement in win rate on complex battlefields compared to baseline performance in simple scenarios; effective enhancement of policy exploration-exploitation and mitigation of partial sparse reward problems through intrinsic motivation and CBR-guided action sampling; and superior capability in escaping local optima while maintaining learning efficiency. The framework’s robustness is further validated by its consistent performance across different SMAC scenarios with varying difficulty levels.},
  archive      = {J_NN},
  author       = {Ruizhu Chen and Rong Fei and Junhuai Li and Aimin Li and Yalin Miao and Lili Wu and Zhiming Chen},
  doi          = {10.1016/j.neunet.2025.108083},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108083},
  shortjournal = {Neural Netw.},
  title        = {Dual-driven optimization of collaborative multi-agent via case learning and curiosity},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive behavior with stable synapses. <em>NN</em>, <em>194</em>, 108082. (<a href='https://doi.org/10.1016/j.neunet.2025.108082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral changes in animals and humans, triggered by errors or verbal instructions, can occur extremely rapidly. While learning theories typically attribute improvements in performance to synaptic plasticity, recent findings suggest that such fast adaptations may instead result from dynamic reconfiguration of the networks involved without changes to synaptic weights. Recently, similar capabilities have been observed in transformers, foundational architecture in machine learning widely used in applications such as natural language and image processing. Transformers are capable of in-context learning, the ability to adapt and acquire new information dynamically within the context of the task or environment they are currently engaged in, without changing their parameters. We argue that this property may stem from gain modulation–a feature widely observed in biological networks, such as pyramidal neurons through input segregation and dendritic amplification. We propose a constructive approach to induce in-context learning in an architecture composed of recurrent networks with gain modulation, demonstrating abilities inaccessible to standard networks. In particular, we show that, such architecture can dynamically implement standard gradient-based by encoding weight changes in the activity of another network. We argue that, while these algorithms are traditionally associated with synaptic plasticity, their reliance on non-local terms suggests that they may be more naturally realized in the brain at the level of neural circuits. We demonstrate that we can extend our approach to temporal tasks and reinforcement learning. We further validate our approach in a MuJoCo ant navigation task, showcasing a neuromorphic control paradigm via real-time network reconfiguration.},
  archive      = {J_NN},
  author       = {Cristiano Capone and Luca Falorsi},
  doi          = {10.1016/j.neunet.2025.108082},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108082},
  shortjournal = {Neural Netw.},
  title        = {Adaptive behavior with stable synapses},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disentangled self-supervised video camouflaged object detection and salient object detection. <em>NN</em>, <em>194</em>, 108077. (<a href='https://doi.org/10.1016/j.neunet.2025.108077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video tasks play an important role in multimedia fields. In various video tasks, such as video camouflaged/salient object detection (VCOD/VSOD), motion and context information are two important aspects. Despite the fact that many existing works have already achieved promising results in VCOD and VSOD tasks, they still have limitations when it comes to leveraging motion and context information. In this paper, we propose a new disentangled perspective to treat motion and context information in VCOD and VSOD tasks. Our proposed model can respectively utilize context and motion information in ContextNet and MotionNet, without conflicting with each other as there can be biases between these two types of information in certain circumstances. Moreover, we further explore how to apply disentangled perspective in the self-supervised manner, which can reduce annotation costs. Specifically, we first design a self-supervised adaptive frame routing mechanism to determine whether each video frame belongs to ContextNet or MotionNet. Then we design a cross-supervision for ContextNet and MotionNet to train these two segmentation networks in self-supervised mechanism. In experiments, our proposed self-supervised disentangled model consistently outperforms state-of-the-art unsupervised methods on VCOD and VSOD datasets.},
  archive      = {J_NN},
  author       = {Haoke Xiao and Lv Tang and Bo Li and Zhiming Luo and Shaozi Li},
  doi          = {10.1016/j.neunet.2025.108077},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108077},
  shortjournal = {Neural Netw.},
  title        = {Disentangled self-supervised video camouflaged object detection and salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design, analysis and verification of noise-tolerant and overshoot-free recurrent neural network. <em>NN</em>, <em>194</em>, 108075. (<a href='https://doi.org/10.1016/j.neunet.2025.108075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A kind of recurrent neural network (RNN) specialized in solving time-varying problems has wide applications in various fields, where the RNN with integral terms (RNN-IT) as a state-of-art method plays an important role in rejecting noise. However, the RNN-IT always experiences overshoot phenomenon when suppressing noise, which greatly affects the convergence time. In order to overcome the above disadvantage of the RNN-IT, this paper proposes a noise-tolerant and overshoot-free recurrent neural network (NORNN) by designing a time-varying additional term, which can flexibly compensate errors and avoid accumulation, thereby resisting noise and eliminating overshoot. Furthermore, the convergence time of the NORNN is obviously improved, which means that the NORNN can effectively and quickly address time-varying problems even when the noise disturbed. Two theorems and a corollary analyze the convergence, noise-tolerance, and overshoot-free properties of the proposed NORNN. Meanwhile, simulation experiments on solving the time-varying matrix inversion problem and the trajectory tracking of the RPRR manipulator also verify its excellent performance.},
  archive      = {J_NN},
  author       = {Lei Jia and Tiandong Zheng and Yujie Wu and Yiwei Li},
  doi          = {10.1016/j.neunet.2025.108075},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108075},
  shortjournal = {Neural Netw.},
  title        = {Design, analysis and verification of noise-tolerant and overshoot-free recurrent neural network},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WPDA: Frequency-based backdoor attack with wavelet packet decomposition. <em>NN</em>, <em>194</em>, 108074. (<a href='https://doi.org/10.1016/j.neunet.2025.108074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores backdoor attack, which is an emerging security threat against deep neural networks (DNNs). The adversary aims to inject a backdoor into the model by manipulating a portion of training samples, such that the backdoor could be activated by a particular trigger to make a target prediction at inference. Currently, existing backdoor attacks often require moderate or high poisoning ratios to achieve the desired attack performance, but making them susceptible to some advanced backdoor defenses ( e . g . , poisoned sample detection). One possible solution to this dilemma is enhancing the attack performance at low poisoning ratios, which has been rarely studied due to its high challenge. To achieve this goal, we propose an innovative frequency-based backdoor attack via wavelet packet decomposition (WPD), which could finely decompose the original image into multiple sub-spectrograms with semantic information. It facilitates us to accurately identify the most critical frequency regions to effectively insert the trigger into the victim image, such that the trigger information could be sufficiently learned to form the backdoor. The proposed attack stands out for its exceptional effectiveness, stealthiness, and resistance at an extremely low poisoning ratio. Notably, it achieves the 98.12 % attack success rate on CIFAR-10 with an extremely low poisoning ratio of 0.004 % ( i.e. , only 2 poisoned samples among 50,000 training samples), and bypasses several advanced backdoor defenses. Besides, we provide more extensive experiments to demonstrate the efficacy of the proposed method, as well as in-depth analyses to explain its underlying mechanism.},
  archive      = {J_NN},
  author       = {Zhengyao Song and Yongqiang Li and Danni Yuan and Li Liu and Shaokui Wei and Baoyuan Wu},
  doi          = {10.1016/j.neunet.2025.108074},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108074},
  shortjournal = {Neural Netw.},
  title        = {WPDA: Frequency-based backdoor attack with wavelet packet decomposition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts. <em>NN</em>, <em>194</em>, 108064. (<a href='https://doi.org/10.1016/j.neunet.2025.108064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are gaining popularity for processing graph data. In real-world scenarios, graph data within the same dataset can vary significantly in scale. This variability leads to depth-sensitivity, where the optimal depth of GNN layers depends on the scale of the graph data. Empirically, fewer layers are sufficient for message passing in smaller graphs, while larger graphs typically require deeper networks to capture long-range dependencies and global features. However, existing methods generally use a fixed number of GNN layers to generate representations for all graphs, overlooking the depth-sensitivity issue in graph data. To address this challenge, we propose the depth adaptive mixture of expert (DA-MoE) method, which incorporates two main improvements to GNN backbone: 1) DA-MoE employs different GNN layers, each considered an expert with its own parameters. Such a design allows the model to flexibly aggregate information at different scales, effectively addressing the depth-sensitivity issue in graph data. 2) DA-MoE utilizes GNN to capture the structural information instead of the linear projections in the gating network. Thus, the gating network enables the model to capture complex patterns and dependencies within the data. By leveraging these improvements, each expert in DA-MoE specifically learns distinct graph patterns at different scales. Furthermore, comprehensive experiments on the TU dataset and open graph benchmark (OGB) have shown that DA-MoE consistently surpasses existing baselines on various tasks, including graph, node, and link-level analyses. The code are available at https://github.com/Celin-Yao/DA-MoE .},
  archive      = {J_NN},
  author       = {Zelin Yao and Mukun Chen and Chuang Liu and Xianke Meng and Yibing Zhan and Jia Wu and Shirui Pan and Huiting Xu and Wenbin Hu},
  doi          = {10.1016/j.neunet.2025.108064},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108064},
  shortjournal = {Neural Netw.},
  title        = {DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph representation learning with disentangled information bottleneck. <em>NN</em>, <em>194</em>, 108056. (<a href='https://doi.org/10.1016/j.neunet.2025.108056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning recently garnered enormous research attention. Despite the notable successes of existing methods, they usually characterize dynamic graphs as a perceptual whole and learn dynamic graph representations within an entangled feature space, which overlook different temporal dependencies inherent in the data. Specifically, the evolution of dynamic graphs is usually decided by a dichotomy in properties: time-invariant properties and time-varying properties. Existing holistic works fail to distinguish these temporal properties and may suffer suboptimal performance in downstream tasks. To tackle this problem, we propose to learn macro-disentangled dynamic graph representations based on the Information Bottleneck theory, leading to a novel dynamic graph representation learning method, Disentangled Dynamic Graph Information Bottleneck (DDGIB). Our DDGIB explicitly embeds the dynamic graphs into a time-invariant representation space and a time-varying representation space. The time-invariant representation space encapsulates stable properties across the temporal span of dynamic graphs, whereas the time-varying representation space encapsulates time-fluctuating properties. The macro disentanglement on the temporal dependencies facilitates the representations’ performance on downstream tasks. Furthermore, we theoretically prove the sufficiency and macro disentanglement of DDGIB. The sufficiency demonstrates that DDGIB can achieve sufficient representations for any possible downstream tasks, while the macro disentanglement certifies that DDGIB can embed the different temporal properties into their corresponding temporal representation space. Extensive experimental results on various datasets and downstream tasks demonstrate the superiority of our method.},
  archive      = {J_NN},
  author       = {Jihong Wang and Yuxin Bai and Chunqiang Zhu and Hao Qian and Ziqi Liu and Minnan Luo},
  doi          = {10.1016/j.neunet.2025.108056},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108056},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph representation learning with disentangled information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning. <em>NN</em>, <em>194</em>, 108023. (<a href='https://doi.org/10.1016/j.neunet.2025.108023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral diversity emerges as a crucial factor for achieving effective collaboration in Multi-Agent Reinforcement Learning (MARL). Current methods often use partial parameter sharing, such as sharing the same representation layer, to balance behavioral diversity and algorithmic scalability. However, this approach ignores that different agents need different decision knowledge, causing training conflicts and knowledge redundancy. To solve these, we propose Tailoring Knowledge for Empowered Cooperative Actions in Multi-Agent Reinforcement Learning (TKCA). Specially, we employ a set of Knowledge Encoders to encode different environment types of knowledge and utilize a Knowledge Selector network to assist each agent in decision-making by selecting the corresponding knowledge. We evaluated TKCA in challenging StarCraftII micromanagement games and Google Research Football games, and the results demonstrate the superior performance of TKCA.},
  archive      = {J_NN},
  author       = {Hu Fu and Yihua Tan and Hao Chen and Pengyi Li},
  doi          = {10.1016/j.neunet.2025.108023},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108023},
  shortjournal = {Neural Netw.},
  title        = {Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="orl">ORL - 3</h2>
<ul>
<li><details>
<summary>
(2026). Energy-optimal scheduling with variable processing speed: The role of task size variability. <em>ORL</em>, <em>64</em>, 107379. (<a href='https://doi.org/10.1016/j.orl.2025.107379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the execution of a single task with an unknown size on a server with variable processing speed. Our goal is to analyze structural properties of the optimal energy consumption under the optimal speed profile that minimizes the expected energy consumption while meeting a hard deadline constraint. Specifically, we investigate how the task size probability distribution impacts the overall energy. Under mild assumptions, our main result shows that the expected energy consumption induced by the optimal speed profile preserves the convex increasing order with respect to the task size distribution. Then, we leverage this property to derive simple bounds and conduct a worst-case analysis. In particular, we derive a simple, general formula for the energy gap induced by the ‘best’ and ‘worst’ task size distributions, expressed in terms of the support and expectation of the task size.},
  archive      = {J_ORL},
  author       = {Jonatha Anselmi and Bruno Gaujal},
  doi          = {10.1016/j.orl.2025.107379},
  journal      = {Operations Research Letters},
  month        = {1},
  pages        = {107379},
  shortjournal = {Oper. Res. Lett.},
  title        = {Energy-optimal scheduling with variable processing speed: The role of task size variability},
  volume       = {64},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A simple approximation algorithm for optimal decision tree. <em>ORL</em>, <em>64</em>, 107370. (<a href='https://doi.org/10.1016/j.orl.2025.107370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the optimal decision tree (ODT) problem, we are given m hypotheses, out of which an unknown “true” hypothesis is drawn according to some probability distribution. The task is to identify the true hypothesis by performing costly queries, each with known responses. ODT is NP-hard to approximate within a factor of ln ⁡ m , and existing O ( ln ⁡ m ) approximation algorithms are complex with large leading constants. We provide a simple algorithm and analysis for ODT, proving an approximation ratio of 8 ln ⁡ m .},
  archive      = {J_ORL},
  author       = {Zhengjia Zhuo and Viswanath Nagarajan},
  doi          = {10.1016/j.orl.2025.107370},
  journal      = {Operations Research Letters},
  month        = {1},
  pages        = {107370},
  shortjournal = {Oper. Res. Lett.},
  title        = {A simple approximation algorithm for optimal decision tree},
  volume       = {64},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Monotone convergence of spreading processes on networks. <em>ORL</em>, <em>64</em>, 107363. (<a href='https://doi.org/10.1016/j.orl.2025.107363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the Bass and SI models for the spreading of innovations and epidemics, respectively, on homogeneous complete networks, on one-dimensional networks, and on heterogeneous two-groups complete networks. We allow the network parameters to be time dependent, which is a prerequisite for the analysis of optimal promotional strategies on networks. Using a novel top-down analysis of the master equations, we present a simple proof for the monotone convergence of these models to their respective infinite-population limits. This leads to explicit expressions for the expected adoption or infection level in the Bass and SI models with time-dependent parameters on infinite homogeneous complete and circular networks, and on heterogeneous two-groups complete networks.},
  archive      = {J_ORL},
  author       = {Gadi Fibich and Amit Golan and Steven Schochet},
  doi          = {10.1016/j.orl.2025.107363},
  journal      = {Operations Research Letters},
  month        = {1},
  pages        = {107363},
  shortjournal = {Oper. Res. Lett.},
  title        = {Monotone convergence of spreading processes on networks},
  volume       = {64},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="parco">PARCO - 5</h2>
<ul>
<li><details>
<summary>
(2025). Software acceleration of multi-user MIMO uplink detection on GPU. <em>PARCO</em>, <em>125</em>, 103150. (<a href='https://doi.org/10.1016/j.parco.2025.103150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the exploration of GPU-accelerated block-wise decompositions for zero-forcing (ZF) based QR and Cholesky methods applied to massive multiple-input multiple-output (MIMO) uplink detection algorithms. Three algorithms are evaluated: ZF with block Cholesky decomposition, ZF with block QR decomposition (QRD), and minimum mean square error (MMSE) with block Cholesky decomposition. The latter was the only one previously explored, but it used standard Cholesky decomposition. Our approach achieves an 11% improvement over the previous GPU-accelerated MMSE study. Through performance analysis, we observe a trade-off between precision and execution time. Reducing precision from FP64 to FP32 improves execution time but increases bit error rate (BER), with ZF-based QRD reducing execution time from 2 . 04 μ s to 1 . 24 μ s for a 128 × 8 MIMO size. The study also highlights that larger MIMO sizes, particularly 2048 × 32, require GPUs to fully utilize their computational and memory capabilities, especially under FP64 precision. In contrast, smaller matrices are compute-bound. Our results recommend GPUs for larger MIMO sizes, as they offer the parallelism and memory resources necessary to efficiently handle the computational demands of next-generation networks. This work paves the way for scalable, GPU-based massive MIMO uplink detection systems.},
  archive      = {J_PARCO},
  author       = {Ali Nada and Hazem Ismail Ali and Liang Liu and Yousra Alkabani},
  doi          = {10.1016/j.parco.2025.103150},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103150},
  shortjournal = {Parallel Comput.},
  title        = {Software acceleration of multi-user MIMO uplink detection on GPU},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enable cross-iteration parallelism for PIM-based graph processing with vertex-level synchronization. <em>PARCO</em>, <em>125</em>, 103149. (<a href='https://doi.org/10.1016/j.parco.2025.103149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing-in-memory (PIM) architectures have emerged as a promising solution for accelerating graph processing by enabling computation in memory and minimizing data movement. However, most existing PIM-based graph processing systems rely on the Bulk Synchronous Parallel (BSP) model, which frequently enforces global barriers that limit cross-iteration computational parallelism and introduce significant synchronization and communication overheads. To address these limitations, we propose the Cross Iteration Parallel (CIP) model, a novel vertex-level synchronization approach that eliminates global barriers by independently tracking the synchronization states of vertices. The CIP model enables concurrent execution across iterations, enhancing computational parallelism, overlapping communication and computation, improving core utilization, and increasing resilience to workload imbalance. We implement the CIP model in a PIM-based graph processing system, GraphDF, which features a few specially designed function units to support vertex-level synchronization. Evaluated on a PyMTL3-based cycle-accurate simulator using four real-world graphs and four graph algorithms, CIP running on GraphDF achieves an average speedup of 1.8 × and a maximum of 2.3 × compared to Dalorex, the state-of-the-art PIM-based graph processing system.},
  archive      = {J_PARCO},
  author       = {Xiang Zhao and Haitao Du and Yi Kang},
  doi          = {10.1016/j.parco.2025.103149},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103149},
  shortjournal = {Parallel Comput.},
  title        = {Enable cross-iteration parallelism for PIM-based graph processing with vertex-level synchronization},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-workflow fault-tolerance scheduling strategy considering resources supply delay in WaaS platforms. <em>PARCO</em>, <em>125</em>, 103148. (<a href='https://doi.org/10.1016/j.parco.2025.103148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workflow as a Service (WaaS) platforms rent virtual machines (VMs) from IaaS providers to run scientific workflows for users. However, current researches on workflow scheduling in WaaS platforms did not consider the possibility of VMs downtime leading to task failures or the resources (such as VMs and containers) supply delay affecting scheduling efficiency. To address this issue, this paper proposes a multi-workflow fault-tolerance scheduling strategy for WaaS platforms. Firstly, since WaaS platforms do not manage hardware directly but schedule workflows at the level of VMs and containers, we establish a workflow scheduling model suitable for WaaS platforms, taking into account the impact of resources supply delay on workflow scheduling. Secondly, we propose a multi-workflow fault-tolerance scheduling strategy for WaaS platforms, which includes preprocessing, fault-tolerance selection, task assignment, and resource adjustment. It involves an improved deadline division algorithm to determine the scheduling order, a fault-tolerance selection algorithm combining two fault-tolerance strategies (replication and re-submission), task assignment algorithm considering task attributes and resource supply delay to schedule tasks, and a resource adjustment algorithm to pre-deploy resources for upcoming tasks. Finally, we compare the proposed scheduling strategy with three other algorithms, and the results also demonstrate its effectiveness.},
  archive      = {J_PARCO},
  author       = {Hui Zhao and Wentao Zhi and Xiaoqin Lu and Jing Wang and Nan Luo and Bo Wan and Quan Wang},
  doi          = {10.1016/j.parco.2025.103148},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103148},
  shortjournal = {Parallel Comput.},
  title        = {Multi-workflow fault-tolerance scheduling strategy considering resources supply delay in WaaS platforms},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALBBA: An efficient ALgebraic bypass BFS algorithm on long vector architectures. <em>PARCO</em>, <em>125</em>, 103147. (<a href='https://doi.org/10.1016/j.parco.2025.103147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breadth First Search (BFS) is a fundamental algorithm in scientific computing, databases, and network analysis applications. In the algebraic BFS paradigm, each BFS iteration is expressed as a sparse matrix–vector multiplication, allowing BFS to be accelerated and analyzed through well-established linear algebra primitives. Although much effort has been made to optimize algebraic BFS on parallel platforms such as CPUs, GPUs, and distributed memory systems, vector architectures that exploit Single Instruction Multiple Data (SIMD) parallelism, particularly with their high performance on sparse workloads, remain relatively underexplored for BFS. In this paper, we propose the ALgebraic Bypass BFS Algorithm (ALBBA), a novel and efficient algebraic BFS implementation optimized for long vector architectures. ALBBA utilizes a customized variant of the SELL- C - σ data structure to fully exploit the SIMD capabilities. By integrating a vectorization-friendly search method alongside a two-level bypass strategy, we enhance both sparse matrix-sparse vector multiplication (SpMSpV) and sparse matrix-dense vector multiplication (SpMV) algorithms, which are crucial for algebraic BFS operations. We further incorporate merge primitives and adopt an efficient selection method for each BFS iteration. Our experiments on an NEC VE20B processor demonstrate that ALBBA achieves average speedups of 3.91 × , 2.88 × , and 1.46 × over Enterprise, GraphBLAST, and Gunrock running on an NVIDIA H100 GPU, respectively.},
  archive      = {J_PARCO},
  author       = {Yuyao Niu and Marc Casas},
  doi          = {10.1016/j.parco.2025.103147},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103147},
  shortjournal = {Parallel Comput.},
  title        = {ALBBA: An efficient ALgebraic bypass BFS algorithm on long vector architectures},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using java to create and analyze models of parallel computing systems. <em>PARCO</em>, <em>125</em>, 103146. (<a href='https://doi.org/10.1016/j.parco.2025.103146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the study is to develop optimal solutions for models of parallel computing systems using the Java language. During the study, programs were written for the examined models of parallel computing systems. The result of the parallel sorting code is the output of a sorted array of random numbers. When processing data in parallel, the time spent on processing and the first elements of the list of squared numbers are displayed. When processing requests asynchronously, processing completion messages are displayed for each task with a slight delay. The main results include the development of optimization methods for algorithms and processes, such as the division of tasks into subtasks, the use of non-blocking algorithms, effective memory management, and load balancing, as well as the construction of diagrams and comparison of these methods by characteristics, including descriptions, implementation examples, and advantages. In addition, various specialized libraries were analyzed to improve the performance and scalability of the models. The results of the work performed showed a substantial improvement in response time, bandwidth, and resource efficiency in parallel computing systems. Scalability and load analysis assessments were conducted, demonstrating how the system responds to an increase in data volume or the number of threads. Profiling tools were used to analyze performance in detail and identify bottlenecks in models, which improved the architecture and implementation of parallel computing systems. The obtained results emphasize the importance of choosing the right methods and tools for optimizing parallel computing systems, which can substantially improve their performance and efficiency.},
  archive      = {J_PARCO},
  author       = {Harish Padmanaban and Nurkasym Arkabaev and Maher Ali Rusho and Vladyslav Kozub and Yurii Kozub},
  doi          = {10.1016/j.parco.2025.103146},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103146},
  shortjournal = {Parallel Comput.},
  title        = {Using java to create and analyze models of parallel computing systems},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="pr">PR - 153</h2>
<ul>
<li><details>
<summary>
(2026). Heterogeneous graph contrastive learning with spectral augmentation and dual aggregation. <em>PR</em>, <em>172</em>, 112505. (<a href='https://doi.org/10.1016/j.patcog.2025.112505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graphs effectively model complex entity relationships in real-world scenarios. However, existing methods primarily focus on topological structures, overlooking the spectral domain, which limits their ability to capture rich, multi-dimensional graph information. Many rely on meta-path schemes to encode semantic details of specific node types, neglecting others and local structural nuances. Thus, they fail to capture comprehensive structural information. To address these issues, a novel combined d ual a ggregation and s pectral a ugmented algorithm, the h eterogeneous g raph c ontrast l earning model (DasaHGCL), is proposed. It applies adaptive spectral augmentation introduced from homogeneous graph learning to the meta-path view of heterogeneous graphs, capturing their spectral invariance for the first time. It also creates an intra-scheme contrast mechanism in dual aggregation algorithms for meta-path and network schema, which circumvents the effect of differences between different aggregation schemes on the model to effectively capture higher-order semantic information and local heterogeneous structural features. Experiments on multiple real-world datasets demonstrate the clear advantages of DasaHGCL.},
  archive      = {J_PR},
  author       = {Jing Zhang and Wan Zhang and Xiaoqian Jiang and Yingjie Xie and Yali Yuan and Shunmei Meng and Cangqi Zhou},
  doi          = {10.1016/j.patcog.2025.112505},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112505},
  shortjournal = {Pattern Recognition},
  title        = {Heterogeneous graph contrastive learning with spectral augmentation and dual aggregation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conformal prediction of molecule-induced cancer cell growth inhibition challenged by strong distribution shifts. <em>PR</em>, <em>172</em>, 112501. (<a href='https://doi.org/10.1016/j.patcog.2025.112501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drug discovery process often employs phenotypic and target-based virtual screening to identify potential drug candidates. Despite the longstanding dominance of target-based approaches, phenotypic virtual screening is undergoing a resurgence due to its potential being now better understood. In the context of cancer cell lines, a well-established experimental system for phenotypic screens, molecules are tested to identify their whole-cell activity, as summarized by their half-maximal inhibitory concentrations. Machine learning has emerged as a potent tool for computationally guiding such screens, yet important research gaps persist, including generalization and uncertainty quantification. To address this, we leverage a clustering-based validation approach, called Leave Dissimilar Molecules Out (LDMO). This strategy enables a more rigorous assessment of model generalization to structurally novel compounds. This study focuses on applying Conformal Prediction (CP), a model-agnostic framework, to predict the activities of novel molecules on specific cancer cell lines. A total of 4320 independent models were evaluated across 60 cell lines, 5 CP variants, 2 set features, and training-test splits, providing strong and consistent results. From this comprehensive evaluation, we concluded that, regardless of the cell line or model, novel molecules with smaller CP-calculated confidence intervals tend to have smaller predicted errors once measured activities are revealed. It was also possible to anticipate the activities of dissimilar test molecules across 50 or more cell lines. These outcomes demonstrate the robust efficacy that LDMO-based models can achieve in realistic and challenging scenarios, thereby providing valuable insights for enhancing decision-making processes in drug discovery.},
  archive      = {J_PR},
  author       = {Saiveth Hernandez-Hernandez and Qianrong Guo and Pedro J. Ballester},
  doi          = {10.1016/j.patcog.2025.112501},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112501},
  shortjournal = {Pattern Recognition},
  title        = {Conformal prediction of molecule-induced cancer cell growth inhibition challenged by strong distribution shifts},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Salient object ranking with reinforcement learning. <em>PR</em>, <em>172</em>, 112499. (<a href='https://doi.org/10.1016/j.patcog.2025.112499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objects in an image inherently draw attention due to their vivid colors and larger sizes, indicating their high saliency. The salient object ranking (SOR) task aims to prioritize multiple salient objects within a scene based on their saliency levels. Past research has predominantly treated the SOR task as a static process, typically formulating it as a regression or classification problem. However, these approaches overlook the dynamic nature of human attention, which shifts as context and inter-object correlations influence focus. To address this, we employ a reinforcement learning strategy, modeling SOR as a dynamic iterative sequence process. We train an actor to select salient objects from the environment. Additionally, we design a reward strategy that encourages the selection of the most prominent object among those not previously chosen. The selection order generated by the actor directly determines the ranking of object saliency in the scene. Furthermore, we identify limitations in existing SOR evaluation metrics, which may falter in certain scenarios. To address this, we introduce a simple and useful metric, referred to as the F1-Sor, into SOR tasks, improving the evaluation accuracy of the SOR tasks. Our model achieves state-of-the-art performance on publicly available SOR datasets.},
  archive      = {J_PR},
  author       = {Qi Gao and Heng Li and Jianpin Chen and Xinyu Chai},
  doi          = {10.1016/j.patcog.2025.112499},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112499},
  shortjournal = {Pattern Recognition},
  title        = {Salient object ranking with reinforcement learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Affinity-aware uncertainty quantification for learning with noisy labels. <em>PR</em>, <em>172</em>, 112495. (<a href='https://doi.org/10.1016/j.patcog.2025.112495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training deep neural networks (DNNs) with noisy labels is a challenging task that significantly degenerates the model’s performance. Most existing methods mitigate this problem by identifying and eliminating noisy samples or correcting their labels according to statistical properties like confidence values. However, these methods often overlook the impact of inherent noise, such as sample quality, which can mislead DNNs to focus on incorrect regions, adulterate the softmax classifier, and generate low-quality pseudo-labels. In this paper, we propose a novel Affinity-aware Uncertainty Quantification (AUQ) framework to explore the perception ambiguity and rectify the salient bias by quantifying the uncertainty. Concretely, we construct the dynamic prototypes to represent intra-class semantic spaces and estimate the uncertainty based on sample-prototype pairs, where the observed affinities between sample-prototype pairs are converted to probabilistic representations as the estimated uncertainty. Samples with higher uncertainty are likely to be hard samples and we design an uncertainty-aware loss to emphasize the learning from those samples with high uncertainty, which helps DNNs to gradually concentrate on the critical regions. Besides, we further utilize sample-prototype affinities to adaptively refine pseudo-labels, enhancing the quality of supervisory signals for noisy samples. Extensive experiments conducted on the CIFAR-10, CIFAR-100 and Clothing1M datasets demonstrate the efficacy and effectiveness of AUQ. Notably, we achieve an average performance gain of 0.4 % on CIFAR-10 and a substantial average improvement of 2.3 % over the second-best method on the more challenging CIFAR-100 dataset. Moreover, there is a 0.6 % improvement over the sub-optimal method on Clothing1M. These results validate AUQ’s capability in enhancing DNN robustness against noisy labels.},
  archive      = {J_PR},
  author       = {Zhihao Zhou and Rui Li and Wenjie Ai and Xueying Li and Zhu Teng and Baopeng Zhang and Junwei Du},
  doi          = {10.1016/j.patcog.2025.112495},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112495},
  shortjournal = {Pattern Recognition},
  title        = {Affinity-aware uncertainty quantification for learning with noisy labels},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning hierarchical uncertainty from hybrid representations for neural active reconstruction. <em>PR</em>, <em>172</em>, 112493. (<a href='https://doi.org/10.1016/j.patcog.2025.112493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active reconstruction is a key area for the robotics and computer vision communities, enabling autonomous agents to dynamically reconstruct scenes or objects from multiple viewpoints for navigation and manipulation tasks. Although existing methods have achieved promising results in 3D reconstruction, the hierarchical uncertainty-aware active reconstruction based on hybrid implicit representations remains underexplored, particularly in balancing accuracy, efficiency, and adaptability. To address this gap, we propose a neural active reconstruction system that combines hybrid neural representations with uncertainty. Specifically, we explore a novel scheme that integrates occupancy, signed distance function, and neural radiance fields for high-fidelity 3D reconstruction. Additionally, we utilize hierarchical uncertainty associated with different representations to select the next best viewpoint for trajectory planning and optimization. Our system has been extensively evaluated on benchmark datasets including Replica and MP3D, demonstrating qualitatively and quantitatively improved reconstruction quality and view planning efficiency compared to baseline approaches.},
  archive      = {J_PR},
  author       = {Shuaixian Wang and Yaokun Li and Chenhui Guo and Guang Tan},
  doi          = {10.1016/j.patcog.2025.112493},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112493},
  shortjournal = {Pattern Recognition},
  title        = {Learning hierarchical uncertainty from hybrid representations for neural active reconstruction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language model encoded multi-scale feature fusion and transformation for predicting protein-peptide binding sites. <em>PR</em>, <em>172</em>, 112487. (<a href='https://doi.org/10.1016/j.patcog.2025.112487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein-peptide interactions serve as a pivotal and indispensable role in diverse biological functions and cellular processes. Although recent studies have begun to employ language models for predicting protein-peptide binding sites (PPBS), the majority of previous approaches have persisted in utilizing intricate sequence-based feature engineering or incorporating costly experimental structural information. To overcome these limitations, we develop a novel sequence-based end-to-end PPBS predictor using deep learning, named Language model encoded Multi-scale Feature Fusion and Transformation (LMFFT). The proposed model starts with a single protein language model for comprehensive multi-scale feature extraction, including residue, dipeptide, and fragment-level representations, which are implemented by the dipeptide embedding-based fragment fusion and further enhanced through the dipeptide contextual encoding. Moreover, multi-scale convolutional neural networks are applied to transform multi-scale features by capturing intricate interactions between local and global information. Our LMFFT achieves state-of-the-art performance across three benchmark datasets, outperforming existing sequence-based methods and demonstrating competitive advantages over certain structure-based baselines. This work provides a cost-effective and efficient solution for PPBS prediction, advancing revealing the sequence-function relationship of proteins.},
  archive      = {J_PR},
  author       = {Hua Zhang and Pengliang Chen and Xiaoqi Yang and Junhao Wang and Guogen Shan and Bi Chen and Bo Jiang},
  doi          = {10.1016/j.patcog.2025.112487},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112487},
  shortjournal = {Pattern Recognition},
  title        = {Language model encoded multi-scale feature fusion and transformation for predicting protein-peptide binding sites},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-AD: Cross-domain unsupervised anomaly detection for medical and industrial applications. <em>PR</em>, <em>172</em>, 112486. (<a href='https://doi.org/10.1016/j.patcog.2025.112486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional deep learning models often lack annotated data, especially in cross-domain applications such as anomaly detection, which is critical for early disease diagnosis in medicine and defect detection in industry. To address this challenge, we propose Multi-AD, an unsupervised convolutional neural network (CNN) model for robust anomaly detection across medical and industrial domain images. Our approach utilizes the squeeze-and-excitation (SE) block to enhance feature extraction by applying channel-wise attention, enabling the model to focus on the most relevant features and detect subtle anomalies. Additionally, knowledge distillation (KD) transfers informative features from the teacher to the student model, enabling effective learning of the differences between normal and anomalous data. Then, the discriminator network further enhances the model’s capacity to distinguish between normal and anomalous data. At the inference stage, by integrating multi-scale features, the student model gains the ability to detect anomalies of varying sizes. Teacher-student ( T - S ) architecture ensures consistency in representing high-dimensional features while adapting these features to improve anomaly detection. Multi-AD was evaluated on several medical datasets, including brain MRI, liver CT, and retina OCT, as well as industrial datasets, such as MVTec AD, demonstrating strong generalization across multiple domains. Experimental results demonstrated that our approach consistently outperformed state-of-the-art models, achieving the best average accuracy for anomaly localization at both the image level (81.4 % for medical and 99.6 % for industrial) and pixel level (97.0 % for medical and 98.4 % for industrial), making it effective for real-world applications.},
  archive      = {J_PR},
  author       = {Wahyu Rahmaniar and Kenji Suzuki},
  doi          = {10.1016/j.patcog.2025.112486},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112486},
  shortjournal = {Pattern Recognition},
  title        = {Multi-AD: Cross-domain unsupervised anomaly detection for medical and industrial applications},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A collaborative spatial–frequency learning network for infrared and visible image fusion. <em>PR</em>, <em>172</em>, 112480. (<a href='https://doi.org/10.1016/j.patcog.2025.112480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing deep fusion models operate predominantly in the spatial domain, which limits their ability to effectively preserve texture details. In contrast, methods that incorporate frequency-domain information often suffer from inadequate interaction with spatial-domain features, thereby constraining overall fusion performance. To address these limitations, we propose a Collaborative Spatial-Frequency Learning Network (CSFNet) for infrared and visible image fusion. In the frequency-domain learning branch, we introduce a frequency refinement module based on wavelet transform to enable cross-band feature interaction and facilitate effective multi-scale feature fusion. In the spatial-domain branch, we embed a learnable low-rank decomposition model that extracts low-rank features from infrared images and sparse detail features from visible images, forming the basis of a dedicated spatial feature extraction module. Additionally, an information aggregation module is designed to learn complementary representations and integrate cross-domain features efficiently. To validate the effectiveness of the proposed approach, we conducted extensive experiments on three publicly available datasets: MSRS, TNO, and RoadScene, and compared CSFNet with sixteen state-of-the-art (SOTA) fusion methods. On the MSRS dataset, CSFNet achieved favorable results, with a mean and standard deviation of SF = 12.2108 ± 3.8706, VIF = 1.0232 ± 0.1397, Qabf = 0.7112 ± 0.0397, SSIM = 0.6909 ± 0.0859, PSNR = 17.6517 ± 3.8767, and AG = 4.0243 ± 1.5465. The minimum performance improvement over SOTA methods was 1.64 %, while the maximum gain reached 108.82 %. Furthermore, CSFNet demonstrated superior performance on a downstream semantic segmentation task.},
  archive      = {J_PR},
  author       = {Hongbin Yu and Xiangcan Du and Wei Song and Haojie Zhou and Junyi Zhang},
  doi          = {10.1016/j.patcog.2025.112480},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112480},
  shortjournal = {Pattern Recognition},
  title        = {A collaborative spatial–frequency learning network for infrared and visible image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Error-resilient incomplete multi-view clustering: Mitigating imputation-induced error accumulation. <em>PR</em>, <em>172</em>, 112477. (<a href='https://doi.org/10.1016/j.patcog.2025.112477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete Multi-View Clustering (IMC) plays a pivotal role in integrating and analyzing multi-view data with missing information. Most of existing IMC methods improve clustering performance by inherently incorporating a data recovery step to derive a common representation or consensus graph. However, the imputation of missing data may introduce biased errors, which can accumulate and amplify during iterative optimization, ultimately distorting clustering results. To tackle this critical issue, we propose a novel unified optimization framework that jointly learns data completion and error removal in a mutually reinforcing manner. Specifically, our method introduces a dual-path architecture: one path reconstructs missing views via self-representation, while the other path explicitly models and eliminates biased errors. Crucially, these two components interact via an alternating minimization scheme, enabling them to mutually enhance each other. This synergy effectively reduces error accumulation, leading to a more accurate graph for clustering. Experiments on real-world datasets show that the proposed framework achieves state-of-the-art performance under extremely high missing rates (up to 90 %), significantly reducing error propagation while outperforming existing baselines.},
  archive      = {J_PR},
  author       = {Xuanlong Ma and Yanhong She and Fenfang Xie and Guo Zhong},
  doi          = {10.1016/j.patcog.2025.112477},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112477},
  shortjournal = {Pattern Recognition},
  title        = {Error-resilient incomplete multi-view clustering: Mitigating imputation-induced error accumulation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CLIP can understand depth. <em>PR</em>, <em>172</em>, 112475. (<a href='https://doi.org/10.1016/j.patcog.2025.112475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we demonstrate that CLIP can also be adapted to downstream tasks where its vision-language alignment is suboptimally learned during pre-training on web-crawled data, all without requiring fine-tuning. We explore the case of monocular depth estimation, where CLIP’s contrastive prior struggles to generalize, compared to its success in domains such as generative modeling and semantic segmentation. Since CLIP fails to consistently capture similarities between image patches and natural language prompts describing distance, we eliminate the use of its pre-trained natural language token embeddings and distill the semantic prior of its frozen text encoder into a single learnable embedding matrix called “mirror” . The main design goal of mirror is to derive a non-human language prompt that approximates an optimal natural language prompt: “ How far is this location from the camera? ” Using this approach, we jointly train two lightweight modules, a mirror and a compact decoder, on top of a frozen CLIP for dense depth prediction. Compared to conventional depth models, our framework is significantly more efficient in terms of parameters and computation. The resulting model exhibits impressive performance, matching several state-of-the-art vision models on the NYU Depth v2 and KITTI benchmark datasets, while outperforming all vision-language depth models based on a frozen CLIP prior. Specifically, our method reduces the Absolute Relative Error (Abs Rel) by 68.7 % on NYU Depth v2 and by 75.6 % on KITTI compared to the method of Auty et al. , a representative CLIP-based baseline. Experiments demonstrate that the suboptimal depth understanding of CLIP in terms of spatial and temporal consistency can be significantly corrected without either fine-tuning it or concatenating mirror with its pre-trained subword token embeddings. Furthermore, an ablation study on the convergence status of mirror shows that it is implicitly trained to capture objects, such as humans and windows, where semantic cues play an important role in detection.},
  archive      = {J_PR},
  author       = {Sohee Kim and Jisu Kang and Dunam Kim and Seokju Lee},
  doi          = {10.1016/j.patcog.2025.112475},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112475},
  shortjournal = {Pattern Recognition},
  title        = {CLIP can understand depth},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving adversarial transferability via semantic-style joint expectation perturbations. <em>PR</em>, <em>172</em>, 112474. (<a href='https://doi.org/10.1016/j.patcog.2025.112474'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Style and content information, which are model-independent inherent properties of an image, serve as crucial information that deep neural networks depend on for classification tasks. However, most existing gradient-based attacks mainly distort content-related information through semantic distortion of the model’s final output, neglecting the role of style information. To fully distort the inherent intrinsic information of the image, this paper proposes Semantic-Style joint Expectation Perturbations (SSEPs). Specifically, we first establish a style loss based on the kernel function from the feature space of the surrogate model and inject it into gradient-based attacks to form a Semantics-Style joint Loss (SSL) for generating joint perturbations. Subsequently, we use gradient normalization and the proposed dynamic gradient decomposition scheme to address the problems of multi-objective gradient magnitude differences and gradient conflicts that occur in SSL during optimization. Finally, we generate SSEPs by motivating the maximization of the expected loss, thereby enhancing the transferability of Adversarial Examples (AEs). On the ImageNet sub-dataset, extensive experiments show that AEs covered with SSEPs have high transferability. Compared to the baseline attack (MI-FGSM), our method achieves at least a 14 % and 5 % higher attack success rate for normally trained models and defense models, respectively. Compared with other classic and advanced gradient-based attacks and feature-level attacks, our method still has advantages in attack performance. Our code is available at: https://github.com/OUTOFTEN/TransferAttack-ssep},
  archive      = {J_PR},
  author       = {Zhi Lin and Bingwen Wang and Xixi Wang and Yu Zhang and Xiao Wang and Kang Deng and Anjie Peng and Jin Tang and Xing Yang},
  doi          = {10.1016/j.patcog.2025.112474},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112474},
  shortjournal = {Pattern Recognition},
  title        = {Improving adversarial transferability via semantic-style joint expectation perturbations},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SAR image change detection based on saliency region guidance and SIFT keypoint extraction. <em>PR</em>, <em>172</em>, 112471. (<a href='https://doi.org/10.1016/j.patcog.2025.112471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic Aperture Radar (SAR) can operate under all-weather, all-day conditions, playing a crucial role in regional change detection (CD). However, due to its unique imaging principles, SAR images contain significant speckle noise and blurred boundary and detail features, which reduces the detection accuracy and leads to missed detection and false detection. To address these issues, this paper proposes a SAR image CD method based on saliency region guidance and Scale-Invariant Feature Transform (SIFT) keypoint extraction to reduce the interference of speckle noise. First, a saliency region guidance method is introduced to analyze the saliency of local features in SAR images, extracting potentially changed regions and reducing the interference of speckle noise. Second, the SIFT is employed to extract keypoints in regions significantly different from the background in the difference map, leveraging its robustness to speckle noise. By extracting keypoints, the approximate location and extent of the changed regions are determined. These are, then, fused with the saliency region information, enhancing the saliency weights of pixels around keypoints for more extraction of change regions. Finally, a Vision Transformer (ViT) detection network is used for SAR image CD, utilizing the combined saliency information from the original saliency map and SIFT keypoints. This approach effectively integrates SIFT’s stable description of local features with ViT’s modeling capability for global features, improving the model’s accuracy and robustness.},
  archive      = {J_PR},
  author       = {Lu Wang and Bailiang Sun and Chunhui Zhao and Suleman Mazhar and Tomoaki Ohtsuki and P. Takis Mathiopoulos and Fumiyuki Adachi},
  doi          = {10.1016/j.patcog.2025.112471},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112471},
  shortjournal = {Pattern Recognition},
  title        = {SAR image change detection based on saliency region guidance and SIFT keypoint extraction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anisotropic pth-order TV-based retinex decomposition with adaptive reflectance regularizer for low-light image enhancement. <em>PR</em>, <em>172</em>, 112468. (<a href='https://doi.org/10.1016/j.patcog.2025.112468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image enhancement plays a fundamental role in image processing and computer vision. Its primary purpose is to improve the visual quality of an image by enhancing its contrast and brightness. However, most existing enhancement methods tend to amplify the imaging noise, especially in very dark regions of the image, leading to undesirable artifacts in the enhanced result. To address this problem, this paper aims to develop a method that enhances low-light images without introducing these artifacts. We propose a novel anisotropic p th-order total variation-based (ApTV-based) Retinex decomposition with an adaptive reflectance regularizer for low-light image enhancement, where p represents the exponent in our regularization term, controlling the degree of structure preservation in the resulting image. Specifically, for 0 < p ≤ 1 , the ApTV with a smaller p -value can effectively extract strong structures of the image, making it suitable for piecewise smooth illumination estimation. In contrast, a larger p -value can help preserve the image’s fine details and suppress noise, making it favorable for accurate reflectance estimation. More importantly, since the degree of noise amplification varies across different regions, we incorporate the obtained illumination into the reflectance regularizer to enable adaptive denoising. Extensive numerical experiments and comparisons with state-of-the-art low-light image enhancement methods demonstrate that the proposed adaptive Retinex decomposition approach achieves superior performance both qualitatively and quantitatively. It effectively addresses noise amplification and artifact issues while enhancing overall image quality.},
  archive      = {J_PR},
  author       = {Po-Wen Hsieh and Suh-Yuh Yang},
  doi          = {10.1016/j.patcog.2025.112468},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112468},
  shortjournal = {Pattern Recognition},
  title        = {Anisotropic pth-order TV-based retinex decomposition with adaptive reflectance regularizer for low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cooperative multi-task learning and reliability assessment for glioma segmentation and IDH genotyping. <em>PR</em>, <em>172</em>, 112467. (<a href='https://doi.org/10.1016/j.patcog.2025.112467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high heterogeneity of gliomas presents significant challenges in distinguishing isocitrate dehydrogenase (IDH) genotypes based on magnetic resonance imaging (MRI) features. To address this issue, we propose a joint optimization framework based on multi-task learning (MLNet), which enables the simultaneous optimization of glioma segmentation and IDH genotype prediction within a unified framework. First, we design a glioma segmentation network based on a CNN-Transformer hybrid architecture to extract glioma features. Second, feature fusion is employed to provide feature support for the IDH genotyping task. A reliability assessment mechanism is introduced to evaluate the IDH genotyping results, determining whether a secondary assessment is necessary. Finally, we construct a multi-task learning loss function and achieve end-to-end joint training through feature sharing across tasks. We evaluate the proposed method on the BraTs2020 dataset, and comparisons with state-of-the-art methods demonstrate that the multi-task learning method offers superior performance.},
  archive      = {J_PR},
  author       = {Meng Li and Du Jiang and Juntong Yun and Rong Liu and Ying Sun and Gongfa Li},
  doi          = {10.1016/j.patcog.2025.112467},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112467},
  shortjournal = {Pattern Recognition},
  title        = {Cooperative multi-task learning and reliability assessment for glioma segmentation and IDH genotyping},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gaussian splitting attack: Gaussian splatting-based multi-view 3D adversarial attack. <em>PR</em>, <em>172</em>, 112466. (<a href='https://doi.org/10.1016/j.patcog.2025.112466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing multi-view adversarial attack methods utilize Neural Radiance Fields (NeRF) to generate adversarial samples from different viewpoints of an object effectively deceiving deep neural networks. However, these methods simply add noise to the rendered images and fail to construct explicit 3D adversarial samples limited by the implicit representation of NeRF. To address the above limitation, we propose a novel G aussian S plitting Attack ( GSAttack ) scheme based on Gaussian Splatting to generate explicit 3D adversarial samples that deceive the classifier in various viewpoints . Specifically, we first quantify the contribution of each Gaussian based on its gradient in adversarial attack. Subsequently, we split tiny Gaussians from the high contribution Gaussians as initial 3D perturbations, which are then optimized by adversarial loss to ensure deception in diverse viewpoints. Furthermore, to ensure the invisibility of 3D perturbation, we devise position and color losses to make the perturbations tightly bound to the object surface and minimize the color differences. Owing to these ingenious designs, our 3D perturbations are more natural in space and effective attack neural network. Experimental results show that the 3D adversarial samples generated by our GSAttack can effectively deceive the classifier over a wider range of viewpoints and achieve superior visualization compared to existing schemes.},
  archive      = {J_PR},
  author       = {Lingzhuang Meng and Mingwen Shao and Yuanjian Qiao and Wenjie Liu and Xiang Lv},
  doi          = {10.1016/j.patcog.2025.112466},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112466},
  shortjournal = {Pattern Recognition},
  title        = {Gaussian splitting attack: Gaussian splatting-based multi-view 3D adversarial attack},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hypergraph regularization-based anchor learning for multi-view clustering. <em>PR</em>, <em>172</em>, 112465. (<a href='https://doi.org/10.1016/j.patcog.2025.112465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current anchor graph-based multi-view clustering methods can effectively address the problem of high computational cost for clustering large-scale multimedia data. However, they have the following shortcomings: (1) The relationships between anchor points are not adequately considered. (2) The correlations between the consistent anchor graph and diverse anchor graphs are ignored. To handle these issues, we propose a novel multi-view clustering method named Hypergraph Regularization-Based Anchor Learning (HRFAL). Specifically, we first process the original data to obtain a consistent anchor graph and diverse anchor graphs, which can explore more comprehensive consistent and complementary information. Meanwhile, the hyper-Laplacian regularization is applied to the anchor points to explore the higher-order relationships between the anchor points, thus enabling the generation of high-quality anchor graphs. Furthermore, the orthogonal diversity constraints are imposed on the consistent and diverse anchor graphs to enhance the distinction between the consistent and diverse components, resulting in better exploitation of consistent and complementary information. Finally, the Schatten p -norm constraint is implemented on the consistent anchor graph to maintain its low-rank structure, thus obtaining more robust consistent information. Experimental results on eight multi-view datasets show that HRFAL exhibits superior performance in terms of accuracy and speed.},
  archive      = {J_PR},
  author       = {Yunpeng Zeng and Peng Song and Beihua Yang and Changjia Wang and Guanghao Du and Yanwei Yu and Wenming Zheng},
  doi          = {10.1016/j.patcog.2025.112465},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112465},
  shortjournal = {Pattern Recognition},
  title        = {Hypergraph regularization-based anchor learning for multi-view clustering},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-layer processing and coarse filtering network for accurate feature matching. <em>PR</em>, <em>172</em>, 112464. (<a href='https://doi.org/10.1016/j.patcog.2025.112464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core task of feature matching is establishing correspondences between two images. The methods based on Transformers have achieved impressive results, which can directly capture the relationships among all features without relying on the distances between them. However, it also reduce the weight of long-distance texture features and ignore simultaneous integration of global, local, and multi-scale features, leading to limited matching accuracy. To address this issue, we propose a detector-free feature matching method based on Transformer with multi-level processing and coarse-grained filtering. First, we apply a local window aggregation module to minimize irrelevant interference through window attention and combine local self-attention with global self-attention to ensure the features have a global perspective but not lose local details. Then, the multi-scale features are processed in layers, integrating multi-scale information into the matching phase, allowing each layer to perform feature matching at different scales for more precise matches. Additionally, we designed a filter to discard incorrectly matched points in the global context, thereby improving the accuracy of the matching points. Extensive experiments demonstrate that our method delivers excellent results comparing with the current state-of-the-art techniques in the tasks of pose estimation, homography estimation, and visual localization. Compared with the baseline method LoFTR, our method achieves an average improvement of 16.07 % in pose estimation, 6.52 % in homography estimation, and 9.69 % in visual localization. Meanwhile, our method also demonstrates superior performance compared to other state-of-the-art feature matching approaches.},
  archive      = {J_PR},
  author       = {Yuan Guo and Wenpeng Li and Ping Zhai},
  doi          = {10.1016/j.patcog.2025.112464},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112464},
  shortjournal = {Pattern Recognition},
  title        = {A multi-layer processing and coarse filtering network for accurate feature matching},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-level noise augmentation for graph clustering with triplet-wise contrastive learning. <em>PR</em>, <em>172</em>, 112463. (<a href='https://doi.org/10.1016/j.patcog.2025.112463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive deep graph clustering has attracted widespread attention due to its self-supervised representation learning mechanism and excellent clustering performance. Although, most existing methods rely on low-pass filtering to achieve denoising, ignoring the potential benefit of high-frequency information and noise in obtaining comprehensive and robust representation. Second, commonly used contrastive learning strategies generally treat non-target samples as negative samples, which is prone to triggering contrastive bias and weakening the representation quality. To this end, this paper proposes a novel contrastive graph clustering framework, Dual-level Noise Augmentation for Graph Clustering with triplet-wise Contrastive learning (DNA-CGC), strengthening the benefit of noise to enrich the representation learning and amplify the contrastive learning efficacy. It consists of two core modules, Hybrid Noise Representation Augmentation (HNRA) and Noise-Aware Contrastive Learning (NACL). The HNRA module integrates low- and high-frequency graph signals to capture both shared and distinctive node characteristics, while introducing Gaussian noise as beneficial perturbation to enrich the representation diversity, thereby achieving multi-information fusion under hybrid noise. The NACL module, on the other hand, generates exclusive negative samples through Gaussian noise and constructs the triplet-wise contrastive pairs (Target, Positive, Negative), mitigating the contrastive bias by preventing false negatives and further facilitating more accurate semantic alignment. Extensive experiments on six benchmark datasets validate the significant advantages of DNA-CGC in terms of clustering performance and representation quality. The code could be available at https://github.com/TianxiangZhao0474/DNA-CGC.git .},
  archive      = {J_PR},
  author       = {Tianxiang Zhao and Youqing Wang and Shilong Xu and Tianchuan Yang and Junbin Gao and Jipeng Guo},
  doi          = {10.1016/j.patcog.2025.112463},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112463},
  shortjournal = {Pattern Recognition},
  title        = {Dual-level noise augmentation for graph clustering with triplet-wise contrastive learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving lesion segmentation in medical images by global and regional feature compensation. <em>PR</em>, <em>172</em>, 112461. (<a href='https://doi.org/10.1016/j.patcog.2025.112461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated lesion segmentation of medical images has made tremendous improvements in recent years due to deep learning advancements. However, accurately capturing fine-grained global and regional feature representations remains a challenge. Many existing methods achieve suboptimal performance in complex lesion segmentation due to information loss during typical downsampling operations and insufficient capture of either regional or global features. To address these issues, we propose the Global and Regional Compensation Segmentation Framework (GRCSF), which introduces two key innovations: the Global Compensation Unit (GCU) and the Region Compensation Unit (RCU). The proposed GCU addresses resolution loss in the U-shaped backbone by preserving global contextual features and fine-grained details during multiscale downsampling. Meanwhile, the RCU introduces a self-supervised learning (SSL) residual map generated by Masked Autoencoders (MAE), obtained as pixel-wise differences between reconstructed and original images, to highlight regions with potential lesions. These SSL residual maps guide precise lesion localization and segmentation through a patch-based cross-attention mechanism that integrates regional spatial and pixel-level features. Additionally, the RCU incorporates patch-level importance scoring to enhance feature fusion by leveraging global spatial information from the backbone. Experiments on three publicly available medical image segmentation datasets, including brain stroke lesion, lung tumor and coronary artery calcification datasets, demonstrate that our GRCSF outperforms state-of-the-art methods, confirming its effectiveness across diverse lesion types and its potential as a generalizable lesion segmentation solution.},
  archive      = {J_PR},
  author       = {Chuhan Wang and Zhenghao Chen and Jean Y.H. Yang and Jinman Kim},
  doi          = {10.1016/j.patcog.2025.112461},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112461},
  shortjournal = {Pattern Recognition},
  title        = {Improving lesion segmentation in medical images by global and regional feature compensation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RGBX-DiffusionDet: A framework for multi-modal RGB-X object detection using DiffusionDet. <em>PR</em>, <em>172</em>, 112460. (<a href='https://doi.org/10.1016/j.patcog.2025.112460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the challenge of object detection using multimodal heterogeneous sensors by extending the recently proposed DiffusionDet framework, initially designed for RGB-only detection. We propose RGBX-DiffusionDet, a generalized diffusion-based object detection framework that enables seamless fusion of heterogeneous 2D modalities (denoted as “X”, e.g., depth, infrared, and polarimetric data) with RGB imagery. The proposed approach adopts a mid-level feature fusion strategy to address the heterogeneous nature of multimodal data, characterized by varying spatial resolutions, noise profiles, and semantic content. Instead of commonly used brute-force feature concatenation, we introduce two novel architectural components: (1) a dynamic channel reduction convolutional block attention module (DCR-CBAM), which enhances cross-modal fusion by emphasizing salient channel features while reducing the dimensionality of merged RGB-X features, and (2) a dynamic multi-level aggregation block (DMLAB), which addresses a limitation of the baseline DiffusionDet decoder by adaptively fusing spatial features to improve object localization. Additionally, we incorporate novel regularization losses that promote channel saliency and spatial selectivity, resulting in compact and discriminative feature embeddings. Extensive experiments on RGB-depth (KITTI), a newly annotated RGB-polarimetric (RGB-P) dataset, and RGB-infrared (M3FD) benchmarks demonstrate consistent superiority of the proposed approach over RGB-only baselines, while maintaining decoding efficiency. We further show that RGBX-DiffusionDet exhibits improved robustness and generalization capability in visually-corrupted conditions, demonstrating its practical efficiency for robust multimodal object detection.},
  archive      = {J_PR},
  author       = {Eliraz Orfaig and Inna Stainvas and Igal Bilik},
  doi          = {10.1016/j.patcog.2025.112460},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112460},
  shortjournal = {Pattern Recognition},
  title        = {RGBX-DiffusionDet: A framework for multi-modal RGB-X object detection using DiffusionDet},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FedFAT: Frequency adpative interpolation for federated domain generalization on heterogeneous medical images. <em>PR</em>, <em>172</em>, 112459. (<a href='https://doi.org/10.1016/j.patcog.2025.112459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple distributed medical institutions can leverage federated learning (FL) to collaboratively build a shared prediction model with privacy protection. However, the presence of non-independent and identically distributed (non-IID) data in medical imaging leads to data drift in practical learning scenarios, detrimentally affecting both convergence and generalization to the unseen domain. In this paper, we propose a novel framework named Federated Frequency Adaptive Interpolation(FedFAT), which leverages a frequency space adaptive interpolation mechanism to mitigate data drift in federated domain generalization. FedFAT enables clients to adaptively exchange partial amplitude information, leveraging multi-source data distributions to enhance generalization. Crucially, local phase information is retained to preserve privacy. To mitigate data drift, FedFAT employs cross-client feature alignment via amplitude normalization, which effectively batch-normalizes images from diverse source distributions. Furthermore, we introduce a client-specific weight perturbation mechanism designed to guide local models toward a consistent low-loss region. We have theoretically analyzed the proposed method and empirically conducted extensive experiments on two medical image classification and segmentation tasks, showing that FedFAT outperforms a set of recent state-of-the-art methods with average Dice improvement of 2.42 % and 10.61 % on the prostate MRI segmentation datasets (PROMISE12, PROSTATEx, and NCI-ISBI) and breast cancer classification datasets(CAMELYON17), respectively. FedFAT also has an improvement of 4.15 % on generalization performance. These results demonstrate the superiority of FedFAT in handling data drift and improving generalization performance.},
  archive      = {J_PR},
  author       = {Donghao Wang and Yingchun Cui and Mingyang Li and Heran Xi and Jinghua Zhu},
  doi          = {10.1016/j.patcog.2025.112459},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112459},
  shortjournal = {Pattern Recognition},
  title        = {FedFAT: Frequency adpative interpolation for federated domain generalization on heterogeneous medical images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards unified molecule-enhanced pathology image representation learning via integrating spatial transcriptomics. <em>PR</em>, <em>172</em>, 112458. (<a href='https://doi.org/10.1016/j.patcog.2025.112458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multimodal pre-training have advanced computational pathology, but current visual-language approaches lack molecular perspective and face performance bottlenecks in clinical settings. Here, we introduce a U nified M olecule-enhanced P athology I mage RE presentation Learning framework ( UMPIRE ) that enhances the robustness and generalization capabilities of pathology image analysis across diverse tissue types and sequencing platforms. UMPIRE leverages complementary information from gene expression profiles to guide multimodal pre-training, addressing the challenge of distribution shifts between research and clinical environments. To overcome the scarcity of paired data, we collected more than 4 million entries of spatial transcriptomics gene expression to train the gene encoder. UMPIRE aligns modalities across 697K pathology image-gene expression pairs, creating a foundation model that demonstrates superior generalization across multiple sequencing platforms and downstream tasks without additional fine-tuning. Comprehensive evaluation shows UMPIRE ’s effectiveness in gene expression prediction, spot classification, and mutation state prediction in whole slide images, with significant improvements over state-of-the-art methods. Our findings demonstrate how molecular data integration enhances visual pattern recognition in computational pathology, providing a resilient approach for bench-to-bedside translation. The code and pre-trained weights are available at https://github.com/Hanminghao/Umpire .},
  archive      = {J_PR},
  author       = {Minghao Han and Dingkang Yang and Jiabei Cheng and Xukun Zhang and Zizhi Chen and Haopeng Kuang and Lihua Zhang},
  doi          = {10.1016/j.patcog.2025.112458},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112458},
  shortjournal = {Pattern Recognition},
  title        = {Towards unified molecule-enhanced pathology image representation learning via integrating spatial transcriptomics},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HMSNet: Hilbert curve enhanced mamba for real-time semantic segmentation. <em>PR</em>, <em>172</em>, 112457. (<a href='https://doi.org/10.1016/j.patcog.2025.112457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a core technology for vehicle perception of the surrounding environment in autonomous driving. However, existing real-time semantic segmentation models face two major challenges: loss of local detail information and inconsistency of intra-class semantic information. To address these issues, we propose a novel network architecture, HMSNet. The network mainly consists of the following three core modules: the Hilbert curve enhanced Visual Mamba Block (HVM Block), Selective Attention Fusion Module (SAFM), and Multi-scale Context-Aware Module (MCAM). The HVM Block utilizes the Hilbert curve to reduce the dimensionality of two-dimensional images and applies a selective scanning algorithm in Mamba, enabling the network to effectively capture local dependencies while maintaining a global receptive field, thereby optimizing the consistency of intra-class semantic information. The SAFM module effectively merges local detail information from shallow networks with global semantic information from deep networks, alleviating the problem of local detail information loss. Finally, the MCAM module, introduced at the end of the network, enhances the model,s ability to judge contextual information, thereby improving segmentation accuracy. Experimental results show that HMSNet achieves an excellent balance between segmentation accuracy and inference speed on challenging public datasets, including CamVid, Cityscapes, and ADE20K.},
  archive      = {J_PR},
  author       = {Lianyin Jia and Aoxiang Gao and Mengjuan Li and Xiaodong Fu and Haihe Zhou and Jiaman Ding},
  doi          = {10.1016/j.patcog.2025.112457},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112457},
  shortjournal = {Pattern Recognition},
  title        = {HMSNet: Hilbert curve enhanced mamba for real-time semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trend-aware time series clustering via self-attentive LSTM. <em>PR</em>, <em>172</em>, 112455. (<a href='https://doi.org/10.1016/j.patcog.2025.112455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series clustering aims to partition time series into subsets with similar patterns, uncovering their underlying structures and dynamics. This paper proposes a novel clustering method that integrates polynomial curve fitting, an enhanced self-attention mechanism, and a long short-term memory (LSTM) network. First, the Hodrick-Prescott (HP) filter is applied to denoise the raw time series. Then, polynomial curve fitting (PCF) is employed to extract multi-order derivative features at each time point, capturing local trend information and constructing a high-dimensional feature space. An enhanced self-attention LSTM model is designed to encode both raw and trend-based features into a hidden state sequence, enabling the model to capture key patterns and long-range dependencies. Finally, a distance metric based on the hidden states is defined and incorporated into a hierarchical clustering (HC) algorithm. Experiments on several public univariate datasets with long sequences demonstrate that the proposed method outperforms conventional approaches, offering a robust solution for modeling and interpreting complex time series.},
  archive      = {J_PR},
  author       = {Chongyan Wu and Bin Yu},
  doi          = {10.1016/j.patcog.2025.112455},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112455},
  shortjournal = {Pattern Recognition},
  title        = {Trend-aware time series clustering via self-attentive LSTM},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view biclustering via non-negative matrix tri-factorisation. <em>PR</em>, <em>172</em>, 112454. (<a href='https://doi.org/10.1016/j.patcog.2025.112454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data is ever more apparent as methods for production, collection and storage of data become more feasible both practically and fiscally. However, not all features are relevant to describe the patterns for all individuals. Multi-view biclustering aims to simultaneously cluster both rows and columns, discovering clusters of rows as well as their view-specific identifying features. A novel multi-view biclustering approach based on non-negative matrix factorisation is proposed named ResNMTF. Demonstrated through extensive experiments on both synthetic and real datasets, ResNMTF successfully identifies both overlapping and non-exhaustive biclusters, without pre-existing knowledge of the number of biclusters present, and is able to incorporate any combination of shared dimensions across views. Further, to address the lack of a suitable bicluster-specific intrinsic measure, the popular silhouette score is extended to the bisilhouette score. The bisilhouette score is demonstrated to align well with known extrinsic measures, and proves useful as a tool for hyperparameter tuning as well as visualisation.},
  archive      = {J_PR},
  author       = {Ella S.C. Orme and Theodoulos Rodosthenous and Marina Evangelou},
  doi          = {10.1016/j.patcog.2025.112454},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112454},
  shortjournal = {Pattern Recognition},
  title        = {Multi-view biclustering via non-negative matrix tri-factorisation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “Efficient multi-view discrete co-clustering with learned graph” [Pattern recognition 168 (2025) 111811]. <em>PR</em>, <em>172</em>, 112453. (<a href='https://doi.org/10.1016/j.patcog.2025.112453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PR},
  author       = {Jiaqi Nie and Qianyao Qiang and Jason Chen Zhang and Fei Hao},
  doi          = {10.1016/j.patcog.2025.112453},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112453},
  shortjournal = {Pattern Recognition},
  title        = {Corrigendum to “Efficient multi-view discrete co-clustering with learned graph” [Pattern recognition 168 (2025) 111811]},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LayerCLIP: A fine-grained class activation map for weakly supervised semantic segmentation. <em>PR</em>, <em>172</em>, 112452. (<a href='https://doi.org/10.1016/j.patcog.2025.112452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation (WSSS) using image-level labels aims to create pseudo-labels leveraging Class Activation Maps (CAM) to train a separate segmentation model. Recent methods that utilize Contrastive Language-Image Pre-training (CLIP) models have achieved significant advancements. These approaches take advantage of CLIP’s capability to identify various categories without requiring additional training. However, due to the limited local information of the final embedding layer, the CAM generated by the CLIP model is still a rough region with an under-activated or over-activated issue. Furthermore, the abundant multi-layer information of CLIP, which plays a vital role in dense prediction, has been ignored. In this paper, we proposed a LayerCLIP model for a fine-grained CAM generation via hierarchical features, which consists of two consecutive components: a dynamic hierarchical CAMs module and an adaptive affinity module. Specifically, the dynamic hierarchical CAMs module utilizes the hierarchical features to produce two complementary CAMs, along with a dynamic strategy to fuse these CAMs. Subsequently, the affinity based on multi-head self-attention is adaptively reweighted to refine CAM by the CAM itself in the adaptive affinity module. LayerCLIP significantly enhances the quality of CAM. Our method achieves a new state-of-the-art performance on PASCAL VOC 2012 (75.1 % mIoU) and MS COCO 2014 (46.9 % mIoU) through extensive benchmark experiments.},
  archive      = {J_PR},
  author       = {Lingma Sun and Le Zou and Xianghu Lv and Zhize Wu and Xiaofeng Wang},
  doi          = {10.1016/j.patcog.2025.112452},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112452},
  shortjournal = {Pattern Recognition},
  title        = {LayerCLIP: A fine-grained class activation map for weakly supervised semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generative models for noise-robust training in unsupervised domain adaptation. <em>PR</em>, <em>172</em>, 112450. (<a href='https://doi.org/10.1016/j.patcog.2025.112450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent unsupervised domain adaptation (UDA) methods show the effectiveness of pseudo-labels for unlabeled target domain. However, pseudo-labels inevitably contain noise, which can degrade adaptation performance. This paper thus propose a Generative models for Noise-Robust Training (GeNRT), a method designed to mitigate label noise while reducing domain shift. The key idea is leveraging the class-wise distributions of the target domain, modeled by generative models, provide more reliable pseudo-labels than individual pseudo-labeled instances. This is because the distributions statistically better represent class-wise information than a single instance. Based on this observation, GeNRT incorporates a Distribution-based Class-wise Feature Augmentation (D-CFA), which enhances feature representations by sampling features from target class distributions modeled by generative models. These augmented features serve a dual purpose: (1) providing class-level knowledge from generative models to train a noise-robust discriminative classifier, and (2) acting as intermediate features to bridge the domain gap at the class level. Furthermore, GeNRT leverages Generative and Discriminative Consistency (GDC), enforcing consistency regularization between a generative classifier (formed by all class-wise generative models) and the learned discriminative classifier. By aggregating knowledge across target class distributions, GeNRT improves pseudo-label reliability and enhances robustness against label noise. Extensive experiments on Office-Home, VisDA-2017, PACS, and Digit-Five show that our GeNRT achieves comparable performance to state-of-the-art methods under both single-source and multi-source UDA settings.},
  archive      = {J_PR},
  author       = {Zhongying Deng and Da Li and Junjun He and Xiaojiang Peng and Yi-Zhe Song and Tao Xiang},
  doi          = {10.1016/j.patcog.2025.112450},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112450},
  shortjournal = {Pattern Recognition},
  title        = {Generative models for noise-robust training in unsupervised domain adaptation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tiny object detection based on dynamic scale-awareness label assignment and contextual enhancement. <em>PR</em>, <em>172</em>, 112449. (<a href='https://doi.org/10.1016/j.patcog.2025.112449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prosperity of recent object detection can not camouflage the deficiencies of tiny object detection. The generic object detectors suffer a dramatic performance degradation on tiny object detection. For this purpose, we present a tiny object detection approach based on Dynamic scale-awareness label assignment and Contextual enhancement (DCNet), which improves the tiny object detection performance from label assignment and feature enhancement perspectives. Considering the IoU-based label assignment seriously harms the positive samples for tiny objects, we design a Dynamic Scale-Awareness (DSA) label assignment to replace it in the region proposal network. The DSA label assignment adaptively rescales preset anchors and introduces the regression information to better assign the preset anchors for tiny objects. Furthermore, the tiny objects often exhibit weak feature responses due to their poor-quality appearance. Therefore, we propose a contextual enhancement module that aggregates contextual information at different scales to enhance tiny objects’ feature responses. Comprehensive experimental analyses on multiple datasets confirm the effectiveness and good generality of our proposed DCNet in tiny object detection.},
  archive      = {J_PR},
  author       = {Tianyang Zhang and Xiangrong Zhang and Chaozhuo Hua and Guanchun Wang and Xiao Han and Licheng Jiao},
  doi          = {10.1016/j.patcog.2025.112449},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112449},
  shortjournal = {Pattern Recognition},
  title        = {Tiny object detection based on dynamic scale-awareness label assignment and contextual enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DBL: Dual-level balanced learning for long-tailed classification. <em>PR</em>, <em>172</em>, 112448. (<a href='https://doi.org/10.1016/j.patcog.2025.112448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data are typically long-tailed, causing neural networks to over-fit head classes and underperform on rare tails. We propose Dual-Level Balanced Learning (DBL), an efficient training framework that balances gradients at both the class and instance levels. DBL combines Class-aware Balancing (CB), which corrects class-level imbalance by re-weighting gradients according to prediction bias; Instance-aware Balancing (IB), which alleviates instance-level imbalance by emphasising the learning of hard examples; and a lightweight Cross-Level Collaboration (CC) scheme that harmonises the two losses. By jointly addressing class- and instance-level imbalance, DBL delivers consistent gains across all classes and most individual samples. Extensive experiments on CIFAR10/100-LT, ImageNet-LT, Places-LT, and iNaturalist18 show that DBL sets new state-of-the-art accuracy on all five benchmarks, confirming its robustness to severe long-tailed distributions.},
  archive      = {J_PR},
  author       = {Zheng Wu and Kehua Guo and Sheng Ren and Bin Hu and Xiangyuan Zhu and Rui Ding},
  doi          = {10.1016/j.patcog.2025.112448},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112448},
  shortjournal = {Pattern Recognition},
  title        = {DBL: Dual-level balanced learning for long-tailed classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-frequency shared-feature-learning based diffusion model for removing surgical smoke. <em>PR</em>, <em>172</em>, 112447. (<a href='https://doi.org/10.1016/j.patcog.2025.112447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical smoke in laparoscopic surgery can deteriorate visibility for surgeons. This work aims to simultaneously remove the surgical smoke and restore true-to-life image colors with deep learning. However, deep learning-based smoke removal remains a challenge due to: 1) the non-homogeneous distribution of surgical smoke, 2) higher frequency modes being hindered from being learned due to spectral bias. In this work, we propose the multi-frequency shared-feature-learning based conditional diffusion model with adaptive smoke attention for removing surgical smoke. The proposed model learns to map both the smoky and smokeless images into a shared inherent feature by the forward learning and synthesize the smokeless image by the reverse learning, and the input noisy image used for the forward learning is wrapped by the smoke attention learning to ease sampling steps and facilitate shared feature optimization. The smoke attention learning employs smoke segmentation and convolutional block attention modules to capture the non-homogeneous features of smoke. The multi-frequency learning is introduced to incorporate with shared feature learning to enhance the mid-to-high frequency features. In addition, the multi-task learning incorporates shared feature loss, smoke perception loss, dark channel prior loss, and contrast enhancement loss to help the model optimization. The experimental results show that the proposed method outperforms other state-of-the-art methods on both synthetic/real laparoscopic surgical images, with the potential to be embedded in laparoscopic devices for de-smoking.},
  archive      = {J_PR},
  author       = {Hao Li and Xiangyu Zhai and Ziwei Liang and Jie Xue and Bin Jin and Haitao Niu and Guangyong Zhang and Huanxin Ding and Dengwang Li and Pu Huang},
  doi          = {10.1016/j.patcog.2025.112447},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112447},
  shortjournal = {Pattern Recognition},
  title        = {Multi-frequency shared-feature-learning based diffusion model for removing surgical smoke},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SeeD: Online similarity-preserving pattern discovery for streaming trajectories. <em>PR</em>, <em>172</em>, 112446. (<a href='https://doi.org/10.1016/j.patcog.2025.112446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid accumulation of fresh trajectory data has fueled a growing interest in the analysis of such data. There has been a notable economic and social value attributed to effectively uncovering mobility behaviors within rich, streaming trajectory data for applications like urban planning, marketing and intelligence. Despite extensive research on pattern discovery, existing methods often confine themselves to fixed patterns, neglecting the potential synergy between pattern discovery and similarity queries. This synergy can be bidirectional: similarity results could be the foundation of pattern discovery, while pattern discovery can accelerate the similarity queries. To bridge this gap, we propose the Online S imilarity-preserving Traj e ctory Patt e rn D iscovery, called SeeD . This framework consists of three core modules: (1) The composite windowing strategy, which extracts multi-scale trajectory information and maintains correlation patterns, ensuring data relevance across various scales. (2) The C lustering-based S imilarity Q uery (CSQ) module, which accelerates similarity computation based on pattern discovery results, thus improving query efficiency. (3) The E volution D etection and A nalysis (EDA) module, which enhances overall performance by analyzing pattern evolution, providing insights into dynamic changes within trajectory data. Extensive experimental results conducted on well-established datasets unequivocally demonstrate the effectiveness of SeeD, indicating its potential to revolutionize the field by offering a robust solution for pattern discovery.},
  archive      = {J_PR},
  author       = {Junhua Fang and Jiayi Li and Chunhui Feng and Zhicheng Pan and Pingfu Chao and Jiajie Xu and Pengpeng Zhao},
  doi          = {10.1016/j.patcog.2025.112446},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112446},
  shortjournal = {Pattern Recognition},
  title        = {SeeD: Online similarity-preserving pattern discovery for streaming trajectories},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Decoding the brain via multi-view brain topology contrastive learning. <em>PR</em>, <em>172</em>, 112445. (<a href='https://doi.org/10.1016/j.patcog.2025.112445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Graph Neural Networks (GNNs) have been widely used in neural decoding due to strong topological feature mining and interpretability. GNNs are heavily based on manually defined brain topology; if there are false connections or noise, it will greatly affect the decoding performance. To address the aforementioned challenges, a series of GNN-based graph topology learning (GTL) methods have received widespread attention due to their ability to automatically optimize brain topology. However, existing GTL methods are usually implemented in a supervised manner and rely on a large amount of annotated data, making it difficult to directly transfer them to different decoding scenarios. Therefore, in this paper, a Brain Topology Inference framework based on Multi-View Contrastive Self-supervised Learning (BTI-MVCSL) is proposed for neural decoding. Specifically, BTI-MVCSL first designs a series of graph learners, which can infer brain topological connections as “learner”, generate topology learning objectives as “instructor” from the original fMRI data, and maximize consistency between “instructor” and “learner” to extract the rich information in hidden connections. Furthermore, in order to achieve fully automated topology learning guidance, BTI-MVCSL develops a new self-learning mechanism that can use the “learner”-view brain topology to update the “instructor”-view brain topology during model optimization and further achieves comparative constraints through the “instructor” topology. The proposed BTI-MVCSL has been extensively evaluated in two publicly available fMRI datasets, demonstrating superior performance and revealing potential changes in brain topology under different decoding tasks.},
  archive      = {J_PR},
  author       = {Ziyu Li and Zhiyuan Zhu and Qing Li and Xia Wu},
  doi          = {10.1016/j.patcog.2025.112445},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112445},
  shortjournal = {Pattern Recognition},
  title        = {Decoding the brain via multi-view brain topology contrastive learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic clustering transformer for LiDAR-based 3D object detection. <em>PR</em>, <em>172</em>, 112444. (<a href='https://doi.org/10.1016/j.patcog.2025.112444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR perception is a critical task in 3D computer vision. Currently, inspired by the success of vision transformers in 2D images, many LiDAR-based detectors also partition the whole scene point cloud into non-overlapping windows, and perform window attention and window shifting to capture local and global information respectively. While these methods improved performance of LiDAR detection task, they often fail to account for the intrinsic separability of 3D LiDAR point clouds. Unlike 2D images, where objects can overlap and blend into one another, objects in LiDAR are distinct and non-overlapping. In this paper, building upon this insight, we propose the Dynamic Cluster Transformer (DCT), a clustering-based point cloud backbone that incorporates transformer architecture. Our approach is designed to exploit the unique characteristics of LiDAR point clouds, enabling a more efficient 3D feature extraction. Specifically, the DCT architecture comprises two primary modules: Sparse Cluster Generation (SCG) and Cluster Feature Interaction (CFI). The Sparse Cluster Generation is responsible for producing initial sparse cluster features from the entire scene point cloud, providing a basis for local and global feature propagation. The Cluster Feature Interaction then facilitates information propagation between these clusters and surrounding voxels, allowing for a more comprehensive understanding of the spatial relationships. This proposed clustering-based learning process is simple yet effective, conforming to the physical characteristics of LiDAR point clouds. Empirical results demonstrate that DCT achieves state-of-the-art performance on the large-scale Waymo Open Dataset and nuScenes dataset.},
  archive      = {J_PR},
  author       = {Yubo Cui and Zhiheng Li and Zheng Fang},
  doi          = {10.1016/j.patcog.2025.112444},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112444},
  shortjournal = {Pattern Recognition},
  title        = {Dynamic clustering transformer for LiDAR-based 3D object detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Condense loss: Exploiting vector magnitude during person re-identification training process. <em>PR</em>, <em>172</em>, 112443. (<a href='https://doi.org/10.1016/j.patcog.2025.112443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The magnitudes of features and weights significantly affect the gradients during the training process. L2 normalized softmax losses (such as NormFace, CosFace, ArcFace, etc.) and Naive softmax losses both reduce the magnitudes of image features in the training process and achieve good results in face recognition and person re-identification tasks, respectively. In this paper, we fully utilize the feature vector magnitudes and propose Condense loss for Re-ID tasks, which replaces the inner production of Naive softmax loss with the negative Euclidean distance. Condense loss generates negative radial gradients when updating weight parameters to push all features compacter. Because the coefficients of tangential gradients (the tangential component of the gradients) are related to feature magnitudes, it ideally provides monotonically decreasing tangential gradients, resulting in gradually diminishing updates that enhance the stability of the training process. We also introduce a margin parameter into Condense loss to enlarge inter-class distances and thus help the model learn more discriminative features. Mathematical analysis is given in this paper, and we have conducted sufficient experiments focusing on Re-ID tasks to prove the corresponding conclusion. The experimental results demonstrate that the Condense loss achieves competitive results compared to the state-of-the-art methods in the person re-identification task. At the same time, it also has a good performance in face recognition tasks.},
  archive      = {J_PR},
  author       = {Xi Yang and Wenjiao Dong and Yingzhi Tang and Gu Zheng and Nannan Wang and Xinbo Gao},
  doi          = {10.1016/j.patcog.2025.112443},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112443},
  shortjournal = {Pattern Recognition},
  title        = {Condense loss: Exploiting vector magnitude during person re-identification training process},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Entropy-informed weighting channel normalizing flow for deep generative models. <em>PR</em>, <em>172</em>, 112442. (<a href='https://doi.org/10.1016/j.patcog.2025.112442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normalizing Flows (NFs) are widely used in deep generative models for their exact likelihood estimation and efficient sampling. However, they require substantial memory since the latent space matches the input dimension. Multi-scale architectures address this by progressively reducing latent dimensions while preserving reversibility. Existing multi-scale architectures use simple, static channel-wise splitting, limiting expressiveness. To improve this, we introduce a regularized, feature-dependent Shuffle operation and integrate it into vanilla multi-scale architecture. This operation adaptively generates channel-wise weights and shuffles latent variables before splitting them. We observe that such operation guides the variables to evolve in the direction of entropy increase, hence we refer to NFs with the Shuffle operation as Entropy-Informed Weighting Channel Normalizing Flow (EIW-Flow). Extensive experiments on CIFAR-10, CelebA, ImageNet, and LSUN demonstrate that EIW-Flow achieves state-of-the-art density estimation and competitive sample quality for deep generative modeling, with minimal computational overhead.},
  archive      = {J_PR},
  author       = {Wei Chen and Shian Du and Shigui Li and Delu Zeng and John Paisley},
  doi          = {10.1016/j.patcog.2025.112442},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112442},
  shortjournal = {Pattern Recognition},
  title        = {Entropy-informed weighting channel normalizing flow for deep generative models},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Buffer-free class-incremental learning with out-of-distribution detection. <em>PR</em>, <em>172</em>, 112441. (<a href='https://doi.org/10.1016/j.patcog.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-incremental learning (CIL) poses significant challenges in open-world scenarios, where models must learn new classes over time without forgetting previous ones and handle inputs from unknown classes that a closed-set model would misclassify. In this paper, we present an in-depth analysis of post-hoc OOD detection methods and investigate their potential to eliminate the need for a memory buffer. When post hoc OOD detection is applied at inference time, we discover that it can effectively replace buffer-based strategies. We examine the performance of these methods in terms of classification accuracy of seen samples and rejection rates of unseen samples. We show that our approach achieves competitive performance compared to recent multi-head and single-head methods that rely on memory buffers and other buffer-free approaches. The results show that the proposed approach outperforms them in a closed-world setting and detects unseen samples while being significantly resource-efficient. Experimental results on CIFAR-10, CIFAR-100, and Tiny ImageNet support our findings and offer new insights into the design of efficient and privacy-preserving CIL systems for open-world settings.},
  archive      = {J_PR},
  author       = {Srishti Gupta and Daniele Angioni and Maura Pintor and Ambra Demontis and Lea Schönherr and Fabio Roli and Battista Biggio},
  doi          = {10.1016/j.patcog.2025.112441},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112441},
  shortjournal = {Pattern Recognition},
  title        = {Buffer-free class-incremental learning with out-of-distribution detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction” [Pattern recognition 172 (2026) 112339]. <em>PR</em>, <em>172</em>, 112440. (<a href='https://doi.org/10.1016/j.patcog.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PR},
  author       = {Chengcheng Li and Luqi Gong and Leiheng Xu and Xin Wang},
  doi          = {10.1016/j.patcog.2025.112440},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112440},
  shortjournal = {Pattern Recognition},
  title        = {Corrigendum to “DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction” [Pattern recognition 172 (2026) 112339]},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A progressive attention network with transformer for multi-label image recognition. <em>PR</em>, <em>172</em>, 112439. (<a href='https://doi.org/10.1016/j.patcog.2025.112439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research typically improves the performance of multi-label image recognition by constructing higher-order pairwise label correlations. However, these methods lack the ability to effectively learn multi-scale features, which makes it difficult to distinguish small-scale objects. Moreover, most current attention-based methods to capture local salient features may ignore many useful non-salient features. To address the aforementioned issues, we propose a Transformer-based Progressive Attention Network (TPANet) for multi-label image recognition. Specifically, we first design a new adaptive multi-scale feature attention (AMSA) module to learn cross-scale features in multi-level features. Then, to excavate various useful object features, we introduce the transformer encoder to construct a semantic spatial attention (ESA) module and also propose a context-aware feature enhanced (CAFE) module. The former ESA module is used to discover complete object regions and capture discriminative features, and the latter CAFE module leverages object-local features to enhance pixel-level global features. The proposed TPANet model can generate more accurate object labels in three popular benchmark datasets (i.e., MS-COCO 2014, Pascal VOC 2007 and Visual Genome), and is competitive to state-of-the-art models (e.g., SST and FL-Tran, etc.).},
  archive      = {J_PR},
  author       = {Sulan Zhang and Zhenwen Liao and Jianeng Li and Lihua Hu and Jifu Zhang},
  doi          = {10.1016/j.patcog.2025.112439},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112439},
  shortjournal = {Pattern Recognition},
  title        = {A progressive attention network with transformer for multi-label image recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Layer-wise correlation and attention discrepancy distillation for semantic segmentation. <em>PR</em>, <em>172</em>, 112438. (<a href='https://doi.org/10.1016/j.patcog.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) has recently garnered increased attention in segmentation tasks due to its effective balance between accuracy and computational efficiency. Nonetheless, existing methods mainly rely on structured knowledge from a single layer, overlooking the valuable discrepant knowledge that captures the diversity and distinctiveness of features across various layers, which is essential for the KD process. We present Layer-wise Correlation and Attention Discrepancy Distillation (LCADD) to tackle this issue, training compact and accurate semantic segmentation networks by considering layer-wise discrepancy knowledge. Specifically, we employ two distillation schemes: (i) correlation discrepancy distillation, which constructs a pixel-wise correlation discrepancy matrix across various layers to seize more detailed spatial dependencies, and (ii) attention discrepancy self-distillation, which aims to guide the shallower layers of the student network to emulate the attention discrepancy maps of the deeper layers, facilitating self-learning of attention discrepancy knowledge within the student network. Each proposed method is designed to work collaboratively in learning discrepancy knowledge, allowing the student network to better imitate the teacher from the perspective of layer-wise discrepancy. Our method has demonstrated superior performance on various semantic segmentation datasets, including Cityscapes, Pascal VOC 2012, and CamVid, compared to the latest knowledge distillation techniques, thereby validating its effectiveness.},
  archive      = {J_PR},
  author       = {Jianping Gou and Kaijie Chen and Cheng Chen and Weihua Ou and Xin Luo and Zhang Yi},
  doi          = {10.1016/j.patcog.2025.112438},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112438},
  shortjournal = {Pattern Recognition},
  title        = {Layer-wise correlation and attention discrepancy distillation for semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gradient semi-masking for improving adversarial robustness. <em>PR</em>, <em>172</em>, 112433. (<a href='https://doi.org/10.1016/j.patcog.2025.112433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In gradient masking, certain complex signal processing and probabilistic optimization strategies exhibit favorable characteristics such as nonlinearity, irreversibility, and feature preservation, thereby providing new solutions for adversarial defense. Inspired by this, this paper proposes a plug-and-play gradient semi-masking module ( GSeM ) to improve the adversarial robustness of neural networks. GSeM primarily contains a feature straight-through pathway that allows for normal gradient propagation and a feature mapping pathway that interrupts gradient flow. The multi-pathway and semi-masking characteristics cause GSeM to exhibit opposing behaviors when processing data and gradients. Specifically, during data processing, GSeM compresses the state space of features while introducing white noise augmentation. However, during gradient processing, it leads to inefficient updates to certain parameters and ineffective generation of training examples. To address this shortcoming, we correct gradient propagation and introduce gradient-corrected adversarial training. Extensive experiments demonstrate that GSeM differs fundamentally from earlier gradient masking methods: it can genuinely enhance the adversarial defense performance of neural networks, surpassing previous state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Xinlei Liu and Tao Hu and Peng Yi and Baolin Li and Jichao Xie and Hailong Ma},
  doi          = {10.1016/j.patcog.2025.112433},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112433},
  shortjournal = {Pattern Recognition},
  title        = {Gradient semi-masking for improving adversarial robustness},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Structural-prior guided bi-generative network for image inpainting. <em>PR</em>, <em>172</em>, 112432. (<a href='https://doi.org/10.1016/j.patcog.2025.112432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting is a great challenge when reconstructed with realistic textures and required to enhance the consistency of semantic structures in large-scale missing regions. However, popular structural prior guidance methods primarily rely on the reconstruction of structural features. Due to the Markovian property inherent in purely feedforward architectures, noise undergoes persistent accumulation and propagation in early network layers. Without intermediate feedback mechanisms, minor artifacts in shallow layers would be nonlinearly amplified through successive convolution operations and cannot be timely corrected, thereby hindering the extraction of valid structural information. To this end, we presents a bi-generative network (Bi-GNet) guided by specific semantic structures, including an auxiliary network N s and an inpainting network N inp . Here N s provides the structural prior information to N inp for reconstructing the texture details of images. Additionally, we provide the spatial coordinate attention (SCA) and the adaptive feature filtering (AFF) module to ensure structural consistency and texture plausibility in the reconstructed content. Experiments demonstrate that Bi-GNet significantly outperforms other state-of-the-art approaches on three datasets and achieves good inpainting results on the Mogao Grottoes mural dataset.},
  archive      = {J_PR},
  author       = {Jiajun Zhang and Jizhao Liu and Huaikun Zhang and Jibao Zhang and Jing Lian},
  doi          = {10.1016/j.patcog.2025.112432},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112432},
  shortjournal = {Pattern Recognition},
  title        = {Structural-prior guided bi-generative network for image inpainting},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning from majority label: A novel problem in multi-class multiple-instance learning. <em>PR</em>, <em>172</em>, 112425. (<a href='https://doi.org/10.1016/j.patcog.2025.112425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a novel multi-class Multiple-Instance Learning (MIL) problem called Learning from Majority Label (LML). In LML, the majority class of instances in a bag is assigned as the bag-level label. The goal of LML is to train a classification model that estimates the class of each instance using the majority label. This problem is valuable in a variety of applications, including pathology image segmentation, political voting prediction, customer sentiment analysis, and environmental monitoring. To solve LML, we propose a Counting Network trained to produce bag-level majority labels, estimated by counting the number of instances in each class. Furthermore, analysis experiments on the characteristics of LML revealed that bags with a high proportion of the majority class facilitate learning. Based on this result, we developed a Majority Proportion Enhancement Module (MPEM) that increases the proportion of the majority class by removing minority class instances within the bags. Experiments demonstrate the superiority of the proposed method on four datasets compared to conventional MIL methods. Moreover, ablation studies confirmed the effectiveness of each module. The code is available at here .},
  archive      = {J_PR},
  author       = {Kaito Shiku and Shinnosuke Matsuo and Daiki Suehiro and Ryoma Bise},
  doi          = {10.1016/j.patcog.2025.112425},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112425},
  shortjournal = {Pattern Recognition},
  title        = {Learning from majority label: A novel problem in multi-class multiple-instance learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Feature subset weighting for distance-based supervised learning. <em>PR</em>, <em>172</em>, 112424. (<a href='https://doi.org/10.1016/j.patcog.2025.112424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces feature subset weighting using monotone measures for distance-based supervised learning. The Choquet integral is used to define a distance function that incorporates these weights. This integration enables the proposed distances to effectively capture non-linear relationships and account for interactions both between conditional and decision attributes and among conditional attributes themselves, resulting in a more flexible distance measure. In particular, we show how this approach ensures that the distances remain unaffected by the addition of duplicate and strongly correlated features. Another key point of this approach is that it makes feature subset weighting computationally feasible, since only m feature subset weights should be calculated each time instead of calculating all feature subset weights ( 2 m ), where m is the number of attributes. Next, we also examine how the use of the Choquet integral for measuring similarity leads to a non-equivalent definition of distance. The relationship between distance and similarity is further explored through dual measures. Additionally, symmetric Choquet distances and similarities are proposed, preserving the classical symmetry between similarity and distance. Finally, we introduce a concrete feature subset weighting distance, evaluate its performance in a k -nearest neighbours (KNN) classification setting, and compare it against Mahalanobis distances and weighted distance methods.},
  archive      = {J_PR},
  author       = {Adnan Theerens and Yvan Saeys and Chris Cornelis},
  doi          = {10.1016/j.patcog.2025.112424},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112424},
  shortjournal = {Pattern Recognition},
  title        = {Feature subset weighting for distance-based supervised learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A simple yet lightweight module for enhancing domain generalization through relative representation. <em>PR</em>, <em>172</em>, 112423. (<a href='https://doi.org/10.1016/j.patcog.2025.112423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain Generalization (DG) learns a model from multiple source domains to combat individual domain differences and ensure generalization to unseen domains. Most existing methods focus on learning domain-invariant absolute representations. However, we empirically observe that such representations often suffer from notable distribution divergence, leading to unstable performance in diverse unseen domains. In contrast, relative representations, constructed w.r.t. a set of anchors, naturally capture geometric relationships and exhibit intrinsic stability within a dataset. Despite this potential, their application to DG remains largely unexplored, due to their common transductive assumption that anchors require access to target-domain data, which is incompatible with the inductive setting of DG. To address this issue, we design Re2SL, a simple and lightweight plug-in module that follows a pre-trained encoder and constructs anchors solely from source-domain prototypes, thereby ensuring a completely inductive design. To our knowledge, Re2SL is the first to explore relative representation for DG. This design is inspired by the insight that ReS idual differences between absolute and domain-specific representations can spontaneously seek stable representations within the same distribution shared across all domains . Leveraging these stable representations, we construct cross-domain ReL ative representation to enhance stability and transferability without accessing any target data during training or anchor computation. Empirical studies show that our constructed representation exhibits minimal H -divergence, confirming its stability. Notably, Re2SL achieves up to 4.3 % improvement while reducing computational cost by 90 %, demonstrating its efficiency.},
  archive      = {J_PR},
  author       = {Meng Cao and Songcan Chen},
  doi          = {10.1016/j.patcog.2025.112423},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112423},
  shortjournal = {Pattern Recognition},
  title        = {A simple yet lightweight module for enhancing domain generalization through relative representation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 4DStyleGaussian: Generalizable 4D style transfer with gaussian splatting. <em>PR</em>, <em>172</em>, 112422. (<a href='https://doi.org/10.1016/j.patcog.2025.112422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D neural style transfer has gained significant attention for its potential to provide user-friendly stylization with 3D spatial consistency. However, existing 3D style transfer methods often struggle with inference efficiency, generalization, and maintaining temporal consistency when handling dynamic scenes. In this paper, we introduce 4DStyleGaussian, a novel 4D style transfer framework designed to achieve real-time stylization of arbitrary style references while maintaining reasonable content affinity, multi-view consistency, and temporal coherence. Our approach leverages an embedded 4D Gaussian Splatting technique, which is trained utilizing a reversible neural network for reducing content loss and artifacts in the feature distillation process. With the pre-trained 4D embedded Gaussians for efficient and view-consistent rendering, we predict a 4D style transformation matrix that facilitates spatially and temporally consistent style transfer. Experiments demonstrate that our method can achieve high-quality and generalizable stylization for 4D scenarios with enhanced efficiency and spatial-temporal consistency, with 7.1 % lower LPIPS and 2.5× faster inference compared to existing methods.},
  archive      = {J_PR},
  author       = {Wanlin Liang and Hongbin Xu and Weitao Chen and Feng Xiao and Wenxiong Kang},
  doi          = {10.1016/j.patcog.2025.112422},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112422},
  shortjournal = {Pattern Recognition},
  title        = {4DStyleGaussian: Generalizable 4D style transfer with gaussian splatting},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Retinex-guided generative diffusion prior for low-light image enhancement. <em>PR</em>, <em>172</em>, 112421. (<a href='https://doi.org/10.1016/j.patcog.2025.112421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Retinex-based training-free low-light image enhancement (LLIE) methods often rely on complex architectures or lack support for text-controlled personalization. In this paper, we propose RetinexGDP, a training-free and text-controllable LLIE framework that uniquely integrates Retinex-based image modeling with generative diffusion priors. First, we introduce a simplified Retinex decomposition by embedding weighted total variation optimization into a single Gaussian convolutional layer, enabling robust illumination estimation without the need for training. Next, we guide the diffusion denoising process using the estimated reflectance map, employing patch-wise inversion and reflectance-conditioned sampling to effectively suppress noise while preserving structural details. Finally, unlike previous diffusion-based LLIE methods that perform only monotonous global brightness enhancement, we incorporate text guidance into the sampling process, enabling controllable enhancement that aligns with user-specific stylistic preferences. RetinexGDP thus provides a modular, interpretable, and text-controllable solution for low-light image enhancement. Experimental results show that RetinexGDP achieves state-of-the-art performance in terms of NIQMC and CPCQI metrics across seven real-world datasets. Code will be available at: https://github.com/zhaozunjin/PLIE},
  archive      = {J_PR},
  author       = {Zunjin Zhao and Daming Shi},
  doi          = {10.1016/j.patcog.2025.112421},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112421},
  shortjournal = {Pattern Recognition},
  title        = {Retinex-guided generative diffusion prior for low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive integration of textual context and visual embeddings for underrepresented vision classification. <em>PR</em>, <em>172</em>, 112420. (<a href='https://doi.org/10.1016/j.patcog.2025.112420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of deep learning has significantly improved image classification performance; however, handling long-tail distributions remains challenging due to the limited data available for rare classes. Existing approaches predominantly focus on visual features, often neglecting the valuable contextual information provided by textual data, which can be especially beneficial for classes with sparse visual examples. In this work, we introduce a novel method addressing this limitation by integrating textual data generated by advanced language models with visual inputs through our newly proposed Adaptive Integration Block for Vision-Text Synergy (AIB-VTS). Specifically designed for Vision Transformer architectures, AIB-VTS adaptively balances visual and textual information during inference, effectively utilizing textual descriptions generated from large language models. Extensive experiments on benchmark datasets demonstrate substantial performance improvements across all class groups, particularly in underrepresented (tail) classes. These results confirm the effectiveness of our approach in leveraging textual context to mitigate data scarcity issues and enhance model robustness.},
  archive      = {J_PR},
  author       = {Seongyeop Kim and Hyung-Il Kim and Yong Man Ro},
  doi          = {10.1016/j.patcog.2025.112420},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112420},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive integration of textual context and visual embeddings for underrepresented vision classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PCFFusion: Progressive cross-modal feature fusion network for infrared and visible images. <em>PR</em>, <em>172</em>, 112419. (<a href='https://doi.org/10.1016/j.patcog.2025.112419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) aims to fuse thermal target information in infrared images and spatial texture information in visible images, improving the observability and comprehensibility of the fused images. Currently, most IVIF methods suffer from the loss of salient target information and texture details in fused images. To alleviate this problem, a progressive cross-modal feature fusion network (PCFFusion) for IVIF is proposed, which comprises two stages: feature extraction and feature fusion. In the feature extraction stage, to enhance the network’s feature representation capability, a feature decomposition module (FDM) is constructed to extract two modal features of different scales by defining a feature decomposition operation (FDO). In addition, by establishing correlations between the high- frequency and low-frequency components of two modal features, a cross-modal feature enhancement module (CMFEM) is built to realize correction and enhancement of the two features at each scale. The feature fusion stage achieves the fusion of two modal features at each scale and the supplementation of adjacent scale features by constructing three cross-domain fusion module (CDFMs). To constrain the fused results preserve more salient targets and richer texture details, a dual-feature fidelity loss function is defined by constructing a salient weight map to balance the two loss terms. Extensive experiments demonstrate that fusion results of the proposed method highlight prominent targets from infrared images while retaining rich background details from visible images, and the performance of PCFFusion is superior to some advanced methods. Specifically, compared to the optimal results obtained by other comparison methods, the proposed network achieves an average increase of 30.35 % and 10.9 % in metrics Mutual Information (MI) and Standard deviation (SD) on the TNO dataset, respectively.},
  archive      = {J_PR},
  author       = {Shuying Huang and Kai Zhang and Yong Yang and Weiguo Wan},
  doi          = {10.1016/j.patcog.2025.112419},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112419},
  shortjournal = {Pattern Recognition},
  title        = {PCFFusion: Progressive cross-modal feature fusion network for infrared and visible images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MonoA2: Adaptive depth with augmented head for monocular 3D object detection. <em>PR</em>, <em>172</em>, 112418. (<a href='https://doi.org/10.1016/j.patcog.2025.112418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3D object detection is a hot direction due to its low cost and configuration simplicity. Achieving accurate instance depth prediction from monocular images is a challenging problem in monocular 3D object detection. Many existing methods perform instance depth prediction based on fixed rules, which are not flexible for various objects. Furthermore, these methods ignore the design of more discriminative task heads. To address these issues, we propose the MonoA 2 , which consists of the Adaptive Depth Module (ADM) and the Augmented Head Module (AHM). The ADM is used to achieve more accurate depth prediction by learning adaptive offsets to decouple the depth prediction from object center constraints. The AHM is proposed to obtain more discriminative task heads through task-aware attention and task-interaction attention. The task-aware attention can generate different weights adapted to different tasks and the task-interaction attention can guide depth tasks to interact with other tasks. Experimental results on the KITTI and Waymo datasets demonstrate the effectiveness of the proposed method. Our method achieves superior performance on the KITTI and Waymo benchmarks.},
  archive      = {J_PR},
  author       = {Jinpeng Dong and Sanping Zhou and Yufeng Hu and Yuhao Huang and Jingjing Jiang and Weiliang Zuo and Shitao Chen and Nanning Zheng},
  doi          = {10.1016/j.patcog.2025.112418},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112418},
  shortjournal = {Pattern Recognition},
  title        = {MonoA2: Adaptive depth with augmented head for monocular 3D object detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time series adaptive mode decomposition (TAMD): Method for improving forecasting accuracy in the apparel industry. <em>PR</em>, <em>172</em>, 112417. (<a href='https://doi.org/10.1016/j.patcog.2025.112417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of apparel sales is critical for inventory management, supply chain optimization, and market strategy planning. However, existing forecasting models often struggle to effectively capture the complex characteristics of apparel sales data, such as distinct seasonality, cyclicality, and strongly nonlinear fluctuations, which significantly hinder prediction accuracy and generalization ability. To address these challenges, this study introduces a novel Time series Adaptive Mode Decomposition (TAMD)-based forecasting algorithm. The proposed method: (1) employs Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and sample entropy-guided Variational Mode Decomposition (VMD) to separate the input time series into noise components and multiple smooth Intrinsic Mode Functions (IMFs), to better capture intrinsic data dynamics; (2) refines the sub-series distribution features via an adaptive module guided by sample entropy, dividing each sub-series into subsequences with maximal distribution difference to improve adaptability to periodic changes and market volatility; (3) predicts each subsequence with adaptive distribution matching based on discontinuous random subsequence combinations, and then linearly superposes the prediction results as a final output, thereby boosting accuracy and generalizability. Comprehensive experiments on both public and self-constructed datasets (including four years of Taobao sales data for dresses, jeans, sweatshirts, and sweaters, totaling over 44.7 million records) demonstrate that TAMD outperforms existing methods significantly, highlighting its effectiveness in revealing the complexity of apparel market data and enhancing prediction performance.},
  archive      = {J_PR},
  author       = {Guangbao Zhou and Pengliang Liu and Quanle Lin and Miao Qian and Zhong Xiang and Zeyu Zheng and Lixian Liu},
  doi          = {10.1016/j.patcog.2025.112417},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112417},
  shortjournal = {Pattern Recognition},
  title        = {Time series adaptive mode decomposition (TAMD): Method for improving forecasting accuracy in the apparel industry},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A framework for bias-aware dataset evaluation in soft facial attribute recognition. <em>PR</em>, <em>172</em>, 112416. (<a href='https://doi.org/10.1016/j.patcog.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft Facial Attribute Recognition (FAR) remains largely unexplored in terms of demographic fairness. To the best of our knowledge, this study presents one of the first comprehensive analyses of demographic bias in FAR, proposing a systematic framework to detect, quantify, and promote awareness of both representational and stereotypical biases, supporting their mitigation. Leveraging established taxonomies, we evaluate state-of-the-art datasets using a rigorous set of interpretable bias metrics to uncover hidden demographic imbalances. To support reliable fairness assessment, we first enrich the datasets with standardized demographic annotations using the FairFace model. We then address label inconsistencies through the integration of predictions from advanced Vision-Language Models (VLMs). Our analysis reveals substantial imbalances across gender, age, and racial categories-specifically White, Black, and Asian- affecting dataset composition. Furthermore, we show that conventional fairness metrics often yield divergent assessments, highlighting the importance of multi-metric evaluation. This study provides a replicable methodology and actionable insights to support bias-aware facial analysis.},
  archive      = {J_PR},
  author       = {Lucia Cascone and Michele Nappi and Chiara Pero and Xinggang Wang},
  doi          = {10.1016/j.patcog.2025.112416},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112416},
  shortjournal = {Pattern Recognition},
  title        = {A framework for bias-aware dataset evaluation in soft facial attribute recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fast multi-view discrete clustering with two solvers. <em>PR</em>, <em>172</em>, 112415. (<a href='https://doi.org/10.1016/j.patcog.2025.112415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view graph clustering follows a three-phase process: constructing view-specific similarity graphs, fusing information from different views, and conducting eigenvalue decomposition followed by post-processing to obtain the clustering indicators. However, it encounters two key challenges: the high computational cost of graph construction and eigenvalue decomposition, and the inevitable information deviation introduced by the last process. To tackle these obstacles, we propose Fast Multi-view Discrete Clustering with two solvers (FMDC), to directly and efficiently solve the multi-view graph clustering problem. FMDC involves: (1) generating a compact set of representative anchors to construct anchor graphs, (2) automatically weighting them into a symmetric and doubly stochastic aggregated similarity matrix, (3) executing clustering on the aggregated form with the discrete indicator matrix directly computed through two efficient solvers that we devised. The linear computational complexity of FMDC w.r.t. data size is a notable improvement over traditional quadratic or cubic complexity. Extensive experiments confirm the superior performance of FMDC both in efficiency and in effectiveness.},
  archive      = {J_PR},
  author       = {Qianyao Qiang and Bin Zhang and Jason Chen Zhang and Feiping Nie},
  doi          = {10.1016/j.patcog.2025.112415},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112415},
  shortjournal = {Pattern Recognition},
  title        = {Fast multi-view discrete clustering with two solvers},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clinical knowledge enhanced medical image classification. <em>PR</em>, <em>172</em>, 112414. (<a href='https://doi.org/10.1016/j.patcog.2025.112414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the scarcity of data in medical field, deep learning-based medical image classification faces challenges in both accuracy and reliability. Foundation models (FMs) provide a promising enhancement strategy by extracting the text medical knowledge embeddings from FMs and use it to guide the specific classification model. However, the clinical knowledge is generally structurized, and the use of pure text as knowledge representation may not be significant enough for enhancing downstream model. Moreover, the lesion areas are generally subtle, combining FMs to downstream model in a coarse-grained manner still faces challenge in precisely attending the lesions. To tackle these challenges, we propose a novel medical image classification model that effectively embeds clinical knowledge through combining graphs and FMs. First, we represent the clinical rules as graphs, where the node describes the critical characteristics of disease. During training, we use FMs to extract the embeddings of node text description, and use graph transformer to extract global representation of graphs. By employing vision transformer to encode input images, we propose a global-local alignment module to transfer clinical knowledge where the embeddings of image branch and graph branch are aligned from image-to-graph level and patch-to-vertex level, respectively. Moreover, we propose a dynamic image patch selection method to reduce the attention of the model to irrelevant and noisy regions. Experimental results on bladder tumor classification dataset verifies that even with limited training data, the proposed method can not only achieve SOTA performance, but also accurately attend the lesion areas, thus improving the trustworthiness.},
  archive      = {J_PR},
  author       = {Zhikang Xu and Jiye Liang and Zhipeng Wei and Xiaodong Yue and Deyu Li},
  doi          = {10.1016/j.patcog.2025.112414},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112414},
  shortjournal = {Pattern Recognition},
  title        = {Clinical knowledge enhanced medical image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asymmetric simulation-enhanced flow reconstruction for incomplete multimodal learning. <em>PR</em>, <em>172</em>, 112413. (<a href='https://doi.org/10.1016/j.patcog.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multimodal learning addresses the common real-world challenge of missing modalities, which undermines the performance of standard multimodal methods. Existing solutions struggle with distribution mismatches between reconstructed and observed data, asymmetric cross-modal structures, and insufficient cross-modal knowledge sharing. To tackle these issues, we propose an asymmetric simulation-enhanced flow reconstruction (ASE-FR) framework, which contains following contributions: (1) Distribution-consistent flow reconstruction module that align available and missing modality distributions by normalizing flows; (2) Asymmetric simulation module that perturbs and randomly masks features to mimic real-world modality absence and improve robustness; (3) Modal-shared knowledge distillation that transfers shared representations from teacher encoders to a student encoder through contrastive learning. This framework is applicable to a range of real-world scenarios, such as multi-sensor networks in smart manufacturing, medical diagnostic systems combining imaging and electronic health records, and autonomous driving platforms that integrate camera and LiDAR data. The experimental results show that our ASE-FR method achieves 94.71 %, 41.85 % and 81.90 % accuracy on Audiovision-MNIST, MM-IMDb and IEMOCAP datasets, as well as 1.1376 error rate on CMU-MOSI dataset, which exhibits competitive performance.},
  archive      = {J_PR},
  author       = {Jiacheng Yao and Jing Zhang and Yixiao Wang and Li Zhuo},
  doi          = {10.1016/j.patcog.2025.112413},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112413},
  shortjournal = {Pattern Recognition},
  title        = {Asymmetric simulation-enhanced flow reconstruction for incomplete multimodal learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Benchmarking the spatial robustness of DNNs via natural and adversarial localized corruptions. <em>PR</em>, <em>172</em>, 112412. (<a href='https://doi.org/10.1016/j.patcog.2025.112412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robustness of deep neural networks is a crucial factor in safety-critical applications, particularly in complex and dynamic environments (e.g., medical or driving scenarios) where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remained underexplored. This paper fills this gap by introducing novel, region-aware metrics for benchmarking the spatial robustness of segmentation models, along with an evaluation framework to assess the impact of natural localized corruptions. Furthermore, it uncovers the inherent complexity of evaluating worst-case spatial robustness using only a single localized adversarial attack. To address this, the work proposes a region-aware multi-attack adversarial analysis to systematically assess model robustness across specific image regions. The proposed metrics and analysis were exploited to evaluate 14 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones, and vice versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.},
  archive      = {J_PR},
  author       = {Giulia Marchiori Pietrosanti and Giulio Rossolini and Alessandro Biondi and Giorgio Buttazzo},
  doi          = {10.1016/j.patcog.2025.112412},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112412},
  shortjournal = {Pattern Recognition},
  title        = {Benchmarking the spatial robustness of DNNs via natural and adversarial localized corruptions},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preserving privacy without compromising accuracy: Machine unlearning for handwritten text recognition. <em>PR</em>, <em>172</em>, 112411. (<a href='https://doi.org/10.1016/j.patcog.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten Text Recognition (HTR) is crucial for document digitization, but handwritten data can contain user-identifiable features, like unique writing styles, posing privacy risks. Regulations such as the “right to be forgotten” require models to remove these sensitive traces without full retraining. We introduce a practical encoder-only transformer baseline as a robust reference for future HTR research. Building on this, we propose a two-stage unlearning framework for multihead transformer HTR models. Our method combines neural pruning with machine unlearning applied to a writer classification head, ensuring sensitive information is removed while preserving the recognition head. We also present Writer-ID Confusion (WIC), a method that forces the forget set to follow a uniform distribution over writer identities, unlearning user-specific cues while maintaining text recognition performance. We compare WIC to Random Labeling, Fisher Forgetting, Amnesiac Unlearning, and DELETE within our prune-unlearn pipeline and consistently achieve better privacy and accuracy trade-offs. This is the first systematic study of machine unlearning for HTR. Using metrics such as Accuracy, Character Error Rate (CER), Word Error Rate (WER), and Membership Inference Attacks (MIA) on the IAM and CVL datasets, we demonstrate that our method achieves state-of-the-art or superior performance for effective unlearning. These experiments show that our approach effectively safeguards privacy without compromising accuracy, opening new directions for document analysis research. Our code is publicly available at https://github.com/leitro/WIC-WriterIDConfusion-MachineUnlearning .},
  archive      = {J_PR},
  author       = {Lei Kang and Xuanshuo Fu and Lluis Gomez and Alicia Fornés and Ernest Valveny and Dimosthenis Karatzas},
  doi          = {10.1016/j.patcog.2025.112411},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112411},
  shortjournal = {Pattern Recognition},
  title        = {Preserving privacy without compromising accuracy: Machine unlearning for handwritten text recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated automatic latent variable selection in multi-output gaussian processes. <em>PR</em>, <em>172</em>, 112410. (<a href='https://doi.org/10.1016/j.patcog.2025.112410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a federated learning approach that automatically selects the number of latent processes in multi-output Gaussian processes (MGPs). The MGP has seen great success as a transfer learning tool when data is generated from multiple sources/units/entities. A common approach in MGPs to transfer knowledge across units involves gathering all data from each unit to a central server and extracting common independent latent processes to express each unit as a linear combination of the shared latent patterns. However, this approach poses key challenges in (i) determining the adequate number of latent processes and (ii) relying on centralized learning which leads to potential privacy risks and significant computational burdens on the central server. To address these issues, we propose a hierarchical model that places spike-and-slab priors on the coefficients of each latent process. These priors help automatically select only needed latent processes by shrinking the coefficients of unnecessary ones to zero. To estimate the model while avoiding the drawbacks of centralized learning, we propose a variational inference-based approach, that formulates model inference as an optimization problem compatible with federated settings. We then design a federated learning algorithm that allows units to jointly select and infer the common latent processes without sharing their data. We also discuss an efficient learning approach for a new unit within our proposed federated framework. Simulation and case studies on Li-ion battery degradation and air temperature data demonstrate the advantageous features of our proposed approach.},
  archive      = {J_PR},
  author       = {Jingyi Gao and Seokhyun Chung},
  doi          = {10.1016/j.patcog.2025.112410},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112410},
  shortjournal = {Pattern Recognition},
  title        = {Federated automatic latent variable selection in multi-output gaussian processes},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-view consistency clustering via structure-enhanced contrastive learning. <em>PR</em>, <em>172</em>, 112409. (<a href='https://doi.org/10.1016/j.patcog.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current state-of-the-art deep multi-view clustering methods resort to contrastive learning to learn consensus representations with Cross-View Consistency ( CVC ). However, contrastive learning has inherent limitations when being applied to the multi-view clustering. On one hand, contrastive learning suffers from class collision issue, compromising the discriminability of consensus representation. On the other hand, contrastive alignment of two views of different quality could lead to representation degradation for the higher-quality view, weakening the robustness of the consensus representation. To alleviate these issues, this paper presents an Adaptive Multi-view consistency clustering method via structure-enhanced contrastive learning ( A da M ), which learns multi-faceted consensus representation that balances view-consistency, discriminability and robustness, forming an optimal consensus representation. Specifically, we first design a view fusion module and a structural learning module to learn view weights and structural relationships among samples, respectively, to derive the consensus representation. Second, beyond CVC , we propose a novel clustering framework called Adaptive Multi-View Consistency ( AMVC ), which adaptively aligns specific view representation with consensus representation based on the learned view weights. Furthermore, compared to CVC , we theoretically demonstrate the superiority of AMVC in learning robust consensus representation. Third, A da M leverages the structural relationships among samples to refine the conventional contrastive loss, further enhancing the discriminability of the consensus representation. Extensive experimental results on eight datasets demonstrate the superior performance of A da M over eight advanced multi-view clustering baselines.},
  archive      = {J_PR},
  author       = {Xuqian Xue and Qi Cai and Zhanwei Zhang and Yiming Lei and Hongming Shan and Junping Zhang},
  doi          = {10.1016/j.patcog.2025.112409},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112409},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive multi-view consistency clustering via structure-enhanced contrastive learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A text-only weakly supervised learning framework for text spotting via text-to-polygon generator. <em>PR</em>, <em>172</em>, 112408. (<a href='https://doi.org/10.1016/j.patcog.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced text spotting methods typically rely on large-scale, meticulously labeled datasets to achieve satisfactory performance. However, annotating fine-grained positional information of texts in real-world scene images is extremely costly and time-consuming. Although some weakly supervised methods have been developed to reduce annotation costs, they face two major challenges: 1) their performance significantly lags behind the fully supervised counterparts, and 2) They are tightly coupled with specific text spotting models, meaning that switching to a different model would require retraining and incur substantial computational costs. To address these limitations, we propose a novel text-only weakly supervised learning framework for text spotting via text-to-polygon generator. In the first stage, we pretrain a text-to-polygon generator on an auxiliary dataset, e.g., synthetic or public datasets, where full annotations are readily accessible. In the second stage, given real-world target datasets annotated with text-only labels, we employ the pretrained generator to produce pseudo polygon labels, thereby constructing a pseudo-labeled supervised dataset for training text spotting models. To ensure high-quality pseudo polygon labels, the text-to-polygon generator first identifies all candidate text regions, then filters those that are relevant to the target text, and finally predicts their precise spatial locations. Notably, this generator requires only a single pretraining session and can subsequently be applied to any text spotting model and target text-only dataset without incurring additional costs. Extensive experiments on public benchmarks demonstrate that our method can significantly reduce labeling costs while maintaining competitive performance.},
  archive      = {J_PR},
  author       = {Gege Zhang and Zhiyong Gan and Ling Deng and Shuaicheng Niu and Zhenghua Peng and Gang Dai and Shuangping Huang and Xiangmin Xu},
  doi          = {10.1016/j.patcog.2025.112408},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112408},
  shortjournal = {Pattern Recognition},
  title        = {A text-only weakly supervised learning framework for text spotting via text-to-polygon generator},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Leveraging synthetic data for zero–shot and few–shot circle detection in real–world domains. <em>PR</em>, <em>172</em>, 112407. (<a href='https://doi.org/10.1016/j.patcog.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circle detection plays a pivotal role in computer vision, underpinning applications from industrial inspection and bioinformatics to autonomous driving. Traditional methods, however, often struggle with real–world complexities, as they demand extensive parameter tuning and adaptation across different domains. In this paper, we present the Synthetic Circle Dataset (SynCircle), a large synthetic image dataset designed to train a YOLO v10 network for circle detection. The YOLO v10 network, pre–trained solely on synthetic data, demonstrates remarkable off–the–shelf performance that surpasses conventional methods in various practical scenarios. Furthermore, we show that incorporating just a few labeled real images for fine–tuning can significantly boost performance, reducing the need for large annotated datasets. To promote reproducibility and streamline adoption, we publicly release both the trained YOLO v10 weights and the full SynCircle dataset.},
  archive      = {J_PR},
  author       = {Paolo Andreini and Marco Tanfoni and Simone Bonechi and Monica Bianchini},
  doi          = {10.1016/j.patcog.2025.112407},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112407},
  shortjournal = {Pattern Recognition},
  title        = {Leveraging synthetic data for zero–shot and few–shot circle detection in real–world domains},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Aegis: A domain generalization framework for medical image segmentation by mitigating feature misalignment. <em>PR</em>, <em>172</em>, 112406. (<a href='https://doi.org/10.1016/j.patcog.2025.112406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain shift caused by variations in data acquisition significantly impedes the deployment of medical image segmentation models in clinical settings. Domain generalization aims to mitigate performance degradation induced by domain shift by training a model using source domain data and generalize well to unseen target domain. In this work, we have an interesting observation: domain shift results in significantly different activation patterns across domains even they have semantically identical input. This cross-domain “feature misalignment” phenomenon motivates us to develop a hypothesis: mitigating cross-domain feature misalignment may enhance domain generalization. To this end, we propose a framework called Aegis , which employs style augmentation to generate augmented image features that simulate domain shift. Subsequently, we introduce a dual attention-guided feature calibration (DAFC) module to facilitate feature interaction between source and augmented images, thereby establishing an implicit alignment constraint within the shared feature space. Furthermore, we propose an uncertainty-guided feature alignment (UFA) loss, which quantifies segmentation discrepancies caused by domain shift and incorporates an uncertainty-weighting mechanism to enhance the alignment of hard-to-classify pixel regions. These components work in synergy to effectively mitigate cross-domain feature misalignment, promote robust feature alignment, and ultimately improve cross-domain generalization. Extensive experiments conducted on three widely used benchmarks demonstrate that the proposed framework significantly outperforms existing methods in domain generalization. Code is available at https://github.com/Zerua-bit/Aegis .},
  archive      = {J_PR},
  author       = {Yuheng Xu and Taiping Zhang and Yuqi Fang},
  doi          = {10.1016/j.patcog.2025.112406},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112406},
  shortjournal = {Pattern Recognition},
  title        = {Aegis: A domain generalization framework for medical image segmentation by mitigating feature misalignment},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preference isolation forest for structure-based anomaly detection. <em>PR</em>, <em>172</em>, 112405. (<a href='https://doi.org/10.1016/j.patcog.2025.112405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of detecting anomalies as samples that do not conform to structured patterns represented by low-dimensional manifolds. To this end, we conceive a general anomaly detection framework called Preference Isolation Forest ( PIF ), that combines the benefits of adaptive isolation-based methods with the flexibility of preference embedding. The key intuition is to embed the data into a high-dimensional preference space by fitting low-dimensional manifolds, and to identify anomalies as isolated points. We propose three isolation approaches to identify anomalies: i ) Voronoi- iForest , the most general solution, ii ) RuzHash - iForest , that avoids explicit computation of distances via Local Sensitive Hashing, and iii ) Sliding- PIF , that leverages a locality prior to improve efficiency and effectiveness.},
  archive      = {J_PR},
  author       = {Filippo Leveni and Luca Magri and Cesare Alippi and Giacomo Boracchi},
  doi          = {10.1016/j.patcog.2025.112405},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112405},
  shortjournal = {Pattern Recognition},
  title        = {Preference isolation forest for structure-based anomaly detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DURN: Data uncertainty-driven robust network for mural sketch detection. <em>PR</em>, <em>172</em>, 112404. (<a href='https://doi.org/10.1016/j.patcog.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mural sketches reveal both the content and structure of the murals and are crucial for the preservation of murals. However, existing methods lack robustness, making it difficult to suppress noise while preserving sketches on damaged murals and fully capturing details on clear murals. To address this, we propose a Data Uncertainty-Driven Robust Network (DURN) for mural sketch detection. DURN uses uncertainty to quantify noise in the murals, converting prediction into a learnable normal distribution, where the mean represents the sketch and the variance denotes the uncertainty. This enables the model to learn both the sketch and the noise simultaneously, achieving noise suppression while preserving the sketches. To enhance sketches, we design an Adaptive Fusion Feature Enhancement Module (AFFE) to dynamically adjust the fusion strategy according to the contribution of features at different scales and reduce the information loss caused by feature dimensionality reduction to maximize the utility of each feature. We develop a novel Deep-Shallow Supervision (DSS) module to mitigate background noise using deep semantic information to guide shallow features without adding parameters. Additionally, we achieve model lightweighting through pruning techniques, ensuring competitive performance while reducing the number of parameters to only 4.5 % of the original. The experimental results show an improvement of 10. 4 % AP over existing methods, demonstrating the robustness of DURN for complex and damaged murals. The source code is available at https://github.com/TIVEN-Z/DURN .},
  archive      = {J_PR},
  author       = {Shenglin Peng and Xingguo Zhao and Jun Wang and Lin Wang and Shuyi Qu and Jingye Peng and Xianlin Peng},
  doi          = {10.1016/j.patcog.2025.112404},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112404},
  shortjournal = {Pattern Recognition},
  title        = {DURN: Data uncertainty-driven robust network for mural sketch detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learn depth space from light field via a distance-constraint query mechanism. <em>PR</em>, <em>172</em>, 112403. (<a href='https://doi.org/10.1016/j.patcog.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Light Field (LF) captures both spatial and angular information of scenes, enabling precise depth estimation. Recent advancements in deep learning have led to significant success in this field; however, existing methods primarily focus on modeling surface characteristics (e.g., depth maps) while overlooking the depth space, which contains additional valuable information. The depth space consists of numerous space points and provides substantially more geometric data than a single depth map. In this paper, we conceptualize depth prediction as a spatial modeling problem, aiming to learn the entire depth space rather than merely a single depth map. Specifically, we define space points as signed distances relative to the scene surface and propose a novel distance-constraint query mechanism for LF depth estimation. To model the depth space effectively, we first develop a mixed sampling strategy to approximate its data representation. Subsequently, we introduce an encoder-decoder network architecture to query the distances of each point, thereby implicitly embedding the depth space. Finally, to extract the target depth map from this space, we present a generation algorithm that iteratively invokes the decoder network. Through extensive experiments, our approach achieves the highest performance on LF depth estimation benchmarks, and also demonstrates superior performance on various synthetic and real-world scenes.},
  archive      = {J_PR},
  author       = {Hao Sheng and Rongshan Chen and Ruixuan Cong and Da Yang and Zhenglong Cui and Sizhe Wang},
  doi          = {10.1016/j.patcog.2025.112403},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112403},
  shortjournal = {Pattern Recognition},
  title        = {Learn depth space from light field via a distance-constraint query mechanism},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised instance segmentation with superpixels. <em>PR</em>, <em>172</em>, 112402. (<a href='https://doi.org/10.1016/j.patcog.2025.112402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation is essential for numerous computer vision applications, including robotics, human-computer interaction, and autonomous driving. Currently, popular models bring impressive performance in instance segmentation by training with a large number of human annotations, which are costly to collect. For this reason, we present a new framework that efficiently and effectively segments objects without the need for human annotations. Firstly, a MultiCut algorithm is applied to self-supervised features for coarse mask segmentation. Then, a mask filter is employed to obtain high-quality coarse masks. To train the segmentation network, we compute a novel superpixel-guided mask loss, comprising hard loss and soft loss, with high-quality coarse masks and superpixels segmented from low-level image features. Lastly, a self-training process with a new adaptive loss is proposed to improve the quality of predicted masks. We conduct experiments on public datasets in instance segmentation and object detection to demonstrate the effectiveness of the proposed framework. The results show that the proposed framework outperforms previous state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Cuong Manh Hoang},
  doi          = {10.1016/j.patcog.2025.112402},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112402},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised instance segmentation with superpixels},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MIGF-net: Multimodal interaction-guided fusion network for image aesthetics assessment. <em>PR</em>, <em>172</em>, 112401. (<a href='https://doi.org/10.1016/j.patcog.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of social media, people like to post images and comments to share their ideas, which provides rich visual and textural semantic information for image aesthetics assessment (IAA). However, most previous works either extracted the unimodal aesthetic features from image due to the difficulty of obtaining comments, or combined multimodal information together but ignoring the interactive relationship between image and comment, which limits the overall performance. To solve the above problem, we propose a Multimodal Interaction-Guided Fusion Network (MIGF-Net) for image aesthetics assessment based on both image and comment semantic information, which can not only solve the challenge of comment generating, but also provide the multimodal feature interactive information. Specifically, considering the coupling mechanism of the image theme, we construct a visual semantic fusion module to extract the visual semantic feature based on the visual attributes and the theme features. Then, a textural semantic feature extractor is designed to mine the semantic information hidden in comments, which not only addresses the issue of missing comments but also effectively complements the visual semantic features. Furthermore, we establish a Dual-Stream Interaction-Guided Fusion module to fuse the semantic features of images and comments, fully exploring the interactive relationship between images and comments in the human brain’s perception mechanism. Experimental results on two public image aesthetics evaluation datasets demonstrate that our model outperforms the current state-of-the-art methods. Our code will be released at https://github.com/wenzhipeng123/MIGF-Net .},
  archive      = {J_PR},
  author       = {Yun Liu and Zhipeng Wen and Leida Li and Peiguang Jing and Daoxin Fan},
  doi          = {10.1016/j.patcog.2025.112401},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112401},
  shortjournal = {Pattern Recognition},
  title        = {MIGF-net: Multimodal interaction-guided fusion network for image aesthetics assessment},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IRIS: An information path planning method based on reinforcement learning and information-directed sampling. <em>PR</em>, <em>172</em>, 112400. (<a href='https://doi.org/10.1016/j.patcog.2025.112400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information Path Planning (IPP) is a critical aspect of robotics, aimed at intelligently selecting information-rich paths to optimize robot trajectories and significantly enhance the efficiency and quality of data collection. However, in the process of maximizing information acquisition, IPP must also account for energy consumption, time constraints, and physical obstacles, which often lead to inefficiencies. To address these challenges, we propose an Information Path Planning method based on Reinforcement Learning and Information-Directed Sampling (IRIS). This model is the first to integrate Reinforcement Learning (RL) with Information-Directed Sampling (IDS), ensuring both immediate rewards and the potential for greater information gain through exploratory actions. IRIS employs an off-policy deep reinforcement learning framework, effectively overcoming the limitations observed in on-policy methods, thereby enhancing the model’s adaptability and efficiency. Simulation results demonstrate that the IRIS algorithm performs exceptionally well across various IPP scenarios. Once training stabilizes, IDS will dominate decision-making with a probability of approximately 1.3 % to yield better outcomes, highlighting its significant potential in this field. The relevant code is available at https://github.com/SUTLZY/IRIS .},
  archive      = {J_PR},
  author       = {Ziyuan Liu and Yan Zhuang and Peng Wu and Yuanchang Liu},
  doi          = {10.1016/j.patcog.2025.112400},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112400},
  shortjournal = {Pattern Recognition},
  title        = {IRIS: An information path planning method based on reinforcement learning and information-directed sampling},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge tailoring: Bridging the teacher-student gap in semantic segmentation. <em>PR</em>, <em>172</em>, 112399. (<a href='https://doi.org/10.1016/j.patcog.2025.112399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation transfers knowledge from a high-capacity teacher network to a compact student network, but a large capacity gap often limits the student’s ability to fully benefit from the teacher’s guidance. In semantic segmentation, another major challenge is the difficulty in predicting accurate object boundaries, as even strong teacher models can produce ambiguous or imprecise outputs. To address both challenges, we present Knowledge Tailoring, a novel distillation framework that adapts the teacher’s knowledge to better match the student’s representational capacity and learning dynamics. Much like a tailor adjusts an oversized suit to fit the wearer’s shape, our method reshapes the teacher’s abundant but misaligned knowledge into a form more suitable for the student. KT introduces feature tailoring, which restructures intermediate features based on channel-wise correlation to narrow the representation gap, and logit tailoring, which improves boundary prediction by refining class-specific logits. The tailoring strategy evolves throughout training, offering guidance that aligns with the student’s progress. Experiments on Cityscapes, Pascal VOC, and ADE20K confirm that KT consistently enhances performance across a variety of architectures including DeepLabV3, PSPNet, and SegFormer. Our code is available for https://github.com/seok-hwa/KT .},
  archive      = {J_PR},
  author       = {Seokhwa Cheung and Seungbeom Woo and Taehoon Kim and Wonjun Hwang},
  doi          = {10.1016/j.patcog.2025.112399},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112399},
  shortjournal = {Pattern Recognition},
  title        = {Knowledge tailoring: Bridging the teacher-student gap in semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Understanding and tackling the modality imbalance problem in multimodal survival prediction. <em>PR</em>, <em>172</em>, 112398. (<a href='https://doi.org/10.1016/j.patcog.2025.112398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the in-depth integration of multimodal data, survival prediction has emerged as a pivotal task in cancer prognosis by facilitating personalized treatment planning and medical resource allocation. In this study, we report an intriguing phenomenon of inter-modality capability gap (ICG) enlargement during joint survival modelling of genomics data and pathology images. This observation, supported by our dedicated theoretical analysis, uncovers a previously unrecognized modality imbalance problem, where pathology modality suffers from limited gradient propagation and insufficient learning while genomics modality dominates in reducing survival loss. To tackle this problem, we further propose a balanced multimodal learning approach for survival prediction named BMLSurv, which introduces two innovative auxiliary learning strategies: self-enhancement learning (SEL) and peer-assistance learning (PAL). The SEL strategy exploits a real-time imbalance measure to guide extra task-aware supervision, therefore dynamically strengthening pathology-specific gradient propagation in a self-enhanced manner. Meanwhile, the PAL strategy leverages the stronger genomics modality as a “helpful peer” to assist the sufficient learning of pathology modality via a new risk-ranking distillation technique. Extensive experiments on representative cancer datasets demonstrate that by successfully address the modality imbalance problem, BMLSurv remarkably narrows the ICG in joint survival modelling and consistently outperforms state-of-the-art methods by a large margin. These results underscore the potential of BMLSurv to advance multimodal survival prediction and enhance clinical decision-making in cancer prognosis.},
  archive      = {J_PR},
  author       = {Chicheng Zhou and Minghui Wang and Yi Shi and Anli Zhang and Ao Li},
  doi          = {10.1016/j.patcog.2025.112398},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112398},
  shortjournal = {Pattern Recognition},
  title        = {Understanding and tackling the modality imbalance problem in multimodal survival prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hyper-network curvature: A new representation method for high-order brain network analysis. <em>PR</em>, <em>172</em>, 112397. (<a href='https://doi.org/10.1016/j.patcog.2025.112397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human brain is a complex system and contains abundant high-order interactions among multiple brain regions, which can be described by brain hyper-network. In brain hyper-networks, nodes represent brain regions of interest (ROIs), while edges describe the interactions of multiple ROIs, providing important high-order information for brain disease analysis and diagnosis. However, most of the existing hyper-network studies focused on the hyper-connection (i.e. hyper-edge) analysis and ignored the local topological information on nodes. To address this problem, we propose a new representation method (i.e., hyper-network curvature) for brain hyper-network analysis. Compared with the existing hyper-network representation methods, the proposed hyper-network curvature can be used to analyze the local topologies of nodes in brain hyper-networks. Based on hyper-network curvature, we further propose a novel graph kernel called brain hyper-network curvature kernel to measure the similarity of a pair of brain hyper-networks. We have proved that the proposed hyper-network curvature is bounded and brain hyper-network curvature kernel is positive definite. To evaluate the effectiveness of our proposed method, we perform the classification experiments on functional magnetic resonance imaging data of brain diseases. The experimental results demonstrate that our proposed method can significantly improve classification accuracy compared to the state-of-the-art graph kernels and graph neural networks for classifying brain diseases.},
  archive      = {J_PR},
  author       = {Kai Ma and Tianyu Du and Qi Zhu and Xuyun Wen and Jiashuang Huang and Xibei Yang and Daoqiang Zhang},
  doi          = {10.1016/j.patcog.2025.112397},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112397},
  shortjournal = {Pattern Recognition},
  title        = {Hyper-network curvature: A new representation method for high-order brain network analysis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated cross-source learning for lung nodule segmentation with data characteristic-aware weight optimization. <em>PR</em>, <em>172</em>, 112396. (<a href='https://doi.org/10.1016/j.patcog.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning enables multiple medical institutions to undertake distributed training while protecting patient privacy. Nevertheless, the significant variance in data distributions across diverse sites results in imbalanced knowledge acquisition, thereby affecting the performance of the global model. To tackle this challenge, we propose a novel federated algorithm for lung nodule segmentation, incorporating a Cross-source Learning (CSL) method. This method generates pseudo nodules by synthesizing the nodule phase spectrum with the nodule amplitude spectrum from other clients. These pseudo nodules are subsequently embedded into pulmonary regions to augment the data. By incorporating knowledge from various clients, which alleviates the challenges posed by non-IID data. On the server side, a Data Characteristic-aware Weight Optimization (DCWO) method is proposed to incorporate client data quality assessment and the size of lung nodule volume as weights to optimize both model performance and fairness. On the client side, we design a Multi-scale Attention Dynamic Convolution (MADC) lightweight network, which dynamically adapts attention to different spatial regions and extracts features at multiple scales. The performance of our method is superior to the state-of-the-art methods on six public and in-house CT datasets of lung cancer.},
  archive      = {J_PR},
  author       = {Xinjun Bian and Huan Lin and Yumeng Wang and Lingqiao Li and Zhenbing Liu and Huadeng Wang and Zhenwei Shi and Yi Qian and Zaiyi Liu and Rushi Lan and Xipeng Pan},
  doi          = {10.1016/j.patcog.2025.112396},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112396},
  shortjournal = {Pattern Recognition},
  title        = {Federated cross-source learning for lung nodule segmentation with data characteristic-aware weight optimization},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint luminance-chrominance learning for quality assessment of low-light image enhancement. <em>PR</em>, <em>172</em>, 112395. (<a href='https://doi.org/10.1016/j.patcog.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods for low-light enhancement quality assessment (LEQA) often underperform across diverse scenarios. One reason is that most of them rely on shallow feature respresentations, while another is that deep-learning-based counterparts fail to make full use of the unique characteristics of low-light enhanced images (LEIs), such as luminance enhancement and color refinement. In this paper, we propose a novel Joint Luminance-Chrominance Learning Network (JLCLNet) for LEQA to comprehensively assess the effects of low-light image enhancement (LLIE) algorithms. Specifically, we construct a two-branch network architecture consisting of a luminance learning branch and a chrominance learning branch. In the luminance learning branch, the low- and high-frequency subbands of the luminance channel in the CIELAB color space, derived from the dual-tree complex wavelet transform (DTCWT), focus on measuring contrast enhancement and structure preservation. Meanwhile, the chrominance learning branch addresses potential color distortions by integrating perceptual information from the two parallel chrominance channels of the CIELAB color space. Finally, the complementary features from both branches are fused to predict quality scores. Experimental results on four public LEQA databases demonstrate the performance advantages of the proposed method compared to the state-of-the-art approaches. The source code of JLCLNet is available at https://github.com/li181119/JLCLNET .},
  archive      = {J_PR},
  author       = {Tuxin Guan and Qiuping Jiang and Xiongli Chai and Chaofeng Li},
  doi          = {10.1016/j.patcog.2025.112395},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112395},
  shortjournal = {Pattern Recognition},
  title        = {Joint luminance-chrominance learning for quality assessment of low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A graph contrastive learning network for change detection with heterogeneous remote sensing images. <em>PR</em>, <em>172</em>, 112394. (<a href='https://doi.org/10.1016/j.patcog.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land cover change detection (LCCD) with heterogeneous remote sensing images (Hete-RSIs) is an attractive topic in the community of remote sensing applications. Intuitively, Hete-RSIs are acquired with different remote sensors, and they cannot be compared directly for LCCD because of the different imaging modalities. In this paper, a graph contrastive learning network (GCLN) is proposed for LCCD with bitemporal Hete-RSIs. First, with the motivation of smoothing the noise and utilizing contextual information, the k-nearest neighbor algorithm is used to improve the spectral homogeneity of the pixels within a superpixel. Then, a pairwise graph is constructed on the basis of each superpixel from spectral similarity and dissimilarity perspectives, and a graph feature learning network is designed to learn the near-far dependencies of graph features for change detection. Finally, the similarity and dissimilarity loss functions are coupled as a contrastive loss function to expand the difference between similar and dissimilar features. Comparisons with seven advanced methods on five pairs of Hete-RSIs demonstrate the feasibility and superiority of the proposed GCLN for LCCD with Hete-RSIs. For example, the improvements on the five datasets are 3.63 % , 8.47 % , 4.17 % , 8.23 % , and 4.98 % in terms of overall accuracy. The code of the proposed approach can be available at: https://github.com/ImgSciGroup/2024-GCLN .},
  archive      = {J_PR},
  author       = {Zhiyong Lv and Sizhe Cheng and Linfu Xie and Junhuai Li and Minghua Zhao},
  doi          = {10.1016/j.patcog.2025.112394},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112394},
  shortjournal = {Pattern Recognition},
  title        = {A graph contrastive learning network for change detection with heterogeneous remote sensing images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AM40: Enhancing action recognition through matting-driven interaction analysis. <em>PR</em>, <em>172</em>, 112393. (<a href='https://doi.org/10.1016/j.patcog.2025.112393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition models frequently face challenges from complex video backgrounds, where actors may blend into their surroundings and complicate motion analysis. Human interactions with action-related elements vary across scenarios, with backgrounds serving as both contextual cues and sources of interference. To address these issues, we introduce video matting techniques to separate foreground subjects from the background. This enables the model to focus on the subject of interest while suppressing irrelevant regions, thereby enhancing the extraction of interactions between the subject and associated objects. To support this methodology, we present ActionMatting40 ( AM40 ) dataset, which comprises 40 action categories annotated with alpha mattes to distinguish human actions and related objects from the background. Furthermore, we propose Matting-Driven Interaction Recognition (MIR), integrating an Action Background Decoupling (ABD) module to mitigate background interference and a Semantic-aware Feature Communication (SFC) module to selectively extract informative features for improved action recognition. Our code and dataset are publicly available at https://github.com/lwxfight/actionmatting .},
  archive      = {J_PR},
  author       = {Siqi Liang and Wenxuan Liu and Zhe Li and Kui Jiang and Siyuan Yang and Chia-Wen Lin and Xian Zhong},
  doi          = {10.1016/j.patcog.2025.112393},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112393},
  shortjournal = {Pattern Recognition},
  title        = {AM40: Enhancing action recognition through matting-driven interaction analysis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Edge craft odyssey: Navigating guided super-resolution with a fast, precise, and lightweight network. <em>PR</em>, <em>172</em>, 112392. (<a href='https://doi.org/10.1016/j.patcog.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal imaging technology is exceptionally valuable in environments where visibility is limited or nonexistent. However, the high cost and technological limitations of high-resolution thermal imaging sensors restrict their widespread use. Many thermal cameras are now paired with high-resolution visible cameras, which can help improve low-resolution thermal images. However, aligning thermal and visible images is challenging due to differences in their spectral ranges, making pixel-wise alignment difficult. Therefore, we present the Edge Craft Odyssey Network (ECONet), a lightweight transformer-based network designed for Guided Thermal Super-Resolution (GTSR) to address these challenges. Our approach introduces a Progressive Edge Prediction module that extracts edge features from visible images using an adaptive threshold within our innovative Edge-Weighted Gradient Blending technique. This technique provides precise control over the blending intensity between low-resolution thermal and visible images. Additionally, we introduce a lightweight Cascade Deep Feature Extractor that focuses on efficient feature extraction and edge weight highlighting, enhancing the representation of high-frequency details. Experimental results show that ECONet outperforms state-of-the-art methods across various datasets while maintaining a relatively low computational and memory requirements. ECONet improves performance by up to 0.20 to 1.3 dB over existing methods and generates super-resolved images in a fraction of a second, approximately 91 % faster than the other methods. The code is available at https://github.com/Rm1n90/ECONet .},
  archive      = {J_PR},
  author       = {Armin Mehri and Parichehr Behjati and Dario Carpio and Angel D. Sappa},
  doi          = {10.1016/j.patcog.2025.112392},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112392},
  shortjournal = {Pattern Recognition},
  title        = {Edge craft odyssey: Navigating guided super-resolution with a fast, precise, and lightweight network},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models. <em>PR</em>, <em>172</em>, 112391. (<a href='https://doi.org/10.1016/j.patcog.2025.112391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent vulnerabilities of large Vision-Language Models (VLMs), security governance has emerged as a critical concern, particularly given the risks posed by noisy and biased training data as well as adversarial attacks, including data poisoning and prompt injection. These perturbations can significantly degrade model performance and introduce multifaceted societal risks. To verify the safe robustness of VLMs and further inspire the design of defensive AI frameworks, we propose Virtual Scenario Hypnosis (VSH), a multimodal prompt injection jailbreak method that embeds malicious queries into prompts through a deceptive narrative framework. This approach strategically distracts the model while compromising its resistance to jailbreak attempts. Our methodology features two key innovations: 1) Targeted adversarial image prompts that transform textual content into visual layouts through optimized typographic designs, circumventing safety alignment mechanisms to elicit harmful responses; and 2) An information veil encrypted In-Context Learning (ICL) method for text prompts that systematically evades safety detection protocols. To streamline evaluation, we employ Large Language Models (LLMs) to facilitate an efficient assessment of jailbreak success rates, supported by a meticulously designed prompt template incorporating multi-dimensional scoring rules and evaluation metrics. Extensive experiments demonstrate the efficacy of VSH, achieving an overall success rate exceeding 82% on 500 harmful queries spanning multiple domains when tested against LLaVA-v1.5-13B and GPT-4o mini.},
  archive      = {J_PR},
  author       = {Xiayang Shi and Shangfeng Chen and Gang Zhang and Wei Wei and Yinlin Li and Zhaoxin Fan and Jingjing Liu},
  doi          = {10.1016/j.patcog.2025.112391},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112391},
  shortjournal = {Pattern Recognition},
  title        = {Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A locality-sensitive hashing based instance selection method with its application to acceleration of feature selection. <em>PR</em>, <em>172</em>, 112390. (<a href='https://doi.org/10.1016/j.patcog.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of important data preprocessing techniques, feature selection aims to remove redundant and irrelevant features and has been extensively applied to many fields. At present, however, the evaluation of existing feature selection algorithms focuses mainly on the scale of the selected features and the performance of models formulated by the selected features, while the running time of feature selection algorithms is usually neglected. It is noted that the computation complexity of the majority of feature selection algorithms is the square order of the number of instances, resulting in an exponential increase of the running time for large-scale data. In this paper, we propose an algorithm of core instance selection based on the locality-sensitive hashing (CISLSH) to improve the computation efficiency of feature selection algorithms by alleviating the instances used for feature selection. Specifically, all the instances are firstly considered to map them into the one-dimensional integer space using a locality-sensitive hashing (LSH) function. Given a set of hash functions families, a bucket index matrix is constructed to integrate all the mapping results of the set of hash functions families. Then, a voting mechanism is designed according to the bucket index matrix, which motivates to present a novel data partitioning method dividing similar instances into the same bucket (partition) as many as possible. Furthermore, the CISLSH algorithm is developed by selecting a core instance from each non-empty bucket. Finally, numerical experiments are conducted to assess the performance of CISLSH. The experimental results show that the execution of feature selection using the representative instances selected by CISLSH can not only significantly reduce the running time of feature selection but also guarantee the effectiveness of the selected features.},
  archive      = {J_PR},
  author       = {Fan Song and Xiao Zhang and Jinhai Li and Changlin Mei},
  doi          = {10.1016/j.patcog.2025.112390},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112390},
  shortjournal = {Pattern Recognition},
  title        = {A locality-sensitive hashing based instance selection method with its application to acceleration of feature selection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive latent disease state learning for multimodal alzheimer’s disease biomarker detection with missing modalities. <em>PR</em>, <em>172</em>, 112389. (<a href='https://doi.org/10.1016/j.patcog.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal neuroimaging genetics is a crucial approach for identifying biomarkers of Alzheimer’s disease (AD) by leveraging the inherent relationships between genetic and neuroimaging data. However, existing methods are limited by susceptibility to input noises, underutilization of complementary information across neuroimaging modalities, and ineffective handling of samples with incomplete modalities. To address these challenges, we propose an Adaptive Latent Disease State Learning (ALDSL) method, which integrates noise reduction, latent space learning, adaptive regularization, and feature selection into a unified framework for detecting AD biomarkers from incomplete multimodal data. ALDSL introduces a noise reduction strategy based on inter-variable correlations and tailored distance metrics to eliminate noises in the input data, thereby obtaining high-quality representations for each modality. Additionally, latent disease state learning with adaptive regularization is proposed to capture inter-modality correlations by projecting the high-quality representations from multiple modalities into a common latent space. To utilize samples with incomplete modalities, we design a modality-specific weight matrix that accounts for the missing information in the latent disease state learning. Furthermore, an adaptive weighting determination strategy is developed to ensure that the modalities with different data types and varying sample sizes contribute on the same scale. We develop an efficient alternating optimization algorithm to solve the objective function of ALDSL. Experimental results on synthetic datasets and the ADNI GO/2 dataset demonstrate the effectiveness of ALDSL in detecting AD biomarkers.},
  archive      = {J_PR},
  author       = {Zhi Chen and Fengli Zhang and Yun Zhang and Jiajing Zhu and Qiaoqin Li and Yongguo Liu},
  doi          = {10.1016/j.patcog.2025.112389},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112389},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive latent disease state learning for multimodal alzheimer’s disease biomarker detection with missing modalities},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MMP: Enhancing unsupervised graph anomaly detection with multi-view message passing. <em>PR</em>, <em>172</em>, 112388. (<a href='https://doi.org/10.1016/j.patcog.2025.112388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complementary and conflicting relationships between views are two fundamental issues when applying Graph Neural Networks (GNNs) to multi-view attributed graph anomaly detection. Most existing approaches do not address the inherent multi-view properties in the attribute space or leverage complementary information through simple representation fusion, which overlooks the conflicting information among different views. In this paper, we argue that effectively applying GNNs to multi-view anomaly detection necessitates reinforcing complementary information between views and, more importantly, managing conflicting information. Building on this perspective, this paper introduces Multi-View Message Passing (MMP), a novel and effective message passing paradigm specifically designed for multi-view anomaly detection. In the multi-view aggregation phase of MMP, views containing different types of information are integrated using view-specific aggregation functions. This approach enables the model to dynamically adjust the amount of information aggregated from complementary and conflicting views, thereby mitigating issues arising from insufficient complementary information and excessive conflicting information, which can lead to suboptimal representation learning. Furthermore, we propose an innovative aggregation loss mechanism that enhances model performance by optimizing the reconstruction differences between aggregated representations and the original views, thereby improving both detection accuracy and model interpretability. Extensive experiments on synthetic and real-world datasets validate the effectiveness and robustness of our method. The source code is available at https://github.com/weihus/MMP .},
  archive      = {J_PR},
  author       = {Weihu Song and Lei Li and Mengxiao Zhu and Yue Pei and Haogang Zhu},
  doi          = {10.1016/j.patcog.2025.112388},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112388},
  shortjournal = {Pattern Recognition},
  title        = {MMP: Enhancing unsupervised graph anomaly detection with multi-view message passing},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HopGAT: A multi-hop graph attention network with heterophily and degree awareness. <em>PR</em>, <em>172</em>, 112387. (<a href='https://doi.org/10.1016/j.patcog.2025.112387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In highly heterophilic graphs, where nodes frequently connect across categories, the attention learning mechanism by dynamically adjusting neighboring node weights, may struggle to capture intricate node relationships. Furthermore, first-hop neighbor information is usually insufficient to encompass the global structure, but multi-hop increases complexity. To address these challenges, we propose HopGAT, a multi-hop graph attention network with heterophily and degree awareness. Firstly, we design heterophily-based neighbor sampling to sequentially filter high-hop neighbors by degree. Next, to obtain comprehensive global information, we construct a multi-hop recursive learning method with head and tail attention vectors to learn multi-hop neighbor features. Finally, we combine the average node degree of the graph with hop decay modeling to learn importance coefficients at different hops and adaptively aggregate the learned multi-hop features. Experimental results demonstrate that HopGAT significantly improves performance across 9 benchmark datasets with various heterophily and different average degrees.},
  archive      = {J_PR},
  author       = {Han Zhang and Huan Wang and Mingjing Han},
  doi          = {10.1016/j.patcog.2025.112387},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112387},
  shortjournal = {Pattern Recognition},
  title        = {HopGAT: A multi-hop graph attention network with heterophily and degree awareness},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A boundary-enhanced and target-driven deformable convolutional network for abdominal multi-organ segmentation. <em>PR</em>, <em>172</em>, 112386. (<a href='https://doi.org/10.1016/j.patcog.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to accurately segment organs from abdominal CT images for clinical diagnosis, treatment planning, and surgical guidance, which remains an extremely challenging task due to low contrast between organs and surrounding tissues and the difference of organ size and shape. Previous works mainly focused on complex network architectures or task-specific modules but frequently failed to learn irregular boundaries and did not consider that different slices from the same case might contain targets of different numbers of categories. To tackle these issues, this paper proposes UAMSNet for abdominal multi-organ segmentation. In UAMSNet, a hybrid receptive field extraction (HRFE) module is introduced to adaptively learn the features of irregular targets, which has an adaptive dilation factor containing distance information to facilitate spatial and channel attention. The HRFE module can simultaneously learn multiple scales and deformations of different organs. Furthermore, a multi-organ boundary-enhanced attention (MBA) module in the encoder and decoder is designed to provide effective boundary information for feature extraction based on the large peak of the organ edge. Finally, the difference in the number of organ categories between different slices is first considered using a loss function, which can adjust the loss computation based on organ categories in the image. The loss function mitigates the effect of false positives during training to ensure the model can adapt to small organ segmentation. Experimental results on WORD and Synapse datasets demonstrate that our UAMSNet outperforms the existing state-of-the-art methods. Ablation experiments confirm the effectiveness of our designed modules and loss function. Our code is publicly available on https://github.com/HeyJGJu/UAMSNet .},
  archive      = {J_PR},
  author       = {Jianguo Ju and Menghao Liu and Wenhuan Song and Tongtong Zhang and Jindong Liu and Pengfei Xu and Ziyu Guan},
  doi          = {10.1016/j.patcog.2025.112386},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112386},
  shortjournal = {Pattern Recognition},
  title        = {A boundary-enhanced and target-driven deformable convolutional network for abdominal multi-organ segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distantly supervised reinforcement localization for real-world object distribution estimation. <em>PR</em>, <em>172</em>, 112385. (<a href='https://doi.org/10.1016/j.patcog.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the distribution of objects in the real world from monocular images is a challenging task due to the disparity between object distributions in perspective images and reality. Many researchers focus on predicting object distributions by converting perspective images into Bird’s-Eye View (BEV) images. In scenarios where camera parameter information is unavailable, the prediction of vanishing lines becomes critical for performing inverse perspective transformations. However, accurately predicting vanishing lines necessitates accounting for variations in object size, which cannot be effectively captured through simple regression models. Therefore, this paper proposes a size variation-aware method, utilizing expert knowledge from object detection to build a reinforcement learning framework for predicting vanishing lines in traffic scenes. Specifically, this method leverages size information from trained detectors to convert perspective images into BEV images without the need for additional camera intrinsic parameters. First, we design a novel reward mechanism that utilizes prior knowledge of scale differences between similar objects in perspective images, allowing the network to automatically update and learn specific vanishing line positions. Second, we propose a fast inverse perspective transformation method, which accelerates the training speed of the proposed approach. To evaluate the effectiveness of the method, experiments are conducted on two traffic flow datasets. The experimental results demonstrate that the proposed algorithm accurately predicts vanishing line positions and successfully transforms perspective images into BEV images. Furthermore, the proposed algorithm performs competitively with directly supervised methods. The code is available at: https://github.com/HotChieh/DDRL.},
  archive      = {J_PR},
  author       = {Haojie Guo and Junyu Gao and Yuan Yuan},
  doi          = {10.1016/j.patcog.2025.112385},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112385},
  shortjournal = {Pattern Recognition},
  title        = {Distantly supervised reinforcement localization for real-world object distribution estimation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A variable gaussian kernel scale active contour model based on jeffreys divergence for ICT image segmentation. <em>PR</em>, <em>172</em>, 112384. (<a href='https://doi.org/10.1016/j.patcog.2025.112384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial computed tomography (ICT), factors like beam scattering, insufficient beam intensity, and detector dark current often lead to weak edges, scattering artifacts, and severe Gaussian noise in ICT images. These issues pose significant difficulties for accurate segmentation of high-density complex structures using existing active contour models (ACMs). To address these limitations, this paper presents a variable Gaussian kernel scale active contour model based on Jeffreys divergence (VGJD). Firstly, the Jeffreys divergence (JD) is incorporated into the energy function to replace the conventional Euclidean distance, enhancing the contour’s ability to quantify pixel value disparity during evolution. Additionally, a filter weight is introduced to minimize the impact of noise. Moreover, a variable Gaussian kernel scale strategy is adopted to effectively integrate both global and local image information, thereby enhancing the robustness of the initial contour and improving the precision of detail segmentation. Finally, optimized length and regularity terms are employed to enforce constraints on the level set function. Extensive experimental results demonstrate that the VGJD model can effectively segment various complex ICT images, achieving superior precision in comparison to other ACM models. The code is available at https://github.com/LiuZX599/ACM-VGJD.git},
  archive      = {J_PR},
  author       = {Zexin Liu and Qi Li and Junyao Wang and Tingyuan Deng and Rifeng Zhou and Yufang Cai and Fenglin Liu},
  doi          = {10.1016/j.patcog.2025.112384},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112384},
  shortjournal = {Pattern Recognition},
  title        = {A variable gaussian kernel scale active contour model based on jeffreys divergence for ICT image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust spatio-temporal graph neural networks with sparse structure learning. <em>PR</em>, <em>172</em>, 112383. (<a href='https://doi.org/10.1016/j.patcog.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of spatio-temporal graph classification by introducing sparse structure learning to enhance its robustness and explainability. Spatio-temporal graph neural networks (STGNN) integrate spatial structure and temporal sequential features into GNN learning, resulting in promising performance in many applications. However, current STGNN models often fail to capture the discriminative sparse substructure and the smooth distribution of these samples. To this end, this paper introduces RostGNN, robust spatio-temporal graph neural networks, for achieving more discriminative graph representations. Concretely, RostGNN extracts the spatial and temporal features by performing gated recurrent units on the given time series data and calculating adjacent matrixes for graphs. Then, we impose the iterative hard-thresholding approach on the final association matrix to obtain a sparse graph. Meanwhile, we calculate a similarity matrix from the side information of samples to smooth the achieved data representations and use fully connected networks for graph classification. We finally applied RostGNN to brain graph classification in experiments on real-world datasets. The results demonstrate that RostGNN delivers robust and discriminative graph representations and performs better than compared methods, benefiting from the sparsity and manifold regularizers. Furthermore, RostGNN can potentially yield useful findings for data understanding.},
  archive      = {J_PR},
  author       = {Yupei Zhang and Yuxin Li and Shuhui Liu and Xuequn Shang},
  doi          = {10.1016/j.patcog.2025.112383},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112383},
  shortjournal = {Pattern Recognition},
  title        = {Robust spatio-temporal graph neural networks with sparse structure learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiscDC: Unsupervised discriminative deep image clustering via confidence-driven self-labeling. <em>PR</em>, <em>172</em>, 112382. (<a href='https://doi.org/10.1016/j.patcog.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering, as an important research topic in machine learning and data mining, has been widely applied in many real-world scenarios. However, existing deep clustering methods primarily rely on implicit optimization objectives such as contrastive learning or reconstruction, which do not explicitly enforce cluster-level discrimination. This limitation restricts their ability to achieve compact intra-cluster structures and distinct inter-cluster separations. To overcome this limitation, we propose a novel unsupervised discriminative deep clustering (discDC) method, which explicitly integrates cluster-level discrimination into the learning process. The proposed discDC framework projects data into a nonlinear latent space with compact and well-separated cluster representations. It explicitly optimizes clustering objectives by minimizing intra-cluster discrepancy and maximizing inter-cluster discrepancy. Additionally, to tackle the lack of label information in unsupervised scenarios, we introduce a confidence-driven self-labeling mechanism, which iteratively derives reliable pseudo-labels to enhance discriminative analysis. Extensive experiments on five benchmark datasets demonstrate the superiority of discDC over state-of-the-art deep clustering approaches.},
  archive      = {J_PR},
  author       = {Jinyu Cai and Wenzhong Guo and Yunhe Zhang and Jicong Fan},
  doi          = {10.1016/j.patcog.2025.112382},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112382},
  shortjournal = {Pattern Recognition},
  title        = {DiscDC: Unsupervised discriminative deep image clustering via confidence-driven self-labeling},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MCoCa: Towards fine-grained multimodal control in image captioning. <em>PR</em>, <em>172</em>, 112381. (<a href='https://doi.org/10.1016/j.patcog.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controllable image captioning (CIC) models have traditionally focused on generating controlled descriptions using specific text styles. However, these approaches are limited as they rely solely on text control signals, which often fail to align with complex human intentions, such as selecting specific areas in images. To enhance multimodal interactivity, we propose to augment current CIC systems with diverse and joint visual-text controls. To achieve this, we first create a comprehensive Multimodal Controllable Image Captioning Corpus (MCoCa) dataset by leveraging language rewriting ability of GPT-3.5, containing 0.97M image-captions pairs along with 21 visual-text control signals. By training the visual and textual adapters equipped on the multimodal large language model with newly proposed instructional prompts on MCoCa, we observe emergent combinatory multimodal controllability and significant improvement in text controllability. We present exhaustive quantitative and qualitative results, benchmarking our trained model’s state-of-the-art zero-shot captioning performance on SentiCap and FlickrStyle10K in terms of both fidelity and controllability. For regional understanding ability of visual-controlled captioning, our method achieves obvious improvement compared with the baseline models.},
  archive      = {J_PR},
  author       = {Shanshan Zhao and Teng Wang and Jinrui Zhang and Xiangchen Wang and Feng Zheng},
  doi          = {10.1016/j.patcog.2025.112381},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112381},
  shortjournal = {Pattern Recognition},
  title        = {MCoCa: Towards fine-grained multimodal control in image captioning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning interpretable binary codes via semantic alignment for customized image retrieval. <em>PR</em>, <em>172</em>, 112380. (<a href='https://doi.org/10.1016/j.patcog.2025.112380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single modality hashing (SMH) has achieved impressive performance on image retrieval task in recent years. The only fly in the ointment is that most of the methods mainly measure the image similarity based on the high-level class labels. The retrieval needs in the real world are diverse in form of different subsets of the semantics (not only the category labels) presented in the query image. However, existing SMH methods fail to account for such customized image retrieval task that allows users to select visual semantics or their combinations present in the query and retrieve similar images based on such selected semantic descriptions. To address such practical issues, we propose a deep hashing to learn Interpretable Binary Codes (IBC), endowing the hashing bits with semantic interpretability rather than purely entangling the class information in the whole codes, i.e., aligning the criteria of binary space partition of each bit with a particular visual semantic concept. Specifically, binary encoding is a highly non-linear operation of dimension reduction, the semantic and spatial information of which has respectively been abstract and lost heavily. In light of the rich semantic interpretability and binary concept detection ability of convolutional filters, we innovatively transfer the semantic knowledge from filters to hashing bits by align the distributions of the binary codes and filter activations that capture the presence/absence of visual patterns in images. To further improve the semantics of filters/bits, the shared and learnable classification rules are introduced and optimized to disentangle the sparse composition between the category label and encoded semantics in filters/bits. With high interpretability, we can selectively combine bits corresponding to the target semantics during retrieval, thereby enabling flexible and customized similarity searches. Extensive experiments on several large-scale datasets covering general objects and scenes, single and multiple label scenarios, demonstrate the interpretability and functionalities of learned binary codes for the customized image retrieval tasks.},
  archive      = {J_PR},
  author       = {Shishi Qiao and Ruiping Wang and Xilin Chen},
  doi          = {10.1016/j.patcog.2025.112380},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112380},
  shortjournal = {Pattern Recognition},
  title        = {Learning interpretable binary codes via semantic alignment for customized image retrieval},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AFFusion: Atmospheric scattering enhancement and frequency integrated spatial-channel attention for infrared and visible image fusion. <em>PR</em>, <em>172</em>, 112379. (<a href='https://doi.org/10.1016/j.patcog.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) seeks to generate fused images that combine rich texture details with distinct thermal radiation features by integrating and leveraging complementary information from multiple sources. However, existing fusion methods frequently neglect the challenges posed by illumination degradation and inaccurate color contrast, which arise due to light energy loss and light scattering during atmospheric transmission. To address these limitations, this study introduces an innovative IVIF framework, termed AFFusion, which integrates an atmospheric scattering physical model with a frequency-domain feature component. By accurately predicting and estimating two key physical parameters-the transmission map and atmospheric light-within the scattering model, AFFusion harnesses atmospheric scattering principles to produce enhanced visible images, thereby mitigating the adverse effects of energy attenuation and scattering. Furthermore, to resolve artifacts and texture loss caused by traditional atmospheric scattering models, AFFusion incorporates Fourier transform in conjunction with spatial and channel attention mechanisms to selectively amplify amplitude and phase features in the frequency domain, thereby enhancing texture fidelity and detail representation within the fused images. Comprehensive experimental evaluations demonstrate that AFFusion surpasses state-of-the-art methods in both qualitative and quantitative performance metrics, while also providing robust support for high-level visual tasks. The implementation code is publicly accessible at https://github.com/cici0206/AFFusion .},
  archive      = {J_PR},
  author       = {Jiwei Hu and Chengcheng Song and Qiwen Jin and Kin-Man Lam},
  doi          = {10.1016/j.patcog.2025.112379},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112379},
  shortjournal = {Pattern Recognition},
  title        = {AFFusion: Atmospheric scattering enhancement and frequency integrated spatial-channel attention for infrared and visible image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Vision-by-prompt: Context-aware dual prompts for composed video retrieval. <em>PR</em>, <em>172</em>, 112378. (<a href='https://doi.org/10.1016/j.patcog.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composed video retrieval (CoVR) is a challenging task of retrieving relevant videos in a corpus by using a query that integrates both a relative change text and a reference video. Most existing CoVR models simply rely on the late-fusion strategy to combine visual and change text. Furthermore, various methods have been proposed to generate pseudo-word tokens from the reference video, which are then integrated into the relative change text for CoVR. However, these pseudo-word-based techniques exhibit limitations when the target video involves complex changes from the reference video, e.g. , object removal. In this work, we propose a novel CoVR framework that learns context information via context-aware dual prompts for relative change text to achieve effective composed video retrieval. The dual prompts cater to two aspects: 1) Global descriptive prompts generated from the pretrained V-L models, e.g. , BLIP-2, to get concise textual representations of the reference video. 2) Local target prompts to learn the target representations that the change text pays attention to. By connecting these prompts with relative change text, one can easily use existing text-to-video retrieval models to enhance CoVR performance. Our proposed framework can be flexibly used for both composed video retrieval (CoVR) and composed image retrieval (CoIR) tasks. Moreover, we take a pioneering approach by adopting the CoVR model to achieve zero-shot CoIR for remote sensing. Experiments on four datasets show that our approach achieves state-of-the-art performance in both CoVR and zero-shot CoIR tasks, with improvements of as high as around 3.5 % in terms of recall@K=1 score.},
  archive      = {J_PR},
  author       = {Hao Wang and Fang Liu and Licheng Jiao and Jiahao Wang and Shuo Li and Lingling Li and Puhua Chen and Xu Liu},
  doi          = {10.1016/j.patcog.2025.112378},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112378},
  shortjournal = {Pattern Recognition},
  title        = {Vision-by-prompt: Context-aware dual prompts for composed video retrieval},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient and compact tensor wheel decomposition for tensor completion. <em>PR</em>, <em>172</em>, 112377. (<a href='https://doi.org/10.1016/j.patcog.2025.112377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor wheel (TW) decomposition has recently emerged as a powerful technique for achieving state-of-the-art recovery performance in tensor completion tasks. However, its widespread application has been hindered by issues related to rank sensitivity and high computational cost. To address these limitations, we introduce an efficient and compact TW decomposition method for low-rank tensor completion. Specifically, we demonstrate that the model complexity of TW decomposition is controlled simultaneously by two elements, namely, the explicit TW rank and implicit sparsity in the core tensor. Therefore, low-rank and sparsity regularization are introduced to ring factors and core factor, respectively, to achieve a compact TW decomposition. Furthermore, to alleviate the computational bottleneck of TW decomposition, we propose a novel generalized inverse operation, which reduces the computational complexity of vanilla TW decomposition from O ( I N R 2 N ) to O ( I N R N ) . Subsequently, we develop an efficient alternating direction method of multipliers (ADMM) algorithm with theoretical convergence guarantees. Numerical tensor completion experiments on color images, multispectral images, and color videos demonstrate that the proposed method achieves superior performance while significantly reducing runtime compared to state-of-the-art methods. The code is available at: https://github.com/justicbro/TWLRS .},
  archive      = {J_PR},
  author       = {Peilin Yang and Yuning Qiu and Zhenhao Huang and Guoxu Zhou and Qibin Zhao},
  doi          = {10.1016/j.patcog.2025.112377},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112377},
  shortjournal = {Pattern Recognition},
  title        = {Efficient and compact tensor wheel decomposition for tensor completion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning to complement with multiple humans. <em>PR</em>, <em>172</em>, 112376. (<a href='https://doi.org/10.1016/j.patcog.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solution for addressing real-world image classification challenges. Human-AI collaborative classification (HAI-CC) aims to synergise the efficiency of machine learning classifiers and the reliability of human experts to support decision making. Learning to defer (L2D) has been one of the promising HAI-CC approaches, where the system assesses a sample and decides to defer to one of human experts when it is not confident. Despite recent progress, existing L2D methods rely on the strong assumption of ground truth label availability for training, while in practice, most datasets often contain multiple noisy annotations per data sample without well-curated ground truth labels. In addition, current L2D methods either consider the setting of a single human expert or defer the decision to one human expert, even though there may be multiple experts available, resulting in a suboptimal utilisation of available resources. Furthermore, current HAI-CC evaluation frameworks often overlook processing costs, making it difficult to assess the trade-off between computational efficiency and performance when benchmarking different methods. To address these gaps, this paper introduces LECOMH – a new HAI-CC method that learns from noisy labels without depending on clean labels for training, simultaneously maximising collaborative accuracy with either one or multiple human experts, while minimising the cost of human collaboration. The paper also introduces benchmarks featuring multiple noisy labels per data sample for both training and testing to evaluate HAI-CC methods. Through quantitative comparisons on these benchmarks, LECOMH consistently outperforms HAI-CC methods and baselines, including human experts alone, multi-rater learning and noisy-label learning methods across both synthetic and real-world datasets.},
  archive      = {J_PR},
  author       = {Zheng Zhang and Cuong Nguyen and Kevin Wells and Thanh-Toan Do and Gustavo Carneiro},
  doi          = {10.1016/j.patcog.2025.112376},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112376},
  shortjournal = {Pattern Recognition},
  title        = {Learning to complement with multiple humans},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-aware state-space method for underwater object detection. <em>PR</em>, <em>172</em>, 112375. (<a href='https://doi.org/10.1016/j.patcog.2025.112375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater Object Detection (UOD) faces significant challenges due to complex degradation factors, such as color shifts caused by light absorption and scattering, spatially varying noise induced by plankton and sea snow, and motion blur resulting from dynamic water currents. Among existing methods, Convolutional Neural Networks (CNNs) are limited by fixed receptive fields, making it difficult to model long-range noise patterns; while Transformers excel at modeling global dependencies, they suffer from high computational complexity and weak capability in restoring fine-grained local features. Neither can effectively address the demands of detecting underwater-specific noise and small objects. To tackle these issues, we propose UOD-Mamba, a state space model (SSM)-based framework for underwater object detection. At its core is the Noise-Aware Dual-path Mamba (NADM) module, which integrates a global-local dual-path fusion strategy to enable both long-range noise modeling and local feature enhancement. The global path balances noise in input features through the Noise-Balanced Preprocessing Module (NBPM) and leverages Mamba’s long-range modeling capability to extract global noise patterns; the local path fuses the Underwater Enhanced Multi-scale Attention Module (UEMA) with CSP convolution to model edge and detail features at a fine-grained level, thereby compensating for the loss of local information. By explicitly learning the distribution characteristics of underwater noise and capturing the differences between noise and target features, the framework enhances detection robustness in noisy environments. Experimental validation on the DUO and RUOD datasets demonstrates that UOD-Mamba sets a new state-of-the-art in detection performance. It also exhibits advantages in explicit modeling of diverse noises, preservation of local details, and computational efficiency across multi-noise scenarios, enabling effective handling of complex underwater interference environments.},
  archive      = {J_PR},
  author       = {Jingchun Zhou and Xudong Wang and Mingjie Li and Zongxin He and Wentian Xin and Xiuguo Zhang},
  doi          = {10.1016/j.patcog.2025.112375},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112375},
  shortjournal = {Pattern Recognition},
  title        = {Noise-aware state-space method for underwater object detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-domain-aware deep unfolding transformer for hyperspectral image super-resolution. <em>PR</em>, <em>172</em>, 112374. (<a href='https://doi.org/10.1016/j.patcog.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusing low-spatial-resolution hyperspectral images with high-spatial-resolution (HSR) multispectral images is pivotal for generating HSR hyperspectral images (HSR-HSIs). While current deep unrolling-based multi-stage frameworks have shown notable advancements due to their robustness and interpretability, they still exhibit limitations in adequately harnessing the HSI prior knowledge. This deficiency is principally attributed to three factors: (1) prior knowledge learned from training samples often overlooks target-specific characteristics; (2) insufficient feature representation within and across stages; and (3) insufficient modeling of spatial–spectral dependencies. To address these issues, we propose a novel Cross-domain-aware Transformer (CaFormer). Specifically, a cross-domain aware attention mechanism is investigated to capture intrinsic joint spatial–spectral dependencies through unified cross-domain feature representation. The attention mechanism models HSI eigenfeatures to derive spatial and spectral representations while preserving their mutual correlations. Furthermore, we introduce a Fourier Domain Perception Block to enhance structural and semantic representations by exploiting amplitude and phase components in the frequency domain, thereby strengthening feature aggregation across stages. To further improve adaptability while preserving the interpretability of deep unrolling networks, CaFormer employs a dual-stage prior learning strategy, transferring prior knowledge learned from general training data to the specific observed scene. Our experimental evaluations on four public datasets and Worldview-2 satellite images confirm that our proposed method outperformed eleven state-of-the-art methods. The code is available at https://github.com/Caoxuheng/HIFtool .},
  archive      = {J_PR},
  author       = {Xuheng Cao and Xuquan Wang and Xiong Dun and Yusheng Lian and Xinbin Cheng and Xiaopeng Hao},
  doi          = {10.1016/j.patcog.2025.112374},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112374},
  shortjournal = {Pattern Recognition},
  title        = {Cross-domain-aware deep unfolding transformer for hyperspectral image super-resolution},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-teacher self-distillation registration for multi-modality medical image fusion. <em>PR</em>, <em>172</em>, 112373. (<a href='https://doi.org/10.1016/j.patcog.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misaligned multimodal medical images pose challenges to the fusion task, resulting in structural distortions and edge artifacts in the fusion results. Existing registration networks primarily consider single-scale deformation fields at each stage, thereby neglecting long-range connections between non-adjacent stages. Moreover, in the fusion task, due to the quadratic computational complexity faced by Transformers during feature extraction, they are unable to effectively capture long-range correlated features. To address these problems, we propose an image registration and fusion method called DTMFusion. DTMFusion comprises two main networks: a Dual-Teacher Self-Distillation Registration (DTSDR) network and a Mamba-Conv-based Fusion (MCF) network. The registration network employs a pyramid progressive architecture to generate independent deformation fields at each layer. We introduce a dual-teacher self-distillation scheme that leverages past learning history and the current network structure as teacher guidance to constrain the generated deformation fields. For the fusion network, we introduced Mamba to address the quadratic complexity problem of Transformers. Specifically, the fusion network involves two key components: the Shallow Fusion Module (SFM) and the Cross-Modality Fusion Module (CFM). The SFM achieves lightweight cross-modality interaction through channel exchange, while the CFM leverages inherent cross-modality relationships to enhance the representation capability of fusion results. Through the collaborative effort of these components, the network can effectively integrate cross-modality complementary information and maintain appropriate apparent strength from a global perspective. Extensive experimental analysis demonstrates the superiority of this method in fusing misaligned medical images.},
  archive      = {J_PR},
  author       = {Aimei Dong and Jingyuan Xu and Long Wang},
  doi          = {10.1016/j.patcog.2025.112373},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112373},
  shortjournal = {Pattern Recognition},
  title        = {Dual-teacher self-distillation registration for multi-modality medical image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FSF-net: Enhance 4D occupancy forecasting with coarse BEV scene flow for autonomous driving. <em>PR</em>, <em>172</em>, 112372. (<a href='https://doi.org/10.1016/j.patcog.2025.112372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {4D occupancy forecasting is one of the important techniques for autonomous driving, which can avoid potential risk in the complex traffic scenes. Scene flow is a crucial element to describe 4D occupancy map tendency. However, an accurate scene flow is difficult to predict in the real scene. In this paper, we find that BEV scene flow can approximately represent 3D scene flow in most traffic scenes. And coarse BEV scene flow is easy to generate. Under this thought, we propose 4D occupancy forecasting method FSF-Net based on coarse BEV scene flow. At first, we develop a general occupancy forecasting architecture based on coarse BEV scene flow. Then, to further enhance 4D occupancy feature representation ability, we propose a vector quantized based Mamba (VQ-Mamba) network to mine spatial-temporal structural scene feature. After that, to effectively fuse coarse occupancy maps forecasted from BEV scene flow and latent features, we design a U-Net based quality fusion (UQF) network to generate the fine-grained forecasting result. Extensive experiments are conducted on public Occ3D dataset. FSF-Net has achieved IoU and mIoU 9.56 % and 10.87 % higher than state-of-the-art method. Hence, we believe that proposed FSF-Net benefits to the safety of autonomous driving.},
  archive      = {J_PR},
  author       = {Erxin Guo and Pei An and You Yang and Qiong Liu and An-An Liu},
  doi          = {10.1016/j.patcog.2025.112372},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112372},
  shortjournal = {Pattern Recognition},
  title        = {FSF-net: Enhance 4D occupancy forecasting with coarse BEV scene flow for autonomous driving},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel image enhancement method based on image decomposition and deep neural networks. <em>PR</em>, <em>172</em>, 112371. (<a href='https://doi.org/10.1016/j.patcog.2025.112371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image decomposition and deep learning are active research areas in computer vision tasks, such as cartoon texture decomposition, low-light image enhancement, rain streak removal, image recovery, etc. This paper proposes a novel low-light image enhancement method by joining image decomposition and deep neural network techniques. We introduce a new image decomposition-based optimization model by incorporating the Tikhonov regularization and multi-scale convolutional sparse coding (MSCSC) to enhance image visual effects. To enhance robustness performance, we introduce a noise-free image decomposition error term to effectively suppress noise in low-light images. To effectively implement the proposed method, we incorporate a deep-unfolding neural network and an adaptive denoiser into the alternating direction method of multipliers (ADMM) framework. Since the deep unfolding network can effectively simulate the optimization algorithm process, the interpretability of the network model is increased. Moreover, through end-to-end training, we can automatically estimate the two priors and parameter settings from training samples. Finally, qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art image enhancement methods in terms of visual quality and robustness. The source code is available at https://github.com/cassiopeia-yxx/LLIE .},
  archive      = {J_PR},
  author       = {Yao Xiao and Youshen Xia},
  doi          = {10.1016/j.patcog.2025.112371},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112371},
  shortjournal = {Pattern Recognition},
  title        = {A novel image enhancement method based on image decomposition and deep neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonuniform low-light image enhancement via noise-aware decomposition and adaptive correction. <em>PR</em>, <em>172</em>, 112370. (<a href='https://doi.org/10.1016/j.patcog.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-illumination conditions often exhibit low brightness with nonuniform distribution, low contrast, and noise, negatively affecting the human visual experience and the accuracy of image-based computer vision tasks. Enhancing nonuniform low-light images is challenging considering the requirement of simultaneously reducing noise, enhancing low-light regions, and suppressing high-light regions. To address these challenges, we innovatively propose a noise-aware decomposition and adaptive correction method (NDAC) to enhance the nonuniform low-light images without the need for paired high-quality training data. Specifically, a noise-aware image decomposition network (NIDNet) is first presented to decompose the input images into illumination, reflection, and noise components, while suppressing the noise in the reflection component through a variable gradient operator and estimating the noise component. Besides, we devise a novel nonlinear adaptive brightness mapping function (NABM), whose parameters are optimized via a designed automatic light enhancement network (ALENet) to brighten the illumination component. The enhancements are obtained by fusing the noiseless reflection component with the brightened illumination component. Extensive experiments on both public and industrial datasets demonstrate that the proposed NDAC method outperforms state-of-the-art approaches in both qualitative and quantitative evaluations.},
  archive      = {J_PR},
  author       = {Jiancai Huang and Zhaohui Jiang and Xingjian Liu and Yap-Peng Tan and Weihua Gui},
  doi          = {10.1016/j.patcog.2025.112370},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112370},
  shortjournal = {Pattern Recognition},
  title        = {Nonuniform low-light image enhancement via noise-aware decomposition and adaptive correction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fourier-enhanced semi-supervised proxy learning for ultra-fine-grained novel class discovery. <em>PR</em>, <em>172</em>, 112369. (<a href='https://doi.org/10.1016/j.patcog.2025.112369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating in open-world environments requires recognizing known categories and discovering new ones, especially in ultra-fine-grained task, where distinguishing similar categories is challenging. The task of Ultra-Fine-Grained Novel Class Discovery (UFG-NCD) intensifies this challenge by requiring systems to identify previously unseen classes within unlabeled data. However, existing UFG-NCD methods fall short in extracting critical visual cues and efficiently transferring knowledge from known to novel categories. To overcome these limitations, this paper proposes Fourier-Enhanced Semi-supervised Proxy Learning (FESPL), a novel framework for UFG-NCD. FESPL incorporates a Fourier amplitude guided block that leverages frequency domain analysis to capture high-frequency details often missed by traditional approaches, enhancing ultra-fine-grained discrimination. Additionally, the semi-supervised proxy learning strategy maximizes information extraction from limited labeled data and promotes robust generalization across known and unseen categories. Our approach achieves substantial improvements in both novel category discovery and known category classification on seven popular UFG-NCD datasets, with average performance gains of 10.41 % in the accuracy of the old class and 4.27 % in the accuracy of the new class in task-agnostic evaluation, while with average performance gains of 4.40 % in clustering accuracy on the unlabeled training data in task-aware evaluation.},
  archive      = {J_PR},
  author       = {Qiupu Chen and Hongkui Jiang and Lin Jiao and Zhou Li and Taosheng Xu and Xue Wang and Rujing Wang},
  doi          = {10.1016/j.patcog.2025.112369},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112369},
  shortjournal = {Pattern Recognition},
  title        = {Fourier-enhanced semi-supervised proxy learning for ultra-fine-grained novel class discovery},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive weighted active contour based HRNet for underwater image segmentation. <em>PR</em>, <em>172</em>, 112368. (<a href='https://doi.org/10.1016/j.patcog.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acquiring optimal results in underwater environments remains challenging due to light absorption, scattering, and suspended particles. Furthermore, the low-resolution outputs from traditional semantic segmentation often result in spatial information loss and blurred segmentation boundaries. To address these issues, we first propose a low-level image enhancement preprocessing module as an independent preliminary stage to improve underwater image quality, thereby enhancing subsequent high-level semantic segmentation performance. Second, leveraging the region-based active contour model-which is independent of image gradients and adept at handling complex contour topology changes-we design a novel level set function to serve as the level set in the geometric active contour model. While this new level set exhibits formal similarity to classical level sets in representing binary segmentation contours, its formulation is derived from network prediction outputs. Third, we construct an adaptive weighted active contour energy function as a loss function within HRNet for multi-class segmentation. This loss function preserves geometric information while penalizing deviations between network-predicted probabilities and ground truth, effectively mitigating spatial information loss and optimizing boundary. Comparative experiments demonstrate that our model outperforms classical methods on objective metrics including mIoU and mPA.},
  archive      = {J_PR},
  author       = {Bo Chen and Jing Ji and Junwei Li and Xiaoli Sun and Feng Gong},
  doi          = {10.1016/j.patcog.2025.112368},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112368},
  shortjournal = {Pattern Recognition},
  title        = {An adaptive weighted active contour based HRNet for underwater image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BORT2: Bi-level optimization for robust target training in multi-source domain adaptation. <em>PR</em>, <em>172</em>, 112367. (<a href='https://doi.org/10.1016/j.patcog.2025.112367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both conventional and source-free multi-source domain adaptation (MSDA) tasks often face bias toward source domains, because more numerous labeled data in these domains, compared with a single unlabeled target domain, can dominate the training process. To alleviate the bias, target adaptation techniques train a target model on the pseudo-labeled target domain data only, with the source-domain-biased models used as the labeling function for pseudo-label generation. However, the pseudo labels may contain noise and harm performance when directly used for supervision. To tackle label noise, we introduce a novel Bi-level Optimization for Robust Target Training (BORT 2 ) scheme. BORT 2 trains a noise-robust target model on pseudo-labeled target data only and meanwhile updates the labeling function (i.e., the source-domain-biased models) to improve pseudo-label quality. Specifically, the target model is a stochastic network designed to be robust to label noise. Such a stochastic network exploits a Gaussian distribution to model the feature of each target instance and deploys an entropy maximization regularizer to the Gaussian to quantify the uncertainty of each pseudo-label, where the uncertainty is utilized to mitigate the negative effects of label noise. In addition, BORT 2 leverages the entropy to update the labeling function for better pseudo-label quality. Updating both the labeling function and the stochastic network involves a nested bi-level optimization problem, addressed using implicit differentiation. Extensive experiments demonstrate that BORT 2 achieves state-of-the-art performance for both conventional and source-free MSDA, as verified on Office-Home, Office-Caltech, PACS, Digit-Five, and the large-scale DomainNet datasets.},
  archive      = {J_PR},
  author       = {Zhongying Deng and Da Li and Xiaojiang Peng and Yi-Zhe Song and Tao Xiang},
  doi          = {10.1016/j.patcog.2025.112367},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112367},
  shortjournal = {Pattern Recognition},
  title        = {BORT2: Bi-level optimization for robust target training in multi-source domain adaptation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ultra-efficient 3D shape reconstruction: Line-coded absolute phase unwrapping algorithm. <em>PR</em>, <em>172</em>, 112366. (<a href='https://doi.org/10.1016/j.patcog.2025.112366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Absolute phase unwrapping-based fringe projection profilometry (APU-FPP) has the advantages of pixel-wise calculation, high precision, and full-field sensing of 3D shape information. To the best of our knowledge, existing APU-FPP methods have a general contradiction between accuracy and efficiency because of projecting extra auxiliary coded fringes (ACFs). In this paper, a line-coded absolute phase unwrapping (LCAPU) algorithm is presented for absolute 3D shape reconstruction of the scene with non-uniform reflectivity and complex surfaces. Firstly, a sequence of single-pixel lines is successively embedded into two sets of 3-step phase-shifting patterns to mark fringe periods, which can thoroughly avoid extra ACFs to disrupt the coherence of adjacent morphological information. Secondly, two line-coded phase-shifting patterns with the same phase shift are used to recognize the corresponding coded lines containing the fringe order cue, which can be simultaneously used to guide fringe mutual compensation, thereby extracting a high-quality phase. Finally, according to the pixel positions and the fringe indices of the decoded lines, a multi-layer decoding (MLD) algorithm is developed to iteratively generate a fringe order map, which can adapt to the randomness of morphological changes. Compared to other methods, the proposed LCAPU can not only perform a one-shot 3D shape reconstruction with a single image acquisition, but also automatically correct phase errors, balancing ultra-efficiency and high accuracy. Experimental results demonstrate the superior performance and the practical application potential in dynamic complex scenes.},
  archive      = {J_PR},
  author       = {Haihua An and Yiping Cao and Hechen Zhang},
  doi          = {10.1016/j.patcog.2025.112366},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112366},
  shortjournal = {Pattern Recognition},
  title        = {Ultra-efficient 3D shape reconstruction: Line-coded absolute phase unwrapping algorithm},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning label-specific features for multi-dimensional classification. <em>PR</em>, <em>172</em>, 112365. (<a href='https://doi.org/10.1016/j.patcog.2025.112365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-dimensional classification (MDC), instances are associated with multiple class variables that are assumed in the output space, and each class variable corresponds to one heterogeneous class space and characterizes the objects’ semantics from one dimension. Learning from MDC examples poses challenges due to the heterogeneity of class spaces, since the outputs from different class spaces are not directly comparable. Moreover, existing approaches often use identical data representation for all labels in a class, which may lead to suboptimal results as each label might be determined by its own specific characteristics. Critically, the inherent incomparability of raw heterogeneous labels prevents existing methods from effectively capturing label correlations, which are essential for guiding feature learning. In this paper, we propose a novel algorithm named LEAD, i.e., learning Label-spEcific feAtures for multi-Dimensional classification. LEAD first resolves label heterogeneity by transforming the original output space into a unified encoded label space through one-hot label encoding. This critical alignment enables explicit extraction of label correlations from the encoded space. To enhance the reliability of the estimation of label correlations, LEAD then leverages feature-space manifold structures via locally linear embedding, propagating labeling information across similar instances to counteract sparsity. Finally, LEAD jointly learns label-specific feature representations and constructs the classifier through sparse learning while incorporating label correlations. Experimental comparisons on fifteen datasets demonstrate that our proposed method outperforms state-of-the-art multi-dimensional classification methods. The code is available at https://github.com/ZhangZan-source/LEAD .},
  archive      = {J_PR},
  author       = {Zan Zhang and Jialin Zhou and Jialu Yao and Lin Liu and Jiuyong Li and Lei Li and Xindong Wu},
  doi          = {10.1016/j.patcog.2025.112365},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112365},
  shortjournal = {Pattern Recognition},
  title        = {Learning label-specific features for multi-dimensional classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TSAR: A two-stage approach to motion artifact reduction in OCTA images. <em>PR</em>, <em>172</em>, 112364. (<a href='https://doi.org/10.1016/j.patcog.2025.112364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical Coherence Tomography Angiography (OCTA) is an innovative and non-invasive imaging technique that leverages motion contrast imaging to generate angiographic images from high-resolution volumetric blood flow data rapidly. However, OCTA imaging is vulnerable to various artifacts induced by eye movements, including displacement artifacts, duplicated scanning artifacts, and white line artifacts. Previous methods that attempted to mitigate eye motion artifacts necessitated costly hardware upgrades. However, despite the availability of advanced eye-tracking hardware and software correction in commercial machines, motion artifacts persist in real-world usage. Recently developed cost-effective learning-based methods only focus on the removal of white line artifacts while neglecting the displacement artifacts and duplicated scanning artifacts. To address this challenge, we propose a comprehensive framework, TSAR, to remove three types of eye motion artifacts in OCTA images. In the first stage, we leverage the intrinsic axial and directional attributes of these artifacts in the first phase to develop an innovative hierarchical transformer network. This network is designed to capture global-wise, local-wise, and vertical-wise features effectively while also removing displacement and duplicate scanning artifacts. Afterward, we leverage the contextual information and develop a residual conditional diffusion model (RCDM) to remove the white line artifacts. By applying our TSAR to the degraded OCTA images, we aim to eliminate all three types of motion artifacts. We evaluate the superior performance of our proposed methodology in artifact removal and image quality enhancement compared to other methods by conducting experiments on both synthetic and real-world OCTA images. The code is available at https://github.com/btma48/TSAR},
  archive      = {J_PR},
  author       = {Benteng Ma and Xiaomeng Li and Xu Lin and Xiaoyu Bai and Dongping Shao and Chubin Ou and Lin An and Jia Qin and Kwang-Ting Cheng},
  doi          = {10.1016/j.patcog.2025.112364},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112364},
  shortjournal = {Pattern Recognition},
  title        = {TSAR: A two-stage approach to motion artifact reduction in OCTA images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quaternionic reweighted amplitude flow for phase retrieval in image reconstruction. <em>PR</em>, <em>172</em>, 112363. (<a href='https://doi.org/10.1016/j.patcog.2025.112363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternionic signal processing provides powerful tools for efficiently managing color signals by preserving the intrinsic correlations among signal dimensions through quaternion algebra. In this paper, we address the quaternionic phase retrieval problem by systematically developing novel algorithms based on an amplitude-based model. Specifically, we propose the Quaternionic Reweighted Amplitude Flow (QRAF) algorithm, which is further enhanced by three of its variants: incremental, accelerated, and adapted QRAF algorithms. In addition, we introduce the Quaternionic Perturbed Amplitude Flow (QPAF) algorithm, which has linear convergence. Extensive numerical experiments on both synthetic data and real images demonstrate that our proposed methods significantly improve recovery performance and computational efficiency compared to state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Ren Hu and Pan Lian},
  doi          = {10.1016/j.patcog.2025.112363},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112363},
  shortjournal = {Pattern Recognition},
  title        = {Quaternionic reweighted amplitude flow for phase retrieval in image reconstruction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust scene text understanding with OCR token and word alignment for text-VQA and text-caption. <em>PR</em>, <em>172</em>, 112362. (<a href='https://doi.org/10.1016/j.patcog.2025.112362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve vision-language tasks incorporating scene text, such as Text-VQA and Text-Caption, recognizing and understanding scene text within image is the first priority. However, the scene text recognized by Optical Character Recognition (OCR) systems often includes spelling errors, such as “pepsi” being recognized as “peosi”. These OCR errors are one of the major challenges for Text-VQA and Text-Caption systems. To address this, we propose a novel multi-modal OCR Token and Word Alignment (TWA) method to alleviate OCR errors in these tasks. First, we artificially create the misspelled OCR tokens and render them onto the RGB images, which can effectively simulates OCR errors. Second, we propose an OCR token-word contrastive learning task to pre-train OCR token representation, making the system more robust to OCR errors. Finally, we introduce a vocabulary predictor with character-level semantic matching, which enables the model to recover the correct word from the vocabulary even with misspelled OCR tokens. A variety of experimental evaluations demonstrate that our method outperforms the state-of-the-art methods on both Text-VQA and Text-Caption datasets.},
  archive      = {J_PR},
  author       = {Zan-Xia Jin and Pinle Qin and Suzhen Lin and Jia Qin and Shuangjiao Zhai and Jianchao Zeng and Xu-Cheng Yin},
  doi          = {10.1016/j.patcog.2025.112362},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112362},
  shortjournal = {Pattern Recognition},
  title        = {Robust scene text understanding with OCR token and word alignment for text-VQA and text-caption},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prior tokenization-based interactive segmentation with vision transformers. <em>PR</em>, <em>172</em>, 112361. (<a href='https://doi.org/10.1016/j.patcog.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively leveraging the provided priors is crucial for interactive segmentation. Existing approaches typically encode clicks via distance-based maps, which are then concatenated or added to the original image as network input. However, these methods do not fully exploit the semantic information embedded in the provided priors, leading to confusion in the feature distribution of different targets and reducing the segmentation quality. To address this issue, we propose a prior tokenization-based interactive segmentation method that uses simple Vision Transformers. By extending the original image tokens with prior tokens, each token represents the semantic features of the foreground and background related to the priors. These tokens participate in the self-attention operation alongside regular image tokens, gradually extracting semantic features from the image tokens to the prior tokens. In addition, we introduce a discriminative loss function to enforce inter-class separation and intra-class compactness of the prior tokens. Subsequently, we employ a cross-attention mechanism to couple the prior tokens with the regular image block token features, ensuring that the features extracted by the network are aligned with the user’s intent. Finally, we use the register method to suppress artifacts and enhance the segmentation performance further. Extensive experiments demonstrate that our method achieves superior interaction efficiency, robustness, and generalization ability across various medical image segmentation benchmarks. The source codes are available at https://github.com/dzyha2011/PT-SimpleClick},
  archive      = {J_PR},
  author       = {Zongyuan Ding and Boyu Wang and Hongyuan Wang and Tao Wang},
  doi          = {10.1016/j.patcog.2025.112361},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112361},
  shortjournal = {Pattern Recognition},
  title        = {Prior tokenization-based interactive segmentation with vision transformers},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CTNet: Color transformation network for low-light image enhancement. <em>PR</em>, <em>172</em>, 112360. (<a href='https://doi.org/10.1016/j.patcog.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light images are often plagued by low visibility, poor contrast, and high noise levels, which significantly impair both subjective visual quality and the performance of downstream tasks. Existing enhancement methods typically struggle with color-related degradations such as color casting, artifacts, and distortion. To address these challenges, we propose an end-to-end Color Transformation Network for low-light image enhancement, with a specific focus on improving color restoration. By leveraging the complementary strengths of the HSV and RGB color spaces in capturing color attributes, our approach enables effective interaction between these color spaces at the feature level. The HSV branch simultaneously enhances the V component while extracting features from the H and S components, thereby providing a more comprehensive set of cues for color recovery. To facilitate interaction, we design a learnable Color Transformation Block that bridges the HSV and RGB feature domains, effectively simulating the HSV-to-RGB conversion. Furthermore, a Cross-Integration Block, employing an attention-based cross-guidance mechanism, enables bi-directional information flow between the two color spaces. Extensive experiments on both real and synthetic datasets demonstrate that our method achieves superior performance, surpassing existing approaches both qualitatively and quantitatively. The project is available at https://github.com/1013990424/CTNet .},
  archive      = {J_PR},
  author       = {Lidong Xie and Runmin Cong and Ju Dai and Wenhan Yang and Junjun Pan and Hao Wu},
  doi          = {10.1016/j.patcog.2025.112360},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112360},
  shortjournal = {Pattern Recognition},
  title        = {CTNet: Color transformation network for low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint adversarial attack: An effective approach to evaluate robustness of 3D object tracking. <em>PR</em>, <em>172</em>, 112359. (<a href='https://doi.org/10.1016/j.patcog.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have widely been used in 3D object tracking, thanks to its superior capabilities to learn from geometric training samples and locate tracking targets. Although the DNN based trackers show vulnerability to adversarial examples, their robustness in real-world scenarios with potentially complex data defects has rarely been studied. To this end, a joint adversarial attack method against 3D object tracking is proposed, which simulates defects of the point cloud data in the form of point filtration and perturbation simultaneously. Specifically, a voxel-based point filtration module is designed to filter points of the tracking template, which is described by the voxel-wise binary distribution regarding the density of the point cloud. Furthermore, a voxel-based point perturbation module adds voxel-wise perturbations to the filtered template, whose direction is constrained by local geometrical information of the template. Experiments conducted on popular 3D trackers demonstrate that the proposed joint attack have decreased the success and precision of existing 3D trackers by 30.2% and 35.4% respectively in average, which made an improvement of 30.5% over existing attack methods.},
  archive      = {J_PR},
  author       = {Riran Cheng and Xupeng Wang and Ferdous Sohel and Hang Lei},
  doi          = {10.1016/j.patcog.2025.112359},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112359},
  shortjournal = {Pattern Recognition},
  title        = {Joint adversarial attack: An effective approach to evaluate robustness of 3D object tracking},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-channel blur invariants of color and multispectral images. <em>PR</em>, <em>172</em>, 112358. (<a href='https://doi.org/10.1016/j.patcog.2025.112358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with the recognition of blurred color/multispectral images directly without any deblurring. We present a general theory of invariants of multispectral images with respect to blur. The paper is a significant non-trivial extension of the recent theory of blur invariants of graylevel images. The main original contribution of the paper lies in introducing cross-channel blur invariants in Fourier domain. We also developed an algorithm for their stable and fast calculation in the moment domain. Moreover, the cross-channel invariants can be found for blurs for which single-channel invariants do not exist. The experiments on simulated and real data demonstrate that incorporating the new cross-channel invariants significantly improves the recognition power and surpasses other existing approaches. The outlook for a possible implementation of the blur invariants into neural networks is briefly sketched in the conclusion.},
  archive      = {J_PR},
  author       = {Václav Košík and Jan Flusser and Filip Šroubek},
  doi          = {10.1016/j.patcog.2025.112358},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112358},
  shortjournal = {Pattern Recognition},
  title        = {Cross-channel blur invariants of color and multispectral images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniForCE: The unimodality forest method for clustering and estimation of the number of clusters. <em>PR</em>, <em>172</em>, 112357. (<a href='https://doi.org/10.1016/j.patcog.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the number of clusters k while clustering the data is a challenging task. An incorrect cluster assumption indicates that the number of clusters k gets wrongly estimated. Consequently, the model fitting becomes less important. In this work, we focus on the concept of unimodality and propose a flexible cluster definition called locally unimodal cluster . A locally unimodal cluster extends for as long as unimodality is locally preserved across pairs of subclusters of the data. Then, we propose the UniForCE method for locally unimodal clustering. The method starts with an initial overclustering of the data and relies on the unimodality graph that connects subclusters forming unimodal pairs. Such pairs are identified using an appropriate statistical test. UniForCE identifies maximal locally unimodal clusters that are statistically significant by computing a spanning forest in the unimodality graph. Experimental results on both real and synthetic datasets illustrate that the proposed methodology is particularly flexible and robust in discovering regular and highly complex cluster shapes. Most importantly, it automatically provides an adequate estimation of the number of clusters.},
  archive      = {J_PR},
  author       = {Georgios Vardakas and Argyris Kalogeratos and Aristidis Likas},
  doi          = {10.1016/j.patcog.2025.112357},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112357},
  shortjournal = {Pattern Recognition},
  title        = {UniForCE: The unimodality forest method for clustering and estimation of the number of clusters},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SequencePAR: Understanding pedestrian attributes via a sequence generation paradigm. <em>PR</em>, <em>172</em>, 112356. (<a href='https://doi.org/10.1016/j.patcog.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current pedestrian attribute recognition (PAR) algorithms use multi-label or multi-task learning frameworks with specific classification heads. These models often struggle with imbalanced data and noisy samples. Inspired by the success of generative models, we propose Sequence Pedestrian Attribute Recognition (SequencePAR), a novel sequence generation paradigm for PAR. SequencePAR extracts pedestrian features using a language-image pre-trained model and embeds the attribute set into query tokens guided by text prompts. A Transformer decoder generates human attributes by integrating visual features and attribute query tokens. The masked multi-head attention layer in the decoder prevents the model from predicting the next attribute during training. The extensive experiments on multiple PAR datasets validate the effectiveness of SequencePAR. Specifically, we achieve 84.92 %, 90.44 %, 90.73 %, and 90.46 % in accuracy, precision, recall, and F1-score on the PETA dataset.},
  archive      = {J_PR},
  author       = {Jiandong Jin and Xiao Wang and Yin Lin and Chenglong Li and Lili Huang and Aihua Zheng and Jin Tang},
  doi          = {10.1016/j.patcog.2025.112356},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112356},
  shortjournal = {Pattern Recognition},
  title        = {SequencePAR: Understanding pedestrian attributes via a sequence generation paradigm},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SATE: Efficient knowledge distillation with implicit student-aware teacher ensembles. <em>PR</em>, <em>172</em>, 112355. (<a href='https://doi.org/10.1016/j.patcog.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent findings suggest that with the same teacher architecture, a fully converged or “stronger” checkpoint surprisingly leads to a worse student. This can be explained by the Information Bottleneck (IB) principle, as the features of a weaker teacher transfer more “dark” knowledge because they maintain higher mutual information with the inputs. Meanwhile, various works have shown that severe teacher-student structural disparity or capability mismatch often leads to worse student performance. To deal with these issues, we propose a generalizable and efficient Knowledge Distillation (KD) framework with implicit Student-Aware Teacher Ensembles (SATE). The SATE framework simultaneously trains a student network and a student-aware intermediate teacher as a learning companion. With the proposed co-training strategy, the intermediate teacher is trained gradually and forms implicit ensembles of weaker teachers along the learning process. Such a design enables the student model to retain more dark knowledge for better generalization ability. The proposed framework improves the training scheme in a plug-and-play way so that it can be applied to improve various classic and state-of-the-art KD methods on both intra-domain (up to 2.184 % ) and cross-domain (up to 7.358 % ) settings, under a diversified configurations on teacher-student architectures, and achieves a major efficient advantage over other generic frameworks. The code is available at https://github.com/diqichen91/SATE.git .},
  archive      = {J_PR},
  author       = {Diqi Chen and Yang Li and Jiajun Liu and Jun Zhou and Yongsheng Gao},
  doi          = {10.1016/j.patcog.2025.112355},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112355},
  shortjournal = {Pattern Recognition},
  title        = {SATE: Efficient knowledge distillation with implicit student-aware teacher ensembles},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative attention based weighted sparse representation of visual objects in complex scenarios. <em>PR</em>, <em>172</em>, 112354. (<a href='https://doi.org/10.1016/j.patcog.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse subspace representation (SSR) is an attractive technique for subspace segmentation of high-dimensional data through a self-representation manner to reveal its algebraic structure. Numerous generalizations of SSR have been developed to meet different applications. However, a fatal limitation in those extensions is their neglect of feature weights in visual samples, which play crucial roles in segmenting or recognizing specific objects. This paper introduces a discriminative attention based weighted SSR model to tackle visual objects. In the proposed model, the prior information is empirically constructed for intra-cluster features and inter-cluster ones, aided by the sparse representation of samples. An attention mechanism is introduced to learn weights of features of samples. The attention based weights of objects in samples and sparse representation of samples are collaboratively learned from the prior information. A hard version and a soft one of attention based sparse subspace representation, abbreviated as HDAWSSR and SDAWSSR, are specified by assigning attention of features by a Boolean matrix and a fuzzy matrix. Algorithms for solving both models are meticulously developed, respectively. Applications of both algorithms in clustering and moving object detection within high-dimensional image data are investigated. Experimental results show that both models outperform the state-of-the-art subspace based segmentation methods.},
  archive      = {J_PR},
  author       = {Ge Yang and Tingquan Deng and Ming Yang and Changzhong Wang},
  doi          = {10.1016/j.patcog.2025.112354},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112354},
  shortjournal = {Pattern Recognition},
  title        = {Discriminative attention based weighted sparse representation of visual objects in complex scenarios},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale feature sharing and collaborative sampling for unsupervised vehicle re-identification. <em>PR</em>, <em>172</em>, 112353. (<a href='https://doi.org/10.1016/j.patcog.2025.112353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle Re-identification (Re-ID) retrieves target vehicle images from non-overlapping cameras. To address label noise in pseudo-labels, we propose the Multi-scale Feature Sharing and Collaborative Sampling (MFSCS) method. Specifically, the designed multi-scale feature sharing module moves beyond reliance on global features, efficiently promoting the exchange of characteristics between global and local aspects. This shared feature approach collectively mitigates the label noise arising from clustering. Recognizing that clustering methods are highly sensitive to outliers, we introduce a collaborative sampling module that cooperatively combines samples in the clustering process before training the model. This cooperative sampling module is better equipped to handle outliers in the samples and update label information more efficiently. As a result, it asymptotically improves the accuracy and stability of the model. The effectiveness of the proposed method in terms of performance is demonstrated through extensive experiments conducted on both the latest challenging truck Re-ID dataset, Truck-ID and VeRi-776.},
  archive      = {J_PR},
  author       = {Jia-Jia Li and Si-Bao Chen and Chris Ding and Bin Luo},
  doi          = {10.1016/j.patcog.2025.112353},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112353},
  shortjournal = {Pattern Recognition},
  title        = {Multi-scale feature sharing and collaborative sampling for unsupervised vehicle re-identification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). You look from old classes: Towards accurate few shot class-incremental learning. <em>PR</em>, <em>172</em>, 112352. (<a href='https://doi.org/10.1016/j.patcog.2025.112352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) is a common but difficult task that faces two challenges: catastrophic forgetting of old classes and insufficient learning of new classes with limited samples. Recent wisdom focuses on preventing catastrophic forgetting yet overlooks the limited samples issue, resulting in poor new class performance. In this paper, we argue that old class samples contain rich knowledge, which can be exploited to supplement the learning of new classes. To this end, we propose to Look from Old Classes (YLOC) for FSCIL, enhancing both the base and incremental sessions. In the base session, we develop a prototype centered loss (PCL) to obtain a compact distribution of old classes. During incremental sessions, we devise a prototype augmentation learning (PAL) method to aid the learning of new classes by exploiting old classes. Extensive experiments on three FSCIL benchmark datasets demonstrate the superiority of our method.},
  archive      = {J_PR},
  author       = {Yijie Hu and Kaizhu Huang and Wei Wang and Xiaowei Huang and Qiufeng Wang},
  doi          = {10.1016/j.patcog.2025.112352},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112352},
  shortjournal = {Pattern Recognition},
  title        = {You look from old classes: Towards accurate few shot class-incremental learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-decoder collaborative learning with multi-hybrid view augmentation for self-supervised 3D action recognition. <em>PR</em>, <em>172</em>, 112351. (<a href='https://doi.org/10.1016/j.patcog.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised methods, including contrastive learning and masked skeleton modeling, have demonstrated considerable potential in the field of skeleton-based action recognition. While contrastive learning captures fine-grained details at the instance level, masked skeleton modeling emphasizes joint-level features. Recent studies have begun to combine these two approaches. However, existing combination methods primarily focus on integrating the tasks within the skeleton space. Moreover, existing contrastive learning methods often fail to exploit the comprehensive interaction information in skeletal structures, resulting in suboptimal performance when recognizing actions involving multiple individuals. To overcome these limitations, we introduce the Dual-Decoder Collaborative Learning (DDC) with Multi-Hybrid View Augmentation (MHGNA) method, which connects these two tasks across multiple spaces. Specifically, the masked skeleton modeling task provides diverse views for the contrastive learning task in the skeleton space, while the contrastive method aligns the features generated by both tasks within the feature space. We further present an innovative view augmentation method that enhances the model’s capacity to understand human interaction relationships by shuffling and replacing data across temporal, spatial, and personal dimensions. Extensive experiments on four downstream tasks across three large-scale datasets demonstrate that DDC exhibits stronger representational capabilities compared to state-of-the-art methods. Our code is available at https://github.com/Yingfei-Wu/DDC .},
  archive      = {J_PR},
  author       = {Wenming Cao and Yingfei Wu and Xinpeng Yin},
  doi          = {10.1016/j.patcog.2025.112351},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112351},
  shortjournal = {Pattern Recognition},
  title        = {Dual-decoder collaborative learning with multi-hybrid view augmentation for self-supervised 3D action recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). D3PD: Dual distillation and dynamic fusion for camera-radar 3D perception. <em>PR</em>, <em>172</em>, 112350. (<a href='https://doi.org/10.1016/j.patcog.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving perception is driving rapid advancements in Bird’s-Eye-View (BEV) technology. The synergy of surround-view imagery and radar is seen as a cost-friendly approach that enhances the understanding of driving scenarios. However, current methods for fusing radar and camera features lack effective environmental perception guidance and dynamic adjustment capabilities, which restricts their performance in real-world scenarios. In this paper, we introduce the D3PD framework, which combines fusion techniques with knowledge distillation to tackle the dynamic guidance deficit in existing radar-camera fusion methods. Our method includes two key modules: Radar-Camera Feature Enhancement (RCFE) and Dual Distillation Knowledge Transfer. The RCFE module enhances the areas of interest in BEV, addressing the poor object perception performance of single-modal features. The Dual Distillation Knowledge Transfer includes four distinct modules: Camera Radar Sparse Distillation (CRSD) for sparse feature knowledge transfer and teacher-student network feature alignment. Position-guided Sampling Distillation(SamD) for refining the knowledge transfer of fused features through dynamic sampling. Detection Constraint Result Distillation (DcRD) for strengthening the positional correlation between teacher and student network outputs in forward propagation, achieving more precise detection perception. and Self-learning Mask Focused Distillation (SMFD) for focusing perception detection results on knowledge transfer through self-learning, concentrating on the reinforcement of local key areas. The D3PD framework outperforms existing methods on the nuScenes benchmark, achieving 49.6 % mAP and 59.2 % NDS performance. Moreover, in the occupancy prediction task, D3PD-Occ has achieved an advanced performance of 37.94 % mIoU. This provides insights for the design and model training of camera and radar-based 3D object detection and occupancy network prediction methods. The code will be available at https://github.com/no-Name128/D3PD .},
  archive      = {J_PR},
  author       = {Junyin Wang and Chenghu Du and Tongao Ge and Bingyi Liu and Shengwu Xiong},
  doi          = {10.1016/j.patcog.2025.112350},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112350},
  shortjournal = {Pattern Recognition},
  title        = {D3PD: Dual distillation and dynamic fusion for camera-radar 3D perception},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TBiGAN-based parallel networks for remaining useful life prediction of multi-stage degraded bearings. <em>PR</em>, <em>172</em>, 112349. (<a href='https://doi.org/10.1016/j.patcog.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of the remaining useful life (RUL) of rolling bearings is crucial for ensuring the safe and reliable operation of rotating machinery. However, existing methods generally overlook the correlation between different degradation stages and RUL, thereby limiting the accuracy of RUL prediction for rolling bearings. To address this challenge, a novel adaptive RUL prediction method for multi-stage degrading rolling bearings is proposed. Specifically, a new Transformer-based network is designed to classify the degradation stages of bearings. Additionally, a parallel RUL prediction model incorporating attention mechanisms is introduced, which integrates Temporal Convolutional Networks (TCN) and Bidirectional Gated Recurrent Units (BiGRU) to capture degradation features from multiple dimensions automatically and enhance the model’s ability to capture long-term dependencies in sequence tasks. Finally, the RUL prediction results from different stages are adaptively integrated using a smoothing technique to generate the final RUL. The accuracy and superiority of the proposed method are validated on the PHM2012 bearing dataset.},
  archive      = {J_PR},
  author       = {Zheng Jianfei and Chen Dongnan and Hu Changhua and Han Qihui and Pei Hong},
  doi          = {10.1016/j.patcog.2025.112349},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112349},
  shortjournal = {Pattern Recognition},
  title        = {TBiGAN-based parallel networks for remaining useful life prediction of multi-stage degraded bearings},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MChartQA and mChartQABench: A multimodal-only solution for complex chart question-answering. <em>PR</em>, <em>172</em>, 112348. (<a href='https://doi.org/10.1016/j.patcog.2025.112348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal chart question-answering (QA) is essential for applications such as financial report analysis, decision support, and invoice parsing. Current methods typically convert charts to text for processing by large language models (LLMs) or use direct multimodal processing. This raises an important question: under what conditions is a multimodal approach essential for chart question-answering? We observe that these traditional approaches often struggle with complex color patterns, structural intricacies, and implicit numerical data. Yet, limited research addresses these challenges. To bridge this gap, we introduce a new multimodal chart dataset, mChartQABench, constructed by consolidating data from existing open-source datasets to address challenges with color, structure, and textless chart data. To handle these complex multimodal scenarios effectively, we propose mChartQA, a framework integrating the advanced language processing of LLMs with a state-of-the-art table-to-text engine. This framework excels in aligning visual and textual data, enhancing deep reasoning and contextual understanding within charts. Experimental results show that mChartQA achieves superior performance across four datasets, with over 20 % overall accuracy improvement on mChartQABench.},
  archive      = {J_PR},
  author       = {Jingxuan Wei and Nan Xu and Guiyong Chang and Yin Luo and Bihui Yu and Ruifeng Guo},
  doi          = {10.1016/j.patcog.2025.112348},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112348},
  shortjournal = {Pattern Recognition},
  title        = {MChartQA and mChartQABench: A multimodal-only solution for complex chart question-answering},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Copula-based conformal prediction for prioritized heterogeneous multi-task learning. <em>PR</em>, <em>172</em>, 112347. (<a href='https://doi.org/10.1016/j.patcog.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction (CP) has emerged as a standard for finite-sample and distribution-free uncertainty quantification (UQ). Although CP is widely used as a post-processing step (on the outputs of machine learning models) to produce reliable set-valued predictions, it is still challenging to post-process heterogeneous (i.e., categorical & numerical) predictions since the traditional CP procedures are either exclusively designed for classification or only tailored to regression. This article proposes the use of a simple yet novel copula-based CP method that jointly produces (discrete) set-valued predictions and (continuous) interval-valued predictions. This approach offers flexibility by allowing the prioritization of specific outputs’ reliability and applies to general heterogeneous multi-task problems. We demonstrate its effectiveness in the context of autonomous driving, on two popular multi-class object detection benchmarks, where it effectively infers set values for object classes and bounding boxes with the specified confidence levels. Experimental results validate our method’s ability in handling heterogeneous multi-task conformal predictions: we achieve high confidence levels without losing the informativeness of the prediction regions.},
  archive      = {J_PR},
  author       = {Bruce Cyusa Mukama and Soundouss Messoudi and Sébastien Destercke and Sylvain Rousseau},
  doi          = {10.1016/j.patcog.2025.112347},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112347},
  shortjournal = {Pattern Recognition},
  title        = {Copula-based conformal prediction for prioritized heterogeneous multi-task learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep spatio-temporal architecture for dynamic ECN analysis with granger causality based causal discovery. <em>PR</em>, <em>172</em>, 112346. (<a href='https://doi.org/10.1016/j.patcog.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurobrain science provides the motivation for research on causal modeling. The existing causal discovery methods have shown promising results in effective connectivity network analysis, however, they often overlook the dynamics of causality, in addition to the incorporation of spatio-temporal information in data. Dynamic effective connectivity networks (dECNs) reveal the changing directed brain activity and the dynamic causal influences among brain regions, which facilitate the identification of individual differences and enhance the understanding of human brain. To learn dynamic causality, we propose a deep spatio-temporal fusion architecture, which employs a dynamic causal deep encoder to incorporate spatio-temporal information into dynamic causality modeling, and a dynamic causal deep decoder to verify the discovered causality. The effectiveness of the proposed method is first illustrated with simulated data. Then, experimental results from Philadelphia Neurodevelopmental Cohort (PNC) demonstrate the superiority of the proposed method in inferring dECNs, which reveal the dynamic evolution of directed flow between brain regions. The analysis shows the difference of dECNs between young adults and children. Specifically, the directed brain functional networks transit from fluctuating undifferentiated systems to more stable specialized networks as one grows. This observation provides further evidence on the modularization and adaptation of brain networks during development, leading to higher cognitive abilities observed in young adults.},
  archive      = {J_PR},
  author       = {Faming Xu and Yiding Wang and Gang Qu and Vince D. Calhoun and Julia M. Stephen and Tony W. Wilson and Yu-Ping Wang and Chen Qiao},
  doi          = {10.1016/j.patcog.2025.112346},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112346},
  shortjournal = {Pattern Recognition},
  title        = {A deep spatio-temporal architecture for dynamic ECN analysis with granger causality based causal discovery},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised domain adaptation via style-aware self-intermediate domain. <em>PR</em>, <em>172</em>, 112344. (<a href='https://doi.org/10.1016/j.patcog.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) has garnered significant attention for its ability to transfer knowledge from a label-rich source domain to a related but unlabeled target domain, with minimizing inter-domain discrepancies being crucial, especially when a substantial gap exists between the domains. To address this, we introduce the novel Style-aware Self-Intermediate Domain (SSID), which effectively bridges large domain gaps by facilitating knowledge transfer while preserving class-discriminative information. Inspired by human transitive inference and learning capabilities, SSID connects seemingly unrelated concepts through a sequence of intermediate, auxiliary synthesized concepts. Meanwhile, an external memory bank is designed to store and update designated labeled features, ensuring the stability of class-specific and class-wise style features. Additionally, we also proposed a novel intra- and inter-domain loss functions that enhance class recognition and feature compatibility, with their convergence rigorously validated through a novel analytical approach. Comprehensive experiments demonstrate that SSID achieves accuracies of 85.4 % and 85.3 % on two widely recognized UDA benchmarks, outperforming the second-best methods by 0.94 % and 1.17 %, respectively. As a plug-and-play solution, SSID integrates seamlessly with various backbone networks, showcasing its effectiveness and versatility in domain adaptation scenarios.},
  archive      = {J_PR},
  author       = {Lianyu Wang and Meng Wang and Daoqiang Zhang and Huazhu Fu},
  doi          = {10.1016/j.patcog.2025.112344},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112344},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised domain adaptation via style-aware self-intermediate domain},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing visual representation of untrimmed videos by counteracting visuality threatening content. <em>PR</em>, <em>172</em>, 112343. (<a href='https://doi.org/10.1016/j.patcog.2025.112343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the remarkable growth of the video platform industry and the surge in video uploads, Content-Based Video Retrieval (CBVR), which finds videos on desired topics from a collection of untrimmed videos using solely the visual modality, is gaining increased attention. However, the challenge of accurate retrieval persists due to the varied and complex content in untrimmed videos, and there has been a lack of discussion on which types of content compromise visual representations. In this paper, we found that text and blur texture are of this nature, grounded in empirical observations. Indeed, in models focusing on the visual modality, both the visual structure of text (without semantics) and the smoothness of blur texture (with few edges and corners) interfere with decision-making. To address them, we propose two strategies: text-masking learning, which excludes the effect of text in the descriptor for inputs that may contain text content, and blur texture filtering, a re-scaling strategy that mitigates the impact of blur textures by exploiting the neural network’s insensitivity to the smoothed pixel-wise gradients. Furthermore, through empirical observations, we demonstrate that our proposed method effectively handles visuality-threatening content. Additionally, we show that our method can lead to state-of-the-art performance across multiple benchmarks of untrimmed videos.},
  archive      = {J_PR},
  author       = {Gwangjin Lee and Won Jo and Hyunwoo Kim and Yukyung Choi},
  doi          = {10.1016/j.patcog.2025.112343},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112343},
  shortjournal = {Pattern Recognition},
  title        = {Enhancing visual representation of untrimmed videos by counteracting visuality threatening content},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Texture-aware transformer with pose-patch mapping for occluded person re-identification. <em>PR</em>, <em>172</em>, 112341. (<a href='https://doi.org/10.1016/j.patcog.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification (re-ID) aims to retrieve the target person from occluded images captured by different cameras, where the challenges lie in identity loss caused by different types of occlusion. To alleviate the occlusion interference, some methods rely on external clues or generate more occlusion samples. However, these methods fail to address the issues of pose misalignment under extreme occlusion and identity confusion caused by non-target pedestrian occlusion. To solve these problems, we design a novel T exture-Aware T ransformer with P ose-Patch M apping (TTPM), which does not require generating any occlusion samples. Specifically, a Multi-patch Feature Encoder is proposed to encode discriminative features from inter patches and intra patches. Afterwards, the Pose-Patch Mapping is designed to construct a positional mapping between poses and patches, which highlights human patches and weakens the impact of occluded patches. Finally, to mitigate the non-target pedestrian occlusion, a Texture-Aware Decoder is introduced to perceive texture features and leverage their distinctiveness to enhance the representation of important regions. Extensive experiments show that our method achieves state-of-the-art results on Occluded-Duke and Occluded-REID datasets.},
  archive      = {J_PR},
  author       = {Dengwen Wang and Guanyu Xing and Yanli Liu},
  doi          = {10.1016/j.patcog.2025.112341},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112341},
  shortjournal = {Pattern Recognition},
  title        = {Texture-aware transformer with pose-patch mapping for occluded person re-identification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient community-aware pre-training method for graph neural networks. <em>PR</em>, <em>172</em>, 112340. (<a href='https://doi.org/10.1016/j.patcog.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While graph neural networks (GNNs) have demonstrated widespread success in various domains, their pre-training techniques lag behind those in computer vision and natural language processing, typically exhibiting limited performance gains and high computational costs. This paper introduces Community-Aware Pre-training (CAP), a novel approach that leverages the inherent community structures prevalent in real-world networks to enhance GNN pre-training efficiency and effectiveness. CAP employs a self-supervised contrastive learning framework to learn node representations that are highly discriminative of their respective communities. To further optimize the pre-training process, we introduce a Monte Carlo Tree Search-based community sampler that efficiently extracts representative subgraphs, mitigating noise and enhancing sample quality. CAP is versatile and can be applied to a broad range of node classification tasks due to the commonly existing community structures within networks. Extensive evaluations on diverse node classification benchmarks demonstrate that CAP consistently outperforms state-of-the-art methods, achieving accuracy improvements of up to 4.34 % while significantly reducing pre-training time by up to 14.87 times compared to existing techniques. Furthermore, CAP enhances the predictive confidence and visualization distinctiveness of node representations, paving a new path for effective and efficient GNN pre-training.},
  archive      = {J_PR},
  author       = {Zhenhua Huang and Wenhao Zhou and Yihang Jiang and Zhaohong Jia and Linyuan Lü and Yunjie Ma},
  doi          = {10.1016/j.patcog.2025.112340},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112340},
  shortjournal = {Pattern Recognition},
  title        = {An efficient community-aware pre-training method for graph neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction. <em>PR</em>, <em>172</em>, 112339. (<a href='https://doi.org/10.1016/j.patcog.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have made significant progress in trajectory prediction tasks but still face several critical challenges. The ordinary differential equation (ODE) solving methods used in standard diffusion models often suffer from error accumulation during multi-step iterations. Additionally, the denoising process is highly time-consuming due to the large number of computational steps, which significantly hinders inference efficiency and makes real-time applications challenging. To address these issues, we propose a diffusion-based method, DiffTrajectory, which integrates the Runge-Kutta (RK4) method, a Leap Initializer Module (LIM), and an Adaptive Dynamic Step-size Strategy (ADSS) to enhance generation accuracy and greatly optimize inference efficiency. Specifically, to tackle the problem of error accumulation, DiffTrajectory formalizes the denoising process as an ODE-solving problem and adopts the RK4 as a numerical solution. By computing multiple intermediate points at each iteration, this approach significantly reduces error accumulation. To improve the efficiency of the denoising process, DiffTrajectory introduces LIM, which leverages a pre-trained initial model to quickly generate a high-quality starting point for denoising, thereby reducing the computational burden during the initial denoising stages. Furthermore, we design the ADSS that adjusts the step size dynamically based on the results of each denoising stage, ensuring the quality of the generated results while substantially shortening inference time. Extensive experiments on the ETH/UCY and NBA datasets demonstrate that DiffTrajectory achieves substantial improvements in both accuracy and efficiency.},
  archive      = {J_PR},
  author       = {Chengcheng Li and Luqi Gong and Leiheng Xu and Xin Wang},
  doi          = {10.1016/j.patcog.2025.112339},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112339},
  shortjournal = {Pattern Recognition},
  title        = {DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A mondrian conformal predictive system with improved decision trees for uncertainty quantification under heteroscedasticity. <em>PR</em>, <em>172</em>, 112338. (<a href='https://doi.org/10.1016/j.patcog.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing application of machine learning in industrial production, model uncertainty quantification has become a critical tool to evaluate the prediction reliability and guide decision-making. The Conformal Predictive System (CPS), which generates Cumulative Distribution Functions (CDFs), provides valuable support for uncertainty quantification. However, CPS faces limitations when addressing heteroskedasticity. This paper proposes a Mondrian Conformal Predictive System (LWT-MCPS) based on an enhanced Decision Tree. The proposed approach constructs decision trees using splitting criteria derived from Levene’s test and Welch’s t -test, ensuring that the variance and mean within each partition remain as homogeneous as possible. Furthermore, it incorporates predicted values and prediction variances estimated using the k -Nearest Neighbors (KNN) as splitting features, effectively mitigating the impact of high-dimensional data on tree partitioning and enhancing the model’s ability to identify heterogeneous regions. Experiments conducted on simulated data, public datasets, and blast furnace ironmaking data demonstrate that LWT-MCPS generates CDFs with lower Continuous Ranked Probability Scores (CRPS) than traditional CPS. These results validate its significant advantages in addressing heteroskedasticity challenges.},
  archive      = {J_PR},
  author       = {Ruiyao Zhang and Ping Zhou},
  doi          = {10.1016/j.patcog.2025.112338},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112338},
  shortjournal = {Pattern Recognition},
  title        = {A mondrian conformal predictive system with improved decision trees for uncertainty quantification under heteroscedasticity},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial multi-semantic features guided spectral-friendly transformer network for hyperspectral image classification. <em>PR</em>, <em>172</em>, 112337. (<a href='https://doi.org/10.1016/j.patcog.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification (HSIC) is a foundational topic in remote sensing. However, the high correlations between bands and the spectral correlations often result in redundant data. Moreover, traditional convolutional neural networks (CNNs) compress spatial dimensions through pooling layers or strides during spatial information extraction, resulting in the loss of spatial information. To overcome these challenges, we propose a spatial multi-semantic features guided spectral-friendly Transformer network (SFTN), which effectively extracts the spectral and spatial features of HSIs. Specifically, a multi-semantic spatial attention (MsSA) module applies unidirectional spatial compression along the height and width dimensions. Thus, this module maintains spatial structure in one direction while aggregating global spatial information, thereby minimizing information loss during compression. It then employs multi-scale depth-shared 1D convolutions to capture multi-semantic spatial information. Furthermore, the spectral-friendly Transformer replaces the traditional multi-head self-attention (MHSA) with spectral correlation self-attention (ECSa), which effectively captures spectral differences and thus reduces the redundancy of spectral information. Extensive experiments on several HSI datasets show that the proposed SFTN method outperforms other state-of-the-art methods in HSIC applications. The source code for this work will be released later.},
  archive      = {J_PR},
  author       = {Xiaoyan Yu and Mingzhu Tai and Yuyang Wang and Zhenqiu Shu and Liehuang Zhu},
  doi          = {10.1016/j.patcog.2025.112337},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112337},
  shortjournal = {Pattern Recognition},
  title        = {Spatial multi-semantic features guided spectral-friendly transformer network for hyperspectral image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation. <em>PR</em>, <em>172</em>, 112336. (<a href='https://doi.org/10.1016/j.patcog.2025.112336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have become indispensable across various fields; however, their susceptibility to backdoor attacks poses significant security risks. In this paper, we propose a backdoor defense scheme based on adversarial prediction proximity and contrastive knowledge distillation. This scheme not only detects poisoned models and labels but also effectively unlearns backdoors while preserving the model’s benign functionality. Based on the observation that untargeted adversarial examples and poisoned samples exhibit proximity in feature space within poisoned models (i.e., adversarial prediction proximity), we first detect backdoors by analyzing changes in the prediction behavior of untargeted adversarial examples for models before and after fine-tuning. Next, we purify the poisoned model using a triplet loss that incorporates clean samples and untargeted adversarial examples. This process is guided by contrastive knowledge distillation, where a fine-tuned model acts as a “benign teacher”, and a backdoor-retained model serves as a “malicious teacher”, encouraging the poisoned model to align its feature representations with clean behavior. Comprehensive experimental results demonstrate that our scheme achieves high accuracy in detecting poisoned models and labels, even with limited access to clean samples. Furthermore, our scheme provides effective backdoor purification, while preserving the integrity and performance of models.},
  archive      = {J_PR},
  author       = {Lin Huang and Leo Yu Zhang and Ching-Chun Chang and Wei Wang and Chuan Qin},
  doi          = {10.1016/j.patcog.2025.112336},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112336},
  shortjournal = {Pattern Recognition},
  title        = {Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hyperspectral space transformations for texture classification. <em>PR</em>, <em>172</em>, 112335. (<a href='https://doi.org/10.1016/j.patcog.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D color space transformations are widely used in color imaging to enhance the results of various tasks, including image segmentation, object recognition, and texture classification. However, such useful transformations are much more limited in hyperspectral imaging, where images contain hundreds to thousands of spectral bands. To improve the performance of hyperspectral image analysis, we introduce four new hyperspectral space transformations in this paper: the Hyper-Chrominance-Luminance (H-CL), the Hyper-Hue-Chroma-Luminance (H-HCL), the Hyper-Hue-Saturation-Intensity (H-HSI), and the Hyper-Hue-Saturation-Value (H-HSV). These transformations extend the corresponding CL, HCL, HSI, and HSV 3D color spaces to multiple dimensions. To investigate their suitability in the context of texture classification, several well-known texture descriptors, including both theory-driven (handcrafted) and data-driven (deep learning) methods, are used in the experiments. Ten hyperspectral datasets are considered: HyTexila, SpecTex, HyperPlastic, and seven datasets extracted from the Timbers database. Among these datasets, six new ones are introduced in this paper. The proposed H-CL, H-HCL, H-HSI, and H-HSV transformations are also compared with state-of-the-art transformation strategies. The experiments conducted in this paper demonstrate the efficacy of the proposed space transformations with an accuracy improvement that can reach +43.47 %.},
  archive      = {J_PR},
  author       = {Alice Porebski and Souraya Ouaidar Hadir and Thierry Gensane and Nicolas Vandenbroucke},
  doi          = {10.1016/j.patcog.2025.112335},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112335},
  shortjournal = {Pattern Recognition},
  title        = {Hyperspectral space transformations for texture classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-target federated backdoor attack based on feature aggregation. <em>PR</em>, <em>172</em>, 112333. (<a href='https://doi.org/10.1016/j.patcog.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current federated backdoor attacks focus on collaboratively training backdoor triggers, where multiple compromised clients train their local trigger patches and then merge them into a global trigger during the inference phase. However, these methods require careful design of the shape and position of trigger patches and lack the feature interactions between trigger patches during training, resulting in poor backdoor attack success rates. Moreover, the pixels of the patches remain untruncated, thereby making abrupt areas in backdoor examples easily detectable by the detection algorithm. To this end, we propose a novel benchmark for the federated backdoor attack based on feature aggregation. Specifically, we align the dimensions of triggers with images, constrain the trigger’s pixel boundaries so that it is within a small range to avoid being detected, and aggregate trigger features from multiple compromised clients to enhance the global trigger’s ability to capture distributed data patterns. Furthermore, leveraging the intra-class attack strategy to train specific triggers for each class of samples, we propose the simultaneous generation of backdoor triggers for all target classes, significantly reducing the overall production time for triggers across all target classes and increasing the risk of the federated model being attacked. Experiments demonstrate that our method can not only bypass the detection of defense methods while patch-based methods fail, but also achieve a zero-shot backdoor attack with a success rate of 77.39 %. To the best of our knowledge, our work is the first to implement such a zero-shot attack in federated learning. Finally, we evaluate attack performance by varying the trigger’s training factors, including poison location, ratio, pixel bound, and trigger training duration (local epochs and communication rounds).},
  archive      = {J_PR},
  author       = {Lingguag Hao and Kuangrong Hao and Bing Wei and Xue-Song Tang},
  doi          = {10.1016/j.patcog.2025.112333},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112333},
  shortjournal = {Pattern Recognition},
  title        = {Multi-target federated backdoor attack based on feature aggregation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LayerMix: Enhanced data augmentation for robust deep learning. <em>PR</em>, <em>172</em>, 112332. (<a href='https://doi.org/10.1016/j.patcog.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) models have demonstrated remarkable performance across various computer vision tasks, yet their vulnerability to distribution shifts remains a critical challenge. Despite sophisticated neural network architectures, existing models often struggle to maintain consistent performance when confronted with Out-of-Distribution (OOD) samples, including natural corruptions, adversarial perturbations, and anomalous patterns. We introduce LayerMix, an innovative Data Augmentation (DA) approach that systematically enhances model robustness through structured fractal-based image synthesis. By meticulously integrating structural complexity into training datasets, our method generates semantically consistent synthetic samples that significantly improve neural network generalization capabilities. Unlike traditional augmentation techniques that rely on random transformations, LayerMix employs a structured mixing pipeline that preserves original image semantics while introducing controlled variability. Extensive experiments across multiple benchmark datasets, including CIFAR-10, CIFAR-100, ImageNet-200, and ImageNet-1K demonstrate LayerMix’s superior performance in classification accuracy and substantially enhances critical Machine Learning (ML) safety metrics, including resilience to natural image corruptions, robustness against adversarial attacks, improved model calibration and enhanced prediction consistency. LayerMix represents a significant advancement toward developing more reliable and adaptable artificial intelligence systems by addressing the fundamental challenges of DL generalization. The code is available at https://github.com/ahmadmughees/layermix .},
  archive      = {J_PR},
  author       = {Hafiz Mughees Ahmad and Dario Morle and Afshin Rahimi},
  doi          = {10.1016/j.patcog.2025.112332},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112332},
  shortjournal = {Pattern Recognition},
  title        = {LayerMix: Enhanced data augmentation for robust deep learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A query-driven twin network framework with optimization-based meta-learning for few-shot hyperspectral image classification. <em>PR</em>, <em>172</em>, 112331. (<a href='https://doi.org/10.1016/j.patcog.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved remarkable results in hyperspectral image (HSI) classification due to its powerful deep feature extraction and nonlinear relationship processing capabilities. However, the success of deep learning methods is largely dependent on extensive labeled samples, which is both time-consuming and labor-intensive. To address this issue, a novel query-driven meta-learning twin network (QMTN) framework is proposed for HSI few-shot learning. QMTN uses two meta-learning channels, allowing for the comprehensive learning of meta-knowledge across diverse meta-tasks and enhancing learning efficiency. Within the QMTN framework, a lightweight spectral-spatial attention residual network is proposed for extraction of HSI features. The network incorporates a residual mechanism in both spectral and spatial feature extraction processes and includes an attention block to improve network performance by focusing on key locations in the spatial features. To maximize the use of the limited samples for constructing diverse meta-tasks, two meta-task generation approaches are employed, with and without simulated noise. Experiments on three public HSI datasets demonstrate that the QMTN framework effectively reduces the dependence on labeled samples in a single scene and significantly improves the classification performance and convergence of the internal network. The meta-task generation method with simulated noise can improve the classification performance of the QMTN.},
  archive      = {J_PR},
  author       = {Jian Zhu and Pengxin Wang and Jian Hui and Xin Ye},
  doi          = {10.1016/j.patcog.2025.112331},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112331},
  shortjournal = {Pattern Recognition},
  title        = {A query-driven twin network framework with optimization-based meta-learning for few-shot hyperspectral image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reliable classification through rank-based conformal prediction sets. <em>PR</em>, <em>172</em>, 112330. (<a href='https://doi.org/10.1016/j.patcog.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning classification tasks often benefit from predicting a set of possible labels with confidence scores to capture uncertainty. However, existing methods struggle with the high-dimensional nature of the data and the lack of well-calibrated probabilities from modern classification models. We propose a novel conformal prediction method that utilizes a rank-based score function suitable for classification models that predict the order of labels correctly, even if not well-calibrated. Our approach constructs prediction sets that achieve the desired coverage rate while managing their size. We provide a theoretical analysis of the expected size of the conformal prediction sets based on the rank distribution of the underlying classifier. Through extensive experiments, we demonstrate that our method outperforms existing techniques on various datasets, providing reliable uncertainty quantification. Our contributions include a novel conformal prediction method, theoretical analysis, and empirical evaluation. This work advances the practical deployment of machine learning systems by enabling reliable uncertainty quantification.},
  archive      = {J_PR},
  author       = {Rui Luo and Zhixin Zhou},
  doi          = {10.1016/j.patcog.2025.112330},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112330},
  shortjournal = {Pattern Recognition},
  title        = {Reliable classification through rank-based conformal prediction sets},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised domain adaptation for cardiac MRI segmentation via adversarial learning in latent space. <em>PR</em>, <em>172</em>, 112328. (<a href='https://doi.org/10.1016/j.patcog.2025.112328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) imaging is crucial for visualizing myocardial infarction (MI), with accurate segmentation of the ventricles and myocardium being essential for effective MI treatment. However, due to the complex myocardial structure and the limited availability of pixel-level annotations in LGE CMR images, accurate segmentation using supervised deep learning methods remains challenging. To address this, we propose an unsupervised domain adaptation framework for LGE CMR segmentation, utilizing CMR images from other modalities. First, we transform balanced Steady-State Free Precession (bSSFP) CMR images, which have abundant annotations, into LGE-like images using an enhanced CycleGAN. This CycleGAN incorporates an adversarial sample mining technique in the latent space to improve the quality of synthetic images. Next, we modify the nnU-Net architecture by introducing non-local blocks to train on these synthetic images, enabling precise segmentation of the myocardium and ventricular regions. We evaluate our method on the MS-CMRSeg 2019 dataset and MyoPS 2020 dataset, achieving an average Dice score of 88.0 % and 82.6 % respectively. Our experimental results demonstrate superior performance compared to state-of-the-art methods. The code for our approach is available at https://github.com/Lucarqi/Adv-CycleGAN .},
  archive      = {J_PR},
  author       = {Fan Zheng and Hengfei Cui and Yanning Zhang and Yong Xia},
  doi          = {10.1016/j.patcog.2025.112328},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112328},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised domain adaptation for cardiac MRI segmentation via adversarial learning in latent space},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficacy of varying sensing features for enhanced performance of deep-learning-informed multidimensional force platform. <em>PR</em>, <em>172</em>, 112327. (<a href='https://doi.org/10.1016/j.patcog.2025.112327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL)-informed vision-based 3D force platforms have demonstrated significant potential for simultaneous assessment of pressure and shear stresses. However, the enhancement of force decoupling capacity is widely recognized as a difficult challenge in the field. For vision-based designs, the marker-embedded sensing layer serves as the pivotal element of the force platform, unveiling diverse sensing characteristics throughout the learning process. However, none of the previous studies have thoroughly investigated the differences among these sensing features and leveraged them to optimize DL models for enhanced performance in multidimensional force detection. This study addresses this gap by systematically evaluating five distinct features (including optical flow, original images, and their derivatives) using four classic CNN architectures. Our comparative analysis reveals a clear feature-force specialization: gray images are most effective for pressure decoupling, while arrow images are superior in decoupling shear stress. Based on this finding, we proposed and validated a dual-branch DL model that fuses these two specialized features. The model achieves a strong, comprehensive performance on both tasks simultaneously, demonstrating the efficacy of our evidence-based feature-fusion strategy. This study provides new insights into sensing feature selection and evidence-based neural network design for vision-based multidimensional force platforms. These advancements have the potential to expedite the deployment of high-performance multidimensional force platforms in real-life applications.},
  archive      = {J_PR},
  author       = {Hu Luo and Yuxin Ma and Zesheng Wang and Jiewen Li and Xin Ma and Wen-Ming Chen},
  doi          = {10.1016/j.patcog.2025.112327},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112327},
  shortjournal = {Pattern Recognition},
  title        = {Efficacy of varying sensing features for enhanced performance of deep-learning-informed multidimensional force platform},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TP-LReID: Lifelong person re-identification using text prompts. <em>PR</em>, <em>172</em>, 112326. (<a href='https://doi.org/10.1016/j.patcog.2025.112326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong person re-identification (LReID) aims to develop a single model that is capable of continuously learning from new domain (present) while retaining knowledge from previously encountered ones (past) and generalizing to unseen domains (future). However, distribution shifts across these domains pose a significant challenge in maintaining performance across past, present, and future domains, that is, causing the catastrophic forgetting on previously seen domains and limited generalization to unseen ones. To address the above issues, we propose to guide consistent feature extraction to bridge distribution shifts using text prompts designed to remain invariant across domains. First, identity-consistent text prompts capturing high-level image semantics are extracted and aligned with image features throughout the lifelong learning pipeline. Moreover, to enhance generalization to unseen domains, we introduce an adversarial training that text features are contrastively aligned with both original and future-style image features, the latter generated by applying gradient-based perturbations in the feature space. Compared with 21 representative models on 11 benchmark datasets, our proposed model, trained without access to historical data, achieves performance comparable to the model trained using a joint training approach, and it performs well on all of the past, present, and future domains. We further explored the forgetting of the first historical domain and the generalization to all unseen domains under all 24 orders, and the results confirmed the superiority of our model. Codes will be released if this paper is accepted.},
  archive      = {J_PR},
  author       = {Zhaoshuo Liu and Zhiwei Guo and Chaolu Feng and Wei Li and Kun Yu and Jun Hu and Jinzhu Yang},
  doi          = {10.1016/j.patcog.2025.112326},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112326},
  shortjournal = {Pattern Recognition},
  title        = {TP-LReID: Lifelong person re-identification using text prompts},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Zoom-shot: Fast, efficient and unsupervised zero-shot knowledge transfer from CLIP to vision encoders. <em>PR</em>, <em>172</em>, 112323. (<a href='https://doi.org/10.1016/j.patcog.2025.112323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models like CLIP demonstrate exceptional capabilities over a broad domain of knowledge, such as with zero-shot classification; however, they also require significant computational resources, narrowing their real-world utility. Recent studies have shown that mapping features from pre-trained vision encoders into CLIP’s latent space can transfer some of CLIP’s abilities to smaller vision encoders, offering a promising alternative. Yet, the performance of these vision encoders still falls short of CLIP’s native capabilities, particularly in low-data regimes. In this work, we argue that enhancing training data coverage/diversity significantly improves mapping efficacy. We achieve this using tailored loss functions rather than relying on data augmentation or increasing training samples. For instance, we exploit the inherent multimodal nature of CLIP’s latent space, by incorporating cycle-consistency loss as one of our loss functions. Moreover, the mapping is learned using entirely unlabelled and unpaired data, eliminating the need for manual labelling or data pairing in novel domains. From these findings, our resulting method (Zoom-shot) offers a viable path to flexible zero-shot models for resource-limited, data-scarce settings. We test Zoom-shot’s zero-shot performance across various pre-trained vision encoders on coarse- and fine-grained datasets and achieve superior performance compared to recent works. In our ablations, we find Zoom-shot allows for a trade-off between data and compute during training; allowing for a significant reduction in required training data. All code and models are available on GitHub.},
  archive      = {J_PR},
  author       = {Jordan Shipard and Arnold Wiliem and Kien Nguyen Thanh and Wei Xiang and Clinton Fookes},
  doi          = {10.1016/j.patcog.2025.112323},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112323},
  shortjournal = {Pattern Recognition},
  title        = {Zoom-shot: Fast, efficient and unsupervised zero-shot knowledge transfer from CLIP to vision encoders},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging. <em>PR</em>, <em>172</em>, 112322. (<a href='https://doi.org/10.1016/j.patcog.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-pixel imaging provides significant advantages for non-visible wavelength detection and ultra-compressed sensing. However, accurate reconstruction from severely under-sampled measurements remains challenging. To tackle this, we propose a novel wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging (WGDNet), which hierarchically reconstructs images through wavelet component-aware reinforcement. Specifically, we design a sampling-guided model to capture essential textures and produce an initial image decomposed into high- and low-frequency components. The low-frequency part is enhanced with adaptive diffusion to preserve structure, while the high-frequency part is directionally incorporated through a multi-frequency adaptive fusion attention (MAFA) mechanism to refine details. Building on this, we develop a residual spatial adaptive fusion (RSAF) module to effectively combine low-frequency structures and high-frequency details. Extensive experiments on five public datasets demonstrate that our method achieves superior performance in both structural preservation and detail recovery. Successful implementation in the imaging system validates the applicability in real scenarios.},
  archive      = {J_PR},
  author       = {Dawei Song and Qiurong Yan and Hui Wang and Jian Yang and Xiaolong Luo},
  doi          = {10.1016/j.patcog.2025.112322},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112322},
  shortjournal = {Pattern Recognition},
  title        = {Wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical community-based graph generation model for improving structural diversity. <em>PR</em>, <em>172</em>, 112320. (<a href='https://doi.org/10.1016/j.patcog.2025.112320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generation remains a challenging task due to the high dimensionality of graphs and the complex dependencies among their edges. Existing models often struggle to produce structurally diverse graphs. To address this limitation, we propose a novel generative framework specifically designed to capture structural diversity in graph generation. Our approach follows a sequential process: initially, a community detection algorithm partitions the input graph into distinct communities. Each community is then generated independently using deep generative models, while a dedicated module concurrently learns the interconnections between communities. To scale to graphs with a larger number of communities, we extend our approach into a hierarchical generative model. The proposed framework not only improves generation accuracy but also significantly reduces generation time for large-scale graphs. Moreover, it enables the application of prior methods that were previously incapable of handling such graphs. To highlight the shortcomings of existing approaches, we conduct experiments on a synthetic dataset comprising diverse graph structures. The results demonstrate substantial improvements in standard evaluation metrics as well as in the quality of the generated graphs.},
  archive      = {J_PR},
  author       = {Masoomeh Sadat Razavi and Abdolreza Mirzaei and Mehran Safayani},
  doi          = {10.1016/j.patcog.2025.112320},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112320},
  shortjournal = {Pattern Recognition},
  title        = {Hierarchical community-based graph generation model for improving structural diversity},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GLGF-CR: A gated local-global fusion approach for cloud removal in real-world remote sensing. <em>PR</em>, <em>172</em>, 112319. (<a href='https://doi.org/10.1016/j.patcog.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical satellite imagery is a critical data source for Earth observation in remote sensing. However, cloud cover often degrades image quality, hindering its application and analysis. Therefore, effective cloud removal from optical satellite images has become a prominent research direction. In real-world scenarios, thick clouds act as pure noise, completely obscuring underlying information, while thin clouds provide partially beneficial information that can be leveraged for reconstruction. Traditional cloud removal methods often fail to distinguish between these two types of noise, leading to suboptimal performance. To address this limitation, we propose a novel cloud removal model, GLGF-CR, which incorporates a Gated Local-Global Fusion module. This module is designed to effectively separate and process the distinct characteristics of thick and thin clouds. For thick clouds, which contain no recoverable information, the model focuses on robust reconstruction using complementary data sources. For thin clouds, the model extracts and utilizes the beneficial information embedded in the partially obscured regions, enabling more accurate and detailed reconstruction. Additionally, a Dual Cross-Attention mechanism is introduced to establish robust mappings between SAR and optical modalities, further improving fusion accuracy. To handle domain shifts between source and target domains, we incorporate a domain adaptation module, which enhances the model’s ability to generalize across diverse real-world scenarios. The proposed algorithm not only outperforms existing methods on the large-scale real-world dataset SEN12MS-CR but also demonstrates strong cross-domain transferability on the Henan flood dataset. By explicitly addressing the dual nature of cloud noise–pure noise in thick clouds and partially beneficial information in thin clouds–this work advances the field of beneficial noise learning, demonstrating how noise can be systematically analyzed and utilized to improve model performance in complex scenarios.},
  archive      = {J_PR},
  author       = {Ganchao Liu and Jiawei Qiu and Jincheng Huang and Yuan Yuan},
  doi          = {10.1016/j.patcog.2025.112319},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112319},
  shortjournal = {Pattern Recognition},
  title        = {GLGF-CR: A gated local-global fusion approach for cloud removal in real-world remote sensing},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised feature selection with concept factorization and robust label learning. <em>PR</em>, <em>172</em>, 112317. (<a href='https://doi.org/10.1016/j.patcog.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is essential for improving model performance in high-dimensional data by identifying the most relevant features. Concept Factorization (CF), building on Non-negative Matrix Factorization (NMF), is valued for revealing meaningful data structure and producing interpretable concept vectors. However, existing CF-based FS methods are typically unsupervised and do not leverage label information, leading to a bias toward high-variance features. This bias can result in the omission of low-variance features that may be highly discriminative, ultimately reducing the effectiveness of FS and compromising model performance, especially in tasks where subtle or rare patterns are important. To address these limitations, this paper proposes SCFLR, a novel semi-supervised FS method that combines CF with robust label learning. SCFLR establishes the CF framework based on the feature space by expressing each concept vector as a conic combination of the feature vectors, thereby leveraging both the underlying data structure and available label information to select a more informative and balanced set of features. To this end, SCFLR defines a linear regression-based loss function derived from the generated concept vectors to leverage information from labeled data. This loss function is further enhanced through a label learning framework based on the L 2 , 1 -norm to ensure a robust label approximation. SCFLR also utilizes the dual-graph regularization to maintain the local geometric structures in both feature and data spaces. In order to tackle the optimization problem of SCFLR, an efficient algorithm, with proof of its convergence, is introduced. Finally, the experimental validation of the SCFLR method on multiple datasets highlights its effectiveness and superior performance compared to other FS methods.},
  archive      = {J_PR},
  author       = {Razieh Sheikhpour and Farid Saberi-Movahed and Mahdi Jalili and Kamal Berahmand},
  doi          = {10.1016/j.patcog.2025.112317},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112317},
  shortjournal = {Pattern Recognition},
  title        = {Semi-supervised feature selection with concept factorization and robust label learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning for DBT classification with saliency-guided 2D synthesis. <em>PR</em>, <em>172</em>, 112316. (<a href='https://doi.org/10.1016/j.patcog.2025.112316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Breast Tomosynthesis (DBT) is a key imaging modality for breast cancer detection, improving lesion visibility by reducing tissue overlap inherent in conventional mammography. In this work, we propose a novel deep learning framework that classifies DBT volumes as malignant or non-malignant, while simultaneously generating a synthetic 2D image to assist diagnostic interpretation. This image is derived from a 3D saliency map computed by the internal attention mechanisms of the model, which highlights and preserves the most diagnostically relevant regions from the original volume. A surface is defined in this saliency space, enabling sampling and projection into a 2D diagnostic representation. This projection offers a compact summary of the volumetric scan, assisting clinicians in diagnostic interpretation and potentially alleviating the cognitive workload. A standard convolutional neural network trained on these synthetic 2D images achieves classification performance comparable to models operating directly on full 3D volumes. We train and evaluate our method on the OPTIMAM dataset and assess generalization through external validation on the independent BCS-DBT dataset without retraining. Results show that the model performs robustly across different clinical sources and provides an interpretable, computationally efficient tool for DBT-based breast cancer diagnosis.},
  archive      = {J_PR},
  author       = {Marco Cantone and Ciro Russo and Federico~V.~L. Dell’Ascenza and Claudio Marrocco and Alessandro Bria},
  doi          = {10.1016/j.patcog.2025.112316},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112316},
  shortjournal = {Pattern Recognition},
  title        = {Deep learning for DBT classification with saliency-guided 2D synthesis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-tolerant scheme and explicit regularizer for deep active learning with noisy oracles. <em>PR</em>, <em>172</em>, 112313. (<a href='https://doi.org/10.1016/j.patcog.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring the query strategies based on deep learning shows promising results in terms of designing the criteria for active learning. However, the labels provided by the oracles might be noisy (inaccurate) due to similarities across several classes causing ambiguity, leading to unreliable results. To address this issue, we propose a noise-tolerant deep active learning method. Specifically, we design a consistency regularization for deep attention network as explicit regularizer, which is used to measure the uncertainty of examples. Besides, we develop the robust model for dealing with the noisy oracles , which first take the associations that make from embeddings of labeled data to those of unlabeled data and back, then we employ the association probability as a weighting fusion schema into angular margin based loss. Moreover, we design the submodular maximization function for reducing the redundancy of selected batch examples. Finally, the formulation is encapsulated into the multi-task framework that helps to adaptive learning towards more generalizable performance. Experimentally, we conduct extensive experiments on classification and segmentation tasks, and the results clearly demonstrate the superiority of the proposed method to the existing state-of-the-art deep active learning approaches.},
  archive      = {J_PR},
  author       = {Yanchao Li and Ziteng Xie and Hongwu Zhong and Guangwei Gao},
  doi          = {10.1016/j.patcog.2025.112313},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112313},
  shortjournal = {Pattern Recognition},
  title        = {Noise-tolerant scheme and explicit regularizer for deep active learning with noisy oracles},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Linguistic query-guided mask generation for referring image segmentation. <em>PR</em>, <em>172</em>, 112306. (<a href='https://doi.org/10.1016/j.patcog.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation aims to segment the image region of interest according to the given language expression, which is a typical multi-modal task. Existing methods either adopt the pixel classification-based or the learnable query-based framework for mask generation, both of which are insufficient to deal with various text-image pairs with a fix number of parametric prototypes. The motivation of this work is to propose an end-to-end framework built on transformer to perform Linguistic query-Guided mask generation, dubbed LGFormer. It views the linguistic features as query to generate a specialized prototype for arbitrary input image-text pair, thus generating more consistent segmentation results. Moreover, we design several cross-modal interaction modules (e.g. vision-language bidirectional attention module, VLBA) in both encoder and decoder to achieve better cross-modal alignment. Extensive experiments demonstrate that our LGFormer achieves a new state-of-the-art performance on ReferIt, RefCOCO+, and RefCOCOg by large margins. Code is available at https://github.com/mqchen1993/LGFormer .},
  archive      = {J_PR},
  author       = {Zhichao Wei and Xiaohao Chen and Mingqiang Chen and Hao Li and Zilong Dong and Siyu Zhu},
  doi          = {10.1016/j.patcog.2025.112306},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112306},
  shortjournal = {Pattern Recognition},
  title        = {Linguistic query-guided mask generation for referring image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TransSTC: Transformer tracker meets efficient spatial-temporal cues. <em>PR</em>, <em>172</em>, 112303. (<a href='https://doi.org/10.1016/j.patcog.2025.112303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, researchers have started developing trackers using the powerful global modeling capabilities of transformer networks. However, existing transformer trackers usually model all template spatial cues indiscriminately and ignore temporal cues of target state changes. This distracts the tracker’s attention and gradually fails to understand the target’s latest state. Therefore, we propose a new tracker called TransSTC, which explores the effective spatial cues in the template and temporal cues during tracking to improve the tracker’s performance. Specifically, we design the target-aware focused coding network to emphasize the efficient spatial cues in the templates, alleviating the impact of spatial cues with low associations of targets in templates on the tracker’s localization accuracy. Additionally, we employ the multi-temporal template update structure that accurately captures variations in the target’s appearance. Within this structure, the collected samples are assessed for target appearance similarity and environmental interference, followed by a three-level sample selection process to ensure the accurate template update. Finally, we introduce the motion constraint framework to dynamically adjust the classification results based on the target’s historical motion trajectory. Extensive experimental results on seven tracking benchmarks demonstrate that TransSTC achieves competitive tracking performance.},
  archive      = {J_PR},
  author       = {Hong Zhang and Wanli Xing and Yifan Yang and Hanyang Liu and Ding Yuan},
  doi          = {10.1016/j.patcog.2025.112303},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112303},
  shortjournal = {Pattern Recognition},
  title        = {TransSTC: Transformer tracker meets efficient spatial-temporal cues},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MGFNet: Multi-granularity medical pattern fusion network for patient risk prediction. <em>PR</em>, <em>172</em>, 112302. (<a href='https://doi.org/10.1016/j.patcog.2025.112302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of patient risk prediction tasks is to predict a patient’s future disease or mortality risk based on his/her historical electronic health record (EHR). Most prior works focus on learning patient evolution patterns from longitudinal EHR data, while ignoring the differences in temporal granularity in medical data, resulting in insufficient information exploitation. To address these limitations, we propose the M ulti- G ranularity Medical Pattern F usion Net work (MGFNet) for patient risk prediction based on temporal data. It learns the evolutionary patterns of medical data at different temporal granularities (both at the vital sign-level and visit-level), and introduces a gated filtering function and a contrastive learning strategy for multi-granularity fusion, which captures fused information from different temporal granularities and supervises each other to obtain a more effective information representation. In addition, for patients with variable visit lengths, we introduce a soft curriculum learning method to learn these patterns by assigning different weights to medical samples to improve prediction accuracy. The final experimental results demonstrate that MGFNet effectively improves the performance of risk prediction compared with state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Lin Cheng and Yuliang Shi and Xiaojing Yu and Xinyu Li and Xinjun Wang and Zhongmin Yan and Zhiyong Chen},
  doi          = {10.1016/j.patcog.2025.112302},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112302},
  shortjournal = {Pattern Recognition},
  title        = {MGFNet: Multi-granularity medical pattern fusion network for patient risk prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning multi-scale spatial-frequency features for image denoising. <em>PR</em>, <em>172</em>, 112300. (<a href='https://doi.org/10.1016/j.patcog.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.},
  archive      = {J_PR},
  author       = {Xu Zhao and Chen Zhao and Xiantao Hu and Hongliang Zhang and Ying Tai and Jian Yang},
  doi          = {10.1016/j.patcog.2025.112300},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112300},
  shortjournal = {Pattern Recognition},
  title        = {Learning multi-scale spatial-frequency features for image denoising},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep intrinsic image decomposition via physics-aware neural networks. <em>PR</em>, <em>172</em>, 112299. (<a href='https://doi.org/10.1016/j.patcog.2025.112299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrinsic image decomposition (IID) aims to separate an observed image into its underlying reflectance and shading components. This task is challenging due to the complex interplay of lighting, surface geometry, and material reflectance in real-world scenes. To address these challenges, this paper proposes a physics-aware deep neural network with a single-encoder, double-decoder architecture. The encoder incorporates an explicit alternating process inspired by a physics-guided model, enabling iterative decoupling of image features into reflectance and shading. Two asymmetric decoders are designed to reconstruct reflectance and shading maps based on their distinct properties. In addition, we introduce a shading loss function leverages spatial distributions of texture and structure. Unlike standard total variation (TV) losses, it employs a texture-likelihood-weighted TV norm, where weights are derived via a patch-matching scheme to distinguish isotropic textures from anisotropic image edges. This design enhances the model’s ability to suppress texture while preserving structure. Experimental results on three datasets (MIT, MPI-Sintel, and IIW) show the effectiveness of our method: on MIT and MPI-Sintel, it reduces the mean-squared-errors of both reflectance and shading by over 40 % compared to existing works, and on IIW, it achieves a superior WHDR score of 13.2, outperforming all existing methods.},
  archive      = {J_PR},
  author       = {Yan Huang and Kangjie Liu and Tengyue Chen and Yong Xu and Hui Ji},
  doi          = {10.1016/j.patcog.2025.112299},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112299},
  shortjournal = {Pattern Recognition},
  title        = {Deep intrinsic image decomposition via physics-aware neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Domain adapter for visual object tracking based on hyperspectral video. <em>PR</em>, <em>172</em>, 112296. (<a href='https://doi.org/10.1016/j.patcog.2025.112296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking based on hyperspectral video attracts increasing attention due to the rich material and motion information in the hyperspectral videos. The prevailing hyperspectral methods adapt pretrained RGB-based object tracking networks for hyperspectral tasks by converting the hyperspectral images into false-color images and fine-tuning the whole network on hyperspectral datasets, which achieves impressive results in challenging scenarios. However, the performance of hyperspectral trackers is limited by the spectral information loss during the transformation, and fine-tuning the entire pretrained network is inefficient for practical applications. To address the issues, a new hyperspectral object tracking method based on domain adaption, hyperspectral adapter for tracking (HyA-T), is proposed in this work. The hyperspectral adapter for the self-attention (HAS) and the hyperspectral adapter for the multilayer perceptron (HAM) are proposed to generate the adaption information and to transfer the multi-head self-attention (MSA) module and the multilayer perceptron (MLP) in pretrained network for the hyperspectral object tracking task by augmenting the spectral information in the original hyperspectral images into the calculation of the MSA and MLP. Additionally, the hyperspectral enhancement of input (HEI) is proposed to augment the original spectral information into the input of the tracking network. The proposed methods extract spectral information directly from the hyperspectral images, which reduce the negative impact of the spectral information loss caused by the transformation. Moreover, only the parameters in the proposed methods are fine-tuned, which is more efficient than the existing methods. Extensive experiments were conducted on four datasets with various spectral bands, verifying the effectiveness of the proposed methods. The HyA-T achieves state-of-the-art performance on all the datasets.},
  archive      = {J_PR},
  author       = {Long Gao and Yunhe Zhang and Langkun Chen and Yan Jiang and Gang He and Weiying Xie and Yunsong Li},
  doi          = {10.1016/j.patcog.2025.112296},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112296},
  shortjournal = {Pattern Recognition},
  title        = {Domain adapter for visual object tracking based on hyperspectral video},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Few-shot image generation via information transfer from the built geodesic surface. <em>PR</em>, <em>172</em>, 112293. (<a href='https://doi.org/10.1016/j.patcog.2025.112293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models trained with limited data often struggle with poor fidelity and diversity. While adapting large pre-trained models is a common solution, such an approach requires significant resources and suitable source domains, which are often unavailable. To address these limitations, we propose Information Transfer from the Built Geodesic Surface (ITBGS), a framework that generates high-quality images from scratch. The core of ITBGS is our Feature Augmentation on Geodesic Surface (FAGS) module, which constructs a Geodesic surface to create a diverse pseudo-source domain from the initial samples. By transferring structural information from the augmented domain to guide the generator’s training, our method completely removes the need for pre-trained models. To refine the output, a supporting Interpolation and Regularization (I&R) module is also introduced to enhance the smoothness and perceptual quality of generated images. Extensive experiments demonstrate that ITBGS achieves state-of-the-art or comparable performance on various few-shot datasets, successfully balancing image fidelity and diversity.},
  archive      = {J_PR},
  author       = {Yuexing Han and Liheng Ruan and Bing Wang},
  doi          = {10.1016/j.patcog.2025.112293},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112293},
  shortjournal = {Pattern Recognition},
  title        = {Few-shot image generation via information transfer from the built geodesic surface},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FADMB: Fully attention-based dual memory bank network for weakly supervised video anomaly detection. <em>PR</em>, <em>172</em>, 112288. (<a href='https://doi.org/10.1016/j.patcog.2025.112288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection is crucial for analyzing surveillance videos and plays a significant role in maintaining public safety. Recent advances in weakly supervised methods, utilizing video-level labels, have improved performance based on techniques like multi-instance learning and temporal modeling. Furthermore, memory banks demonstrate great potential in unsupervised anomaly detection, prompting their integration into weakly supervised setups. However, these methods depend on the Top- k selection mechanism to update the prototypes within memory banks, which has limitations such as overlooking valuable prototypes, leading to a biased updating process, and requiring hyperparameters. To tackle these challenges, we introduce a novel video anomaly detection model, FADMB ( F ully A ttention-based D ual M emory B ank network), which replaces the Top- k selection mechanism with an innovative attention-based prototype updating paradigm to obtain a more comprehensive and robust memory bank. Additionally, we design a Hybrid Encoder that encodes local and global temporal information to produce superior video representations. Extensive experiments demonstrate the superiority of FADMB, achieving 85.79 % AUC on UCF-Crime dataset and 83.29 % AP on XD-Violence dataset.},
  archive      = {J_PR},
  author       = {Zhiming Luo and Shuheng Huang and Kun Yang and Jianzhe Gao and Shaozi Li},
  doi          = {10.1016/j.patcog.2025.112288},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112288},
  shortjournal = {Pattern Recognition},
  title        = {FADMB: Fully attention-based dual memory bank network for weakly supervised video anomaly detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="ras">RAS - 12</h2>
<ul>
<li><details>
<summary>
(2026). Robust walking motion generation for biped robots using manipulability-based reinforcement learning. <em>RAS</em>, <em>195</em>, 105209. (<a href='https://doi.org/10.1016/j.robot.2025.105209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reinforcement learning, designing an effective reward function is essential for developing and controlling humanoid robots. The criteria for replicating human learning and achieving human-like responses in bipedal robots remain unclear. Integrating kinematic and dynamic characteristics into the reward function, along with the use of detailed models, can enhance efficiency and robustness. This study proposes a novel manipulability-based reward function within an end-to-end learning framework, enabling the agent to autonomously generate robust, real-time movements. Incorporating the kinematic manipulability index into the proposed reward function significantly improves the robot's locomotion behavior and ability to handle disturbances. Results indicate that incorporating kinematic manipulability into training enhances the robot's forward speed and improves its ability to handle sagittal and lateral disturbances, as well as uncertainties in length and weight distribution. Furthermore, compared to a classical hierarchical controller, the trained agent attained higher speeds and demonstrated superior disturbance handling, validating the effectiveness of the proposed learning-based approach. These findings highlight the significance of incorporating kinematic manipulability into the reward function to enhance the agility and adaptability of bipedal robots.},
  archive      = {J_RAS},
  author       = {Amin Tadayyoni and Behnam Miripour Fard and Ali Jamali},
  doi          = {10.1016/j.robot.2025.105209},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105209},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robust walking motion generation for biped robots using manipulability-based reinforcement learning},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asymmetric bounded fuzzy adaptive control for uncertain coordinative multiple robot manipulators. <em>RAS</em>, <em>195</em>, 105198. (<a href='https://doi.org/10.1016/j.robot.2025.105198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a fuzzy adaptive control technology for determining the desired trajectory of collaborative robot manipulators when grasping a general object. While the classical fuzzy logic systems (FLSs) are commonly used to compensate for some unknown nonlinear continuous functions, their approximation accuracies are often limited. To address this issue, a non-zero time-varying parameter is introduced in the input of Mamdani type or Takagi–Sugeno (T–S) type FLSs. This parameter allows for universal approximation, enabling the system to automatically adjust the approximation precision through adaptive rules. The unknown nonlinear continuous functions are represented using a combined form of homogeneous functions, which are then approximated using FLSs. Unlike previous fuzzy adaptive control schemes, this approach overcomes the limitation of a finite universal approximation domain. Additionally, the proposed method can calculate the coefficients of consequents in T–S type FLSs, reducing the computational load of the controller. The effectiveness of the proposed sliding mode surface is demonstrated in ensuring the required tracking performance, with all signals in the closed-loop system being uniformly ultimately bounded (UUB). The efficiency of the control scheme is further demonstrated through various simulation results.},
  archive      = {J_RAS},
  author       = {Yongqing Fan and Lin Yang and Zhen Li},
  doi          = {10.1016/j.robot.2025.105198},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105198},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Asymmetric bounded fuzzy adaptive control for uncertain coordinative multiple robot manipulators},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrative AI framework for robotics: LLM-enabled reinforcement learning in object manipulation and task planning. <em>RAS</em>, <em>195</em>, 105197. (<a href='https://doi.org/10.1016/j.robot.2025.105197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper develops an innovative hybrid AI framework that combines contextual reasoning of a large language model (LLM) with adaptivity of reinforcement learning (RL) for improved robotic object manipulation and task execution. In particular, the proposed system integrates high-level task planning, where GPT-4 and an RL submodule collaboratively generate optimized task strategies, with low-level real-time control through RL, allowing for enhanced adaptability in dynamic environments. The experimental results demonstrate significant improvements in task success rates and operational efficiency compared to standalone RL and GPT-4 approaches. In static environments, the integrative approach achieved a 90% task success rate, with an average completion time of 42.1 s and only 1.1 retries, outperforming RL-only (72%) and GPT-4-only (78%) methods. In dynamic environments, our integrative system maintained an 85% success rate, compared to 65% for RL-only and 70% for GPT-4-only. For complex tasks, the hybrid model showed a substantial advantage, with an 80% success rate, highlighting its superior performance in tasks requiring both high-level reasoning and low-level precision control.},
  archive      = {J_RAS},
  author       = {Truong Nhut Huynh and Kim-Doang Nguyen},
  doi          = {10.1016/j.robot.2025.105197},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105197},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Integrative AI framework for robotics: LLM-enabled reinforcement learning in object manipulation and task planning},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Behavior-based navigation of a two-wheeled self-balancing robot using a modified hybrid automaton. <em>RAS</em>, <em>195</em>, 105195. (<a href='https://doi.org/10.1016/j.robot.2025.105195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to advances in robotics science, mobile robots are being used in more and more applications worldwide, and the autonomous navigation of these robots is an important topic in their discussion. This paper focuses on the autonomous navigation of a two-wheeled self-balancing robot (TWSBR) in an unknown environment using behavior-based control in the form of a hybrid automaton. This hybrid automaton includes the behaviors “Go To Goal” and “Avoid Obstacle,” and to avoid the Zeno phenomenon between these two behaviors, another behavior is considered in between, called “Follow Wall,” which the robot uses to move around the obstacle. However, two bugs are identified in the conventional hybrid automaton. The first bug causes the robot to not follow the optimal path. Another bug is that the Zeno phenomenon occurs between the two behaviors “Follow Wall” and “Go To Goal,” causing odometry errors in the experimental environment. The results show that the modified hybrid automaton successfully corrects the bugs and works as intended. The navigation algorithm is designed for the point mass model, so it is transformed to the unicycle model using a transformation, which can be used as input to the TWSBR controller. After linearizing the dynamic equations of the robot around its equilibrium point, the pole placement method is used to create the TWSBR controller. By adding the Luenberger observer to estimate the state variables, the non-full-state feedback system is also controlled. The results of the simulations demonstrate that the whole system is functioning properly so that the robot follows the path determined by the navigation algorithm while maintaining its equilibrium.},
  archive      = {J_RAS},
  author       = {Mohsen Heydari Khalili and Majid Sadedel},
  doi          = {10.1016/j.robot.2025.105195},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105195},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Behavior-based navigation of a two-wheeled self-balancing robot using a modified hybrid automaton},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A path planning decision system for unknown pipeline detection using UAVs. <em>RAS</em>, <em>195</em>, 105194. (<a href='https://doi.org/10.1016/j.robot.2025.105194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Pipeline-Aimed path Planner (PAPlanner), a sampling-based path planner for UAVs in unknown oil/gas pipelines. Its key contributions include a dynamic anchor point update strategy and path optimization that adapts to bends and diameter changes, eliminating redundant backtracking and enabling continuous exploration. By integrating real-time voxel maps, the algorithm optimizes paths to stay near the pipeline axis. Simulation results show that PAPlanner reduces average path length by 26.4% compared to the advanced MBPlanner method in the elbow scene experiment, demonstrating efficient safe trajectory maintenance. In the variable diameter scene experiment, where MBPlanner fails frequently, PAPlanner achieves a 0% failure rate. Real flight experiments validate its robustness with a 0.309 m average trajectory deviation from the axis, confirming reliable navigation. This work presents a novel framework enhancing UAV exploration efficiency in pipelines, overcoming limitations of existing algorithms for autonomous inspection in sensor-degraded confined environments.},
  archive      = {J_RAS},
  author       = {Dekai Lin and Ruitao Ma and Yin Zhao and Jiakuo Zhang and Shubin Liu and Hang Zhu},
  doi          = {10.1016/j.robot.2025.105194},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105194},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A path planning decision system for unknown pipeline detection using UAVs},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CPP-DIP: Multi-objective coverage path planning for MAVs in dispersed and irregular plantations. <em>RAS</em>, <em>195</em>, 105193. (<a href='https://doi.org/10.1016/j.robot.2025.105193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coverage Path Planning (CPP) is vital in precision agriculture to improve efficiency and resource utilization. In irregular and dispersed plantations, traditional grid-based CPP often causes redundant coverage over non-vegetated areas, leading to waste and pollution. To overcome these limitations, we propose CPP-DIP, a multi-objective CPP framework designed for Micro Air Vehicles (MAVs). The framework transforms the CPP task into a Traveling Salesman Problem (TSP) and optimizes flight paths by minimizing travel distance, turning angles, and intersection counts. Unlike conventional approaches, our method does not rely on GPS-based environmental modeling. Instead, it uses aerial imagery and a Histogram of Oriented Gradients (HOG)-based approach to detect trees and extract image coordinates. A density-aware waypoint strategy is applied: Kernel Density Estimation (KDE) is used to reduce redundant waypoints in dense regions, while a greedy algorithm ensures complete coverage in sparse areas. To verify the generality and scalability of the framework, TSP instances of varying sizes are solved using three methods: Greedy Heuristic Insertion (GHI), Ant Colony Optimization (ACO), and Monte Carlo Reinforcement Learning (MCRL). An object-based optimization is subsequently applied to further refine the paths. Additionally, CPP-DIP integrates ForaNav, our insect-inspired navigation method, for accurate tree localization and tracking. Experimental results show that MCRL provides a balanced solution, reducing travel distance by 16.9 % compared to ACO while maintaining comparable performance to GHI. It also improves path smoothness by reducing turning angles by 28.3 % and 59.9 % relative to ACO and GHI, respectively, and eliminates intersections. Computational resource comparisons further highlight that GHI scales efficiently with increasing waypoints, whereas ACO and MCRL incur higher computational costs. These results confirm the robustness, efficiency, and scalability of the proposed CPP-DIP.},
  archive      = {J_RAS},
  author       = {Weijie Kuang and Hann Woei Ho and Ye Zhou},
  doi          = {10.1016/j.robot.2025.105193},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105193},
  shortjournal = {Robot. Auton. Syst.},
  title        = {CPP-DIP: Multi-objective coverage path planning for MAVs in dispersed and irregular plantations},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EM-LSD: A lightweight and efficient model for multi-scale line segment detection. <em>RAS</em>, <em>195</em>, 105192. (<a href='https://doi.org/10.1016/j.robot.2025.105192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of detecting line segments in dynamic and geometrically complex environments, EM-LSD, a lightweight and efficient line segment detection model, is introduced. Accurate and efficient detection of line segments is critical for tasks such as environmental modeling and localization in SLAM, where the failure to extract robust line features can result in unreliable mapping and trajectory estimation. The design of EM-LSD is guided by the limitations of existing methods: traditional approaches often fail to capture multi-scale and global features in noisy scenes, while deep learning models with multi-stage architectures impose high computational costs, making them unsuitable for real-time applications. Inspired by the observation that multi-scale feature extraction is essential for handling diverse geometric structures, EM-LSD incorporates a Dense Atrous Convolution (DAC) module to effectively capture multi-scale information with minimal computational overhead. Additionally, the need for robustness against structural complexities and noise led to the integration of dual decoders with a Channel-Spatial Multi-scale Attention (CSMA) module and a Multi-scale Atrous Deformable Block (MADB), enabling adaptive feature representation. Experimental results on the Wireframe and YorkUrban datasets validate EM-LSD’s superior accuracy, robustness, and real-time performance, emphasizing its capability to support resource-constrained SLAM applications. This model not only addresses the limitations of existing methods but also enhances the reliability of environment modeling and localization, offering inspiration for the development of lightweight and efficient detection frameworks.},
  archive      = {J_RAS},
  author       = {Shuo Hu and Liye Zhao and Qing Wang},
  doi          = {10.1016/j.robot.2025.105192},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105192},
  shortjournal = {Robot. Auton. Syst.},
  title        = {EM-LSD: A lightweight and efficient model for multi-scale line segment detection},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Neuromorphic visuotactile slip perception for robotic manipulation. <em>RAS</em>, <em>195</em>, 105191. (<a href='https://doi.org/10.1016/j.robot.2025.105191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visuotactile sensing technology has received extensive attention in the tactile sensing community due to its stable high-resolution deformation sensing capabilities. However, the existing visuotactile sensing methods are far from humanoid neural information processing mechanism. To address this gap, we propose a neuromorphic visuotactile slip detection method named VT-SNN using Tactile Address-Event Representation (TAER) encoding combined with brain-inspired Spiking Neural Network (SNN) modeling in this paper. Our extensive experimental results demonstrate that the VT-SNN achieves slip detection accuracy of 99.59% and F1 score of 99.28%, which is comparable to Artificial Neural Networks (ANNs) while exhibiting significant advantages in power dissipation and inference time. Furthermore, we deployed the VT-SNN on Intel neuromorphic computing chip–Loihi and performed closed-loop slip-feedback robotic manipulation tasks such as bottle-cap tightening and loosening. Our closed-loop neuromorphic visuotactile sensing system shows significant promise for high accuracy, low latency, and low power dissipation for robotic dexterous manipulation.},
  archive      = {J_RAS},
  author       = {Yiming Qiao and Chaofan Zhang and Shaowei Cui and Lu Cao and Zhigang Wang and Peng Wang and Shuo Wang},
  doi          = {10.1016/j.robot.2025.105191},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105191},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Neuromorphic visuotactile slip perception for robotic manipulation},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm. <em>RAS</em>, <em>195</em>, 105190. (<a href='https://doi.org/10.1016/j.robot.2025.105190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstacle-aware configuration control represents a critical challenge in the deployment of continuum robots for advanced applications such as robotic-assisted laparoscopic surgery and intelligent industrial grasping systems. At present, in order to realize the obstacle avoidance function of flexible robots, inverse kinematic calculations are usually unavoidable. The problems of large amount of computation, long solution time, and non-convergence of results make the configuration control for flexible robots still challenging. Most of the current studies use the inverse kinematics calculation of end tracking, and for flexible robots with multiple degrees of freedom, the success rate of obstacle avoidance is low and the computational cost is large. In this paper, a three-segment continuum configuration planning method based on Rapidly-exploring Random Tree (RRT) algorithm is proposed, in which the rough obstacle avoidance path is obtained by RRT algorithm, then the three-segment fitting is carried out by using the second-order Bézier curve, and the length error is evaluated to meet the planning requirements. Experiments such as obstacle avoidance tests, the arrival of target endpoints at different positions and different obstacle environments show that the proposed method can effectively map the feasible solution to the actual configuration. Compared with the inverse kinematics method, the proposed approach improves the success rate of obtaining feasible solutions by at least 14.8% and reduces the solution time by at least 55%. In addition, no prior curvature information and traditional inverse kinematics calculation are needed for the configuration control.},
  archive      = {J_RAS},
  author       = {Qiqi Pan and Hongbo Wang and Yongfei Feng and Shijie Guo and Jingjing Luo},
  doi          = {10.1016/j.robot.2025.105190},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105190},
  shortjournal = {Robot. Auton. Syst.},
  title        = {RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions. <em>RAS</em>, <em>195</em>, 105185. (<a href='https://doi.org/10.1016/j.robot.2025.105185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the following problem: A robot operating in a 2D environment with a limited vision range finds a path to a goal in an unknown environment containing obstacles. In this paper, we propose a novel algorithm to solve the problem. In some special cases, our algorithm is convergent with respect to ‖ . ‖ . The problem involves discovering the environmental map and blind alley regions, that are bounded by obstacles, and it provides no possible passage for robots except in and out of their path entry occur, the robot has to return back to some positions outside to escape from such regions such that the returned path is not longer than the path entry (Blind Alley Region problem, (BAR) problem, in short). To solve the (BAR) problem, sequences of bundles of line segments during the robot’s traveling are constructed in our algorithm. Some advantages of our algorithm are that (a) It reduces search space in blind alley regions because it only works on the sequences of bundles of the line segments built by the robot’s limited vision range. (b) Our algorithm ensures that the returned path to escape from the regions is not longer than the previous path of the robot. (c) Due to the construction of the sequences of bundles of line segments, our paths are not always “close” obstacles and the number of turns of such paths is smaller ones determined by other shortest path algorithms (e.g., A*, RRT*). Our algorithm is implemented in Python and we experience the algorithm on some autonomous robots with different vision ranges in real environment. We also compare our result with RRTX, a state-of-art local path-planning algorithm, and A ∗ , a basic one. The experimental results show that our algorithm provides better solutions than RRTX and A* results in some specific circumstances.},
  archive      = {J_RAS},
  author       = {Phan Thanh An and Pham Hoang Anh and Tran Thanh Binh and Tran Van Hoai},
  doi          = {10.1016/j.robot.2025.105185},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105185},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances. <em>RAS</em>, <em>195</em>, 105184. (<a href='https://doi.org/10.1016/j.robot.2025.105184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust and enhanced control strategy for a multi-quadrotor suspended payload system, which is characterized by complex nonlinear dynamics and unknown external disturbances. A precise dynamic model of the system is formulated using the Udwadia–Kalaba method. A distributed cooperative planning framework, based on graph theory, is employed to enable effective information exchange and cooperative control among multiple quadrotors. To mitigate the impact of unknown disturbances, such as wind fields and variations in payload mass, a disturbance observer is developed to estimate and compensate for these disturbances, thereby enhancing system robustness. Furthermore, an improved prescribed performance control method is proposed to address the issue of exceeding performance boundaries. The steady-state error of the system is effectively reduced by adaptively adjusting the prescribed performance boundary and combining it with integral backstepping, and real-time constraints on tracking errors and closed-loop stability are achieved. Simulation results validate that the proposed control strategy significantly enhances the control performance and disturbance rejection capability of the multi-quadrotor suspended payload system, demonstrating superior robustness.},
  archive      = {J_RAS},
  author       = {Xinyu Chen and Yunsheng Fan and Guofeng Wang and Dongdong Mu},
  doi          = {10.1016/j.robot.2025.105184},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105184},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-agent reinforcement learning for zero-shot coverage path planning with dynamic UAV networks. <em>RAS</em>, <em>195</em>, 105163. (<a href='https://doi.org/10.1016/j.robot.2025.105163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in autonomous systems have enabled the development of intelligent multi-robot systems for dynamic environments. Unmanned Aerial Vehicles play an important role in multi-robot applications such as precision agriculture, search-and-rescue, and wildfire monitoring, all of which rely on solving the coverage path planning problem. While Multi-Agent Coverage Path Planning approaches have shown potential, many existing methods lack the scalability and adaptability needed for diverse and dynamic scenarios. This paper presents a decentralized Multi-Agent Coverage Path Planning framework based on Multi-Agent Reinforcement Learning with parameter sharing and Centralized Training with Decentralized Execution. The framework incorporates a customized Rainbow Deep-Q Network, a size-invariant reward function, and a robustness and safety filter to ensure completeness and reliability in dynamic environments. Our training pipeline combines curriculum learning, domain randomization, and transfer learning, enabling the model to generalize to unseen scenarios. We demonstrate zero-shot generalization on scenarios with significantly larger maps, an increased number of obstacles, and a varying number of agents compared to what is seen during training. Furthermore, the models can also adapt to more structured maps and handle different tasks, such as search-and-rescue, without the need for retraining.},
  archive      = {J_RAS},
  author       = {José P. Carvalho and A. Pedro Aguiar},
  doi          = {10.1016/j.robot.2025.105163},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105163},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multi-agent reinforcement learning for zero-shot coverage path planning with dynamic UAV networks},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="spa">SPA - 9</h2>
<ul>
<li><details>
<summary>
(2026). Swarm dynamics for global optimization on finite sets. <em>SPA</em>, <em>191</em>, 104780. (<a href='https://doi.org/10.1016/j.spa.2025.104780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the global optimisation of a function U defined on a finite set V endowed with an irreducible and reversible Markov generator. By integration, we extend U to the set P ( V ) of probability distributions on V and we penalize it with a time-dependent generalized entropy functional. Endowing P ( V ) with a Maas’ Wasserstein-type Riemannian structure enables us to consider an associated time-inhomogeneous gradient descent algorithm. There are several ways to interpret this P ( V ) -valued dynamical system as the time-marginal laws of a time-inhomogeneous non-linear Markov process taking values in V , each of them allowing for interacting particle approximations. This procedure extends to the discrete framework the continuous state space swarm algorithm approach of Bolte et al. (2023), but here we go further by considering more general generalized entropy functionals for which functional inequalities can be proven. Thus in the full generality of the above finite framework, we give conditions on the underlying time dependence ensuring the convergence of the algorithm toward laws supported by the set of global minima of U . Numerical simulations illustrate that one has to be careful about the choice of the time-inhomogeneous non-linear Markov process interpretation.},
  archive      = {J_SPA},
  author       = {Nhat-Thang Le and Laurent Miclo},
  doi          = {10.1016/j.spa.2025.104780},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104780},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Swarm dynamics for global optimization on finite sets},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deviation inequalities for contractive infinite memory processes. <em>SPA</em>, <em>191</em>, 104778. (<a href='https://doi.org/10.1016/j.spa.2025.104778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a class of stochastic processes that encompasses many natural and widely used examples. A key feature of these processes is their infinite memory, which enables them to retain information from arbitrarily distant past states. Using the martingale decomposition method, we derive deviation and moment inequalities for separately Lipschitz functionals of such processes, under various moment conditions on certain dominating random variables. Our results extend those obtained for Markov chains by Dedecker and Fan [Stochastic Process. Appl., 2015], as well as recent results by Chazottes et al. [Ann. Appl. Probab., 2023] concerning specific infinite-memory models with sub-Gaussian concentration bounds. We also discuss an application to the stochastic gradient Langevin dynamics algorithm.},
  archive      = {J_SPA},
  author       = {Paul Doukhan and Xiequan Fan},
  doi          = {10.1016/j.spa.2025.104778},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104778},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Deviation inequalities for contractive infinite memory processes},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reflected BSDE driven by a marked point process with a convex/concave generator. <em>SPA</em>, <em>191</em>, 104777. (<a href='https://doi.org/10.1016/j.spa.2025.104777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a class of reflected backward stochastic differential equations (RBSDE) driven by a marked point process (MPP) with a convex/concave generator. Based on fixed point argument, θ -method and truncation technique, the well-posedness of this kind of RBSDE with unbounded terminal condition and obstacle is investigated. Besides, we present an application on the pricing of American options via utility maximization, which is solved by constructing an RBSDE with a convex generator.},
  archive      = {J_SPA},
  author       = {Zihao Gu and Yiqing Lin and Kun Xu},
  doi          = {10.1016/j.spa.2025.104777},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104777},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Reflected BSDE driven by a marked point process with a convex/concave generator},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mixing time and cutoff for the k-SPEP. <em>SPA</em>, <em>191</em>, 104776. (<a href='https://doi.org/10.1016/j.spa.2025.104776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the mixing time of the capacity k symmetric partial exclusion process of Schütz and Sandow with m particles on a segment of length N , and we show that this process exhibits cutoff at time 1 2 k π 2 N 2 log m . We also introduce a related complete multi-species process that we call the S k , N shuffle and show that this process exhibits cutoff at time 1 2 k π 2 N 2 log ( N ) . This extends the celebrated result of Lacoin, which proved cutoff for the symmetric simple exclusion process on a segment of length N and the adjacent transposition shuffle.},
  archive      = {J_SPA},
  author       = {Eyob Tsegaye},
  doi          = {10.1016/j.spa.2025.104776},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104776},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Mixing time and cutoff for the k-SPEP},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Convergence of adapted smoothed empirical measures. <em>SPA</em>, <em>191</em>, 104775. (<a href='https://doi.org/10.1016/j.spa.2025.104775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adapted Wasserstein distance ( AW -distance) controls the calibration errors of optimal values in various stochastic optimization problems, pricing and hedging problems, optimal stopping problems, etc. However, statistical aspects of the AW -distance are bottlenecked by the failure of empirical measures ( Emp ) to converge under this distance. Kernel smoothing and adapted projection have been introduced to construct converging substitutes of empirical measures, known respectively as smoothed empirical measures ( S - Emp ) and adapted empirical measures ( A - Emp ). However, both approaches have limitations. Specifically, S - Emp lack comprehensive convergence results, whereas A - Emp in practical applications lead to fewer distinct samples compared to standard empirical measures. In this work, we address both of the aforementioned issues. First, we develop comprehensive convergence results of S - Emp . We then introduce a smoothed version for A - Emp , which provide as many distinct samples as desired. We refer them as AS - Emp and establish their convergence in mean, deviation and almost sure convergence. The convergence estimation incorporates two results: the empirical analysis of the smoothed adapted Wasserstein distance ( AW ( σ ) -distance) and its bandwidth effects. Both results are novel and their proof techniques could be of independent interest.},
  archive      = {J_SPA},
  author       = {Songyan Hou},
  doi          = {10.1016/j.spa.2025.104775},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104775},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Convergence of adapted smoothed empirical measures},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal control of the nonlinear stochastic Fokker–Planck equation. <em>SPA</em>, <em>191</em>, 104774. (<a href='https://doi.org/10.1016/j.spa.2025.104774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a control problem for the nonlinear stochastic Fokker–Planck equation. This equation describes the evolution of the distribution of nonlocally interacting particles affected by a common source of noise. The system is directed by a controller that acts on the drift term with the goal of minimising a cost functional. We establish the well-posedness of the state equation, prove the existence of optimal controls, and formulate a stochastic maximum principle (SMP) that provides necessary and sufficient optimality conditions for the control problem. The adjoint process arising in the SMP is characterised by a nonlocal (semi)linear backward SPDE for which we study existence and uniqueness. We also rigorously connect the control problem for the nonlinear stochastic Fokker–Planck equation to the control of the corresponding McKean–Vlasov SDE that describes the motion of a representative particle. Our work extends existing results for the control of the Fokker–Planck equation to nonlinear and stochastic dynamics. In particular, the sufficient SMP, which we obtain by exploiting the special structure of the Fokker–Planck equation, seems to be novel even in the linear deterministic setting. We illustrate our results with an application to a model of government interventions in financial systems, supplemented by numerical illustrations.},
  archive      = {J_SPA},
  author       = {Ben Hambly and Philipp Jettkant},
  doi          = {10.1016/j.spa.2025.104774},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104774},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Optimal control of the nonlinear stochastic Fokker–Planck equation},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Duality for some models of epidemic spreading. <em>SPA</em>, <em>191</em>, 104773. (<a href='https://doi.org/10.1016/j.spa.2025.104773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the role of boundaries and the structure of nontrivial duality functions for three non-conservative interacting particle systems in one dimension that model epidemic spreading: (i) the diffusive contact process (DCP), (ii) a model that we introduce and call generalized diffusive contact process (GDCP), both in finite volume in contact with boundary reservoirs, i.e., with open boundaries, and (iii) the susceptible–infectious–recovered (SIR) model on Z . We establish duality relations for each system through an analytical approach. It turns out that with open boundaries self-duality breaks down and qualitatively different properties compared to closed boundaries (i.e., finite volume without reservoirs) arise: Both the DCP and GDCP are ergodic but no longer absorbing, while the respective dual processes are absorbing but not ergodic. We provide expressions for the stationary correlation functions in terms of the dual absorption probabilities. We perform explicit computations for a small sized DCP, and for arbitrary size in a particular setting of the GDCP. The duality function is factorized for the DCP and GDCP, contrary to the SIR model for which the duality relation is nonlocal and yields an explicit expression of the time evolution of some specific correlation functions, describing the time decay of the sizes of clusters of susceptible individuals.},
  archive      = {J_SPA},
  author       = {C. Franceschini and E. Saada and G.M. Schütz and S. Velasco},
  doi          = {10.1016/j.spa.2025.104773},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104773},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Duality for some models of epidemic spreading},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A tamed euler scheme for SDEs with non-locally integrable drift coefficient. <em>SPA</em>, <em>191</em>, 104772. (<a href='https://doi.org/10.1016/j.spa.2025.104772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we show that for SDEs with a drift coefficient that is non-locally integrable, one may define a tamed Euler scheme that converges in L p at rate 1 / 2 to the true solution. The taming is required in this case since one cannot expect the regular Euler scheme to have finite moments in L p . Our proof strategy involves controlling the inverse moments of the distance of scheme and the true solution to the singularity set. We additionally show that our setting applies to the case of two scalar valued particles with singular interaction kernel. To the best of the authors’ knowledge, this is the first work to prove strong convergence of an Euler-type scheme in the case of non-locally integrable drift.},
  archive      = {J_SPA},
  author       = {Tim Johnston and Sotirios Sabanis},
  doi          = {10.1016/j.spa.2025.104772},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104772},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A tamed euler scheme for SDEs with non-locally integrable drift coefficient},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scaling limit and large deviation for 3D globally modified stochastic Navier–Stokes equations with transport noise. <em>SPA</em>, <em>191</em>, 104770. (<a href='https://doi.org/10.1016/j.spa.2025.104770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the globally modified stochastic (hyperviscous) Navier–Stokes equations with transport noise on 3D torus. We first establish the existence and pathwise uniqueness of the weak solutions, and then show their convergence to the solutions of the deterministic 3D globally modified (hyperviscous) Navier–Stokes equations in an appropriate scaling limit. Furthermore, we prove a large deviation principle for the stochastic globally modified hyperviscous system.},
  archive      = {J_SPA},
  author       = {Chang Liu and Dejun Luo},
  doi          = {10.1016/j.spa.2025.104770},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104770},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Scaling limit and large deviation for 3D globally modified stochastic Navier–Stokes equations with transport noise},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="swevo">SWEVO - 35</h2>
<ul>
<li><details>
<summary>
(2025). Survey on multi-task optimization: Towards cross-domain and asynchronous multi-task. <em>SWEVO</em>, <em>99</em>, 102175. (<a href='https://doi.org/10.1016/j.swevo.2025.102175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task optimization (MTO) accelerates the acquisition of optimal solutions for all tasks through effective knowledge transfer. To satisfy various practical demands, multiple tasks are often transformed into different types of optimization problems. Hence, there are numerous MTO variants in the MTO research community. To motivate deeper research on MTO and its variants, this paper mainly summarizes MTO and its variants from single-domain to cross-domain and from synchronous to asynchronous. First, the single-domain and synchronous MTO is classified into single-objective MTO, multi-objective MTO, constrained MTO, many-task optimization, and other variants based on the task types. Second, technical applications that employ MTO techniques to solve other types of optimization problems are also collated, which differ significantly from MTO variants. Finally, several promising research directions of MTO are presented theoretically and practically, including mining knowledge representations to minimize information loss, cross-domain MTO with multiple different task types, asynchronous MTO with inconsistent task arrival times, and an application of MTO to neural architecture search problems.},
  archive      = {J_SWEVO},
  author       = {Honggui Han and Ben Zhao and Xiaolong Wu and Xin Li},
  doi          = {10.1016/j.swevo.2025.102175},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102175},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Survey on multi-task optimization: Towards cross-domain and asynchronous multi-task},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid MOEA with problem-specific operators for beam-hopping based resource allocation in multi-beam LEO satellites. <em>SWEVO</em>, <em>99</em>, 102174. (<a href='https://doi.org/10.1016/j.swevo.2025.102174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient allocation of satellite communication resources has become increasingly vital due to the dynamic and growing nature of traffic demand. The beam-hopping resource allocation technique addresses this challenge by enabling sequential and adaptive beam illumination, along with a dynamic distribution of power and bandwidth based on existing user demand. This work formulates the large-dimensional and highly constrained beam-hopping problem for low-power, low earth orbit satellites as a multi-objective optimization problem. It considers three key objectives: unserved capacity (UC), which measures the portion of traffic demand that remains unmet; extra served capacity (EC), which reflects excess traffic delivered beyond the requested demand, indicating possible inefficiencies; and time to serve (TTS), which represents the average waiting time for users in non-illuminated cells. Aiming at innovating in optimization, specialized initialization, crossover, mutation, and local search operators for multi-objective evolutionary algorithms (MOEAs) have been proposed. Performance is assessed through Hypervolume (HV) metrics and statistical confidence analysis. An extensive experimental analysis is presented first for a canonical NSGA-II algorithm, characterizing the impact of the new operators and hybrid components on performance. Then, beyond Pareto-based approaches such as NSGA-II, a study of both decomposition- and indicator-based MOEAs, namely MOEA/D and SMS-EMOA is assessed, demonstrating the generalizability of the presented approach. Compared to previous results in the literature, our hybrid approaches achieve up to 5% improvement in UC, up to 100% gains in EC, and up to 60% improvement in TTS for the best configuration.},
  archive      = {J_SWEVO},
  author       = {Samuel Martínez Zamacola and Francisco Luna Valero and Ramón Martínez Rodríguez-Osorio},
  doi          = {10.1016/j.swevo.2025.102174},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102174},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Hybrid MOEA with problem-specific operators for beam-hopping based resource allocation in multi-beam LEO satellites},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative multi-CP model and meta-feedback learning-assisted matheuristic for solving the flexible job shop scheduling problem with sequence-dependent setup times. <em>SWEVO</em>, <em>99</em>, 102173. (<a href='https://doi.org/10.1016/j.swevo.2025.102173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible job shop scheduling problem with sequence-dependent setup times (FJSP-SDST) is a crucial challenge in modern manufacturing, where varying setup times significantly impact scheduling performance. This challenge has motivated significant research interest in solving FJSP-SDST through both exact and approximate methods. Although existing exact methods, such as mixed-integer linear programming and constraint programming (CP) have been explored, they remain inefficient in solving large-scale instances. To address this limitation, this paper proposes a collaborative multi-CP model, inspired by the collaborative optimization paradigm, which integrates global and local optimization stages to effectively solve large instances. Due to the NP-hard nature of FJSP-SDST, an approximate method, the meta-feedback learning-assisted matheuristic (MFLA-MH) algorithm, is proposed. The algorithm adopts collaborative variable neighborhood search as its main framework and incorporates meta-feedback learning to adaptively guide search operator selection. Additionally, two mathematical neighborhood structures and a mathematical evolution operator, as matheuristic techniques, are designed to optimize the subproblem solutions and overcome the limitations of traditional encoding-decoding methods. Experimental results on 20 real-world cases demonstrate that the collaborative multi-CP model and MFLA-MH efficiently generate high-quality solutions, and outperform state-of-the-art methods.},
  archive      = {J_SWEVO},
  author       = {Weiyao Cheng and Chaoyong Zhang and Leilei Meng and Yaping Ren and Saif Ullah},
  doi          = {10.1016/j.swevo.2025.102173},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102173},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Collaborative multi-CP model and meta-feedback learning-assisted matheuristic for solving the flexible job shop scheduling problem with sequence-dependent setup times},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep Q-network assisted variable neighborhood search algorithm for berth allocation considering berth shifting in dry bulk terminals. <em>SWEVO</em>, <em>99</em>, 102172. (<a href='https://doi.org/10.1016/j.swevo.2025.102172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expansion of global maritime trade, along with the surge in dry bulk vessel sizes, has intensified the shortage of deep-water berths. This work investigates a discrete berth allocation problem considering berth shifting in dry bulk terminals. It includes two shifting strategies: 1) load-reduction shifting, where large vessels first unload partial cargo at deep-water berths to lighten their draft, and then shift to shallow-water berths to complete operations; and 2) berth-releasing shifting, where small vessels shift from deep-water berths to shallow-water berths when a large vessel needs the space. A mixed-integer linear programming model is formulated to minimize the total vessel service time. A Deep Q-Network assisted Variable Neighborhood Search algorithm (DQN-VNS) is proposed to solve this problem. First, a Dynamic-priority-based Heuristic Initialization Strategy is proposed to generate high-quality initial solutions. Then, a Deep Q-Network is employed to guide the search by adaptively choosing the most promising neighborhood operator. Numerical experiments are conducted on real historical data from a dry bulk terminal. The results demonstrate that DQN-VNS can effectively improve search efficiency and solution quality, significantly reducing vessel service time in dry bulk terminals. This work can significantly enhance the operational efficiency of dry bulk terminals.},
  archive      = {J_SWEVO},
  author       = {Wei Zhang and Liang Qi and Weili Zhao and Lei Zhang and Song Xue and Wenjing Luan and Yangming Zhou},
  doi          = {10.1016/j.swevo.2025.102172},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102172},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Deep Q-network assisted variable neighborhood search algorithm for berth allocation considering berth shifting in dry bulk terminals},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOEA/D-BDN: Multimodal multi-objective evolutionary algorithm based on bi-dynamic niche strategy and adaptive weight decomposition. <em>SWEVO</em>, <em>99</em>, 102171. (<a href='https://doi.org/10.1016/j.swevo.2025.102171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multimodal multi-objective problems (MMOPs) have emerged as a prominent research focus in the field of multi-objective optimization. The key challenge in solving MMOPs is to identify multiple equivalent Pareto-optimal solution sets corresponding to discontinuous or complex Pareto fronts. To address this challenge, this paper proposes a novel multimodal multi-objective evolutionary algorithm (MOEA/D-BDN), which integrates a bi-dynamic niche strategy with an adaptive weight decomposition mechanism. Within the decomposition framework, the algorithm introduces an archiving mechanism to preserve historically outstanding individuals, thereby maintaining population diversity and convergence. Furthermore, a bi-dynamic niche distance (BDN) metric is employed to evaluate the overall density in both objective and decision spaces, enabling more effective updating and removal of solutions from the archive. To improve the uniformity of the Pareto front approximation, an adaptive weight adjustment strategy is used to dynamically guide the search direction. Experimental results on several benchmark MMOPs show that MOEA/D-BDN significantly outperforms state-of-the-art multimodal multi-objective evolutionary algorithms in terms of convergence, diversity, and distribution quality, demonstrating its effectiveness and competitiveness in handling complex MMOPs.},
  archive      = {J_SWEVO},
  author       = {Chunliang Zhang and Huang Li and Shangbin Long and Xia Yue and Haibin Ouyang and Houyao Zhu and Steven Li},
  doi          = {10.1016/j.swevo.2025.102171},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102171},
  shortjournal = {Swarm Evol. Comput.},
  title        = {MOEA/D-BDN: Multimodal multi-objective evolutionary algorithm based on bi-dynamic niche strategy and adaptive weight decomposition},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metaheuristics for analog circuit design optimization: A survey. <em>SWEVO</em>, <em>99</em>, 102170. (<a href='https://doi.org/10.1016/j.swevo.2025.102170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As CMOS technology continues to scale down, the design complexity of very large-scale integrated circuits (VLSI) is rapidly increasing. Analog circuit design, in particular, remains time-consuming due to the critical impact of component dimensions on performance. Although the application of metaheuristics in analog circuit automation dates back to the 1980s, the growing complexity of analog design tasks and the need to reduce design cycles has sparked renewed interest in using metaheuristic approaches to address these challenges. In this paper, we provide a comprehensive and up-to-date review of existing studies on the application of metaheuristics in analog circuit design automation, including circuit synthesis, sizing, and layout synthesis, while assessing their effectiveness in meeting design objectives. The paper provides an in-depth discussion from the metaheuristics perspective and highlights key research directions for future exploration.},
  archive      = {J_SWEVO},
  author       = {Abdelaziz Lberni and Malika Alami Marktani and Abdelaziz Ahaitouf and Ali Ahaitouf},
  doi          = {10.1016/j.swevo.2025.102170},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102170},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Metaheuristics for analog circuit design optimization: A survey},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A preference modified inverted generational distance indicator guided algorithm for evolutionary multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102169. (<a href='https://doi.org/10.1016/j.swevo.2025.102169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference-based evolutionary multi-objective optimization algorithms have attracted much attention in the area of evolutionary computation. However, there are only a few researchers incorporating performance indicators for designing preference-based evolutionary algorithm. In this paper, we propose a preference modified inverted generational distance indicator guided algorithm, named PIGA, for evolutionary multi-objective optimization. The main purpose is that decision-makers provide their preferences, ultimately identifying the portion of Pareto optimal solutions where are located in region of interest. A new preference construction strategy based on coordinate transformation is first proposed. The reference points in the whole objective space can be projected into the preference space, obtaining the preferred reference points. The non-preferred reference points remain in the original objective space, outside the specified preference region. In addition, we define the distance between the candidate solution and preferred reference points as the preference distance and the distance to non-preferred reference points as the penalty distance. Finally, a preference-based modified inverted generational distance indicator is formulated to obtain the preferred optimal solutions according to the preferences and penalty distances. The comparative results are comprehensively analyzed by comparing it with some related preference-based evolutionary algorithms on some test instances. Experimental results have validated the effectiveness and feasibility of the proposed algorithm under different scenarios with the given preference range.},
  archive      = {J_SWEVO},
  author       = {Fei Li and Hao Tian and Hao Shen and Xingyi Zhang and Jianchang Liu and Zaiwu Gong},
  doi          = {10.1016/j.swevo.2025.102169},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102169},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A preference modified inverted generational distance indicator guided algorithm for evolutionary multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Material delivery optimization for make-to-order reconfigurable job shops using an improved chaotic multi-verse algorithm. <em>SWEVO</em>, <em>99</em>, 102167. (<a href='https://doi.org/10.1016/j.swevo.2025.102167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for product customization has highlighted the importance of make-to-order (MTO) material delivery. Although manufacturers have deployed intelligent reconfigurable job shops equipped with flexible workstations and automated guided vehicles (AGVs), challenges remain due to inefficient material scheduling, delayed deliveries, and the complexity arising from diverse material types. This study proposes an active delivery strategy based on a workshop material supermarket, in which both AGV path planning and workstation layout are jointly optimized in response to dynamically changing orders. A multi-objective delivery path model is formulated to support demand splitting while minimizing material delivery costs and maximizing timeliness satisfaction. The model incorporates constraints related to AGV capacity, path feasibility, and demand alignment. To address the nonlinearity and complexity of the problem, an improved chaotic multi-verse optimizer (ICMVO) is proposed. The algorithm employs chaotic encoding to enhance population diversity and mitigate premature convergence. It further integrates gravitational and collision operators to improve global and local search capabilities and adopts adaptive orbital dynamics control to balance exploration and exploitation. A dual-population iterative strategy is employed to enable joint decision-making on workstation coordinates, path direction, and vehicle assignment. Through comprehensive comparisons with state-of-the-art meta-heuristics, the superiority of the ICMVO algorithm and the effectiveness of its components are demonstrated. Moreover, the proposed material delivery optimization method is implemented in a cloud–edge–terminal system and validated in practical MTO reconfigurable job shops through improvements in productivity and cost efficiency.},
  archive      = {J_SWEVO},
  author       = {Qinge Xiao and Kai Wang and Chi Ma and Ye Chen},
  doi          = {10.1016/j.swevo.2025.102167},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102167},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Material delivery optimization for make-to-order reconfigurable job shops using an improved chaotic multi-verse algorithm},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trend analysis-based prediction strategies for dynamic multi-objective evolutionary optimization. <em>SWEVO</em>, <em>99</em>, 102166. (<a href='https://doi.org/10.1016/j.swevo.2025.102166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) change over time, which require Evolutionary algorithms (EA) to track Pareto-optimal solutions (PS) and/or Pareto-optimal front (PF) in a dynamic environment. Most prediction-based algorithms solely use a single model to learn the changing pattern for solution prediction. In the face of complex DMOPs, they may achieve an unsatisfactory performance. To address this issue, a novel trend analysis-based prediction strategy (TAP) is proposed in this paper. Based on previous population information, a simple trend analysis is designed to extract the changing pattern of each solution, and classify them into different types: irregular, translational, and stationary. For irregular changing solutions, a neural network nonlinear model is presented to predict the new location. For translational changing solutions, a simple linear model is built to estimate their new positions. For stationary solutions, they are preserved. As a result, TAP is more responsive to different dynamic environments. TAP is incorporated into the dynamic multiobjective evolutionary algorithm (DMOEA) based on decomposition (MOEA/D) to construct a novel algorithm denoted as MOEA/D-TAP. To verify the performance of the proposed method, comparison experiments are carried out on 26 test instances of four different benchmarks compared with six state-of-the-art methods. The test results indicate that TAP is highly competitive.},
  archive      = {J_SWEVO},
  author       = {Anran Cao and Xiaoli Li and Kang Wang},
  doi          = {10.1016/j.swevo.2025.102166},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102166},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Trend analysis-based prediction strategies for dynamic multi-objective evolutionary optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A strategy cooperative algorithm based on state-awareness for large-scale multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102165. (<a href='https://doi.org/10.1016/j.swevo.2025.102165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multi-objective optimization problems (LSMOPs) usually involve hundreds to thousands of decision variables. When dealing with unconstrained 2-3-objective LSMOPs, multi-objective evolutionary algorithms (MOEAs) are likely to get trapped in local optima, making it difficult to ensure the diversity and convergence of solutions within limited computational resources. To tackle this challenge, we propose a strategy-cooperative algorithm based on state-awareness for large-scale multi-objective optimization, abbreviated as LMOEA-SC. In LMOEA-SC, we have designed a state-aware mechanism that can monitor the evolutionary state of the population in real-time. Based on the real-time information, LMOEA-SC flexibly switches and collaborates between the proposed learning strategy based on diversity protection competitive swarm optimization (DPCSO) and the escape strategy based on global exploration sampling (GES), thus effectively coping with different evolutionary states and challenges. The obtained statistical results, with a 73% improvement, clearly show that compared with six state-of-the-art MOEAs, LMOEA-SC has significant competitiveness in numerous large-scale multi-objective test instances with up to 2,000 decision variables.},
  archive      = {J_SWEVO},
  author       = {Hao Liu and Jinhua Zheng and Yaru Hu and Xiaozhong Yu and Junwei Ou and Juan Zou and Shengxiang Yang},
  doi          = {10.1016/j.swevo.2025.102165},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102165},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A strategy cooperative algorithm based on state-awareness for large-scale multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternating curvature-driven evolutionary genetic algorithm for cable insulation thickness measurement. <em>SWEVO</em>, <em>99</em>, 102164. (<a href='https://doi.org/10.1016/j.swevo.2025.102164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate insulation thickness measurement in industrial cables presents a critical yet challenging optimization problem, characterized by an extremely large solution space and stringent requirements for sub-millimeter precision under real-time constraints. Traditional computer vision approaches struggle with computational complexity when processing irregular cross-sections, while conventional evolutionary algorithms exhibit poor convergence characteristics due to the non-convex search landscape. To address these dual challenges, we propose an Alternating Curvature-Driven Genetic Algorithm (ACD-GA) that innovatively integrates geometric prior knowledge with evolutionary computing. Our key advancement lies in establishing a multi-scale curvature gene information database that synergizes differential geometry with adaptive genetic operators. This hybrid architecture features three core innovations: (1) Adaptive generation of initial populations based on multi-scale curvature characteristics to ensure gene quality and diversity; (2) Alternating crossover-mutation operations guided by curvature information to accelerate solution convergence; (3) A population renewal mechanism combining crossover-mutation with original populations and post-selection updates to preserve high-quality genes. Experiments on both regular and irregular IEC standard specimens demonstrate the superiority of ACD-GA in terms of accuracy, repeatability, and convergence efficiency. Compared with traditional manual inspection and fitted ray methods, ACD-GA reduces the average detection time by over 95.8%, decreases the minimum insulation thickness deviation by more than 89.3%, and significantly improves measurement repeatability. When compared with classical evolutionary algorithms (GA, PSO, ACO, SA, DE) and the latest intelligent methods (PSOCO, HPDE, TDE), ACD-GA achieves reductions of 21.1%–86.7% in minimum thickness deviation and up to 88.5% in repeatability, while maintaining comparable detection efficiency.},
  archive      = {J_SWEVO},
  author       = {Yujie LiuFu and Mingyu Hu and Haoran Xu and Junru Song},
  doi          = {10.1016/j.swevo.2025.102164},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102164},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Alternating curvature-driven evolutionary genetic algorithm for cable insulation thickness measurement},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid metaheuristic algorithms for image watermarking: An experimental study. <em>SWEVO</em>, <em>99</em>, 102163. (<a href='https://doi.org/10.1016/j.swevo.2025.102163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invisible image watermarking is a promising method for protecting the copyright of digital images such as photographs, illustrations, and scans. An effective watermarking algorithm embeds a special mark into an image that does not change the image content but can be extracted from it even after some common post-processing operations such as cropping or compression. Many authors use metaheuristic optimization algorithms to achieve a trade-off between imperceptibility and robustness of embedding. In recent years, researchers have been interested in hybrid metaheuristics, which combine operations of individual metaheuristics in some way. However, designs and compositions of hybrid metaheuristic optimization schemes for image watermarking have not been sufficiently studied to date. In this paper, we present an experimental study of various hybrid metaheuristics including sequential, interleaved, and parallel schemes for popular bioinspired optimization algorithms including genetic algorithm, differential evolution algorithm, particle swarm optimization algorithm, firefly algorithm, and artificial bee colony algorithm. We evaluate the effectiveness of hybrid metaheuristics for image watermarking using an algorithm based on changing the ratio between absolute values ​​of sums of discrete cosine transform coefficient groups as an example and perform an experimental comparison of different schemes. The results of the study show that a approach to metaheuristic hybridization and a composition of hybrid scheme significantly affect the imperceptibility and robustness of the image watermarking algorithm. In particular, the interleaved hybridization type provides the best results for the algorithm under consideration.},
  archive      = {J_SWEVO},
  author       = {Anna Melman and Oleg Evsutin},
  doi          = {10.1016/j.swevo.2025.102163},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102163},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Hybrid metaheuristic algorithms for image watermarking: An experimental study},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal financial portfolio selection using a metaheuristic approach with multiple strategies. <em>SWEVO</em>, <em>99</em>, 102162. (<a href='https://doi.org/10.1016/j.swevo.2025.102162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimisation with cardinality constraints has been extensively studied in the realm of financial investment, recognised as an NP-hard quadratic programming problem. As an innovative metaheuristic approach, the dung beetle optimiser leverages its unique optimisation search mechanism to effectively tackle unconstrained optimisation problems. However, the realities of portfolio optimisation involve various constraints; thus, the original dung beetle optimiser may not suffice. Consequently, this study develops an improved dung beetle optimiser to address cardinality constrained portfolio optimisation, incorporating a new decision variable update strategy, a constraint handling strategy, and a local search strategy. These techniques facilitate the efficient selection of assets from among multiple candidate assets. To validate the capabilities of the indicated methodologies, five datasets from OR-Library and six datasets from NGINX are employed for testing. The results from these datasets consistently indicate that the proposed strategies outperform existing alternatives. Furthermore, the comparison results with various methods presented in other works demonstrate that the proposed technology is competitive in the realm of cardinality constrained portfolio optimisation.},
  archive      = {J_SWEVO},
  author       = {Limin Wang and Guosen Lin and Qijun Zhang and Muhammet Deveci and Seifedine Kadry and Mingyang Li},
  doi          = {10.1016/j.swevo.2025.102162},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102162},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Optimal financial portfolio selection using a metaheuristic approach with multiple strategies},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A population-oriented hybrid search surrogate-assisted evolutionary algorithm for expensive constrained optimization multi-objective problems with small feasible regions. <em>SWEVO</em>, <em>99</em>, 102161. (<a href='https://doi.org/10.1016/j.swevo.2025.102161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization problems with expensive objectives and constraints frequently arise in real industries, such problems are called expensive constrained multi-objective optimization problems(ECMOPs). Due to the expensive cost of actual fitness calculations, constructing suitable surrogates for objectives and constraints is crucial for finding potentially feasible solutions. To enhance the search efficiency of surrogate-assisted multi-objective optimization algorithms in complex, small feasible regions with many decision variables, a population-oriented hybrid search surrogate-assisted evolutionary algorithm is proposed, called PHSEA. In PHSEA, the state of the current population is determined by relevance of the objective optimization and constraint violation reduction, as well as the ideal point change rate. Three search strategies are used: unconstrained, weakly constrained and strongly constrained surrogate-assisted search strategy, to search for feasible solutions. Furthermore, according to different search requirements, three archives with separate update criteria were used to construct the surrogate model for constraint functions. On this basis, we propose a population-oriented hybrid search framework that enhances the algorithm’s ability to search for potential solutions in small feasible regions. The proposed method was compared against two surrogate-assisted algorithms and three surrogate-free algorithms on 33 benchmark problems and 6 real-world engineering problems. Experimental results demonstrate that PHSEA exhibits strong competitiveness in solving ECMOPs characterized by small feasible regions and a large number of decision variables.},
  archive      = {J_SWEVO},
  author       = {Cong Zhu and Yongkuan Yang and Xiangsong Kong and Wenji Li},
  doi          = {10.1016/j.swevo.2025.102161},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102161},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A population-oriented hybrid search surrogate-assisted evolutionary algorithm for expensive constrained optimization multi-objective problems with small feasible regions},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolutionary method with shift pattern learning for real-world multi-skilled personnel scheduling with flexible shifts. <em>SWEVO</em>, <em>99</em>, 102160. (<a href='https://doi.org/10.1016/j.swevo.2025.102160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel scheduling remains a significant organizational challenge with substantial potential for cost and time savings. Despite extensive research in this domain, few studies have been successfully implemented in practice, and even fewer have gained widespread acceptance among end-users. This gap between research and application often arises from oversimplified real-world models, which may result from subjective solution evaluations or a lack of collaboration between modelers and end-users. To bridge this gap, this paper proposes a machine learning-enhanced memetic algorithm (MLMA) that mimics schedules created by experts to solve a highly complex personnel scheduling problem involving multi-skilled workers and flexible shift types (irregular workforce)—a real-world challenge commonly faced in the hospitality sector. By leveraging historical scheduling preferences, the MLMA generates solutions that align with past practices, enhancing their practicality and appeal to end-users. Experiments conducted on real-life instances demonstrate the effectiveness of the proposed approach in addressing real-world problems, where the workforce is predominantly part-time, possesses mixed skills, and requires flexible shifts. Furthermore, the results highlight the MLMA’s ability to identify shift patterns that closely resemble historical schedules, underscoring its potential for practical implementation and its role in bridging the gap between research and real-world application.},
  archive      = {J_SWEVO},
  author       = {Ning Xue and Ruibin Bai and Huan Jin and Tianxiang Cui},
  doi          = {10.1016/j.swevo.2025.102160},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102160},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An evolutionary method with shift pattern learning for real-world multi-skilled personnel scheduling with flexible shifts},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offline reinforcement learning strategies guided meta-heuristics for scheduling bi-objective unmanned surface vessel problems with multiple constraints. <em>SWEVO</em>, <em>99</em>, 102159. (<a href='https://doi.org/10.1016/j.swevo.2025.102159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a reinforcement learning-guided meta-heuristics framework for bi-objective unmanned surface vessel (USV) scheduling problems under complex marine constraints, aiming to minimize the maximum completion time and total collision risk index, simultaneously. First, to specify the problems, a bi-objective mathematical model is developed considering three constraints, battery capacity, marine obstacles, and uncertain task executing time. Second, four meta-heuristics are used and improved to solve the focused problems. Based on the problem features, seven local search operators are designed to enhance the algorithms’ performances. Third, two state-reward strategies are designed and integrated into Q-learning and SARSA, respectively, to form four reinforcement learning (RL) algorithms. The four RL algorithms are off-line trained and employed to select the optimal local search operator during the iteration of meta-heuristics for improving the search efficiency. Finally, the study evaluates the performances of the proposed algorithms on 10 cases with different scales. The experimental results and statistical tests verify the efficiency of the local search operators. It is demonstrated that the four proposed RL algorithms can further improve algorithms’ performances. The particle swarm optimization (PSO) integrating Q-learning with the second state-reward strategy (PSO_QL2) exhibits the best competitiveness among all compared algorithms.},
  archive      = {J_SWEVO},
  author       = {Wuze Huang and Kaizhou Gao and Naiqi Wu and Liang Zhao and Renato Tinós},
  doi          = {10.1016/j.swevo.2025.102159},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102159},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Offline reinforcement learning strategies guided meta-heuristics for scheduling bi-objective unmanned surface vessel problems with multiple constraints},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm for integrated design-production-distribution scheduling problems in mass personalized customization. <em>SWEVO</em>, <em>99</em>, 102158. (<a href='https://doi.org/10.1016/j.swevo.2025.102158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, new requirements are proposed for the manufacturing industry transitioning to distributed production models due to emergence of mass personalized customization. Integrated scheduling of design, production and distribution, mixed management of batch and flexible manufacturing are becoming the imminent challenges faced by enterprises. This article proposes an integrated design-production-distribution scheduling problem in distributed mixed shops. It considers distributed flow shops for batch manufacturing and distributed flexible job shops for flexible manufacturing. First, a mixed integer linear programming model is formulized to minimize the maximum completion time, total costs, and total tardiness. Second, a learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm is developed to settle the model. Genetic operators are adopted to improve the global and local search abilities. Three subpopulations with adaptive crossover and mutation probabilities are constructed to enhance the convergence and diversity of population. A Q-learning-assisted cooperative approach is adopted to realize the information communication among subpopulations in the genetic operations. The Q-learning method is used to intelligently choose parent individuals from three subpopulations by utilizing its self-learning strategies. A variable neighborhood search approach considering problem-knowledge neighborhood structures is devised to refine the excellent individuals in population. Finally, the presented algorithm is compared against three well-known intelligent optimization methods on a collection of instances. Comparison outcomes verify the superiority of the developed algorithm in handling the considered problem.},
  archive      = {J_SWEVO},
  author       = {Yanhe Jia and Wei Wang and Jian Zhang},
  doi          = {10.1016/j.swevo.2025.102158},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102158},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm for integrated design-production-distribution scheduling problems in mass personalized customization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feasibility-guided search and prediction for dynamic constrained multiobjective evolutionary optimization. <em>SWEVO</em>, <em>99</em>, 102157. (<a href='https://doi.org/10.1016/j.swevo.2025.102157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic constrained multiobjective optimization problems (DCMOPs) are characterized by the variations of both objectives and constraints over time, posing two main challenges: (1) balancing feasibility, convergence, and diversity in the evolutionary search and (2) generating an effective initial population for new environments. To address these problems, this paper proposes a dynamic constrained multiobjective evolutionary algorithm with feasibility-guided search and prediction (called FGSP), which integrates a feasibility-guided evolutionary search (FGES) and a feasible information guidance prediction (FIGP). Specifically, FGES adaptively adjusts evolutionary strategies by monitoring the proportion of infeasible solutions and a time-dependent tolerance threshold for infeasibility, such that it can perform exploration without constraints to navigate through large infeasible regions and conduct feasibility-driven exploitation to refine solutions near the constrained Pareto front, thereby balancing convergence, feasibility, and diversity. Concurrently, FIGP utilizes an artificial neural network trained on historically feasible solutions to predict a high-quality initial population for new environments, significantly accelerating adaptation to dynamic changes via pattern learned from past environments. After comparing the proposed FGSP with five state-of-the-art algorithms on the latest benchmark problems and one real-world problem, the experimental results validate the effectiveness of FGSP in obtaining feasible non-dominated solutions.},
  archive      = {J_SWEVO},
  author       = {Lisha Dong and Qianhui Wang and Qiongfang Liu and Junkai Ji and Ka-Chun Wong and Qiuzhen Lin},
  doi          = {10.1016/j.swevo.2025.102157},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102157},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Feasibility-guided search and prediction for dynamic constrained multiobjective evolutionary optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster and reinforcement learning-based multi-objective evolutionary algorithm for joint scheduling of virtual machines and prioritize tasks in cloud computing. <em>SWEVO</em>, <em>99</em>, 102156. (<a href='https://doi.org/10.1016/j.swevo.2025.102156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, cloud computing is considered an essential on-demand service that is facing an ongoing problem in Virtual Machine (VM) placement and task scheduling optimization that simultaneously improves server efficiency and user experience. Considering these challenges, this paper aims to reduce the makespan, cost, and total tardiness in Joint Scheduling of Virtual Machines and Prioritize Tasks (JSVPT) by a multi-objective optimization framework. We designed a novel Cluster-Based Multi-Objective Evolutionary Algorithm (MOEA-CD/RLPD) framework, which includes a three-tier encoding scheme with Reinforcement Learning (RL)-guided local search, preselection, and dynamic resource allocation strategy to solve the problem. To guide the search process, we employ K-means clustering to decompose the population into diverse subgroups, promoting balanced exploration. The pre-selection mechanism uses a classifier to identify promising solutions in the decision space, which allows resources to be used effectively. Reinforcement learning adaptively selects intensification operators based on reward feedback, improving exploitation by intensifying promising regions of the search space. An Improved Strength Pareto Evolutionary Algorithm 2 (ISPEA2) is incorporated to maintain a diverse and high-quality Pareto archive. The performance of the proposed algorithm is assessed on multiple test instances covering different scales and benchmarked against five state-of-the-art Multi-Objective Evolutionary Algorithms (MOEAs). Experimental studies demonstrate that the proposed algorithm outperforms most existing algorithms in the literature.},
  archive      = {J_SWEVO},
  author       = {Aanchal Agrawal and Arun Kumar Pal},
  doi          = {10.1016/j.swevo.2025.102156},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102156},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Cluster and reinforcement learning-based multi-objective evolutionary algorithm for joint scheduling of virtual machines and prioritize tasks in cloud computing},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAFSP with limited assembly buffers: A deadlock-free coding-decoding paradigm and hybrid cooperative co-evolutionary approach. <em>SWEVO</em>, <em>99</em>, 102155. (<a href='https://doi.org/10.1016/j.swevo.2025.102155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most prior studies on the Distributed Assembly Flowshop Scheduling Problem (DAFSP) presume infinite buffer capacity for assembly machines. However, in practical DAFSP, assembly buffers are often limited, potentially leading to a deadlock where buffers are full of jobs yet none of them can be assembled into a product. Since the deadlock in DAFSP is caused by incorrect jobs’ sequences in assembly buffers, we formulate a Petri net to model this entry process for the first time. Based on this Petri net model and improved Banker algorithm (IBA), we develop a polynomial-complexity algorithm IDAM to ensure the deadlock-free decoding of a DAFSP solution, which is coded by job and factory permutations. The makespan of such a solution is calculated backward to maintain its deadlock-free property. Furthermore, according to the proposed coding-decoding paradigm for deadlock-free solutions, we propose a hybrid cooperative co-evolution (HCCE) algorithm for DAFSP to minimize the makespan. Notably, our HCCE algorithm incorporates an elite archive (EAR) and two subpopulations. It employs problem-specific operators for heuristic initialization and global-search procedures, and four local-search operators are successively applied to every individual in the EAR. Finally, comprehensive experiments demonstrate the effectiveness and superiority of the proposed HCCE algorithm.},
  archive      = {J_SWEVO},
  author       = {Siyi Wang and Yanxiang Feng and Xiaoling Li and Guanghui Zhang},
  doi          = {10.1016/j.swevo.2025.102155},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102155},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DAFSP with limited assembly buffers: A deadlock-free coding-decoding paradigm and hybrid cooperative co-evolutionary approach},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective combination of mechanisms for particle swarm optimization-based ensemble strategy. <em>SWEVO</em>, <em>99</em>, 102154. (<a href='https://doi.org/10.1016/j.swevo.2025.102154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-quality ensemble strategy can effectively integrate several coefficients, mechanisms, and algorithms into a single framework. The adaptability, timing of intervention, and complementarity are the key factors to consider for the selected coefficients, mechanisms, and algorithms. In this study, two complementary variants based on Particle Swarm Optimization (PSO), namely Modified PSO (MPSO) and Social Learning PSO (SLPSO), were selected, forming IMPSO and ISLPSO after improvements. IMPSO excels at exploration, while ISLPSO excels at exploitation. The Improved Novel Ratio Adaptation Scheme (INRAS) is employed as a selection strategy and provides the ability to abandon less-optimal particles. The Modified Nonlinear Population Size Reduction (MNLPSR) enables the extension of generations, allowing for more sufficient evolution in later stages. Due to the use of MNLPSR, an improved inertia weight and adaptive acceleration coefficients are introduced to ensure compatibility with the proposed algorithm. Additionally, an improved dynamic differential mutation strategy is designed not only to be compatible with the proposed algorithm but also to enhance particle diversity. Both the Improved Sine Cosine Algorithm (ISCA) and Sequential Quadratic Programming (SQP), which focus on searching near the global best particles, are incorporated into the proposed ensemble strategy. This PSO-based variant is named the Effective Combination of Mechanisms for a PSO-based Ensemble Strategy (ECM-PSOES). Ablation experiments demonstrated the effectiveness of the individual coefficients and mechanisms. The novel PSO-based variant was evaluated on the CEC2017 benchmarks and compared with 14 state-of-the-art PSO-based variants and 11 non-PSO algorithms. Additionally, to evaluate the flexible and robust capability of the proposed algorithm, three real-world applications for long-term Transmission Network Expansion Planning (TNEP), Planetary Gear Train Design (PGTD), and Robot Gripper Design (RGD) were tested. The experimental results illustrate that the proposed algorithm displays superior performance compared to recently proposed PSO-based variants and most non-PSO algorithms. However, the proposed algorithm falls short of outperforming Differential Evolution (DE)-based algorithms and still requires time to match the performance of top-tier metaheuristics. The source code of ECM-PSOES is provided at https://github.com/microhard1999/CODES .},
  archive      = {J_SWEVO},
  author       = {Libin Hong and Zhantao Gu and Ruibin Bai and John Woodward and Ender Özcan},
  doi          = {10.1016/j.swevo.2025.102154},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102154},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An effective combination of mechanisms for particle swarm optimization-based ensemble strategy},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive weight optimization algorithm based on decision variable grouping for large-scale multi-objective optimization problems. <em>SWEVO</em>, <em>99</em>, 102149. (<a href='https://doi.org/10.1016/j.swevo.2025.102149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving large-scale multi-objective optimization problems (LSMOPs), the optimization effect of traditional multi-objective optimization algorithms deteriorates as the number of decision variables increases. The weight optimization method based on problem transformation can effectively address LSMOPs, demonstrating superior convergence compared to most evolutionary algorithms. However, existing problem transformation methods often fail to balance convergence and diversity, leading to get trapped in local optima. In order to effectively solve this problem, we propose an adaptive weight optimization algorithm based on variable grouping (GWOEA). The algorithm optimizes weights within groups to accelerate population convergence, while the adaptive control strategy boosts diversity, avoiding local optima and ensuring a balance between convergence and diversity during the optimization process. To reduce the size of solving LSMOPs, weight optimization is performed by grouping decision variables. The weights of variables within each group are first computed, and then these weights are directly optimized instead of the decision variables. The adaptive control strategy is designed to detect whether population evolution has stagnated and to handle stagnant populations, ensuring that the population retains its ability to explore. To evaluate the effectiveness of GWOEA, comprehensive comparative experiments are conducted on benchmark test problems, including variable sizes ranging from 500 to 5000. The results show that the proposed algorithm has relatively better optimization performance.},
  archive      = {J_SWEVO},
  author       = {Hao Wang and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.102149},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102149},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An adaptive weight optimization algorithm based on decision variable grouping for large-scale multi-objective optimization problems},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GTG-ACO: Graph transformer guided ant colony optimization for learning heuristics and pheromone dynamics for combinatorial optimization. <em>SWEVO</em>, <em>99</em>, 102147. (<a href='https://doi.org/10.1016/j.swevo.2025.102147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization (CO) problems are fundamental to numerous real-world applications, ranging from logistics and scheduling to resource allocation. For solving CO problems, Ant Colony Optimization (ACO) is a widely used metaheuristic that simulates cooperative foraging behavior to iteratively construct high-quality solutions. However, traditional ACO suffers from handcrafted heuristic functions that fail to generalize across different instances and uniform pheromone initialization, which results in inefficient exploration and slow convergence. To address these limitations, we introduce G raph T ransformer G uided A nt C olony O ptimization- GTG-ACO , a novel approach that jointly learns both heuristic and initial pheromone matrices, enabling the model to generalize across diverse problem instances without manual tuning. Additionally, GTG-ACO employs Graph Transformer augmented with Squeeze-and-Excitation (SE) network as the backbone for heuristic and pheromone learner. The Graph Transformers enable adaptive representation learning by leveraging attention mechanisms to dynamically capture structural relationships in graph representation of combinatorial optimization problems. Additionally, SE networks enhance the model by recalibrating feature importance, ensuring that critical information is amplified while suppressing less relevant features. Extensive evaluations on four combinatorial optimization problems—Traveling Salesman Problem (TSP), Capacitated Vehicle Routing Problem (CVRP), Single Machine Total Weighted Tardiness Problem (SMTWTP) and Bin Packing Problem (BPP)—demonstrate that GTG-ACO consistently outperforms state-of-the-art baselines achieving improvements ranging from 1% to 56%. Furthermore, we validate its real-world applicability by evaluating it on benchmark datasets TSPLIB and CVRPLIB. Thus, GTG-ACO establishes itself as a powerful and generalizable framework by jointly learning heuristic and pheromone matrices, enabling more informed exploration, which leads to superior solution quality in combinatorial optimization problems. Our code is publicly available at https://github.com/abrarrahmanabir/GTG-ACO .},
  archive      = {J_SWEVO},
  author       = {Abrar Rahman Abir and Muhammad Ali Nayeem and M. Sohel Rahman and Md Adnan Arefeen},
  doi          = {10.1016/j.swevo.2025.102147},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102147},
  shortjournal = {Swarm Evol. Comput.},
  title        = {GTG-ACO: Graph transformer guided ant colony optimization for learning heuristics and pheromone dynamics for combinatorial optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective multi-UAV path planning via evolutionary multitasking optimization with adaptive operator selection and knowledge fusion. <em>SWEVO</em>, <em>99</em>, 102145. (<a href='https://doi.org/10.1016/j.swevo.2025.102145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is crucial for UAV task execution, underpinning effective aerial reconnaissance and precision strikes. An ideal flight path must both minimize travel distance and reduce the risk of enemy detection or destruction. Due to the inherent trade-off between these objectives, multi-UAV path planning is conventionally formulated as a multiobjective optimization problem. However, as the number of obstacles, threats, and UAVs increases, the computational complexity escalates, hindering the generation of optimal path planning solutions via conventional multiobjective optimization approaches. To address this challenge, we model a multiobjective multi-UAV path planning (MOMUPP) problem that simultaneously optimizes flight distance and threat cost, with the latter quantified using line-of-sight theory and terrain occlusion effects. We further construct an auxiliary task that approximates the MOMUPP problem and develop an evolutionary multitasking framework to facilitate effective knowledge transfer between tasks. Building on this framework, we propose the evolutionary multitasking multiobjective path planning (EMMOP) algorithm. EMMOP incorporates a double deep Q-networks-based adaptive operator selection (DAOS) mechanism that dynamically selects the optimal search operators for each task based on the current evolutionary state, thereby generating high-quality offspring. Additionally, a knowledge transfer strategy based on directional information extraction and knowledge fusion (KTDF) enables efficient exchange of critical information between the main and auxiliary tasks. Experiments on 15 benchmark instances across five map scenarios indicate that EMMOP outperforms five state-of-the-art methods, enhancing hypervolume by 2.46% and pure diversity by 28.27%, while generating shorter, safer, and collision-free UAV paths with diverse trade-off solutions for decision-makers. The source code is available at https://github.com/Leopard125/EMMOP .},
  archive      = {J_SWEVO},
  author       = {Kai Meng and Binghong Wu and Bin Xin and Fang Deng and Chen Chen},
  doi          = {10.1016/j.swevo.2025.102145},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102145},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multiobjective multi-UAV path planning via evolutionary multitasking optimization with adaptive operator selection and knowledge fusion},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic performance evaluation of evolutionary multi-objective optimization algorithms for gait cycle optimization of a 25-DOFs NAO humanoid robot. <em>SWEVO</em>, <em>99</em>, 102144. (<a href='https://doi.org/10.1016/j.swevo.2025.102144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are increasingly using optimization methods to achieve optimal dynamic performance of humanoid robots, often involving multiple conflicting objectives. Multi-objective optimization algorithms (MOAs) aim to find a Pareto front of optimal solutions, but selecting the best algorithm based on solution quality and computational efficiency remains challenging. This study comprehensively evaluates MOAs from different paradigms: swarm intelligence (CMOPSO), genetic algorithms (NSGA-II, DCNSGA-III), and decomposition-based approaches (CMOEA/D) for optimizing the gait cycle of a 25 DOF NAO humanoid robot during single support phase (SSP) and double support phase (DSP) scenarios. The algorithms’ convergence, diversity, and constraint-handling capabilities are systematically analyzed in solving the gait generation problem. The bi-objective optimization simultaneously minimizes power consumption and maximizes dynamic stability subject to eight functional constraints with 12-13 decision parameters. Through performance evaluation using running inverted generational distance (IGD) and hypervolume (HV) metrics across eleven independent runs of each algorithm, NSGA-II emerges as the most suitable algorithm, demonstrating superior convergence and solution quality, while CMOPSO shows competitive performance with faster initial convergence. DCNSGA-III exhibits moderate performance with constraint-handling difficulties, and CMOEA/D demonstrates poor convergence characteristics requiring significantly more computational resources. Two distinct knee regions emerge during both SSP and DSP, representing optimal trade-off solutions, with a systematic framework provided for practitioners to select appropriate gait parameters based on operational priorities. The running IGD metric combined with HV validation demonstrates effectiveness in providing robust algorithmic insights, enabling practitioners to select suitable algorithms for similar complex real-world optimization problems.},
  archive      = {J_SWEVO},
  author       = {Pushpendra Gupta and Dilip Kumar Pratihar and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.102144},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102144},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Dynamic performance evaluation of evolutionary multi-objective optimization algorithms for gait cycle optimization of a 25-DOFs NAO humanoid robot},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive landscape-aware repelling restart covariance matrix adaptation-evolution strategy for multimodal and global optimization. <em>SWEVO</em>, <em>99</em>, 102143. (<a href='https://doi.org/10.1016/j.swevo.2025.102143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal optimization using Covariance Matrix Adaptation-Evolution Strategy (CMA-ES), redundant restarts are caused by repeated convergence to previously explored local basins, which leads to significant computational resource waste. To address this problem, previous research proposed the concept of Repelling Restart and developed RR-CMA-ES, but issues remain regarding rigid repulsion and gradient information of local basin structures. Building on this foundation, we propose an Adaptive Landscape-aware Repelling Restart CMA-ES (ALR-CMA-ES) that enhances the original RR-CMA-ES through three key improvements: 1) A fitness sensitive dynamic exclusion mechanism that adaptively adjusts tabu region radius based on local optimality and convergence frequency, prioritizing avoidance of high-quality basins; 2) A covariance matrix mechanism preserving convergence history to geometrically align hyper-ellipsoidal exclusion regions with explored local basin landscapes; 3) A Boltzmann-like probabilistic acceptance scheme incorporating exclusion regions, permit- ting controlled exploration near tabu boundaries. Experiments on the BBOB benchmark demonstrate that ALR-CMA-ES outperforms RR-CMA-ES in 90% of tested problems spanning 2D to 50D. This method provides a practical solution for expensive black-box optimization by systematically integrating landscape topology awareness into tabu mechanisms, while proposing a new solution for multimodal optimization problems.},
  archive      = {J_SWEVO},
  author       = {Xikang Wang and Tongxi Wang and Hua Xiang},
  doi          = {10.1016/j.swevo.2025.102143},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102143},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Adaptive landscape-aware repelling restart covariance matrix adaptation-evolution strategy for multimodal and global optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-learning classification-based multi-objective evolutionary algorithm for machine multi-state energy-efficient flexible job shop scheduling under time-of-use pricing. <em>SWEVO</em>, <em>99</em>, 102142. (<a href='https://doi.org/10.1016/j.swevo.2025.102142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the “dual carbon” strategic goals, the coordinated optimization of energy consumption and production efficiency has become a core issue for manufacturing industries. As an important means to promote energy structure transformation, electric substitution has made significant progress in industrial manufacturing, transportation, household electrification, and other fields. Among them, industrial production accounts for over 60% of the total electric energy substitution, becoming the largest electricity consumer. Note that the electricity price is based on time-of-use pricing (TOU), meanwhile, electric consumption is related to the machine multi-state (MM). Regarding these matters, this study focuses on determining sensible machine states and formulating reasonable production scheduling plan, to minimize both production time and power consumption. First, a novel energy-efficient flexible job shop scheduling problem is developed, which considers both the TOU strategy and the MM conditions (EFJSP-MM-TOU). Second, a self-learning classification-based multi-objective evolutionary algorithm (SCMOEA) is proposed to solve the EFJSP-MM-TOU. In specific, the SCMOEA enhances population diversity through a hybrid initialization strategy, adopts a dynamic selection of cross individuals based on the self-learning classification mechanism to improve the search efficiency, and designs four local search operators to increase the potential for approaching better positions. Third, by employing the MK standard dataset in EFJSP-MM-TOU, the proposed SCMOEA is compared with its three variants and five state-of-the-art algorithms to verify its optimization performance. The experimental results suggest that SCMOEA has advantages in terms of Pareto optimal solutions’ diversity and convergence. Finally, by testing in an actual enterprise case, the results further support the effectiveness of the EFJSP-MM-TOU and the significance of SCMOEA.},
  archive      = {J_SWEVO},
  author       = {Da Wang and Lina Qian and Kai Zhang and Dengwang Li and Shicun Zhao and Junqing Li},
  doi          = {10.1016/j.swevo.2025.102142},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102142},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A self-learning classification-based multi-objective evolutionary algorithm for machine multi-state energy-efficient flexible job shop scheduling under time-of-use pricing},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using genetic programming to improve data collection for offline reinforcement learning. <em>SWEVO</em>, <em>99</em>, 102140. (<a href='https://doi.org/10.1016/j.swevo.2025.102140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (RL) learns policies solely from fixed pre-collected datasets, making it applicable to use-cases where data collection is expensive or risky. Consequently, the performance of these offline learners is highly dependent on the dataset used. Still the questions of how this data is collected and what dataset characteristics are needed are not thoroughly investigated. Simultaneously, evolutionary methods have reemerged as a promising alternative to classic RL, leading to the field of evolutionary RL (EvoRL), combining the two learning paradigms to exploit their supplementary attributes. This study aims to join these research directions and examine the effects of Genetic Programming (GP) on dataset characteristics in RL and its potential to enhance the performance of offline RL algorithms. A comparative approach was employed, comparing Deep Q-Networks (DQN) and GP for data collection across multiple environments and collection modes. The exploration and exploitation capabilities of these methods were quantified and a comparative analysis was conducted to determine whether data collected through GP led to superior performance in multiple offline learners. The findings indicate that GP demonstrates strong and stable performance in generating high-quality experiences with competitive exploration. GP exhibited lower uncertainty in experience generation compared to DQN and produced high trajectory quality datasets across all environments. More offline algorithms showed statistically significant performance gains with GP-collected data than trained on DQN-collected trajectories. Furthermore, their performance was less dependent on the environment, as the GP consistently generated high-quality datasets. This study showcases the effective combination of GP's properties with offline learners, suggesting a promising avenue for future research in optimizing data collection for RL.},
  archive      = {J_SWEVO},
  author       = {David Halder and Georgios Douzas and Fernando Bacao},
  doi          = {10.1016/j.swevo.2025.102140},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102140},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Using genetic programming to improve data collection for offline reinforcement learning},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple direction search algorithm for continuous optimization. <em>SWEVO</em>, <em>99</em>, 102138. (<a href='https://doi.org/10.1016/j.swevo.2025.102138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The particle swarm optimization algorithm has been successfully applied to various optimization problems. One of its key features is the combination of particle velocity and search direction towards the optimal position in the history and swarm. Recognizing the limitations of the particle swarm optimization algorithm, this paper proposes a new evolutionary algorithm called the multiple direction search algorithm. The algorithm integrates five different search directions, including a multi-point direction constructed using principal component analysis. The integrated direction is generated by the weighted sum of the search directions. Theoretical analysis shows that under mild conditions, the rate of convergence along the weighted direction is no worse than the rate of convergence along the best of single search directions by a positive constant, or even faster in certain cases. The performance of the proposed algorithm was evaluated on three benchmark test suites by computer simulation. Experimental results demonstrate that the proposed method outperforms seven state-of-the-art particle swarm optimization algorithms.},
  archive      = {J_SWEVO},
  author       = {Wei Huang and Jun He and Liehuang Zhu},
  doi          = {10.1016/j.swevo.2025.102138},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102138},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A multiple direction search algorithm for continuous optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-tightening based adaptive two-stage evolutionary algorithm for constrained multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102137. (<a href='https://doi.org/10.1016/j.swevo.2025.102137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) are prevalent in practical applications, yet existing methods often struggle to handle their diverse characteristics, such as disconnected feasible regions and infeasible solutions near the true constraints Pareto front (CPF). To address these challenges, this paper proposes a constraint-tightening based adaptive two-stage evolutionary algorithm (CT-TSEA) for CMOPs, incorporating a constraint boundary tightening strategy and parameter dynamic adjustment strategy. In the first stage, a constraint boundary tightening strategy based on evaluation counts guides the population toward feasible regions. Initially, constraint boundaries are relaxed to explore the solution space thoroughly, identifying promising solutions. As evaluations increase, the search boundaries shrink, enhancing the feasibility of solutions. Additionally, a step-size adaptive adjustment method improves infeasible solutions using their information, boosting search efficiency and solution diversity. The second stage introduces a dynamic adjustment method for crossover probability and scaling factor, balancing exploration and exploitation. It better balances the exploration and exploitation capabilities of the population. The proposed method is validated via comparing with seven state-of-the-art peer competitors across 59 test instances from four benchmark suites and 21 real-world problems. The corresponding results demonstrate that CT-TSEA has the higher competitiveness in addressing complex CMOPs.},
  archive      = {J_SWEVO},
  author       = {Cunyan Liu and Qingda Chen and Junhua Liu and Wei Zhang and Meng Wang and Can Liu},
  doi          = {10.1016/j.swevo.2025.102137},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102137},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Constraint-tightening based adaptive two-stage evolutionary algorithm for constrained multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploratory landscape analysis on black-box optimization problems via graph neural network. <em>SWEVO</em>, <em>99</em>, 102136. (<a href='https://doi.org/10.1016/j.swevo.2025.102136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most real-world optimization problems are poorly understood, some of which are black-box optimization problems (BBOPs). Exploratory landscape analysis (ELA) paves the way for algorithm design to deal with BBOPs. Existing ELA methods have limitations on unseen problems and lack analysis on the problem itself. To this end, this study introduces a novel ELA framework leveraging Graph Neural Network (GNN) upon BBOP’s surrogate model. Specifically, a neural network surrogate model is constructed whose architecture is utilized to represent BBOP in the form of graph. Then, GNN is responsible for capturing the relationships between the graph-represented BBOP and high-level features. As one of the most notable features in optimization, multimodality of multi-objective problems is to be identified for illustration. More than 99% accuracy on independent test set demonstrates the effectiveness of the proposed framework with simultaneously avoiding the effect of problem dimensions.},
  archive      = {J_SWEVO},
  author       = {Xu Yang and Rui Wang and Kaiwen Li and Wenhua Li and Tao Zhang},
  doi          = {10.1016/j.swevo.2025.102136},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102136},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Exploratory landscape analysis on black-box optimization problems via graph neural network},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention-based joint value estimation strategy for multi-agent coordination optimization. <em>SWEVO</em>, <em>99</em>, 102132. (<a href='https://doi.org/10.1016/j.swevo.2025.102132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordination optimization plays a vital role in complex multi-agent systems, and Multi-Agent Reinforcement Learning (MARL) has emerged as a widely adopted solution. However, MARL still faces significant challenges in this domain, including low coordination efficiency and inaccurate value estimation. To address these issues, we propose MVAPO, a novel Multi-Head Joint Value Attention-based Policy Optimization algorithm that improves policy learning through enhanced value approximation and selective attention to agent contributions. The key innovation of MVAPO lies in the introduction of a joint value network augmented with a multi-head attention mechanism. In this mechanism, context-aware team rewards serve as query inputs, directing attention to the most relevant agents in different situations. This allows the model to dynamically focus on the agents that are most critical at any given time, thus improving coordination efficiency and the accuracy of value estimates. Furthermore, MVAPO incorporates feedforward and residual layers, eliminating linear and monotonic constraints, which significantly enhances its representational capacity. Extensive experiments on a multi-UAV benchmark across a variety of scenarios demonstrate that MVAPO consistently outperforms state-of-the-art methods in both reward acquisition and win rates, highlighting its superior performance and robustness.},
  archive      = {J_SWEVO},
  author       = {Ze Wang and Ni Li and Guanghong Gong and Haitao Yuan},
  doi          = {10.1016/j.swevo.2025.102132},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102132},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An attention-based joint value estimation strategy for multi-agent coordination optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA2MODE: Dynamic archive with adaptive multi-operator differential evolution for numerical optimization. <em>SWEVO</em>, <em>99</em>, 102130. (<a href='https://doi.org/10.1016/j.swevo.2025.102130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Dynamic Archive with Adaptive Multi-Operator Differential Evolution (DA2MODE), a new algorithm that aims to boost the performance of meta-heuristic and evolutionary methods in numerical optimization. DA2MODE introduces a Progressive Adaptive Selector with Exponential Smoothing (PASES), which dynamically updates the selection probabilities of both mutation and crossover operators. Unlike prior approaches that emphasize only mutation operators or rely on short-term success within the current generation, PASES adapts based on cumulative operator performance over time, thus favoring the best-performing operators more reliably. DA2MODE employs an Adaptive Non-Elite Archive Update (ANEAU) mechanism that injects a controlled fraction of non-elite solutions into the archive. ANEAU promotes early exploration, which is gradually reduced to strengthen exploitation. Additionally, the control parameters (crossover probability and mutation factor) are automatically tuned in DA2MODE, allowing full adaptivity of both operator selection and parameter control. Extensive experiments on the CEC2017/2018, CEC2020-2022, and 1000-dimensional CEC2013 benchmarks, along with four real-world engineering design problems, confirm that DA2MODE consistently outperforms 33 competitive algorithms, including CEC winners and recent advanced DE variants. It achieves top performance across all statistical tests, demonstrating superior convergence speed and final accuracy. These results establish DA2MODE as a robust, scalable, and reliable algorithm for solving complex numerical optimization problems. The source code of the DA2MODE algorithm is publicly available at: URL https://github.com/MohamedRedaMu/DA2MODE-Algorithm and URL https://uk.mathworks.com/matlabcentral/fileexchange/182019-da2mode-algorithm .},
  archive      = {J_SWEVO},
  author       = {Mohamed Reda and Ahmed Onsy and Amira Y. Haikal and Ali Ghanbari},
  doi          = {10.1016/j.swevo.2025.102130},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102130},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DA2MODE: Dynamic archive with adaptive multi-operator differential evolution for numerical optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale multi-objective optimization framework based on a dual-space attention mechanism. <em>SWEVO</em>, <em>99</em>, 102089. (<a href='https://doi.org/10.1016/j.swevo.2025.102089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing attention-based methods for large-scale multi-objective optimization (LMOAM) focus only on decision variables, using their variance to guide search behavior. However, single-space strategies ignore critical information in the objective space and the diversity and search efficiency are often degraded for solving multimodal multi-objective optimization problems (MOPs). To address this problem, a novel large-scale optimization framework that integrates a dual-space attention mechanism is proposed in this paper. Different from building attention only with information in decision space, a dual-space Key matrix that quantifies variable importance by combining decision-variable and objective-space distributions is first designed in the framework to refine the precision of the attention. Subsequently, a cross-space clustering method is adopted to select the representative solutions by analyzing the characteristics of individuals in both spaces to construct the Query matrix. The accuracy of attention allocation is improved. Finally, A linear inverse mapping strategy is used to enhance the diversity of the population by translating promising objective-space solutions back to the decision space. Unlike existing approaches, the characteristics of decision and objective space are linked with a new attention mechanism, and the exploration and exploitation of the population are well balanced. Three types of experiments are designed on two benchmark test sets with 500-dimensional and 1000-dimensional decision variables and the voltage transformer optimization problem to demonstrate the efficacy of the AIDF framework, experimental results indicate that AIDF surpasses comparative algorithms in terms of the average performance of IGD and HV.},
  archive      = {J_SWEVO},
  author       = {Xu Li and Debao Chen and Feng Zou and Fangzhen Ge and Zhenghua Xin},
  doi          = {10.1016/j.swevo.2025.102089},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102089},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A large-scale multi-objective optimization framework based on a dual-space attention mechanism},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PheroCom: Decentralised and asynchronous robot swarm coordination framework based on virtual pheromone and vibroacoustic communication. <em>SWEVO</em>, <em>99</em>, 102083. (<a href='https://doi.org/10.1016/j.swevo.2025.102083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing and controlling the dynamics of stigmergic substances used by bio-inspired approaches pose significant challenges when applied to robotics. In order to overcome this challenge, this work proposes a framework based on the virtualisation and control of these substances at a local scope, with the primary goal of coordinating robot swarms. This framework introduces a novel pheromone representation that enables decentralisation and decision asynchronicity, while its lightweight design ensures accessibility to resource-constrained platforms. Each robot maintains an independent virtual pheromone map in its memory, which is continuously updated through its own pheromone deposits and evaporation. Additionally, each robot’s pheromone map is also updated by aggregating information from other robots that are exploring nearby areas. Consequently, individual and independent maps eliminate the need for a centralised agent to manage and distribute pheromone information. This propagation mechanism is inspired by ants’ vibroacoustic communication, which is characterised as a form of indirect communication. The framework was evaluated using an agent-based mass simulation tool and a real-world simulation platform. Experiments were conducted to validate the framework in diverse environments, with variations in shapes, sizes, and the number of robots. Results demonstrated that this proposal can effectively perform the coordination of robot swarms, and the robots have exhibited satisfactory performance while executing the surveillance task.},
  archive      = {J_SWEVO},
  author       = {Claudiney R. Tinoco and Luiz Gustavo A. Martins and Gina M.B. Oliveira},
  doi          = {10.1016/j.swevo.2025.102083},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102083},
  shortjournal = {Swarm Evol. Comput.},
  title        = {PheroCom: Decentralised and asynchronous robot swarm coordination framework based on virtual pheromone and vibroacoustic communication},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tcs">TCS - 13</h2>
<ul>
<li><details>
<summary>
(2025). Complexity of the game connected domination problem. <em>TCS</em>, <em>1057</em>, 115559. (<a href='https://doi.org/10.1016/j.tcs.2025.115559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The connected domination game is a variant of the domination game where the played vertices must form a connected subgraph at all stages of the game. In this paper we prove that deciding whether the game connected domination number is smaller than a given integer is PSPACE-complete using log-space reductions for both Dominator- and Staller-start connected domination game.},
  archive      = {J_TCS},
  author       = {Vesna Iršič Chenoweth},
  doi          = {10.1016/j.tcs.2025.115559},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115559},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Complexity of the game connected domination problem},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A convergence technique for the game i-MARK. <em>TCS</em>, <em>1057</em>, 115557. (<a href='https://doi.org/10.1016/j.tcs.2025.115557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The game of i -MARK is an impartial combinatorial game introduced by Sopena (2016). The game is parametrized by two sets of positive integers S , D , where min D ≥ 2 . From position n ≥ 0 one can move to any position n − s , s ∈ S , as long as n − s ≥ 0 , as well as to any position n / d , d ∈ D , as long as n > 0 and d divides n . The game ends when no more moves are possible, and the last player to move is the winner. Sopena, and subsequently Friman and Nivasch (2021), characterized the Sprague–Grundy sequences of many cases of i -MARK ( S , D ) with | D | = 1 . Friman and Nivasch also obtained some partial results for the case i -MARK ( { 1 } , { 2 , 3 } ) . In this paper we present a convergence technique that gives polynomial-time algorithms for the Sprague–Grundy sequence of many instances of i -MARK with | D | > 1 . In particular, we prove our technique works for all games i -MARK ( { 1 } , { d 1 , d 2 } ) .},
  archive      = {J_TCS},
  author       = {Gabriel Nivasch and Oz Rubinstein},
  doi          = {10.1016/j.tcs.2025.115557},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115557},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A convergence technique for the game i-MARK},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 1-good-neighbour diagnosability of modified bubblesort graphs under the PMC and MM* models. <em>TCS</em>, <em>1057</em>, 115556. (<a href='https://doi.org/10.1016/j.tcs.2025.115556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modified bubblesort graph, denoted as M B n ( n ≥ 2 ) , is a noteworthy topological structure in the choice of interconnection networks. In this paper, we determine the h -extra connectivity of M B n . Additionally, we evaluate the 1-good-neighbor diagnosability of modified bubblesort graphs under the PMC and MM * models. Finally, we investigate the 1-good-neighbor non-inclusive diagnosability of M B n .},
  archive      = {J_TCS},
  author       = {Asghar A. Asgharian Sardroud and Mohsen Ghasemi and Shuming Zhou},
  doi          = {10.1016/j.tcs.2025.115556},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115556},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The 1-good-neighbour diagnosability of modified bubblesort graphs under the PMC and MM* models},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal gathering of robots in anonymous butterfly networks via leader election. <em>TCS</em>, <em>1057</em>, 115553. (<a href='https://doi.org/10.1016/j.tcs.2025.115553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots with very weak capabilities placed on the vertices of a graph are required to move toward a common vertex from where they do not move anymore. The task is known as the Gathering problem and it has been extensively studied in the last decade with respect to both general graphs and specific topologies. Most of the challenges faced are due to possible isometries observable from the placement of the robots with respect to the underlying topology. Rings, Grids, and Complete graphs are just a few examples of very regular topologies where the placement of the robots and suitable movements are crucial for succeeding in Gathering. Here we are interested in understanding what can be done in Butterfly graphs where really many isometries are present and most importantly unavoidable by any movement. We propose a Gathering algorithm for the so-called leader configurations, i.e., those where the initial placement of the robots admits the detection (and election) of one robot as the leader. We introduce a non-trivial technique to elect the leader which is of its own interest. We also prove that the proposed Gathering algorithm is asymptotically optimal in terms of synchronous rounds required.},
  archive      = {J_TCS},
  author       = {Serafino Cicerone and Alessia Di Fonso and Gabriele Di Stefano and Alfredo Navarra},
  doi          = {10.1016/j.tcs.2025.115553},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115553},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Optimal gathering of robots in anonymous butterfly networks via leader election},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient shape formation by 3D hybrid programmable matter: An algorithm for low diameter intermediate structures. <em>TCS</em>, <em>1057</em>, 115552. (<a href='https://doi.org/10.1016/j.tcs.2025.115552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the shape formation problem within the 3D hybrid model, where a single agent with a strictly limited viewing range and the computational capacity of a deterministic finite automaton manipulates passive tiles through pickup, movement, and placement actions. The goal is to reconfigure a set of tiles into a specific shape termed an icicle . The icicle, identified as a dense, hole-free structure, is strategically chosen to function as an intermediate shape for more intricate shape formation tasks. It is designed for easy exploration by a finite-state agent, enabling the identification of tiles that can be lifted without breaking connectivity. Compared to the line shape, the icicle presents distinct advantages, including a reduced diameter and the presence of multiple removable tiles. We propose an algorithm that transforms an arbitrary initially connected tile structure into an icicle in O ( n 3 ) steps, matching the runtime of the line formation algorithm from prior work. Our theoretical contribution is accompanied by an extensive experimental analysis, indicating that our algorithm decreases the diameter of tile structures on average.},
  archive      = {J_TCS},
  author       = {Kristian Hinnenthal and David Liedtke and Christian Scheideler},
  doi          = {10.1016/j.tcs.2025.115552},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115552},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient shape formation by 3D hybrid programmable matter: An algorithm for low diameter intermediate structures},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The grothendieck computability model. <em>TCS</em>, <em>1057</em>, 115550. (<a href='https://doi.org/10.1016/j.tcs.2025.115550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Translating notions and results from category theory to the theory of computability models of Longley and Normann, we introduce the Grothendieck computability model. We define the first-projection-simulation and prove its basic properties. With the Grothendieck computability model, the category of computability models is shown to be a type-category, in the sense of Pitts, a result that bridges the categorical interpretation of dependent types with the theory of computability models. We also show that the category of computability models is a category with 2-family arrows and a corresponding structure of Sigma-objects. Finally, we introduce the notion of a fibration and opfibration-simulation, and we prove that the first-projection-simulation is a split opfibration-simulation.},
  archive      = {J_TCS},
  author       = {Luis Gambarte and Iosif Petrakis},
  doi          = {10.1016/j.tcs.2025.115550},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115550},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The grothendieck computability model},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hop domination on subclasses of perfect graphs. <em>TCS</em>, <em>1057</em>, 115547. (<a href='https://doi.org/10.1016/j.tcs.2025.115547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set S ⊆ V ( G ) is said to be a hop dominating set if every vertex u ∈ V ( G ) ∖ S , there exists a vertex v ∈ S such that d ( u , v ) = 2 where d ( u , v ) represents the distance between u and v in G . Given a graph G , Hop Domination asks to find the minimum size of a hop dominating set of G , also called the hop domination number . Henning et al. (Graphs Combin. 2017) showed that Hop Domination is NP -hard for bipartite graphs and chordal graphs. Since the class of chordal graphs is contained in the class of perfect graphs, the problem is NP -hard on perfect graphs. We would like to study the complexity of the problem on subclasses of perfect graphs and understand where the complexity of the problem shifts from tractable to intractable. The following are the results of this paper. We present polynomial algorithms for Hop Domination on permutation graphs, interval graphs and biconvex bipartite graphs. This generalizes the polynomial time algorithm for Hop Domination on bipartite permutation graphs. We also initiate a study on this problem from the parameterized complexity perspective. We show that the decision version of Hop Domination is W [ 2 ] -hard when parameterized by solution size.},
  archive      = {J_TCS},
  author       = {D. Karthika and R. Muthucumaraswamy and Sriram Bhyravarapu and Pritesh Kumar},
  doi          = {10.1016/j.tcs.2025.115547},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115547},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hop domination on subclasses of perfect graphs},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tight length theorems for multiset extensions of higman’s lemma. <em>TCS</em>, <em>1057</em>, 115546. (<a href='https://doi.org/10.1016/j.tcs.2025.115546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-quasi-ordered (wqo) set generalizes the notion of well-foundedness and is a powerful tool for analyzing the complexity of computational problems through upper bounds on the length of controlled bad sequences, known as length theorems. The finitary multiset extension of a wqo-set induces an ordering on finite multisets over elements of that set, where one multiset precedes another if there exists an injective mapping between their elements that preserves the original ordering. In this work, we refine existing length theorems for the finitary multiset extension of Higman’s ordering over finite alphabets, and we establish a matching lower bound. As a corollary, we obtain tighter length bounds for the majoring extension of Higman’s ordering over finite alphabets. We demonstrate the application of our results in the complexity analysis of noncommutative hypersequent logics.},
  archive      = {J_TCS},
  author       = {Vitor Greati and Revantha Ramanayake},
  doi          = {10.1016/j.tcs.2025.115546},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115546},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tight length theorems for multiset extensions of higman’s lemma},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A note on busy beaver bounds. <em>TCS</em>, <em>1057</em>, 115541. (<a href='https://doi.org/10.1016/j.tcs.2025.115541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the relationship between several variations of the Busy Beaver game proposed by Radó (1962), such as the s p a c e ( n ) or the n u m ( n ) functions, establishing new bounds on these functions in terms of each other, as well as some properties about their growth. We also introduce and investigate a new function, b o u n c e s ( n ) , to this family of noncomputable functions. We give some specific values for b o u n c e s ( n ) , as well as several results concerning its growth and its relationship to the previously studied Busy Beaver functions. We also investigate growth properties and relationships of these functions when considering Turing Machines with non-binary alphabets with a single blank symbol.},
  archive      = {J_TCS},
  author       = {Tomás Schitter and Sergio Abriola and Nicolás González},
  doi          = {10.1016/j.tcs.2025.115541},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115541},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A note on busy beaver bounds},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On shuffling and splitting automata. <em>TCS</em>, <em>1057</em>, 115539. (<a href='https://doi.org/10.1016/j.tcs.2025.115539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of finite state three-tape transducers which models the operation of shuffling and splitting words. We present them as automata over the so-called Shuffling Monoid. These automata can be seen as either shufflers or splitters interchangeably. We prove that functionality is decidable for splitters, and we also show that the equivalence between functional splitters is decidable. Moreover, in the deterministic case, the algorithm for equivalence is polynomial on the number of states of the splitter.},
  archive      = {J_TCS},
  author       = {Ignacio Mollo Cunningham},
  doi          = {10.1016/j.tcs.2025.115539},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115539},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On shuffling and splitting automata},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-criteria sublinear time algorithms for clustering with outliers in high dimensions. <em>TCS</em>, <em>1057</em>, 115538. (<a href='https://doi.org/10.1016/j.tcs.2025.115538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world datasets often contain outliers, and the presence of outliers can make clustering problems be much more challenging. Existing algorithms for clustering with outliers often have high computational complexities. In this paper, we propose a simple yet effective sublinear framework for solving the representative center-based clustering with outliers problems: k -median/means clustering with outliers. Our analysis is fundamentally different from the previous (uniform and non-uniform) sampling based ideas. In particular, our sample complexity is independent of the input size and dimensionality, and thus it is suitable for dealing with large-scale and high-dimensional datasets. We also conduct a set of experiments to evaluate the effectiveness of our proposed method on both synthetic and real datasets.},
  archive      = {J_TCS},
  author       = {Jiawei Huang and Wenjie Liu and Hu Ding},
  doi          = {10.1016/j.tcs.2025.115538},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115538},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bi-criteria sublinear time algorithms for clustering with outliers in high dimensions},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategy templates for almost-sure and positive winning of stochastic parity games towards permissive and resilient control. <em>TCS</em>, <em>1057</em>, 115535. (<a href='https://doi.org/10.1016/j.tcs.2025.115535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic games are fundamental in various applications, including the control of cyber-physical systems (CPS), where both controller and environment are modeled as players. Traditional algorithms typically aim to determine a single winning strategy to develop a controller. However, in CPS control and other domains, permissive controllers are essential, as they enable the system to adapt when additional constraints arise and remain resilient to runtime changes. This work generalizes the concept of (permissive winning) strategy templates , originally introduced by Anand et al. at TACAS and CAV 2023 for deterministic games, to incorporate stochastic games. These templates capture an infinite number of winning strategies, allowing for efficient strategy adaptation to system changes. We focus on two winning criteria (almost-sure and positive winning) and five winning objectives (safety, reachability, Büchi, co-Büchi, and parity). Our contributions include algorithms for constructing templates for each winning criterion and objective and a novel approach for extracting a winning strategy from a given template. Discussions on comparisons between templates and between strategy extraction methods are provided.},
  archive      = {J_TCS},
  author       = {Kittiphon Phalakarn and Sasinee Pruekprasert and Ichiro Hasuo},
  doi          = {10.1016/j.tcs.2025.115535},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115535},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Strategy templates for almost-sure and positive winning of stochastic parity games towards permissive and resilient control},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The diagnosability of multiprocessor systems under the enhanced comparison model. <em>TCS</em>, <em>1057</em>, 115534. (<a href='https://doi.org/10.1016/j.tcs.2025.115534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosability of a multiprocessor system G is a fundamental topic. The g -extra diagnosability of G requires that every fault-free component in G − F has at least g + 1 vertices, while the g -good-neighbor diagnosability requires that every fault-free vertex has at least g fault-free neighbors. In this paper, we first propose a new model, the enhanced comparison (EC) model on G , and establish the relationship between the g -extra diagnosability and the g -good-neighbor diagnosability of G . Second, we present and prove necessary and sufficient conditions for the g -extra diagnosability of G , and determine the g -extra diagnosability of the hyper Petersen network. Finally, we present and prove necessary and sufficient conditions for the g -good-neighbor diagnosability of G , and determine the g -good-neighbor diagnosability of the star graph.},
  archive      = {J_TCS},
  author       = {Shiying Wang and Wei Feng},
  doi          = {10.1016/j.tcs.2025.115534},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115534},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The diagnosability of multiprocessor systems under the enhanced comparison model},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
