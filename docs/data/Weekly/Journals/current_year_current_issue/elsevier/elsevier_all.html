<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>elsevier</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij">AIJ - 24</h2>
<ul>
<li><details>
<summary>
(2025). Unsupervised sentence selection for creating a representative corpus in turkish: An active learning approach. <em>AIJ</em>, <em>348</em>, 104422. (<a href='https://doi.org/10.1016/j.artint.2025.104422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, active learning methods adapted for sentence selection of Turkish sentences are evaluated through language learning with neural models. Turkish is an agglutinative language with a complex morphology, where the linguistic properties of words are encoded in suffixes. The active learning methods based on regression, clustering, language models, distance metrics, and neural networks are applied to unlabeled sentence selection. In this respect, a sentence corpus is selected from a larger corpus, with the same number of samples for each target word in intrinsic and extrinsic evaluation tasks. The selected sentences are used for the training of SkipGram, CBOW, and self-attention LSTM language models and extracted embeddings are evaluated by the semantic analogy, POS and sentiment analysis tasks. The evaluation scores of the models trained on the samples selected by the active learning method are compared. The results of the selected sentences based on language models indicate an improvement over random selection based on a static vocabulary. These results also show that the selection affects the quality of unsupervised word embedding extraction even if the target vocabulary is kept the same. Along with the accuracy, the time efficiency of the language models is shown to be better than other methods especially methods based on neural network models, and distance metrics.},
  archive      = {J_AIJ},
  author       = {Hayri Volkan Agun},
  doi          = {10.1016/j.artint.2025.104422},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104422},
  shortjournal = {Artif. Intell.},
  title        = {Unsupervised sentence selection for creating a representative corpus in turkish: An active learning approach},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learngene: Inheritable “genes” in intelligent agents. <em>AIJ</em>, <em>348</em>, 104421. (<a href='https://doi.org/10.1016/j.artint.2025.104421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological intelligence has driven significant progress in artificial intelligence (AI), but a critical gap remains: biological systems inherit innate abilities from genes, with brains initialized by blueprints refined over 3.5 billion years of evolution, while machines rely heavily on inefficient, data-driven learning from scratch. This gap arises from the lack of a genetic mechanism in machines to transfer and accumulate inheritable knowledge across generations. To bridge this gap, we propose learngenes, network fragments that act as inheritable “genes” for machines. Unlike conventional knowledge transfer methods, learngenes enable efficient and universal knowledge transfer by selectively encapsulating task-agnostic knowledge. To facilitate the transfer and accumulation of task-agnostic knowledge across generations, we introduce Genetic Reinforcement Learning (GRL), a framework that simulates the learning and evolution of organisms in intelligent agents following Lamarckian principles. Through GRL, we identify learngenes as network fragments within agents' policy networks, equipping newborn agents with innate abilities for rapid adaptation to novel tasks. We demonstrate the advantages of learngene-based knowledge transfer over evolution-based search and traditional pre-trained models, and show how learngenes evolve through the accumulation of task-agnostic knowledge. Overall, this work establishes a novel paradigm for knowledge transfer and model initialization in AI, offering new possibilities for more adaptive, efficient, and scalable learning systems.},
  archive      = {J_AIJ},
  author       = {Fu Feng and Jing Wang and Xu Yang and Xin Geng},
  doi          = {10.1016/j.artint.2025.104421},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104421},
  shortjournal = {Artif. Intell.},
  title        = {Learngene: Inheritable “genes” in intelligent agents},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging theory and practice in bidirectional heuristic search with front-to-end consistent heuristics. <em>AIJ</em>, <em>348</em>, 104420. (<a href='https://doi.org/10.1016/j.artint.2025.104420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research on bidirectional heuristic search (BiHS) has been shaped by the must-expand pairs (MEP) theory, which identifies the pairs of nodes that must be expanded to ensure solution optimality. Another line of research has focused on algorithms utilizing lower bounds derived from consistent heuristics during the search. This paper bridges these two approaches, offering a unified framework that demonstrates how both existing and novel algorithms can be derived from MEP theory. We introduce an extended set of bounds, encompassing both previously known and newly formulated ones. Using these bounds, we develop a range of algorithms, each employing different criteria for termination, node selection, and search direction. Finally, we empirically evaluate how these bounds and algorithms impact search efficiency.},
  archive      = {J_AIJ},
  author       = {Lior Siag and Shahaf S. Shperberg},
  doi          = {10.1016/j.artint.2025.104420},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104420},
  shortjournal = {Artif. Intell.},
  title        = {Bridging theory and practice in bidirectional heuristic search with front-to-end consistent heuristics},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimax off-policy evaluation and learning with subgaussian and differentiable importance weighting. <em>AIJ</em>, <em>348</em>, 104419. (<a href='https://doi.org/10.1016/j.artint.2025.104419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the statistical properties of the off-policy estimation problem, i.e., estimating expectations under a target policy using samples collected from a different policy. We begin by presenting a novel minimax concentration lower bound that highlights the fundamental limits of off-policy estimation. We then analyze two well-known importance weighting (IW) techniques: vanilla IW and self-normalized importance weighting (SN). For both methods, we derive concentration and anti-concentration results, showing that their concentration rates are provably suboptimal compared to our lower bound. Observing that this undesired behavior arises from the heavy-tailed nature of the IW and SN estimators, we propose a new class of parametric estimators based on a transformation using the power mean (PM), which is no longer heavy-tailed. We study the theoretical properties of the PM estimator in terms of bias and variance. We show that, with suitable (possibly data-driven) tuning of its parameters, the PM estimator satisfies two key properties under certain conditions: ( i ) it achieves a subgaussian concentration rate that matches our lower bound and ( ii ) it maintains differentiability with respect to the target policy. Finally, we validate our approach through numerical simulations on both synthetic datasets and contextual bandits, comparing it against standard off-policy evaluation and learning baselines. 1},
  archive      = {J_AIJ},
  author       = {Alberto Maria Metelli and Alessio Russo and Marcello Restelli},
  doi          = {10.1016/j.artint.2025.104419},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104419},
  shortjournal = {Artif. Intell.},
  title        = {Minimax off-policy evaluation and learning with subgaussian and differentiable importance weighting},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the disjunctive rational closure of a conditional knowledge base. <em>AIJ</em>, <em>348</em>, 104418. (<a href='https://doi.org/10.1016/j.artint.2025.104418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most widely investigated decision problems in symbolic AI is that of which conditional sentences of the form “if α , then normally β ” should follow from a knowledge base containing this type of statements. Probably, the most notable approach to this problem is the rational closure construction put forward by Lehmann and Magidor in the'90s, which has been adapted to logical languages of various expressive powers since then. At the core of rational closure is the Rational Monotonicity property, which allows one to retain existing (defeasible) conclusions whenever new information cannot be negated by existing conclusions. As it turns out, Rational Monotonicity is not universally accepted, with many researchers advocating the investigation of weaker versions thereof leading to a larger class of consequence relations. A case in point is that of the Disjunctive Rationality property, which states that if one may draw a (defeasible) conclusion from a disjunction of premises, then one should be able to draw this conclusion from at least one of the premises taken alone. While there are convincing arguments that the rational closure forms the ‘simplest’ rational consequence relation extending a given set of conditionals, the question of what the simplest disjunctive consequence relation in this setting is has not been explored in depth. In this article, we do precisely that by motivating and proposing a concrete construction of the disjunctive rational closure of a conditional knowledge base, of which the properties and consequences of its adoption we also investigate in detail. (Previous versions of this work have been selected for presentation at the 18th International Workshop on Nonmonotonic Reasoning (NMR 2020) [1] and at the 35th AAAI Conference on Artificial Intelligence (AAAI 2021) [2] . The present submission extends and elaborates on both papers.)},
  archive      = {J_AIJ},
  author       = {Richard Booth and Ivan Varzinczak},
  doi          = {10.1016/j.artint.2025.104418},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104418},
  shortjournal = {Artif. Intell.},
  title        = {On the disjunctive rational closure of a conditional knowledge base},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking visual prompt learning as masked visual token modeling. <em>AIJ</em>, <em>348</em>, 104417. (<a href='https://doi.org/10.1016/j.artint.2025.104417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt learning has achieved great success in efficiently exploiting large-scale pre-trained models in natural language processing (NLP). It reformulates the downstream tasks as the generative pre-training ones to achieve consistency, thus improving the performance stably. However, when transferring it to the vision area, current visual prompt learning methods are almost designed on discriminative pre-trained models, and there is also a lack of careful design to unify the forms of pre-training and downstream tasks. To explore prompt learning on the generative pre-trained visual model, as well as keeping the task consistency, we propose Visual Prompt learning as masked visual Token Modeling (VPTM) to transform the downstream visual classification task into the pre-trained masked visual token prediction task. In addition, we develop the prototypical verbalizer for mapping the predicted visual token with implicit semantics to explicit downstream labels. To our best knowledge, VPTM is the first visual prompt method on the generative pre-trained visual model, which achieves consistency between pre-training and downstream visual classification by task reformulation. Experiments show that VPTM outperforms other visual prompt methods and achieves excellent efficiency. Moreover, the task consistency of VPTM contributes to the robustness against prompt location, prompt length and prototype dimension, and could be deployed uniformly.},
  archive      = {J_AIJ},
  author       = {Ning Liao and Bowen Shi and Xiaopeng Zhang and Min Cao and Junchi Yan and Qi Tian},
  doi          = {10.1016/j.artint.2025.104417},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104417},
  shortjournal = {Artif. Intell.},
  title        = {Rethinking visual prompt learning as masked visual token modeling},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Planning for temporally extended goals in pure-past linear temporal logic. <em>AIJ</em>, <em>348</em>, 104409. (<a href='https://doi.org/10.1016/j.artint.2025.104409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study planning for temporally extended goals expressed in Pure-Past Linear Temporal Logic ( ppltl ) in the context of deterministic (i.e., classical) and fully observable nondeterministic (FOND) domains. ppltl is the variant of Linear-time Temporal Logic on finite traces ( ltl f ) that refers to the past rather than the future. Although ppltl is as expressive as ltl f , we show that it is computationally much more effective for planning. In particular, we show that checking the validity of a plan for a ppltl formula is Markovian. This is achieved by introducing a linear number of additional propositional variables that capture the validity of the entire formula in a modular fashion. The solution encoding introduces only a linear number of new fluents proportional to the size of the ppltl goal and does not require any additional spurious action. We implement our solution technique in a system called Plan4Past , which can be used alongside state-of-the-art classical and FOND planners. Our empirical analysis demonstrates the practical effectiveness of Plan4Past in both classical and FOND problems, showing that the resulting planner performs overall better than other planning approaches for ltl f goals.},
  archive      = {J_AIJ},
  author       = {Luigi Bonassi and Giuseppe De Giacomo and Marco Favorito and Francesco Fuggitti and Alfonso Emilio Gerevini and Enrico Scala},
  doi          = {10.1016/j.artint.2025.104409},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104409},
  shortjournal = {Artif. Intell.},
  title        = {Planning for temporally extended goals in pure-past linear temporal logic},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incentives for responsiveness, instrumental control and impact. <em>AIJ</em>, <em>348</em>, 104408. (<a href='https://doi.org/10.1016/j.artint.2025.104408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce three concepts that describe an agent's incentives: response incentives indicate which variables in the environment, such as sensitive demographic information, affect the decision under the optimal policy. Instrumental control incentives indicate whether an agent's policy is chosen to manipulate part of its environment, such as the preferences or instructions of a user. Impact incentives indicate which variables an agent will affect, intentionally or otherwise. For each concept, we establish sound and complete graphical criteria, and discuss general classes of techniques that may be used to produce incentives for safe and fair agent behaviour. Finally, we outline how these notions may be generalised to multi-decision settings. This journal paper extends our conference publication “Agent Incentives: A Causal Perspective”: the material on response incentives and instrumental control incentives is updated, while the work on impact incentives and multi-decision settings is entirely new.},
  archive      = {J_AIJ},
  author       = {Ryan Carey and Eric Langlois and Chris van Merwijk and Shane Legg and Tom Everitt},
  doi          = {10.1016/j.artint.2025.104408},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104408},
  shortjournal = {Artif. Intell.},
  title        = {Incentives for responsiveness, instrumental control and impact},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abstracting situation calculus action theories. <em>AIJ</em>, <em>348</em>, 104407. (<a href='https://doi.org/10.1016/j.artint.2025.104407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a general framework for agent abstraction based on the situation calculus and the ConGolog agent programming language. We assume that we have a high-level specification and a low-level specification of the agent, both represented as basic action theories. A refinement mapping specifies how each high-level action is implemented by a low-level ConGolog program and how each high-level fluent can be translated into a low-level formula. We define a notion of sound abstraction between such action theories in terms of the existence of a suitable bisimulation between their respective models. Sound abstractions have many useful properties that ensure that we can reason about the agent's actions (e.g., executability, projection, and planning) at the abstract level, and refine and concretely execute them at the low level. We also characterize the notion of complete abstraction where all actions (including exogenous ones) that the high level thinks can happen can in fact occur at the low level. To facilitate verifying that one has a sound/complete abstraction relative to a mapping, we provide a set of necessary and sufficient conditions. Finally, we identify a set of basic action theory constraints that ensure that for any low-level action sequence, there is a unique high-level action sequence that it refines. This allows us to track/monitor what the low-level agent is doing and describe it in abstract terms (i.e., provide high-level explanations, for instance, to a client or manager).},
  archive      = {J_AIJ},
  author       = {Bita Banihashemi and Giuseppe De Giacomo and Yves Lespérance},
  doi          = {10.1016/j.artint.2025.104407},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104407},
  shortjournal = {Artif. Intell.},
  title        = {Abstracting situation calculus action theories},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards optimal subsidy bounds for envy-freeable allocations. <em>AIJ</em>, <em>348</em>, 104406. (<a href='https://doi.org/10.1016/j.artint.2025.104406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fair division of indivisible items with subsidies among n agents, where the absolute marginal valuation of each item is at most one. Under monotone nondecreasing valuations (where each item is a good), Brustle et al. [9] demonstrated that a maximum subsidy of 2 ( n − 1 ) and a total subsidy of 2 ( n − 1 ) 2 are sufficient to guarantee the existence of an envy-freeable allocation. In this paper, we improve upon these bounds, even in a wider model. Namely, we show that, given an EF1 allocation, we can compute in polynomial time an envy-free allocation with a subsidy of at most n − 1 per agent and a total subsidy of at most n ( n − 1 ) / 2 . Moreover, when the valuations are monotone nondecreasing, we provide a polynomial-time algorithm that computes an envy-free allocation with a subsidy of at most n − 1.5 per agent and a total subsidy of at most ( n 2 − n − 1 ) / 2 .},
  archive      = {J_AIJ},
  author       = {Yasushi Kawase and Kazuhisa Makino and Hanna Sumita and Akihisa Tamura and Makoto Yokoo},
  doi          = {10.1016/j.artint.2025.104406},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104406},
  shortjournal = {Artif. Intell.},
  title        = {Towards optimal subsidy bounds for envy-freeable allocations},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local-MIP: Efficient local search for mixed integer programming. <em>AIJ</em>, <em>348</em>, 104405. (<a href='https://doi.org/10.1016/j.artint.2025.104405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed Integer Programming (MIP) is a fundamental model in operations research with broad industrial applications. Local search is a powerful methodology for solving complex optimization problems; however, the development of local search algorithms for MIP still needs exploration. In this work, we propose Local-MIP , an efficient local search algorithm tailored for MIP that integrates novel operators and employs a two-mode architecture to adaptively apply operators based on the current solution's feasibility. For the feasible mode, we propose the lift move operator and a corresponding lift process to improve the objective value while maintaining feasibility. For the infeasible mode, we propose the breakthrough move and mixed tight move operators to respectively optimize the objective function and satisfy constraints. To apply operators intelligently, we develop a dynamic weighting scheme that balances the priorities of the objective function and constraints. Furthermore, we propose a two-level scoring function structure that hierarchically selects operations, guiding the search toward high-quality feasible solutions. Experiments are conducted on public benchmarks to compare Local-MIP with state-of-the-art MIP solvers in finding high-quality solutions. The results show that Local-MIP significantly outperforms CPLEX , HiGHS , SCIP , and Feasibility Jump while remaining competitive with the commercial solver Gurobi on challenging problems within short time limits. Moreover, Local-MIP establishes 10 new records on MIPLIB open instances.},
  archive      = {J_AIJ},
  author       = {Peng Lin and Shaowei Cai and Mengchuan Zou and Jinkun Lin},
  doi          = {10.1016/j.artint.2025.104405},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104405},
  shortjournal = {Artif. Intell.},
  title        = {Local-MIP: Efficient local search for mixed integer programming},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Centralized training with hybrid execution in multi-agent reinforcement learning via predictive observation imputation. <em>AIJ</em>, <em>348</em>, 104404. (<a href='https://doi.org/10.1016/j.artint.2025.104404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study hybrid execution in multi-agent reinforcement learning (MARL), a paradigm where agents aim to complete cooperative tasks with arbitrary communication levels at execution time by taking advantage of information-sharing among the agents. Under hybrid execution, the communication level can range from a setting in which no communication is allowed between agents (fully decentralized), to a setting featuring full communication (fully centralized), but the agents do not know beforehand which communication level they will encounter at execution time. We contribute MARO, an approach that makes use of an auto-regressive predictive model, trained in a centralized manner, to estimate missing agents' observations at execution time. We evaluate MARO on standard scenarios and extensions of previous benchmarks tailored to emphasize the impact of partial observability in MARL. Experimental results show that our method consistently outperforms relevant baselines, allowing agents to act with faulty communication while successfully exploiting shared information.},
  archive      = {J_AIJ},
  author       = {Pedro P. Santos and Diogo S. Carvalho and Miguel Vasco and Alberto Sardinha and Pedro A. Santos and Ana Paiva and Francisco S. Melo},
  doi          = {10.1016/j.artint.2025.104404},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104404},
  shortjournal = {Artif. Intell.},
  title        = {Centralized training with hybrid execution in multi-agent reinforcement learning via predictive observation imputation},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algebras of actions in an agent's representations of the world. <em>AIJ</em>, <em>348</em>, 104403. (<a href='https://doi.org/10.1016/j.artint.2025.104403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning efficient representations allows robust processing of data, data that can then be generalised across different tasks and domains, and it is thus paramount in various areas of Artificial Intelligence, including computer vision, natural language processing and reinforcement learning, among others. Within the context of reinforcement learning, we propose in this paper a mathematical framework to learn representations by extracting the algebra of the transformations of worlds from the perspective of an agent. As a starting point, we use our framework to reproduce representations from the symmetry-based disentangled representation learning (SBDRL) formalism proposed by [1] and prove that, although useful, they are restricted to transformations that respond to the properties of algebraic groups. We then generalise two important results of SBDRL –the equivariance condition and the disentangling definition– from only working with group-based symmetry representations to working with representations capturing the transformation properties of worlds for any algebra, using examples common in reinforcement learning and generated by an algorithm that computes their corresponding Cayley tables. Finally, we combine our generalised equivariance condition and our generalised disentangling definition to show that disentangled sub-algebras can each have their own individual equivariance conditions, which can be treated independently, using category theory. In so doing, our framework offers a rich formal tool to represent different types of symmetry transformations in reinforcement learning, extending the scope of previous proposals and providing Artificial Intelligence developers with a sound foundation to implement efficient applications.},
  archive      = {J_AIJ},
  author       = {Alexander Dean and Eduardo Alonso and Esther Mondragón},
  doi          = {10.1016/j.artint.2025.104403},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104403},
  shortjournal = {Artif. Intell.},
  title        = {Algebras of actions in an agent's representations of the world},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cooperativity in controlled query evaluation over ontologies. <em>AIJ</em>, <em>348</em>, 104402. (<a href='https://doi.org/10.1016/j.artint.2025.104402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlled Query Evaluation (CQE) is a methodology designed to maintain confidentiality by either rejecting specific queries or adjusting responses to safeguard sensitive information. In this investigation, our focus centers on CQE within Description Logic ontologies, aiming to ensure that queries are answered truthfully as long as possible before resorting to deceptive responses, a cooperativity property which is called the “longest honeymoon”. Our work introduces new semantics for CQE, denoted as MC-CQE, which enjoys the longest honeymoon property and outperforms previous methodologies in terms of cooperativity. We study the complexity of query answering in this new framework for ontologies expressed in the Description Logic DL-Lite R . Specifically, we establish data complexity results under different maximally cooperative semantics and for different classes of queries. Our results identify both tractable and intractable cases. In particular, we show that the evaluation of Boolean unions of conjunctive queries is the same under all the above semantics and its data complexity is in . This result makes query answering amenable to SQL query rewriting. However, this favorable property does not extend to open queries, even with a restricted query language limited to conjunctions of atoms. While, in general, answering open queries in the MC-CQE framework is intractable, we identify a sub-family of semantics under which answering full conjunctive queries is tractable.},
  archive      = {J_AIJ},
  author       = {Piero Bonatti and Gianluca Cima and Domenico Lembo and Francesco Magliocca and Lorenzo Marconi and Riccardo Rosati and Luigi Sauro and Domenico Fabio Savo},
  doi          = {10.1016/j.artint.2025.104402},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104402},
  shortjournal = {Artif. Intell.},
  title        = {Enhancing cooperativity in controlled query evaluation over ontologies},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BATED: Learning fair representation for pre-trained language models via biased teacher-guided disentanglement. <em>AIJ</em>, <em>348</em>, 104401. (<a href='https://doi.org/10.1016/j.artint.2025.104401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Pre-trained Language Models (PLMs) and their widespread deployment in various real-world applications, social biases of PLMs have attracted increasing attention, especially the fairness of downstream tasks, which potentially affects the development and stability of society. Among existing debiasing methods, intrinsic debiasing methods are not necessarily effective when applied to downstream tasks, and the downstream fine-tuning process may introduce new biases or catastrophic forgetting. Most extrinsic debiasing methods rely on sensitive attribute words as prior knowledge to supervise debiasing training. However, it is difficult to collect sensitive attribute information of real data due to privacy and regulation. Moreover, limited sensitive attribute words may lead to inadequate debiasing training. To this end, this paper proposes a debiasing method to learn fair representation for PLMs via B i A sed TE acher-guided D isentanglement (called BATED ). Specific to downstream tasks, BATED performs debiasing training under the guidance of a biased teacher model rather than relying on sensitive attribute information of the training data. First, we leverage causal contrastive learning to train a task-agnostic general biased teacher model. We then employ Variational Auto-Encoder (VAE) to disentangle the PLM-encoded representation into the fair representation and the biased representation. The Biased representation is further decoupled via biased teacher-guided disentanglement, while the fair representation learn downstream tasks. Therefore, BATED guarantees the performance of downstream tasks while improving the fairness. Experimental results on seven PLMs testing three downstream tasks demonstrate that BATED outperforms the state-of-the-art overall in terms of fairness and performance on downstream tasks.},
  archive      = {J_AIJ},
  author       = {Yingji Li and Mengnan Du and Rui Song and Mu Liu and Ying Wang},
  doi          = {10.1016/j.artint.2025.104401},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104401},
  shortjournal = {Artif. Intell.},
  title        = {BATED: Learning fair representation for pre-trained language models via biased teacher-guided disentanglement},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On preference learning based on sequential bayesian optimization with pairwise comparison. <em>AIJ</em>, <em>348</em>, 104400. (<a href='https://doi.org/10.1016/j.artint.2025.104400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User preference learning is generally a hard problem. Individual preferences are typically unknown even to users themselves, while the space of choices is infinite. Here we study user preference learning from information-theoretic perspective. We model preference learning as a system with two interacting sub-systems, one representing a user with his/her preferences and another one representing an agent that has to learn these preferences. The user with his/her behavior is modeled by a parametric preference function. To efficiently learn the preferences and reduce search space quickly, we propose the agent that interacts with the user to collect the most informative data for learning. The agent presents two proposals to the user for evaluation, and the user rates them based on his/her preference function. We show that the optimum agent strategy for data collection and preference learning is a result of maximin optimization of the normalized weighted Kullback-Leibler (KL) divergence between true and agent-assigned predictive user response distributions. The resulting value of the KL-divergence, which we also call of a remaining system uncertainty (RSU), provides an efficient performance metric in the absence of the ground truth. This metric characterizes how well the agent can predict user and, thus, the quality of the underlying learned user (preference) model. Our proposed agent comprises sequential mechanisms for user model inference and proposal generation. To infer the user model (preference function), Bayesian approximate inference is used in the agent. The data collection strategy is to generate proposals, responses to which help resolving uncertainty associated with prediction of the user responses the most. The efficiency of our approach is validated by numerical simulations. Also a real-life example of preference learning application is provided.},
  archive      = {J_AIJ},
  author       = {Tanya Ignatenko and Kirill Kondrashov and Marco Cox and Bert de Vries},
  doi          = {10.1016/j.artint.2025.104400},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104400},
  shortjournal = {Artif. Intell.},
  title        = {On preference learning based on sequential bayesian optimization with pairwise comparison},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Choosing abstraction levels for model-based software debugging: A theoretical and empirical analysis for spreadsheet programs. <em>AIJ</em>, <em>348</em>, 104399. (<a href='https://doi.org/10.1016/j.artint.2025.104399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based diagnosis is a generally applicable, principled approach to the systematic debugging of a wide range of system types such as circuits, knowledge bases, physical devices, or software. Based on a formal description of the system, it enables precise and deterministic reasoning about potential faults responsible for observed misbehavior. In software, such a formal system description can often even be extracted from the buggy program fully automatically. As logical reasoning is central to diagnosis, the performance of model-based debuggers is largely influenced by reasoning efficiency, which in turn depends on the complexity and expressivity of the system description. Since highly detailed models capturing exact semantics often exceed the capabilities of current reasoning tools, researchers have proposed more abstract representations. In this work, we thoroughly analyze system modeling techniques with a focus on fault localization in spreadsheets—one of the most widely used end-user programming paradigms. Specifically, we present three constraint model types characterizing spreadsheets at different abstraction levels, show how to extract them automatically from faulty spreadsheets, and provide theoretical and empirical investigations of the impact of abstraction on both diagnostic output and computational performance. Our main conclusions are that (i) for the model types, there is a trade-off between the conciseness of generated fault candidates and computation time, (ii) the exact model is often impractical, and (iii) a new model based on qualitative reasoning yields the same solutions as the exact one in up to more than half the cases while being orders of magnitude faster. Due to their ability to restrict the solution space in a sound way, the explored model-based techniques, rather than being used as standalone approaches, are expected to realize their full potential in combination with iterative sequential diagnosis or indeterministic but more performant statistical debugging methods.},
  archive      = {J_AIJ},
  author       = {Patrick Rodler and Birgit Hofer and Dietmar Jannach and Iulia Nica and Franz Wotawa},
  doi          = {10.1016/j.artint.2025.104399},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104399},
  shortjournal = {Artif. Intell.},
  title        = {Choosing abstraction levels for model-based software debugging: A theoretical and empirical analysis for spreadsheet programs},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Argus: Programming with communication protocols in a belief-desire-intention architecture. <em>AIJ</em>, <em>348</em>, 104398. (<a href='https://doi.org/10.1016/j.artint.2025.104398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protocols model multiagent systems (MAS) by capturing the communications between its agents. Belief-Desire-Intention (BDI) architectures provide an attractive way for organizing an agent in terms of cognitive concepts. Current BDI approaches, however, lack adequate support for engineering protocol-based agents. We describe Argus, an approach that melds recent advances in flexible, declarative communication protocols with BDI architectures. For concreteness, we adopt Jason as an exemplar of the BDI paradigm and show how to support protocol-based reasoning in it. Specifically, Argus contributes (1) a novel architecture and formal operational semantics combining protocols and BDI; (2) a code generation-based programming model that guides the implementation of agents; and (3) integrity checking for incoming and outgoing messages that help ensure that the agents are well-behaved. The Argus conceptual architecture builds quite naturally on top of Jason. Thus, Argus enables building more flexible multiagent systems while using a BDI architecture than is currently possible.},
  archive      = {J_AIJ},
  author       = {Samuel H. Christie V and Munindar P. Singh and Amit K. Chopra},
  doi          = {10.1016/j.artint.2025.104398},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104398},
  shortjournal = {Artif. Intell.},
  title        = {Argus: Programming with communication protocols in a belief-desire-intention architecture},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social behavior as a key to learning-based multi-agent pathfinding dilemmas. <em>AIJ</em>, <em>348</em>, 104397. (<a href='https://doi.org/10.1016/j.artint.2025.104397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-agent Path Finding (MAPF) problem involves finding collision-free paths for a team of agents in a known, static environment, with important applications in warehouse automation, logistics, or last-mile delivery. To meet the needs of these large-scale applications, current learning-based methods often deploy the same fully trained, decentralized network to all agents to improve scalability. However, such parameter sharing typically results in homogeneous behaviors among agents, which may prevent agents from breaking ties around symmetric conflict (e.g., bottlenecks) and might lead to live-/deadlocks. In this paper, we propose SYLPH, a novel learning-based MAPF framework aimed to mitigate the adverse effects of homogeneity by allowing agents to learn and dynamically select different social behaviors (akin to individual, dynamic roles), without affecting the scalability offered by parameter sharing. Specifically, SYLPH offers a novel hierarchical mechanism by introducing Social Value Orientation (SVO) as a temporally extended latent variable that plays a central role in both policy generation and reward assignment. To support this hierarchical decision-making process, we introduce Social-aware Multi-Policy PPO (SMP3O), a reinforcement learning method that ensures stable and effective training through a mechanism for the cross-utilization of advantages. Moreover, we design an SVO-based learning tie-breaking algorithm, allowing agents to proactively avoid collisions, rather than relying solely on post-processing techniques. As a result of this hierarchical decision-making and exchange of social preferences, SYLPH endows agents with the ability to reason about the MAPF task through more latent spaces and nuanced contexts, leading to varied responses that can help break ties around symmetric conflicts. Our comparative experiments show that SYLPH achieves state-of-the-art performance, surpassing other learning-based MAPF planners in random, room-like, and maze-like maps, while our ablation studies demonstrate the advantages of each component in SYLPH. We finally experimentally validate our trained policies on hardware in three types of maps, showing how SYLPH allows agents to find high-quality paths under real-life conditions. Our code and videos are available at: marmotlab.github.io/mapf_sylph .},
  archive      = {J_AIJ},
  author       = {Chengyang He and Tanishq Duhan and Parth Tulsyan and Patrick Kim and Guillaume Sartoretti},
  doi          = {10.1016/j.artint.2025.104397},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104397},
  shortjournal = {Artif. Intell.},
  title        = {Social behavior as a key to learning-based multi-agent pathfinding dilemmas},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MATE: Masked optimal transport with dynamic selection for partial label graph learning. <em>AIJ</em>, <em>348</em>, 104396. (<a href='https://doi.org/10.1016/j.artint.2025.104396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of partial label graph learning, in which every graph is associated with a set of candidate labels. Previous methods for weakly supervised graph classification often provide pseudo-labels for graph samples that could be overconfident and biased towards the dominant classes, thus resulting in substantial error accumulation. In this paper, we introduce a new framework named M asked Optim a l T ransport with Dynamic S e lection (MATE) for partial label graph learning, which improves the quality of graph assignments from the perspectives of class balancing and uncertainty mining. In particular, our MATE masks probabilities out of candidate sets and then adopts optimal transport to optimize the assignments without class biases. This design is based on the assumption that the true label distribution is class-balanced or nearly balanced, which is common in various training datasets and real-world scenarios. To further reduce potential noise, we propose a novel scoring metric termed partial energy discrepancy (PED) to evaluate the uncertainty of assignments, and then introduce a dynamic selection strategy that modifies the sample-specific thresholds via momentum updating. Finally, these samples are divided into three levels, i.e., confident, less-confident, and unconfident and each group is trained separately in our collaborative optimization framework. Extensive experiments on various benchmarks demonstrate the superiority of our MATE compared to various state-of-the-art baselines.},
  archive      = {J_AIJ},
  author       = {Yiyang Gu and Binqi Chen and Zihao Chen and Ziyue Qiao and Xiao Luo and Junyu Luo and Zhiping Xiao and Wei Ju and Ming Zhang},
  doi          = {10.1016/j.artint.2025.104396},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104396},
  shortjournal = {Artif. Intell.},
  title        = {MATE: Masked optimal transport with dynamic selection for partial label graph learning},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpreting capsule networks for image classification by routing path visualization. <em>AIJ</em>, <em>348</em>, 104395. (<a href='https://doi.org/10.1016/j.artint.2025.104395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks are popular for computer vision as they often give state-of-the-art performance, but are difficult to interpret because of their complexity. This black box modeling is especially troubling when the application concerns human well-being such as in medical image analysis or autonomous driving. In this work, we propose a technique called routing path visualization for capsule networks, which reveals how much of each region in an image is routed to each capsule. In turn, this technique can be used to interpret the entity that a given capsule detects, and speculate how the network makes a prediction. We demonstrate our new visualization technique on several real world datasets. Experimental results suggest that routing path visualization can precisely localize the predicted class from an image, even though the capsule networks are trained using just images and their respective class labels, without additional information defining the location of the class in the image.},
  archive      = {J_AIJ},
  author       = {Amanjot Bhullar and Michael Czomko and R. Ayesha Ali and Douglas L. Welch},
  doi          = {10.1016/j.artint.2025.104395},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104395},
  shortjournal = {Artif. Intell.},
  title        = {Interpreting capsule networks for image classification by routing path visualization},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relaxed core stability in hedonic games. <em>AIJ</em>, <em>348</em>, 104394. (<a href='https://doi.org/10.1016/j.artint.2025.104394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core is a well-known and fundamental notion of stability in games intended to model coalition formation such as hedonic games: an outcome is core stable if there exists no blocking coalition , i.e., no set of agents that may profit by forming a coalition together. The fact that the cardinality of a blocking coalition, i.e., the number of deviating agents that have to coordinate themselves, can be arbitrarily high, and the fact that agents may benefit only by a tiny amount from their deviation, while they could incur in a higher cost for deviating, suggest that the core is not able to suitably model practical scenarios in large and highly distributed multi-agent systems. For this reason, we consider relaxed core stable outcomes where the notion of permissible deviations is modified along two orthogonal directions: the former takes into account the size q of the deviating coalition, and the latter the amount of utility gain, in terms of a multiplicative factor k , for each member of the deviating coalition. These changes result in two different notions of stability, namely, the q-size core and k-improvement core . We consider fractional hedonic games, that is a well-known subclass of hedonic games for which core stable outcomes are not guaranteed to exist and it is computationally hard to decide non-emptiness of the core; we investigate these relaxed concepts of stability with respect to their existence, computability and performance in terms of price of anarchy and price of stability, by providing in many cases tight or almost tight bounds. Interestingly, the considered relaxed notions of core also possess the appealing property of recovering, in some notable cases, the convergence, the existence and the possibility of computing stable solutions in polynomial time.},
  archive      = {J_AIJ},
  author       = {Angelo Fanelli and Gianpiero Monaco and Luca Moscardelli},
  doi          = {10.1016/j.artint.2025.104394},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104394},
  shortjournal = {Artif. Intell.},
  title        = {Relaxed core stability in hedonic games},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provably efficient information-directed sampling algorithms for multi-agent reinforcement learning. <em>AIJ</em>, <em>348</em>, 104392. (<a href='https://doi.org/10.1016/j.artint.2025.104392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work designs and analyzes a novel set of algorithms for multi-agent reinforcement learning (MARL) based on the principle of information-directed sampling (IDS). These algorithms draw inspiration from foundational concepts in information theory, and are proven to be sample efficient in MARL settings such as two-player zero-sum Markov games (MGs) and multi-player general-sum MGs. For episodic two-player zero-sum MGs, we present three sample-efficient algorithms for learning Nash equilibrium. The basic algorithm, referred to as MAIDS , employs an asymmetric learning structure where the max-player first solves a minimax optimization problem based on the joint information ratio of the joint policy, and the min-player then minimizes the marginal information ratio with the max-player's policy fixed. Theoretical analyses show that it achieves a Bayesian regret of O ˜ ( K ) for K episodes. To reduce the computational load of MAIDS , we develop an improved algorithm called Reg-MAIDS , which has the same Bayesian regret bound while enjoying less computational complexity. Moreover, by leveraging the flexibility of IDS principle in choosing the learning target, we propose two methods for constructing compressed environments based on rate-distortion theory, upon which we develop an algorithm Compressed-MAIDS wherein the learning target is a compressed environment. Finally, we extend Reg-MAIDS to multi-player general-sum MGs and prove that it can learn either the Nash equilibrium or coarse correlated equilibrium in a sample-efficient manner.},
  archive      = {J_AIJ},
  author       = {Qiaosheng Zhang and Chenjia Bai and Shuyue Hu and Zhen Wang and Xuelong Li},
  doi          = {10.1016/j.artint.2025.104392},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104392},
  shortjournal = {Artif. Intell.},
  title        = {Provably efficient information-directed sampling algorithms for multi-agent reinforcement learning},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the design of truthful mechanisms for the capacitated facility location problem with two and more facilities. <em>AIJ</em>, <em>348</em>, 104390. (<a href='https://doi.org/10.1016/j.artint.2025.104390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we explore the Mechanism Design aspects of the m -Capacitated Facility Location Problem ( m -CFLP) on a line, focusing on two frameworks. In the first framework, the number of facilities is arbitrary, all facilities share the same capacity, and the number of agents matches the total capacity of the facilities. In the second framework, we need to locate two facilities, each with a capacity equal to at least half the number of agents. For both frameworks, we propose truthful mechanisms with bounded approximation ratios in terms of Social Cost (SC) and Maximum Cost (MC). When m > 2 , our results stand in contrast to the impossibility results known for the classical m -Facility Location Problem, where capacity constraints are absent. Moreover, all the proposed mechanisms are optimal with respect to MC and either optimal or near-optimal with respect to the SC among anonymous mechanisms. We then establish lower bounds on the approximation ratios that any truthful and deterministic mechanism achieves with respect to SC and MC for both frameworks. Lastly, we run several numerical experiments to empirically evaluate the performances of our mechanisms with respect to the SC or the MC. Our empirical analysis shows that our proposed mechanisms outperform all previously proposed mechanisms applicable in this setting.},
  archive      = {J_AIJ},
  author       = {Gennaro Auricchio and Zihe Wang and Jie Zhang},
  doi          = {10.1016/j.artint.2025.104390},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104390},
  shortjournal = {Artif. Intell.},
  title        = {On the design of truthful mechanisms for the capacitated facility location problem with two and more facilities},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="amc">AMC - 15</h2>
<ul>
<li><details>
<summary>
(2026). The list r-hued coloring of p5-free graph. <em>AMC</em>, <em>511</em>, 129742. (<a href='https://doi.org/10.1016/j.amc.2025.129742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a list L of graph G , an ( L , r ) -coloring of graph G is a proper coloring such that the color of vertex v belongs to its list L ( v ) , and each vertex of degree d G ( v ) is adjcent to vertices with at least min { r , d G ( v ) } different colors. The list r -hued chromatic number, denoted by χ L , r ( G ) , is the smallest integer k such that for any k -list L of G , G has an ( L , r ) -coloring. We prove the following: ( i ) If G = G ( U , V ) is a connected P 5 -free bipartite graph and min { | U | , | V | } = s , then χ L , r ( G ) ≤ max { 2 r , s + 1 } . ( i i ) If G is a connected P 5 -free graph and r ≤ 3 , then χ L , r ( G ) ≤ r χ L ( G ) .},
  archive      = {J_AMC},
  author       = {Xuanhe Jia and Fengxia Liu and Baiyun Ji and Zihang Zhao},
  doi          = {10.1016/j.amc.2025.129742},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129742},
  shortjournal = {Appl. Math. Comput.},
  title        = {The list r-hued coloring of p5-free graph},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability analysis of stochastic McKean–Vlasov equations with discrete observation. <em>AMC</em>, <em>511</em>, 129740. (<a href='https://doi.org/10.1016/j.amc.2025.129740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the stability issue of stochastic McKean–Vlasov equations (SMVEs) through an innovative method: stabilization via stochastic delay feedback control with discrete observation. Unlike conventional techniques, this approach leverages historical states instead of solely relying on the current state, setting it apart from traditional stochastic feedback controls. The study examines how the diffusion term contributes to enhancing system stability despite the presence of random fluctuations and delays, guaranteeing both p -th moment exponential stability and almost sure exponential stability under a specific delay threshold δ * . The primary contributions of this work include introducing a novel stability analysis framework utilizing stochastic delay feedback control, constructing Lyapunov functions that incorporate both state and distribution, and providing insights into asymptotic and moment exponential stability. Although identifying the optimal delay δ * remains a practical challenge, the theoretical foundation laid in this study offers valuable guidance for real-world applications.},
  archive      = {J_AMC},
  author       = {Yicheng Liu and Quanxin Zhu},
  doi          = {10.1016/j.amc.2025.129740},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129740},
  shortjournal = {Appl. Math. Comput.},
  title        = {Stability analysis of stochastic McKean–Vlasov equations with discrete observation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Collaborated risk perception against multiple epidemics in a multiplayer network. <em>AMC</em>, <em>511</em>, 129738. (<a href='https://doi.org/10.1016/j.amc.2025.129738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concurrent outbreak of epidemics has become a great threat to public health. An important problem is how individuals can protect themselves as the mandated protective measures are relaxed. Previous studies developed various models to investigate the correlated spreading dynamics of concurrent epidemics and the protective measures against them. However, a critical oversight remains that people’s risk perceptions on multiple epidemics are also correlated or even collaborated. In this paper, we build an SS-IS-SI-II coupled model in a multilayer network to describe two concurrent epidemics, integrating collaborated risk perception and spontaneous social distancing as individuals’ self-protection. Moreover, an adjustable coefficient is proposed to describe different levels of inter-epidemic correlations (competition/independence/cooperation). It is found that increasing the levels of inter-epidemic correlation will increase the infected density of both epidemics. Collaborated risk perception is generally more effective in reducing infections across different levels of inter-epidemic correlation, compared with independent risk perception. But its effect is dependent. For one epidemic, when its infectivity is very high or the infectivity of the other epidemic is very low, the effect of collaborated risk perception will be largely reduced. Based on the model, we further investigate the minimum social distancing required to contain epidemics under different conditions, and the priority on different layers is also explored. This research extends existing literature on co-evolutional epidemic dynamics, and lay a foundation to model correlated risk perceptions against epidemics. The results provide implications for individuals to take self-protection against concurrent epidemics.},
  archive      = {J_AMC},
  author       = {Yahong Chen and He Huang},
  doi          = {10.1016/j.amc.2025.129738},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129738},
  shortjournal = {Appl. Math. Comput.},
  title        = {Collaborated risk perception against multiple epidemics in a multiplayer network},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Superconvergent methods for solving two-dimensional hammerstein integral equations. <em>AMC</em>, <em>511</em>, 129737. (<a href='https://doi.org/10.1016/j.amc.2025.129737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the superconvergent degenerate kernel method and the superconvergent Nyström method for the numerical solution of two-dimensional Hammerstein integral equations of the second kind. By employing piecewise polynomial interpolation of degree r , we prove that, under symmetry conditions on both the triangulation and the interpolation nodes, convergence orders of 2 r + 3 and 2 r + 4 are achieved for the approximate solutions and their iterated versions, respectively. Furthermore, we discuss computational aspects related to the construction of the corresponding nonlinear systems, and we present numerical examples to illustrate the theoretical results obtained.},
  archive      = {J_AMC},
  author       = {M. Sennour and D. Sbibih and M. Tahrichi},
  doi          = {10.1016/j.amc.2025.129737},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129737},
  shortjournal = {Appl. Math. Comput.},
  title        = {Superconvergent methods for solving two-dimensional hammerstein integral equations},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrating emotion and expectation improves cooperation. <em>AMC</em>, <em>511</em>, 129736. (<a href='https://doi.org/10.1016/j.amc.2025.129736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperation is a key issue attracting widespread attention across various fields. Emotions and expectations jointly participate in the decision-making process, and are key factors influencing the evolution of cooperation. Therefore, this paper proposes a game evolution model that considers the dual influences of emotions and expectations. In the model, a player’s initial strategy depends on their emotions. Subsequently, expectations influence the decision-making process, altering the player’s initial strategy to the current strategy. Specifically, high expectations lead players to maintain their initial strategy, whereas low expectations prompt them to change strategies. Furthermore, the paper analyzes the evolution of cooperation in the prisoner’s dilemma and the influence of expectations. Simulation results show that under high betrayal temptation, players with loneliness and defection would change their initial strategy to cooperation due to low expectations, while those players who initially gather with cooperation strategies maintain the cooperation strategies due to higher expectations, ultimately increasing the cooperation fraction and payoff of the population. Therefore, expectations effectively enhance the cooperation level and payoff of the population. When the scale of individuals changing their strategies based on expectations (ICSE) is large, the effect of expectations on enhancing cooperation and payoff is more pronounced. Frequent consideration of anticipated initial strategy changes also yields the same effect. Additionally, mechanisms of the influence of emotion on payoff, direct emotion interaction and the influence of strategy on emotion collectively contribute to enhancing the significantly evolutionary advantage of friendly emotions and cooperation strategies. This paper contributes to a deeper understanding of the role of expectations in the evolution of emotions and cooperation, laying the groundwork for enhancing social cooperation through expectation management.},
  archive      = {J_AMC},
  author       = {Wen Lu and Shu Liang},
  doi          = {10.1016/j.amc.2025.129736},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129736},
  shortjournal = {Appl. Math. Comput.},
  title        = {Integrating emotion and expectation improves cooperation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On sketch-and-project methods for solving tensor equations. <em>AMC</em>, <em>511</em>, 129735. (<a href='https://doi.org/10.1016/j.amc.2025.129735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a regular sketch-and-project method for solving linear tensor equations based on the t-product and present its equivalent Fourier domain version, along with several special cases corresponding to existing classical matrix equation methods. Furthermore, we extend this framework via a hierarchical approach to solve generalized Sylvester tensor equations. All the methods are proved to converge linearly in expectation. Finally, numerical experiments demonstrate the efficiency and effectiveness of the proposed approach.},
  archive      = {J_AMC},
  author       = {Ling Tang and Yanjun Zhang and Hanyu Li},
  doi          = {10.1016/j.amc.2025.129735},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129735},
  shortjournal = {Appl. Math. Comput.},
  title        = {On sketch-and-project methods for solving tensor equations},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sampling patterns for zernike-like bases in non-standard geometries. <em>AMC</em>, <em>511</em>, 129727. (<a href='https://doi.org/10.1016/j.amc.2025.129727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zernike polynomials are widely used in optics and ophthalmology due to their direct connection to classical optical aberrations. While orthogonal on the unit disk, their application to discrete data or non-circular domains–such as ellipses, annuli, and hexagons–presents challenges in terms of numerical stability and accuracy. In this work, we extend Zernike-like orthogonal functions to these non-standard geometries using diffeomorphic mappings and construct sampling patterns that preserve favorable numerical conditioning. We provide theoretical bounds for the condition numbers of the resulting collocation matrices and validate them through extensive numerical experiments. As a practical application, we demonstrate accurate wavefront interpolation and reconstruction in segmented mirror telescopes composed of hexagonal facets. Our results show that appropriately transferred sampling configurations, especially Optimal Concentric Sampling and Lebesgue points , allow stable high-order interpolation and effective wavefront modeling in complex optical systems. Moreover, the Optimal Concentric Samplings can be computed with an explicit expression, which is a significant advantage in practice.},
  archive      = {J_AMC},
  author       = {S. Díaz-Elbal and A. Martínez-Finkelshtein and D. Ramos-López},
  doi          = {10.1016/j.amc.2025.129727},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129727},
  shortjournal = {Appl. Math. Comput.},
  title        = {Sampling patterns for zernike-like bases in non-standard geometries},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal information spreading strategy for containing epidemic spreading on higher-order multiplex networks. <em>AMC</em>, <em>511</em>, 129725. (<a href='https://doi.org/10.1016/j.amc.2025.129725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When an epidemic spreads through a population, related information also spreads concurrently, prompting individuals to adopt protective behaviours (e.g., washing hands). Collective behaviour has been shown to play a critical role in shaping the dynamics of epidemic spreading, and higher-order networks offer a natural framework to describe such group interactions in social contact networks. Yet, the interplay between epidemic and information dynamics on higher-order structures is not fully understood, further limiting our understanding of the optimal information spreading strategy for containing epidemic spreading.In this study, we first construct a higher-order multiplex network framework based on simplicial complexes. Then, a coevolutionary spreading model is proposed, integrating epidemic spreading and information spreading on simplicial complexes. The epidemic spreads through both lower-order (pairwise) and higher-order (group) interactions, while information spreads through lower-order interactions in a degree-preferential manner. Using an extended Microscopic Markov Chain Approach, we analytically derive the dynamical equations of the system and compute the basic reproduction number using the next-generation matrix method. Finally, we conduct extensive numerical simulations of the spreading process across various parameter regimes. Our results demonstrate the role of higher-order infections in promoting epidemics. Although information spreading generally suppresses the spread of most epidemics, it can paradoxically enhance the spread of certain epidemics with a very low spreading capacity. Increases in the recovery probabilities of both the disease and the information can weaken the promoting effect of higher-order infection and enhance the suppressive effect of the information. For certain epidemics with weak spreading capabilities but strong recovery capabilities, the spread of information can completely suppress the outbreak of the disease, while the enhancement of higher-order infections can promote the outbreak of these diseases. By analysing the effects of different information spreading strategies on epidemic spreading, we find that the optimal strategy for containing the epidemic is to allow information to spread without degree preference.},
  archive      = {J_AMC},
  author       = {Jiayi Song and Wenjie Li and Yunzhu Xiao and Ling Chen and Chun Yang and Li Qi and Wei Wang},
  doi          = {10.1016/j.amc.2025.129725},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129725},
  shortjournal = {Appl. Math. Comput.},
  title        = {Optimal information spreading strategy for containing epidemic spreading on higher-order multiplex networks},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the fairness and cooperation among free-riders. <em>AMC</em>, <em>511</em>, 129724. (<a href='https://doi.org/10.1016/j.amc.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the free-rider problem in peer-to-peer (P2P) systems, where agents enjoy the group effort without contributing their share. We introduce the Free-Rider Game (FRG), a non-cooperative game incorporating a fairness-aware profit allocation rule based on the Robin Hood index. We show that FRG admits strong structural properties. First, making a non-zero contribution is a dominant strategy for any player. Second, a player contributes positively whenever at least one other player does so. Third, FRG admits a unique Nash equilibrium in which each player contributes the fullest, eliminating free riding. Fourth, equilibrium outcomes are proportionally fair, ensuring balanced allocation across agents. Finally, FRG guarantees full participation by embedding fairness directly into the payoff structure, differentiating it from classical public goods games, which often yield zero or partial contributions.},
  archive      = {J_AMC},
  author       = {Avadh Kishor},
  doi          = {10.1016/j.amc.2025.129724},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129724},
  shortjournal = {Appl. Math. Comput.},
  title        = {On the fairness and cooperation among free-riders},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Equilibrium analysis of edge-heterogeneous binary network games. <em>AMC</em>, <em>511</em>, 129723. (<a href='https://doi.org/10.1016/j.amc.2025.129723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies on the equilibrium of binary network games have primarily focused on scenarios characterized by agent heterogeneity, where agents exhibit unique attributes but their interactions with different neighbors remain uniform. In this paper, we investigate the edge-heterogeneous binary network game, a more general framework that incorporates heterogeneity into agent interactions. We establish two sufficient equilibrium conditions under asynchronous best-response dynamics from different perspectives. The first condition requires underlying symmetry in interactions between neighboring agents, integrating and generalizing three classical convergence situations in binary network games. The second condition focuses on network balance, positing that equilibrium is achievable if the coordination value network of a game is structurally balanced. Additionally, for games meeting this condition, we develop a method to predict the final state based on initial state information. These results reveal factors that steer edge-heterogeneous binary network games towards equilibrium, providing valuable insights for controlling such highly nonlinear systems. Lastly, we extend the analysis to higher-order network games and propose an equilibrium condition for edge-heterogeneous 2-order network games.},
  archive      = {J_AMC},
  author       = {Jiawen Wang and Yangyang Luan and Xiaoqun Wu},
  doi          = {10.1016/j.amc.2025.129723},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129723},
  shortjournal = {Appl. Math. Comput.},
  title        = {Equilibrium analysis of edge-heterogeneous binary network games},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Theory and numerics of subspace approximation of eigenvalue problems. <em>AMC</em>, <em>511</em>, 129722. (<a href='https://doi.org/10.1016/j.amc.2025.129722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale eigenvalue problems arise in various fields of science and engineering and demand computationally efficient solutions. In this study, we investigate the subspace approximation for parametric linear eigenvalue problems, aiming to mitigate the computational burden associated with high-fidelity systems. We provide general error estimates under non-simple eigenvalue conditions, establishing some theoretical foundations for understanding the convergence behavior of subspace approximations. Numerical examples, including problems with one-dimensional to three-dimensional spatial domain and one-dimensional to two-dimensional parameter domain, are presented to demonstrate the efficacy of reduced basis method in handling parametric variations in boundary conditions and coefficient fields to achieve significant computational savings while maintaining high accuracy, making them promising tools for practical applications in large-scale eigenvalue computations.},
  archive      = {J_AMC},
  author       = {Siu Wun Cheung and Youngsoo Choi and Seung Whan Chung and Jean-Luc Fattebert and Coleman Kendrick and Daniel Osei-Kuffuor},
  doi          = {10.1016/j.amc.2025.129722},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129722},
  shortjournal = {Appl. Math. Comput.},
  title        = {Theory and numerics of subspace approximation of eigenvalue problems},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). H-function-based state bounding results of discrete-time delayed systems. <em>AMC</em>, <em>511</em>, 129721. (<a href='https://doi.org/10.1016/j.amc.2025.129721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the h -function-based state bounding estimation problem for discrete-time nonlinear systems (DTNSs) with time-varying delays and bounded disturbances. First, a direct method based on the system solutions is proposed to provide sufficient conditions, which are composed of simple inequalities and depend on the time delays, to ensure that the state trajectories of the considered system always stay within a polyhedron or converge into it. Second, it is demonstrated that the obtained sufficient conditions are precisely the global h -stability (G h -S) criteria of the considered system when disturbances disappear, and when the initial function is restricted within a certain range, the resulting polyhedron can be considered as h -function-based reachable set estimation of the states. Finally, the applicability of the theoretical results obtained is illustrated through two numerical examples.},
  archive      = {J_AMC},
  author       = {Huan Zhang and Xiaona Yang and Tianqiu Yu},
  doi          = {10.1016/j.amc.2025.129721},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129721},
  shortjournal = {Appl. Math. Comput.},
  title        = {H-function-based state bounding results of discrete-time delayed systems},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Composite sliding mode adaptive tracking control for singularly perturbed semi-markov jump non-linear systems with fault and disturbances. <em>AMC</em>, <em>511</em>, 129717. (<a href='https://doi.org/10.1016/j.amc.2025.129717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work epitomizes the construction of composite sliding mode-oriented adaptive tracking controller for singularly perturbed semi-Markov jump non-linear systems exposed to multiple disturbances and actuator fault. Typically, a model reference adaptive tracking control algorithm composed of baseline control, enhanced error correction term and adaptive laws is embodied with sliding mode control law to attain robust and rapid tracking performance. On top of that, a disturbance observer is embedded with fault estimator configuration to simultaneously deliver precise evaluations of both exogenous disturbances and faults that influence the system state tracking processes and these assessment are assimilated into the established tracking protocol. Collectively, a robust composite sliding mode-oriented adaptive tracking control strategy with disturbance estimation and fault-tolerance strategies is devised to assure adequate tracking objectives as well as the extended dissipativity performance specifications. After then, by deploying relevant Lyapunov function terms, the necessities for confirming the stochastic stability with preset extended dissipativity performance of the adopted system is detailed into linear matrix inequalities. Furthermore, the reliability of the analysed findings is further affirmed by graphical illustrations attained from numerical simulations.},
  archive      = {J_AMC},
  author       = {N. Shobana and R. Sakthivel and O.M. Kwon and M. Sankar and M. Asha Safana},
  doi          = {10.1016/j.amc.2025.129717},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129717},
  shortjournal = {Appl. Math. Comput.},
  title        = {Composite sliding mode adaptive tracking control for singularly perturbed semi-markov jump non-linear systems with fault and disturbances},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-triggered prescribed performance control of the multiplayer game nonlinear system via integral reinforcement learning. <em>AMC</em>, <em>511</em>, 129716. (<a href='https://doi.org/10.1016/j.amc.2025.129716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a view to addressing the optimal control problem of multiplayer game nonlinear systems, an event-triggered prescribed performance control method based on the fusion of integral reinforcement learning (IRL) and adaptive dynamic programming (ADP) is proposed. Firstly, an auxiliary prescribed performance function (PPF) is designed to transform the original system into an unconstrained one. Drawing on the concepts of game theory, the multi-input optimal control problem is reformulated as a mixed zero-sum (MZS) game problem. Subsequently, an IRL-based event-triggered control (ETC) method is designed with a triggering condition. In this event-triggered method, ETC is updated only when the event-triggering condition is met, which reduces unnecessary communication overhead. On the basis of IRL, a critic-only neural network (NN) is established to approximate solutions of the event-triggered Hamilton-Jacobi-Bellman (HJB) equations without using the dynamic knowledge of the system. Additionally, the Lyapunov stability theorem is employed to ensure the uniform ultimate boundedness (UUB) of the system state and neural network weights. And the Zeno behavior can be avoided. Finally, an example is provided to verify the effectiveness of the proposed method in this paper.},
  archive      = {J_AMC},
  author       = {Yuanyang Hu and Jiaqi Chen and Chunbin Qin},
  doi          = {10.1016/j.amc.2025.129716},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129716},
  shortjournal = {Appl. Math. Comput.},
  title        = {Event-triggered prescribed performance control of the multiplayer game nonlinear system via integral reinforcement learning},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Numerical approximation for a stochastic time-fractional cable equation. <em>AMC</em>, <em>511</em>, 129709. (<a href='https://doi.org/10.1016/j.amc.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient numerical method is proposed to address a stochastic time-fractional cable equation driven by fractionally integrated additive noise. Under the reasonable assumptions, we rigorously establish for the first time, the existence, uniqueness, and regularity of the mild solution for this equation. For spatial discretization, a semi-discrete scheme is constructed employing the Galerkin FEM, and the optimal spatial error estimate is derived based on the semigroup approach. In temporal discretization, a piecewise constant function is introduced to approximate the noise, leading to the formulation of a regularized stochastic time-fractional cable equation. A detailed proof of the temporal error estimates is provided via the semigroup approach. Numerical experiments demonstrate that the temporal convergence order attains O ( τ 1 / 2 ) for initial data of either smooth or non-smooth type. The order is independent of the parameters α 1 ∈ ( 0 , 1 ) , α 2 ∈ ( 0 , 1 ) , and β ∈ ( 0 , 1 ) in the equation. These results perfectly align with the theoretical predictions.},
  archive      = {J_AMC},
  author       = {Qimin Li and Yubin Yan and Leijie Qiao and Yu Zhang},
  doi          = {10.1016/j.amc.2025.129709},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129709},
  shortjournal = {Appl. Math. Comput.},
  title        = {Numerical approximation for a stochastic time-fractional cable equation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="artmed">ARTMED - 15</h2>
<ul>
<li><details>
<summary>
(2025). The interpretable deep learning framework and validation for seizure detection in pediatric electroencephalography: An improved accuracy and performance analysis. <em>ARTMED</em>, <em>170</em>, 103276. (<a href='https://doi.org/10.1016/j.artmed.2025.103276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an interpretable deep learning framework and compares the two novel models. A fully convolutional network with squeeze-and-excitation modules (SE-FCN) is designed to enhance spatial sensitivity and retain temporal resolution. In addition, a transformer-based model (TransNet) is developed to capture temporal and channel-wise dependencies via self-attention. These two models output channel saliency weights to the EEG electrode space and generate heatmaps for inferring potential epileptogenic zones. Deep learning primarily adopts convolutional neural networks (CNNs) or sequence generation networks (SGNs) and faces the limitations. For instance, CNN-based models often lack hierarchical modeling and fail to quantify channel-wise contributions, hindering spatial localization. SGN-based models struggle to capture complex spatiotemporal dependencies and typically lack adaptive attention tailored to electroencephalography (EEG) characters. Epileptic seizure detection is vital for effective clinical intervention and existing methods operated as black boxes, limiting clinical interpretability. This study evaluates the models on the CHB-MIT pediatric EEG dataset using a subject-independent cross-validation protocol. SE-FCN achieves an AUC of 0.89 and accuracy of 86.7 %, while TransNet achieves an AUC of 0.92 and accuracy of 86.4 %. Saliency maps from both models demonstrate high consistency and enable categorization of 22 patients into five groups based on inferred seizure origins.},
  archive      = {J_ARTMED},
  author       = {Yu Zhou and Yuxin Gao and Qiang Li and Ruiheng Wu and Aiping Yang and Ming-Lang Tseng},
  doi          = {10.1016/j.artmed.2025.103276},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103276},
  shortjournal = {Artif. Intell. Med.},
  title        = {The interpretable deep learning framework and validation for seizure detection in pediatric electroencephalography: An improved accuracy and performance analysis},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel memory interaction neural network for multi-label drug–drug interaction prediction with neighbor importance sampling. <em>ARTMED</em>, <em>170</em>, 103275. (<a href='https://doi.org/10.1016/j.artmed.2025.103275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-administration of multiple drugs can frequently cause drug–drug interactions (DDIs), including adverse drug reactions (ADRs) that may increase the likelihood of morbidity and mortality. Identifying potential DDIs presents a significant challenge, due to the complexity of pharmacology. Recent advances in knowledge graphs have contributed to DDI prediction by providing a robust framework for representing various relationships between drugs and other entities, such as proteins, diseases, and drug attributes. However, current network-based models often fail to uncover interaction information among DDI triplets, as they typically encode triplets independently. Additionally, uniform sampling methods may overlook differences in neighboring node properties. In this work, we propose a novel memory interaction neural network for DDI prediction, which integrates drug molecular sequences with semantic information from the drug knowledge graph. Specifically, we introduce a neighbor importance sampling strategy that selectively samples highly connected neighbors, improving computational efficiency and reducing noise. We also design a memory interaction module that utilizes multi-head attention mechanisms and deep neural networks to capture interactions among DDI triplets. Experimental evaluation on KEGG and OGB-biokg datasets demonstrates the superiority of our model compared to classical and state-of-the-art methods in predicting DDIs. Datasets and code for this proposed DDIs prediction model are freely accessible at https://github.com/wj1108114106/Multi-label-DDIs .},
  archive      = {J_ARTMED},
  author       = {Jing Wang and Runzhi Li and Shuo Zhang and YunLi Xing and Siyu Yan and Lihong Ma},
  doi          = {10.1016/j.artmed.2025.103275},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103275},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel memory interaction neural network for multi-label drug–drug interaction prediction with neighbor importance sampling},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Types, functions, and mechanisms of machine learning for personalizing smoking cessation interventions: A systematic scoping review. <em>ARTMED</em>, <em>170</em>, 103274. (<a href='https://doi.org/10.1016/j.artmed.2025.103274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose Artificial intelligence can realize personalization. This systematic scoping review provides the types, functions, and mechanisms of machine learning (ML) for personalizing smoking cessation interventions. Methodology We searched fourteen databases including PubMed, CINAHL, EMBASE, the Cochrane Library, IEEE Xplore, PsycINFO, Scopus, Web of Science, AAAI, ACM Digital Library, ArXIV, Mednar, ProQuest, and Science.gov . We selected 98 articles from 4073 records that met the criteria. Two independent reviewers screened and selected the articles. Two reviewers extracted the data using a self-developed data charting form independently. Results The findings are reported in narrative syntheses, tables, and figures. The types of ML included artificial neural networks, Bayesian algorithms, clustering algorithms, decision tree algorithms, deep learning (DL) algorithms, ensemble algorithms, linear classifiers, others, and unspecified. The most common ML technique used was supervised learning (81 %), and the ML functions included (1) message tailoring (17 %), (2) prediction and detection of smoking events (34 %), (3) social media surveillance (14 %), (4) predictive models (24 %), and (5) biomarker analysis (10 %). The ML mechanisms involved the following sequence: data input, data preprocessing, feature extraction and selection, training and validation, and data output. Conclusion This review is the first to describe the potential use of ML for personalizing smoking cessation interventions. We provide recommendations for future research by identifying the limitations and gaps in the studies. Future studies should refine, validate, and test ML models using robust experimental methods to conclude their effectiveness.},
  archive      = {J_ARTMED},
  author       = {Yu Jie Xavia Ng and Shing Hui Reina Cheong and Wen Wei Ang and Ying Lau and Siew Tiang Lau},
  doi          = {10.1016/j.artmed.2025.103274},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103274},
  shortjournal = {Artif. Intell. Med.},
  title        = {Types, functions, and mechanisms of machine learning for personalizing smoking cessation interventions: A systematic scoping review},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding the cortical responses to mechanical wrist perturbations: A two-step shared structure NARX method. <em>ARTMED</em>, <em>170</em>, 103273. (<a href='https://doi.org/10.1016/j.artmed.2025.103273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared structure nonlinear autoregressive with exogenous input (NARX) model is a promising tool for exploring cortical responses mechanism to external stimuli, essential for advancing our understanding of brain function and developing methods for direct brain information encoding. In this paper, we proposed a two-step method to overcome limitations in existing method, which neglect data relationships and rely on a greedy search for regression terms, leading to less accurate models. In our approach, data from multiple trials are concatenated, and then the orthogonal forward regression (OFR) algorithm identifies model terms in first step, enhancing inter-trial connections and establishing a preliminary model for each subject. Shared model terms across subjects are then used to construct a general target model. Next, non-shared regression terms that best represent population-level information are identified, using adaptive multi-population genetic algorithms, and use to enhance the target models' descriptive power. Simulations results show significant competitiveness in terms of accuracy as compared to other state-of-the-art methods. When applied to real electroencephalography signals under mechanical disturbance, structural and parameter analysis revealed consistent neural response patterns across subjects, with subject-specific responses likely stemming from muscle feedback. Frequency response analysis further suggests that the brain may generate motor inhibition signals based on sensory inputs to maintain a pre-disturbance resting state. These findings provide valuable insights into cortical response mechanisms and have potential implications for future brain information encoding research.},
  archive      = {J_ARTMED},
  author       = {Nan Zheng and Yurong Li and Wuxiang Shi and Jiyu Tan},
  doi          = {10.1016/j.artmed.2025.103273},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103273},
  shortjournal = {Artif. Intell. Med.},
  title        = {Decoding the cortical responses to mechanical wrist perturbations: A two-step shared structure NARX method},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven dynamic grouping for adaptive clinical trials: Rethinking randomization in precision medicine. <em>ARTMED</em>, <em>170</em>, 103272. (<a href='https://doi.org/10.1016/j.artmed.2025.103272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating artificial intelligence into biomedical human subjects research is transforming traditional experimental paradigms. This perspective introduces the concept of “dynamic grouping,” wherein artificial intelligence (AI) systems continuously reassign participants across experimental conditions based on real-time biomarker data and clinical response patterns. Unlike traditional biomedical research designs that rely on fixed treatment and control groups, dynamic grouping allows participant assignments to evolve throughout the study. We examine the ethical implications, methodological challenges, and research opportunities associated with this paradigm, particularly in clinical trials, precision medicine, and digital therapeutics. To support this analysis, we present three computational simulations that quantify its impact: (i) a heterogeneity simulation demonstrating how patient variability affects the advantage of dynamic grouping, (ii) a statistical power analysis showing potential sample size reductions in adaptive designs, and (iii) a clinical outcome distribution analysis highlighting how dynamic grouping reduces negative treatment outcomes and optimizes patient responses. Our findings suggest that dynamic grouping can improve treatment effectiveness, enhance resource allocation, and increase statistical efficiency, although it also raises new challenges for causal inference, informed consent, and regulatory oversight. As AI continues to reshape medical research, adapting ethical and methodological frameworks will be essential for its responsible implementation.},
  archive      = {J_ARTMED},
  author       = {Madhur Mangalam},
  doi          = {10.1016/j.artmed.2025.103272},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103272},
  shortjournal = {Artif. Intell. Med.},
  title        = {AI-driven dynamic grouping for adaptive clinical trials: Rethinking randomization in precision medicine},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H-SynEx: Using synthetic images and ultra-high resolution ex vivo MRI for hypothalamus subregion segmentation. <em>ARTMED</em>, <em>170</em>, 103271. (<a href='https://doi.org/10.1016/j.artmed.2025.103271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hypothalamus is a small structure located in the center of the brain and is involved in significant functions such as sleeping, temperature, and appetite control. Various neurological disorders are also associated with hypothalamic abnormalities. Automated image analysis of this structure from brain MRI is thus highly desirable to study the hypothalamus in vivo . However, most of the automated segmentation tools currently available focus exclusively on T1w images. In this study, we introduce H-SynEx, a machine learning method for automated segmentation of hypothalamic subregions that generalizes across different MRI sequences and resolutions without retraining. H-synEx was trained with synthetic images built from label maps derived from ultra-high resolution ex vivo MRI scans, allowing finer-grained manual segmentation when compared with 1 mm isometric in vivo images. We validated our method using Dice Coefficient (DSC) and Average Hausdorff distance (AVD) across in vivo images from six different datasets with six different MRI sequences (T1, T2, proton density, quantitative T1, fractional anisotropy, and FLAIR). Statistical analysis compared hypothalamic subregion volumes in controls, Alzheimer’s disease (AD), and behavioral variant frontotemporal dementia (bvFTD) subjects using the Area Under the Receiver Operating Characteristic curve (AUROC) and the Wilcoxon rank sum test. Our results show that H-SynEx successfully leverages information from ultra-high resolution scans to segment in vivo from different MRI sequences. Our automated segmentation was able to discriminate controls versus patients with Alzheimer’s disease on FLAIR images with 5 mm spacing. H-SynEx is openly available at https://github.com/liviamarodrigues/hsynex .},
  archive      = {J_ARTMED},
  author       = {Livia Rodrigues and Martina Bocchetta and Oula Puonti and Douglas Greve and Ana Carolina Londe and Marcondes França and Simone Appenzeller and Juan Eugenio Iglesias and Leticia Rittner},
  doi          = {10.1016/j.artmed.2025.103271},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103271},
  shortjournal = {Artif. Intell. Med.},
  title        = {H-SynEx: Using synthetic images and ultra-high resolution ex vivo MRI for hypothalamus subregion segmentation},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining multi-electrode and multi-wave electroencephalogram based time-interval temporal patterns for improved classification capabilities and explainability. <em>ARTMED</em>, <em>170</em>, 103269. (<a href='https://doi.org/10.1016/j.artmed.2025.103269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interface (BCI) systems, and particularly electroencephalogram (EEG) based BCI systems, have become more widely used in recent years and are utilized in various applications and domains ranging from medicine and marketing to games and entertainment. While different algorithms have been used to analyze EEG data and enable its classification, existing algorithms have two main drawbacks; both their classification and explainability capabilities are limited. Lacking in explainability, they cannot indicate which electrodes and waves led to a classification decision or explain how areas and frequencies of the brain's activity correlate to a specific task. In this study, we propose a novel extension for the time-interval temporal patterns mining algorithms aimed at enhancing the data mining process by enabling a richer set of patterns to be learned from the EEG data, thereby contributing to improved classification and explainability capabilities. The extended algorithm is designed to capture and leverage the unique nature of EEG data by decomposing it into different brain waves and modeling the relations among them and between different electrodes. Our evaluation of the proposed extended algorithm on multiple learning tasks and three EEG datasets demonstrated the extended algorithm's ability to mine richer patterns that improve the classification performance by 4–11 % based on the Area-Under the receiver operating characteristic Curve (AUC) metric, compared to the original version of the algorithm. Moreover, the algorithm was shown to shed light on the areas and frequencies of the brain's activity that are correlated with specific tasks.},
  archive      = {J_ARTMED},
  author       = {Ofir Landau and Nir Nissim},
  doi          = {10.1016/j.artmed.2025.103269},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103269},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mining multi-electrode and multi-wave electroencephalogram based time-interval temporal patterns for improved classification capabilities and explainability},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey for large language models in biomedicine. <em>ARTMED</em>, <em>170</em>, 103268. (<a href='https://doi.org/10.1016/j.artmed.2025.103268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent breakthroughs in large language models (LLMs) offer unprecedented natural language understanding and generation capabilities. However, existing surveys on LLMs in biomedicine often focus on specific applications or model architectures, lacking a comprehensive analysis that integrates the latest advancements across various biomedical domains. This review, based on an analysis of 484 publications sourced from databases including PubMed, Web of Science, and arXiv, provides an in-depth examination of the current landscape, applications, challenges, and prospects of LLMs in biomedicine, distinguishing itself by focusing on the practical implications of these models in real-world biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot learning across a broad spectrum of biomedical tasks, including diagnostic assistance, drug discovery, and personalized medicine, among others, with insights drawn from 137 key studies. Then, we discuss adaptation strategies of LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to enhance their performance in specialized biomedical contexts where zero-shot fails to achieve, such as medical question answering and efficient processing of biomedical literature. Finally, we discuss the challenges that LLMs face in the biomedicine domain including data privacy concerns, limited model interpretability, issues with dataset quality, and ethics due to the sensitive nature of biomedical data, the need for highly reliable model outputs, and the ethical implications of deploying AI in healthcare. To address these challenges, we also identify future research directions of LLM in biomedicine including federated learning methods to preserve data privacy and integrating explainable AI methodologies to enhance the transparency of LLMs. As this field of LLM rapidly evolves, continued research and development are essential to fully harness the capabilities of LLMs in biomedicine while ensuring their responsible and effective deployment.},
  archive      = {J_ARTMED},
  author       = {Chong Wang and Mengyao Li and Junjun He and Zhongruo Wang and Erfan Darzi and Zan Chen and Jin Ye and Tianbin Li and Yanzhou Su and Jing Ke and Kaili Qu and Shuxin Li and Yi Yu and Pietro Liò and Tianyun Wang and Yu Guang Wang and Yiqing Shen},
  doi          = {10.1016/j.artmed.2025.103268},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103268},
  shortjournal = {Artif. Intell. Med.},
  title        = {A survey for large language models in biomedicine},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-quality triage and diagnosis of gynecological diseases via artificial intelligence. <em>ARTMED</em>, <em>170</em>, 103267. (<a href='https://doi.org/10.1016/j.artmed.2025.103267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely detection and diagnosis of diseases are key elements of an efficient healthcare system. In recent years, artificial intelligence (AI) has played an increasingly important role in improving the accuracy and efficiency of disease diagnosis in clinical practice. However, most existing AI systems for disease diagnosis have focused on either classifying patients into broad disease categories or diagnosing a specific disease, leaving a gap in the development of a coherent AI system for both triage and diagnosis in a department of a general hospital. In this study, we fill this gap with SmartGyne, an advanced AI system that can achieve high-quality triage and diagnosis for a full spectrum of gynecological diseases. By extracting useful clinical evidence for diagnosis from a large amount of electronic medical records, SmartGyne establishes an effective framework to integrate real-world clinical evidence and knowledge into a coherent AI system that can effectively handle a full spectrum of complex diseases in a department of a general hospital. Validation experiments demonstrated that SmartGyne achieved an overall accuracy of 80.1 % in triage for gynecological diseases, and 99.4 % in diagnosis for a gynecological subspecialty. In comparison with human physicians, SmartGyne showed competitive triage and diagnostic performance, and improved consultation efficiency and accuracy for physicians with limited specialized experience. These results show that SmartGyne achieves high-quality triage and diagnosis, holding the potential to improve the efficiency of the healthcare system in China, as well as other countries lacking professional gynecologists.},
  archive      = {J_ARTMED},
  author       = {Linru Fu and Che Wang and Zhaoyang Liu and Changzai Pan and Zhe Du and Zhijing Sun and Lan Zhu and Ke Deng},
  doi          = {10.1016/j.artmed.2025.103267},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103267},
  shortjournal = {Artif. Intell. Med.},
  title        = {High-quality triage and diagnosis of gynecological diseases via artificial intelligence},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving prototypical parts abstraction for case-based reasoning explanations designed for the kidney stone type recognition. <em>ARTMED</em>, <em>170</em>, 103266. (<a href='https://doi.org/10.1016/j.artmed.2025.103266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The in-vivo identification of the kidney stone types during an ureteroscopy would be a major medical advance in urology, as it could reduce the time of the tedious renal calculi extraction process, while diminishing infection risks. Furthermore, such an automated procedure would make possible to prescribe anti-recurrence treatments immediately. Nowadays, only few experienced urologists are able to recognize the kidney stone types in the images of the videos displayed on a screen during the endoscopy. This visual recognition by urologists is also highly operator dependent. Thus, several deep learning (DL) models have recently been proposed to automatically recognize the kidney stone types using ureteroscopic images. However, these DL models are of black box nature and do not establish the relationship of the visual features they used to take the decision with the color, texture and morphological features visually analyzed in biological laboratories to determine the type of extracted kidney stone fragments using the reference morphoconstitutional analysis (MCA) procedure. This contribution proposes a case-based reasoning DLmodel which uses prototypical parts (PPs) and generates local and global descriptors. The PPs encode for each class (i.e., kidney stone type) visual feature information (hue, saturation, intensity and textures) similar to that used by biologists during MCA. The PPs are optimally generated due a new loss function used during the model training. Moreover, the local and global descriptors of PPs allow to explain the decisions (“what” information, “where in the images”) in an understandable way for biologists and urologists. The proposed DL model has been tested on a database including images of the six most widespread kidney stone types in industrialized countries. The overall average classification accuracy was 90 . 37 ± 0 . 6 % . When comparing this results with that of the eight other DL models of the kidney stone state-of-the-art, it can be seen that the valuable gain in explanability was not reached at the expense of accuracy which was even slightly increased with respect to that ( 88 . 2 ± 2 . 1 % ) of the best method of the literature. These promising and interpretable results also encourage urologists to put their trust in AI-based solutions.},
  archive      = {J_ARTMED},
  author       = {Daniel Flores-Araiza and Francisco Lopez-Tiro and Clément Larose and Salvador Hinojosa and Andres Mendez-Vazquez and Miguel Gonzalez-Mendoza and Gilberto Ochoa-Ruiz and Christian Daul},
  doi          = {10.1016/j.artmed.2025.103266},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103266},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving prototypical parts abstraction for case-based reasoning explanations designed for the kidney stone type recognition},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical multimodal foundation models in clinical diagnosis and treatment: Applications, challenges, and future directions. <em>ARTMED</em>, <em>170</em>, 103265. (<a href='https://doi.org/10.1016/j.artmed.2025.103265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning have significantly revolutionized the field of clinical diagnosis and treatment, offering novel approaches to improve diagnostic precision and treatment efficacy across diverse clinical domains, thus driving the pursuit of precision medicine. The growing availability of multi-organ and multimodal datasets has accelerated the development of large-scale Medical Multimodal Foundation Models (MMFMs). These models, known for their strong generalization capabilities and rich representational power, are increasingly being adapted to address a wide range of clinical tasks, from early diagnosis to personalized treatment strategies. This review offers a comprehensive analysis of recent developments in MMFMs, focusing on three key aspects: datasets, model architectures, and clinical applications. We also explore the challenges and opportunities in optimizing multimodal representations and discuss how these advancements are shaping the future of healthcare by enabling improved patient outcomes and more efficient clinical workflows.},
  archive      = {J_ARTMED},
  author       = {Kai Sun and Siyan Xue and Fuchun Sun and Haoran Sun and Yu Luo and Ling Wang and Siyuan Wang and Na Guo and Lei Liu and Tian Zhao and Xinzhou Wang and Lei Yang and Shuo Jin and Jun Yan and Jiahong Dong},
  doi          = {10.1016/j.artmed.2025.103265},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103265},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical multimodal foundation models in clinical diagnosis and treatment: Applications, challenges, and future directions},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end solution for out-of-hospital emergency medical dispatch triage based on multimodal and continual deep learning. <em>ARTMED</em>, <em>170</em>, 103264. (<a href='https://doi.org/10.1016/j.artmed.2025.103264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study was to build a multimodal, multitask predictive model—named E2eDeepEMC 2 —to improve out-of-hospital emergency incident severity assessments while coping with shifts in data distributions over time. We drew on 2 054 694 independent incidents recorded by the Valencian emergency medical dispatch service between 2009 and 2019 (excluding 2013), combining demographic, temporal, clinical and free-text inputs. To handle temporal drift, our model integrates continual learning strategies and comprises three encoder modules (for context, clinical data and text), whose outputs are merged to predict the life-threatening level, admissible response delay and emergency system jurisdiction. Compared with the Valencian Region’s existing in-house triage protocol, E2eDeepEMC 2 achieved absolute F1-score gains of 18.46% for life-threatening level, 25.96% for response delay and 3.63% for jurisdiction. Compared to non-continual learning baselines, it also outperformed them by 3.04%, 9.66% and 0.58%, respectively. Deployment of E2eDeepEMC 2 is currently underway in the Valencian Region, underscoring its practical impact on real-world emergency dispatch decision-making.},
  archive      = {J_ARTMED},
  author       = {Pablo Ferri and Carlos Sáez and Antonio Félix-De Castro and Purificación Sánchez-Cuesta and Juan M. García-Gómez},
  doi          = {10.1016/j.artmed.2025.103264},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103264},
  shortjournal = {Artif. Intell. Med.},
  title        = {An end-to-end solution for out-of-hospital emergency medical dispatch triage based on multimodal and continual deep learning},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRA-PT: Low-rank adapting UNETR for hippocampus segmentation using principal tensor singular values and vectors. <em>ARTMED</em>, <em>170</em>, 103254. (<a href='https://doi.org/10.1016/j.artmed.2025.103254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hippocampus is an important brain structure involved in various psychiatric disorders, and its automatic and accurate segmentation is vital for studying these diseases. Recently, deep learning-based methods have made significant progress in hippocampus segmentation. However, training deep neural network models requires substantial computational resources, time, and a large amount of labeled training data, which is frequently scarce in medical image segmentation. To address these issues, we propose LoRA-PT, a novel parameter-efficient fine-tuning (PEFT) method that transfers the pre-trained UNETR model from the BraTS2021 dataset to the hippocampus segmentation task. Specifically, LoRA-PT divides the parameter matrix of the transformer structure into three distinct sizes, yielding three third-order tensors. These tensors are decomposed using tensor singular value decomposition to generate low-rank tensors consisting of the principal singular values and vectors, with the remaining singular values and vectors forming the residual tensor. During fine-tuning, only the low-rank tensors (i.e., the principal tensor singular values and vectors) are updated, while the residual tensors remain unchanged. We validated the proposed method on three public hippocampus datasets, and the experimental results show that LoRA-PT outperformed state-of-the-art PEFT methods in segmentation accuracy while significantly reducing the number of parameter updates. Our source code is available at https://github.com/WangangCheng/LoRA-PT/tree/LoRA-PT .},
  archive      = {J_ARTMED},
  author       = {Guanghua He and Wangang Cheng and Hancan Zhu and Gaohang Yu},
  doi          = {10.1016/j.artmed.2025.103254},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103254},
  shortjournal = {Artif. Intell. Med.},
  title        = {LoRA-PT: Low-rank adapting UNETR for hippocampus segmentation using principal tensor singular values and vectors},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMSupcon: An image fusion-based multi-modal supervised contrastive method for brain tumor diagnosis. <em>ARTMED</em>, <em>170</em>, 103253. (<a href='https://doi.org/10.1016/j.artmed.2025.103253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of brain tumors is pivotal for effective treatment, with MRI serving as a commonly used non-invasive diagnostic modality in clinical practices. Fundamentally, brain tumor diagnosis is a type of pattern recognition task that requires the integration of information from multi-modal MRI images. However, existing fusion strategies are hindered by the scarcity of multi-modal imaging samples. In this paper, we propose a new training paradigm tailored for the scenario of multi-modal imaging in brain tumor diagnosis, called multi-modal supervised contrastive learning method (MMSupcon). This method significantly enhances diagnostic accuracy through two key components: multi-modal medical image fusion and multi-modal supervised contrastive loss. First, the fusion component integrates complementary imaging modalities to generate information-rich samples. Second, by introducing fused samples to guide original samples in learning feature consistency or inconsistency among classes, our loss component effectively preserves the integrity of cross-modal information while maintaining the distinctiveness of individual modalities. Finally, MMSupcon is validated on a real-world brain tumor dataset collected from Beijing Tiantan Hospital, achieving state-of-the-art performance. Furthermore, additional experiments on two public BraTS glioma classification datasets also demonstrate our substantial performance improvements. The source code is released at https://github.com/hywang02/MMSupcon .},
  archive      = {J_ARTMED},
  author       = {Haoyu Wang and Jing Zhang and Siying Wu and Haoran Wei and Xun Chen and Yunwei Ou and Xiaoyan Sun},
  doi          = {10.1016/j.artmed.2025.103253},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103253},
  shortjournal = {Artif. Intell. Med.},
  title        = {MMSupcon: An image fusion-based multi-modal supervised contrastive method for brain tumor diagnosis},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathway information on methylation analysis using deep neural network (PROMINENT): An interpretable deep learning method with pathway prior for phenotype prediction using gene-level DNA methylation. <em>ARTMED</em>, <em>170</em>, 103236. (<a href='https://doi.org/10.1016/j.artmed.2025.103236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background DNA methylation is a key epigenetic marker that influences gene expression and phenotype regulation, and is affected by both genetic and environmental factors. Traditional linear regression methods such as elastic nets have been employed to assess the cumulative effects of multiple DNA methylation markers on phenotypes. However, these methods often fail to capture the complex nonlinear nature of the data. Recent deep learning approaches, such as MethylNet, have improved the prediction accuracy but lack interpretability and efficiency. Findings To address these limitations, we introduced P athway Info r mati o n on M ethylat i on Analysis using a Deep Ne ural N e t work (PROMINENT), a novel interpretable deep learning method that integrates gene-level DNA methylation data with biological pathway information for phenotype prediction. PROMINENT enhances interpretability and prediction accuracy by incorporating gene- and pathway-level priors from databases such as Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG). It employs SHapley Additive exPlanations (SHAP) to prioritize significant genes and pathways. Evaluated across various datasets, childhood asthma, idiopathic pulmonary fibrosis (IPF), and first-episode psychosis (FEP)—PROMINENT consistently outperformed existing methods in terms of prediction accuracy and computational efficiency. PROMINENT also identified crucial genes and pathways involved in disease mechanisms. Conclusions PROMINENT represents a significant advancement in leveraging DNA methylation data for phenotype prediction, offering both high accuracy and interpretability within reasonable computational time. This method holds promise for elucidating the epigenetic underpinnings of complex diseases and enhancing the utility of DNA methylation data in biomedical research.},
  archive      = {J_ARTMED},
  author       = {Soyeon Kim and Laizhi Zhang and Yidi Qin and Rebecca I. Caldino Bohn and Hyun Jung Park},
  doi          = {10.1016/j.artmed.2025.103236},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103236},
  shortjournal = {Artif. Intell. Med.},
  title        = {Pathway information on methylation analysis using deep neural network (PROMINENT): An interpretable deep learning method with pathway prior for phenotype prediction using gene-level DNA methylation},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="asoc">ASOC - 71</h2>
<ul>
<li><details>
<summary>
(2025). Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets. <em>ASOC</em>, <em>185</em>, 113969. (<a href='https://doi.org/10.1016/j.asoc.2025.113969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors segmentation in Magnetic Resonance Imaging (MRI) images poses significant challenges owing to the uncertain location and size of the tumors, the difficulty in describing their boundaries, and the fuzzy demarcation of diseased tissues. Although U-Net and its recent variants have emerged as leading models for semantic segmentation in medical imaging, they still face structural limitations. These limitations cause the erosion of detail information during downsampling and poor performance in segmenting small lesions when handling targets of varying sizes, indicating a lack of detail handling capability. To counteract these issues, we designed a segmentation model that enhances detail features using frequency information. To reduce the loss of feature information during downsampling, we developed a downsampling module based on lifting wavelets. By lifting wavelets to group and integrate features according to frequency from high to low, we reduce feature resolution while enhancing information transmission and minimizing feature information loss. In our designed multi-frequency directional filtering edge feature extraction module, we extract low-frequency and high-frequency features and construct a dual-channel multi-directional filtering combination. This combination extracts directional information from low-frequency and high-frequency features separately, increasing the multi-angle directional information of the features and enriching the detailed information such as direction and position within the features. On the BraTS2018, BraTS2020, and BraTS2024 brain tumor datasets, our model demonstrated optimal results compared to 14 other advanced models. The average Dice Similarity Coefficients are 78.48 %, 79.80 %, and 74.35 %, while the 95th percentile Hausdorff Distances are 5.75, 6.60, and 7.72. Our code link is https://github.com/Eric-H8/BraTS_Seg_Model .},
  archive      = {J_ASOC},
  author       = {Xin Hua and Zhijiang Du and Hongjian Yu and Zibo Li and Qiaohui Lu and Hui Zhao},
  doi          = {10.1016/j.asoc.2025.113969},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extracting knowledge from limited data: An updated review of data-driven and model-driven few-shot learning for agriculture. <em>ASOC</em>, <em>185</em>, 113968. (<a href='https://doi.org/10.1016/j.asoc.2025.113968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has demonstrated considerable success in agricultural applications. However, its conventional implementations heavily depend on large-scale labelled datasets—a requirement that is often impractical in agriculture due to data scarcity, high annotation costs, or environmental variability. While insufficient training data can significantly limit the performance of standard deep learning models, Few-Shot Learning (FSL) has emerged as a transformative paradigm, enabling robust model training with minimal labelled samples by utilising limited data for training instead. Despite its potential, a critical review assessing how FSL addresses expert system challenges in agriculture remains notably absent. This paper attempts to fill this void by presenting an updated comprehensive review of FSL's applications in agriculture. We categorise FSL methodologies into two primary approaches: data processing-driven and model learning-driven. Data processing–driven approaches address data scarcity by enriching representational diversity through synthetic samples generated with models such as generative adversarial networks, or by transferring knowledge from related domains to improve generalisation. In contrast, model learning–driven strategies confront the same challenge through specialised architectures and optimisation techniques that enable effective generalisation from limited samples. Within this taxonomy, data processing–driven paradigms include transfer learning and generative artificial intelligence, while model learning–driven paradigms cover metric learning methods such as Siamese or prototypical networks, together with model-based and optimisation approaches designed for efficient generalisation. Our analysis pinpoints cutting-edge technologies within each sector, shedding light on overlooked areas and opportunities where FSL can harness limited data to yield promising outcomes when used to solve problems in agriculture.},
  archive      = {J_ASOC},
  author       = {Kam Meng Goh and Usman Ullah Sheikh and Jun Kit Chaw and Weng Kin Lai and Weng Chun Tan and Santhi Krishnamoorthy},
  doi          = {10.1016/j.asoc.2025.113968},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113968},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Extracting knowledge from limited data: An updated review of data-driven and model-driven few-shot learning for agriculture},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coverage exploration of unknown obstacle-cluttered environments using a swarm of ground robots. <em>ASOC</em>, <em>185</em>, 113964. (<a href='https://doi.org/10.1016/j.asoc.2025.113964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a coverage exploration algorithm for unknown obstacle-cluttered environments using a swarm of ground robots. A key contribution of this work is the proposed fitness function, which balances multiple exploration objectives and encourages robots to disperse effectively, avoiding excessive overlapping visits. The robots are assumed to start from a single corner of the environment, reflecting practical situations where pre-distributing them is not feasible. This setup highlights a key feature of the algorithm, as it enables self-organization and effective distribution of the robots throughout the environment. The robustness of the method is demonstrated through experiments in various environmental setups, showing its resilience to different obstacle structures and reliable performance across diverse scenarios. The approach also leverages the benefits of swarm behavior, where an increasing number of robots improves exploration efficiency through enhanced collaboration and coverage. The algorithm is evaluated against a swarm random walk approach and two multi-robot meta-heuristic methods, significantly outperforming them in terms of coverage efficiency and robustness.},
  archive      = {J_ASOC},
  author       = {Khalil Al-rahman Youssefi and Wilfried Elmenreich},
  doi          = {10.1016/j.asoc.2025.113964},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113964},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Coverage exploration of unknown obstacle-cluttered environments using a swarm of ground robots},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WamGLM: A multimodal large-scale language model for wafer map defect information in-depth query through multi-turn dialogue based on prototypical supervised contrastive learning. <em>ASOC</em>, <em>185</em>, 113962. (<a href='https://doi.org/10.1016/j.asoc.2025.113962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure production efficiency and process stability in semiconductor manufacturing, it is of critical importance to detect wafer map defects and perform information query for tracing and solving problems during the manufacturing process. Numerous vision models based on deep learning have been successfully applied to wafer map defect recognition (WMDR), yielding remarkable results. However, the dynamic and in-depth querying of wafer map defect information remains relatively underexplored. Leveraging the rapid advancements in multimodal large language models (MLLMs), this paper proposes a novel approach for wafer map defect information query (WMDIQ). First, following the paradigm of employing cross-modal alignment model to bridge vision and language models, an end-to-end response MLLM: general language model for wafer map (WamGLM), is constructed for WMDIQ. Concurrently, by designing an interactive dialogue framework between large language models (LLMs), the first large-scale multi-turn dialogue dataset: visual multi-turn question answering dataset for wafer map defects (WaferMapVMQA Dataset), is constructed for wafer map defect analysis. Subsequently, WamGLM is trained using a two-stage fine-tuning strategy. In the first stage, a visual fine-tuning method based on prototypical supervised contrastive learning (PSCL) is introduced to enhance the intra-class compactness and inter-class separability of defect features. In the second stage, language fine-tuning is conducted using the WaferMapVMQA Dataset to infuse specialized knowledge into WamGLM. To validate the effectiveness and superiority of the proposed method, experiments are conducted on a real wafer map dataset. The results demonstrate that the proposed method significantly outperforms other methods in both defect recognition performance and information query response performance. Our code is available at: https://github.com/ZihaoLei/WamGLM .},
  archive      = {J_ASOC},
  author       = {Shulong Gu and Zihao Lei and Guangrui Wen and Quanning Xu and Zhaojun Steven Li and Xuefeng Chen and Chunsheng Yang},
  doi          = {10.1016/j.asoc.2025.113962},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113962},
  shortjournal = {Appl. Soft. Comput.},
  title        = {WamGLM: A multimodal large-scale language model for wafer map defect information in-depth query through multi-turn dialogue based on prototypical supervised contrastive learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria linguistic optimization for covert communication in secure LLM-based steganography. <em>ASOC</em>, <em>185</em>, 113960. (<a href='https://doi.org/10.1016/j.asoc.2025.113960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel framework for covert communication through secure steganography using large language models (LLMs). Our approach leverages multi-criteria linguistic optimization to encode secret information directly into stylistic features of auto-regressively generated text. This strategy balances embedding capacity with naturalness and coherence. The secret message is partitioned into fixed-size blocks. Each block is embedded into binary stylistic feature vectors via a surjective linear mapping, which introduces redundancy. This redundancy enables the use of a history-aware cost function that selects stylistic vectors to minimize abrupt transitions and preserve fluency across sentences. Candidate sentences are generated by prompting LLMs with contextual and stylistic constraints. Rejection sampling then ensures exact feature matching and high linguistic quality. Experimental evaluation in multiple LLMs, diverse text contexts, and parameter settings demonstrates effective embedding capacities of up to 0.30 bits per token while maintaining strong linguistic naturalness, validated through perplexity, lexical diversity, readability, and a linguistic acceptability metric. Importantly, decoding recovers the full secret with zero error under ideal conditions. This confirms the reliability of the method. The current work focuses on embedding efficiency and imperceptibility. Robustness against active text alterations and formal undetectability assessments remain open challenges for future research. The proposed multi-criteria linguistic optimization framework offers a promising avenue for advanced covert communication by harmonizing secure information embedding with fluent, human-like language generation.},
  archive      = {J_ASOC},
  author       = {Kamil Woźniak and Marek R. Ogiela and Lidia Ogiela},
  doi          = {10.1016/j.asoc.2025.113960},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113960},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-criteria linguistic optimization for covert communication in secure LLM-based steganography},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A granularity time series forecasting model combining three-way decision and trend information granule. <em>ASOC</em>, <em>185</em>, 113957. (<a href='https://doi.org/10.1016/j.asoc.2025.113957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term forecasting of time series plays a vital role across diverse applications but is challenged by error accumulation arising from recursive predictions and the insufficient retention of trend information in conventional methods. To tackle these issues, we propose a novel forecasting model based on granular time series (GTS). The model utilizes an improved L 1 -trend filtering technique to achieve optimal segmentation of information granules, preserving essential trend features. Subsequently, we introduce dual evaluation functions based on distance similarity to jointly drive the three-way decision (TWD) process for aggregating information granules, thereby effectively reducing error propagation. Finally, the aggregated granules serve as inputs to a long short-term memory (LSTM) neural network to generate accurate forecasts. In addition, the proposed model is evaluated on several real-world datasets through sensitivity and comparative analyses. The results demonstrate that the model exhibits strong performance in long-term forecasting tasks.},
  archive      = {J_ASOC},
  author       = {Jianuan Qiu and Shuhua Su and Jingjing Qian},
  doi          = {10.1016/j.asoc.2025.113957},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113957},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A granularity time series forecasting model combining three-way decision and trend information granule},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective genetic programming for binary classification with adaptive thresholds and a generalization-optimizing fitness function. <em>ASOC</em>, <em>185</em>, 113956. (<a href='https://doi.org/10.1016/j.asoc.2025.113956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) has been widely applied to classifier construction due to its flexible representation and powerful feature construction capabilities. Existing studies have proposed various fitness functions to improve GP-based classifiers, but most of them rely on a fixed decision threshold. However, when dealing with imbalanced classification problems, a fixed threshold often biases the model toward the majority class, thereby compromising overall performance. To address this issue, in this paper, we propose a novel multi-objective GP framework for constructing binary classifiers with adaptive threshold adjustment. During evolution, the method employs Youden’s Index to dynamically adjust the threshold of each individual, enabling the classifiers to better fit the underlying data distribution. In addition, we introduce a new class separation metric, dist t , to quantify the clarity of class boundaries and enhance the generalization ability of the evolved models. The framework jointly optimizes three objectives: minority class accuracy, majority class accuracy, and the proposed dist t metric. Experiments on 14 imbalanced datasets demonstrate that our method significantly outperforms conventional single-objective GP with fixed thresholds. Further results also confirm the positive impact of the proposed dist t metric on classification performance. Compared to seven existing GP algorithms and five traditional machine learning classifiers, our approach achieves superior overall performance and better generalization ability.},
  archive      = {J_ASOC},
  author       = {Minghui Bai and Yuan Gao and Xiaoying Gao and Jianbin Ma},
  doi          = {10.1016/j.asoc.2025.113956},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113956},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective genetic programming for binary classification with adaptive thresholds and a generalization-optimizing fitness function},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fuzzy entropy optimization with opposition-based archimedes search for robust multilevel image segmentation. <em>ASOC</em>, <em>185</em>, 113943. (<a href='https://doi.org/10.1016/j.asoc.2025.113943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation plays a critical role in diverse computer vision applications. Multilevel thresholding (MLT) remains one of its most widely used unsupervised techniques due to its simplicity and interpretability. However, existing MLT methods often suffer from two major limitations: (1) the inability to adapt to local intensity variations and (2) the computational burden associated with high-dimensional threshold search. To address these challenges, this study proposes a novel segmentation framework that integrates a Proximity-Adaptive Fuzzy Entropy (PAFE) model with an Opposition-Based Learning-enhanced Archimedes Optimization Algorithm (OBL-EAOA). The PAFE model utilizes dynamically adjusted trapezoidal membership functions based on intensity proximity to candidate thresholds, allowing for a more adaptive and smooth entropy surface. Meanwhile, the OBL-EAOA enhances optimization performance through opposition-based learning and adaptive parameter control, improving exploration diversity and convergence speed. The proposed PAFE-EAOA framework is validated on two benchmark datasets, BSD500 and PASCAL VOC 2012, using five standard metrics: PSNR, SSIM, FSIM, SNR, and computation time. Compared with several state-of-the-art methods including Kapur Entropy (KE)-EAOA, Fuzzy Entropy (FE)-EAOA, Patch-Levy-Based Bees Algorithm (PLBA), Marine Predators Algorithm (MPA), Improved Grey Wolf Optimizer (IGWO), and standard Archimedes Optimization Algorithm (AOA), the proposed approach consistently achieves superior segmentation quality. Notably, it reduces computation time by up to 60 % and achieves statistically significant improvements, as confirmed by the Wilcoxon signed-rank test. These results demonstrate the framework’s robustness, scalability, and effectiveness for real-world MLT-based image segmentation.},
  archive      = {J_ASOC},
  author       = {Anusha Ganesan and Sungho Kim and Ganesan Nagabushnam},
  doi          = {10.1016/j.asoc.2025.113943},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113943},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive fuzzy entropy optimization with opposition-based archimedes search for robust multilevel image segmentation},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework. <em>ASOC</em>, <em>185</em>, 113942. (<a href='https://doi.org/10.1016/j.asoc.2025.113942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal additive manufacturing (AM) has revolutionized industries such as aerospace and automotive manufacturing due to its ability to rapidly prototype complex structures. Laser Directed Energy Deposition (L-DED) is a key AM technique, offering high deposition rates and superior mechanical properties. However, the inherent complexity and high cost of L-DED equipment demand reliable maintenance management to minimize downtime. Traditional maintenance approaches struggle to keep pace with escalating production demands and to cope with growing equipment complexity. To address this, we propose a dual-driven intelligent maintenance system for L-DED, integrating Digital Twins (DT) and Large Language Models (LLMs). The system features a comprehensive DT framework that synchronizes the virtual entity with the physical one in real time, it also incorporates an intelligent maintenance Q&A assistant powered by Retrieval-Augmented Generation (RAG), leveraging L-DED maintenance knowledge bases to provide accurate operational support. Additionally, we propose a Directed Acyclic Graphs (DAG)-based framework to assess LLMs’ ability to guide users through complete fault diagnosis. Our work aims to enhance the reliability and efficiency of L-DED maintenance through advanced digital technologies, ultimately improving productivity and reducing downtime in additive manufacturing.},
  archive      = {J_ASOC},
  author       = {Jian Tang and Shitong Peng and Jianan Guo and Danya Song and Dongna Gao and Weiwei Liu and Fengtao Wang},
  doi          = {10.1016/j.asoc.2025.113942},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113942},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model. <em>ASOC</em>, <em>185</em>, 113941. (<a href='https://doi.org/10.1016/j.asoc.2025.113941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large model technology exemplified by large language models has been applied in the field of industrial fault diagnosis. However, existing large models are optimized for specific equipment types and have yet to fully exploit the potential of time-series monitoring data to enable widespread application across diverse mechanical equipment in various industrial scenarios. To address this challenge, a fault diagnosis large model (UniTS-FD) is designed based on unified time series model (UniTS). First, a multi-scale feature fusion backbone network is developed based on UniTS backbone to capture general mechanical fault features. Second, the fault classification head integrates the Pearson correlation coefficient to assess the similarity of class information within linear space for enabling adaptive classification. Third, P-LoRA fine-tuning approach incorporating LoRA and prompt technology is proposed to fine-tune the fault classification head, which enhances the generalization ability of the UniTS-FD model for fault diagnosis tasks of various mechanical equipment. Finally, the UniTS-FD model is pre-trained on 11 fault datasets and fine-tuning experiments were conducted on four different fault datasets to achieve cross-machine fault diagnosis. Experimental results demonstrate the effectiveness of the UniTS-FD in fault diagnosis tasks.},
  archive      = {J_ASOC},
  author       = {Zhiwei Zhang and Chengbin Wei and Weimin Zhang and Long Wen},
  doi          = {10.1016/j.asoc.2025.113941},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113941},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A federated learning-based method for personalized manufacturing service recommendation with collaborative relationships. <em>ASOC</em>, <em>185</em>, 113940. (<a href='https://doi.org/10.1016/j.asoc.2025.113940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the industrial Internet environment, the increasing complexity of manufacturing tasks has rendered them no longer accomplishable by independent manufacturing services. Meanwhile, current recommendation systems predominantly face challenges in maintaining data privacy and security during client parameter exchanges. To address these issues, this paper proposes CoFedSVD+ +, a federated learning-based method for personalized manufacturing service recommendation that integrates an enhanced SVD+ + algorithm with homomorphic encryption. First, we devise an enhanced similarity calculation method to analyze collaborative relationships among manufacturing services. Second, we implement a homomorphic encryption protocol within the federated learning framework to resolve data isolation challenges. Third, the improved SVD+ + algorithm is employed to capture implicit feedback information and predict missing Quality of Service (QoS) metrics. Fourth, a Top-N service composition recommendation list is generated through synergistic analysis of collaborative relationships and QoS predictions. Finally, we validate our approach using real-world case data from an industrial Internet platform. Experimental comparisons with existing recommendation algorithms demonstrate superior recommendation effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Lei Wang and Jun Wang and Feng Xiang and Tongshun Li and Yang Xu and Yibing Li},
  doi          = {10.1016/j.asoc.2025.113940},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113940},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A federated learning-based method for personalized manufacturing service recommendation with collaborative relationships},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Span-level emotion-cause-category triplet extraction with instruction tuning LLMs and data augmentation. <em>ASOC</em>, <em>185</em>, 113938. (<a href='https://doi.org/10.1016/j.asoc.2025.113938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Span-level emotion-cause-category triplet extraction is a fine-grained task in emotion cause analysis that aims to identify emotion spans, cause spans, and their corresponding emotion categories from documents. Existing methods, including clause-level emotion-cause pair extraction and span-level emotion-cause detection, often suffer from redundant information and difficulties in accurately classifying emotion categories, particularly when emotions are expressed implicitly or ambiguously. To overcome these challenges, this study explores a fine-grained approach to span-level emotion-cause-category triplet extraction and introduces an innovative framework that leverages instruction tuning and data augmentation techniques based on large language models. The proposed method employs task-specific triplet extraction instructions and utilizes low-rank adaptation to fine-tune large language models, eliminating the necessity for intricate task-specific architectures. Furthermore, an LLM-based data augmentation strategy is developed to address data scarcity by guiding large language models in generating high-quality synthetic training data. Extensive experimental evaluations demonstrate that the proposed approach significantly outperforms existing baseline methods, achieving at least a 12.8 % improvement in span-level emotion-cause-category triplet extraction metrics. The results demonstrate the method’s effectiveness and robustness, offering a promising avenue for advancing research in emotion cause analysis.},
  archive      = {J_ASOC},
  author       = {Xiangju Li and Dong Yang and Xiaogang Zhu and Faliang Huang and Peng Zhang and Zhongying Zhao},
  doi          = {10.1016/j.asoc.2025.113938},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113938},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Span-level emotion-cause-category triplet extraction with instruction tuning LLMs and data augmentation},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep cross-visual semantic hashing with self-calibrated collaborative attention. <em>ASOC</em>, <em>185</em>, 113937. (<a href='https://doi.org/10.1016/j.asoc.2025.113937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has garnered considerable attention due to its remarkable retrieval efficiency and low storage cost, particularly in visual retrieval scenarios. However, current deep hashing methods generally integrate hash coding into a single-stream architecture, which limits the discriminative power of learned visual features and yields suboptimal hash codes. Additionally, over-reliance on semantic labels shared across samples fails to fully exploit the intrinsic semantic correlations between labels and corresponding visual features. To address these issues, we propose a deep cross-visual semantic hashing (DCvSH) method for image retrieval. First, we develop a visual image feature decoupling encoding network that leverages a self-calibrated collaborative attention mechanism to disentangle common and specific semantics across related images. These decoupled features are fed into a shared decoder for image reconstruction, yielding discriminative visual feature representations. Second, we construct a cross-visual semantic representation learning network with a two-level multi-layer perceptron to capture the underlying relationships between semantic label encodings and visual feature embeddings, while a hypergraph structure is introduced to preserve pairwise similarity relationships. Experimental results on the CIFAR-10, NUS-WIDE, and MIRFLICKR datasets demonstrate consistent improvements, with average mean average precision (mAP) scores reaching 0.895, 0.874, and 0.881 at different code lengths, respectively. Notably, DCvSH outperforms other baselines across all evaluation metrics.},
  archive      = {J_ASOC},
  author       = {Hao Feng and Xiangbo Zhou and Yue Wu and Jian Zhou and Banglei Zhao},
  doi          = {10.1016/j.asoc.2025.113937},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113937},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep cross-visual semantic hashing with self-calibrated collaborative attention},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large model for fault diagnosis of industrial equipment based on a knowledge graph construction. <em>ASOC</em>, <em>185</em>, 113936. (<a href='https://doi.org/10.1016/j.asoc.2025.113936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the significant heterogeneity of multi-modal data and the challenges in capturing fault semantics for industrial equipment, a fault diagnosis framework that integrates a time-frequency knowledge graph with the large model DeepSeek-V3 is proposed. Specifically, an unsupervised knowledge graph construction method is designed based on multi-modal vibration data signals. This method mines temporal evolution relationships using dynamic time warping and quantifies the relevance between features and faults via mutual information, thereby forming a dynamic graph representation. Additionally, DeepSeek-V3 encodes the natural language descriptions of vibration features, integrating graph structure and time-frequency map features to achieve collaborative reasoning and diagnosis among text, graphs, and maps. Experimental results show that the proposed method achieves high accuracy and significantly outperforms benchmark models, surpassing traditional methods. The proposed framework, through the deep integration of data-driven knowledge graphs and large model semantic understanding, demonstrates high precision, strong robustness, and transparent decision-making capabilities, providing new insights for intelligent diagnosis of industrial equipment.},
  archive      = {J_ASOC},
  author       = {Jichao Zhuang and Jiaming Yang and Weigang Li and Jian Chen and Yunjun Zheng and Zhuyun Chen},
  doi          = {10.1016/j.asoc.2025.113936},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113936},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Large model for fault diagnosis of industrial equipment based on a knowledge graph construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval-valued pythagorean fuzzy distance-based extended inferior ratio method for multiattribute decision-making: Application to green supplier selection in manufacturing industry. <em>ASOC</em>, <em>185</em>, 113935. (<a href='https://doi.org/10.1016/j.asoc.2025.113935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued Pythagorean fuzzy sets (IVPFSs) have emerged as a powerful tool for handling uncertainty and vagueness in multiattribute decision-making (MADM). In this paper, we first propose a novel distance measure for IVPFSs based on triangular divergence, which satisfies all core distance axioms and significantly improves discrimination ability compared to existing measures. Building on this, we introduce a maximizing deviation strategy with a new loss function to objectively determine attribute weights. Furthermore, we develop an extended inferior ratio (EIR) method that incorporates a dynamic weight parameter to flexibly balance the influence of positive and negative ideal solutions. The performance of the proposed method is demonstrated through a case study on green supplier selection in the manufacturing industry. The results indicate that, among the seven criteria evaluated, the most suitable suppliers are ranked as follows: β (1.0000), α (0.6471), δ (0.3500), ϵ (0.0690), and θ (0.0000). In addition, sensitivity and comparative analyses confirm the robustness and consistency of the proposed method, reflecting its effectiveness and practical value for sustainable decision-making in real-world scenarios.},
  archive      = {J_ASOC},
  author       = {Zhe Liu and Donglai Wang and Muhammet Deveci and Sukumar Letchmunan},
  doi          = {10.1016/j.asoc.2025.113935},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113935},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval-valued pythagorean fuzzy distance-based extended inferior ratio method for multiattribute decision-making: Application to green supplier selection in manufacturing industry},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multidimensional trade performance assessment for integrating sustainability and economic diversification in OECD countries using a spherical fuzzy SIWEC-SPC-based decision support model. <em>ASOC</em>, <em>185</em>, 113934. (<a href='https://doi.org/10.1016/j.asoc.2025.113934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Countries participate in regional trade blocks to enhance their trade activities and trade performance. This study proposes a novel approach to trade performance assessment, introducing innovations both in terms of performance parameters and methodology. From a performance parameter perspective, the inclusion of sustainable development and economic diversity levels in trade performance evaluation differentiates this study from traditional trade performance measurement approaches. From a methodological perspective, a hybrid model that simultaneously considers both subjective and objective criterion weighting based on expert opinions is introduced. The spherical fuzzy (SF)−simple weight calculation (SIWEC)−symmetry point of criterion (SPC)−opportunity losses-based polar coordinate distance (OPLO-POCOD) model, developed as a decision support system, is proposed for evaluating the trade performance of country blocs. SF-SIWEC is employed as the subjective criterion weighting method, while SPC serves as the objective criterion weighting method. The OPLO-POCOD alternative ranking method is employed to calculate the trade performance of countries. The proposed methodology is applied to the Organization for Economic Cooperation and Development (OECD) countries. According to the subjective weighting method, "sustainable development (0.0978)" emerges as the most important criterion, whereas in the objective weighting method, "number of product types (export) (0.1612)" is identified as the most significant one. In the final criterion weights, "number of product types (export) (0.1232)" is also determined to be the most important criterion. Considering the final criterion weights, the United States (0.9871) has the highest trade performance among the OECD countries. Thus, when both sustainability and economic diversification are considered, it is understood that the most influential criteria in determining multidimensional trade performance are the number of exported product types and sustainable development. From this perspective, the United States stands out as the country with the highest multidimensional trade performance among OECD countries. This study contributes to the literature by integrating sustainability and economic diversification parameters into trade performance measurement as well as proposing a comprehensive methodology for performance evaluation in trade blocs.},
  archive      = {J_ASOC},
  author       = {Galip Cihan Yalçın and Karahan Kara and Emre Kadir Özekenci and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113934},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113934},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multidimensional trade performance assessment for integrating sustainability and economic diversification in OECD countries using a spherical fuzzy SIWEC-SPC-based decision support model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing supply routes in a network interdiction model with dual defense operations. <em>ASOC</em>, <em>185</em>, 113933. (<a href='https://doi.org/10.1016/j.asoc.2025.113933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel bi-level defender–attacker model (BDAM) designed to address real-world homeland defense scenarios. Building on the shortest path network interdiction problem (SPNIP), BDAM incorporates dual defense operations—node interdiction and edge destruction—while explicitly modeling the defender’s supply support. Unlike conventional SPNIP formulations, BDAM jointly considers the attacker’s path disruption and the defender’s logistical requirements, ensuring that all interdicted nodes are supported by available supply nodes without exceeding their capacity. To solve this NP-hard problem, a hybrid metaheuristic algorithm named Improved Simplified Swarm Optimization with Dijkstra (iSSOD) is proposed. The method integrates a population-based SSO framework with a randomized repair mechanism to ensure feasibility and an entropy-guided local search to enhance exploitation. The attacker’s optimal response is computed efficiently using Dijkstra’s algorithm, embedded within the defender’s fitness evaluation. The experimental results on 36 artificial instances demonstrate that iSSOD consistently outperforms several benchmark evolutionary algorithms, providing high-quality solutions through a defense-aware, supply-constrained optimization framework. Furthermore, a real-world case study based on geographic data validates the model’s applicability under realistic defense conditions.},
  archive      = {J_ASOC},
  author       = {Wei-Chang Yeh and Chyh-Ming Lai and Tsung-Hua Wu},
  doi          = {10.1016/j.asoc.2025.113933},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113933},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimizing supply routes in a network interdiction model with dual defense operations},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A continuous encoding-based representation for efficient multi-fidelity multi-objective neural architecture search. <em>ASOC</em>, <em>185</em>, 113932. (<a href='https://doi.org/10.1016/j.asoc.2025.113932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) is a powerful tool for automatically designing optimized deep learning models but is often limited by high computational costs, especially in multi-objective settings. To address this, an adaptive Co-Kriging-assisted multi-fidelity multi-objective NAS algorithm is proposed to reduce the computational cost and accelerate convergence of NAS by incorporating a clustering-based local multi-fidelity infill sampling strategy. Additionally, we introduce a novel continuous encoding method to compactly represent node connections within a generalized U-Net backbone, significantly reducing search dimensionality. Extensive experiments demonstrate that our method consistently outperforms state-of-the-art NAS approaches under limited computational budgets on three benchmarks, a 2D Darcy flow regression task, a CHASE_DB1 biomedical image segmentation task, and an urban wind velocity prediction task. Analysis further shows that our algorithm autonomously identifies design patterns consistent with expert-curated U-Net variants in literature, confirming its efficiency and potential for insight into performant architectures.},
  archive      = {J_ASOC},
  author       = {Zhao Wei and Chin Chun Ooi and Yew-Soon Ong},
  doi          = {10.1016/j.asoc.2025.113932},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113932},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A continuous encoding-based representation for efficient multi-fidelity multi-objective neural architecture search},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning-based adaptive operator selection for traveling salesman problem. <em>ASOC</em>, <em>185</em>, 113930. (<a href='https://doi.org/10.1016/j.asoc.2025.113930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In evolutionary optimization, effectively leveraging knowledge about search operator performance is crucial for enhancing algorithmic results. Traditional operator selection strategies often rely on fixed heuristics or trial-and-error, which struggle to adapt to the nonstationary search dynamics of evolutionary runs—i.e., the stage-dependent, instance-dependent, and population-dependent shifts in operator effectiveness—and typically yield suboptimal performance. To address these challenges, we propose a novel meta-learning-based adaptive operator selection (AOS) framework. It leverages a Long Short-Term Memory (LSTM) neural network to learn temporal patterns of operator performance from historical data and dynamically adjust operator choice on-the-fly. The framework also integrates domain-specific biases to preserve population diversity and promote effective exploration, and it continuously updates its selection policy through dynamic online learning as the evolutionary process unfolds. Experiments on the Traveling Salesman Problem (TSP) benchmark demonstrate that the proposed LSTM-based AOS method significantly outperforms conventional approaches to operator selection. In particular, it achieved a median optimality gap of 9.87 % on a suite of TSP instances—approximately a 20 % improvement over the best fixed-operator configuration—indicating superior solution quality. Moreover, our approach consistently surpassed other state-of-the-art AOS techniques, underscoring the efficacy of the LSTM-driven framework and its significant potential to enhance evolutionary algorithm performance on complex optimization tasks.},
  archive      = {J_ASOC},
  author       = {Ho Young Jeong and Byung Duk Song},
  doi          = {10.1016/j.asoc.2025.113930},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113930},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Meta-learning-based adaptive operator selection for traveling salesman problem},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and robust ensemble evolving pixel cloud-based image segmentation approach. <em>ASOC</em>, <em>185</em>, 113926. (<a href='https://doi.org/10.1016/j.asoc.2025.113926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing cluster-based image segmentation algorithms have the burden of iterative computation caused by the change of cluster centers and are sensitive to noise. In this paper, we present a fast and robust ensemble evolving pixel cloud-based image segmentation approach. The concept of pixel clouds by clustering pixels of the same pattern around their focal pixels is proposed. The following attributes distinguish the proposed algorithm: (1) The pixel clouds are evolvable according to the global densities of the incoming pixels and the number of pixel clouds is automatically determined. (2) The focal pixels of pixel clouds are dynamically updated with the highest local densities by using the recursive density estimation, which avoids redundant distance calculations when a new pixel arrives. (3) A multiscale morphological gradient reconstruction operation is employed to merge or filter meaningless pixel clouds, especially in noisy images, which helps to adaptively polish neighboring pixel clouds and compact the pixel clouds. (4) An ensemble structure is introduced to fasten the image segmentation speed by splitting the whole image into multiple independent sub-images, in which the pixel clouds are independently formed and evolved. Comprehensive experiments on natural images, remote sensing images and medical images reveal that the proposed approach surpasses the state-of-the-art algorithms in both segmentation accuracy and computational efficiency. Even for the noisy images, the proposed approach demonstrates more robust performance.},
  archive      = {J_ASOC},
  author       = {Tao Zhang and Hai-Jun Rong and Zhao-Xu Yang and Chi-Man Vong},
  doi          = {10.1016/j.asoc.2025.113926},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113926},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fast and robust ensemble evolving pixel cloud-based image segmentation approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven approach to tackling academic stress-coping and mental health issues in college students using spherical fuzzy MARCOS methodology. <em>ASOC</em>, <em>185</em>, 113925. (<a href='https://doi.org/10.1016/j.asoc.2025.113925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drastically developing nature of the knowledge economy and the rising need for top-notch expertise have placed tremendous pressure on college students. As higher education becomes more accessible, masses of students are enrolling in colleges, which puts additional pressure on colleges and institutions; as a result, they cannot provide adequate resources to the students. As the class size increases, many students require mental health assistance, academic guidance, and financial aid, which then puts pressure on the teachers and the facilities. This flood of students overloads the facilities, resulting in it becoming more challenging to provide attention and concern, leading many students to feel overlooked and affecting their mental health. Due to not getting timely support, students may find it challenging to handle their academic responsibilities. Moreover, the students face a heavy workload, unclear guidance, and limited resource access. The objective of this study is to develop a structured, data-driven decision-making framework for systematically evaluating and improving student mental health and academic stress-coping strategies in a college setting. To address this, a comprehensive decision-making structure, measurement of alternatives, and ranking according to the compromised solution (MARCOS) within the spherical fuzzy (SF) environment, has been applied, which evaluates the key factors causing mental health issues by comparing the ideal and anti-ideal alternatives. The novelty of the proposed approach lies in leveraging the SF framework’s explicit ability to model hesitation (abstinence) alongside truth and falsity degrees, enabling more accurate representation of subjective psychological assessments compared to traditional fuzzy models. Furthermore, the method calculates utility functions corresponding to each alternative (coping technique), prioritizes the strategies, and selects the most effective intervention. The results reveal that personalized mental health plans emerged as the top-ranked coping strategy, highlighting the importance of tailored support in culturally and contextually diverse academic environments.},
  archive      = {J_ASOC},
  author       = {Raiha Imran and Munazza Amin and Kifayat Ullah and Dragan Pamucar and Zeeshan Ali and Oumaima Saidani and Vladimir Simic},
  doi          = {10.1016/j.asoc.2025.113925},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113925},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A data-driven approach to tackling academic stress-coping and mental health issues in college students using spherical fuzzy MARCOS methodology},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure and efficient vehicle control of autonomous vehicles using federated deep reinforcement learning. <em>ASOC</em>, <em>185</em>, 113924. (<a href='https://doi.org/10.1016/j.asoc.2025.113924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving is largely considered a revolutionary technology and the ultimate alternative for smart urban mobility. Artificial Intelligence (AI) has been the main pillar of AV technology. However, despite the significant success achieved through the application of various Deep Reinforcement Learning (DRL) techniques in the field of AVs, numerous challenges remain to be addressed. Particularly, in the case of vehicle control, existing works have shown limited results when extensive action and state spaces are involved, and where the efficacy of agents is often compromised due to the variability of states and actions. In response to these challenges, we introduce a pioneering approach leveraging Federated Deep Reinforcement Learning (FDRL), which fosters the exchange of experiences among participating agents while safeguarding their privacy. FDRL enhances the exploration of all agents’ actions and states in different environments and effectively overcomes the problem of low sample efficiency in action and state spaces for all agents. Our approach is based on three distinct FDRL algorithms: Federated Proximal Policy Optimization (FPPO), Federated Deep Deterministic Policy Gradient (FDDPG), and Federated Deep Q-Network (FDQN), each tailored to control AVs within unique environments. Our results demonstrate the superiority of our approach in terms of average reward, waiting time, and speed, when compared to local models such as PPO, DDPG, and DQN.},
  archive      = {J_ASOC},
  author       = {Badr Ben Elallid and Nabil Benamar and Miloud Bagaa and Nabil Mrani},
  doi          = {10.1016/j.asoc.2025.113924},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113924},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Secure and efficient vehicle control of autonomous vehicles using federated deep reinforcement learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulating phenomenal consciousness using generative agents based on large language models. <em>ASOC</em>, <em>185</em>, 113922. (<a href='https://doi.org/10.1016/j.asoc.2025.113922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios, LLMs may require multiple attempts to achieve human-level performance, potentially leading to inaccurate responses or inferences in practical environments, affecting their long-term consistency and behavior. This paper introduces the Internal Time-Consciousness Machine (ITCM), a computational consciousness structure to simulate the process of human consciousness. We further propose the ITCM-based Agent (ITCMA), which supports action generation and reasoning in open-world settings, and can independently complete tasks. ITCMA enhances LLMs’ ability to understand implicit instructions and apply common-sense knowledge by considering agents’ interaction and reasoning with the environment. The trained ITCMA performs better than state-of-the-art (SOTA) in the seen set. Even untrained ITCMA can achieve higher task completion rates than SOTA on the seen set, indicating its superiority over traditional intelligent agents in utility and generalization. In real-world tasks with quadruped robots, the task completion rate of untrained ITCMA is close to its performance in the unseen set, demonstrating its comparable utility and universality in real-world settings. CCS Concepts: ∙ Human-centered computing → Interactive systems and tools; ∙ Computing methodologies → Natural language processing.},
  archive      = {J_ASOC},
  author       = {Hanzhong Zhang and Jibin Yin and Haoyang Wang and Ziwei Xiang},
  doi          = {10.1016/j.asoc.2025.113922},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113922},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Simulating phenomenal consciousness using generative agents based on large language models},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymmetrical variable driven simulated binary crossover operator for large scale multi-objective optimization. <em>ASOC</em>, <em>185</em>, 113921. (<a href='https://doi.org/10.1016/j.asoc.2025.113921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the excessive number of decision variables, large scale multi-objective optimization has gradually become a hot research topic over the past few years. Although various reproduction operators have been proposed to effectively generate offspring solutions in the huge decision space, they have a common issue in that most of them are focused on the symmetrical variables and neglect asymmetrical variables. Based on the summary above, it is empirically proved that asymmetrical variables with great similarities play an important role in facilitating each other ′ s effective exploration of the huge decision space. Therefore, to effectively tackle large scale multi-objective optimization problems, the asymmetrical variables are incorporated into the design of a new asymmetrical variable driven simulated binary crossover operator. On the basis of the proposed asymmetrical variable driven simulated binary crossover operator, this paper further constructs a large scale multi-objective evolutionary framework based on asymmetrical variable driven simulated binary crossover operator. Extensive experiments and analyses on typical large scale multi-objective optimization problems with up to 10,000 decision variables and practical engineering problems with 6000 decision variables show its superiority over state-of-the-art optimizers.},
  archive      = {J_ASOC},
  author       = {Maoqing Zhang and Kun Wang},
  doi          = {10.1016/j.asoc.2025.113921},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113921},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Asymmetrical variable driven simulated binary crossover operator for large scale multi-objective optimization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling. <em>ASOC</em>, <em>185</em>, 113920. (<a href='https://doi.org/10.1016/j.asoc.2025.113920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agentic workflows, powered by Industrial Large Models (ILMs), represent a significant development emphasizing collaboration between humans and intelligent systems. This paper presents a structured perspective on the role of agentic workflows for smart design and manufacturing, grounded in integrating ILMs. We define an agentic workflow as a labeled Activity-on-Vertex (AOV) graph, where each node represents a functionally closed subtask and is executed by an ILM-based agent, a human operator, or an automated system. This formalism supports analyzable, modular, and hybrid execution, offering a foundation for modeling complex, mixed-initiative processes in manufacturing environments. To support real-world deployment, we introduce a set of reusable agentic workflow patterns that describe how ILM agents perceive, plan, and act in coordination with other components. Besides, a proof-of-concept case study illustrates the practical application of the human-in-the-loop framework through the agentic generation of CAD models. The study covers task decomposition, workflow implementation, and benchmarking, providing evidence for the feasibility of agentic workflows. Building upon these findings, this work contributes to advancing the development and application of agentic workflows in smart manufacturing contexts.},
  archive      = {J_ASOC},
  author       = {Keyou Zheng and Yuanwei Zhong and Xuyang Su and Jiewu Leng and Qiang Liu and Xin Chen},
  doi          = {10.1016/j.asoc.2025.113920},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fault diagnosis of railway vehicle on-board controller with large language models. <em>ASOC</em>, <em>185</em>, 113919. (<a href='https://doi.org/10.1016/j.asoc.2025.113919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying fault types of the Vehicle On-Board Controller (VOBC) in railway systems is of great significance for ensuring the safe operation of trains. Recently, Large Language Models (LLMs) have demonstrated excellent semantic understanding and natural language interaction capabilities, offering a novel solution for VOBC fault diagnosis. However, LLMs pretrained on general domains lack specific knowledge related to railway VOBC fault diagnosis scenarios, resulting in insufficient adaptability to railway-specific text corpora. This paper conducts an in-depth study on the adaptability of LLMs to VOBC fault diagnosis and proposes Railway Fault Diagnosis Large Language Model (RFD-LLM). First, we adopt railway domain adaptation based on Low-Rank Adaptation (LoRA) to match VOBC fault patterns. Second, instruction tuning is applied to achieve domain knowledge alignment and enhance the model’s ability to follow instructions. The proposed RFD-LLM is the first large language model-based fault diagnosis model for railway VOBC, capable of efficiently and accurately identifying seven types of VOBC fault patterns. RFD-LLM provides a new solution for the development of large models in the railway domain.},
  archive      = {J_ASOC},
  author       = {Cong Peng and Jiali Peng and Zisheng Wang and Zongyao Wang and Junjie Chen and Jianping Xuan and Tielin Shi},
  doi          = {10.1016/j.asoc.2025.113919},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113919},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive fault diagnosis of railway vehicle on-board controller with large language models},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An MADM model using frank operations based power aggregation operator under p,q-quasirung orthopair fuzzy sets for highway selection in war-plane landing. <em>ASOC</em>, <em>185</em>, 113918. (<a href='https://doi.org/10.1016/j.asoc.2025.113918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In military logistics and operational planning, selecting an optimal highway for war-plane landings and take-offs is a critical and strategic decision. This process involves several key factors that directly affect mission success, operational safety, and public security. Among the most important attributes are the highway’s straight and long stretch with sufficient width to accommodate war-plane landing distances, and its surface condition, which must be free from obstacles, debris, and damage. Low traffic density is crucial to avoid the risk of collisions during landing. Additionally, favourable weather conditions, proximity to military camps, availability of emergency services and fuel, and a secure and hazard-free surrounding terrain are essential for safe and efficient operations. These factors collectively form the backbone of a reliable and tactical approach to highway selection for military air operations. Thus, in order to assess and rank various options for the landing and take-off of war planes, a strong and trustworthy procedure for making decisions is required. The purpose of this experiment is to build a comprehensive structure in multi-attribute decision making environment, using suggested p , q -quasirung orthopair fuzzy Frank power averaging as well as p , q -quasirung orthopair fuzzy Frank power geometric operators to capture ambiguity and uncertainty in highway selection. Furthermore, p , q -quasirung orthopair fuzzy Frank power weighted aggregation along with p , q -quasirung orthopair fuzzy Frank power weighted geometric operators are implemented for integrating the distance as well as similarity measures. Finally, sensitivity analysis and a comparison with the present technique are included to further demonstrate the superiority and validity of the technique that is suggested.},
  archive      = {J_ASOC},
  author       = {Sanjita Giri and Sankar Kumar Roy and Muhammet Deveci},
  doi          = {10.1016/j.asoc.2025.113918},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113918},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An MADM model using frank operations based power aggregation operator under p,q-quasirung orthopair fuzzy sets for highway selection in war-plane landing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility. <em>ASOC</em>, <em>185</em>, 113917. (<a href='https://doi.org/10.1016/j.asoc.2025.113917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of metropolitan populations causes transportation network congestion, which increases fuel usage, travel time, and environmental damage. Traditional traffic management systems (TMS) seldom handle these issues in real time. Recently developed Large Language Models (LLMs), especially those using Reinforcement Learning (RL), may enhance urban transportation systems. Traffic management technology's real-time flexibility and shifting congestion patterns provide improved potential. Traditional approaches cannot estimate traffic flow or adapt to urban settings. A strong AI-driven method is needed to improve urban mobility and traffic flow. This paper introduces the LLM-RL Traffic Optimization Framework (LLM-RL-TOF). LLMs analyze real-time traffic data and give predictive insights in this context. Due to these new insights, the RL algorithm can improve traffic flow in real time and reduce congestion via dynamic traffic management. IoT sensors and urban traffic cameras capture real-time traffic data, including traffic volume and incidents. This data helps the LLM estimate bottlenecks, accidents, and traffic congestion. An RL agent uses LLM outputs to adjust traffic signal timing and suggest alternate routes. With real-time alternatives, traffic flow and urban mobility may be optimized. The junction throughput rate rose 17.5 %, the queue length accumulation index fell 22.3 %, and the average vehicle delay fell 18.6 %. The decrease in average vehicle delay enabled all these gains.},
  archive      = {J_ASOC},
  author       = {Arvind R. Singh and Muhammad Wasim Abbas Ashraf and Rajkumar Singh Rathore and Bin Li and M.S. Sujatha},
  doi          = {10.1016/j.asoc.2025.113917},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113917},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving speech emotion recognition using gated cross-modal attention and multimodal homogeneous feature discrepancy learning. <em>ASOC</em>, <em>185</em>, 113915. (<a href='https://doi.org/10.1016/j.asoc.2025.113915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition (SER) remains a significant and crucial challenge due to the complex and multifaceted nature of human emotions. To tackle this challenge, researchers strive to integrate information from diverse modalities through multimodal learning. However, existing multimodal fusion techniques often overlook the intricacies of interactions between different modalities, resulting in suboptimal feature representations. In this paper, we propose WavFusion, a multimodal framework designed for SER that tackles key research challenges, such as effective multimodal fusion, modality heterogeneity, and discriminative representation learning. By utilizing a gated cross-modal attention mechanism and multimodal homogeneous feature discrepancy learning, WavFusion outperforms existing state-of-the-art methods on benchmark datasets. Our research highlights the importance of capturing subtle cross-modal interactions and learning discriminative representations for accurate multimodal SER. Experimental results indicate that the proposed method is highly competitive and better than most of the latest state-of-the-art methods for SER. WavFusion achieves 0.78 % and 1.27 % improvement in accuracy and 0.74 % and 0.44 % improvement in weighted F1 score over the previous methods on the IEMOCAP and MELD datasets, respectively.},
  archive      = {J_ASOC},
  author       = {Feng Li and Jiusong Luo and Wanjun Xia},
  doi          = {10.1016/j.asoc.2025.113915},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113915},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving speech emotion recognition using gated cross-modal attention and multimodal homogeneous feature discrepancy learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind turbine blades defect detection based on global and local attention with multi-feature fusion. <em>ASOC</em>, <em>185</em>, 113914. (<a href='https://doi.org/10.1016/j.asoc.2025.113914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbine blades are prone to small-scale defects—such as cracks, corrosion, and contamination—during long-term operation. Accurate detection of these defects is essential for ensuring the safety and efficiency of wind power systems. However, small-object detection remains challenging due to limited feature representation and weak discriminative cues. To address this, an enhanced YOLOX-s-based framework called Global-Frequency Dual-aware YOLOX (GFD-YOLOX) is proposed. GFD-YOLOX introduces three main improvements. First, the Path Aggregation Feature Pyramid Network (PAFPN) in the neck is replaced with Dual-Frequency Fused Bidirectional Feature Pyramid Network (DFF-BiFPN) to strengthen multi-scale contextual representation. Second, the backbone bottleneck is redesigned with a lightweight structure, improving computational efficiency and convergence speed. Third, a Hierarchical Frequency-Adaptive Fusion (HFAF) module is integrated to enhance cross-scale feature interaction by combining fine-grained and global information. On the self-constructed WTBlade-Defect dataset (3570 annotated images, five defect types: corrosion, hide-craze, surface-eye, thunderstrike, dirt), GFD-YOLOX achieves mAP@0.5 and mAP@0.5:0.95 scores of 94.5 % and 68.9 %, respectively, with 44.3 FPS inference—improving by 13.6 % and 14.4 % over state-of-the-art models. On the public dataset of Ashley Foster et al., it achieves 94.8 % and 69.3 %, with gains of 10.4 % and 10.9 %. These results demonstrate that GFD-YOLOX delivers substantial accuracy gains while maintaining real-time speed and strong cross-dataset generalization, indicating high potential for deployment in operational wind turbine inspection systems.},
  archive      = {J_ASOC},
  author       = {Dandan Liu and Mingjie Liu},
  doi          = {10.1016/j.asoc.2025.113914},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113914},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind turbine blades defect detection based on global and local attention with multi-feature fusion},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous feature selection with group structure mining in fuzzy decision systems for medical diagnosis. <em>ASOC</em>, <em>185</em>, 113913. (<a href='https://doi.org/10.1016/j.asoc.2025.113913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications such as medical diagnosis and group decision making, the potential structural information contained in multi-dimensional features in the form of group domains plays an important role. However, most existing feature selection methods adopt transformed feature spaces for group structure analysis, which lack intrinsic semantic information interpretation. Meanwhile, fuzzy and uncertain heterogeneous data acquired from multiple devices increase the difficulty of task learning. Motivated by these two issues, this work devises a Heterogeneous Feature Selection method with Group Structure Mining in fuzzy decision systems (HFS-GSM), which follows the principle of one “strategy" and one “mechanism". Specifically, a feature group generation strategy based on fuzzy approximation Markov blanket is first designed for mining features with group structure, which introduces the concept of Markov blanket into the fuzzy rough set and utilizes the idea of approximation and fuzzy uncertainty measures. Then, a fuzzy dependency-based overlapping group elimination mechanism is proposed by attribution division, which avoids local redundancy while preserving global discriminative information. Furthermore, the effectiveness of HFS-GSM is verified in comparison with seven representative feature selection methods on publicly available medical datasets. Finally, medical diagnosis data provided by a hospital are obtained to demonstrate the reliability and utility of HFS-GSM in practical applications.},
  archive      = {J_ASOC},
  author       = {Jihong Wan and Hongmei Chen and Li Xiao and Chuangpeng Shen and Wei Huang and Xiaoping Li},
  doi          = {10.1016/j.asoc.2025.113913},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113913},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Heterogeneous feature selection with group structure mining in fuzzy decision systems for medical diagnosis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ahybrid ICEEMDAN-BO-GRU model for real-time grouting parameter prediction. <em>ASOC</em>, <em>185</em>, 113912. (<a href='https://doi.org/10.1016/j.asoc.2025.113912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unit injection volume is one of the core control indicators for evaluating the construction quality of curtain grouting. In actual construction processes, accurate prediction of unit injection volume enables early warning of abnormal conditions during construction. However, geological conditions and construction parameters significantly influence unit injection volume, among other factors, and the data exhibits high nonlinearity. Previous studies have achieved suboptimal prediction accuracy. To address the issue of low prediction accuracy in traditional algorithms when handling highly nonlinear data, this study first applies the Improved Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN) algorithm to decompose the raw data, and the nonlinear features in the curtain grouting data are effectively eliminated. Subsequently, the Gated Recurrent Unit (GRU) and Bayesian Optimization (BO) algorithms are organically integrated, and Bayesian optimization is applied to the hyperparameters of the GRU model to enhance its predictive performance, thereby constructing an intelligent predictive model for the curtain grouting unit injection volume. Finally, an engineering application study was conducted using an actual curtain grouting project at a pumped-storage power station. The results indicate that the model exhibits good computational accuracy and efficiency, providing theoretical and methodological support for constructing intelligent prediction models in curtain grouting.},
  archive      = {J_ASOC},
  author       = {Fei Tong and Dongqing Bai and Xufei Ma and Lin Cheng and Jie Yang and Xiangyu Cao},
  doi          = {10.1016/j.asoc.2025.113912},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113912},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ahybrid ICEEMDAN-BO-GRU model for real-time grouting parameter prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DefGCL: Defence-enhanced graph contrastive learning against attribute inference attacks. <em>ASOC</em>, <em>185</em>, 113911. (<a href='https://doi.org/10.1016/j.asoc.2025.113911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-structured data are prevalent in many real-world applications, such as social networks, drug discovery, and fraud detection. While Graph Neural Networks (GNNs) have shown remarkable performance by capturing rich relational patterns, their success often relies on large labeled datasets and raises growing privacy concerns. Graph Contrastive Learning (GCL) has emerged as a powerful unsupervised alternative by leveraging data augmentations to learn robust representations without labeled data. However, recent studies reveal that GCL models are particularly vulnerable to attribute inference attacks, and existing works prioritize performance improvement over privacy protection. To address this issue, we propose a D e f ense-enhanced G raph C ontrastive L earning, dubbed DefGCL , that integrates four coordinated defense strategies to enhance privacy without degrading utility. Specifically, DefGCL employs edge-based graph augmentations to limit exposure to structural attributes, selects negative samples with low attribute sensitivity scores to reduce leakage, modifies the contrastive loss to decouple graph embeddings from attributes, and injects differential privacy noise during the embedding stage. Extensive experiments on five benchmark datasets demonstrate that DefGCL achieves state-of-the-art (SOTA) performance in both privacy preservation and task accuracy. For instance, on the AIDS dataset, DefGCL reduces attribute inference accuracy by 35 % while incurring only a 0.60 % drop in main task performance. Additionally, DefGCL improves computational efficiency by reducing runtime by nearly 50 % compared to baseline methods. 1},
  archive      = {J_ASOC},
  author       = {Jinyin Chen and Fanyu Ao and Wenbo Mu and Haiyang Xiong},
  doi          = {10.1016/j.asoc.2025.113911},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113911},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DefGCL: Defence-enhanced graph contrastive learning against attribute inference attacks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction. <em>ASOC</em>, <em>185</em>, 113910. (<a href='https://doi.org/10.1016/j.asoc.2025.113910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable wind speed prediction is critical for stabilizing wind power integration. However, current methods are limited by accuracy and stability issues, hindering their large-scale application in wind farms. To overcome these problems, this study innovatively proposes an IMFSformer-CNN model integrating three core components. First, the spatio-temporal and multi-factor feature extraction technology comprehensively captures the spatio-temporal patterns and complex dependencies of wind speed dynamics, incorporating multiple factors such as meteorological variables and spatial correlation. Second, the multi-feature sparse attention mechanism reduces computational complexity by combining sparse attention with multi-feature attention, enhancing representation ability and scalability for precise interval value prediction. Finally, the enhanced interval spatio-temporal prediction fusion model combines the global dependency modeling capabilities of the improved Transformer architecture with the local receptive field advantages of CNN. This hybrid design facilitates the simultaneous capture of both macro-scale atmospheric patterns and micro-scale wind speed fluctuations. The model achieved prediction interval coverage probabilities of 0.921 and 0.899, and coverage width criteria of 1.493 and 3.776, outperforming other models on both datasets. This significantly enhances accuracy and practical value for wind farm cluster forecasting, supporting more reliable and efficient wind energy integration into power grids.},
  archive      = {J_ASOC},
  author       = {Weiyi Jiang and Jujie Wang and Xuecheng He},
  doi          = {10.1016/j.asoc.2025.113910},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction. <em>ASOC</em>, <em>185</em>, 113909. (<a href='https://doi.org/10.1016/j.asoc.2025.113909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction has significant application value in many fields. However, existing methods often fail to fully capture the spatial relationships between joints and the temporal flow of information when modeling complex spatiotemporal dependencies. Additionally, these methods are prone to overfitting dominant features while neglecting other important aspects, and struggle with perceiving contour features effectively. To address these issues, this study introduces a novel encoder-decoder framework. The encoder generates a dual-layer adaptive adjacency matrix using a distance partition strategy to parameterize joint relationships, while incorporating a gating mechanism to control the temporal flow of information. The decoder then employs separate spatiotemporal attention modules to decode temporal and spatial features independently. These features are subsequently reconstructed through a spatiotemporal fusion strategy, effectively decoupling and modeling complex spatiotemporal dependencies. To address the issue of overfitting to dominant features, we introduce a denoising reconstruction strategy that allows the model to learn richer combinations of spatiotemporal features under multiple constraints. Furthermore, a multi-granularity information adaptive fusion module is incorporated to achieve adaptive fusion of both local and contour features. Experimental results across several benchmark datasets demonstrate that our method significantly outperforms the state-of-the-art approaches, showcasing its effectiveness in human motion prediction tasks.},
  archive      = {J_ASOC},
  author       = {Yong Li and Linfeng Zhu and Haofei Xie and Xinchang Yi},
  doi          = {10.1016/j.asoc.2025.113909},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113909},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFNN: Fractional order basis function multi-step neural network method for fractional partial differential equations. <em>ASOC</em>, <em>185</em>, 113907. (<a href='https://doi.org/10.1016/j.asoc.2025.113907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement in artificial intelligence technology, the increasing number of researchers utilize it to address complex equations in ocean engineering. So the technology of artificial intelligence has become a practical area of research. In this paper, we design a novel method to solve the fractional order long water wave equation, which is called the fractional order basis function multi-step neural network. Firstly, a power series is constructed based on a fractional order basis function, which serves as the approximate solution. Secondly, neural networks and the initial conditions of differential equations are integrated into the construction of approximate solutions. Furthermore, the solution is discretized, and a multi-step unfolding strategy is employed on the resulting discrete solution. This approach ensures that each point in the solution is influenced by its predecessor. By means of repeated applications of the optimization algorithm, the residuals are successively diminished, thereby yielding approximate solutions to the equations. Finally, the efficacy and versatility of the proposed strategy were validated through a series of numerical experiments. Compared with the method of fractional physics-informed neural networks, there are up to 18.7 -fold and 22.8 -fold increases in stability of average and maximum residuals. Simultaneously, initial conditions are retained in new solutions.},
  archive      = {J_ASOC},
  author       = {Jianke Zhang and Xudong Tian and Chang Zhou},
  doi          = {10.1016/j.asoc.2025.113907},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113907},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FFNN: Fractional order basis function multi-step neural network method for fractional partial differential equations},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrimination index based attribute reduction for partially labeled heterogeneous data via a new prediction label strategy and statistical distribution of data. <em>ASOC</em>, <em>185</em>, 113904. (<a href='https://doi.org/10.1016/j.asoc.2025.113904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods often struggle to effectively utilize the statistical distribution of data and unlabeled information when dealing with partially labeled heterogeneous data, leading to limited performance in attribute reduction. To address this issue, this paper presents a novel semi-supervised attribute reduction method that integrates statistical distribution of data, conditional discrimination index and a new prediction label strategy. Initially, the similarity between objects is constructed by analyzing the statistical distribution of data. Subsequently, a new prediction label strategy is introduced, which not only utilizes existing label information but also completes missing information by predicting new labels, thereby enhancing the completeness and usability of data. Finally, conditional discrimination index, a tool for measuring the importance of attributes in classification tasks, is employed to design an attribute reduction algorithm. The experimental results on real-world partially labeled heterogeneous datasets show that the proposed p-CDIAR algorithm exhibits superior performance compared to the existing nine reduction algorithms, with an average increase of 4.67 % in classification accuracy and 6.32 % in outlier detection performance.},
  archive      = {J_ASOC},
  author       = {Qingnian Li and Haixin Huang and Tao Lu and Huaming Wei and Zhaowen Li},
  doi          = {10.1016/j.asoc.2025.113904},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113904},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Discrimination index based attribute reduction for partially labeled heterogeneous data via a new prediction label strategy and statistical distribution of data},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended belief rule-based system with online joint learning strategy. <em>ASOC</em>, <em>185</em>, 113901. (<a href='https://doi.org/10.1016/j.asoc.2025.113901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of dynamic data streams in the advanced technology environment, it is necessary to solve the evolving classification problems by using adaptable and interpretable artificial intelligence techniques. To meet this challenge, a new extended belief rule-based (EBRB) system incorporating online joint learning strategy is proposed in this paper. The online joint learning strategy comprises two key components: rule update and parameter update schemes. In the rule update scheme, different rule incorporation processes are designed for the labeled or unlabeled input data while overlapping and redundant rules are removed from the rule base. To adapt the updated rule base, the parameter update scheme is designed to retune the parameters within updated rule base. The antecedent attribute weights are optimized using the Bayesian optimization algorithm and the rule weights are updated based on the consistency of rules. To evaluate the performance of the developed system, it is applied to assist radiologists in diagnosing thyroid nodules. Compared with the existing offline EBRB systems and online learning methods, the proposed online joint learning EBRB system could generate higher classification accuracy with fewer rules in the limited running time.},
  archive      = {J_ASOC},
  author       = {Bingbing Hou and Min Xue and Leilei Chang and Zijian Wu},
  doi          = {10.1016/j.asoc.2025.113901},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113901},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Extended belief rule-based system with online joint learning strategy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing local density and approximate distance for nonparametric outlier detection. <em>ASOC</em>, <em>185</em>, 113898. (<a href='https://doi.org/10.1016/j.asoc.2025.113898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is an essential yet challenging task in intelligent data analysis, and some density-based unsupervised methods have been introduced to identify outliers in low-density regions. However, these methods still suffer from inaccurate density estimation and limited capability in detecting diverse types of outliers. In this study, we propose a nonparametric outlier detection method with the fusion of density and distance (POD-FDD). The proposed method employs adaptive kernel density estimation based on natural neighborhoods, which reduces the sensitivity to parameters in density estimation. Moreover, the optimistic and pessimistic densities are introduced to enhance the reliability of density estimation in the local neighborhood. In addition, approximate reachability distance information is integrated to improve the capability of identifying cluster outliers. Ultimately, a robust parametric-free outlier detection method is developed to detect different types of outliers. Extensive comparative experiments and statistical significance analysis on synthetic and public datasets demonstrate its superior performance, achieving an average improvement of 1.97 % in the AUC metric.},
  archive      = {J_ASOC},
  author       = {Zhiyu Chen and Can Gao and Jie Zhou and Ying Yu},
  doi          = {10.1016/j.asoc.2025.113898},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113898},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fusing local density and approximate distance for nonparametric outlier detection},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model. <em>ASOC</em>, <em>185</em>, 113897. (<a href='https://doi.org/10.1016/j.asoc.2025.113897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, extreme events caused by global climate change have intensified the phenomenon of saltwater intrusion (SWI) in estuaries. The nonlinear and non-stationary characteristics of estuarine SWI have led to an exponential decline in the timeliness of traditional regression prediction models, making it difficult to meet the operational needs of SWI forecasting. To address this, this study proposed a technical framework for SWI risk level forecasting based on temporal clustering, with its core innovation lying in algorithmic improvements for accurately characterizing complex disaster systems. The key challenges in forecasting SWI risk levels involved capturing the dynamic nonlinear relationships between multidimensional disaster factors (such as runoff, tide level, and wind) and SWI severity, as well as enhancing feature discriminability in label-limited scenarios. Accordingly, this study optimized algorithms through dual-path supervised and unsupervised learning: In the supervised learning framework, LightGBM, RF, XGBoost, and Extra trees were introduced as base learners into the Deep Forest (DF) model. The complementary feature-space partitioning of diverse learners was leveraged to improve the model’s ability to distinguish risk -level boundaries, achieving an average performance gain of 7.8 %. In the unsupervised learning framework, discriminative regularization was incorporated into the Extreme Learning Machine-Autoencoder (ELM-AE) model. By forcing features of samples from the same class to cluster toward the class center, the model’s feature separability for rare events (e.g., severe SWI) was enhanced, leading to an average performance improvement of 11 %. Finally, the optimal model was used to extract dynamic evolution patterns between multidimensional disaster factors and SWI risk levels, with interpretability analysis conducted for real-world forecasting. Notably, upstream flow sequences exhibited high distinguishability between no-SWI and severe-SWI, while mild and moderate SWI showed similar flow patterns, with tidal sequences being the primary differentiator. The algorithmic advancements not only enhanced the accuracy and efficiency of SWI forecasting but also provided a generalizable framework for risk classification in nonlinear hydrological systems.},
  archive      = {J_ASOC},
  author       = {Qingqing Tian and Hongyu Yang and Yu Tian and Peiyao Weng},
  doi          = {10.1016/j.asoc.2025.113897},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113897},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with mirror-task for multimodal sentiment analysis. <em>ASOC</em>, <em>185</em>, 113896. (<a href='https://doi.org/10.1016/j.asoc.2025.113896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning (MTL) in Multimodal Sentiment Analysis (MSA) involves implementing various parameter-sharing strategies among tasks. Currently, MSA primarily focuses on hard parameter-sharing mechanisms based on encoder sharing, while soft parameter-sharing is often neglected. To explore a reasonable combination of soft and hard mechanisms in MSA and optimize multimodal representations, along with multimodal contrastive learning, we propose D 3 MSA. It consists of D ouble network (primaryNet and MirrorNet), D ouble parameter-sharing strategies and D ouble contrastive learning modes for multimodal sentiment analysis. D 3 MSA utilizes hard-sharing to consolidate correlations between positive samples of intra-sample contrastive learning. In soft-sharing, we propose a pre-trained MirrorNet (MN) that generates negative samples by the learned inverse distributions. This optimizes the feature space of negative samples. MN interacts with the MSA task through soft-sharing during inter-sample contrastive learning. Experimental results demonstrate that our proposed method can achieve advanced performance on the CMU-MOSI and CMU-MOSEI datasets with lightweight training that requires only a small number of parameters.},
  archive      = {J_ASOC},
  author       = {Hang Shi and Lianmin Zhou and Yuanyuan Pu and Zhengpeng Zhao and Jinjing Gu and Dan Xu},
  doi          = {10.1016/j.asoc.2025.113896},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113896},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning with mirror-task for multimodal sentiment analysis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems. <em>ASOC</em>, <em>185</em>, 113895. (<a href='https://doi.org/10.1016/j.asoc.2025.113895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multimodal multiobjective problems (CMMOPs) have multiple equivalent constrained Pareto optimal sets in the decision space corresponding to the identical constrained Pareto front in the objective space. The key to solving CMMOPs is how to balance feasibility, convergence, and diversity of solutions in both the decision and objective spaces. In view of this, this paper proposes a Nearest-Best neighbors optimization algorithm with constraint-based fitness (NBNOA) to solve CMMOPs. First, a constraint-based fitness assignment scheme is designed to assign specific fitness values to individuals in the population. Then, the Nearest-better-neighbor clustering method is adopted to identify the nearest-better neighbor and best neighbor of each individual according to the specific fitness values. On this basis, a Nearest-Best neighbors guided strategy is developed to guide the search direction of individuals, striking a better balance between exploration and exploitation capabilities. Moreover, a CDP-density elite selection mechanism is constructed to obtain feasible Pareto optimal solutions with higher precision and better diversity. Extensive experiments on two CMMOPs test suites demonstrated that the proposed NBNOA significantly outperforms nine state-of-the-art algorithms. Notably, NBNOA ranks first among all ten algorithms and achieves the best values for 23 out of 31 benchmark functions regarding the reciprocal of Pareto sets proximity and inverted generational distance. Furthermore, NBNOA is applied to a real-world CMMOP, verifying its effective practical application capability. Additionally, NBNOA is tested on two high-dimensional constrained multiobjective optimization problems test suites, further proving its competitive performance in solving complex problems.},
  archive      = {J_ASOC},
  author       = {Xuming Han and Ting Zhou and Limin Wang and Yali Chu},
  doi          = {10.1016/j.asoc.2025.113895},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113895},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency decomposition and patch modeling framework for time-series forecasting. <em>ASOC</em>, <em>185</em>, 113890. (<a href='https://doi.org/10.1016/j.asoc.2025.113890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is widely applied across diverse fields, including finance, transportation, and energy, and has made significant contributions in these areas. However, in real-world applications, time series data can be complex and dynamic. Current methodologies still encounter several challenges in managing high-dimensional data, extracting intricate features, and making long-term forecasts. In this study, we propose a Frequency Decomposition and Patch Modeling Framework (FPF). Our FPF consists of the Frequency Domain Decomposition Block (FDB) and the Dual Patch Modeling Block (DPMB). DPMB consists of Patch Enhancement Block and Patch Mixing Block. First, FDB transforms the input sequence to the frequency domain through the Fast Fourier Transform and designs frequency masks to decompose the data into high-frequency and low-frequency components, to extract fast-changing patterns and trend information respectively. Subsequently, DPMB divides the components into patches, where the high-frequency components are modeled by MLP-based Patch Enhancement Block to capture local features, and the low-frequency components are modeled by Transformer-based Patch Mixing Block to capture global dependencies and cross-patch correlations. We conducted comprehensive experiments using seven real-world time series forecasting datasets, including ETT, Traffic, Electricity, and Weather. The findings indicate that this method demonstrates superior performance in the field of time series forecasting.},
  archive      = {J_ASOC},
  author       = {Denghui Xu and Hua Wang and Fan Zhang},
  doi          = {10.1016/j.asoc.2025.113890},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113890},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Frequency decomposition and patch modeling framework for time-series forecasting},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OdML: An optimization-driven meta-learning framework for multi-task approximate model predictive control. <em>ASOC</em>, <em>185</em>, 113882. (<a href='https://doi.org/10.1016/j.asoc.2025.113882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in approximate model predictive control (MPC) have leveraged deep neural networks (DNNs) to imitate optimal control laws, significantly reducing the computational cost of real-time optimization. However, these methods often struggle to adapt efficiently to previously unseen system dynamics and suffer from poor data efficiency in real time. In this paper, we address these challenges by treating control problems with different system parameters as separate tasks within a meta-learning scope. Under this scope, we propose OdML, an Optimization-driven Meta-Learning approach for approximate MPC that enables rapid online fine-tuning of DNN-based controllers. We introduce an optimization-driven fine-tuning mechanism that allows for fast adaptation to new tasks using limited online data, without requiring full knowledge of the system parameters. Furthermore, to ensure safety during adaptation, we incorporate control barrier functions into the optimization process, allowing the controller to satisfy safety constraints even under previously unseen conditions. We demonstrate the effectiveness of OdML through various simulation scenarios, highlighting its ability to achieve safe and efficient control.},
  archive      = {J_ASOC},
  author       = {Junbo Tong and Shuhan Du and Daming Shi and Wenhui Fan},
  doi          = {10.1016/j.asoc.2025.113882},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113882},
  shortjournal = {Appl. Soft. Comput.},
  title        = {OdML: An optimization-driven meta-learning framework for multi-task approximate model predictive control},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning trader without offline training. <em>ASOC</em>, <em>185</em>, 113881. (<a href='https://doi.org/10.1016/j.asoc.2025.113881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we pursue the question of a fully online trading algorithm (i.e. one that does not need offline training on previously gathered data). For this task we consider Double Deep Q -learning in the episodic setting with Fast Learning Networks approximating the expected reward Q . Additionally, we define the possible terminal states of an episode in such a way as to introduce a mechanism to conserve some of the money in the trading pool when market conditions are seen as unfavourable. Some of these money are taken as profit and some are reused at a later time according to certain criteria. After describing the algorithm, we test it using 1-minute-tick price data for 4 major cryptocurrencies from Binance. We see that the agent performs better than trading with randomly chosen actions on each timestep. And it does so when tested on the whole dataset for a given market as well as on different subsets, representing different market trends.},
  archive      = {J_ASOC},
  author       = {Boian Lazov},
  doi          = {10.1016/j.asoc.2025.113881},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113881},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep reinforcement learning trader without offline training},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering algorithm based on boundary elimination and backbone construction. <em>ASOC</em>, <em>185</em>, 113880. (<a href='https://doi.org/10.1016/j.asoc.2025.113880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) is an effective clustering algorithm, but it still has some problems and faces some challenges. For instance, it cannot identify the variable density datasets, the assignment strategy is easy to produce domino phenomenon, and the clustering results of DPC and its improved algorithms are easily affected by the intersection points between clusters. To solve these problems, in this paper, we propose a novel density peak clustering algorithm based on boundary elimination and backbone construction, called BEBC-DPC. A new local density is defined based on the natural neighbor search, and the boundary degree is defined by the position relationship between each point and its neighbors, which accurately describes the local distribution information of the point. The boundary points of clusters are eliminated by fusing the density and the boundary degree, which reduces the influence of the intersection points on the cluster division. In addition, the cluster backbone construction method based on representative points and representative sets is proposed. The density relationship among non-boundary points is used to form representative sets, and the similarity between representative sets is used to construct the cluster backbones, which can effectively describe the overall distribution structure characteristics of the clusters. Moreover, the adjacency degree of each boundary point is defined by using the neighbor information and distance information, and the boundary points are gradually assigned to the most appropriate cluster backbone based on it to complete the clustering. Finally, sufficient experiments are performed on synthetic, UCI and image datasets, and the proposed BEBC-DPC is compared with DPC and its improved algorithms. Experimental results show the effectiveness of the proposed BEBC-DPC on various types of datasets.},
  archive      = {J_ASOC},
  author       = {Zhizhong Zhao and Sugen Chen and Cong Hu},
  doi          = {10.1016/j.asoc.2025.113880},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Density peak clustering algorithm based on boundary elimination and backbone construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria decision analysis-based framework for supply chain management evaluation with multi-dimensional sensitivity analysis: A green logistics perspective. <em>ASOC</em>, <em>185</em>, 113879. (<a href='https://doi.org/10.1016/j.asoc.2025.113879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transition toward sustainable Supply Chain Management (SCM) presents complex decision-making challenges that require robust and transparent evaluation methods. Effective decision-making in this context requires robust evaluation methods capable of handling complex, multi-dimensional aspects of the decision process. This study proposes a comprehensive decision-support framework that integrates Multi-Criteria Decision Analysis (MCDA) with advanced sensitivity analysis techniques to assess the stability and reliability of alternative rankings under uncertainty. The framework combines established MCDA methods with submodel exclusion analysis and the Comprehensive Sensitivity Analysis Method (COMSAM), which allows for systematic perturbation of the decision matrix and evaluation of robustness across multiple dimensions. Applied to a green logistics case study, the framework demonstrates its capacity to support sustainable decision-making by accounting for varying stakeholder priorities and data uncertainty. The approach offers methodological advances in robustness assessment, practical relevance for sustainability-focused SCM, and open-source implementation to ensure reproducibility. The proposed framework is adaptable to a wide range of decision contexts, contributing to the development of more reliable and explainable MCDA-based evaluations.},
  archive      = {J_ASOC},
  author       = {Jakub Więckowski and Wojciech Sałabun},
  doi          = {10.1016/j.asoc.2025.113879},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113879},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-criteria decision analysis-based framework for supply chain management evaluation with multi-dimensional sensitivity analysis: A green logistics perspective},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable type 2 fuzzy Min–Max neural networks for pattern classification. <em>ASOC</em>, <em>185</em>, 113875. (<a href='https://doi.org/10.1016/j.asoc.2025.113875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fuzzy Min–Max (FMM) algorithm is a powerful classification method capable of handling non-linear class boundaries and making both hard and soft decisions while learning from online data. However, it faces significant challenges, including sensitivity to the expansion coefficient, information loss during the contraction stage, and the overlap problem. To address these limitations, we propose a Reliable Type-2 Fuzzy Min–Max (RT2FMM) algorithm, which incorporates type-2 fuzzy logic to consider hyperbox uncertainty and effectively resolve the overlap problem. By assigning distinct certainties to overlapping regions, RT2FMM eliminates the need for the contraction stage and the overlap test. Additionally, we introduce weighted factors for hyperboxes, which enhances the reliability of membership values and models their mutual effects. Our comprehensive experimental evaluation across twenty datasets demonstrates that RT2FMM significantly outperforms existing FMM-based models in terms of robustness and accuracy. The Friedman test further confirms the superior performance of RT2FMM compared to commonly used classifiers, highlighting its potential as a robust solution for complex classification tasks.},
  archive      = {J_ASOC},
  author       = {Ali Nik-Khorasani and Mohammad-R. Akbarzadeh-T.},
  doi          = {10.1016/j.asoc.2025.113875},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113875},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reliable type 2 fuzzy Min–Max neural networks for pattern classification},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fortifying vision models: A comprehensive survey of defences against adversarial examples. <em>ASOC</em>, <em>185</em>, 113874. (<a href='https://doi.org/10.1016/j.asoc.2025.113874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and Machine learning (ML) have seen many advancements in the past two decades. It has led to the creation of several techniques, including Deep Neural Networks (DNN), Convolution Neural Networks (CNN), Autoencoders, Generative Adversarial Networks (GAN) and Diffusion models. These techniques have been applied to various real-world applications, such as self-driving cars, medical diagnosis and voice assistants. Despite these advancements, a carefully crafted input can fool the ML model. Such attacks are known as adversarial examples. It is a serious threat to safety critical systems. This survey provides a comprehensive review of defences against adversarial examples by tracing their evolution from early empirical methods to more principled, theoretically grounded approaches. We systematically categorise defences based on their underlying mechanisms. In addition to surveying state-of-the-art techniques, we spotlight emerging trends such as generative defences and diffusion-based purification. Finally, we identify persistent vulnerabilities and outline promising directions for future research towards building truly resilient vision models. This work aims to equip researchers and practitioners with a deep understanding of current defences and inspire innovation in adversarial robustness for the next generation of vision applications.},
  archive      = {J_ASOC},
  author       = {Siddheshwar Kumar and Shashank Srivastava and Shashwati Banerjea},
  doi          = {10.1016/j.asoc.2025.113874},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113874},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fortifying vision models: A comprehensive survey of defences against adversarial examples},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform. <em>ASOC</em>, <em>185</em>, 113873. (<a href='https://doi.org/10.1016/j.asoc.2025.113873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative image detection faces persistent challenges in terms of generalization and interpretability, limiting its reliability in complex scenarios. To address these issues, we propose AOT-PixelNet, a lightweight and interpretable detection framework that integrates an Adaptive Orthogonal Transform (AOT) module with a streamlined 1 × 1 convolution-based PixelNet architecture. The AOT module leverages diverse orthogonal transforms, such as FFT and DCT, to extract informative frequency-domain features, thereby enhancing sensitivity to medium- and high-frequency artifacts. Meanwhile, PixelNet minimizes parameter count (only 0.98 million) while effectively capturing cross-channel inconsistencies and mitigating overfitting. Experimental evaluations on multiple unseen GAN and diffusion-based datasets demonstrate that AOT-PixelNet achieves superior performance with minimal computational cost. Specifically, it outperforms the NPR method by 0.6% and 11.76% on the ForenSynths and GenImage datasets, respectively, validating the framework’s robustness, effectiveness, and interpretability.},
  archive      = {J_ASOC},
  author       = {Dengtai Tan and Deyi Yang and Boao Tan and Chengyu Niu and Yang Yang and Shichao Li},
  doi          = {10.1016/j.asoc.2025.113873},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113873},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud. <em>ASOC</em>, <em>185</em>, 113872. (<a href='https://doi.org/10.1016/j.asoc.2025.113872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud facilitates the user to complete their work utilizing the cost strategy of pay-as-you-go, which is based on the consumed Virtual Machine (VM) hours. Thus, the scheduler must offer the highest throughput to attain efficient allocation of resources in the cloud paradigm. Cloud services are dependent on characteristics such as fault tolerance, security, scalability, and availability. Hence, an effective scheduler is necessary to arrange the scheduling tasks and adjust the server loads. Typically, a load-balancing task focuses on detecting the overloaded and under-loaded nodes and adjusting the load between them. When considering the significant role of fault-tolerance in load-balancing algorithms, it seems to suffer from poor organization and a lack of in-depth experiments in this sector. This paper proposes a new task for the load-balancing operation. Initially, task scheduling is performed where the fault tolerance and the priority-aided scheduling approach are adopted. Furthermore, resource optimization is carried out in the scheduling task using Randomly Improved Electric Fish Optimization (RIEFO). To validate the load balancing operation, several multi-objective functions such as resource utilization, delay, time, makespan, active servers, throughput, success rate, fault tolerance rate, and energy consumption are derived. Moreover, because of the system’s dynamic environment, the status of the server varies simultaneously. The server status prediction is significant in allocating the tasks to the server or the VM resources. Thus, the Attention-based Cascaded Residual Bidirectional Long Short-Term Memory (ACRes-BiLSTM) is employed to predict the server status before performing the resource allocation. Finally, the tasks are scheduled effectively using the predicted server status. The performance is estimated using numerous performance metrics.},
  archive      = {J_ASOC},
  author       = {Gudivada Lokesh and Kasarapu Ramani and K.K. Baseer},
  doi          = {10.1016/j.asoc.2025.113872},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113872},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +. <em>ASOC</em>, <em>185</em>, 113871. (<a href='https://doi.org/10.1016/j.asoc.2025.113871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape leaf diseases, such as black rot, powdery mildew, and downy mildew, pose a significant threat to global viticulture, leading to substantial yield losses and reduced fruit quality. Early and accurate identification of these diseases is essential for precision agriculture and sustainable crop management. This study presents a comprehensive comparison of traditional and deep learning-based image segmentation methods for detecting grape leaf lesions. A series of classical segmentation techniques, including Mean Shift, Fuzzy C-Means (FCM), Normalized Cut, K-Means, and Fuzzy K-Means (FKM), were evaluated alongside an advanced DeepLabv3 + model. The baseline DeepLabv3 + architecture was further enhanced by integrating a ResNeSt-50 backbone with various attention mechanisms, including Squeeze-and-Excitation (SE) Block, Convolutional Block Attention Module (CBAM), Bottleneck Attention Module (BAM), Self-Attention, and Dual Attention Network (DANet). Among all models, DeepLabv3 + with ResNeSt-50 and CBAM achieved the highest performance, attaining 98.2 % accuracy, 97.1 % precision, 96.7 % recall, 96.6 % mean Intersection over Union (mIoU), and a 96.8 % Dice Score. The results demonstrate that attention-augmented deep networks significantly outperform classical methods, especially in handling complex lesion structures under diverse environmental conditions. While traditional algorithms remain useful in resource-constrained scenarios, deep learning models, particularly those enhanced with spatial and channel-wise attention, offer greater accuracy and robustness, making them ideal for integration into intelligent agricultural platforms such as drones, mobile scanners, and automated disease monitoring systems. Future work will focus on incorporating temporal and multimodal data, expanding dataset diversity, and optimizing lightweight models for real-time deployment on edge devices.},
  archive      = {J_ASOC},
  author       = {Kittipol Wisaeng},
  doi          = {10.1016/j.asoc.2025.113871},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113871},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger. <em>ASOC</em>, <em>185</em>, 113870. (<a href='https://doi.org/10.1016/j.asoc.2025.113870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Teaching-Learning-Based optimization (TLBO) algorithm, which includes teacher phase and learner phase, is a widely used method for global optimization. However, TLBO will experience premature convergence and get stuck in local optimum when faced with complex optimization challenges. Especially when tackling complex problems in practical engineering applications, which involves multiple variables and numerous constraints. To address this issue, a new variant termed Stochastic Proportional–Differential TLBO (SPD-TLBO) has been developed. The SPD phase allows students to learn not only from the current population but also from previous stochastic errors and their generation differences using adaptive random operators. By incorporating an SPD operator into the original TLBO framework, the algorithm’s search diversity is enhanced, reducing the likelihood of premature convergence to local optimum. The experimental results conducted at the IEEE Conference on Evolutionary Computation 2014 (CEC 2014) indicated that the proposed SPD-TLBO algorithm achieved an effective balance between exploration and exploitation capabilities. Specifically, the SPD-TLBO algorithm achieves the highest ranking in 21 out of 30 cases (70%) for 30-dimensional problems and 18 out of 30 cases (60%) for 50-dimensional problems. Statistical tests and convergence analyses show that the SPD-TLBO algorithm outperforms other algorithms in solving global optimization problems. Additionally, when applied to engineering optimization problems, the SPD-TLBO algorithm shows significant advantages over other algorithms. Therefore, the SPD-TLBO algorithm is further applied to optimize the structure of a wafer transfer finger in semiconductor manufacturing.},
  archive      = {J_ASOC},
  author       = {Jinfeng Sun and Yunlang Xu and Haibo Zhou},
  doi          = {10.1016/j.asoc.2025.113870},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113870},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network. <em>ASOC</em>, <em>185</em>, 113867. (<a href='https://doi.org/10.1016/j.asoc.2025.113867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus Disease 2019 (COVID-19) is an infectious illness that affects both humans and animals. Individuals infected with COVID-19 are prone to lung complications during the recovery phase . Radiography and Computed Tomography (CT) are the most commonly used methods for diagnosing lung-related diseases. The primary aim of this paper is to assess the impact of COVID-19 on patients’ lungs, heart, and blood sugar levels using a deep learning-based approach. Initially, data related to the heart, blood sugar levels, and lungs of COVID-19-infected individuals are collected. From this dataset, three types of features are extracted. Deep features are obtained using Iterated Dilated Convolutional Neural Networks (IDCNN). From these deep features, which are obtained from the IDCNN, the optimal weighted features are derived by implementing the Hybrid Dolphin Pod Cuttlefish Optimization (HDPCO) algorithm. Subsequently, the HDPCO algorithm is also employed for optimal feature extraction. In addition, dimensionality reduction is performed using Principal Component Analysis (PCA). These three sets of features from the IDCNN, HDPCO, and PCA, are then fused into a single feature set . This fused feature set is fed into a hybrid classifier composed of a Deep Temporal Convolutional Network (DTCN) and an Attention-based Long Short-Term Memory (ALSTM) network . The classifier parameters are optimized using the HDPCO algorithm. The output from the hybrid classifier provides the final prediction result. Experimental results demonstrate that the proposed COVID-19 impact prediction model significantly outperforms existing models in terms of prediction accuracy and efficiency.},
  archive      = {J_ASOC},
  author       = {Sadanandam Kalvala and B. Baranidharan},
  doi          = {10.1016/j.asoc.2025.113867},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113867},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware. <em>ASOC</em>, <em>185</em>, 113866. (<a href='https://doi.org/10.1016/j.asoc.2025.113866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing offers the potential to enhance computational efficiency beyond classical methods, but practical implementation remains challenging due to the limitations of Noisy Intermediate-Scale Quantum (NISQ) hardware, namely, restricted qubit counts, limited connectivity, and the presence of noise and decoherence. This study presents a novel approach to edge detection by leveraging a recently developed Quantum Fuzzy Inference Engine, implemented on a NISQ device. We introduce an optimized quantum circuit for its implementation, reducing qubit requirements and gate depth to improve execution on NISQ hardware. To overcome constraints related to large-scale image processing, a hybrid quantum–classical lookup table approach is employed. Edge detection performance is evaluated on the Berkeley Segmentation Data Set and Benchmarks 500 dataset under different conditions, including classical execution, ideal quantum simulation, noisy quantum simulation, and NISQ hardware calculation. Results demonstrate that the quantum fuzzy logic-based edge detection achieves outcomes comparable to classical methods by using fewer operations, marking a step toward practical quantum-enhanced image processing.},
  archive      = {J_ASOC},
  author       = {G. Nunziata and S. Crisci and G. De Gregorio and R. Schiattarella and G. Acampora and L. Coraggio and N. Itaco},
  doi          = {10.1016/j.asoc.2025.113866},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113866},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent cooperation-based bi-criteria evolutionary many-objective optimization. <em>ASOC</em>, <em>185</em>, 113865. (<a href='https://doi.org/10.1016/j.asoc.2025.113865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective evolutionary algorithms (MaOEAs) excel in solving many-objective optimization problems (MaOPs), which are mainly classified into two frameworks: the Pareto domination and the non-Pareto domination. The Pareto criterion (PC) obtains a well-converged solution set in multi-objective spaces through the Pareto dominance relationship between solutions. However, insufficient environmental selection pressure in many-objective spaces leads to slow convergence. The non-Pareto criterion (NPC) enhances the selection pressure by evaluating the solution set with a set of sortable scalar values. However, it is difficult to ensure the Pareto-optimal consistency of convergence and distribution when facing highly irregular Pareto fronts (PFs). Therefore, combining the two sets of criteria can satisfy the demand for uniform distribution while bringing significant selection pressure. A multi-agent cooperative strategy is proposed in this study to realize the combination of the two criteria. This strategy controls the evolutionary direction of two populations separately by deploying two agents, and promotes cooperative evolution between these populations through the exchange and flow of large amounts of information. In order to better realize the cooperative effect, we adopt the multi-agent reinforcement learning (MARL) strategy to accurately regulate the variation operator and parameter configurations of the bi-population. In addition, the effectiveness of the proposed method is validated on 74 test problems (DTLZ, WFG, and UF) and 3 real-world problems. The results show that the proposed algorithm is more competitive than 6 state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Jiazheng Li and Yuan Liu and Juan Zou and Shuyi Liu and Shengxiang Yang and Jinhua Zheng},
  doi          = {10.1016/j.asoc.2025.113865},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113865},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent cooperation-based bi-criteria evolutionary many-objective optimization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompted complex context generation guided fine-grained ship recognition. <em>ASOC</em>, <em>185</em>, 113856. (<a href='https://doi.org/10.1016/j.asoc.2025.113856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained ship recognition in complex marine environments is challenged by background interference, high inter-class similarity, and limited labeled data. Existing methods often rely on inefficient cascades or holistic feature extraction, which limits both accuracy and efficiency. To address these issues, we propose a Prompted Complex Context Generation Guided Fine-Grained Ship Recognition framework, consisting of two core modules. The Cross-Attention Context Generation Module utilizes a diffusion model to generate diverse background images from prompts, maintaining target consistency and enriching the training data to mitigate data scarcity. It also employs a cross-attention map to highlight target-relevant regions, guiding the Attention Map Guided Fusion Module. The Attention Map Guided Fusion Module adopts a dual-branch transformer architecture: one branch extracts global features from background-enhanced images, and the other captures local features through attention-guided cropping of target-specific regions. By integrating both global and local features, our method effectively identifies key target characteristics. Experimental results demonstrate that our approach achieves 97.04% accuracy on the publicly available MAR-ships dataset and 84.57% accuracy on the challenging GCS dataset, outperforming state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Runtian Wang and Kejun Wu and Renjie Qiao and Chunsheng Yang and Chengtao Cai},
  doi          = {10.1016/j.asoc.2025.113856},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113856},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prompted complex context generation guided fine-grained ship recognition},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label feature selection via asymmetric redundancy and variable precision dependency. <em>ASOC</em>, <em>185</em>, 113852. (<a href='https://doi.org/10.1016/j.asoc.2025.113852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is an effective data preprocessing technique that can significantly mitigate the challenges posed by high-dimensional features in multi-label learning. However, the exploration of feature-label correlations has often been strictly limited to inclusion relationships, while ignoring the fusion of local and global label information. Moreover, most previous work has typically assumed that redundancy between features is fully symmetric, overlooking the valuable insights that asymmetric redundancy provides for designing feature selection. To address these issues, this paper proposes a novel multi-label feature selection via asymmetric redundancy and variable precision dependency. Specifically, it constructs a conditional probability model to reflect the local label semantics, incorporating this into the construction of the variable precision dependency through a fusion indicator. Subsequently, the optimistic and pessimistic information overlap between features is discussed, allowing variable precision granularity to capture asymmetric redundancy between features. Building upon this, an information fusion method is proposed to quantify the pessimistic asymmetric redundancy between features by inducing knowledge granularity in the feature space. Finally, a comprehensive evaluation metric, Maximum Correlation-maximum Discrimination-minimum Redundancy (MCDR), is proposed to evaluate the significance of features. The experimental results on fifteen multi-label benchmark datasets indicate that the proposed method outperforms the other seven state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Wenbin Qian and Xiwen Lu and Shiming Dai and Jintao Huang},
  doi          = {10.1016/j.asoc.2025.113852},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113852},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-label feature selection via asymmetric redundancy and variable precision dependency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy. <em>ASOC</em>, <em>185</em>, 113851. (<a href='https://doi.org/10.1016/j.asoc.2025.113851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing decision tree algorithms often use a single-layer measure to process data, which cannot fully consider the complex interactions and dependencies between different granularity levels. In addition, decision tree algorithms inevitably face the issue of multi-value preference, which may lead to the selection of unreasonable attributes in the process of partition, thereby affecting the performance of the algorithms. Therefore, this paper proposes an improved decision tree algorithm, called Ze-VNDT, which combines variable precision rough sets with Zentropy. First, to avoid the information loss caused by data discretization, this paper introduces variable precision neighborhood rough sets for data processing. Second, by analyzing the granularity level structure within the variable precision neighborhood rough set model, knowledge uncertainty is analyzed from three granularity levels: decision classes, approximate relations, and similarity classes. We describe the uncertain knowledge from the overall to the internal using the idea of going from coarse to fine, and design a Zentropy to measure uncertainty. To address the issue of multi-value preference, an adaptive weighted Zentropy uncertainty measure is designed based on the definition of uncertainty measure based on Zentropy. Third, when constructing the improved decision tree algorithm, the optimal attributes are selected based on the designed uncertainty measure. Finally, numerical experiments on 18 UCI datasets validated the effectiveness and rationality of the proposed algorithm. The experimental results showed that, compared to traditional algorithms and the latest improved algorithms, the proposed algorithm achieved an average accuracy of 94.79%, an average precision of 85.77%, an average recall rate of 84.68%, and an F1-score of 84.97% across the 18 datasets. It ranked first in all five evaluation metrics, demonstrating higher stability and accuracy.},
  archive      = {J_ASOC},
  author       = {Hui Dong and Caihui Liu and Xiying Chen and Duoqian Miao},
  doi          = {10.1016/j.asoc.2025.113851},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113851},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skin lesion classification with mini-batch sampling and deep metric learning. <em>ASOC</em>, <em>185</em>, 113850. (<a href='https://doi.org/10.1016/j.asoc.2025.113850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin lesion image classification based on deep learning has recently garnered significant attention. However, directly applying methods that perform well in general computer vision tasks to skin lesion image classification is not ideal, as skin lesion image datasets possess intrinsic characteristics, such as class imbalance, intra-class variability, and inter-class similarity. To tackle these challenges simultaneously, we propose a novel unified learning framework, named mBSML, which integrates mini-batch sampling and deep metric learning. In this framework, mini-batch sampling re-samples data in real-time during each iteration of learning, while a new loss function combines mini-batch distance metric-based loss with cross-entropy loss. Through the alternating training procedure on both imbalanced training data and balanced re-sampling data, mBSML effectively learns from global distribution information and local similarity information, not only from the original dataset but also from the minority classes. Extensive experiments conducted on two publicly available datasets demonstrate the effectiveness of mBSML for skin lesion image classification.},
  archive      = {J_ASOC},
  author       = {Shengdan Hu and Zhifei Zhang and Li Ying and Guangming Lang},
  doi          = {10.1016/j.asoc.2025.113850},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113850},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Skin lesion classification with mini-batch sampling and deep metric learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes. <em>ASOC</em>, <em>185</em>, 113849. (<a href='https://doi.org/10.1016/j.asoc.2025.113849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in airport surface scenes is crucial for enhancing safety. However, the coexistence of objects with significant scale disparities within the same region complicates feature representation, limiting existing models’ ability to capture fine-grained details, especially for small objects. To address this challenge, we propose AOD-YOLO, an Airport Object Detection (AOD) model incorporating a Self-Modulating Multi-Scale Feature Aggregation Mechanism. This model introduces two key innovations: (1) Enhanced Context Modeling: By leveraging large-kernel convolution, frequency-domain modulation, and statistical feature analysis, our approach effectively adjusts feature contributions across different object scales, improving contextual understanding in complex scenes; (2) Optimized Small Object Representation: A dynamic gradient gain allocation strategy refines small-object features, enhancing detection accuracy and overall feature presentation. AOD-YOLO consistently improves performance across model scales. On our self-constructed Airport dataset and the public VisDrone-DET2019 dataset, it achieves mean Average Precision (mAP 0.5 ) of 87.9% and 44.9%, respectively—outperforming state-of-the-art models like YOLOv11 and Gold-YOLO by substantial margins. Additionally, through optimized network module placement, AOD-YOLO achieves 112 FPS, striking a balance between computational efficiency and accuracy, making it well-suited for real-time airport object detection.},
  archive      = {J_ASOC},
  author       = {Yingqing Wang and Weili Zeng and Ziyu Zhao and Baogeng Li and Zhibin Quan},
  doi          = {10.1016/j.asoc.2025.113849},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113849},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gloss-free sign language translation based on fusion attention. <em>ASOC</em>, <em>185</em>, 113848. (<a href='https://doi.org/10.1016/j.asoc.2025.113848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language translation converts sign language videos into spoken language text. Traditional gloss-based approaches require costly gloss annotations, driving recent interest in gloss-free methods. In this paper, we propose a novel gloss-free sign language translation method based on fusion attention (SLTFA) that uniquely models the intrinsic logical structure of sign language. The key innovation is the development of a dual-attention mechanism that mimics the natural hierarchical structure of sign language: intra-gloss attention captures fine-grained relationships within video frame sequences representing individual semantic units, while inter-gloss attention models the broader contextual connections between these units, similar to how words form coherent sentences. Additionally, we introduce a contrastive loss strategy for cross-modal soft alignment that effectively bridges the gap between visual and textual representations. Extensive experiments on the RWTH-PHOENIX-WEATHER-2014T dataset demonstrate SLTFA’s superior performance, achieving a BLEU-4 score of 16.99 and a ROUGE score of 40.82. On the CSL-Daily dataset, our approach achieves a BLEU-1 score of 25.56 and a ROUGE score of 27.51, demonstrating strong performance across different sign languages.},
  archive      = {J_ASOC},
  author       = {Yingchun Xie and Wei Su and Chongliang Zhong and Chuan Cai and Yongna Yuan},
  doi          = {10.1016/j.asoc.2025.113848},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113848},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Gloss-free sign language translation based on fusion attention},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient mathematical-based optimization method to optimize multi-hydropower operating rules. <em>ASOC</em>, <em>185</em>, 113846. (<a href='https://doi.org/10.1016/j.asoc.2025.113846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing hydropower multi-reservoir systems requires both effective operating rules and efficient optimization techniques. The main contribution of this paper is offering a unique approach that elegantly combines two important parts: creating an efficient optimization method and developing hydropower operating rules. In this regard, a nonlinear rule curve (NLRC) and a linear rule curve (LRC), are tailored for the coordination of a hydropower multi-reservoir system (HMRS) in Iran. To optimize operating rules, the study fabricates a novel algorithm termed the multi-operator weighted mean of vectors (MINFO). The algorithm combines a powerful global search strategy (GSS) that thoroughly searches the solution space with an efficient local search (LS), striking a balance between solution diversity and convergence speed. To fine-tune this balance, an adaptive parameter-tuning strategy is applied. Furthermore, the active-set sequential quadratic programming (ASQP) serves as a localized escaping operator to enhance the algorithm's convergence speed. The effectiveness of the proposed MINFO algorithm is first evaluated through a nonlinear five-reservoir problem. The findings indicate that the MINFO algorithm outperforms a set of 14 distinct optimization methods. Subsequently, the MINFO algorithm is applied to identify optimal NLRC and LRC for a six-reservoir hydropower system. The results underscore the superiority of optimized NLRC, yielding a potential power augmentation of up to 17 % in comparison to the LRC approach. In summation, this study constitutes a seminal contribution by cultivating an efficient rule curve framework for the management of HMRSs.},
  archive      = {J_ASOC},
  author       = {Shuguang Li and Iman Ahmadianfar and Aitazaz A. Farooque and Zaher Mundher Yaseen},
  doi          = {10.1016/j.asoc.2025.113846},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113846},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient mathematical-based optimization method to optimize multi-hydropower operating rules},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach. <em>ASOC</em>, <em>185</em>, 113837. (<a href='https://doi.org/10.1016/j.asoc.2025.113837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting debris and monitoring marine life in sea aquaculture face challenges due to limited visibility and the presence of diverse. Underwater object detection by Autonomous Unmanned Vehicle(AUV) is inherently more challenging than land due to light attenuation and water turbidity, especially for small and dense objects in murky images, where extracting high-quality features is hindered. In this paper, we present an efficient approach for real-time underwater object detection through improvements in image enhancement, data augmentation, and feature aggregation. Initially, U-Shape Transformer is applied to enhance the original images. For data augmentation, it is observable that while Mosaic data augmentation enhances complex images but fails to improve small-object detection due generation of less number of images with small objects. To address this limitation, we propose Underwater-Mosaic (U-Mosaic), a modified Mosaic data augmentation technique designed to enhance small-object detection. Additionally, it was noted that existing YOLOv4 struggles with detecting small and densely populated objects in underwater images as unable to get sufficient features for small objects due to downsampling, image quality and also found difficulty in selecting anchor box size. Therefore, we propose a model called Advanced YOLOv4, tailored for underwater object detection. The proposed Advanced YOLOv4 aims to improve object detection efficiency by altering the neck and prediction layers of YOLOv4. Moreover, we introduce an additional spatial pyramid pooling layer to aggregate features and reduce feature dimensions thereby improving object detection rates. Also, the proposed work concentrates on very large object detection and for this purpose used downsampling during the detection of large objects. The proposed approach is validated through two distinct application areas: (i) detecting and locating debris (ii) detecting fish from underwater images. For validation, the Trash ICRA19 dataset is used for debris detection, while the Brackish dataset is employed for fish detection. UIQM and UCIQE, image enhancement assessment metrics are used to measure quality of enhanced images and found more than 20% better result for both the datasets. The proposed real-time underwater object detection model outperformed single-stage object detectors like YOLOv3, YOLOv4, YOLOv5, YOLOv7, and KPE-YOLOv5 by 5% in terms of mean Average Precision(mAP). Also proposed work compared with two-stage detector RCNN and found 8% better mAP than RCNN.},
  archive      = {J_ASOC},
  author       = {Pratima Sarkar and Sourav De and Prasenjit Dey and Sandeep Gurung},
  doi          = {10.1016/j.asoc.2025.113837},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113837},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniCon: Unified image-guiding generation with noise consistency. <em>ASOC</em>, <em>185</em>, 113832. (<a href='https://doi.org/10.1016/j.asoc.2025.113832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have demonstrated remarkable capabilities in image-to-image tasks. However, existing methods typically focus either on structural (e.g., layout, content) or stylistic guidance, with few approaches effectively excel at both. On the other hand, many methods require time-consuming fine-tuning or high inference latency, making interactive generation applications challenging to realize. To address these issues, we propose a two-stage framework referred as UniCon ( Uni fied Image-guiding Generation with Noise Con sistency). To improve time efficiency, we follow the paradigm of inversion-based image manipulation and introduce a novel method called Noise Consistency Inversion . Leveraging the nature of Consistency Models, this inversion process is highly efficient, requiring only a single neural function evaluation (NFE) in the inversion process. To achieve high consistency and finer control, we introduce a unified attention-based guidance mechanism that supports structural, stylistic, or joint reference inputs, without any additional fine-tuning. Experiments with structure- and style-specific methods show that our approach performs competitively or better in each individual aspect. In comparison of style transfer tasks that demand both structure and style, our method outperforms state-of-the-art baselines, confirming the effectiveness of our union control strategy. And overall, our approach also achieves the best efficiency in terms of runtime performance.},
  archive      = {J_ASOC},
  author       = {Yuanjun Liao and Yuning Gong and Yanci Zhang},
  doi          = {10.1016/j.asoc.2025.113832},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113832},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UniCon: Unified image-guiding generation with noise consistency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment. <em>ASOC</em>, <em>185</em>, 113830. (<a href='https://doi.org/10.1016/j.asoc.2025.113830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Turkish textile and apparel sector plays a crucial role in the national economy through employment, exports, and investment. The financial performance of companies is a key determinant of their sustainability and competitiveness, especially in global markets. The Turkish textile and apparel sector is one of the essential industries in terms of macro-economic indicators such as net foreign exchange inflow, employment and investment. This sector is also one of the critical actors in world trade. A robust performance evaluation model is essential for stakeholders such as investors, creditors, and managers. However, the assessment of firms is a very critical decision involving uncertainty due to various conflicting criteria based on judgements. In this study, an integrated multi-criteria decision-making (MCDM) model including interval type-2 fuzzy hierarchy process (IT2FAHP) and Compromise Ranking of Alternatives from Distance to Ideal Solution (CRADIS) approaches are proposed to assess the financial performance of Turkish textile and clothing firms that are traded in Borsa İstanbul (BİST) in the period from 2006 to 2020. In line with the determined purpose, the arithmetic average of the determined financial ratios during the analysis period covering 15 years is computed to obtain long-term performance indicators. The importance weights of the selected financial criteria for the performance evaluation model are identified by employing the IT2FAHP approach. Then, the firms are ranked according to their financial performances with the CRADIS method. In addition, the results from the sensitivity analysis validate the proposed approach and prove that it is practical. Moreover, practical and managerial implications are discussed based on the results. The results offer valuable insights for strategic decision-making and can support efforts to enhance financial stability in the textile and apparel sector. According to the results, "LUKSK" had the highest long-term financial performance among the 11 companies discussed. This company is followed by BOSSA, YATAS, and ATEKS companies. The alternatives confirm the robustness of the proposed model in maintaining its place in the ranking in 190 scenarios. In addition, the comparative analysis confirms the consistency of the proposed ranking framework.},
  archive      = {J_ASOC},
  author       = {Ömer Faruk Görçün and Mohsin Shabir and Ahmet Çalık and Özcan Işık},
  doi          = {10.1016/j.asoc.2025.113830},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113830},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks. <em>ASOC</em>, <em>185</em>, 113829. (<a href='https://doi.org/10.1016/j.asoc.2025.113829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty analysis of wind speed forecasting using the Lower Upper Bound Estimation (LUBE) represents an advanced interval prediction method that does not require assumptions about data distribution. Previous studies, however, have exclusively focused on univariate prediction models, neglecting the information from other variables, and have not fully exploited the prediction errors in their loss function during training. To address these issues, an interpretable dual-output multivariate wind speed interval prediction scheme (IMWSIPS) that utilizes a hyper-heuristic optimization algorithm and a deep neural network is proposed, along with a novel loss function for training. The system initially takes multiple inputs such as historical wind speed and other influencing factors including wind direction, density, temperature, and pressure into a deep neural network. The actual wind speeds are then scaled up and down by factors of 1 + θ 1 (0 <θ 1 <1) and 1 + θ 2 (-1 <θ 2 <0), respectively, to produce two outputs from the network. On this basis, an optimization problem to minimize interval width under a given coverage probability is formulated and solved using the developed hyper-heuristic algorithm, yielding optimal values for θ 1 and θ 2 and the prediction intervals for sub-models. Subsequently, the advantages of five deep neural network models are leveraged to construct an ensemble model, with weights optimized by the hyper-heuristic algorithm to derive the final prediction intervals. Ultimately, the system's interpretability is analyzed at both variable and sub-model levels. Experimental and discussion results demonstrate that the introduction of IMWSIPS not only signifies enhancements in forecasting performance but also implies improvements in wind energy utilization efficiency and reductions in operational costs for power systems.},
  archive      = {J_ASOC},
  author       = {Mengzheng Lv and Jianzhou Wang and Shuai Wang and Yang Zhao and Jialu Gao and Yuansheng Qian},
  doi          = {10.1016/j.asoc.2025.113829},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113829},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The fuzzified grey wolf: An improved grey wolf optimizer based on dynamic fuzzy system FGWO. <em>ASOC</em>, <em>185</em>, 113818. (<a href='https://doi.org/10.1016/j.asoc.2025.113818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Grey Wolf Optimizer (GWO) is a leading, powerful, and effective algorithm in swarm optimization techniques, showing competitive performance across various optimization problems. Yet, GWO is burdened by high tendencies toward exploitation and imprecise population diversity. This work introduces an improved GWO called the Fuzzified Grey Wolf Optimizer (FGWO) for solving global optimization problems. FGWO benefits from a dynamic fuzzy inference system (DFIS) to capture the optimal value of a → throughout iterations. DFIS integrates two inputs: the diversity rate and iteration number, and by inferring the optimal value of a → , FGOW determines whether to exploit or explore. Moreover, DFIS employs an adaptive membership function to capture the precise value of population diversity throughout the course of iteration. This optimal a → determination strategy can achieve a balanced exploitation–exploration ratio, mitigating premature convergence and enhancing diversity. FGWO is evaluated on CEC2017 benchmark functions, four engineering designs, and a breast cancer genes feature selection design. FGWO was compared with three other improved GWOs, and across all experiments, the outcomes demonstrate its superiority in terms of efficiency and applicability to real-world designed problems.},
  archive      = {J_ASOC},
  author       = {Mohammed Dheyaa Algubili and Labiba M. Alhelfi and Hana’ M. Ali},
  doi          = {10.1016/j.asoc.2025.113818},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113818},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The fuzzified grey wolf: An improved grey wolf optimizer based on dynamic fuzzy system FGWO},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy lagrange interpolation method from summation of interactive fuzzy numbers. <em>ASOC</em>, <em>185</em>, 113817. (<a href='https://doi.org/10.1016/j.asoc.2025.113817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel approach to extending the sum of interactive fuzzy numbers, which is independent of the order of its operands. Interactive fuzzy numbers are fuzzy quantities in which the values across different α -cuts are not assumed to vary independently, incorporating dependencies that better reflect real-world uncertainty. A characterization of the proposed summation is given in terms of α -cuts, making computational implementation easier. It is shown that this operation preserves essential mathematical properties, including associativity. This is particularly important, as it enables the consistent aggregation of multiple fuzzy quantities without concern for the order in which the operands are grouped. The norm and width behaviors under this new summation are also analyzed. To illustrate the theoretical results, several examples are provided. As a practical application, the classical Lagrange polynomial interpolation method is extended to handle uncertain parameters represented by interactive fuzzy numbers. A fuzzy curve fitting problem is examined using this framework, and a comparative discussion highlights the advantages of the proposed method over existing approaches.},
  archive      = {J_ASOC},
  author       = {Geizane Lima da Silva and Estevão Esmi and Vinícius Francisco Wasques and Laécio Carvalho de Barros},
  doi          = {10.1016/j.asoc.2025.113817},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113817},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy lagrange interpolation method from summation of interactive fuzzy numbers},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction. <em>ASOC</em>, <em>185</em>, 113776. (<a href='https://doi.org/10.1016/j.asoc.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material properties are illustrated by numerical data and semantic factors. In general, existing methods typically adopt machine learning (ML) algorithms to regress numerical properties or transfer other pre-trained knowledge graphs (KGs) to the material, due to the limitations of small-sample datasets. However, integrating semantic and numerical information from multi-modal data which across diverse experimental conditions remains a significant challenge in materials science. In this paper, a numerical reasoning method for material KGs (NR-KG) 1 was proposed, which constructs a cross-modal KG using semantic nodes and numerical proxy nodes. Both types of information by projecting KG into a canonical KG were captured and a graph neural network to predict material properties was utilized. In process, a novel projection prediction loss is proposed to extract semantic features from numerical information. NR-KG facilitates end-to-end processing of cross-modal data, mining relationships and cross-modal information in small-sample datasets, and fully utilizes effective experimental data to enhance the accuracy of material prediction. We propose two new high-entropy alloys (HEA) property datasets with semantic descriptions. NR-KG outperforms state-of-the-art (SOTA) methods on two material datasets, with MSE values of 3520 and 2.210, and achieving relative improvements of 25.9% and 16.1%, respectively, over the second-best methods, KANO and PCHMLP (semantic). It also achieves RMSE values of 0.584 and 0.521 on the FreeSolv and ESOL public molecular datasets, surpassing SOTA methods by 48.8% and 22.2% over KANO, highlighting its potential application and generalizability.},
  archive      = {J_ASOC},
  author       = {Guangxuan Song and Dongmei Fu and Zhongwei Qiu and Zijiang Yang and Jiaxin Dai and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.asoc.2025.113776},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113776},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing. <em>ASOC</em>, <em>185</em>, 113697. (<a href='https://doi.org/10.1016/j.asoc.2025.113697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading in volatile markets, such as cryptocurrencies, requires portfolio models that can swiftly adapt to regime shifts while controlling risk. We propose a novel approach that frames portfolio management as a dynamic strategy-selection problem. Instead of directly predicting asset weights, our agent selects from a pool of expert strategies based on recent market trends. We introduce a Transformer-based Variational Autoencoder (VAE) to extract disentangled trend representations, and a trend-aware actor–critic model to perform expert selection. Experiments demonstrate that this modular, strategy-level control mechanism outperforms existing methods in risk-sensitive crypto portfolio management.},
  archive      = {J_ASOC},
  author       = {Ahmad Asadi and Reza Safabakhsh},
  doi          = {10.1016/j.asoc.2025.113697},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113697},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="autom">AUTOM - 58</h2>
<ul>
<li><details>
<summary>
(2026). Congealed neural network design for uncertain nonlinear spatiotemporal control systems. <em>AUTOM</em>, <em>183</em>, 112636. (<a href='https://doi.org/10.1016/j.automatica.2025.112636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note is concerned with the approximation-based adaptive control problem for a class of uncertain nonlinear spatiotemporal systems. A congealed neural network (ConNN) is first proposed to approximate nonlinear spatiotemporal uncertainties arising from system states and time-varying parameters. Unlike conventional NN approximation structures, the ConNN explicitly decomposes the time-varying coupling weight into a congealed weight and a time-dependent perturbation. The congealed weight is estimated using a standard adaptive law for constant parameters, while the residual perturbation is handled within the network structure. To enhance robustness, smooth sliding-mode-like functions are then embedded into the control architecture, effectively attenuating bias terms, particularly in reference tracking scenarios. It is shown that the resulting ConNN-based adaptive controller guarantees adjustable, bounded-error tracking performance, thereby extending the applicability of robust adaptive control to complex spatiotemporal systems and outperforming existing NN-based approaches.},
  archive      = {J_AUTOM},
  author       = {Tianrun Liu and Yang-Yang Chen and Xiaohua Ge},
  doi          = {10.1016/j.automatica.2025.112636},
  journal      = {Automatica},
  month        = {1},
  pages        = {112636},
  shortjournal = {Automatica},
  title        = {Congealed neural network design for uncertain nonlinear spatiotemporal control systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed adaptive fixed-time formation tracking for heterogeneous multi-agent systems. <em>AUTOM</em>, <em>183</em>, 112632. (<a href='https://doi.org/10.1016/j.automatica.2025.112632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the problem of fixed-time time-varying formation tracking control (FTC) for heterogeneous linear multiagent systems (MASs) under the directed communication graph. It is assumed that the Laplacian matrix associated with the communication graph is unavailable and that the system matrices of the leader are only available to its neighboring followers. This differs from many existing works on fixed-time FTC problems where the communication graphs are typically undirected and protocol designs often rely on certain global information. A novel distributed observer is first put forward to estimate both the state and system matrices of the leader in fixed time. Then, an adaptive scheme is developed to solve the time-varying regulator equations resulting from the estimated leader system matrices in fixed time. Based on the proposed observer and the adaptive solutions to the regulator equations, a distributed adaptive fixed-time FTC protocol is further proposed via coordinate transformation techniques. It is shown that our proposed controllers do not require the input matrices of the followers to be of full row rank. It is also shown that the concerned fixed-time FTC problem can be solved with the proposed fixed-time FTC strategy in a distributed manner. Our results can be directly applied to solve both the adaptive fixed-time cooperative output regulation problem and the leader-following consensus problems of MASs under the directed graph. Finally, the effectiveness of the proposed fixed-time FTC strategy is demonstrated through a numerical example.},
  archive      = {J_AUTOM},
  author       = {Shiyu Zhou and Dong Sun and Gang Feng},
  doi          = {10.1016/j.automatica.2025.112632},
  journal      = {Automatica},
  month        = {1},
  pages        = {112632},
  shortjournal = {Automatica},
  title        = {Distributed adaptive fixed-time formation tracking for heterogeneous multi-agent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nature-inspired dynamic control for pursuit-evasion of robots. <em>AUTOM</em>, <em>183</em>, 112629. (<a href='https://doi.org/10.1016/j.automatica.2025.112629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pursuit-evasion problem is widespread in nature, engineering, and societal applications. It is commonly observed in nature that predators often exhibit faster speeds than their prey but have less agile maneuverability. Over millions of years of evolution, animals have developed effective and efficient strategies for pursuit and evasion. In this paper, we provide a dynamic framework for the pursuit-evasion problem of unicycle systems, drawing inspiration from nature. First, we address the scenario with one pursuer and one evader by proposing an Alert-Turn control strategy, which consists of two efficient ingredients: a sudden turning maneuver and an alert condition for starting and maintaining the maneuver. We present and analyze the escape and capture results at two levels: a lower level of a single run and a higher level with respect to parameters’ changes. In addition, we provide a theorem with sufficient conditions for capture. The Alert-Turn strategy is then extended to more complex scenarios involving multiple pursuers and evaders by integrating aggregation control laws and a target-changing mechanism. By adjusting a ‘selfish parameter’, the aggregation control commands produce various escape patterns of evaders: cooperative mode, selfish mode, and their combinations. The influence of the selfish parameter is quantified, and the target-changing mechanism is explored from a statistical perspective. Our findings align closely with observations in nature. Finally, the proposed strategies are validated through numerical simulations that replicate some chasing behaviors of animals in nature.},
  archive      = {J_AUTOM},
  author       = {Panpan Zhou and Sirui Li and Benyun Zhao and Bo Wahlberg and Xiaoming Hu},
  doi          = {10.1016/j.automatica.2025.112629},
  journal      = {Automatica},
  month        = {1},
  pages        = {112629},
  shortjournal = {Automatica},
  title        = {Nature-inspired dynamic control for pursuit-evasion of robots},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event/self-triggered cooperative control via reinforcement learning for a quadrotor team under multiple faults and denial-of-service attacks. <em>AUTOM</em>, <em>183</em>, 112628. (<a href='https://doi.org/10.1016/j.automatica.2025.112628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cooperative fault-tolerant control problem of a quadrotor team, subject to multiple faults and denial-of-service (DoS) attacks, is addressed via event/self-triggered strategies and reinforcement learning. Multiple under-actuated quadrotors with nonlinearities, couplings, and unknown dynamical parameters are introduced to achieve distributed cooperation. Event-triggered observers are developed to estimate position references under uncertain cyber faults and DoS attacks. Observer-based optimal controllers for the nominal position and attitude subsystems are learned by off-policy reinforcement learning without dynamical information. Fault-tolerant controllers are constructed by integrating the learned controllers and adaptive actuator fault compensators. A self-triggered strategy is further proposed to avoid continuous communication. The relationship among the time-varying topology coupled with cyber faults, the features of DoS attacks, and the closed-loop control system stability is analyzed, and the exclusion of Zeno behavior is proved. Simulation results illustrate the effectiveness of the proposed methods.},
  archive      = {J_AUTOM},
  author       = {Ziming Ren and Hao Liu and Hongwei Zhang and Ci Chen and Frank L. Lewis},
  doi          = {10.1016/j.automatica.2025.112628},
  journal      = {Automatica},
  month        = {1},
  pages        = {112628},
  shortjournal = {Automatica},
  title        = {Event/self-triggered cooperative control via reinforcement learning for a quadrotor team under multiple faults and denial-of-service attacks},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive distributed observer design for nonlinear multiagent systems. <em>AUTOM</em>, <em>183</em>, 112625. (<a href='https://doi.org/10.1016/j.automatica.2025.112625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed state estimation is crucial for the leader-following control problem of multiagent systems (MASs). In this paper, adaptive distributed observers (DOs) are designed for a nonlinear autonomous leader system using only its output. Via system transformation, the DO design problem of the origin system is converted to that of a canonical system with lumped dynamics. When the lumped dynamics is parametric, an adaptive DO is developed to reconstruct the state and the unknown parameters under an undirected topology, which also addresses the distributed state/parameter estimation problem of an uncertain autonomous system with its dynamics in a parametric form. Then, the DO framework is extended to the case of non-parametric uncertainties, and a neural network (NN) DO is designed for reconstructing the state/lumped dynamics over a strongly connected digraph Finally, the effectiveness of the proposed DOs is demonstrated via numerical simulations.},
  archive      = {J_AUTOM},
  author       = {Jixing Lv and Changhong Wang and Lihua Xie},
  doi          = {10.1016/j.automatica.2025.112625},
  journal      = {Automatica},
  month        = {1},
  pages        = {112625},
  shortjournal = {Automatica},
  title        = {Adaptive distributed observer design for nonlinear multiagent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel switching rule to observer-based control for switched systems. <em>AUTOM</em>, <em>183</em>, 112622. (<a href='https://doi.org/10.1016/j.automatica.2025.112622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores observer-based control for switched systems subject to partially unknown sojourn probability information. To more accurately capture the dynamic nature of switched systems, a novel switching rule related to duration time is devised, in which the system switching is governed by a joint distribution function. This function uniquely integrates both the current system mode and its duration, effectively addressing the challenges of incompleteness in probability information. Distinct from the conventional semi-Markov kernel technique, the sojourn probabilities involve fewer parameters and can be more readily measured using statistical techniques, thereby lessening computational burden. Additionally, a non-monotonic Lyapunov function is constructed, leading to less conservative conditions that ensure the mean-square stability of the switched systems. Eventually, the effectiveness and superiority of the devised methodology are verified through a practical example.},
  archive      = {J_AUTOM},
  author       = {Jun Cheng and Tianfeng Tang and Huaicheng Yan and Zheng-Guang Wu and Dan Zhang},
  doi          = {10.1016/j.automatica.2025.112622},
  journal      = {Automatica},
  month        = {1},
  pages        = {112622},
  shortjournal = {Automatica},
  title        = {A novel switching rule to observer-based control for switched systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sampled-data primal–dual gradient dynamics in model predictive control. <em>AUTOM</em>, <em>183</em>, 112621. (<a href='https://doi.org/10.1016/j.automatica.2025.112621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model predictive control (MPC) can incur computational burden that exceeds what the application warrants, sometimes even for linear systems. Recently, a rapid computation method that guides the input toward convergence with the optimal control problem solution by employing primal–dual gradient (PDG) dynamics has been proposed for linear MPCs. However, stability has been ensured under the assumption that the controller is a continuous-time system, leading to potential instability when the controller undergoes discretization and is implemented as a sampled-data system. In this paper, we propose a discrete-time dynamical controller incorporating specific modifications to the PDG approach and present stability conditions. Additionally, we introduce an extension to enhance control performance that was traded off in the original. Numerical examples substantiate that our proposed method, which can be executed in only 1 μ s on a commodity laptop, not only ensures stability considering sampled-data implementation but also substantially enhances the control performance.},
  archive      = {J_AUTOM},
  author       = {Ryuta Moriyasu and Sho Kawaguchi and Kenji Kashima},
  doi          = {10.1016/j.automatica.2025.112621},
  journal      = {Automatica},
  month        = {1},
  pages        = {112621},
  shortjournal = {Automatica},
  title        = {Sampled-data primal–dual gradient dynamics in model predictive control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cooperative dynamic surrounding coverage control for multi-autonomous surface vehicle fleets with limited sensing ranges. <em>AUTOM</em>, <em>183</em>, 112620. (<a href='https://doi.org/10.1016/j.automatica.2025.112620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative surrounding coverage by a multi-autonomous surface vehicle (ASV) fleet involves dynamic coverage with concentric moving trajectories. This low-cost form of coverage, which operates with limited perceptual ranges, has long presented a significant challenge in real-world collective marine detection applications. To this end, the paper establishes a surrounding coverage control framework that minimizes the required number of ASVs by covering a designated region across multiple consecutive periods. A distributed randomized gradient-free (DRGF) protocol is thereby proposed to identify the optimal central point of the coverage region. Accordingly, a distributed control law is designed to regulate the ASV dynamic surrounding coverage operation around the optimal concentric point. Significantly, sufficient conditions are derived to guarantee the asymptotical convergence of the closed-loop multi-ASV fleet governed by the present DGRF. Finally, experiments are conducted on a self-established lake-based multi-ASV fleet platform to verify the effectiveness of the present surrounding coverage scheme.},
  archive      = {J_AUTOM},
  author       = {Jiayu Zou and Hai-Tao Zhang and Bin Liu and Xiaohua Liu and Jianing Ding and Ning Xing and Shiqi Fu and Lijun Zhu},
  doi          = {10.1016/j.automatica.2025.112620},
  journal      = {Automatica},
  month        = {1},
  pages        = {112620},
  shortjournal = {Automatica},
  title        = {Cooperative dynamic surrounding coverage control for multi-autonomous surface vehicle fleets with limited sensing ranges},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asynchronous resilient collision-free formation control for nonlinear MASs under DoS attacks. <em>AUTOM</em>, <em>183</em>, 112619. (<a href='https://doi.org/10.1016/j.automatica.2025.112619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-agent systems (MASs) exchange the communication information by the communication network, which is vulnerable to denial-of-service (DoS) attacks. DoS attacks can disrupt the communication channels and result in the collisions between agents, thus it is an important and challenging topic to study the collision avoidance formation control issue under DoS attacks. This paper investigates the asynchronous resilient collision-free formation control issue for nonlinear MASs with DoS attacks. An asynchronous resilient distributed observer is proposed to estimate the output information of leader under DoS attacks. Based on the designed distributed observer and by constructing two high-order filters, an asynchronous resilient collision-free formation control method is presented by backstepping control design theory. The presented formation control method can ensure that the formation tracking errors asymptotically converge to zero, and the collision avoidance objective is realized. Moreover, the non-differentiable problem of virtual controllers is solved. Finally, we apply the developed formation control method to multiple Euler-Lagrangian (EL) systems, the simulation and comparison results verify its effectiveness.},
  archive      = {J_AUTOM},
  author       = {Jun Zhang and Jun Ning and Shaocheng Tong},
  doi          = {10.1016/j.automatica.2025.112619},
  journal      = {Automatica},
  month        = {1},
  pages        = {112619},
  shortjournal = {Automatica},
  title        = {Asynchronous resilient collision-free formation control for nonlinear MASs under DoS attacks},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sector stabilization criterion of a novel nonlinear flexible marine riser coupled system. <em>AUTOM</em>, <em>183</em>, 112618. (<a href='https://doi.org/10.1016/j.automatica.2025.112618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes a sector stabilization criterion for a nonlinear flexible marine riser system that incorporates lateral and transverse coupling vibrations, derived from Hamilton’s principle. This criterion, grounded in the sector-bounded condition, encompasses a wide range of linear and nonlinear feedback control laws applied to the transverse and lateral directions at the top boundary of the flexible marine riser, respectively. In the analysis, the nonlinear semigroup theory is utilized to establish the well-posedness of the resulting closed-loop coupled system. Notably, the solution demonstrates continuous dependence on the initial conditions. Furthermore, the exponential stability of the closed-loop coupled system is achieved by employing a generalized Gronwall-type integral inequality and the integral multiplier method, which involves the innovative development of an energy-like functional. To demonstrate the effectiveness of the proposed controls, numerical simulations utilizing the finite element method are presented.},
  archive      = {J_AUTOM},
  author       = {Yi Cheng and Xin Wang and Yuhu Wu and Bao-Zhu Guo},
  doi          = {10.1016/j.automatica.2025.112618},
  journal      = {Automatica},
  month        = {1},
  pages        = {112618},
  shortjournal = {Automatica},
  title        = {Sector stabilization criterion of a novel nonlinear flexible marine riser coupled system},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global exponential stabilization of 2 × 2 linear hyperbolic PDEs via dynamic event-triggered backstepping control. <em>AUTOM</em>, <em>183</em>, 112617. (<a href='https://doi.org/10.1016/j.automatica.2025.112617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces novel dynamic event-triggered control (ETC) mechanisms for 2 × 2 linear hyperbolic PDEs in three configurations: continuous-time event-triggered control (CETC), periodic event-triggered control (PETC), and self-triggered control (STC). These mechanisms ensure global exponential stability (GES) under ETC using PDE backstepping, with stability estimates provided in the spatial L 2 norm of the states. The proposed CETC and PETC designs are observer-based and require continuous boundary measurements collocated with the actuation. In contrast, the STC design requires full-state measurements; however, unlike CETC and PETC, it does not require continuous measurements for the triggering mechanism—only measurements taken at event times. In the CETC design, a lower bound on the time between two consecutive events is enforced, and a dynamic variable with appropriately designed switching dynamics is introduced. By employing a novel Lyapunov functional, GES of the closed-loop system is established under zero-order hold implementation of the backstepping control between events. Events are triggered when the dynamic variable crosses zero from the positive side, after which it is immediately reset to an appropriate nonnegative value. Detecting events, therefore, necessitates continuous monitoring of this dynamic variable. To address this limitation, PETC and STC strategies are proposed. The PETC design identifies a suitable triggering condition that requires only periodic checks and derives an upper bound on the allowable sampling period. This PETC approach preserves the GES guaranteed by CETC without requiring continuous monitoring of a triggering condition, although it still relies on continuous measurements. Unlike CETC and PETC, STC requires neither continuous measurements nor monitoring of a triggering condition. Instead, at each event, STC computes the time to the next event — beyond a suitably enforced minimal dwell-time — using only measurements taken at events. Despite relying solely on event-triggered measurements, STC is capable of guaranteeing GES of the closed-loop system. The well-posedness of the closed-loop systems under all three strategies is established. A simulation study is provided to illustrate the theoretical results.},
  archive      = {J_AUTOM},
  author       = {Bhathiya Rathnayake and Mamadou Diagne},
  doi          = {10.1016/j.automatica.2025.112617},
  journal      = {Automatica},
  month        = {1},
  pages        = {112617},
  shortjournal = {Automatica},
  title        = {Global exponential stabilization of 2 × 2 linear hyperbolic PDEs via dynamic event-triggered backstepping control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Signal temporal logic control synthesis among uncontrollable dynamic agents with conformal prediction. <em>AUTOM</em>, <em>183</em>, 112616. (<a href='https://doi.org/10.1016/j.automatica.2025.112616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of dynamical systems under temporal logic specifications among uncontrollable dynamic agents is challenging due to the agents’ a-priori unknown behavior. Existing works have considered the problem where either all agents are controllable, the agent models are deterministic and known, or no safety guarantees are provided. We propose a predictive control synthesis framework that guarantees, with high probability, the satisfaction of signal temporal logic (STL) tasks that are defined over a controllable system in the presence of uncontrollable stochastic agents. We use trajectory predictors and conformal prediction to construct probabilistic prediction regions for each uncontrollable agent that are valid over multiple future time steps. Specifically, we construct a normalized prediction region over all agents and time steps to reduce conservatism and increase data efficiency. We then formulate a worst-case bilevel mixed integer program (MIP) that accounts for all agent realizations within the prediction region to obtain an open-loop controller that provably guarantee task satisfaction with high probability. To efficiently solve this bilevel MIP, we propose an equivalent MIP program based on KKT conditions of the original bilevel formulation. Building upon this, we design a closed-loop controller, where both recursive feasibility and task satisfaction can be guaranteed with high probability. We illustrate our control synthesis framework on two case studies.},
  archive      = {J_AUTOM},
  author       = {Xinyi Yu and Yiqi Zhao and Xiang Yin and Lars Lindemann},
  doi          = {10.1016/j.automatica.2025.112616},
  journal      = {Automatica},
  month        = {1},
  pages        = {112616},
  shortjournal = {Automatica},
  title        = {Signal temporal logic control synthesis among uncontrollable dynamic agents with conformal prediction},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-triggered boundary estimation for 2 × 2 hyperbolic PDEs with disturbance. <em>AUTOM</em>, <em>183</em>, 112615. (<a href='https://doi.org/10.1016/j.automatica.2025.112615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the event-triggered boundary estimation problem for 2 × 2 linear hyperbolic partial differential equations (PDEs) subject to disturbances. These disturbances enter the PDEs through the boundary and are represented as an ordinary differential equation (ODE). The scenario considered involves transmitting boundary measurements to the observer only when necessary, as determined by a dynamic event-triggering condition. This approach aims to conserve communication and computational resources. The event-triggered observer is designed using the backstepping method, and an event-triggering condition is proposed to determine the time instants when sampled measurements should be transmitted. Under this event-triggered estimation mechanism, a minimal dwell-time between consecutive triggering time instants is guaranteed. Furthermore, the well-posedness of the solutions and the exponential convergence of the estimation error are ensured. Finally, the obtained results are applied to the Saint-Venant equations to demonstrate the effectiveness of the event-triggered estimation method.},
  archive      = {J_AUTOM},
  author       = {Yan Zhao and Rafael Vazquez},
  doi          = {10.1016/j.automatica.2025.112615},
  journal      = {Automatica},
  month        = {1},
  pages        = {112615},
  shortjournal = {Automatica},
  title        = {Event-triggered boundary estimation for 2 × 2 hyperbolic PDEs with disturbance},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven unknown-input observers. <em>AUTOM</em>, <em>183</em>, 112614. (<a href='https://doi.org/10.1016/j.automatica.2025.112614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown inputs related to, e.g., sensor aging, modeling errors, or device bias, represent a major concern in wireless sensor networks, as they degrade the state estimation performance. To improve the performance, unknown-input observers (UIOs) have been proposed. Most of the results available to design UIOs are based on explicit system models, which can be difficult or impossible to obtain in real-world applications. Data-driven techniques, on the other hand, have become a viable alternative for the design and analysis of unknown systems using only data. In this context, a novel data-driven distributed unknown-input observer (D-DUIO) for unknown continuous-time linear time-invariant (LTI) systems is developed, which requires solely some data collected offline, without any prior knowledge of the system matrices. In the paper, first, a model-based approach to the design of a DUIO is presented. A sufficient condition for the existence of such a DUIO is recalled, and a new one is proposed, that is prone to a data-driven adaptation. Moving to a data-driven approach, it is shown that under suitable assumptions on the input/output/state data collected from the continuous-time system, it is possible to both claim the existence of a D-DUIO and to derive its matrices in terms of the matrices of pre-collected data. Finally, the efficacy of the D-DUIO is illustrated by means of numerical examples.},
  archive      = {J_AUTOM},
  author       = {Yuzhou Wei and Giorgia Disarò and Wenjie Liu and Jian Sun and Maria Elena Valcher and Gang Wang},
  doi          = {10.1016/j.automatica.2025.112614},
  journal      = {Automatica},
  month        = {1},
  pages        = {112614},
  shortjournal = {Automatica},
  title        = {Distributed data-driven unknown-input observers},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robustness of supervisory controllers subject to measurement disturbances. <em>AUTOM</em>, <em>183</em>, 112613. (<a href='https://doi.org/10.1016/j.automatica.2025.112613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the supervisory control problem for a class of uncertain nonlinearly parameterized systems in the presence of measurement disturbance. Based on the well-established estimator-based supervisory control structure, a robustification of supervisory controller dealing with measurement disturbance is developed taking advantage of the monitoring signals redesign, such that the plant state asymptotically converges to a given set-point or its neighborhood, subject to the vanishing or the persistent measurement disturbance, respectively. Moreover, a constructive design of the multi-estimator using measurement feedback is proposed for the supervisory control of a class of uncertain nonlinearly parameterized systems in the strict-feedback form. A numerical simulation based on an uncertain mass–spring system is given to show the efficacy of our proposed algorithm, in which we use an event-trigger to be a measurement disturbance generator.},
  archive      = {J_AUTOM},
  author       = {Yutian Wang and Qingkai Meng and Yi Jiang},
  doi          = {10.1016/j.automatica.2025.112613},
  journal      = {Automatica},
  month        = {1},
  pages        = {112613},
  shortjournal = {Automatica},
  title        = {Robustness of supervisory controllers subject to measurement disturbances},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-driven min–max MPC for linear systems: Robustness and adaptation. <em>AUTOM</em>, <em>183</em>, 112612. (<a href='https://doi.org/10.1016/j.automatica.2025.112612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven controllers design is an important research problem, in particular when data is corrupted by the noise. In this paper, we propose a data-driven min–max model predictive control (MPC) scheme using noisy input-state data for unknown linear time-invariant (LTI) system. The unknown system matrices are characterized by a set-membership representation using the noisy input-state data. Leveraging this representation, we derive an upper bound on the worst-case cost and determine the corresponding optimal state-feedback control law through a semidefinite program (SDP). We prove that the resulting closed-loop system is robustly stabilized and satisfies the input and state constraints. Further, we propose an adaptive data-driven min–max MPC scheme which exploits additional online input-state data to improve closed-loop performance. Numerical examples show the effectiveness of the proposed methods.},
  archive      = {J_AUTOM},
  author       = {Yifan Xie and Julian Berberich and Frank Allgöwer},
  doi          = {10.1016/j.automatica.2025.112612},
  journal      = {Automatica},
  month        = {1},
  pages        = {112612},
  shortjournal = {Automatica},
  title        = {Data-driven min–max MPC for linear systems: Robustness and adaptation},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Local practically safe extremum seeking with assignable rate of attractivity to the safe set. <em>AUTOM</em>, <em>183</em>, 112611. (<a href='https://doi.org/10.1016/j.automatica.2025.112611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Assignably Safe Extremum Seeking (ASfES), an algorithm designed to minimize a measured, static objective function while maintaining a measured, static metric of safety (a control barrier function or CBF) to be positive in a practical sense. We ensure that for trajectories with safe initial conditions, the violation of safety can be made arbitrarily small through appropriately chosen design constants. We also guarantee an assignable “attractivity” rate: from unsafe initial conditions, the trajectories approach the safe set, in the sense of the measured CBF, at a rate no slower than a user-assigned rate. Similarly, from safe initial conditions, the trajectories approach the unsafe set, in the sense of the CBF, no faster than the assigned attractivity rate. The feature of assignable attractivity is not present in the semiglobal version of safe extremum seeking, where the semiglobality of convergence is achieved by slowing the adaptation. We also demonstrate local convergence of the parameter to a neighborhood of the minimum of a quadratic objective function constrained to the safe set with a linear CBF. The ASfES algorithm and analysis are multivariable, but we also extend the algorithm to a Newton-Based ASfES scheme which we show is only useful in the scalar case. The proven properties of the designs are illustrated through simulation examples.},
  archive      = {J_AUTOM},
  author       = {Alan Williams and Miroslav Krstic and Alexander Scheinker},
  doi          = {10.1016/j.automatica.2025.112611},
  journal      = {Automatica},
  month        = {1},
  pages        = {112611},
  shortjournal = {Automatica},
  title        = {Local practically safe extremum seeking with assignable rate of attractivity to the safe set},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Secondary safety control for systems with sector bounded nonlinearities. <em>AUTOM</em>, <em>183</em>, 112610. (<a href='https://doi.org/10.1016/j.automatica.2025.112610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of safety verification and safety-aware controller synthesis for systems with sector bounded nonlinearities. We aim to keep the states of the system within a given safe set under potential actuator and sensor attacks. Specifically, we adopt the setup that a controller has already been designed to stabilize the plant. Using invariant sets and barrier certificate theory, we first give sufficient conditions to verify the safety of the closed-loop system under attacks. Furthermore, by using a subset of sensors that are assumed to be free of attacks, we provide a synthesis method for a secondary controller that enhances the safety of the system. The sufficient conditions to verify safety are derived using Lyapunov-based tools and the S -procedure. Using the projection lemma, the conditions are then formulated as linear matrix inequality (LMI) problems which can be solved efficiently. Lastly, our theoretical results are illustrated through numerical simulations.},
  archive      = {J_AUTOM},
  author       = {Yankai Lin and Michelle S. Chong and Carlos Murguia},
  doi          = {10.1016/j.automatica.2025.112610},
  journal      = {Automatica},
  month        = {1},
  pages        = {112610},
  shortjournal = {Automatica},
  title        = {Secondary safety control for systems with sector bounded nonlinearities},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Non-parametric IQC multipliers in data-driven robust controller synthesis. <em>AUTOM</em>, <em>183</em>, 112608. (<a href='https://doi.org/10.1016/j.automatica.2025.112608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a robust data-driven controller synthesis method for generalised multi-input multi-output (MIMO) systems. Using the frequency response of a linear time-invariant (LTI) MIMO system and characterising perturbations through Integral Quadratic Constraint (IQC), the method provides a convex set of controllers robust to perturbations. This facilitates the design of controllers with either robust stability or robust performance criteria. Notably, the proposed method is versatile, as it is also applicable for non-parametric IQC multipliers. An example of a non-parametric IQC multiplier for elliptical uncertainty quantification is demonstrated and subsequently employed in designing a robust controller for a hybrid active-passive micro-vibration platform. Experimental results show that the synthesised controller effectively achieves the desired levels of both robustness and performance.},
  archive      = {J_AUTOM},
  author       = {Vaibhav Gupta and Elias Klauser and Alireza Karimi},
  doi          = {10.1016/j.automatica.2025.112608},
  journal      = {Automatica},
  month        = {1},
  pages        = {112608},
  shortjournal = {Automatica},
  title        = {Non-parametric IQC multipliers in data-driven robust controller synthesis},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Iterative learning control for performance-driven switched systems under all unknown channel gains. <em>AUTOM</em>, <em>183</em>, 112607. (<a href='https://doi.org/10.1016/j.automatica.2025.112607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fading channels introduce random and unknown gains into signal transmission, which has a great impact on the accuracy of the transmitted data, thus affecting system stability. However, there are few studies on this regard in the control field. In this paper, the transmission of both feedback and switching signals is affected by the unknown channel gains, which induces severe mode asynchronization in the switched systems under iterative learning control (ILC). For the faded switching signals, by designing a calibration-rounding mechanism (CRM) to recover it, the asynchronous time can gradually decrease with the iteration, and finally the system achieves synchronization, that is calibration-rounding-based iterative synchronization (CRIS). For the faded feedback signals, an improved gain estimation mechanism (IGEM) is given to correct the signal faster with fewer iterations. Moreover, a novel tracking performance-driven switching law (TPD-SL) is proposed to reasonably schedule subsystems for obtaining optimal performance. A set of new average dwell time (ADT) conditions with the minimum synchronization time is obtained. Finally, the effectiveness of the method is verified by numerical simulations.},
  archive      = {J_AUTOM},
  author       = {Yiwen Qi and Ziyu Qu and Dong Shen},
  doi          = {10.1016/j.automatica.2025.112607},
  journal      = {Automatica},
  month        = {1},
  pages        = {112607},
  shortjournal = {Automatica},
  title        = {Iterative learning control for performance-driven switched systems under all unknown channel gains},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Induced norm analysis of linear systems for nonnegative input signals. <em>AUTOM</em>, <em>183</em>, 112606. (<a href='https://doi.org/10.1016/j.automatica.2025.112606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the analysis of the L p ( p ∈ [ 1 , ∞ ) , p = ∞ ) induced norms of continuous-time linear systems where input signals are restricted to be nonnegative. This norm is referred to as the L p + induced norm in this paper. It has been shown recently that the L 2 + induced norm is effective for the stability analysis of nonlinear feedback systems where the nonlinearity returns only nonnegative signals. However, the exact computation of the L 2 + induced norm is essentially difficult. To get around this difficulty, in the first part of this paper, we provide a copositive-programming-based method for the upper bound computation by capturing the nonnegativity of the input signals by copositive multipliers. In the second part, we consider how far the L 2 + induced norm can be smaller than the standard L 2 induced norm, and derive the uniform infimum on the ratio of the L 2 + induced norm to the L 2 induced norm over all linear systems including infinite-dimensional ones. Then, for each linear system, we finally derive a computation method of the lower bounds of the L 2 + induced norm that are larger than (or equal to) the value determined by the uniform infimum. The effectiveness of the upper/lower bound computation methods is illustrated by numerical examples.},
  archive      = {J_AUTOM},
  author       = {Yoshio Ebihara and Noboru Sebe and Hayato Waki and Dimitri Peaucelle and Sophie Tarbouriech and Victor Magron and Tomomichi Hagiwara},
  doi          = {10.1016/j.automatica.2025.112606},
  journal      = {Automatica},
  month        = {1},
  pages        = {112606},
  shortjournal = {Automatica},
  title        = {Induced norm analysis of linear systems for nonnegative input signals},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed fault-tolerant control for a class of uncertain cascaded ODE-PDE multi-agent systems. <em>AUTOM</em>, <em>183</em>, 112605. (<a href='https://doi.org/10.1016/j.automatica.2025.112605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed fault-tolerant control is proposed for a class of uncertain cascaded ordinary differential equation (ODE)-partial differential equation (PDE) multi-agents. For the cascaded system under consideration, the output of ODEs serves as the input signal of PDEs such that a distributed control involving states of the ODE as well as the PDE system is expected to be designed for consensus tracking. Based on the designed distributed control, where the actuator is assumed to be healthy, a distributed fault-tolerant control is designed to guarantee the performance of the system, and it is further improved to deal with actuator failures. To enhance the robustness of the cascaded system, the system uncertainties and the external disturbances of both followers and leader are compensated using adaptive laws and an adaptive distributed observer, based on which the stabilization of the cascaded ODE-PDE multi-agent system can be achieved with partially known agents’ information. Simulation results are carried out to prove the effectiveness of the proposed method.},
  archive      = {J_AUTOM},
  author       = {Xueyan Xing and Guoqiang Hu},
  doi          = {10.1016/j.automatica.2025.112605},
  journal      = {Automatica},
  month        = {1},
  pages        = {112605},
  shortjournal = {Automatica},
  title        = {Distributed fault-tolerant control for a class of uncertain cascaded ODE-PDE multi-agent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A compensation-oriented algorithm for difference-driven identification under binary-valued observations and data packet dropout. <em>AUTOM</em>, <em>183</em>, 112604. (<a href='https://doi.org/10.1016/j.automatica.2025.112604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the identification problem for finite impulse response (FIR) systems with binary-valued observations under event-triggered communication mechanism and data packet dropout. The challenge lies in the inability to distinguish between untriggered events and packet loss when no information is received, which prevents us from obtaining the statistical properties of the binary-valued sequence. A compensation-oriented difference-driven identification (CODD) algorithm is proposed to estimate the parameter by recovering the mean of the original binary-valued sequence, where different values for the observation estimates are assigned when receiving 0, 1 or nothing. Even though, the convergence analysis of the parameter estimate is still challenging since the assigned values are dependent. To tackle this difficulty, the estimate error is divided into two parts: an initial assigned value related part, which is demonstrated to be convergent through the construction of an auxiliary set, and the remaining component, which happens to be a convergent martingale-difference sequence. As a result, the almost sure convergence and the asymptotic normality of the CODD algorithm are established when data packet loss probability is less than 1 2 . By calculating the communication rate, it is proven that the difference-driven mechanism can save 50% of the communication cost compared to original binary-valued systems. Furthermore, when data packet loss probability is high, an m -channel compensation-oriented identification ( m -CODD) algorithm is constructed by utilizing retransmission of the each observation for m times, which is designed based on the packet loss probability. The properties of m -CODD algorithm including convergence, asymptotic normality and communication rate are established. Numerical simulations are illustrated to show the theoretical results.},
  archive      = {J_AUTOM},
  author       = {Tianning Han and Ying Wang and Jin Guo and Yanlong Zhao},
  doi          = {10.1016/j.automatica.2025.112604},
  journal      = {Automatica},
  month        = {1},
  pages        = {112604},
  shortjournal = {Automatica},
  title        = {A compensation-oriented algorithm for difference-driven identification under binary-valued observations and data packet dropout},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive fault-tolerant control of nonlinear systems: A self-regulating spatiotemporal performance approach. <em>AUTOM</em>, <em>183</em>, 112602. (<a href='https://doi.org/10.1016/j.automatica.2025.112602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of performance constraints of uncertain nonlinear systems with actuator faults. Particularly, by developing the boundary threshold triggering strategy, the performance boundaries would be updated adaptively once the distance between the tracking error and the performance boundaries is smaller than the given threshold. Moreover, compared with the existing works, the transient behaviors are improved, and the limitation imposed on the initial conditions is removed attributed to the construction of novel performance functions and error transformation. Then, an adaptive fault-tolerant control scheme with self-regulating spatiotemporal performance is designed for a class of nonlinear systems with non-parametric uncertainties. It is shown that both the boundedness of the closed-loop signals and the satisfactory performance constraints are guaranteed in the presence of unpredictable actuator failure. The effectiveness of the proposed method is verified by theoretical analysis and numerical simulation.},
  archive      = {J_AUTOM},
  author       = {Zeqiang Li and Jason J.R. Liu and Yongduan Song},
  doi          = {10.1016/j.automatica.2025.112602},
  journal      = {Automatica},
  month        = {1},
  pages        = {112602},
  shortjournal = {Automatica},
  title        = {Adaptive fault-tolerant control of nonlinear systems: A self-regulating spatiotemporal performance approach},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fully coupled nonlinear FBS△Es: Solvability and LQ control insights. <em>AUTOM</em>, <em>183</em>, 112601. (<a href='https://doi.org/10.1016/j.automatica.2025.112601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a class of fully coupled nonlinear forward–backward stochastic difference equations (FBS △ Es) is proposed and the existence of solutions is proved based on a linear-quadratic (LQ) optimal control problem. Inspired from the solvability studies of various forward–backward stochastic differential equations (FBSDEs), the dominant-monotone framework is discretized and a continuum approach is used to prove the unique solvability of the fully coupled FBS △ Es and to obtain a pair of estimates on the solutions, and finally, the conclusions are applied to the related LQ problem.},
  archive      = {J_AUTOM},
  author       = {Zhipeng Niu and Qingxin Meng and Xun Li and Maoning Tang},
  doi          = {10.1016/j.automatica.2025.112601},
  journal      = {Automatica},
  month        = {1},
  pages        = {112601},
  shortjournal = {Automatica},
  title        = {Fully coupled nonlinear FBS△Es: Solvability and LQ control insights},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Aerial target encirclement and interception with noisy range observations. <em>AUTOM</em>, <em>183</em>, 112600. (<a href='https://doi.org/10.1016/j.automatica.2025.112600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a strategy to encircle and intercept a non-cooperative aerial point-mass moving target by leveraging noisy range measurements for state estimation. In this approach, the guardians actively ensure the observability of the target by using an anti-synchronization (AS), 3D “vibrating string” trajectory, which enables rapid position and velocity estimation based on the Kalman filter. Additionally, a novel anti-target controller is designed for the guardians to enable adaptive transitions from encircling a protected target to encircling, intercepting, and neutralizing a hostile target, taking into consideration the input constraints of the guardians. Based on the guaranteed uniform observability, the exponentially bounded stability of the state estimation error and the convergence of the encirclement error are rigorously analyzed. Simulation results and real-world UAV experiments are presented to further validate the effectiveness of the system design.},
  archive      = {J_AUTOM},
  author       = {Fen Liu and Shenghai Yuan and Thien-Minh Nguyen and Wei Meng and Lihua Xie},
  doi          = {10.1016/j.automatica.2025.112600},
  journal      = {Automatica},
  month        = {1},
  pages        = {112600},
  shortjournal = {Automatica},
  title        = {Aerial target encirclement and interception with noisy range observations},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stochastic gradient hamiltonian sequential monte carlo filter with earth mover’s distance sampling for target tracking. <em>AUTOM</em>, <em>183</em>, 112599. (<a href='https://doi.org/10.1016/j.automatica.2025.112599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed missile tracking requires advanced filtering algorithms to overcome the limitations of traditional nonlinear methods. This study presents the stochastic gradient Hamiltonian sequential Monte Carlo filter, combining stochastic gradient Hamilton Monte Carlo with sequential Monte Carlo (SMC) for enhanced sampling performance and reduced computational burden. The method incorporates Earth Mover’s Distance based adaptive resampling with theoretical bounds for optimal particle count. Validation through univariate nonstationary growth model simulation and bearing-only tracking experiments demonstrates superior performance over conventional methods, achieving 15 % root mean square error improvement compared to conventional SMC and 30 % over extended Kalman filter/unscented Kalman filter approaches.},
  archive      = {J_AUTOM},
  author       = {Chang Ho Kang and Sun Young Kim},
  doi          = {10.1016/j.automatica.2025.112599},
  journal      = {Automatica},
  month        = {1},
  pages        = {112599},
  shortjournal = {Automatica},
  title        = {Stochastic gradient hamiltonian sequential monte carlo filter with earth mover’s distance sampling for target tracking},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed nash equilibrium seeking with a dynamic set of players. <em>AUTOM</em>, <em>183</em>, 112598. (<a href='https://doi.org/10.1016/j.automatica.2025.112598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formulates a new distributed Nash equilibrium seeking problem with a dynamic set of players in which players are allowed to join and leave the network in a free manner during the decision-making process. To accommodate the dynamic joining and leaving behaviors of the players, a status estimation mechanism, which is capable of estimating in a finite time whether the players are active or inactive, is introduced. Based on the status estimation mechanism, a gradient play based algorithm is developed for distributed Nash equilibrium seeking in the dynamic environment. It is shown that under strongly connected communication graphs, players’ actions are convergent to a small neighborhood of the new Nash equilibrium linearly every time the player set changes. Moreover, the convergence accuracy and convergence rate can be adjusted by suitably tuning the step-size. To cover more general communication scenarios, strongly connected graphs are further relaxed to be B-jointly connected graphs, under which the convergence properties of the proposed algorithm are analytically studied. Furthermore, the upper bound of the average tracking error is quantified to evaluate the dynamic performance of the proposed algorithm. In the last, a simulation study on energy consumption games is given to verify the effectiveness of the proposed algorithm.},
  archive      = {J_AUTOM},
  author       = {Yuxuan Liu and Maojiao Ye and Lei Ding and Lihua Xie and Qing-Long Han},
  doi          = {10.1016/j.automatica.2025.112598},
  journal      = {Automatica},
  month        = {1},
  pages        = {112598},
  shortjournal = {Automatica},
  title        = {Distributed nash equilibrium seeking with a dynamic set of players},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Constrained finite-time and fixed-time stabilization for linear systems: Adaptive implicit lyapunov function-based control. <em>AUTOM</em>, <em>183</em>, 112597. (<a href='https://doi.org/10.1016/j.automatica.2025.112597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, finite-time and fixed-time stabilization problems are investigated for single-input single-output (SISO) linear system under the control input constraint. The achievement of finite-time or fixed-time convergence rates is facilitated through the utilization of adaptive implicit Lyapunov function (ILF)-based control. For ease of practical implementation, the dynamics of Approximated-ILF (AILF) guarantees the precise estimation of ILF, while the stability of AILF-based control holds established. Furthermore, from both performance and input-constrained safety considerations, the anti-windup (AW) AILF endows the system with tolerance to saturation and maintains the non-asymptotic convergence properties. Numerical simulations support the obtained theoretical results and verify their effectiveness.},
  archive      = {J_AUTOM},
  author       = {Peng Wang and Mou Chen and Shuzhi Sam Ge and Xiaobing Zhang},
  doi          = {10.1016/j.automatica.2025.112597},
  journal      = {Automatica},
  month        = {1},
  pages        = {112597},
  shortjournal = {Automatica},
  title        = {Constrained finite-time and fixed-time stabilization for linear systems: Adaptive implicit lyapunov function-based control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Input-to-state stability of self-triggered impulsive control systems. <em>AUTOM</em>, <em>183</em>, 112596. (<a href='https://doi.org/10.1016/j.automatica.2025.112596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the local input-to-state stability ( LISS ) of nonlinear systems under the self-triggered impulsive control ( STIC ) method. A novel LISS -type comparison principle is proposed, by which the LISS property of addressed system can be derived by the LISS property of its comparison system. On the basis of it, some Lyapunov-based sufficient conditions for non-Zeno behavior and LISS of nonlinear systems are provided in the framework of STIC . Moreover, the designed self-triggering mechanism ( STM ) is in the form of an explicit relationship with simple structure and east implementation. Finally, two numerical examples are given to illustrate the effectiveness of the proposed results.},
  archive      = {J_AUTOM},
  author       = {Xiaodi Li and Mingzhu Wang},
  doi          = {10.1016/j.automatica.2025.112596},
  journal      = {Automatica},
  month        = {1},
  pages        = {112596},
  shortjournal = {Automatica},
  title        = {Input-to-state stability of self-triggered impulsive control systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-triggered global and group consensus for linear multiagent systems with multiplicative noises. <em>AUTOM</em>, <em>183</em>, 112595. (<a href='https://doi.org/10.1016/j.automatica.2025.112595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the event-triggered global and group consensus problems for linear multiagent systems (MASs) with multiplicative noises and directed topology. First, for the global consensus of MASs under a balanced directed graph, a stochastic input-to-state stability property is proved to show that the piecewise constant control input has sufficient feedback capability; based on the relative state measurement, two novel static and dynamic event-triggered mechanisms (ETMs) are established to reduce the number of controller updates, where the Zeno phenomenon is effectively eliminated by imposing a uniformly strictly fixed positive time for all the inter-event times. Especially, new stochastic stability analysis techniques are developed to give sufficient conditions of mean square and almost sure consensus in both static and dynamic ETMs. Moreover, the obtained results on global consensus are extended to the setting of group consensus in order to cope with some grouping tasks in practical applications. Finally, some examples are presented to show the validity of theoretical results.},
  archive      = {J_AUTOM},
  author       = {Ruru Jia and Yuan-Hua Ni and Guangchen Wang},
  doi          = {10.1016/j.automatica.2025.112595},
  journal      = {Automatica},
  month        = {1},
  pages        = {112595},
  shortjournal = {Automatica},
  title        = {Event-triggered global and group consensus for linear multiagent systems with multiplicative noises},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-model-hybrid-driven near-optimal operational control of two-time-scale industrial systems with unknown operational model. <em>AUTOM</em>, <em>183</em>, 112594. (<a href='https://doi.org/10.1016/j.automatica.2025.112594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the optimal operational control (OOC) problem of two-time-scale (TTS) industrial systems with unknown operation model. Based on the singular perturbation theory (SPT), the OOC problem of TTS industrial systems is decomposed into an optimal regulation problem in fast time-scale and an optimal set-point tracking problem in slow time-scale. Then, by convex duality, the obtained optimization problems are equivalently transformed into convex optimization (CO) problems, and a data-model-hybrid-driven composite controller is designed. The design method of this composite controller avoids the potential numerical stiffness problems, and does not need complete system dynamics information while ensuring the steady-state output tracking error converges to zero. Finally, an example of mixed separation thickening process (MSTP) of hematite beneficiation is given to show the effectiveness of the proposed scheme.},
  archive      = {J_AUTOM},
  author       = {Yao Xu and Linna Zhou and Jianguo Zhao and Lei Ma and Chunyu Yang},
  doi          = {10.1016/j.automatica.2025.112594},
  journal      = {Automatica},
  month        = {1},
  pages        = {112594},
  shortjournal = {Automatica},
  title        = {Data-model-hybrid-driven near-optimal operational control of two-time-scale industrial systems with unknown operational model},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-triggered distributed optimal coordination of heterogeneous linear MASs over weight-unbalanced digraphs. <em>AUTOM</em>, <em>183</em>, 112593. (<a href='https://doi.org/10.1016/j.automatica.2025.112593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the distributed optimal coordination problem of heterogeneous linear multi-agent systems is studied, in which the actual information of the left eigenvector and out-degree cannot be obtained in advance. The underlying communication network among agents is assumed to be a weight-unbalanced and strongly connected digraph. The global objective function of the whole system is the sum of privately-known local objective functions, which are assumed to be strongly convex with Lipschitz continuous gradients. To achieve the distributed optimal coordination with low communication and computational resource consumption, and to efficiently reduce the frequency of control signal updates, a new distributed event-triggered control scheme is proposed. In this scheme, an auxiliary system with adaptive edge weights is established to generate the optimal trajectories and the tracking control inputs are designed for agents to track the given optimal trajectories. It is privacy-preserving to some extent as no actual state or output information of agents is communicated with neighbors. Sufficient conditions are derived, under which the distributed optimal coordination under consideration can be exponentially achieved. Moreover, the Zeno-behavior is shown to be excluded. Additionally, for cases where agent states are unmeasurable, a new distributed event-triggered observer-based control input is designed for each agent to achieve optimal coordination. Finally, numerical simulations are carried out to show the good performance of the proposed control scheme.},
  archive      = {J_AUTOM},
  author       = {Dandan Wang and Jialing Zhou and Guanghui Wen},
  doi          = {10.1016/j.automatica.2025.112593},
  journal      = {Automatica},
  month        = {1},
  pages        = {112593},
  shortjournal = {Automatica},
  title        = {Event-triggered distributed optimal coordination of heterogeneous linear MASs over weight-unbalanced digraphs},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reducing real-time complexity via sub-control lyapunov functions: From theory to experiments. <em>AUTOM</em>, <em>183</em>, 112592. (<a href='https://doi.org/10.1016/j.automatica.2025.112592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The techniques to design control Lyapunov functions (CLF), along with a proper stabilizing feedback, possibly in the presence of constraints, often provide control laws that are too complex for proper implementation online, especially when an optimization problem is involved. In this work, we show how to acquire an alternative, computationally attractive feedback. Given a nominal CLF and a nominal state feedback, we say that a different positive definite function is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative is negative-definite and bounded above by the Lyapunov derivative of the nominal function with the nominal control. It turns out that if we consider a family of basis functions, then an SCLF can be computed by linear programming, with an infinite number of constraints. The idea is that although the offline computational burden to achieve the new controller and solve the linear program is considerable, the online computational burden is drastically reduced. Comprehensive simulations and experiments on drone control are conducted to demonstrate the effectiveness of the study.},
  archive      = {J_AUTOM},
  author       = {Huu-Thinh Do and Franco Blanchini and Stefano Miani and Ionela Prodan},
  doi          = {10.1016/j.automatica.2025.112592},
  journal      = {Automatica},
  month        = {1},
  pages        = {112592},
  shortjournal = {Automatica},
  title        = {Reducing real-time complexity via sub-control lyapunov functions: From theory to experiments},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adversarial dynamic games for markov jump systems: A policy iteration Q-learning method. <em>AUTOM</em>, <em>183</em>, 112591. (<a href='https://doi.org/10.1016/j.automatica.2025.112591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reinforcement Q-learning approach for solving adversarial dynamic games in Markov jump systems. The H ∞ control problem is first formulated as a two-player zero-sum dynamic game, where the control policy and the disturbance policy act as adversarial players. To derive the Nash equilibrium control strategies for such games, a set of coupled algebraic Riccati equations is established, with the disturbance attenuation level properly prescribed. On this basis, two novel data-driven parallel Q-learning algorithms are proposed. The advantages of the proposed method are threefold: (i) it does not require precise knowledge of the system dynamics; (ii) it learns the optimal disturbance attenuation level; (iii) it yields Nash equilibrium control strategies. Finally, two simulation examples validate the effectiveness of the proposed method.},
  archive      = {J_AUTOM},
  author       = {Hao Shen and Jiacheng Wu and Jing Wang and Zhengguang Wu},
  doi          = {10.1016/j.automatica.2025.112591},
  journal      = {Automatica},
  month        = {1},
  pages        = {112591},
  shortjournal = {Automatica},
  title        = {Adversarial dynamic games for markov jump systems: A policy iteration Q-learning method},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). H2/H∞ state and output feedback control with sparse actuation. <em>AUTOM</em>, <em>183</em>, 112581. (<a href='https://doi.org/10.1016/j.automatica.2025.112581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present novel convex optimization formulations for designing full-state and output-feedback controllers with sparse actuation that achieve user-specified H 2 and H ∞ performance criteria. The sparsity is induced through the ℓ 1 -minimization over channel-wise H 2 norms from disturbances to the individual actuator signals, while simultaneously constraining H 2 or H ∞ norm from disturbances to the output variables The proposed approach is applied to a structural dynamics problem, demonstrating the advantages of simultaneous optimization of the control law and the actuation architecture in realizing an efficient closed-loop system, as well as highlighting the trade-offs between maximum allowable actuator magnitudes and the controller sparsity.},
  archive      = {J_AUTOM},
  author       = {Vedang M. Deshpande and Raktim Bhattacharya},
  doi          = {10.1016/j.automatica.2025.112581},
  journal      = {Automatica},
  month        = {1},
  pages        = {112581},
  shortjournal = {Automatica},
  title        = {H2/H∞ state and output feedback control with sparse actuation},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive dynamic event–triggered distributed optimal coordination of heterogeneous uncertain nonlinear multiagent systems. <em>AUTOM</em>, <em>183</em>, 112580. (<a href='https://doi.org/10.1016/j.automatica.2025.112580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed optimal coordination problem for a class of heterogeneous uncertain nonlinear multiagent systems. Instead of relying on the analytical forms of gradient functions, we use the measured gradient values depending on agents’ real-time outputs and propose a novel adaptive distributed control scheme. This scheme integrates event-triggered optimal coordinators, high-order filters, and tracking controllers. To handle the interaction between optimal coordinators and filters, we incorporate a new compensation term into the updating law for the coupling weight of each edge. Moreover, we design a novel adaptive distributed dynamic event-triggering mechanism that ensures that the inter-event times of each agent are lower bounded by a positive constant. Asymptotic convergence of agents’ outputs to the optimal point is proved by constructing a composite Lyapunov function. The proposed control scheme does not depend on global topology information. A numerical example is given to demonstrate the effectiveness of the proposed control scheme.},
  archive      = {J_AUTOM},
  author       = {Tianyu Liu and Lu Liu},
  doi          = {10.1016/j.automatica.2025.112580},
  journal      = {Automatica},
  month        = {1},
  pages        = {112580},
  shortjournal = {Automatica},
  title        = {Adaptive dynamic event–triggered distributed optimal coordination of heterogeneous uncertain nonlinear multiagent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accelerated primal–dual methods for strongly convex objective functions in continuous and discrete time. <em>AUTOM</em>, <em>183</em>, 112579. (<a href='https://doi.org/10.1016/j.automatica.2025.112579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a “second-order primal” + “first-order dual” continuous-time dynamic for linearly constrained optimization problems, where the objective function is μ -strongly convex. We consider a constant damping 2 μ for the second-order ordinary differential equation in the primal variable, following Nesterov’s acceleration for strongly convex optimization. A positive constant scaling is applied to the primal variable, while a positive increasing scaling function is applied to the dual variable. We prove that the proposed dynamic achieves a fast convergence rate for both the objective residual and the feasibility violation, with the decay rate potentially reaching O ( e − μ t ) . Additionally, we show that the dynamic is robust under small perturbations. By discretizing the proposed continuous-time dynamic, we develop an accelerated linearized augmented Lagrangian method for strongly convex composite optimization with linear constraints, where the objective function has a nonsmooth + smooth composite structure. The proposed algorithm achieves a fast convergence rate that matches the one of the continuous-time dynamic. We also consider an inexact version of the proposed algorithm, which can be viewed as a discrete version of the perturbed continuous-time dynamic. Numerical results are provided to verify the practical performances.},
  archive      = {J_AUTOM},
  author       = {Xin He and Dong He and Ya-Ping Fang},
  doi          = {10.1016/j.automatica.2025.112579},
  journal      = {Automatica},
  month        = {1},
  pages        = {112579},
  shortjournal = {Automatica},
  title        = {Accelerated primal–dual methods for strongly convex objective functions in continuous and discrete time},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical supervisory control of networked and cyber-attacked discrete-event systems. <em>AUTOM</em>, <em>183</em>, 112578. (<a href='https://doi.org/10.1016/j.automatica.2025.112578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In standard supervisory control of discrete-event systems, partial (incomplete) observations are given by deterministic functions such as natural projections, which erase unobservable events, or masks, which can represent indistinguishable events, where two or more different events yield the same observation. However, communication channels in modern technological systems are not always reliable and can be attacked by malicious external agents. In that case, the plant observations obtained by the supervisor may not be deterministic, e.g., due to delays and losses, or external attacks. This paper considers a unified supervisory control framework with set-valued (nondeterministic) observations and proposes a simplified version of nondeterministic observability, together with a generalized normality. It shows how the results of hierarchical control can be extended to the networked and cyber-attacked discrete-event systems at the same time.},
  archive      = {J_AUTOM},
  author       = {Shaowen Miao and Jan Komenda and Feng Lin},
  doi          = {10.1016/j.automatica.2025.112578},
  journal      = {Automatica},
  month        = {1},
  pages        = {112578},
  shortjournal = {Automatica},
  title        = {Hierarchical supervisory control of networked and cyber-attacked discrete-event systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the design of linear time varying model predictive control for trajectory stabilization. <em>AUTOM</em>, <em>183</em>, 112577. (<a href='https://doi.org/10.1016/j.automatica.2025.112577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilizing a reference trajectory of a nonlinear system is a recurrent, non-trivial task in control engineering. A common approach is to linearize the dynamics along the trajectory, thus deriving a linear-time-varying (LTV) model, and to design a model predictive controller (MPC), which results to be computationally efficient, since only convex programs need to be solved in real time, while retaining constraint handling capabilities. Building on recent developments in gain-scheduling control design, where linearization errors and tracking error bounds are considered, a new approach to derive such LTV-MPC controllers is presented. The method addresses the systematic derivation of a suitable terminal cost. The resulting MPC law is tube-based, exploiting the co-designed auxiliary gain-scheduled controller. Computational and implementation aspects are discussed as well, and the resulting hierarchical method is demonstrated both in simulation and in experiments with a small drone with fast dynamics and limited embedded computational capacity.},
  archive      = {J_AUTOM},
  author       = {Nicolas Kessler and Lorenzo Fagiano},
  doi          = {10.1016/j.automatica.2025.112577},
  journal      = {Automatica},
  month        = {1},
  pages        = {112577},
  shortjournal = {Automatica},
  title        = {On the design of linear time varying model predictive control for trajectory stabilization},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intersection-based architectures for decentralized diagnosis of discrete event systems. <em>AUTOM</em>, <em>183</em>, 112576. (<a href='https://doi.org/10.1016/j.automatica.2025.112576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two intersection-based architectures, named the normal-state-estimator-intersection-based architecture (N-SEI architecture) and the failure-state-estimator-intersection-based architecture (F-SEI architecture), are examined for decentralized diagnosis of discrete event systems. For each of these architectures, the corresponding notion of codiagnosability is defined. These defined notions of codiagnosability are incomparable with inference diagnosability for the inference-based architecture. In addition, codiagnosability for the N-SEI architecture is weaker than the existing notion of intersection-based codiagnosability, while codiagnosability for the F-SEI architecture is incomparable with it. For each of the N-SEI and F-SEI architectures, a method for verifying the corresponding notion of codiagnosability is developed.},
  archive      = {J_AUTOM},
  author       = {Shigemasa Takai and Takashi Yamamoto},
  doi          = {10.1016/j.automatica.2025.112576},
  journal      = {Automatica},
  month        = {1},
  pages        = {112576},
  shortjournal = {Automatica},
  title        = {Intersection-based architectures for decentralized diagnosis of discrete event systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed stochastic constrained optimization with constant step-sizes via saddle-point dynamics. <em>AUTOM</em>, <em>183</em>, 112575. (<a href='https://doi.org/10.1016/j.automatica.2025.112575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers distributed stochastic optimization problems over a multi-agent network, where each agent collaboratively minimizes the sum of individual expectation-valued cost functions subject to nonidentical set constraints. We first recast the distributed constrained optimization as a constrained saddle-point problem. Subsequently, two distributed stochastic algorithms via optimistic gradient descent ascent (SOGDA) and extragradient (SEG) methods are developed with constant step sizes, in which the variable sample-size technique is incorporated to reduce the variance of the sampled gradients. We present the explicit selection criteria of the constant step size, under which the developed algorithms achieve almost sure convergence to an optimal solution. Moreover, the convergence rate is O ( 1 / k ) for merely convex cost functions, which matches the optimal rate of its deterministic counterpart. Finally, a numerical example is provided to reflect the theoretical findings.},
  archive      = {J_AUTOM},
  author       = {Yi Huang and Shisheng Cui and Xianlin Zeng and Ziyang Meng},
  doi          = {10.1016/j.automatica.2025.112575},
  journal      = {Automatica},
  month        = {1},
  pages        = {112575},
  shortjournal = {Automatica},
  title        = {Distributed stochastic constrained optimization with constant step-sizes via saddle-point dynamics},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A characterization method of terminal ingredients for nonlinear MPC using value-based reinforcement learning. <em>AUTOM</em>, <em>183</em>, 112574. (<a href='https://doi.org/10.1016/j.automatica.2025.112574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability of nonlinear model predictive control (MPC) relies significantly on stabilizing factors such as the terminal region and cost. A larger terminal region not only expands the region of attraction for the closed-loop system but also contributes to reducing online computation costs. However, existing methods in the literature often impose limitations on the degrees of freedom available for characterizing terminal ingredients. This limitation arises from the reliance on either a predetermined linear local controller or a preset control Lyapunov function. This paper introduces an innovative approach to terminal ingredient characterization leveraging value-based reinforcement learning (RL). This method provides ample degrees of freedom for expanding the terminal region. To achieve this, a deep neural network is employed to learn the parametric state value function, serving as the terminal cost for MPC. The local controller adopts a one-step MPC instead of a predetermined linear or nonlinear feedback controller. Subsequently, a terminal set sequence is constructed iteratively through the one-step set expansion. The proposed approach’s effectiveness is validated through simulations.},
  archive      = {J_AUTOM},
  author       = {Jinghan Cui and Jinwu Gao and Xiangjie Liu and Yuqi Liu and Shuyou Yu},
  doi          = {10.1016/j.automatica.2025.112574},
  journal      = {Automatica},
  month        = {1},
  pages        = {112574},
  shortjournal = {Automatica},
  title        = {A characterization method of terminal ingredients for nonlinear MPC using value-based reinforcement learning},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Aperiodic-sampled neural network controllers with closed-loop stability verifications. <em>AUTOM</em>, <em>183</em>, 112573. (<a href='https://doi.org/10.1016/j.automatica.2025.112573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we synthesize two aperiodic-sampled deep neural network (DNN) control schemes, based on the closed-loop tracking stability guarantees. By means of the integral quadratic constraint coping with the input–output behavior of system uncertainties/nonlinearities and the convex relaxations of nonlinear DNN activations leveraging their local sector-bounded attributes, we establish conditions to design the event- and self-triggered logics and to compute the ellipsoidal inner approximations of region of attraction, respectively. Finally, we perform a numerical example of an inverted pendulum to illustrate the effectiveness of the proposed aperiodic-sampled DNN control schemes.},
  archive      = {J_AUTOM},
  author       = {Renjie Ma and Zhijian Hu and Rongni Yang and Ligang Wu},
  doi          = {10.1016/j.automatica.2025.112573},
  journal      = {Automatica},
  month        = {1},
  pages        = {112573},
  shortjournal = {Automatica},
  title        = {Aperiodic-sampled neural network controllers with closed-loop stability verifications},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backstepping for partial differential equations: A survey. <em>AUTOM</em>, <em>183</em>, 112572. (<a href='https://doi.org/10.1016/j.automatica.2025.112572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems modeled by partial differential equations (PDEs) are at least as ubiquitous as those by nature finite-dimensional and modeled by ordinary differential equations (ODEs). And yet, systematic and readily usable methodologies, for such a significant portion of real systems, have been historically scarce. Around the year 2000, the backstepping approach to PDE control began to offer not only a less abstract alternative to PDE control techniques replicating optimal and spectrum assignment techniques of the 1960s, but also enabled the methodologies of adaptive and nonlinear control, matured in the 1980s and 1990s, to be extended from ODEs to PDEs, allowing feedback synthesis for systems that are uncertain, nonlinear, and infinite-dimensional. The PDE backstepping literature has since grown to hundreds of papers and nearly a dozen books. This survey aims to facilitate the entry into this thriving area of overwhelming size and topical diversity. Designs of controllers and observers, for parabolic, hyperbolic, and other classes of PDEs, in one or more dimensions, with nonlinear, adaptive, sampled-data, and event-triggered extensions, are covered in the survey. The lifeblood of control are technology and physics. The survey places a particular emphasis on applications that have motivated the development of the theory and which have benefited from the theory and designs: flows, flexible structures, materials, thermal and chemically reacting dynamics, energy (from oil drilling to batteries and magnetic confinement fusion), and vehicles.},
  archive      = {J_AUTOM},
  author       = {Rafael Vazquez and Jean Auriol and Federico Bribiesca-Argomedo and Miroslav Krstic},
  doi          = {10.1016/j.automatica.2025.112572},
  journal      = {Automatica},
  month        = {1},
  pages        = {112572},
  shortjournal = {Automatica},
  title        = {Backstepping for partial differential equations: A survey},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Maximum principle for partial information non-zero sum stochastic differential games with mixed delays. <em>AUTOM</em>, <em>183</em>, 112570. (<a href='https://doi.org/10.1016/j.automatica.2025.112570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with one kind of partial information non-zero sum stochastic differential game with mixed delays. Both the state and control processes contain delays, where the former contains moving-average delay, discrete delay and noisy memory. We establish a necessary as well as two sufficient stochastic maximum principles for the game. As one of the main features of this research, a new kind of sufficient maximum principle is given, where the diffusion term can be controlled with non-convex control domains, and no second-order adjoint equation is needed. The theoretical results are applied to study two examples where the adjoint processes can be derived by two approaches and then the equilibrium points are obtained. This research generalizes those of stochastic optimal control problems.},
  archive      = {J_AUTOM},
  author       = {Pan Chen and Feng Zhang},
  doi          = {10.1016/j.automatica.2025.112570},
  journal      = {Automatica},
  month        = {1},
  pages        = {112570},
  shortjournal = {Automatica},
  title        = {Maximum principle for partial information non-zero sum stochastic differential games with mixed delays},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State estimation for lithium-ion batteries based on electrolyte–electrode PDE observers. <em>AUTOM</em>, <em>183</em>, 112568. (<a href='https://doi.org/10.1016/j.automatica.2025.112568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate information about the states of an electrochemical battery model facilitates a deeper understanding of battery behavior and enables performance enhancement. This paper first proposes backstepping Partial Differential Equation (PDE) observers for lithium concentration in the electrolyte phase within the negative electrode, positive electrode, and separator. Reverse sensitivity analysis is conducted to identify the most suitable measurable parameter for obtaining the electrolyte lithium concentration at the boundaries, which is used in the design of the electrolyte-phase observer. Subsequently, enhanced observers for the solid-phase lithium concentration in the negative and positive electrodes are developed. The proposed solid-phase observer enables more accurate State-of-Charge (SoC) estimation by leveraging the closed-loop electrolyte-phase observer. Simulations of the reverse sensitivity analysis and state observers are performed on a commercial cylindrical lithium iron phosphate ( LiFePO 4 ) cell to validate the effectiveness of the proposed approach.},
  archive      = {J_AUTOM},
  author       = {Sara Sepasiahooyi and Shu-Xia Tang},
  doi          = {10.1016/j.automatica.2025.112568},
  journal      = {Automatica},
  month        = {1},
  pages        = {112568},
  shortjournal = {Automatica},
  title        = {State estimation for lithium-ion batteries based on electrolyte–electrode PDE observers},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interval-constraint multiagent systems: Global attractivity and structural stability of equilibria. <em>AUTOM</em>, <em>183</em>, 112566. (<a href='https://doi.org/10.1016/j.automatica.2025.112566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the dynamic behavior of an interval-constraint multiagent system. Each agent has a constraint interval that limits its potential consensus values, achieved by encoding a nonsmooth piecewise function into the agent. In addition, the underlying graphs considered are strongly connected. First, a dichotomy of equilibria is identified: either a unique non-consensus equilibrium point or multiple consensus points, depending on whether the intersection of the constraint intervals is empty or not. Then, the set of equilibria is proven to be a global attractor. Structural stability of such a system is also proven based on real-analysis methods, showing that the equilibria have continuous dependence on changes of the constraint intervals. Three running examples are used to illustrate the proposed results.},
  archive      = {J_AUTOM},
  author       = {Fengqiu Liu and Kuize Zhang and Yuhu Wu and Xiaoping Xue},
  doi          = {10.1016/j.automatica.2025.112566},
  journal      = {Automatica},
  month        = {1},
  pages        = {112566},
  shortjournal = {Automatica},
  title        = {Interval-constraint multiagent systems: Global attractivity and structural stability of equilibria},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Closed-loop data-enabled predictive control and its equivalence with closed-loop subspace predictive control. <em>AUTOM</em>, <em>183</em>, 112556. (<a href='https://doi.org/10.1016/j.automatica.2025.112556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factors like growing data availability and increasing system complexity have sparked interest in data-driven predictive control (DDPC) methods like Data-enabled Predictive Control (DeePC). However, closed-loop identification bias arises in the presence of noise, which reduces the effectiveness of obtained control policies. In this paper we propose Closed-loop Data-enabled Predictive Control (CL-DeePC), a framework that unifies different approaches to address this challenge. To this end, CL-DeePC incorporates instrumental variables (IVs) to synthesize and sequentially apply consistent single or multi-step-ahead predictors. Furthermore, a computationally efficient CL-DeePC implementation is developed that reveals an equivalence with Closed-loop Subspace Predictive Control (CL-SPC). Time marching simulations of DeePC and CL-DeePC are conducted using Hankel matrices of past data that are updated at every time step to induce potentially troublesome closed-loop correlations between inputs and noise. Compared to DeePC, CL-DeePC simulations demonstrate superior reference tracking, with a sensitivity study finding a 48% lower susceptibility to noise-induced reference tracking performance degradation.},
  archive      = {J_AUTOM},
  author       = {Rogier Dinkla and Tom Oomen and Sebastiaan Paul Mulders and Jan-Willem van Wingerden},
  doi          = {10.1016/j.automatica.2025.112556},
  journal      = {Automatica},
  month        = {1},
  pages        = {112556},
  shortjournal = {Automatica},
  title        = {Closed-loop data-enabled predictive control and its equivalence with closed-loop subspace predictive control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated online learning for gaussian process regression. <em>AUTOM</em>, <em>183</em>, 112554. (<a href='https://doi.org/10.1016/j.automatica.2025.112554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Byzantine-resilient federated online learning for Gaussian process regression (GPR). We develop a Byzantine-resilient federated GPR algorithm that allows a cloud and a group of agents to collaboratively learn a latent function and improve the learning performances where some agents exhibit Byzantine failures, i.e., arbitrary and potentially adversarial behavior. Each agent-based local GPR sends potentially compromised local predictions to the cloud, and the cloud-based aggregated GPR computes a global model by a Byzantine-resilient product of experts aggregation rule. Then the cloud broadcasts the current global model to all the agents. Agent-based fused GPR refines local predictions by fusing the received global model with that of the agent-based local GPR. Moreover, we quantify the learning accuracy improvements of the agent-based fused GPR over the agent-based local GPR. Experiments on a toy example and two medium-scale real-world datasets are conducted to demonstrate the performances of the proposed algorithm.},
  archive      = {J_AUTOM},
  author       = {Xu Zhang and Zhenyuan Yuan and Minghui Zhu},
  doi          = {10.1016/j.automatica.2025.112554},
  journal      = {Automatica},
  month        = {1},
  pages        = {112554},
  shortjournal = {Automatica},
  title        = {Byzantine-resilient federated online learning for gaussian process regression},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Observer-based asymptotic active fault diagnosis: Separate and joint design of observer gain and input. <em>AUTOM</em>, <em>183</em>, 112548. (<a href='https://doi.org/10.1016/j.automatica.2025.112548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes observer gain and input design methods for observer-based asymptotic active fault diagnosis, which are based on a newly-defined notion named the excluding degree of the origin from a zonotope. Using the excluding degree, a quantitative specification is obtained to characterize the performance of set-based robust fault diagnosis. Furthermore, a separate gain design method and a joint gain and input design method are proposed, respectively. This is the first work to achieve a joint observer gain and input design for set-based active fault diagnosis. Compared with the existing methods that design gains and input separately, the proposed joint gain and input design method has advantages to exploit the fault diagnosis potential of observer-based schemes. Finally, several examples are used to illustrate the effectiveness of the proposed methods.},
  archive      = {J_AUTOM},
  author       = {Feng Xu and Yiming Wan and Ye Wang and Vicenç Puig},
  doi          = {10.1016/j.automatica.2025.112548},
  journal      = {Automatica},
  month        = {1},
  pages        = {112548},
  shortjournal = {Automatica},
  title        = {Observer-based asymptotic active fault diagnosis: Separate and joint design of observer gain and input},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Controller synthesis from noisy-input noisy-output data. <em>AUTOM</em>, <em>183</em>, 112545. (<a href='https://doi.org/10.1016/j.automatica.2025.112545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of synthesizing a dynamic output-feedback controller for a linear system, using solely input–output data corrupted by measurement noise. To handle input–output data, an auxiliary representation of the original system is utilized. By exploiting the structure of the auxiliary system, we design a controller that robustly stabilizes all possible systems consistent with data. Notably, we also provide a novel solution to extend the results to generic multi-input multi-output systems. The findings are illustrated by numerical examples.},
  archive      = {J_AUTOM},
  author       = {Lidong Li and Andrea Bisoffi and Claudio De Persis and Nima Monshizadeh},
  doi          = {10.1016/j.automatica.2025.112545},
  journal      = {Automatica},
  month        = {1},
  pages        = {112545},
  shortjournal = {Automatica},
  title        = {Controller synthesis from noisy-input noisy-output data},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accuracy bounds for the simulation of a class of continuous-time nonlinear models. <em>AUTOM</em>, <em>183</em>, 112543. (<a href='https://doi.org/10.1016/j.automatica.2025.112543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world dynamic systems evolve in the continuous-time world, while their models are simulated in the digital world using discrete-time numerical simulation algorithms. Such simulation is essential for a variety of system and control problems such as system identification and performance analysis of (control) systems. Ideally, the simulated model response should be identical to the system response. However, this is typically not the case in practice, even when the effects of unmodelled dynamics and parametric uncertainty are excluded. Even in that scenario, a mismatch exists between the response of the system and the model due to the interface between the physical world and the digital computer, unknown disturbances, and simulation inaccuracies. For the class of continuous-time, nonlinear Lur’e-type systems, this paper analyses the mismatch between the steady-state system response and the steady-state model response computed using the so-called mixed time–frequency algorithm. Firstly, a bound on the mismatch between the steady-state system response and the computed steady-state model response based on continuous-time signals is derived. Secondly, a bound for the same mismatch is derived for a sampled version of the signals. The bounds are further decomposed into several components, each given an interpretation that can be used to reduce the bounds on the mismatch. In a numerical case study, we show that reducing the bounds also reduces the actual mismatch.},
  archive      = {J_AUTOM},
  author       = {Fahim Shakib and Johan Schoukens and Alexander Yu. Pogromsky and Alexey Pavlov and Nathan van de Wouw},
  doi          = {10.1016/j.automatica.2025.112543},
  journal      = {Automatica},
  month        = {1},
  pages        = {112543},
  shortjournal = {Automatica},
  title        = {Accuracy bounds for the simulation of a class of continuous-time nonlinear models},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revisiting lossless convexification: Theoretical guarantees for discrete-time optimal control problems. <em>AUTOM</em>, <em>183</em>, 112537. (<a href='https://doi.org/10.1016/j.automatica.2025.112537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lossless Convexification (LCvx) is a modeling approach that transforms a class of nonconvex optimal control problems, where nonconvexity primarily arises from control constraints, into convex problems through convex relaxations. These convex problems can be solved using polynomial-time numerical methods after discretization, which converts the original infinite-dimensional problem into a finite-dimensional one. However, existing LCvx theory is limited to continuous-time optimal control problems, as the equivalence between the relaxed convex problem and the original nonconvex problem holds only in continuous-time. This paper extends LCvx theory to discrete-time optimal control problems by classifying them into normal and long-horizon cases. For normal cases, after an arbitrarily small perturbation to the system dynamics (recursive equality constraints), applying the existing LCvx method to discrete-time problems results in optimal controls that meet the original nonconvex constraints at all but no more than n x − 1 temporal grid points, where n x is the state dimension. For long-horizon cases, the existing LCvx method fails, but we resolve this issue by integrating it with a bisection search, leveraging the continuity of the value function from the relaxed convex problem to achieve similar results as in normal cases. This paper strengthens the theoretical foundation of LCvx, extending the applicability of LCvx theory to discrete-time optimal control problems.},
  archive      = {J_AUTOM},
  author       = {Dayou Luo and Kazuya Echigo and Behçet Açıkmeşe},
  doi          = {10.1016/j.automatica.2025.112537},
  journal      = {Automatica},
  month        = {1},
  pages        = {112537},
  shortjournal = {Automatica},
  title        = {Revisiting lossless convexification: Theoretical guarantees for discrete-time optimal control problems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated cubic regularized newton learning with sparsification-amplified differential privacy. <em>AUTOM</em>, <em>183</em>, 112531. (<a href='https://doi.org/10.1016/j.automatica.2025.112531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the cubic-regularized Newton method within a federated learning framework while addressing two major concerns: privacy leakage and communication bottlenecks. We propose the Differentially Private Federated Cubic Regularized Newton (DP-FCRN) algorithm, which leverages second-order techniques to achieve lower iteration complexity than first-order methods. We incorporate noise perturbation during local computations to ensure privacy. Furthermore, we employ sparsification in uplink transmission, which not only reduces the communication costs but also amplifies the privacy guarantee. Specifically, this approach reduces the necessary noise intensity without compromising privacy protection. We analyze the convergence properties of our algorithm and establish the privacy guarantee. Finally, we validate the effectiveness of the proposed algorithm through experiments on a benchmark dataset.},
  archive      = {J_AUTOM},
  author       = {Wei Huo and Changxin Liu and Kemi Ding and Karl Henrik Johansson and Ling Shi},
  doi          = {10.1016/j.automatica.2025.112531},
  journal      = {Automatica},
  month        = {1},
  pages        = {112531},
  shortjournal = {Automatica},
  title        = {Federated cubic regularized newton learning with sparsification-amplified differential privacy},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A consensus kalman filter on l2 spaces. <em>AUTOM</em>, <em>183</em>, 112530. (<a href='https://doi.org/10.1016/j.automatica.2025.112530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the estimation problem of infinite dimensional discrete-time stochastic linear systems with finite dimensional measurements on sensor networks modeled by connected undirected graphs. The framework encompasses discretized PDEs with sampled measurements. A new scheme of distributed consensus on measurements is extended to systems evolving in L 2 spaces in order to limit the information exchange to finite-dimensional vectors. We show that, in analogy to the finite-dimensional case, at each node the variance of the estimation error tends to the one of the centralized Kalman filter for systems is L 2 when the number of consensus steps increases.},
  archive      = {J_AUTOM},
  author       = {Stefano Battilotti and Alessandro Borri and Filippo Cacace and Massimiliano d’Angelo and Alfredo Germani},
  doi          = {10.1016/j.automatica.2025.112530},
  journal      = {Automatica},
  month        = {1},
  pages        = {112530},
  shortjournal = {Automatica},
  title        = {A consensus kalman filter on l2 spaces},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning for safe time-critical verification using reachability analysis. <em>AUTOM</em>, <em>183</em>, 112528. (<a href='https://doi.org/10.1016/j.automatica.2025.112528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a safe time-critical control problem using reachability analysis and design a reinforcement learning-based mechanism for learning online and in fixed-time the solution to the safe time-critical control problem. Safety is ensured by determining a set of states for which there exists an admissible control law generating a system trajectory that does not reach a set of forbidden states at a user-prescribed time instant. Specifically, we cast our safe time-critical problem as a Mayer optimal feedback control problem whose solution satisfies the Hamilton–Jacobi–Bellman (HJB) equation and characterizes the set of safe states. Since the HJB equation is generally difficult to solve, we develop an online critic-only reinforcement learning-based algorithm for simultaneously learning the solution to the HJB equation and the safe set in a fixed time. In particular, we introduce a non-Lipschitz experience replay-based learning law utilizing recorded and current data for updating the critic weights to learn the value function and the safe set. The non-Lipschitz property of the dynamics gives rise to fixed-time convergence, whereas the experience replay-based approach eliminates the need to satisfy the persistence of excitation condition provided that a recorded data set is sufficiently rich. Simulation results illustrate the efficacy of the proposed approach to the problem of fixed-wing unmanned aerial vehicle collision avoidance.},
  archive      = {J_AUTOM},
  author       = {Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis and Wassim M. Haddad},
  doi          = {10.1016/j.automatica.2025.112528},
  journal      = {Automatica},
  month        = {1},
  pages        = {112528},
  shortjournal = {Automatica},
  title        = {Fixed-time learning for safe time-critical verification using reachability analysis},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Orchestrating on-board sensors for global hybrid robust stabilization of unicycles. <em>AUTOM</em>, <em>183</em>, 112502. (<a href='https://doi.org/10.1016/j.automatica.2025.112502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider mobile robots described through unicycle dynamics equipped with on-board range sensors and cameras, one facing forward and one facing backward, providing measurements of the distance and misalignment to a target. We propose a hybrid control law combining the two on-board measurements and discuss stability results for the closed-loop expressed in the on-board camera-based coordinates, using Lyapunov-based arguments. We prove robustness of the stability properties to uncertainties affecting the sensors and external perturbations acting on the robot. The results are illustrated via simulations.},
  archive      = {J_AUTOM},
  author       = {Riccardo Ballaben and Alessandro Astolfi and Philipp Braun and Luca Zaccarian},
  doi          = {10.1016/j.automatica.2025.112502},
  journal      = {Automatica},
  month        = {1},
  pages        = {112502},
  shortjournal = {Automatica},
  title        = {Orchestrating on-board sensors for global hybrid robust stabilization of unicycles},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cma">CMA - 12</h2>
<ul>
<li><details>
<summary>
(2025). A data-driven algorithm for solving image despeckling PDE model using physics-informed ConvNet. <em>CMA</em>, <em>200</em>, 202-227. (<a href='https://doi.org/10.1016/j.camwa.2025.09.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a new data-driven algorithm for the Perona-Malik image despeckling problem. The advantage of the proposed algorithm over neural network-based methods is that it does not need any noisy and clean image data pair for training. The proposed algorithm is implemented using a three-dimensional convolution neural network (ConvNet) architecture. We compare its output with results obtained from several existing methods, including the operator splitting RBF collocation method, the finite difference method (FDM), and physics-informed neural networks (PINNs). To evaluate the performance of the proposed algorithm, simulations are carried out using grayscale images that have been artificially corrupted with different levels of speckle noise. Using the peak signal to noise ratio (PSNR) and structural similarity index measure (SSIM) as the evaluation metric, we observed that the proposed algorithm outperforms these existing methods, demonstrating superior image quality with the same numerical scheme and the same discretization. To the best of our knowledge, this work represents the first application of physics-inspired convolutional neural network for PDE-based image despeckling model.},
  archive      = {J_CMA},
  author       = {Haridarshan Kumar and Sanjeev Kumar},
  doi          = {10.1016/j.camwa.2025.09.022},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {202-227},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A data-driven algorithm for solving image despeckling PDE model using physics-informed ConvNet},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An easy to implement numerical framework for a cancer invasion mathematical model with two distinct cancer sub-populations. <em>CMA</em>, <em>200</em>, 180-201. (<a href='https://doi.org/10.1016/j.camwa.2025.09.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a finite element scheme for solving a model that involves sub-populations of cancer cells. The model is formulated by four coupled partial differential equations, which represent the evolution of tumor growth, the density of cancer cell sub-populations arising from mutations, the density of the extracellular matrix (ECM), and the concentration of matrix-degrading enzymes (MDE). A semi-implicit backward Euler finite element framework has been developed for this model. Unconditional error estimates have been established for all variables, and the unconditional stability of the solutions has also been demonstrated. To validate the proposed numerical scheme, we have performed numerical simulations, including an assessment of the convergence rate and comparisons between the numerical solutions and analytical solutions.},
  archive      = {J_CMA},
  author       = {Yadhavan Karuppusamy and Lingeshwaran Shangerganesh and Sally Mohammed Farghaly Abdelaliem and A.S. Hendy},
  doi          = {10.1016/j.camwa.2025.09.011},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {180-201},
  shortjournal = {Comput. Meth. Appl.},
  title        = {An easy to implement numerical framework for a cancer invasion mathematical model with two distinct cancer sub-populations},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilize physics-informed neural networks for stiff differential equations: Re-spacing layer. <em>CMA</em>, <em>200</em>, 167-179. (<a href='https://doi.org/10.1016/j.camwa.2025.09.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximating the solution of stiff differential equations, which exhibit abrupt changes in certain regions, using physics-informed neural networks (PINNs) is challenging. Typically, training PINNs involves using a larger number of samples concentrated around regions of rapid changes to resolve the sharp gradients. However, this strategy leads to data imbalance, resulting in slower convergence and reduced solution quality. Here, we propose Re-spacing layer (RS-layer) to mitigate these challenges. RS-layer is a pre-trained encoding layer designed to map the skewed distribution of sampling points onto a uniform distribution, maintaining the desirable statistical properties of the input data for effective PINN training. We demonstrate that RS-layer improves PINN training by regularizing the solution gradient in the transformed space. The efficacy of our method is validated through numerical experiments on one-dimensional singularly perturbed equations, the ROBER problem, and the Akzo Nobel problem. Our results show that RS-layer not only accelerates convergence, but also enhances accuracy.},
  archive      = {J_CMA},
  author       = {Eunsuh Kim and Heejae Kwon and Sungha Cho and Kyongmin Yeo and Minseok Choi},
  doi          = {10.1016/j.camwa.2025.09.014},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {167-179},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Stabilize physics-informed neural networks for stiff differential equations: Re-spacing layer},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hp-version discontinuous galerkin time-stepping schemes for diffusive-viscous wave equation. <em>CMA</em>, <em>200</em>, 145-166. (<a href='https://doi.org/10.1016/j.camwa.2025.09.021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a fully discrete scheme for the diffusion-viscous wave equation (DVWe) in the second-order formulation, combining hp -DG time-stepping schemes with conforming finite element methods (FEM). Two major theoretical contributions are presented: (1) hp -version a priori error estimates in both the energy-norm and DG-norm, which are optimal in the spatial mesh size h , temporal step size τ , and temporal polynomial order q , yet suboptimal by one order in the spatial polynomial order p . Furthermore, for solutions exhibiting weak singularities in time, exponential convergence in terms of the total number of temporal degrees of freedom is proven using the hp -refinement strategy. (2) An energy decay estimate that offers explicit bounds involving the model parameters, discretization parameters, and the Poincaré inequality constant. A series of numerical experiments are presented to validate the practical performance of the proposed approach.},
  archive      = {J_CMA},
  author       = {Min Zhang and Zhaonan Dong and Wenjing Yan},
  doi          = {10.1016/j.camwa.2025.09.021},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {145-166},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Hp-version discontinuous galerkin time-stepping schemes for diffusive-viscous wave equation},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation of unknown sources in a time fractional PDE by the optimal ones and their reconstruction. <em>CMA</em>, <em>200</em>, 117-144. (<a href='https://doi.org/10.1016/j.camwa.2025.09.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, our focus is on studying a geometric inverse source problem that is governed by two-dimensional time-fractional subdiffusion. The problem involves determining the shape and location of the unknown source's geometrical support from boundary measurements of its associated potential. Firstly, we prove the uniqueness of the inverse problem. In the second phase, we propose a novel reconstruction method that utilizes the coupled complex boundary method (CCBM) to solve the identification problem. The main idea of this method is to approximate the overdetermined problem to a complex boundary value problem with a complex Robin boundary condition coupling the Dirichlet and Neumann boundary conditions. Next, we utilize the imaginary part of the solution throughout the domain to construct a shape cost function, which we then minimize with respect to ball-shaped sources by using a Newton-type topological derivative method to reconstruct the geometrical support of the unknown source.},
  archive      = {J_CMA},
  author       = {Mourad Hrizi and Ravi Prakash and Antonio André Novotny},
  doi          = {10.1016/j.camwa.2025.09.020},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {117-144},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Approximation of unknown sources in a time fractional PDE by the optimal ones and their reconstruction},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An averaged l1 ADI compact difference scheme for the three-dimensional time-fractional mobile/immobile transport equation with weakly singular solutions. <em>CMA</em>, <em>200</em>, 102-116. (<a href='https://doi.org/10.1016/j.camwa.2025.09.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a three-dimensional (3D) time-fractional mobile/immobile (MIM) transport equation, which incorporates the Caputo time-fractional derivative of order α ∈ ( 0 , 1 ) , is taken into consideration. The space derivatives are discretized using the compact finite difference approximation, and the Caputo time-fractional derivative is estimated by employing the averaged L1 formula. Combining with corresponding alternating direction implicit (ADI) algorithms, the overall computational cost is reduced significantly. Using the discrete energy analysis methodology, we demonstrate that the suggested method possesses temporal second-order convergence and spatial fourth-order convergence under the regularity assumption. Numerical experiments demonstrate that ADI techniques is effective in computing 3D problems.},
  archive      = {J_CMA},
  author       = {Kai Liu and Haixiang Zhang and Xuehua Yang},
  doi          = {10.1016/j.camwa.2025.09.019},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {102-116},
  shortjournal = {Comput. Meth. Appl.},
  title        = {An averaged l1 ADI compact difference scheme for the three-dimensional time-fractional mobile/immobile transport equation with weakly singular solutions},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pricing american options with exogenous and endogenous transaction costs. <em>CMA</em>, <em>200</em>, 85-101. (<a href='https://doi.org/10.1016/j.camwa.2025.09.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an American option pricing problem with liquidity risks and transaction fees. As endogenous transaction costs, liquidity risks of the underlying asset are modeled by a mean-reverting process. Transaction fees are exogenous transaction costs and are assumed to be proportional to the trading amount, with the long-run liquidity level depending on the proportional transaction costs rate. Two nonlinear partial differential equations are established to characterize the option values for the holder and the writer, respectively. To illustrate the impact of these transaction costs on option prices and optimal exercise prices, we apply the alternating direction implicit method to solve the linear complementarity problem numerically. Finally, we conduct model calibration from market data via maximum likelihood estimation, and find that our model incorporating liquidity risks outperforms the Leland model significantly.},
  archive      = {J_CMA},
  author       = {Dong Yan and Xin-Jie Huang and Guiyuan Ma and Xin-Jiang He},
  doi          = {10.1016/j.camwa.2025.09.008},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {85-101},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Pricing american options with exogenous and endogenous transaction costs},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A space-time discontinuous petrov-galerkin finite element formulation for a modified schrödinger equation for laser pulse propagation in waveguides. <em>CMA</em>, <em>200</em>, 67-84. (<a href='https://doi.org/10.1016/j.camwa.2025.09.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a modified nonlinear Schrödinger equation for modeling pulse propagation in optical waveguides. The proposed model bifurcates into a system of elliptic and hyperbolic equations depending on waveguide parameters. The proposed model leads to a stable first-order system of equations, distinguishing itself from the canonical nonlinear Schrödinger equation. We have employed the space-time discontinuous Petrov-Galerkin finite element method to discretize the first-order system of equations. We present a stability analysis for both the elliptic and hyperbolic systems of equations and demonstrate the stability of the proposed model through several numerical examples on space-time meshes.},
  archive      = {J_CMA},
  author       = {A. Chakraborty and J. Muñoz-Matute and L. Demkowicz and J. Grosek},
  doi          = {10.1016/j.camwa.2025.09.004},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {67-84},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A space-time discontinuous petrov-galerkin finite element formulation for a modified schrödinger equation for laser pulse propagation in waveguides},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence analysis of an energy-stable linearized virtual element method for the strongly damped klein-gordon equation. <em>CMA</em>, <em>200</em>, 49-66. (<a href='https://doi.org/10.1016/j.camwa.2025.09.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and analyze an efficient, linearized, fully discrete scheme for the nonlinear, strongly damped Klein-Gordon equation on polygonal meshes. The numerical scheme uses a conforming virtual element method for spatial discretization and a modified leapfrog (central finite difference) scheme for time discretization, with the nonlinear term | u | p − 1 u is treated semi-implicitly. We first prove that the proposed scheme is energy dissipative in the sense of discrete energy, and then the stability of the numerical solution in the H 1 -norm is established using mathematical induction, which plays an important role in handling the nonlinear term. By applying the boundedness of the numerical solution and the Sobolev embedding inequality, we derive the optimal H 1 error estimate of order O ( h k + τ 2 ) without imposing any ratio restrictions between the time step τ and the mesh size h . Additionally, we remark that the leapfrog virtual element scheme can be applied to some more complex nonlinear damped wave equations. Finally, some numerical examples are provided to confirm the theoretical results.},
  archive      = {J_CMA},
  author       = {Zhixin Liu and Minghui Song and Yuhang Zhang},
  doi          = {10.1016/j.camwa.2025.09.002},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {49-66},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Convergence analysis of an energy-stable linearized virtual element method for the strongly damped klein-gordon equation},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A posteriori error estimate of the discontinuous galerkin method with lagrange multiplier for elliptic problems. <em>CMA</em>, <em>200</em>, 38-48. (<a href='https://doi.org/10.1016/j.camwa.2025.09.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to derive and analyze an a posteriori error estimator for the solution of the discontinuous Galerkin method with Lagrange multiplier (DGLM) for the elliptic problems with nonhomogeneous Dirichlet boundary condition u = g for g in H 1 / 2 ( ∂ Ω ) . A general version of the DGLM method is derived. Strong stability of the solution of the DGLM method is proved. Edgewise iterative scheme for the general DGLM method is described.},
  archive      = {J_CMA},
  author       = {Mi-Young Kim},
  doi          = {10.1016/j.camwa.2025.09.005},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {38-48},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A posteriori error estimate of the discontinuous galerkin method with lagrange multiplier for elliptic problems},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability and convergence analysis of mixed finite element approximations for a biot-brinkman model. <em>CMA</em>, <em>200</em>, 22-37. (<a href='https://doi.org/10.1016/j.camwa.2025.09.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many multiphysics processes of fluid-solid interaction within a porous medium can be described by the Biot-Brinkman model to account for the effects of viscosity in fluid flow. By introducing the auxiliary variables, we can transform the original problem into two generalized Stokes equations. The generalized Stokes equations incorporate a built-in mechanism to circumvent the Poisson locking for the continuous Galerkin method. Subsequently, we establish an energy law and provide a priori estimates for the reformulated problem. Well-posedness is demonstrated using the standard Galerkin method in conjunction with a compactness argument. After that, we develop stable mixed finite element algorithms for the reformulated problem. Influenced by Lamé constant λ , we design three finite element pairs for the proposed algorithms and present the corresponding error estimates. Numerical tests are conducted to validate the theoretical results.},
  archive      = {J_CMA},
  author       = {Wenlong He and Jiwei Zhang},
  doi          = {10.1016/j.camwa.2025.09.006},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {22-37},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Stability and convergence analysis of mixed finite element approximations for a biot-brinkman model},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed neural network for option pricing weather derivatives model. <em>CMA</em>, <em>200</em>, 1-21. (<a href='https://doi.org/10.1016/j.camwa.2025.09.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weather derivatives are financial tools that use a weather index as the underlying asset to provide protection against non-catastrophic weather events. In this article, we propose a physics-informed neural network (PINN) approach for pricing weather derivatives associated with two standard processes: the Ornstein-Uhlenbeck process and the Ornstein-Uhlenbeck process with jump-diffusions. PINNs are a scientific machine learning method specifically designed to address problems related to partial differential equations (PDEs). To apply the PINN technique for jump-diffusion, we convert the partial integro-differential equation into a PDE using integral discretization. We randomly select training data points within the domain and utilize the transformed PDE along with the initial and boundary conditions to construct the loss function. For the neurons in the hidden layer, we employ the hyperbolic tangent function (tanh) as the activation function. The weights of the network connection are optimized using the L-BFGS algorithm. We will conduct numerical experiments to evaluate the efficiency of the proposed technique. Additionally, we compare our method with conventional numerical approaches to show that our technique serves as an effective alternative to existing pricing methods for weather derivatives. Finally, we will examine a real-world case study where the model's parameters are determined using precipitation data.},
  archive      = {J_CMA},
  author       = {Saurabh Bansal and Pradanya Boro and Srinivasan Natesan},
  doi          = {10.1016/j.camwa.2025.09.001},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {1-21},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Physics-informed neural network for option pricing weather derivatives model},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cmame">CMAME - 13</h2>
<ul>
<li><details>
<summary>
(2026). GPU-accelerated multi-phase, multi-resolution SPH method with ray tracing for laser powder bed fusion. <em>CMAME</em>, <em>448</em>, 118423. (<a href='https://doi.org/10.1016/j.cma.2025.118423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powder-scale simulation of laser powder bed fusion (LPBF) is increasingly vital for understanding, predicting, and controlling metallurgical defects. However, the complex multi-physics and multi-material interactions involved, along with high computational demands, pose significant challenges. This study presents the first multiphase smoothed particle hydrodynamics (SPH) simulation framework for LPBF under both low and high evaporation regimes, incorporating a multi-resolution particle strategy and ray tracing (RT). An adaptive particle refinement (APR) method, compatible with multiphase SPH and optimized for GPU acceleration, is developed to enhance computational efficiency of the multiphase model. The RT model is also optimized and integrated with the APR-GPU architecture, further improving performance. A physics-based wetting force model is introduced, along with a novel method for improving normal vector accuracy near the contact line. The proposed framework is validated through three benchmark cases and applied to simulate LPBF processes. The results demonstrate that the framework achieves high accuracy and efficiency in resolving key LPBF phenomena, including melt pool dynamics and keyhole formation.},
  archive      = {J_CMAME},
  author       = {Yibo Ma and Zhilang Zhang and Christian Weißenfels and Minli Zhou and Lingxiao Ma and Xiaofei Tang and Moubin Liu},
  doi          = {10.1016/j.cma.2025.118423},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118423},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {GPU-accelerated multi-phase, multi-resolution SPH method with ray tracing for laser powder bed fusion},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sparse data assimilation for under-resolved large-eddy simulations. <em>CMAME</em>, <em>448</em>, 118421. (<a href='https://doi.org/10.1016/j.cma.2025.118421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for accurate and fast scale-resolving simulations of fluid flows, where turbulent dispersion is a crucial physical feature, is evident. Large-eddy simulations (LES) are computationally more affordable than direct numerical simulations, but their accuracy depends on sub-grid scale models and the quality of the computational mesh. In order to compensate related errors, a data assimilation approach for LES is devised in this work. The presented method is based on variational assimilation of sparse time-averaged velocity reference data. Working with the time-averaged LES momentum equation allows to employ a stationary discrete adjoint method. Therefore, a stationary corrective force in the unsteady LES momentum equation is iteratively updated within the gradient-based optimization framework in conjunction with the adjoint gradient. After data assimilation, corrected anisotropic Reynolds stresses are inferred from the stationary corrective force. Ultimately, this corrective force that acts on the mean velocity is replaced by a term that scales the velocity fluctuations through nudging of the corrected anisotropic Reynolds stresses. Efficacy of the proposed framework is demonstrated for turbulent flow over periodic hills and around a square cylinder. Coarse meshes are leveraged to further enhance the speed of the optimization procedure. Time- and spanwise-averaged velocity reference data from high-fidelity simulations is taken from the literature. Our results demonstrate that adjoint-based assimilation of averaged velocity enables the optimization of the mean flow, vortex shedding frequency (i. e., Strouhal number), and anisotropic Reynolds stresses. This highlights the superiority of scale-resolving simulations such as LES over simulations based on the (unsteady) Reynolds-averaged equations.},
  archive      = {J_CMAME},
  author       = {Justin Plogmann and Oliver Brenner and Patrick Jenny},
  doi          = {10.1016/j.cma.2025.118421},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118421},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Sparse data assimilation for under-resolved large-eddy simulations},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DGTO: Derivable geodesics-coupled topology optimization for multi-axis 3D printing of continuous fiber-reinforced spatial structures. <em>CMAME</em>, <em>448</em>, 118419. (<a href='https://doi.org/10.1016/j.cma.2025.118419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous fiber reinforced composites (CFRCs) are composite materials with exceptional mechanical properties to enhance structural mechanical performance. In comparison with traditional three-axis 3D printing (also referred to as 2.5D printing), multi-axis 3D printing simultaneously moves the nozzle and rotates the build platform during the printing process, making it particularly suited for fabricating spatial structures made of CFRCs due to better alignment between the fiber depositions and principal stress directions. In this research, we propose a Derivable Geodesics-coupled Topology Optimization (DGTO) method for design of CFRCs given the manufacturing scheme of multi-axis 3D printing. A prominent feature of DGTO is the introduction of two geodesic fields to achieve curved layer generation and continuous fiber path planning. The heat diffusion equation and Poisson equation are solved to produce the geodesic fields, and hence, all objective functions and constraints related to the slices and paths are derivable, making them perfectly suitable to be integrated with topology optimization. Hence, the proposed method concurrently optimizes the density field and the auxiliary geodesic fields, simultaneously tuning the material distribution and spatial fiber distribution, thereby attaining optimal performance while fulfilling the manufacturing constraints of multi-axis printing, i.e., self-support of structure and overlap/gap-free of continuous fibers. Four numerical examples are presented to demonstrate the effectiveness of the algorithm, especially showing outstanding performances than designs for traditional three-axis 3D printing.},
  archive      = {J_CMAME},
  author       = {Kaixian Liang and Jikai Liu and Shuzhi Xu and Yifan Guo},
  doi          = {10.1016/j.cma.2025.118419},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118419},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {DGTO: Derivable geodesics-coupled topology optimization for multi-axis 3D printing of continuous fiber-reinforced spatial structures},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Active evolutionary gaussian process for structural large-scale full-field reliability analysis and critical domain prognosis with only few initial samples. <em>CMAME</em>, <em>448</em>, 118418. (<a href='https://doi.org/10.1016/j.cma.2025.118418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability analysis is crucial for ensuring structural integrity, yet it requires repeated, time-consuming evaluations of responses and multivariate limit state functions, while struggling to provide full-field estimations efficiently. Therefore, we propose an active evolutionary reduced Gaussian Process framework ( AER-GP ) for fast and large-scale full-field reliability analysis and critical domain prognosis, utilizing only a few initial samples. In which we first define a novel probability indicator of erroneously evaluating the sign of the minimum of the full-field limit state function. Based on this, we then develop an efficient convergence criterion that relies on the expected error in failure probability estimates. Furthermore, we advance the dual order-reduced Gaussian process coupled Monte Carlo methods to accurately predict the large-scale full-field stochastic response under material and load uncertainty. Where the preliminary design of experiments starts from a significantly small number of sets (e.g.,5), and is progressively added by those samples containing the most information to distinguish the failure boundary. More importantly, we propose a novel mechanism for structural critical domain prognosis mechanism based on the failure probability of each single material point within the entire field, and make accurate critical domain prognosis. Real-world examples, including a car wheel hub and a single-tower cable-stayed bridge, demonstrate that the proposed algorithm achieves high prediction accuracy, computational efficiency, and robustness in large-scale structural reliability analysis and critical domain prognosis. It consistently outperforms widely used methods such as AK-MCS, EFF-MCS, ERF-MCS, and H-MCS. Notably, the proposed AER-GP method requires only a small number of initial DoE samples (fewer than 40), and through adaptive learning, it can reliably produce results with very low errors (typically less than 2%).},
  archive      = {J_CMAME},
  author       = {Xinlong Li and Chensen Ding},
  doi          = {10.1016/j.cma.2025.118418},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118418},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Active evolutionary gaussian process for structural large-scale full-field reliability analysis and critical domain prognosis with only few initial samples},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph neural network surrogates for contacting deformable bodies with necessary and sufficient contact detection. <em>CMAME</em>, <em>448</em>, 118413. (<a href='https://doi.org/10.1016/j.cma.2025.118413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate models for the rapid inference of nonlinear boundary value problems in mechanics are helpful in a broad range of engineering applications. However, effective surrogate modeling of applications involving the contact of deformable bodies, especially in the context of varying geometries, is still an open issue. In particular, existing methods are confined to rigid body contact or, at best, contact between rigid and soft objects with well-defined contact planes. Furthermore, they employ contact or collision detection filters that serve as a rapid test but use only the necessary and not sufficient conditions for detection. In this work, we present a graph neural network architecture that utilizes continuous collision detection and, for the first time, incorporates sufficient conditions designed for contact between soft deformable bodies. We test its performance on two benchmarks, including a problem in soft tissue mechanics of predicting the closed state of a bioprosthetic aortic valve. We find a regularizing effect on adding additional contact terms to the loss function, leading to better generalization of the network. These benefits hold for simple contact at similar planes and element normal angles, and complex contact at differing planes and element normal angles. We also demonstrate that the framework can handle varying reference geometries. However, such benefits come with high computational costs during training, resulting in a trade-off that may not always be favorable. We quantify the training cost and the resulting inference speedups on various hardware architectures. Importantly, our graph neural network implementation results in up to a hundred- to thousand-fold speedup on GPU, and twenty- to two hundred-fold speedup on CPU for our benchmark problems at inference.},
  archive      = {J_CMAME},
  author       = {Vijay K. Dubey and Collin E. Haese and Osman Gültekin and David Dalton and Manuel K. Rausch and Jan Fuhg},
  doi          = {10.1016/j.cma.2025.118413},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118413},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Graph neural network surrogates for contacting deformable bodies with necessary and sufficient contact detection},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum neural network-assisted topology optimization: Concept and implementation with parameterized quantum circuits. <em>CMAME</em>, <em>448</em>, 118411. (<a href='https://doi.org/10.1016/j.cma.2025.118411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a quantum machine learning-assisted approach to accelerating density-based topology optimization using quantum neural network (QNN), a class of trainable models based on parameterized quantum circuits (PQCs). The proposed framework extracts key features from classical data, starting by encoding the corresponding finite element analysis results, i.e., strain energy, sensitivity, and design variables from early design iterations obtained using the standard optimizer. Then, the PQCs are fine-tuned using minimization of the binary cross-entropy loss function, enabling the model to learn the mapping between input features and optimal design. Specifically, the framework consists of two main stages. First, an offline training stage where the QNN is calibrated using precomputed iterative results from a relatively coarse mesh obtained through the standard optimizer, establishing pattern recognition between input features and the final design variables. The second is an online stage where the trained QNN model is integrated with the standard optimizer to accelerate the final design. Numerical results show that QNN requires only a small number of qubits, and once trained on coarse meshes with several different boundary conditions, can effectively integrate with standard optimizers to predict target designs across various configurations, including different resolutions, volume constraints, and loading conditions. Furthermore, the proposed QNN-assisted framework significantly reduces computational time compared to standard iterative approaches, laying the groundwork for solving large-scale problems with near-term quantum computers.},
  archive      = {J_CMAME},
  author       = {Naruethep Sukulthanasorn and Kenjiro Terada},
  doi          = {10.1016/j.cma.2025.118411},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118411},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Quantum neural network-assisted topology optimization: Concept and implementation with parameterized quantum circuits},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generative emulation of chaotic dynamics with coherent prior. <em>CMAME</em>, <em>448</em>, 118410. (<a href='https://doi.org/10.1016/j.cma.2025.118410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven emulation of nonlinear dynamics is challenging due to long-range skill decay that often produces physically unrealistic outputs. Recent advances in generative modeling aim to address these issues by providing uncertainty quantification and correction. However, the quality of generated simulation remains heavily dependent on the choice of conditioning prior. In this work, we present an efficient generative framework for nonlinear dynamics emulation, connecting principles of turbulence with diffusion-based modeling: Cohesion. Our method estimates large-scale coherent structure of the underlying dynamics as guidance during the denoising process, where small-scale fluctuation in the flow is then resolved. These coherent prior are efficiently approximated using reduced-order models, such as deep Koopman operators, that allow for rapid generation of long prior sequences while maintaining stability over extended forecasting horizon. With this gain, we can reframe forecasting as trajectory planning, a common task in reinforcement learning, where conditional denoising is performed once over entire sequences, minimizing the computational cost of autoregressive-based generative methods. Numerical evaluations on chaotic systems of increasing complexity, including Kolmogorov flow, shallow water equations, and subseasonal-to-seasonal climate dynamics, demonstrate Cohesion superior long-range forecasting skill that can efficiently generate physically-consistent simulations, even in the presence of partially-observed guidance.},
  archive      = {J_CMAME},
  author       = {Juan Nathaniel and Pierre Gentine},
  doi          = {10.1016/j.cma.2025.118410},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118410},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Generative emulation of chaotic dynamics with coherent prior},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Concurrent 3D topology optimization method for hierarchical hybrid structures under static and dynamic loads with CPU-GPU heterogeneous parallelism. <em>CMAME</em>, <em>448</em>, 118408. (<a href='https://doi.org/10.1016/j.cma.2025.118408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology optimization of 3D hierarchical hybrid structures (HHS) is constrained by the coupling of high-dimensional design spaces and multiscale computational complexity, often addressed by restricting certain designable components, which limits the full exploration of the design space and realization of performance potential. This paper proposes a novel concurrent topology optimization method for 3D-HHS, achieving concurrent optimization of all designable components, including macroscopic topology, substructural topology, and their spatial distribution, under static and dynamic loads. This approach significantly expands the design space, enhancing the mechanical performance of hierarchical structures. To address the computational challenges of large-scale 3D problems, we employ CPU-GPU heterogeneous parallel computing to improve the efficiency of structural response and sensitivity analysis. Numerical examples demonstrate that this method delivers superior 3D-HHS designs with markedly improved optimization efficiency, providing an innovative solution for efficient 3D structural optimization.},
  archive      = {J_CMAME},
  author       = {Yunfei Liu and Ruxin Gao and Ying Li and Daining Fang},
  doi          = {10.1016/j.cma.2025.118408},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118408},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Concurrent 3D topology optimization method for hierarchical hybrid structures under static and dynamic loads with CPU-GPU heterogeneous parallelism},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Configuration-decoupled concurrent topology optimization of heterogeneous lattice structures. <em>CMAME</em>, <em>448</em>, 118405. (<a href='https://doi.org/10.1016/j.cma.2025.118405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-configuration lattice structures have recently been introduced into structural optimization due to their broadly tunable physical properties. Traditional methods for multi-configuration lattice optimization employ extreme strategies of complete fusion or separation, leading to a trade-off between optimality and scalability that has not been fully addressed in the existing literature. The paper suggests decomposing the lattice library into pairs of lattices, through which multi-configuration lattice optimization is decoupled into the concurrent optimization of iso-value, combination category, and ratio within combination. A novel hybrid interpolation scheme is proposed to describe the effective mechanical behavior of the configuration-decoupled lattices. In this approach, polynomial models are employed to characterize the performance of individual lattice combinations, while the Uniform Multiphase Materials Interpolation model is used to integrate the contributions of all combinations. Benchmark experiments, including full-scale simulations, are conducted to validate the effectiveness of the framework. The proposed method enables rapid convergence to configuration layouts that align with the principal stress orientations. Compared to single- and dual-configuration designs, it achieves compliance reductions of 61.0 % and 26.2 %, respectively, approaching the performance of density-based topology optimization. Extended numerical experiments reveal the joint influence of resolution and configuration count on the overall performance. This method achieves a better trade-off between optimality and extensibility, enabling more flexible utilization of large lattice databases in practical engineering fields.},
  archive      = {J_CMAME},
  author       = {Xinze Shen and Changdong Zhang and Wenhe Liao and Dawei Li and Tingting Liu},
  doi          = {10.1016/j.cma.2025.118405},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118405},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Configuration-decoupled concurrent topology optimization of heterogeneous lattice structures},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intrepid MCMC: Metropolis-hastings with exploration. <em>CMAME</em>, <em>448</em>, 118402. (<a href='https://doi.org/10.1016/j.cma.2025.118402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In engineering examples, one often encounters the need to sample from unnormalized distributions with complex shapes that may also be implicitly defined through a physical or numerical simulation model, making it computationally expensive to evaluate the associated density function. For such cases, MCMC has proven to be an invaluable tool. Random-walk Metropolis Methods (also known as Metropolis-Hastings (MH)), in particular, are highly popular for their simplicity, flexibility, and ease of implementation. However, most MH algorithms suffer from significant limitations when attempting to sample from distributions with multiple modes (particularly disconnected ones). In this paper, we present Intrepid MCMC - a novel MH scheme that utilizes a simple coordinate transformation to significantly improve the mode-finding ability and convergence rate to the target distribution of random-walk Markov chains while retaining most of the simplicity of the vanilla MH paradigm. Through multiple examples, we showcase the improvement in the performance of Intrepid MCMC over vanilla MH for a wide variety of target distribution shapes. We also provide an analysis of the mixing behavior of the Intrepid Markov chain, as well as the efficiency of our algorithm for increasing dimensions. A thorough discussion is presented on the practical implementation of the Intrepid MCMC algorithm. Finally, its utility is highlighted through a Bayesian parameter inference problem for a two-degree-of-freedom oscillator under free vibration.},
  archive      = {J_CMAME},
  author       = {Promit Chakroborty and Michael D. Shields},
  doi          = {10.1016/j.cma.2025.118402},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118402},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Intrepid MCMC: Metropolis-hastings with exploration},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-level overlapping additive schwarz preconditioner for training scientific machine learning applications. <em>CMAME</em>, <em>448</em>, 118400. (<a href='https://doi.org/10.1016/j.cma.2025.118400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel two-level overlapping additive Schwarz preconditioner for accelerating the training of scientific machine learning applications. The design of the proposed preconditioner is motivated by the nonlinear two-level overlapping additive Schwarz preconditioner. The neural network parameters are decomposed into groups (subdomains) with overlapping regions. In addition, the network’s feed-forward structure is indirectly imposed through a novel subdomain-wise synchronization strategy and a coarse-level training step. Through a series of numerical experiments, which consider physics-informed neural networks and operator learning approaches, we demonstrate that the proposed two-level preconditioner significantly speeds up the convergence of the standard (LBFGS) optimizer while also yielding more accurate machine learning models. Moreover, the devised preconditioner is designed to take advantage of model-parallel computations, which can further reduce the training time.},
  archive      = {J_CMAME},
  author       = {Youngkyu Lee and Alena Kopaničáková and George Em Karniadakis},
  doi          = {10.1016/j.cma.2025.118400},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118400},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Two-level overlapping additive schwarz preconditioner for training scientific machine learning applications},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overlapping schwarz preconditioners for isogeometric discretizations of acoustic wave problems. <em>CMAME</em>, <em>448</em>, 118397. (<a href='https://doi.org/10.1016/j.cma.2025.118397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this work is to construct and analyze two-level overlapping additive Schwarz (OAS) preconditioners for isogeometric discretizations of the acoustic wave equation with absorbing boundary conditions. Both Collocation and Galerkin isogeometric methods are employed for space discretization, while time advancing is performed by means of a Newmark implicit scheme. The linear systems to be solved at each time step are ill conditioned, especially in case of highly regular splines, thus their solution requires the use of effective preconditioners. Two-level OAS solvers consist of partitioning the domain into overlapping subdomains, solving independent local problems on each subdomain and an additional coarse problem associated with the subdomain mesh. Several two-dimensional numerical results validate our theoretical estimates, showing the scalability and quasi-optimality of the algorithms proposed. We also investigate numerically the robustness of the OAS preconditioners with respect to the spline polynomial degree, the spline regularity and the overlap parameter.},
  archive      = {J_CMAME},
  author       = {Elena Zampieri and Simone Scacchi and Luca F. Pavarino},
  doi          = {10.1016/j.cma.2025.118397},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118397},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Overlapping schwarz preconditioners for isogeometric discretizations of acoustic wave problems},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Latent space modeling of parametric and time-dependent PDEs using neural ODEs. <em>CMAME</em>, <em>448</em>, 118394. (<a href='https://doi.org/10.1016/j.cma.2025.118394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Differential Equations (PDEs) are central to science and engineering. Since solving them is computationally expensive, a lot of effort has been put into approximating their solution operator via both traditional and recently increasingly Deep Learning (DL) techniques. In this paper, we propose an autoregressive and data-driven method using the analogy with classical numerical solvers for time-dependent, parametric and (typically) nonlinear PDEs. We present how Dimensionality Reduction (DR) can be coupled with Neural Ordinary Differential Equations (NODEs) in order to learn the solution operator of arbitrary PDEs accounting both for (continuous) time and parameter dependency. The idea of our work is that it is possible to map the high-fidelity (i.e., high-dimensional) PDE solution space into a reduced (low-dimensional) space, which subsequently exhibits dynamics governed by a (latent) Ordinary Differential Equation (ODE). Solving this (easier) ODE in the reduced space allows avoiding solving the PDE in the high-dimensional solution space, thus decreasing the computational burden for repeated calculations for e.g., uncertainty quantification or design optimization purposes. The main outcome of this work is the importance of exploiting DR as opposed to the recent trend of building large and complex architectures: we show that by leveraging DR we can deliver not only more accurate predictions, but also a considerably lighter and faster DL model compared to existing methodologies.},
  archive      = {J_CMAME},
  author       = {Alessandro Longhi and Danny Lathouwers and Zoltán Perkó},
  doi          = {10.1016/j.cma.2025.118394},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {1},
  pages        = {118394},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Latent space modeling of parametric and time-dependent PDEs using neural ODEs},
  volume       = {448},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="comcom">COMCOM - 5</h2>
<ul>
<li><details>
<summary>
(2025). Revisiting the problem of optimizing spreading factor allocations in LoRaWAN: From theory to practice. <em>COMCOM</em>, <em>243</em>, 108321. (<a href='https://doi.org/10.1016/j.comcom.2025.108321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper revisits the problem of optimizing LoRa network success probability by proposing an optimized allocation strategy for Spreading Factors (SFs) under both uniform and Gaussian network deployments with a single or multiple gateways. More specifically, we solve the problem of finding the best SF allocations in dense network deployments whose EDs are first assigned with the minimum SF. Theoretical models are developed to quantify the success probability of transmissions, considering the capture effect as well as intra- and inter-SF interference. A mathematical optimization framework is introduced to determine the optimal SF distribution that maximizes the average probability of packet reception. The problem is solved using Mixed Integer Linear Programming (MILP), and then evaluated using simulations. Even though optimal SF allocation strategies have been proposed in the literature, no practical insights have been discovered and no real-world deployments have been considered. To this extent, the practical benefits of using improved or optimal SF settings are discovered in this paper. Simulation results confirm the theoretical findings while they demonstrate an up to 10 percentage points improvements in Packet Reception Ratio (PRR) in the real-world use-case.},
  archive      = {J_COMCOM},
  author       = {Dimitrios Zorbas and Aruzhan Sabyrbek and Luigi Di Puglia Pugliese},
  doi          = {10.1016/j.comcom.2025.108321},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108321},
  shortjournal = {Comput. Commun.},
  title        = {Revisiting the problem of optimizing spreading factor allocations in LoRaWAN: From theory to practice},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy consumption optimization in UAV-assisted multi-layer mobile edge computing with active transmissive RIS. <em>COMCOM</em>, <em>243</em>, 108320. (<a href='https://doi.org/10.1016/j.comcom.2025.108320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV)-assisted edge computing provides low-latency and low-energy consumption computing capabilities for sparsely distributed Internet of Things (IoT) networks. In addition, the assisted UAVs provide line-of-sight links to further improve communication quality. However, the existing offloading strategies have low efficiency and high costs. Motivated by this, we propose a novel UAV-assisted multi-layer mobile edge computing network with active transmissive reconfigurable intelligent surface (RIS). The introduced an active transmissive RIS not only receives data from UAVs but also performs computing functionality. We establish an optimization to minimize the total system energy consumption under delay constraints by jointly planning UAV positions and allocating computing bits, sub-carriers, time slots, transmission power, and RIS transmission coefficient. To tackle this problem, we first use the block coordinate descent (BCD) algorithm to decouple it into four sub-problems. Then, we solve them by adopting successive convex approximation (SCA), difference-convex (DC) programming, and introducing slack variables. Experimental results demonstrate that the proposed network is superior to the other five baselines concerning energy consumption reduction. Also, the influences of system parameters are verified, including the number of IoT devices, the number of RIS elements, and the delay threshold.},
  archive      = {J_COMCOM},
  author       = {Kexin Yang and Yaxi Liu and Boxin He and Jiahao Huo and Wei Huangfu},
  doi          = {10.1016/j.comcom.2025.108320},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108320},
  shortjournal = {Comput. Commun.},
  title        = {Energy consumption optimization in UAV-assisted multi-layer mobile edge computing with active transmissive RIS},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A preemptive task unloading scheme based on second optional unloading in cloud-fog collaborative networks. <em>COMCOM</em>, <em>243</em>, 108315. (<a href='https://doi.org/10.1016/j.comcom.2025.108315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-distance data transmission between Internet of Things (IoT) devices and remote cloud center often leads to unacceptable latency for certain tasks. Fog computing has emerged as a promising solution for low-latency tasks. Consequently, the concept of cloud-fog collaborative networks has garnered significant attention. However, existing research primarily focuses on heterogeneous tasks, overlooking the crucial aspect of considering both task priority and second unloading. To address this gap, this paper proposes a novel task unloading scheme that concurrently takes preemptive priority and second optional unloading into account. In this scheme, delay-sensitive tasks (DSTs) are given preemptive priority over delay-tolerant tasks (DTTs). Furthermore, some DTTs may undergo preprocessing in the fog layer to optimize resource utilization. Moreover, tasks encountering blocking or preemption in the fog layer can also be secondarily unloaded to the cloud layer. In this framework, we devise a four-dimensional Markov chain (4DMC) to model and analyze this process. Through numerical experiments, we assess performance indicators under various parameters. Ultimately, our proposed strategy is compared with the unloading scheme that does not incorporate second unloading through both numerical analysis and simulation validation. The results indicate that our scheme notably enhances the throughput of DTTs, albeit at a marginal performance trade-off.},
  archive      = {J_COMCOM},
  author       = {Yuan Zhao and Hongmin Gao and Shuaihua Liu},
  doi          = {10.1016/j.comcom.2025.108315},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108315},
  shortjournal = {Comput. Commun.},
  title        = {A preemptive task unloading scheme based on second optional unloading in cloud-fog collaborative networks},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ScaleIP: A hybrid autoscaling of VoIP services based on deep reinforcement learning. <em>COMCOM</em>, <em>243</em>, 108314. (<a href='https://doi.org/10.1016/j.comcom.2025.108314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive resource provisioning has become crucial for cloud-based applications, especially those managing real-time traffic like Voice over IP (VoIP), which experience rapidly fluctuating workloads. Traditional static provisioning methods often fall short in these dynamic environments, leading to inefficiencies and potential service disruptions. Existing solutions struggle to maintain performance under varying traffic conditions, particularly for time-sensitive applications. This paper introduces ScaleIP, a hybrid autoscaling solution for containerized VoIP services that offers real-time adaptability and efficient resource management. ScaleIP leverages Deep Reinforcement Learning to make dynamic and efficient scaling decisions, improving call latency, increasing the number of successfully routed calls, and maximizing resource utilization. We evaluated ScaleIP through extensive experiments conducted on a real testbed utilizing the customer Call Detail Record (CDR) from 2023 provided by World Direct, encompassing over 89 million calls. The results show that ScaleIP consistently maintains call latency below 2 s, increases the number of successfully routed calls by 3.26 ×, and increases the resource utilization up to 60 % compared to state-of-the-art autoscaling methods.},
  archive      = {J_COMCOM},
  author       = {Zahra Najafabadi Samani and Juan Aznar Poveda and Dominik Gratz and Rene Hueber and Philipp Kalb and Thomas Fahringer},
  doi          = {10.1016/j.comcom.2025.108314},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108314},
  shortjournal = {Comput. Commun.},
  title        = {ScaleIP: A hybrid autoscaling of VoIP services based on deep reinforcement learning},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond performance comparing the costs of applying deep and shallow learning. <em>COMCOM</em>, <em>243</em>, 108312. (<a href='https://doi.org/10.1016/j.comcom.2025.108312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of mobile network traffic and the emergence of complex applications, such as self-driving cars and augmented reality, demand ultra-low latency, high throughput, and massive device connectivity, which traditional network design approaches struggle to meet. These issues were initially addressed in Fifth-Generation (5G) and Beyond-5G (B5G) networks, where Artificial Intelligence (AI), particularly Deep Learning (DL), is proposed to optimize the network and to meet these demanding requirements. However, the resource constraints and time limitations inherent in telecommunication networks raise questions about the practicality of deploying large Deep Neural Networks (DNNs) in these contexts. This paper analyzes the costs of implementing DNNs by comparing them with shallow ML models across multiple datasets and evaluating factors such as execution time and model interpretability. Our findings demonstrate that shallow ML models offer comparable performance to DNNs, with significantly reduced training and inference times, achieving up to 90% acceleration. Moreover, shallow models are more interpretable, as explainability metrics struggle to agree on feature importance values even for high-performing DNNs.},
  archive      = {J_COMCOM},
  author       = {Rafael Teixeira and Leonardo Almeida and Pedro Rodrigues and Mário Antunes and Diogo Gomes and Rui L. Aguiar},
  doi          = {10.1016/j.comcom.2025.108312},
  journal      = {Computer Communications},
  month        = {11},
  pages        = {108312},
  shortjournal = {Comput. Commun.},
  title        = {Beyond performance comparing the costs of applying deep and shallow learning},
  volume       = {243},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cor">COR - 25</h2>
<ul>
<li><details>
<summary>
(2026). A novel mathematical model for the scheduling of a zero inventory production: An application of process scheduling in fog computing. <em>COR</em>, <em>185</em>, 107284. (<a href='https://doi.org/10.1016/j.cor.2025.107284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main production-related costs in manufacturing is inventory cost since manufacturing firms allocate a vast area to raw material, semi-processed, and final products in production lines and warehouses. Reducing the volume of these inventories leads to lower production-related costs. This paper presents a novel mathematical model for zero-inventory production scheduling. In this model, the jobs arrive at fixed times and are scheduled on a set of unrelated machines. The jobs have different operations that need to be processed one by one. Since the system has zero inventory, the jobs must be processed immediately upon arrival. Also, whenever a job’s operation is complete, the following operation must instantly start (no wait time). That operation is outsourced if no machines are available to process any of the job’s operations. The jobs’ operations are dispatched to the machines from a dispatching center, and there is a latency between the dispatching center, the machines, and the outsourcing center. We present a mixed-integer non-linear programming (MINLP) model to formulate this problem. Then, the MINLP model is turned into a mixed-integer linear programming (MILP) model by linearizing its constraints. Since many production scheduling problems are known to be NP-hard, particularly those involving unrelated parallel machines, precedence constraints, and time-dependent decisions like ours, we adopt two metaheuristics to solve the problem for large-scale cases where exact methods are computationally inefficient. The first is a Genetic Algorithm (GA), and the second is a Teaching-Learning-Based Optimization (TLBO) algorithm. The performance of these algorithms is tested against the optimal solutions obtained from CPLEX for a set of small-scale problems. We consider a real case study, an image processing system, to validate the proposed developments (the MILP model and the GA). The results show that the presented model and algorithm can reduce the system’s total cost by about 12.57% compared to the existing online dispatching rules.},
  archive      = {J_COR},
  author       = {Mani Sharifi and Sharareh Taghipour and Abdolreza Abhari and Maciej Rysz},
  doi          = {10.1016/j.cor.2025.107284},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107284},
  shortjournal = {Comput. Oper. Res.},
  title        = {A novel mathematical model for the scheduling of a zero inventory production: An application of process scheduling in fog computing},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified approach to extract interpretable rules from tree ensembles via integer programming. <em>COR</em>, <em>185</em>, 107283. (<a href='https://doi.org/10.1016/j.cor.2025.107283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree ensembles are widely used machine learning models, known for their effectiveness in supervised classification and regression tasks. Their performance derives from aggregating predictions of multiple decision trees, which are renowned for their interpretability properties. However, tree ensemble models do not reliably exhibit interpretable output. Our work aims to extract an optimized list of rules from a trained tree ensemble, providing the user with a condensed, interpretable model that retains most of the predictive power of the full model. Our approach consists of solving a set partitioning problem formulated through Integer Programming. The extracted list of rules is unweighted and defines a partition of the training data, assigning each instance to exactly one rule, and thereby simplifying the explanation process. The proposed method works with tabular or time series data, for both classification and regression tasks, and its flexible formulation can include any arbitrary loss or regularization functions. Our computational experiments offer statistically significant evidence that our method performs comparably to several rule extraction methods in terms of predictive performance and fidelity towards the tree ensemble. Moreover, we empirically show that the proposed method effectively extracts interpretable rules from tree ensembles that are designed for time series data.},
  archive      = {J_COR},
  author       = {Lorenzo Bonasera and Emilio Carrizosa},
  doi          = {10.1016/j.cor.2025.107283},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107283},
  shortjournal = {Comput. Oper. Res.},
  title        = {A unified approach to extract interpretable rules from tree ensembles via integer programming},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing high-tech product take-back schemes in a closed-loop supply chain. <em>COR</em>, <em>185</em>, 107282. (<a href='https://doi.org/10.1016/j.cor.2025.107282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent product development is a solution to the shortened product lifecycles in the consumer electronics industry. It enables companies to maintain competitiveness and strengthen their market share. However, environmental concerns bring reverse logistics practices into focus. A take-back policy is a strategic reverse logistics activity known to foster market share; however, it poses various challenges and uncertainties. Considering uncertain demand, we introduced an innovative adoption model with two distinct take-back policies, trade-in and credit, to address challenges in multi-generation production planning. Inspired by real-world practices of companies like Apple and Samsung, our model first examines how trade-in programs drive repeat purchases and enhance market share, with credit-based programs to attract new customers. It then captures changes in demand, production planning, recovery decisions, and internal competition among multiple product generations. Distinct from previous conclusions, this study explores how producers can strategically manage demand for new generations to slow diffusion, thereby increasing refurbishment and recycling volumes over time. Our findings highlight the pivotal role of adaptive pricing strategies and production scalability in maximizing profitability and promoting sustainability in competitive high-tech industries.},
  archive      = {J_COR},
  author       = {Fatemeh Keshavarz-Ghorbani and Mohamad Y. Jaber and Seyed Hamid Reza Pasandideh},
  doi          = {10.1016/j.cor.2025.107282},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107282},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing high-tech product take-back schemes in a closed-loop supply chain},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Q-learning-based hyper-heuristic algorithm for open dimension irregular packing problems. <em>COR</em>, <em>185</em>, 107279. (<a href='https://doi.org/10.1016/j.cor.2025.107279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic methods provide a computationally efficient framework for addressing two-dimensional irregular packing problems, particularly in resource-constrained industrial settings. As a typical combinatorial optimization problem, irregular packing exhibits exponential growth in computational complexity with increasing workpiece counts, while the solution space dynamically reconfigures due to geometric variability among workpieces. Although heuristic algorithms can generate feasible layouts within acceptable timeframes, their reliance on fixed search rule limits adaptability to diverse scenarios, necessitating more flexible approaches. In this paper, a hyper-heuristic algorithm based on Q-Learning is proposed to solve open dimension packing problems, including one-open and two-open dimension problems. Q-Learning is adopted as the high-level strategy for its ability to optimize low-level heuristic selection through reward-driven experience accumulation. The method incorporates a mixed encoding method for solution representation, four specialized low-level heuristic operators, a linear population decline mechanism, and an elite preservation strategy to balance exploration–exploitation. The Q-Learning controller dynamically selects operators by updating the Q-table based on Bellman’s equation. The proposed algorithm is compared to some advanced algorithms in general datasets. The results show that our method has better performance and applicability.},
  archive      = {J_COR},
  author       = {Yongchun Wang and Qingjin Peng and Zhen Wang and Shuiquan Huang and Zhengkai Xu and Chuanzhen Huang and Baosu Guo},
  doi          = {10.1016/j.cor.2025.107279},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107279},
  shortjournal = {Comput. Oper. Res.},
  title        = {Q-learning-based hyper-heuristic algorithm for open dimension irregular packing problems},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid modelling using simulation and machine learning in healthcare. <em>COR</em>, <em>185</em>, 107278. (<a href='https://doi.org/10.1016/j.cor.2025.107278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling & Simulation (M&S) and Machine Learning (ML) methodologies have undergone significant advancements, enabling transformative applications across various industries. The integration of M&S and ML into a Hybrid M&S-ML approach leverages the unique strengths of both fields, offering enhanced model precision, improved efficiency, and more effective decision support. This review explores the increasing convergence of ML algorithms with traditional M&S methods- namely Agent-Based Modelling & Simulation, Discrete Event Simulation, and System Dynamics- in healthcare applications. Through a systematic review of 90 relevant studies, this article provides a comprehensive synthesis of the current state-of-the-art Hybrid M&S-ML in healthcare. Specifically, it examines the M&S and ML methodologies employed, associated software tools and programming languages, analyses integration patterns and data exchange mechanisms, and explores application domains, as well as the types and motivations for hybridisation. Key findings highlight prominent methodological and technical trends, as well as opportunities for combining M&S with ML to address healthcare challenges. These insights provide direction for modellers and data scientists in developing hybrid M&S–ML approaches that more effectively combine simulation capabilities with data-driven learning. The review also demonstrates the potential of such approaches to advance methodological innovation and support evidence-based decision-making in diverse healthcare contexts.},
  archive      = {J_COR},
  author       = {Ali Ahmadi and Masoud Fakhimi and Carin Magnusson},
  doi          = {10.1016/j.cor.2025.107278},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107278},
  shortjournal = {Comput. Oper. Res.},
  title        = {Hybrid modelling using simulation and machine learning in healthcare},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A note on battery swapping policies in the electric vehicle routing problem with time windows and battery swapping vehicles. <em>COR</em>, <em>185</em>, 107277. (<a href='https://doi.org/10.1016/j.cor.2025.107277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Çatay and Sadati [An improved matheuristic for solving the electric vehicle routing problem with time windows and synchronized mobile charging/battery swapping. Computers & Operations Research 159, 106310, 2023] explores a variant of the Electric Vehicle Routing Problem with Time Windows that incorporates mobile chargers for recharging electric vehicles (EVs) at selected locations while serving customers. The authors propose a matheuristic method to address this problem and its special case, where EV batteries are swapped in constant time instead of being recharged over variable durations. While comparing their results with those in the literature, the authors overlook a critical assumption regarding the swapping policy, potentially causing confusion in interpreting the findings. This note addresses the issue, clarifies the overlooked assumption, and updates the results that do not align with the actual scenario in the literature. Furthermore, it introduces two new battery swapping policies and presents an extensive computational study to offer new insights on synchronized mobile battery swapping.},
  archive      = {J_COR},
  author       = {Bülent Çatay and İhsan Sadati},
  doi          = {10.1016/j.cor.2025.107277},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107277},
  shortjournal = {Comput. Oper. Res.},
  title        = {A note on battery swapping policies in the electric vehicle routing problem with time windows and battery swapping vehicles},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive K-means and reinforcement learning (RL) algorithm to effective vaccine distribution. <em>COR</em>, <em>185</em>, 107275. (<a href='https://doi.org/10.1016/j.cor.2025.107275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new adaptive reinforcement learning (RL) approach, integrated with a K-means clustering algorithm and guided by simulated annealing, to address the capacitated vehicle routing for vaccine distribution (CVRVD) problem. This integrated method provides an efficient and scalable solution for optimizing vaccine distribution logistics. By incorporating cost factors related to travel distance, inventory levels, and penalty terms – while adhering to delivery time windows – our approach improves both operational efficiency and vaccine allocation effectiveness. Experimental results demonstrate that our K-means supported RL algorithm significantly outperforms traditional solvers in tackling this NP-hard problem, particularly in large-scale scenarios. Specifically, our approach can efficiently solve CVRVD instances with up to 1,000 facilities—scenarios that are computationally intractable for exact methods. We demonstrate the effectiveness of the adaptive K-means supported RL algorithm using data from New Jersey, USA, where facility-level vaccination data were available through the state’s Immunization Information System. Beyond vaccine distribution, our method has broad applicability in logistics and transportation, enabling more efficient and cost-effective allocation of critical resources such as vaccines and medical supplies.},
  archive      = {J_COR},
  author       = {Elson Cibaku and İ. Esra Büyüktahtakın},
  doi          = {10.1016/j.cor.2025.107275},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107275},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive K-means and reinforcement learning (RL) algorithm to effective vaccine distribution},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A Q-learning-based evolutionary algorithm for solving the low-carbon multi-objective flexible job shop scheduling problem. <em>COR</em>, <em>185</em>, 107266. (<a href='https://doi.org/10.1016/j.cor.2025.107266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, how to reduce energy consumption at the manufacturing system level in the low-carbon multi-objective flexible job shop scheduling problem (LCM-FJSP) has received significant attention. In this research, a model with the maximum completion time, total machine workload and total carbon emissions is built. Moreover, a Q-learning-based adaptive weight-adjusted decomposition evolutionary algorithm (QMOEA/D-AWA) is proposed. In the QMOEA/D-AWA, an initialization strategy with four heuristic initial rules for obtaining high-quality population, a variable neighborhood search strategy with four problem-specific local search methods for enhancing exploration and a Q-learning-based parameter adaptive strategy for automatically determining the number of neighborhood solutions are designed. To validate the effectiveness of the proposed QMOEA/D-AWA, it is compared with five state-of-the-art algorithms on 15 instances. In the statistical analysis, the QMOEA/D-AWA obtains the overwhelming metric results in 10 instances. In the visual analysis, the completion time is reduced by 3.74%, the total workload is reduced by 3.94%, and the carbon emissions are reduced by 5.94%.},
  archive      = {J_COR},
  author       = {Zhixue Wang and Maowei He and Hanning Chen and Yabao Hu and Yelin Xia},
  doi          = {10.1016/j.cor.2025.107266},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107266},
  shortjournal = {Comput. Oper. Res.},
  title        = {A Q-learning-based evolutionary algorithm for solving the low-carbon multi-objective flexible job shop scheduling problem},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A benders-branch-and-cut methodology for global cargo vessel traffic prediction given declining arctic sea ice and changing risks. <em>COR</em>, <em>185</em>, 107265. (<a href='https://doi.org/10.1016/j.cor.2025.107265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global warming has led to declining sea-ice in the Arctic Ocean, making it easier for ice-class vessels to navigate Arctic waters for greater portions of the year. As sailing conditions in these waters improve over coming decades, these passageways are expected to open for larger portions of the year and to become increasingly viable options for unsupported transit and even open-water vessels. This paper proposes a Benders-branch-and-cut methodology for estimating changes in global maritime cargo flow patterns under future climate scenarios with declining Arctic sea ice. The model accounts for changing incident risk along Arctic passageways and corresponding ice-class vessel and icebreaker escort requirements, lower speeds, increased insurance premiums, higher accident probabilities, and constraints on path-based maximum risk exposure. The resulting mixed-integer program involves path-based, continuous decision variables. The solution technique is applied on a model of the global maritime container network including 80 ports, 76 routes, 426 links and 4,303 legs associated with the world’s largest carrier alliance. Embedded acceleration techniques and a label-correcting algorithm that employs specialized fathoming rules for a non-additive, constrained path subproblem enable solution at this global scale. The outcome is an estimate of seasonal future global maritime trade flows along key global routes and through ports predicted under six climate-related scenarios. Results illustrate that the developed model can provide support to companies, nations and regions as they prepare for a changing global landscape and climate.},
  archive      = {J_COR},
  author       = {Wenjie Li and Elise Miller-Hooks},
  doi          = {10.1016/j.cor.2025.107265},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107265},
  shortjournal = {Comput. Oper. Res.},
  title        = {A benders-branch-and-cut methodology for global cargo vessel traffic prediction given declining arctic sea ice and changing risks},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning approach for dynamic job-shop scheduling problem considering time variable and new job arrivals. <em>COR</em>, <em>185</em>, 107263. (<a href='https://doi.org/10.1016/j.cor.2025.107263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the complexity of the production process due to increased demand for customization has greatly increased the difficulty of dynamic job-shop scheduling problem (DJSP). This paper proposes a deep reinforcement learning (DRL) approach to tackle the DJSP based on proximal policy optimization (PPO) algorithm. A novel state representation method that expresses state features as multi-channel images is proposed to simplify the state characterization process. Various heuristic-based priority dispatching rules (PDRs)are used to construct action space. By converting scheduling instances into images and leveraging the spatial pyramid pooling fast (SPPF) module for feature extraction, this model can handle scheduling instances of varying scales and map size-independent processing information matrix to fixed action space. Additionally, a dense reward based on a predefined scheduling region is developed to offer detailed guidance to the agent, enabling more precise and comprehensive policy assessment. Static tests are conducted on well-known benchmarks, and the experimental results indicate that our scheduling model surpasses the performance of the three latest DRL approaches on average. Compared with PDR methods, dynamic experiments demonstrate that the proposed DRL model excels in adaptability and robustness when new tasks arrive and the processing time fluctuates with uncertainty.},
  archive      = {J_COR},
  author       = {Haoyang Yu and Wenbin Gu and Na Tang and Zhenyang Guo},
  doi          = {10.1016/j.cor.2025.107263},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107263},
  shortjournal = {Comput. Oper. Res.},
  title        = {A deep reinforcement learning approach for dynamic job-shop scheduling problem considering time variable and new job arrivals},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient resource utilization and scheduling strategy for in-service aircraft maintenance and operations. <em>COR</em>, <em>185</em>, 107262. (<a href='https://doi.org/10.1016/j.cor.2025.107262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal scheduling of maintenance activities requires the solution of combinatorial optimization problems that need to be efficiently modeled and solved with optimization techniques. Maintenance scheduling and operations-associated problems in the aviation industry can efficiently enhance competitiveness. In the maintenance and scheduling problem, aircrafts need to undergo tasks for both line (A check) and base (C check) maintenance at various hangers at MRO (Maintenance, Repair and Operations) based on resource availability (both human and material). The determination of the optimal maintenance plan, in terms of allocating the resources to the aircraft, and resource movement from one aircraft to another based on availability and licensed skills in the presence of multiple tasks and capacity constraints so as to obtain maximum utilization of resources at maintenance site and minimize the turnaround time is a complex combinatorial optimization problem. To the best of our knowledge, this work is the first CP (Constraint Programming) based mathematical solution that jointly integrates zone, task precedence, technician-pool sharing, and multi-shift continuity for large-scale aircraft maintenance scheduling. In this article, we proposed an efficient optimization strategy that overcomes many of the drawbacks of the formulation/strategies available in literature and helps in determining efficient execution of maintenance work packages. The proposed strategy is generic, encompassing multi-aircraft, multi-skill and multi-shift scheduling capabilities and is validated on two real scenario business case studies, one each for line maintenance (A check) tasks and base maintenance (C check) tasks, as well as six large-scale synthetic scenarios with up to 20,000 tasks, demonstrating feasibility and scalable performance. The proposed strategy is demonstrated on MRO scheduling and it shows an improvement of up to 30.68% in the turn-around time by incorporating the proposed optimization strategy.},
  archive      = {J_COR},
  author       = {Sandeep Singh Chauhan and Likhith Maadhav and Abhijit Dake and Gauthier Brillaud},
  doi          = {10.1016/j.cor.2025.107262},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107262},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient resource utilization and scheduling strategy for in-service aircraft maintenance and operations},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven optimization approach for the integrated train scheduling and maintenance planning in high-speed railways. <em>COR</em>, <em>185</em>, 107261. (<a href='https://doi.org/10.1016/j.cor.2025.107261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In railway systems, preventive maintenance plans are essential for ensuring the safety of train operations. However, these tasks are often subject to various disturbances (e.g., bad weather), leading to unpredictable deviations between planned and actual maintenance durations, which can further disrupt train schedules. Unlike most studies that assume constant maintenance durations, this paper introduces a data-driven, two-stage distributionally robust optimization (DRO) model for jointly optimizing train scheduling and maintenance planning. In the first stage, we determine the initial train schedule and maintenance plan. In the second stage, we allow for slight adjustments to train departure and arrival times at each station to accommodate disturbances affecting maintenance tasks. Our objective is to minimize both the expected travel time of trains and the deviation from the planned schedule under worst-case scenarios for maintenance disturbances. To capture the uncertainty of maintenance disturbances, we construct an ambiguity set using historical data and the Wasserstein metric. We show that the proposed two-stage DRO model, formulated over the Wasserstein ambiguity set, can be reformulated into an efficiently solvable equivalent form. Finally, we apply our model to a real-world case study of the Beijing–Guangzhou high-speed railway and compare it with traditional stochastic programming methods, including sample average approximation and robust optimization. The results highlight the efficiency of our approach and provide valuable insights for railway management.},
  archive      = {J_COR},
  author       = {Hangyu Ji and Chuntian Zhang and Jiateng Yin and Lixing Yang},
  doi          = {10.1016/j.cor.2025.107261},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107261},
  shortjournal = {Comput. Oper. Res.},
  title        = {A data-driven optimization approach for the integrated train scheduling and maintenance planning in high-speed railways},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ROBIST: Robust optimization by iterative scenario sampling and statistical testing. <em>COR</em>, <em>185</em>, 107260. (<a href='https://doi.org/10.1016/j.cor.2025.107260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose ROBIST , a simple, yet effective, data-driven algorithm for optimization under parametric uncertainty. The algorithm first generates solutions in an iterative manner by sampling and optimizing over a relatively small set of scenarios. Then, using statistical testing, the robustness of the solutions is evaluated, which can be done with a much larger set of scenarios. ROBIST offers a number of practical advantages over existing methods as it is: (i) easy to implement, (ii) able to deal with a wide range of problems and (iii) capable of providing sharp probability guarantees that are easily computable and independent of the dimensions of the problem. Numerical experiments demonstrate the effectiveness of ROBIST in comparison to alternative methods.},
  archive      = {J_COR},
  author       = {Justin Starreveld and Guanyu Jin and Dick den Hertog and Roger J.A. Laeven},
  doi          = {10.1016/j.cor.2025.107260},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107260},
  shortjournal = {Comput. Oper. Res.},
  title        = {ROBIST: Robust optimization by iterative scenario sampling and statistical testing},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A branch-and-price algorithm for energy aware task scheduling of constellations of nanosatellites. <em>COR</em>, <em>185</em>, 107259. (<a href='https://doi.org/10.1016/j.cor.2025.107259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-price algorithm for solving the Optimal Network Task Scheduling (ONTS) problem in satellite constellations. The algorithm efficiently manages both constellation tasks that can be performed by any satellite and satellite-specific tasks that must be executed by designated satellites, while considering critical energy constraints. We formulate the problem as a Mixed-Integer Linear Programming (MILP) model and develop a Dantzig–Wolfe decomposition that handles battery management constraints for the satellites at the master level, while addressing constellation-wide coordination requirements in the subproblems. A novel dynamic programming algorithm is proposed to solve the pricing subproblem for constellation tasks, augmented with dual stabilization techniques to improve convergence. Comprehensive computational experiments on realistic instances derived from nanosatellite operations demonstrate the effectiveness of the algorithm. Results show that our structured formulation significantly outperforms a naive approach, particularly for large instances, while effectively balancing workload distribution and energy management across the constellation. This work provides a practical framework for optimizing task scheduling in modern satellite constellations, with direct applications in Earth observation, telecommunications, and scientific missions.},
  archive      = {J_COR},
  author       = {Pedro Marcolin Antunes and Laio Oriel Seman and Eduardo Camponogara},
  doi          = {10.1016/j.cor.2025.107259},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107259},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-price algorithm for energy aware task scheduling of constellations of nanosatellites},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A branch-and-cut algorithm for the pallet-loading vehicle routing problem considering load balance of semi-trailer trucks. <em>COR</em>, <em>185</em>, 107258. (<a href='https://doi.org/10.1016/j.cor.2025.107258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work presented in this paper is motivated by some practical applications, introducing and solving a new problem called the split delivery vehicle routing problem with time windows and two-dimensional loading constraints considering load balance (2L-SDVRPTW-LB). This problem expands the integrated routing and loading problem, in which the required pallet orders are delivered to customers by a fleet of homogeneous semi-trailer trucks. Firstly, with the goal to minimize the total transportation cost, a mixed-integer linear programming model for the 2L-SDVRPTW-LB is proposed. Secondly, an exact algorithm framework based on the branch-and-cut algorithm is designed to solve the problem. In the algorithm framework, a metaheuristic algorithm is designed to obtain the upper bound. Subsequently, various classes of valid inequalities are introduced to strengthen the formulation, while the constraints ensuring load balance are applied in a lazy manner to optimize computational efficiency. Numerical experiments based on modified benchmark instances demonstrate that the proposed branch-and-cut algorithm effectively solves the 2L-SDVRPTW-LB and its variant of excluding split delivery. This study provides valuable insights for addressing the pallet-loading vehicle routing problem considering load balance of semi-trailer trucks.},
  archive      = {J_COR},
  author       = {Xiangbin Xu and Haoxing Ouyang},
  doi          = {10.1016/j.cor.2025.107258},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107258},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-cut algorithm for the pallet-loading vehicle routing problem considering load balance of semi-trailer trucks},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid memetic metaheuristic for medical staff assignment in major public health emergencies. <em>COR</em>, <em>185</em>, 107256. (<a href='https://doi.org/10.1016/j.cor.2025.107256'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During major public health emergencies, effective assignment of medical staff is crucial for saving lives and controlling the spread of epidemics. This work focuses on the assignment of doctors and nurses to hospitals to form treatment groups that carry out patient treatment tasks. We consider the practical constraints of skill types of medical staff and the severity of patients’ conditions and propose a mixed integer programming model with the objective of maximizing demand satisfaction and personnel skill matching. To solve this problem, we introduce a hybrid memetic search algorithm that combines a specialized crossover operator for generating promising offspring solutions and a variable neighborhood search procedure to improve their quality. Computational results demonstrate that our algorithm outperforms the general mixed integer programming solver GUROBI . The key components of the proposed algorithm are experimentally analyzed and managerial insights are derived.},
  archive      = {J_COR},
  author       = {Yang Wang and He Zheng and Zequn Wei and Christophe Wilbaut and Saïd Hanafi},
  doi          = {10.1016/j.cor.2025.107256},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107256},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid memetic metaheuristic for medical staff assignment in major public health emergencies},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-guided iterated local search for the minmax multiple traveling salesman problem. <em>COR</em>, <em>185</em>, 107255. (<a href='https://doi.org/10.1016/j.cor.2025.107255'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minmax multiple traveling salesman problem involves minimizing the costs of a longest tour among a set of tours. The problem is of great practical interest because it can be used to formulate several real-life applications. To solve this computationally challenging problem, we propose a learning-driven iterated local search approach that combines an effective local search procedure to find high-quality local optimal solutions and a multi-armed bandit algorithm to select removal and insertion operators to escape local optimal traps. Extensive experiments on 77 commonly used benchmark instances show that the algorithm achieves excellent results in terms of solution quality and running time. In particular, it achieves 32 new best results (improved upper bounds) and matches the best-known results for 35 other instances. Additional experiments shed light on the understanding of the algorithm’s constituent elements. Multi-armed bandit selection can be used advantageously in other multi-operator local search algorithms.},
  archive      = {J_COR},
  author       = {Pengfei He and Jin-Kao Hao and Jinhui Xia},
  doi          = {10.1016/j.cor.2025.107255},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107255},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning-guided iterated local search for the minmax multiple traveling salesman problem},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Grouping strategies on two-phase methods for bi-objective combinatorial optimization. <em>COR</em>, <em>185</em>, 107254. (<a href='https://doi.org/10.1016/j.cor.2025.107254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-phase methods are commonly used to solve bi-objective combinatorial optimization problems. In the first phase, all extreme supported nondominated points are generated through a dichotomic search. This phase also allows the identification of search zones that may contain other nondominated points. The second phase focuses on exploring these search zones to locate the remaining points, which typically accounts for most of the computational cost. Ranking algorithms are frequently employed to explore each zone individually, but this approach leads to redundancies, causing multiple visits to the same solutions. To mitigate these redundancies, we propose several strategies that group adjacent zones, allowing a single run of the ranking algorithm for the entire group. Additionally, we explore an implicit grouping approach based on a new concept of coverage. Our experiments on the Bi-Objective Spanning Tree Problem demonstrate the beneficial impact of these grouping strategies when combined with coverage.},
  archive      = {J_COR},
  author       = {Felipe O. Mota and Luís Paquete and Daniel Vanderpooten},
  doi          = {10.1016/j.cor.2025.107254},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107254},
  shortjournal = {Comput. Oper. Res.},
  title        = {Grouping strategies on two-phase methods for bi-objective combinatorial optimization},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Drone-aided mobile blood collection problem: A rolling-horizon-based matheuristic. <em>COR</em>, <em>185</em>, 107253. (<a href='https://doi.org/10.1016/j.cor.2025.107253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the drone-aided mobile blood collection problem, which integrates mobile blood donation vehicles with drones to improve operations related to the blood collection in urban areas. Each vehicle, carrying multiple drones, travels to several collection sites to conduct blood collection operations within a working day. Drones fly between vehicles to pick up collected blood bags and deliver them to the blood center. This collaborative framework enhances the performances of the collection system and ensures the freshness of collected blood upon arrival to the blood center. We develop a novel mixed-integer linear programming model to optimally synchronize the routes and collection schedules of mobile units and drones to ensure the timely delivery of collected blood to the blood center. We also develop a rolling-horizon-based matheuristic to solve large-scale instances of the problem. This algorithm combines a rolling horizon approach, which divides the problem into manageable subproblems solved sequentially, with a local branching technique that enhances solutions by exploring promising neighborhoods. To evaluate the algorithm’s performance, we conduct a comprehensive computational study. Our results show that the proposed algorithm not only finds better solutions than those obtained by Gurobi but also outperforms other matheuristics, including the rolling horizon, relax-and-fix, and fix-and-optimize algorithms. Finally, we demonstrate the real-life applicability of the problem through a case study in Quebec City, Canada.},
  archive      = {J_COR},
  author       = {Amirhossein Abbaszadeh and Hossein Hashemi Doulabi},
  doi          = {10.1016/j.cor.2025.107253},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107253},
  shortjournal = {Comput. Oper. Res.},
  title        = {Drone-aided mobile blood collection problem: A rolling-horizon-based matheuristic},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fair and efficient multi-agent routing for cooperative and autonomous agricultural fleets with implements. <em>COR</em>, <em>185</em>, 107252. (<a href='https://doi.org/10.1016/j.cor.2025.107252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing use of autonomous tractor fleets with detachable implements presents complex logistical challenges in agriculture. Current systems often rely on simple heuristics and avoid implement swapping, limiting efficiency. A central challenge is to dynamically coordinate vehicle routing and implement exchanges to enable efficient, low-intervention task execution. Due to high costs, such fleets are owned mainly by large enterprises or cooperatives, where fair task allocation and profit sharing are critical. Addressing both coordination and fairness, in this paper, we introduce the Agricultural Fleet Vehicle Routing Problem with Implements (AFVRPI). We propose a distributed model derived from a centralized formulation also presented in this paper. This model is embedded within a Distributed Multi-Agent System Architecture (DIMASA), where autonomous vehicle agents manage routing and implement use under limited fuel autonomy, while implement agents ensure compatibility and sufficient capacity to meet task demands. Our solution applies systematic egalitarian social welfare optimization to iteratively maximize the profit of the worst-off vehicle, balancing fairness with system efficiency. To enhance scalability, we use column generation in the distributed model, achieving solution quality comparable to the centralized model while significantly reducing computing time. Simulation results on new benchmark instances demonstrate that our distributed multi-agent AFVRPI approach is scalable, efficient, and fair.},
  archive      = {J_COR},
  author       = {Aitor López-Sánchez and Marin Lujak and Frédéric Semet and Holger Billhardt},
  doi          = {10.1016/j.cor.2025.107252},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107252},
  shortjournal = {Comput. Oper. Res.},
  title        = {Fair and efficient multi-agent routing for cooperative and autonomous agricultural fleets with implements},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flexible scheduling of customized bus for green mega-events: A distributionally robust optimization approach. <em>COR</em>, <em>185</em>, 107249. (<a href='https://doi.org/10.1016/j.cor.2025.107249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mega-events such as the Olympics and the World Championships face significant challenges in evacuating large numbers of attendees after the events conclude, which consume substantial transportation resources. Under the global pressure to reduce carbon emissions, energy conservation and emission reduction are increasingly becoming top priorities. This paper focuses on the efficient scheduling of customized buses (CB) after green mega-events, incorporating skip-stop operations and coordinated bus services to minimize energy consumption, fixed and transportation costs, and facilitate the evacuation of attendees, while accounting for practical constraints such as the availability of customized buses, vehicle capacity, time windows, and flow balance. A distributionally robust optimization (DRO) model is developed, using a novel ambiguity set to model uncertain demand via parametric interval-valued fuzzy variables. To ensure computational tractability, the model is reformulated as an integer linear programming model. To address the computational challenges of large-scale instances, an improved variable neighborhood search heuristic is designed by incorporating the reinforcement learning techniques, including the KL-UCB algorithm and a sliding window mechanism. Extensive numerical experiments are conducted to verify the performance of the proposed heuristic. Computational results demonstrate that the proposed DRO model effectively handles uncertainty, offering robust and adaptable solutions. Compared to existing heuristics, the proposed heuristic improves performance by 6.51% on average, and incorporating reinforcement learning into VNS enhances computational efficiency by 4.88% on average. A real-life case study further validates the model, demonstrating that the skip-stop strategy significantly reduces vehicle travel time and enhances overall operational efficiency.},
  archive      = {J_COR},
  author       = {Xiaojie An and Xiang Li and Bowen Zhang},
  doi          = {10.1016/j.cor.2025.107249},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107249},
  shortjournal = {Comput. Oper. Res.},
  title        = {Flexible scheduling of customized bus for green mega-events: A distributionally robust optimization approach},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal planning of power distribution networks with fault-tolerant configuration. <em>COR</em>, <em>185</em>, 107248. (<a href='https://doi.org/10.1016/j.cor.2025.107248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power Distribution networks are essential infrastructures that should be designed by satisfying two conflicting requests: cost minimization and reliability. While traditional network planning aimed at radial configurations, which are more similar to the typical working configuration of a network but are not fault-tolerant, modern techniques seek for meshed configurations, since these architectures are more fault-tolerant. Due to the complexity of the problem and the large size of nowadays instances, most of the techniques used for planning are based on heuristic approaches. Thus, they are usually unable to guarantee optimality and not even able to provide an assessment of the distance from the optimal solution. In this work, we address the challenge of planning a fault tolerant network through an exact approach, by introducing innovative Mixed-Integer Linear Programming models designed for the planning of meshed distribution networks with loop-feeder or open-loop topology. Differently from other techniques, our approach simplifies the formulation by avoiding the need for fault scenarios, significantly reducing the computational burden of the optimization problem. The outcomes of our approach are the generation of optimal meshed network, which effectively balance cost and reliability of the electric distribution system. Comprehensive studies on realistic test instances show the advantages of the proposed formulations.},
  archive      = {J_COR},
  author       = {Renato Bruni and Alberto Geri and Marco Maccioni and Ludovico Nati},
  doi          = {10.1016/j.cor.2025.107248},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107248},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal planning of power distribution networks with fault-tolerant configuration},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Centrality measures and opinion dynamics in two-layer networks with replica nodes. <em>COR</em>, <em>185</em>, 107245. (<a href='https://doi.org/10.1016/j.cor.2025.107245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two fast and accurate algorithms to approximate game-theoretic centrality measures and examine connection between centrality measures, network properties, and key performance indicators (consensus time and winning rate) of opinion dynamic processes on such networks. As an example, we consider a Zachary’s karate club as a social network and extend it by adding the second (internal) layer of communication. The internal layer represents the network where individuals can share their real opinions with the close friends. The structures of the external and internal layers may be different. The significant positive correlation between internal graph density and consensus time, and significant negative correlation between centrality of authoritative nodes and consensus time are found. The proposed algorithms are verified by a series of experiments from two aspects: the accuracy and the efficiency. The algorithms are novel and can be considered as a contribution to the network theory independently of opinion dynamics as they can be used to calculate node centrality in any weighted graph.},
  archive      = {J_COR},
  author       = {Chi Zhao and Elena Parilina},
  doi          = {10.1016/j.cor.2025.107245},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107245},
  shortjournal = {Comput. Oper. Res.},
  title        = {Centrality measures and opinion dynamics in two-layer networks with replica nodes},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI automatic decision in newsvendor model with nash bargaining fairness concern. <em>COR</em>, <em>185</em>, 107227. (<a href='https://doi.org/10.1016/j.cor.2025.107227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of artificial intelligence (AI) automatic ordering and producing decisions on fairness-concerned supply chains under the newsvendor model. We develop a dyadic supply chain model in which the manufacturer acts as the Stackelberg leader while the retailer serves as the follower in a push supply chain. In contrast, their roles are switched in a pull supply chain. We assume that only human decision-making leads to decision regret behavior, whereas AI-automated decision-making does not. Without adopting AI, our results show that fairness concern does not necessarily lead to a decreasing quantity in ordering or producing, which is different from most previous studies. Different from the prior findings, our work reveals that in binding equilibrium, if fairness concerns are considered, the order quantity will decrease, while in non-binding equilibrium, the order quantity may not necessarily be less than the previous results. Interestingly, when decision regret bias is considered for fairness-concerned decision-makers, we can obtain quantity coordination solutions for supply chains under specific conditions. With adopting AI, our results show that increasing fairness concerns are beneficial for improving the follower’s profit while at the expense of sacrificing the leader’s profit margins, while the leader can only benefit from AI adoption when the decision regret bias of the follower is relatively high. It is noteworthy that under certain conditions, AI automation may negatively impact the profits of both push and pull decentralized supply chains. For instance, in low-margin profit scenarios where decision-makers exhibit moderate regret bias and fairness concerns, such effects can emerge. This indicates that under specific circumstances, the human behavioral factors — regret bias and fairness concerns — may sometimes enhance the performance of decentralized supply chain members. Our research findings provide significant practical implications for the adoption of AI-automated decision-making in real-world supply chains.},
  archive      = {J_COR},
  author       = {Rui Hou and Yishen Cen and Jianxin Chen},
  doi          = {10.1016/j.cor.2025.107227},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107227},
  shortjournal = {Comput. Oper. Res.},
  title        = {AI automatic decision in newsvendor model with nash bargaining fairness concern},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Green horizons: Sustainable global logistics in dynamic supply chain management. <em>COR</em>, <em>185</em>, 107226. (<a href='https://doi.org/10.1016/j.cor.2025.107226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain management in a global scale involves addressing numerous uncertainties, from demand fluctuations to unforeseen disruptions. Developing advanced solution approaches is critical to manage such complexities and ensure resilience. This study presents a multi-stage stochastic–dynamic model for the global supply chain, incorporating hedging policies. The aim is to identify optimal order scheduling for bill of materials, production planning, and inventory management across warehouses (i.e., materials and finished products). Due to the dynamic nature of the global supply chain (e.g., demand fluctuations, disruptions, and lead time), a multi-stage stochastic model is developed for the stochastic–dynamic supply chain network. To address dynamic factors of real-world global supply chain, an accelerated parallel stochastic dual dynamic integer programming (SDDiP) approach is proposed to deal with disruptions (e.g., political unrest, natural disasters, and pandemics), enhancing supply chain resiliency. To validate the proposed parallel SDDiP , various scenarios with different sizes are generated using the case study and compared to the SDDiP with Benders cuts and integrated stage-wise Lagrangian dual cut ( SWLDC ) (i.e., SDDiP-SWLDC ). According to the obtained results, the proposed parallel node strategy for accelerated SDDiP consistently outperforms the basic stochastic dual dynamic programming (SDDP) and demonstrated robust CPU scalability. Evaluation across various scenario sizes shows stochastic dual dynamic integer programming-mixed integer rounding cuts ( SDDiP-MIR ) achieving faster computation and a smaller 7% optimality gap compared to SDDiP-SWLDC and SDDiP in large-size instances, highlighting its superior performance in complex supply chain settings.},
  archive      = {J_COR},
  author       = {Mahsa Mohammadi and Babak Mohamadpour Tosarkani},
  doi          = {10.1016/j.cor.2025.107226},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107226},
  shortjournal = {Comput. Oper. Res.},
  title        = {Green horizons: Sustainable global logistics in dynamic supply chain management},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="csda">CSDA - 8</h2>
<ul>
<li><details>
<summary>
(2026). Fast and efficient causal inference in large-scale data via subsampling and projection calibration. <em>CSDA</em>, <em>214</em>, 108281. (<a href='https://doi.org/10.1016/j.csda.2025.108281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the average treatment effect in large-scale datasets faces significant computational and storage challenges. Subsampling has emerged as a critical strategy to mitigate these issues. This paper proposes a novel subsampling method that builds on the G-estimation method offering the double robustness property. The proposed method uses a small subset of data to estimate computationally complex nuisance parameters, while leveraging the full dataset for the computationally simple final estimation. To ensure that the resulting estimator remains first-order insensitive to variations in nuisance parameters, a projection approach is introduced to optimize the estimation of the outcome regression function and treatment regression function such that the Neyman orthogonality conditions are satisfied. It is shown that the resulting estimator is asymptotically normal and achieves the same convergence rate as the full data-based estimator when either the treatment or the outcome models is correctly specified. Additionally, when both models are correctly specified, the proposed estimator achieves the same asymptotic variance as the full data-based estimator. The finite sample performance of the proposed method is demonstrated through simulation studies and an application to birth data, comprising over 30 million observations collected over the past eight years. Numerical results indicate that the proposed estimator is nearly as computationally efficient as the uniform subsampling estimator, while achieving similar estimation efficiency to the full data-based G-estimator.},
  archive      = {J_CSDA},
  author       = {Miaomiao Su},
  doi          = {10.1016/j.csda.2025.108281},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108281},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Fast and efficient causal inference in large-scale data via subsampling and projection calibration},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An algorithm for estimating threshold boundary regression models. <em>CSDA</em>, <em>214</em>, 108274. (<a href='https://doi.org/10.1016/j.csda.2025.108274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an innovative iterative two-stage algorithm designed for estimating threshold boundary regression (TBR) models. By transforming the non-differentiable least-squares (LS) problem inherent in fitting TBR models into an optimization framework, our algorithm combines the optimization of a weighted classification error function for the threshold model with obtaining LS estimators for regression models. To improve the efficiency and flexibility of TBR model estimation, we integrate the weighted support vector machine (WSVM) as a surrogate method for solving the weighted classification problem. The TBR-WSVM algorithm offers several key advantages over recently developed methods: it eliminates pre-specification requirements for threshold parameters, accommodates flexible estimation of nonlinear threshold boundaries, and streamlines the estimation process. We conducted several simulation studies to illustrate the finite-sample performance of TBR-WSVM. Finally, we demonstrate the practical applicability of the TBR model through a real data analysis.},
  archive      = {J_CSDA},
  author       = {Chih-Hao Chang and Takeshi Emura and Shih-Feng Huang},
  doi          = {10.1016/j.csda.2025.108274},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108274},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {An algorithm for estimating threshold boundary regression models},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rate accelerated inference for integrals of multivariate random functions. <em>CSDA</em>, <em>214</em>, 108273. (<a href='https://doi.org/10.1016/j.csda.2025.108273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of integrals is a fundamental task in the analysis of functional data, where the data are typically considered as random elements in a space of squared integrable functions. Effective unbiased estimation and inference procedures are proposed for integrals of uni- and multivariate random functions. Applications to key problems in functional data analysis involving random design points are examined and illustrated. In the absence of noise, the proposed estimates converge faster than the sample mean and standard numerical integration algorithms. The estimator also supports effective inference by generally providing better coverage with shorter confidence and prediction intervals in both noisy and noiseless settings.},
  archive      = {J_CSDA},
  author       = {Valentin Patilea and Sunny G․ W․ Wang},
  doi          = {10.1016/j.csda.2025.108273},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108273},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Rate accelerated inference for integrals of multivariate random functions},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust selection of the number of change-points via FDR control. <em>CSDA</em>, <em>214</em>, 108272. (<a href='https://doi.org/10.1016/j.csda.2025.108272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust quantification of uncertainty regarding the number of change-points presents a significant challenge in data analysis, particularly when employing false discovery rate (FDR) control techniques. Emphasizing the detection of genuine signals while controlling false positives is crucial, especially for identifying shifts in location parameters within flexible distributions. Traditional parametric methods often exhibit sensitivity to outliers and heavy-tailed data. Addressing this limitation, a robust method accommodating diverse data structures is proposed. The approach constructs component-wise sign-based statistics. Leveraging the global symmetry inherent in these statistics enables the derivation of data-driven thresholds suitable for multiple testing scenarios. Method development occurs within the framework of U-statistics, which naturally encompasses existing cumulative sum-based procedures. Theoretical guarantees establish FDR control for the component-wise sign-based method under mild assumptions. Demonstrations of effectiveness utilize simulations with synthetic data and analyses of real data.},
  archive      = {J_CSDA},
  author       = {Hui Chen and Chengde Qian and Qin Zhou},
  doi          = {10.1016/j.csda.2025.108272},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108272},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Robust selection of the number of change-points via FDR control},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Kernel density estimation with a markov chain monte carlo sample. <em>CSDA</em>, <em>214</em>, 108271. (<a href='https://doi.org/10.1016/j.csda.2025.108271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference relies on the posterior distribution, which is often estimated with a Markov chain Monte Carlo sampler. The sampler produces a dependent stream of variates from the limiting distribution of the Markov chain, the posterior distribution. When one wishes to display the estimated posterior density, a natural choice is the histogram. However, abundant literature has shown that the kernel density estimator is more accurate than the histogram in terms of mean integrated squared error for an i.i.d. sample. With this as motivation, a kernel density estimation method is proposed that is appropriate for the dependence in the Markov chain Monte Carlo output. To account for the dependence, the cross-validation criterion is modified to select the bandwidth in standard kernel density estimation approaches. A data-driven adjustment to the biased cross-validation method is suggested with introducing the integrated autocorrelation time of the kernel. The convergence of the modified bandwidth to the optimal bandwidth is shown by adapting theorems from the time series literature. Simulation studies show that the proposed method finds the bandwidth close to the optimal value, while standard methods lead to smaller bandwidths under Markov chain samples and hence to undersmoothed density estimates. A study with real data shows that the proposed method has a considerably smaller integrated mean squared error than standard methods. The R package KDEmcmc to implement the suggested algorithm is available on the Comprehensive R Archive Network.},
  archive      = {J_CSDA},
  author       = {Hang J. Kim and Steven N. MacEachern and Young Min Kim and Yoonsuh Jung},
  doi          = {10.1016/j.csda.2025.108271},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108271},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Kernel density estimation with a markov chain monte carlo sample},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Measure selection for functional linear model. <em>CSDA</em>, <em>214</em>, 108270. (<a href='https://doi.org/10.1016/j.csda.2025.108270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in modern science have led to an increased prevalence of functional data, which are usually viewed as elements of the space of square-integrable functions L 2 . Core methods in functional data analysis, such as functional principal component analysis, are typically grounded in the Hilbert structure of L 2 and rely on inner products based on integrals with respect to the Lebesgue measure over a fixed domain. A more flexible framework is proposed, where the measure can be arbitrary, allowing natural extensions to unbounded domains and prompting the question of optimal measure choice. Specifically, a novel functional linear model is introduced that incorporates a data-adaptive choice of the measure that defines the space, alongside an enhanced function principal component analysis. Selecting a good measure can improve the model’s predictive performance, especially when the underlying processes are not well-represented when adopting the default Lebesgue measure. Simulations, as well as applications to COVID-19 data and the National Health and Nutrition Examination Survey data, show that the proposed approach consistently outperforms the conventional functional linear model.},
  archive      = {J_CSDA},
  author       = {Su I Iao and Hans-Georg Müller},
  doi          = {10.1016/j.csda.2025.108270},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108270},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Measure selection for functional linear model},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of normal-reference tests for high-dimensional means with implementation in the r package ‘HDNRA’. <em>CSDA</em>, <em>214</em>, 108269. (<a href='https://doi.org/10.1016/j.csda.2025.108269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of testing for equal mean vectors in high-dimensional data poses significant difficulties in statistical inference. Much of the existing literature introduces methods that often rely on stringent regularity conditions for the underlying covariance matrices, enabling asymptotic normality of test statistics. However, this can lead to complications in controlling test size. To address these issues, a new set of tests has emerged, leveraging the normal-reference approach to improve reliability. The latest normal-reference methods for testing equality of mean vectors in high-dimensional samples, potentially with differing covariance structures, are reviewed. The theoretical underpinnings of these tests are revisited, providing a new unified justification for the validity of centralized L 2 -norm-based normal-reference tests (NRTs) by deriving the convergence rate of the distance between the null distribution of the test statistic and its corresponding normal-reference distribution. To facilitate practical application, an R package, HDNRA , is introduced, implementing these NRTs and extending beyond the two-sample problem to accommodate general linear hypothesis testing (GLHT). The package, designed with user-friendliness in mind, achieves efficient computation through a core implemented in C++ using Rcpp , OpenMP , and RcppArmadillo . Examples with real datasets are included, showcasing the application of various tests and providing insights into their practical utility.},
  archive      = {J_CSDA},
  author       = {Pengfei Wang and Tianming Zhu and Jin-Ting Zhang},
  doi          = {10.1016/j.csda.2025.108269},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108269},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Overview of normal-reference tests for high-dimensional means with implementation in the r package ‘HDNRA’},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional subgroup functional quantile regression with panel and dependent data. <em>CSDA</em>, <em>214</em>, 108268. (<a href='https://doi.org/10.1016/j.csda.2025.108268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional additive functional partial linear single-index quantile regression with high-dimensional parameters under subgroup panel data is investigated. Based on spline-based approach, we construct oracle estimators of the unknown parameter and functions, and discuss their consistency with rates and asymptotic normality under α -mixing assumptions. A penalized estimation method by using the SCAD technique is introduced to estimate the additive functions and parameter, enabling variable selection and automatic identification of the number of groups. Hypothesis testing for the parameter is also considered, and the asymptotic distributions of the restricted estimators and the test statistic are derived under both the null and local alternative hypotheses. Simulation studies and real data analysis are conducted to verify the validity of the proposed methods and applications.},
  archive      = {J_CSDA},
  author       = {Xiao-Ge Yu and Han-Ying Liang},
  doi          = {10.1016/j.csda.2025.108268},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108268},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {High-dimensional subgroup functional quantile regression with panel and dependent data},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cviu">CVIU - 10</h2>
<ul>
<li><details>
<summary>
(2025). KD-mamba: Selective state space models with knowledge distillation for trajectory prediction. <em>CVIU</em>, <em>261</em>, 104499. (<a href='https://doi.org/10.1016/j.cviu.2025.104499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction is a key component of intelligent mobility systems and human–robot interaction. The inherently stochastic nature of human behavior, coupled with external environmental influences, poses significant challenges for long-term prediction. However, existing approaches struggle to effectively model spatial interactions and accurately predict long-term destinations, while their high computational demands limit real-world applicability. To address these limitations, this paper presents KD-Mamba, the Selective State Space Models with Knowledge Distillation for trajectory prediction. The model incorporates the U-CMamba module, which features a U-shaped encoder–decoder architecture. By integrating convolutional neural networks (CNN) with the Mamba mechanism, this module effectively captures local spatial interactions and global contextual information of human motion patterns. Subsequently, we introduce a Bi-Mamba module, which captures long-term dependencies in human movement, ensuring a more accurate representation of trajectory dynamics. Knowledge distillation strengthens both modules by facilitating knowledge transfer across diverse scenarios. Compared to transformer-based approaches, KD-Mamba reduces computational complexity from quadratic to linear. Extensive experimental results from two real-world trajectory datasets indicate that KD-Mamba outperforms the existing mainstream baselines. The proposed method provides insights into the application of trajectory prediction in human-in-the-loop assistive systems.},
  archive      = {J_CVIU},
  author       = {Shaokang Cheng and Sourav Das and Shiru Qu and Lamberto Ballan},
  doi          = {10.1016/j.cviu.2025.104499},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104499},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {KD-mamba: Selective state space models with knowledge distillation for trajectory prediction},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage attribute-guided dual attention network for fine-grained fashion retrieval. <em>CVIU</em>, <em>261</em>, 104497. (<a href='https://doi.org/10.1016/j.cviu.2025.104497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained clothing retrieval is essential for intelligent shopping and personalized recommendation systems. However, conventional methods often fail to capture subtle attribute variations. This paper proposes a novel two-stage attribute-guided dual attention network. The network combines global and local feature extraction with Attribute-aware Multi-Scale Spatial Attention (AMSA) and Attribute-guided Dynamic Channel Attention (ADCA). AMSA captures attribute-specific spatial details at multiple scales, while ADCA dynamically adjusts channel importance based on attribute embeddings, enabling precise attribute-level similarity modeling. A multi-level joint loss function further optimizes both global and local representations and enhances feature alignment. Experiments on FashionAI and the self-built FGDress dataset show that the proposed method achieves mAP scores of 66.01% and 73.98%, respectively, outperforming baseline approaches. Attribute-level analysis confirms robust recognition of both well-defined and challenging attributes. These results validate the practicality and generalizability of the proposed framework, with promising applications in personalized recommendation, fashion trend analysis, and design evaluation.},
  archive      = {J_CVIU},
  author       = {Bo Pan and Jun Xiang and Ning Zhang and Ruru Pan},
  doi          = {10.1016/j.cviu.2025.104497},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104497},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Two-stage attribute-guided dual attention network for fine-grained fashion retrieval},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JSF: A joint spatial-frequency domain network for low-light image enhancement. <em>CVIU</em>, <em>261</em>, 104496. (<a href='https://doi.org/10.1016/j.cviu.2025.104496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enhancement of low-light images remains a prominent focus in the field of image processing. The degree of lightness significantly influences vision-based intelligent recognition and analysis. Departing from conventional methods, this paper proposes an innovative joint spatial-frequency domain network for low-light image enhancement, referred to as JSF. In the spatial domain, brightness is optimized through the amalgamation of global and local information. In the frequency domain, noise is reduced and details are amplified using Fourier Transformation to carry out amplitude and phase enhancement. Additionally, the enhanced results from the aforementioned domains are fused by linear and nonlinear stretching. To validate the effectiveness of JSF, this paper presents both qualitative and quantitative comparison results, demonstrating its superiority over several existing state-of-the-art methods.},
  archive      = {J_CVIU},
  author       = {Yahong Wu and Feng Liu and Rong Wang},
  doi          = {10.1016/j.cviu.2025.104496},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104496},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {JSF: A joint spatial-frequency domain network for low-light image enhancement},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCNet: A feature complementary network for nighttime flare removal. <em>CVIU</em>, <em>261</em>, 104495. (<a href='https://doi.org/10.1016/j.cviu.2025.104495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nighttime image flare removal is a very challenging task due to the presence of various types of unfavorable degrading effects, including glare, shimmer, streak and saturated blobs. Most of the existing methods focus on the spatial domain and limited perception field, resulting in incomplete flare removal and severe artifacts. To address these challenges, we propose a two-stage feature complementary network for nighttime flare removal, which is used for flare perception and removal, respectively. In the first stage, a Spatial-Frequency Complementary Module (SFCM) is designed to perceive the flare region from different domains to get a mask of the flare. In the second stage, the flare mask and image are fed into the Spatial-Frequency Complementary Gating Module (SFCGM) to preserve the background information, while removing the flares from different angles and restoring the detailed features. Finally the flare and non-flare regions are modeled by the Flare Interactive Module (FIM) to refine the flare regions at a fine-grained level to suppress the artifact problem. Extensive experiments on Flare 7K++ validate the superiority of the proposed approach over state-of-the-arts, both qualitatively and quantitatively.},
  archive      = {J_CVIU},
  author       = {Kejing Qi and Bo Wang and Chongyi Li},
  doi          = {10.1016/j.cviu.2025.104495},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104495},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {FCNet: A feature complementary network for nighttime flare removal},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRE-net: A forgery image detection framework based on gradient feature and reconstruction error. <em>CVIU</em>, <em>261</em>, 104494. (<a href='https://doi.org/10.1016/j.cviu.2025.104494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous technological breakthroughs in Generative Adversarial Networks (GANs) and diffusion models, remarkable progress has been achieved in the field of image generation. These technologies enable the creation of highly realistic images, thereby intensifying the risk of spreading fake information. However, traditional image detectors face a growing challenge of inadequate generalization capabilities when confronted with images generated by models that were not included during the training phase. To tackle this challenge, we introduce a novel detection framework, named GRE-Net (Network integrating Gradient and Reconstruction Error), which extracts gradient feature through the DPG module and calculates the reconstruction error utilizing the DIRE method. By integrating these two aspects into a comprehensive feature representation, GRE-Net effectively detects the authenticity of images. Specifically, we devise a dual-branch model that leverages the proposed DPG (Discriminator of ProjectedGAN to extract Gradient) module to extract gradient feature from images and concurrently employs the DIRE (DIffusion Reconstruction Error) method to obtain the diffusion reconstruction error of images. By fusing the features extracted from these two modules as a universal representation, we describe the artifacts produced by generative models, crafting a comprehensive detector capable of identifying both GAN-generated and diffusion model-generated images. Notably, the DPG approach utilizes the discriminator of ProjectedGAN as an intermediary bridge, mapping all data into the gradient domain. This transformation process effectively captures the intrinsic feature differences during the image generation process. Subsequently, the gradient feature are fed into a classifier to achieve efficient discrimination between authentic and fake images. To validate the efficacy of our proposed detector, we conducted evaluations on a dataset comprising images generated by ten diverse diffusion models and GANs. Extensive experiments demonstrate that our detector exhibits stronger generalization capabilities and higher robustness, rendering it suitable for real-world generated image detection tasks.},
  archive      = {J_CVIU},
  author       = {Wenqing Wu and Xinyi Shi and Jinghai Ai and Xiaodong Wang},
  doi          = {10.1016/j.cviu.2025.104494},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104494},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {GRE-net: A forgery image detection framework based on gradient feature and reconstruction error},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating forgetting in the adaptation of CLIP for few-shot classification. <em>CVIU</em>, <em>261</em>, 104493. (<a href='https://doi.org/10.1016/j.cviu.2025.104493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adapter-style efficient transfer learning has demonstrated outstanding performance in fine-tuning vision-language models, especially in scenarios with limited data. However, existing methods fail to effectively balance the prior knowledge acquired during the pre-training process and the training samples. To address this problem, we propose a method called Mitigating Forgetting in the Adaptation (MiFA) of CLIP. MiFA first employs class prototypes to represent the most prominent features of a class, and these prototypes provide a robust initialization for the classifier. To overcome the forgetting of prior knowledge, MiFA then leverages a memory module that retains the initial parameters and the parameters of training history by creating a memory weight through momentum. The weight is used to initialize a new classification layer, which, along with the original layer, guides each other to balance prior knowledge and feature adaptation. Similarly, in the text processing branch, a parallel initialization strategy is adopted to ensure that the model’s performance is improved. Text features are employed to initialize a text classification layer, and CLIP logits help prevent excessive forgetting of useful text information. Extensive experiments have demonstrated the effectiveness of our method.},
  archive      = {J_CVIU},
  author       = {Jiale Cao and Yuanheng Liu and Zhong Ji and Jingren Liu and Aiping Yang and Yanwei Pang},
  doi          = {10.1016/j.cviu.2025.104493},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104493},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Mitigating forgetting in the adaptation of CLIP for few-shot classification},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint multi-dimensional dynamic attention and transformer for general image restoration. <em>CVIU</em>, <em>261</em>, 104491. (<a href='https://doi.org/10.1016/j.cviu.2025.104491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outdoor images often suffer from severe degradation due to rain, haze, and noise, impairing image quality and challenging high-level tasks. Current image restoration methods struggle to handle complex degradation while maintaining efficiency. This paper introduces a novel image restoration architecture that combines multi-dimensional dynamic attention and self-attention within a U-Net framework. To leverage the global modeling capabilities of transformers and the local modeling capabilities of convolutions, we integrate sole CNNs in the encoder–decoder and sole transformers in the latent layer. Additionally, we design convolutional kernels with selected multi-dimensional dynamic attention to capture diverse degraded inputs efficiently. A transformer block with transposed self-attention further enhances global feature extraction while maintaining efficiency. Extensive experiments demonstrate that our method achieves a better balance between performance and computational complexity across five image restoration tasks: deraining, deblurring, denoising, dehazing, and enhancement, as well as superior performance for high-level vision tasks. The source code will be available at https://github.com/House-yuyu/MDDA-former .},
  archive      = {J_CVIU},
  author       = {Huan Zhang and Xu Zhang and Nian Cai and Jianglei Di and Yun Zhang},
  doi          = {10.1016/j.cviu.2025.104491},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104491},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Joint multi-dimensional dynamic attention and transformer for general image restoration},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO. <em>CVIU</em>, <em>261</em>, 104489. (<a href='https://doi.org/10.1016/j.cviu.2025.104489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone-based target detection presents inherent challenges, including the high density and overlap of targets in drone images, as well as the blurriness of targets under varying lighting conditions, which complicates accurate identification. Traditional methods often struggle to detect numerous small, densely packed targets against complex backgrounds. To address these challenges, we propose LAM-YOLO, an object detection model specifically designed for drone-based applications. First, we introduce a light-occlusion attention mechanism to enhance the visibility of small targets under diverse lighting conditions. Additionally, we incorporate Involution modules to improve feature layer interactions. Second, we employ an improved SIB-IoU as the regression loss function to accelerate model convergence and enhance localization accuracy. Finally, we implement a novel detection strategy by introducing two auxiliary detection heads to better identify smaller-scale targets. Our quantitative results demonstrate that LAM-YOLO outperforms methods such as Faster R-CNN, YOLOv11, and YOLOv12 in terms of mAP@0.5 and mAP@0.5:0.95 on the VisDrone2019 public dataset. Compared to the original YOLOv8, the average precision increases by 7.1%. Additionally, the proposed SIB-IoU loss function not only accelerates convergence speed during training but also improves average precision compared to the traditional loss function.},
  archive      = {J_CVIU},
  author       = {Yuchen Zheng and Yuxin Jing and Jufeng Zhao and Guangmang Cui},
  doi          = {10.1016/j.cviu.2025.104489},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104489},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camera pose in SfT and NRSfM under isometric and weaker deformation models. <em>CVIU</em>, <em>261</em>, 104488. (<a href='https://doi.org/10.1016/j.cviu.2025.104488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camera pose is a very natural concept in 3D vision in the rigid setting. It is however much more difficult to work with in deformable settings. Consequently, numerous deformable reconstruction methods simply ignore camera pose. We analyse the concept of pose in deformable settings and prove that it is unconstrained with the existing formulations, properly justifying the existing pose-less methods reconstructing structure only. We explain this result intuitively by the impossibility to define an intrinsic coordinate frame to a general deforming object. The proposed analysis uses the isometric deformation model and extends to the weaker models including conformality and equiareality We propose a novel prior to rescue camera pose estimation in deformable settings, which attributes the deforming object’s dominant rigid-body motion to the camera. We show that adding this prior to any existing formulation fully constrains camera pose and leads to elegant two-step solution methods, involving deformable structure reconstruction using a base method in the first step, and absolute orientation or Procrustes analysis in the second step. We derive the proposed approach for the template-based and template-less settings, respectively implemented using Shape-from-Template (SfT) and Non-Rigid Structure-from-Motion (NRSfM) as base methods and validate them experimentally, showing that the computed pose is qualitatively and quantitatively plausible.},
  archive      = {J_CVIU},
  author       = {Adrien Bartoli and Agniva Sengupta},
  doi          = {10.1016/j.cviu.2025.104488},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104488},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Camera pose in SfT and NRSfM under isometric and weaker deformation models},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-granularity balance learning for long-tailed image classification. <em>CVIU</em>, <em>261</em>, 104469. (<a href='https://doi.org/10.1016/j.cviu.2025.104469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In long-tailed datasets, the training of deep neural network-based models faces challenges, where the model may become biased towards the head classes with abundant training data, resulting in poor performance on tail classes with limited samples. Most current methods employ contrastive learning to learn more balanced representations by finding the class center. However, these methods use class centers to address local imbalance within a mini-batch, they overlook the global imbalance between batches throughout an epoch, caused by the long-tailed distribution of the dataset. In this paper, we propose bi-granularity balance learning to address the two-layer imbalance. We decouple the attraction–repulsion term in contrastive loss into two independent components: global and local balance. The global balance component focuses on capturing semantic information from different perspectives of the image and shifting learning attention from the head classes to the tail classes in the global perspective. The local balance component aims to learn inter-class separability from the local perspective. The proposed method efficiently learns the intra-class compactness and inter-class separability in long-tailed model training and improves the performance of the long-tailed model. Experimental results show that the proposed method achieves competitive performance on long-tailed benchmarks such as CIFAR-10/100-LT, TinyImageNet-LT, and iNaturalist 2018.},
  archive      = {J_CVIU},
  author       = {Ning Ren and Xiaosong Li and Yanxia Wu and Yan Fu},
  doi          = {10.1016/j.cviu.2025.104469},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104469},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Bi-granularity balance learning for long-tailed image classification},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="disopt">DISOPT - 3</h2>
<ul>
<li><details>
<summary>
(2025). Computational aspects of lifted cover inequalities for knapsacks with few different weights. <em>DISOPT</em>, <em>58</em>, 100912. (<a href='https://doi.org/10.1016/j.disopt.2025.100912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cutting planes are frequently used for solving integer programs. A common strategy is to derive cutting planes from building blocks or a substructure of the integer program. In this paper, we focus on knapsack constraints that arise from single row relaxations. Among the most popular classes derived from knapsack constraints are lifted minimal cover inequalities. The separation problem for these inequalities is NP-hard though, and one usually separates them heuristically, therefore not fully exploiting their potential. For many benchmarking instances however, it turns out that many knapsack constraints only have few different coefficients. This motivates the concept of sparse knapsacks where the number of different coefficients is a small constant, independent of the number of variables present. For such knapsacks, we observe that there are only polynomially many different classes of structurally equivalent minimal covers. This opens the door to specialized techniques for using lifted minimal cover inequalities. In this article we will discuss two such techniques, which are based on specialized sorting methods. On the one hand, we present new separation routines that separate equivalence classes of inequalities rather than individual inequalities. On the other hand, we derive compact extended formulations that express all lifted minimal cover inequalities by means of a polynomial number of constraints. These extended formulations are based on tailored sorting networks that express our separation algorithm by linear inequalities. We conclude the article by a numerical investigation of the different techniques for popular benchmarking instances.},
  archive      = {J_DISOPT},
  author       = {Christopher Hojny and Cédric Roy},
  doi          = {10.1016/j.disopt.2025.100912},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100912},
  shortjournal = {Discret. Optim.},
  title        = {Computational aspects of lifted cover inequalities for knapsacks with few different weights},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved bound for the price of anarchy for related machine scheduling. <em>DISOPT</em>, <em>58</em>, 100911. (<a href='https://doi.org/10.1016/j.disopt.2025.100911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce an improved upper bound for the efficiency of Nash equilibria in utilitarian scheduling games on related machines. The machines have varying speeds and adhere to the shortest processing time first policy. The goal of each job is to minimize its completion time, while the social objective is to minimize the sum of completion times. Our main finding establishes an upper bound of 2 − 1 / ( 4 m − 2 ) on the price of anarchy for the general case of m machines. We improve this bound to 3/2 for the case of two machines, and to 2 − 1 / ( 2 m ) for the general case of m machines when the machines have divisible speeds, i.e., if the speed of each machine is divisible by the speed of any slower machine.},
  archive      = {J_DISOPT},
  author       = {André Berger and Arman Rouhani and Marc Schröder},
  doi          = {10.1016/j.disopt.2025.100911},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100911},
  shortjournal = {Discret. Optim.},
  title        = {An improved bound for the price of anarchy for related machine scheduling},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the circuit diameter conjecture for counterexamples to the hirsch conjecture. <em>DISOPT</em>, <em>58</em>, 100910. (<a href='https://doi.org/10.1016/j.disopt.2025.100910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circuit diameters of polyhedra are a fundamental tool for studying the complexity of circuit augmentation schemes for linear programming and for finding lower bounds on combinatorial diameters. The main open problem in this area is the circuit diameter conjecture, the analogue of the Hirsch conjecture in the circuit setting. A natural question is whether the well-known counterexamples to the Hirsch conjecture carry over. Previously, Stephen and Yusun showed that the Klee-Walkup counterexample to the unbounded Hirsch conjecture does not transfer to the circuit setting. Our main contribution is to show that the original counterexamples for other variants, using monotone walks or for bounded polytopes, also do not transfer. A challenge lies in the dependence of circuit diameters on the specific realization of a polyhedron. We discuss for which realizations, in addition to the original ones from the literature, our tools resolve this question. Our results rely on new observations on structural properties of these counterexamples. To analyze the bounded case, we exploit the geometry of certain 2-faces of the polytopes underlying all known bounded Hirsch counterexamples in Santos’ work. For Todd’s monotone Hirsch counterexample, we study linear programs on spindles and prove sufficient conditions for short monotone circuit walks to exist. We then enumerate all linear programs over Todd’s polytope and find four new orientations that contradict the monotone Hirsch conjecture, while the remaining 7107 satisfy the bound. The conclusion then follows by applying these sufficient conditions to Todd’s counterexample.},
  archive      = {J_DISOPT},
  author       = {Alexander E. Black and Steffen Borgwardt and Matthias Brugger},
  doi          = {10.1016/j.disopt.2025.100910},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100910},
  shortjournal = {Discret. Optim.},
  title        = {On the circuit diameter conjecture for counterexamples to the hirsch conjecture},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="dke">DKE - 14</h2>
<ul>
<li><details>
<summary>
(2026). ASF: A novel associative scoring function for embedded knowledge graph reasoning. <em>DKE</em>, <em>161</em>, 102511. (<a href='https://doi.org/10.1016/j.datak.2025.102511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important tools for knowledge management is the Knowledge Graph (KG), a multi-relational graph that depicts rich factual information across entities. A KG represents entities as nodes and relations as edges, with each edge represented by a triplet: (head entity, relation, tail entity). The Scoring Function (SF) in a KG quantifies the plausibility of these triplets and is often derived from KG embeddings. However, due to the distinct relational patterns across KGs, an SF that performs well on one KG might fail on another, making the design of optimal SFs a challenging task. This study introduces the concept of an Associative Scoring Function (ASF), which leverages Association Rule Mining (ARM) to discover and incorporate patterns and characteristics of symmetric, asymmetric, inverse, and other relational types within embedded KGs. The ARM technique in ASF uses the FP-Growth algorithm to extract meaningful associations, which is enhanced further through hyperparameter tuning. Extensive experiments on benchmark datasets demonstrate that ASF is KG-independent and performs better than state-of-the-art SFs. These results highlight ASF's potential to generalize across diverse KGs, offering a significant advancement in the KG link prediction task.},
  archive      = {J_DKE},
  author       = {MVPT Lakshika and HA Caldera},
  doi          = {10.1016/j.datak.2025.102511},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102511},
  shortjournal = {Data Knowl. Eng.},
  title        = {ASF: A novel associative scoring function for embedded knowledge graph reasoning},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A graph-based model for semantic textual similarity measurement. <em>DKE</em>, <em>161</em>, 102509. (<a href='https://doi.org/10.1016/j.datak.2025.102509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring semantic similarity between sentence pairs is a fundamental problem in Natural Language Processing with applications in various domains, including machine translation, speech recognition, automatic question answering, and text summarization. Despite its significance, accurately assessing semantic similarity remains a challenging task, particularly for underrepresented languages such as Vietnamese. Existing methods have yet to fully leverage the unique linguistic characteristics of Vietnamese for semantic similarity measurement. To address this limitation, we propose GBNet-STS (Graph-Based Network for Semantic Textual Similarity), a novel framework for measuring the semantic similarity of Vietnamese sentence pairs. GBNet-STS integrates lexical-grammatical similarity scores and distributional semantic similarity scores within a multi-layered graph-based model. By capturing different semantic perspectives through multiple interconnected layers, our approach provides a more comprehensive and robust similarity estimation. Experimental results demonstrate that GBNet-STS outperforms traditional methods, achieving state-of-the-art performance in Vietnamese semantic similarity tasks.},
  archive      = {J_DKE},
  author       = {Van-Tan Bui and Quang-Minh Nguyen and Van-Vinh Nguyen and Duc-Toan Nguyen},
  doi          = {10.1016/j.datak.2025.102509},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102509},
  shortjournal = {Data Knowl. Eng.},
  title        = {A graph-based model for semantic textual similarity measurement},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rule-guided process discovery. <em>DKE</em>, <em>161</em>, 102508. (<a href='https://doi.org/10.1016/j.datak.2025.102508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event data extracted from information systems serves as the foundation for process mining, enabling the extraction of insights and identification of improvements. Process discovery focuses on deriving descriptive process models from event logs, which form the basis for conformance checking, performance analysis, and other applications. Traditional process discovery techniques predominantly rely on event logs, often overlooking supplementary information such as domain knowledge and process rules. These rules, which define relationships between activities, can be obtained through automated techniques like declarative process discovery or provided by domain experts based on process specifications. When used as an additional input alongside event logs, such rules have significant potential to guide process discovery. However, leveraging rules to discover high-quality imperative process models, such as BPMN models and Petri nets, remains an underexplored area in the literature. To address this gap, we propose an enhanced framework, IMr, which integrates discovered or user-defined rules into the process discovery workflow via a novel recursive approach. The IMr framework employs a divide-and-conquer strategy, using rules to guide the selection of process structures at each recursion step in combination with the input event log. We evaluate our approach on several real-world event logs and demonstrate that the discovered models better align with the provided rules without compromising their conformance to the event log. Additionally, we show that high-quality rules can improve model quality across well-known conformance metrics. This work highlights the importance of integrating domain knowledge into process discovery, enhancing the quality, interpretability, and applicability of the resulting process models.},
  archive      = {J_DKE},
  author       = {Ali Norouzifar and Marcus Dees and Wil van der Aalst},
  doi          = {10.1016/j.datak.2025.102508},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102508},
  shortjournal = {Data Knowl. Eng.},
  title        = {Rule-guided process discovery},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LQ-FJS: A logical query-digging fake-news judgment system with structured video-summarization engine using LLM. <em>DKE</em>, <em>161</em>, 102507. (<a href='https://doi.org/10.1016/j.datak.2025.102507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of online social platforms can greatly benefit people by fostering remote relationships, but it also inevitably amplifies the impact of multimodal fake news on societal trust and ethics. Existing fake-news detection AI systems are still vulnerable to the inconspicuous and indiscernible multimodal misinformation, and often lacking interpretability and accuracy in cross-platform settings. Hence, we propose a new innovative logical query-digging fake-news judgment system (LQ-FJS) to tackle the above problem based on multimodal approach. The LQ-FJS verifies the truthfulness of claims made within multimedia news by converting video content into structured textual summaries. It then acts as an interpretable agent, explaining the reasons for identified fake news by the structured video-summarization engine (SVSE) to act as an interpretable detection intermediary agent. The SVSE generates condensed captions for raw video content, converting it into structured textual narratives. Then, LQ-FJS exploits these condensed captions to retrieve reliable information related to the video content from LLM. Thus, LQ-FJS cross-verifies external knowledge sources and internal LLM responses to determine whether contradictions exist with factual information through a multimodal inconsistency verification procedure. Our experiments demonstrate that the subtle summarization produced by SVSE can facilitate the generation of explanatory reports that mitigate large-scale trust deficits caused by opaque “black-box” models. Our experiments show that LQ-FJS improves F1 scores by 4.5% and 7.2% compared to state-of-the-art models (FactLLaMA 2023 and HiSS 2023), and increases 14% user trusts through interpretable conclusions.},
  archive      = {J_DKE},
  author       = {Jhing-Fa Wang and Din-Yuen Chan and Hsin-Chun Tsai and Bo-Xuan Fang},
  doi          = {10.1016/j.datak.2025.102507},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102507},
  shortjournal = {Data Knowl. Eng.},
  title        = {LQ-FJS: A logical query-digging fake-news judgment system with structured video-summarization engine using LLM},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ABBA: Index structure for sequential pattern-based aggregate queries. <em>DKE</em>, <em>161</em>, 102506. (<a href='https://doi.org/10.1016/j.datak.2025.102506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern-based aggregate (PBA) queries constitute an important and widely used type of analytical queries in sequence OLAP (S-OLAP) systems. Unfortunately, finding accurate answers to PBA queries in the S-OLAP system is often very expensive both in terms of time and memory consumption. In this paper we propose an efficient and easily maintainable index structure called the ABBA Index, which addresses the problem of PBA query processing. Experiments conducted using the KDD Cup data and public transport passengers’ travel behavior data show that our index outperforms state-of-the art solutions while requiring much less memory. The ABBA Index can be easily extended to support pattern-based aggregate queries over hierarchy (PBA-H), a novel class of analytical queries which we introduce as the second main contribution of the paper. Sensitivity, scalability and complexity analysis of the ABBA Index is also provided.},
  archive      = {J_DKE},
  author       = {Witold Andrzejewski and Tadeusz Morzy and Maciej Zakrzewicz},
  doi          = {10.1016/j.datak.2025.102506},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102506},
  shortjournal = {Data Knowl. Eng.},
  title        = {ABBA: Index structure for sequential pattern-based aggregate queries},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Elevating human-machine collaboration in NLP for enhanced content creation and decision support. <em>DKE</em>, <em>161</em>, 102505. (<a href='https://doi.org/10.1016/j.datak.2025.102505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-machine collaboration in Natural Language Processing (NLP) is revolutionizing content creation and decision support by seamlessly combining the strengths of both entities for enhanced efficiency and quality. The lack of seamless integration between human creativity and machine efficiency in NLP hinders optimal content creation and decision support. The objective of this study is to explore and promote the integration of human-machine collaboration in NLP to enhance both content creation and decision support processes. Data Acquisition for NLP requests involves defining the task and target audience, identifying relevant data sources like text documents and web data, and incorporating human expertise for data curation through validation and annotation. Machine processing techniques like tokenization, stemming/lemmatization, and removal of stop words, as well as human input for tasks like data annotation and error correction, to improve data quality and relevance for NLP applications. The combination of automated processing and human feedback leads to more precise and dependable effects. Techniques such as sentiment analysis, topic modelling, and entity recognition are utilized to excerpt valued perceptions from the data and enhance collaboration between humans and machines. These techniques help to streamline the NLP process and ensure that the system is providing accurate and relevant information to users. The analysis of NLP models in machine processing involves training the models to perform specific tasks, such as summarization, sentiment analysis, information extraction, trend identification, and creative content generation. The results show that social media leads with 90% usage, pivotal for audience engagement, while blogs at 78% highlight their depth in content creation implementation using Python software. These trained models are then used to improve decision-making processes, generate creative content, and enhance the accuracy of search results. The future scope involves leveraging advanced NLP techniques to deepen the collaboration between humans and machines for more effective content creation and decision support.},
  archive      = {J_DKE},
  author       = {Priyanka V. Deshmukh and Aniket K. Shahade},
  doi          = {10.1016/j.datak.2025.102505},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102505},
  shortjournal = {Data Knowl. Eng.},
  title        = {Elevating human-machine collaboration in NLP for enhanced content creation and decision support},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ELEVATE-ID: Extending large language models for end-to-end entity linking evaluation in indonesian. <em>DKE</em>, <em>161</em>, 102504. (<a href='https://doi.org/10.1016/j.datak.2025.102504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their effectiveness in low-resource languages remains underexplored, particularly in complex tasks such as end-to-end Entity Linking (EL), which requires both mention detection and disambiguation against a knowledge base (KB). In earlier work, we introduced IndEL — the first end-to-end EL benchmark dataset for the Indonesian language — covering both a general domain (news) and a specific domain (religious text from the Indonesian translation of the Quran), and evaluated four traditional end-to-end EL systems on this dataset. In this study, we propose ELEVATE-ID, a comprehensive evaluation framework for assessing LLM performance on end-to-end EL in Indonesian. The framework evaluates LLMs under both zero-shot and fine-tuned conditions, using multilingual and Indonesian monolingual models, with Wikidata as the target KB. Our experiments include performance benchmarking, generalization analysis across domains, and systematic error analysis. Results show that GPT-4 and GPT-3.5 achieve the highest accuracy in zero-shot and fine-tuned settings, respectively. However, even fine-tuned GPT-3.5 underperforms compared to DBpedia Spotlight — the weakest of the traditional model baselines — in the general domain. Interestingly, GPT-3.5 outperforms Babelfy in the specific domain. Generalization analysis indicates that fine-tuned GPT-3.5 adapts more effectively to cross-domain and mixed-domain scenarios. Error analysis uncovers persistent challenges that hinder LLM performance: difficulties with non-complete mentions, acronym disambiguation, and full-name recognition in formal contexts. These issues point to limitations in mention boundary detection and contextual grounding. Indonesian-pretrained LLMs, Komodo and Merak, reveal core weaknesses: template leakage and entity hallucination, respectively—underscoring architectural and training limitations in low-resource end-to-end EL. 1},
  archive      = {J_DKE},
  author       = {Ria Hari Gusmita and Asep Fajar Firmansyah and Hamada M. Zahera and Axel-Cyrille Ngonga Ngomo},
  doi          = {10.1016/j.datak.2025.102504},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102504},
  shortjournal = {Data Knowl. Eng.},
  title        = {ELEVATE-ID: Extending large language models for end-to-end entity linking evaluation in indonesian},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-aware complex question answering over temporal knowledge graph. <em>DKE</em>, <em>161</em>, 102503. (<a href='https://doi.org/10.1016/j.datak.2025.102503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Question Answering (KGQA) is a crucial topic in Knowledge Graphs (KGs), with the objective of retrieving the corresponding facts from KGs to answer given questions. In practical applications, facts in KGs usually have time constraints, thus, question answering on Temporal Knowledge Graphs (TKGs) has attracted extensive attention. Existing Temporal Knowledge Graph Question Answering (TKGQA) methods focus on dealing with complex questions involving multiple facts, and mainly face two challenges. First, these methods only consider matching questions with facts in TKGs to identify the answer, ignoring the temporal order between different facts, which makes it challenging to solve the questions involving temporal order. Second, they usually focus on the representation of the question text while neglecting the rich semantic information within the questions, which leads to certain limitations in understanding question. To address the above challenges, this research proposes a model named Time-Aware Complex Question Answering (TA-CQA). Specifically, we extend the Temporal Knowledge Graph Embedding (TKGE) model by incorporating temporal order information into the embedding vectors, ensuring that the model can distinguish the temporal order of different facts. To enhance the semantic representation of the question, we integrate question information using attention mechanism and learnable encoder. Different from the previous TKGQA methods, we propose time relevance measurement to further enhance the accuracy of answer prediction by better capturing the correlation between question information and time information. Multiple sets of experiments on CronQuestions and TimeQuestions demonstrate our model’s superior performance across all question types. In particular, for complex questions involving multiple facts, the hit@1 values are increased by 3.2% and 3.5% respectively.},
  archive      = {J_DKE},
  author       = {Luyi Bai and Tongyue Zhang and Guangchen Feng},
  doi          = {10.1016/j.datak.2025.102503},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102503},
  shortjournal = {Data Knowl. Eng.},
  title        = {Time-aware complex question answering over temporal knowledge graph},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conceptual modeling of user perspectives — From data warehouses to alliance-driven data ecosystems. <em>DKE</em>, <em>161</em>, 102502. (<a href='https://doi.org/10.1016/j.datak.2025.102502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of modern information systems has highlighted the need for advanced conceptual modeling techniques that incorporate multi-perspective and view-based approaches. This paper explores the role of multi-perspective modeling and view modeling in designing distributed, heterogeneous systems while addressing diverse user requirements and ensuring semantic consistency. These methods enable the representation of multiple viewpoints, traceability, and dynamic integration across different levels of abstraction. Key advancements in schema mapping, view maintenance, and semantic metadata management are examined, illustrating how they support query optimization, data quality, and interoperability. We discuss how data management architectures, such as data ecosystems, data warehouses, and data lakes, leverage these innovations to enable flexible and sustainable data sharing. By integrating user-centric and goal-oriented modeling frameworks, the alignment of technical design with organizational and social requirements is emphasized. Future challenges include the need for enhanced reasoning capabilities and collaborative tools to manage the growing complexity of interconnected systems while maintaining adaptability and trust.},
  archive      = {J_DKE},
  author       = {Sandra Geisler and Christoph Quix and István Koren and Matthias Jarke},
  doi          = {10.1016/j.datak.2025.102502},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102502},
  shortjournal = {Data Knowl. Eng.},
  title        = {Conceptual modeling of user perspectives — From data warehouses to alliance-driven data ecosystems},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Source-free domain adaptation with complex distribution considerations for time series data. <em>DKE</em>, <em>161</em>, 102501. (<a href='https://doi.org/10.1016/j.datak.2025.102501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained model from a labeled source domain to an unlabeled target domain without accessing source domain data, thereby protecting source domain privacy. Although SFDA has recently been applied to time series data, the inherent complex distribution characteristics including temporal variability and distributional diversity of such data remain underexplored. Time series data exhibit significant dynamic variability influenced by collection environments, leading to discrepancies between sequences. Additionally, multidimensional time series data face distributional diversity across dimensions. These complex characteristics increase the learning difficulty for source models and widen the adaptation gap between the source and target domains. To address these challenges, this paper proposes a novel SFDA method for time series data, named Adaptive Latent Subdomain feature extraction and joint Prediction (ALSP). The method divides the source domain, which has a complex distribution, into multiple latent subdomains with relatively simple distributions, thereby effectively capturing the features of different subdistributions. It extracts latent domain-specific and domain-invariant features to identify subdomain-specific characteristics. Furthermore, it combines domain-specific classifiers and a domain-invariant classifier to enhance model performance through multi-classifier joint prediction. During target domain adaptation, ALSP reduces domain dependence by extracting invariant features, thereby narrowing the distributional gap between the source and target domains. Simultaneously, it leverages prior knowledge from the source domain distribution to support the hypothesis space and dynamically adapt to the target domain. Experiments on three real-world datasets demonstrate that ALSP achieves superior performance in cross-domain time series classification tasks, significantly outperforming existing methods.},
  archive      = {J_DKE},
  author       = {Jing Shang and Zunming Chen and Zhiwen Xiao and Zhihui Wu and Yifei Zhang and Jibing Wang},
  doi          = {10.1016/j.datak.2025.102501},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102501},
  shortjournal = {Data Knowl. Eng.},
  title        = {Source-free domain adaptation with complex distribution considerations for time series data},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conceptual modeling: A large language model assistant for characterizing research contributions. <em>DKE</em>, <em>161</em>, 102497. (<a href='https://doi.org/10.1016/j.datak.2025.102497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The body of conceptual modeling research publications is vast and diverse, making it challenging for a single researcher or research group to fully comprehend the field’s overall development. Although some approaches have been proposed to help organize these research contributions, it is still unrealistic to expect human experts to manually comprehend and characterize all of this research. However, as generative AI tools based on large language models, such as ChatGPT, become increasingly sophisticated, it may be possible to replace or augment tedious, manual work with semi-automated approaches. In this research, we present a customized version of ChatGPT that is tuned to the task of characterizing conceptual modeling research. Experiments with this AI tool demonstrate that it is feasible to create a usable knowledge survey for the continually evolving body of conceptual modeling research contributions.},
  archive      = {J_DKE},
  author       = {Stephen W. Liddle and Heinrich C. Mayr and Oscar Pastor and Veda C. Storey and Bernhard Thalheim},
  doi          = {10.1016/j.datak.2025.102497},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102497},
  shortjournal = {Data Knowl. Eng.},
  title        = {Conceptual modeling: A large language model assistant for characterizing research contributions},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic time warping for classifying long-term trends in time series. <em>DKE</em>, <em>161</em>, 102495. (<a href='https://doi.org/10.1016/j.datak.2025.102495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the potential of dynamic time warping (DTW) for recognizing different segments in time series data characterized by their long-term trends and curvature. To perform classification, a set of reference data for each class is required, where each time series in the reference set represents a typical shape of that class. The classification process involves computing the DTW distance between a given time series and each reference time series, then assigning the time series to the class with the minimum distance. Experiments on both simulated and real-world time series data from two different use cases demonstrate that DTW can correctly classify the different segments. Additionally, the paper investigates whether incorrectly classified phases could indicate data security issues. Additional experiments are performed to assess the number of data points required to reliably classify a segment correctly. These experiments highlight the limitations and emphasize the importance of selecting good reference data.},
  archive      = {J_DKE},
  author       = {Anna-Christina Glock and Klaus Chmelina and Johannes Fürnkranz and Thomas Hütter},
  doi          = {10.1016/j.datak.2025.102495},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102495},
  shortjournal = {Data Knowl. Eng.},
  title        = {Dynamic time warping for classifying long-term trends in time series},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semantic-aware query answering with large language models. <em>DKE</em>, <em>161</em>, 102494. (<a href='https://doi.org/10.1016/j.datak.2025.102494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern data-driven world, answering queries over heterogeneous and semantically inconsistent data remains a significant challenge. Modern datasets originate from diverse sources, such as relational databases, semi-structured repositories, and unstructured documents, leading to substantial variability in schemas, terminologies, and data formats. Traditional systems, constrained by rigid syntactic matching and strict data binding, struggle to capture critical semantic connections and schema ambiguities, failing to meet the growing demand among data scientists for advanced forms of flexibility and context-awareness in query answering. In parallel, the advent of Large Language Models (LLMs) has introduced new capabilities in natural language interpretation, making them highly promising for addressing such challenges. However, LLMs alone lack the systematic rigor and explainability required for robust query processing and decision-making in high-stakes domains. In this paper, we propose Soft Query Answering (Soft QA), a novel hybrid approach that integrates LLMs as an intermediate semantic layer within the query processing pipeline. Soft QA enhances query answering adaptability and flexibility by injecting semantic understanding through context-aware, schema-informed prompts, and leverages LLMs to semantically link entities, resolve ambiguities, and deliver accurate query results in complex settings. We demonstrate its practical effectiveness through real-world examples, highlighting its ability to resolve semantic mismatches and improve query outcomes without requiring extensive data cleaning or restructuring.},
  archive      = {J_DKE},
  author       = {Paolo Atzeni and Teodoro Baldazzi and Luigi Bellomarini and Eleonora Laurenza and Emanuel Sallinger},
  doi          = {10.1016/j.datak.2025.102494},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102494},
  shortjournal = {Data Knowl. Eng.},
  title        = {Semantic-aware query answering with large language models},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated requirements framework for analytical and AI projects. <em>DKE</em>, <em>161</em>, 102493. (<a href='https://doi.org/10.1016/j.datak.2025.102493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To this day, the requirements of data warehouses, user visualizations and ML projects have been tackled in an independent manner, ignoring the possible cross-requirements, collective constraints and dependencies between the outputs of the different systems that should be taken into account to ensure a successful analytical project. In this work, we take a holistic approach and propose a methodology that supports modeling and subsequent analysis while taking into account these three aspects. This methodology has several advantages, mainly that (i) it enables us to identify possible conflicts between actors on different tasks that are overlooked if the systems are treated in an isolated manner and (ii) this holistic view enables modeling multi-company systems, where the information or even the analytical results can be provided by third-parties, identifying key participants in federated environments. After presenting the required formalism to carry out this kind of analysis, we showcase it on a real-world running example of the tourism sector.},
  archive      = {J_DKE},
  author       = {Juan Trujillo and Ana Lavalle and Alejandro Reina-Reina and Jorge García-Carrasco and Alejandro Maté and Wolfgang Maaß},
  doi          = {10.1016/j.datak.2025.102493},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102493},
  shortjournal = {Data Knowl. Eng.},
  title        = {An integrated requirements framework for analytical and AI projects},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="dss">DSS - 9</h2>
<ul>
<li><details>
<summary>
(2025). Corporate credit scoring method based on unlabeled data and multi-source data. <em>DSS</em>, <em>198</em>, 114543. (<a href='https://doi.org/10.1016/j.dss.2025.114543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlabeled data and multi-source data provide unprecedented opportunities for the financial industry to improve credit scoring accuracy. When utilizing unlabeled data, existing credit scoring methods often suffer from unreliability issues due to improper clustering or the introduction of noise when predicting labels. When utilizing multi-source data, existing credit scoring methods based on federated learning frameworks fail to tailor models for different data distributions of different data sources due to the limitations of relying on a single global model. Moreover, recent studies have explored the individual value of unlabeled data and multi-source data, but they often fail to utilize both. To address these issues, we propose UMDCS (Unlabeled and Multi-Source data Driven Credit Scoring), a self-supervised credit scoring method that utilizes both unlabeled and multi-source data simultaneously. To utilize unlabeled data, we propose a novel sample masking function to generate pseudo-labels for unlabeled data and pre-train the encoder using the pretext tasks. To utilize multi-source data, we employ a horizontal federated learning framework to aggregate local encoders into a global model while preserving data privacy. The global encoder is concatenated with personalized predictors to form personalized credit scoring models for each data source. Five experiments and statistical significance tests show that UMDCS outperforms other baseline methods.},
  archive      = {J_DSS},
  author       = {Yunhong Xu and Yitong Chen and Li Sun and Yu Chen},
  doi          = {10.1016/j.dss.2025.114543},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114543},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Corporate credit scoring method based on unlabeled data and multi-source data},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Being responsible or affable: Investigating the effects of AI error correction behaviors on user engagement. <em>DSS</em>, <em>198</em>, 114542. (<a href='https://doi.org/10.1016/j.dss.2025.114542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affable design is increasingly employed in AI conversational agents to foster smoother interaction and enhance user experience. However, a growing concern is that this overemphasis on social appeal often overlooks corrective interventions, particularly when users hold false or biased beliefs. Such omissions carry the risk of reinforcing user misconceptions and ultimately undermining the effectiveness of human–AI collaboration. Drawing upon the attribution theory, this study investigates whether the error-correction behavior of AI agents offset these risks and improve user engagement. Empirical evidence from three experimental studies verifies that AI agents' error-correction behavior indeed enhances users' perceived responsibility of AI agents and strengthens their engagement intentions. This effect does not appear to compromise social comfort, especially in the context where responsibility takes precedence, such as healthcare. This study further finds that the high expertise of AI agents amplifies the positive effects of error-correction behavior, while high entitativity diminishes these effects by blurring AI agents' responsibility. These findings offer important guidance for designing responsible AI agents and highlight the value of AI error-correction behaviors in human-AI interaction.},
  archive      = {J_DSS},
  author       = {Yunchang Zhu and Xianghua Lu},
  doi          = {10.1016/j.dss.2025.114542},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114542},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Being responsible or affable: Investigating the effects of AI error correction behaviors on user engagement},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emotion aware session based news recommender systems. <em>DSS</em>, <em>198</em>, 114540. (<a href='https://doi.org/10.1016/j.dss.2025.114540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News recommender systems are decision support systems that exploit user-article interactions over a short duration of time to discover users’ interests and predict unseen news articles to generate a ranking of news articles that are relevant and interesting. In the news recommendation scenario, the relevance of articles decays quickly, and fresh articles are generated daily. Session based models are proposed using time-aware approaches to exploit interactions sequentially. Prior news recommender systems do not consider emotional information expressed in news articles within sessions for recommendations. Emotions play a key role in supporting decision-making and emotionally charged headlines can evoke curiosity or urgency, prompting users to click on certain articles. This paper presents an innovative decision support system for session based news recommendation, using expressed emotions from news articles, such as expressed in the title, abstract, and text, to improve user decision-making. We introduce a novel methodology that incorporates expressed emotions into three session based news recommendation models. Our results demonstrate that expressed emotion carries valuable information to improve session based news recommenders on various ranking metrics significantly and proved especially beneficial in scenarios with limited user interaction history, addressing the cold-start problem. The results show significant improvements in ranking metrics, emphasizing the utility of emotional features for dynamic decision-making support.},
  archive      = {J_DSS},
  author       = {Benjamin Gundersen and Saikishore Kalloori and Abhishek Srivastava},
  doi          = {10.1016/j.dss.2025.114540},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114540},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Emotion aware session based news recommender systems},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision support for integrated trade agent's procurement and sales planning under uncertainty. <em>DSS</em>, <em>198</em>, 114537. (<a href='https://doi.org/10.1016/j.dss.2025.114537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a trade agent decision optimization problem (TADOP), in which a trade agent (TA) selects a subset of retailers and suppliers to maximize its profit under uncertain demand and spot price. The TA operates between suppliers and retailers as a third-party platform and decide which subset of retailers to serve, taking into account capacity reservations with option suppliers in advance. Once demand and spot price are realized, the TA decides how much to procure from each channel to fulfill retailers' demand. The problem is formulated as a two-stage stochastic program. Due to the high complexity and large number of scenarios, we reformulate the problem as a set-partition model, where the master problem (MP) selects the combination of retailers to serve, and the subproblem (SP) identifies the optimal procurement plans, thus reducing the number of variables and constraints. To further enhance tractability, the SP is transformed into an equivalent shortest-path problem (SPP) to address issues of non-linearity and non-convexity. Experimental results demonstrate the effectiveness of the decomposition approach, providing TAs with a practical decision-making tool for procurement and sales. Furthermore, the insights gained into TAs' procurement and sales strategies across various scenarios offer valuable guidance for decision-making in uncertain supply chain environments.},
  archive      = {J_DSS},
  author       = {An Liu and Xinyu Wang and Jiafu Tang},
  doi          = {10.1016/j.dss.2025.114537},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114537},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Decision support for integrated trade agent's procurement and sales planning under uncertainty},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling hybrid firm relationships with graph neural networks for stock investment decisions. <em>DSS</em>, <em>198</em>, 114528. (<a href='https://doi.org/10.1016/j.dss.2025.114528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The highly volatile nature of the stock market makes predicting data patterns challenging. Significant efforts have been dedicated to modeling complex stock correlations to improve stock return forecasting and support better investor decision-making. Although various predefined intrinsic associations and learned implicit graph structures have been discovered, they have limitations in fully exploring and leveraging both types of graph information. In this paper, we proposed a Hybrid Structure-aware Graph Neural Network (HSGNN) framework. Unlike models that rely solely on predefined or learned graphs, HSGNN utilizes money-flow graphs to complementarily learn implicit graph structures and applies sparse supply-chain graphs to jointly enhance stock return forecasting. Extensive experiments on real stock benchmarks demonstrate our proposed HSGNN outperforms various state-of-the-art forecasting methods, offering a robust decision-support system for financial stakeholders.},
  archive      = {J_DSS},
  author       = {Yang Du and Biao Li and Zhichen Lu and Gang Kou},
  doi          = {10.1016/j.dss.2025.114528},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114528},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Modeling hybrid firm relationships with graph neural networks for stock investment decisions},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social capital matters: Towards comprehensive user preference for product recommendation with deep learning. <em>DSS</em>, <em>198</em>, 114527. (<a href='https://doi.org/10.1016/j.dss.2025.114527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommender systems help address data sparsity in user–product interactions by leveraging social relationships to infer user preferences. However, existing models often overlook the role of social capital that influence decision-making in social commerce. Social capital consists of structural, relational, and cognitive dimensions, all of which shape user preferences. To better understand these influences, we propose a multi-task learning framework named DeepSC that integrates social capital theory into preference modeling. Its user preference learning module extracts structural features through graph-based pre-training, learns relational features from dynamic user embeddings, and models cognitive features using a hypergraph attention network. Additionally, the dual graph-based product feature learning module enhances cognitive feature extraction by incorporating product co-interactions. DeepSC is optimized through a joint learning objective, combining point-wise and pair-wise learning with an auxiliary social link prediction task to refine user representations. Experiments on three e-commerce datasets demonstrate that DeepSC significantly outperforms the state-of-the-art recommendation models, highlighting the effectiveness of integrating social capital into social preference learning. Our research advances social recommendation by providing a social capital theory-driven approach to modeling user behavior in digital commerce.},
  archive      = {J_DSS},
  author       = {Weiyue Li and Ming Gao and Bowei Chen and Jingmin An and Yeming Gong},
  doi          = {10.1016/j.dss.2025.114527},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114527},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Social capital matters: Towards comprehensive user preference for product recommendation with deep learning},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cybersecurity risk assessment using temporal knowledge graph-based explainable decision support system. <em>DSS</em>, <em>198</em>, 114526. (<a href='https://doi.org/10.1016/j.dss.2025.114526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing cybersecurity policies is crucial for any organization to combat evolving cyber threats. The absence of a comprehensive dataset has prevented previous studies from analyzing the risk of organizations’ cybersecurity policies. Past studies have not considered temporal information in the policies. Analysis of cybersecurity policies using attention mechanism requires automated determination of optimal number of attention units which remains unaddressed. Moreover, absence of interpretation in cybersecurity studies creates a barrier to understanding policy vulnerabilities and developing targeted solutions. To address these challenges, we develop a decision support system which (i) enhances risk classification of organization’s cybersecurity policies, (ii) develops a comprehensive cybersecurity policy dataset from the websites of 190 companies, transformed into a knowledge graph to capture entity relationships among various policies, (iii) integrates temporal information into the knowledge graph by incorporating time stamps from event sequences in cyberattack information, (iv) develops Explainable Factor Analysis based Multi-Head Attention mechanism, which automates the determination of the optimal number of attention units and optimizes data allocation across attention units using factor analysis, and (v) utilizes attention heatmaps and shapley values for interpretability. Our cybersecurity policy dataset is used as a case study with four benchmark datasets for further validation. Results reveal that our model outperforms the other state-of-the-art, achieving an 87.78% F 1 score, followed by robustness checking and statistical significance testing. Finally, Shapley values are used to interpret the model’s output to identify vulnerabilities within the organizational policies, providing crucial insights enabling decision-makers to enhance their cybersecurity policies and mitigate potential threats.},
  archive      = {J_DSS},
  author       = {Subhajit Bag and Sobhan Sarkar and Indranil Bose},
  doi          = {10.1016/j.dss.2025.114526},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114526},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Enhancing cybersecurity risk assessment using temporal knowledge graph-based explainable decision support system},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A field study on the impact of the counter ad-blocking wall strategy on user engagement. <em>DSS</em>, <em>198</em>, 114525. (<a href='https://doi.org/10.1016/j.dss.2025.114525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ad-blocking tools prevent ads from being shown to web users. Their increasingly widespread usage poses an existential risk to online publishers who provide free content and rely on display ads for revenue. Studies on counter ad-blocking strategies taken by publishers are limited, especially with regard to how these strategies affect user engagement, thus posing additional uncertainties to the selection of a suitable counter ad-blocking strategy. Through a randomized field experiment with a large global publisher, our study seeks to understand how the two most common counter ad-blocking strategies, (i) Wall and (ii) Acceptable Ads Exchange (AAX), affect user engagement differently. Our results show that the Wall strategy causes a lower overall engagement compared to AAX, mainly due to users who refuse to whitelist and leave the website. Over time, the negative impact increases, albeit at a slower speed. Furthermore, heavier users, identified based on the amount of engagement in the pre-treatment period, are less affected by the Wall strategy than lighter users; instrumental users, who read for practical purposes, are less affected than entertainment users. Finally, the Wall strategy has a bigger negative impact on the engagement of popular and new articles, compared to niche and old articles, respectively, as observed by a longer tail in engagement distribution with respect to content. These results on the heterogeneous effects of counter ad-blocking strategies on engagement offer novel and important managerial implications on a publisher’s choice of counter ad-blocking strategy and editorial decisions.},
  archive      = {J_DSS},
  author       = {Michael K. Chen and Shuai Zhao and Cristian Borcea and Yi Chen},
  doi          = {10.1016/j.dss.2025.114525},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114525},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A field study on the impact of the counter ad-blocking wall strategy on user engagement},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-platform rumor detection framework considering data privacy protection and different detection capabilities of online social platforms. <em>DSS</em>, <em>198</em>, 114524. (<a href='https://doi.org/10.1016/j.dss.2025.114524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anonymity and widespread popularity of online social platforms (OSPs) allow users to share uncertain posts freely, leading to numerous rumors. Similar rumors spread widely across OSPs, resulting in frequent cross-platform rumors (CPRs). Owing to the unique nature of the cross-platform spread, the dual challenges of data privacy protection constraints and differences in the data and detection capabilities of OSPs exacerbate the difficulty of CPR detection. Thus, to detect CPRs effectively, we designed and implemented a novel deep learning framework named Cross Platform Rumor Detection based on Improved Federated Learning (CPRDIFL), which integrates and improves federated learning and the pre-trained Masked and Contextualized BERT (MacBERT). Our framework uses FL to analyze data from OSPs independently, thus avoiding the need for data integration and ensuring the data privacy protection of OSPs. Moreover, MacBERT is deployed on the clients of CPRDIFL to extract contextual features from posts and dynamically update local weights based on the data and detection performance. Weight parameters are dynamically shared between clients and servers and between clients to achieve complementary advantages across OSPs. Our framework was used in six comprehensive experiments in different scenarios, and the experimental results showed that it achieved the best results in CPR detection. This study not only provides an effective solution for CPR detection but also marks a significant step toward the automated detection of cross-OSP information pollution.},
  archive      = {J_DSS},
  author       = {Xuelong Chen and Jinchao Pan},
  doi          = {10.1016/j.dss.2025.114524},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114524},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A cross-platform rumor detection framework considering data privacy protection and different detection capabilities of online social platforms},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="eaai">EAAI - 106</h2>
<ul>
<li><details>
<summary>
(2025). A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting. <em>EAAI</em>, <em>162</em>, 112517. (<a href='https://doi.org/10.1016/j.engappai.2025.112517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electric load forecasting remains challenged by the dual requirements of accuracy and robustness due to the combined effects of strong seasonality, multi-scale spikes, and stochastic disturbances. To address this, we propose a novel multi-scale forecasting framework, NP-WavKAN-Fusion, which integrates Neural Prophet for data decomposition and a Wavelet-based Kolmogorov–Arnold Network (WavKAN) with learnable wavelet kernels for multi-scale encoding. This fusion model utilizes a Bi-directional Gated Recurrent Unit (BiGRU) to capture long-term temporal dependencies and an adaptive feature fusion gate (AFF) to dynamically re-weight static and dynamic features for final load predictions. Extensive experiments on two public datasets from Australia and Morocco show that NP-WavKAN-Fusion consistently outperforms traditional models, reducing the mean absolute error by at least 30 %. For multi-step forecasting tasks, NP-WavKAN-Fusion maintains error inflation within 15 %, demonstrating superior performance compared to state-of-the-art long-sequence models such as Informer and PatchTST. The Diebold–Mariano test confirms that NP-WavKAN-Fusion yields statistically significant improvements, with 19 out of 20 comparisons showing lower errors. Ablation studies show that removing either the Neural Prophet component or the AFF significantly increases the forecasting error, validating the necessity of our layered denoising and fusion strategies. The proposed NP-WavKAN-Fusion framework demonstrates strong potential for real-world applications in electric load forecasting, offering robust performance under various temporal and non-stationary conditions.},
  archive      = {J_EAAI},
  author       = {Chunliang Mai and Lixin Zhang and Xuewei Chao and Xue Hu and Omar Behar},
  doi          = {10.1016/j.engappai.2025.112517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks. <em>EAAI</em>, <em>162</em>, 112465. (<a href='https://doi.org/10.1016/j.engappai.2025.112465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-isothermal plastic deformation creates modeling challenges for constitutive model development. Current constitutive models challenge to capture the coupled microstructural changes that occur when temperature varies during processing. The Micro-Mechanism Informed Artificial Neural Network (MMIANN) framework was developed to address these limitations using artificial intelligence (AI) and machine learning (ML) techniques. The MMIANN framework combines physics-based evolution equations for key metallurgical processes—dislocation density, grain boundary migration, and precipitation kinetics—with neural network predictions. These micro-mechanisms operate as internal state variables that guide the network's material behavior predictions. The architecture uses parallel physics-based and neural pathways, blended through adaptive coefficients. Thermodynamic constraints maintain consistency through penalty-based enforcement of the Clausius-Duhem inequality. The model was trained and validated using experimental data from simultaneous cooling and tensile deformation of AA7075 aluminum alloy. The tests replicated industrial hot forming conditions with cooling rates from 25 to 75 °C per second (°C/s). This experimental approach captures the thermal-mechanical coupling that drives microstructural evolution in practice. MMIANN achieved correlation coefficients exceeding 0.96 for stress, temperature, and grain size predictions. The framework captures thermomechanical regimes. Processing maps generated by the AI model link process parameters to microstructural outcomes. The analysis reveals an optimal processing window (40–55 °C/s cooling, 0.15–0.25 strain ( ε )) and identifies three regimes where different strengthening mechanisms dominate. By integrating metallurgical science with machine learning, this framework provides a practical tool for non-isothermal manufacturing processes. The approach bridges microstructural understanding with process control for thermal-mechanical operations through the application of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Yo-Lun Yang and Tsai-Fu Chung and Chia-Hung Liao and Liang-Yu Chen and Hsing-Yu Wu and Uthayakumar Marimuthu and Arumugaprabu Veerasimman and Sundarakannan Rajendran and Vigneshwaran Shanmugam},
  doi          = {10.1016/j.engappai.2025.112465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery. <em>EAAI</em>, <em>162</em>, 112461. (<a href='https://doi.org/10.1016/j.engappai.2025.112461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring of complex industrial systems is critical for ensuring operational reliability. Data-driven methods using artificial intelligence have advanced anomaly detection (AD) and fault diagnosis (FD), but existing approaches often treat them separately, focus on known faults, and struggle with previously unseen or rare conditions in multi-modal scenarios. This study proposes a novel condition monitoring framework that integrates AD and FD within a distributed architecture. Lightweight models—including kernel principal component analysis, support vector machines, and one-dimensional convolutional neural networks—enable efficient and scalable processing. A multilevel information fusion strategy ensures consistent detection and diagnosis while facilitating the isolation of previously unknown faults. Module test results demonstrate the effectiveness and robustness of the proposed feature extraction and adaptive modeling approaches. The overall test results for previously unknown faults vary across channels and modules. For samples with misalignment and inner blade wear, channel-level detection accuracy ranges from 0.007 to 0.989, with unknown recognition rates up to 0.933 and diagnosis probabilities from 0.508 to 0.933. For strong misalignment and fan-end inner race faults, nearly all channels achieve 100 % detection accuracy, with some diagnosis probabilities above 0.9, while unknown recognition remains minimal (mostly below 0.05). Importantly, the proposed framework integrates detection and diagnostic outputs across channels, effectively mapping previously unseen faults to similar known categories or to an unknown category. Overall, the proposed framework offers a referenced solution for condition monitoring of industrial systems like pumps, turbines, and compressors, and lays the foundation for future improvements incorporating domain knowledge and model-driven interpretability.},
  archive      = {J_EAAI},
  author       = {Yingqian Liu and Rongyong Zhang and Luigi Grossi and Zhipin Ye and Huairui Li and Rongsheng Zhu and Qiang Fu},
  doi          = {10.1016/j.engappai.2025.112461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite element-integrated neural network framework for spatial modal prediction in machine tool structures. <em>EAAI</em>, <em>162</em>, 112456. (<a href='https://doi.org/10.1016/j.engappai.2025.112456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of position-dependent structural dynamics in (CNC) machine tools is critical for ensuring machining precision, avoiding resonance, and enabling real-time health monitoring. This study proposes an integrated framework combining finite element analysis (FEA), experimental modal testing, and artificial neural networks (ANNs) to model and predict position-dependent dynamics across the machine workspace. A validated FEA model of a high-rigidity vertical machining centre is developed and correlated with experimental modal analysis using a PCB 086D20 impact hammer and tri-axial accelerometer. Natural frequencies and mode shapes are extracted and compared, showing deviation under 10 %, confirming model fidelity. To capture position-dependent dynamics, modal analysis was performed at 27 spatial locations, revealing significant frequency variation across planes, indicating localized compliance zones. A multilayer ANN is trained on the modal dataset to predict frequencies based on spatial coordinates, achieving R 2 values above 0.99. The proposed hybrid approach enables real-time estimation of structural dynamics, reducing the need for repeated testing and supporting intelligent control strategies in large-format CNC systems. This work contributes a predictive foundation for dynamic stability optimization, resonance avoidance, and digital twin development in precision machining applications.},
  archive      = {J_EAAI},
  author       = {Aman Ullah and Tzu-Chi Chan and Jun-Fa Huang and Shinn-Liang Chang},
  doi          = {10.1016/j.engappai.2025.112456},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112456},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite element-integrated neural network framework for spatial modal prediction in machine tool structures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach. <em>EAAI</em>, <em>162</em>, 112450. (<a href='https://doi.org/10.1016/j.engappai.2025.112450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanofluids have garnered significant research interest due to their enhanced heat transfer and thermal characteristics. A novel hybrid nanofluid has exhibited exceptional thermal properties, combining five nanoparticles of uniform shapes with a base fluid, such as blood. This study investigates the influence of fin thickness, varying with length, considering the implications of internal heat production, convection, and thermal radiation processes in rectangular, convex, and triangular fin descriptions. Wet scenarios are interpreted to evaluate differences in thermal energy dynamics for fin shapes like Rectangular, Convex and Triangular. Darcy's model is employed to account for the material's porous nature. A finite difference scheme, implemented using Partial Differential Equation solver (PDSolve) in Maple (2024), provides graphical insights into fin effectiveness and thermal steady-state responses across various parameters. Incorporating Penta hybrid nanofluids enhances fin performance, with rectangular fins' Nusselt numbers (up to 1.936) proving more efficient, delivering faster thermal responses than triangular fins and convex fins. Further, using the Adam Optimisation algorithm, Convolutional Neural Networks were used to validate the current model. It was observed that these networks could accurately forecast the truth values, and the two findings matched, as indicated in Table 3 As a potential biological application, this research offers insight into optimising cooling systems for biomedical devices, such as heat exchangers in artificial organs.},
  archive      = {J_EAAI},
  author       = {Maddina Dinesh Kumar and Nehad Ali Shah and Dharmaiah Gurram and Se-Jin Yook},
  doi          = {10.1016/j.engappai.2025.112450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced multi-modal emotion recognition using the feature level fusion. <em>EAAI</em>, <em>162</em>, 112447. (<a href='https://doi.org/10.1016/j.engappai.2025.112447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal human emotion recognition is a complex process of synthesizing information from various modalities to calculate emotion states. This field faces several challenges: (1) Acoustic is an essential component of emotion expression, but it often underperforms compared to visual and text in emotion recognition. (2) Capturing the feature interaction among different modalities is usually complex. (3) Processing high-definition videos can significantly reduce the efficiency of visual analysis. In this study, we presented a learning architecture designed to recognize human emotions effectively. For the first challenge, we implemented a multi-level acoustic encoder (MLAE) that enhances the extraction of acoustic information to improve the acoustic contribution in multi-modal emotion recognition. Facing the second challenge, we introduced the cross-attention block module, which adeptly captures the inter-modal interactions. To address the third challenge, we adopted the re-parameterized visual geometry group network (RepVGG) as the visual feature encoder, employing its multi-branch learning and single-branch reasoning structure to maintain high reasoning efficiency. Our model has demonstrated the state-of-the-art performance of the interactive emotional dyadic motion capture (IEMOCAP) dataset and the multi-modal opinion sentiment and emotion intensity of the Carnegie Mellon University (CMU-MOSEI) dataset.},
  archive      = {J_EAAI},
  author       = {Aziguli Wulamu and Yuheng Wu and Xin Liu and Yao Zhang and Jinghan Xu and Yang Zhang},
  doi          = {10.1016/j.engappai.2025.112447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced multi-modal emotion recognition using the feature level fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection. <em>EAAI</em>, <em>162</em>, 112446. (<a href='https://doi.org/10.1016/j.engappai.2025.112446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—Permanent magnet synchronous motors (PMSMs) are widely used in industrial applications but remain vulnerable to stator faults, such as inter-coil and inter-turn short circuits. Although recent deep learning-based fault detection methods have shown promise, they typically rely on large volumes of labelled fault data for training. To address this limitation, this paper proposes a novel unsupervised fault detection framework, termed Deep Adaptive Wavelet Autoencoder (DAWA) with Mutually Independent Empirical Cumulative Distribution (MIECD), specifically designed for PMSM fault detection. DAWA utilizes convolutional neural networks to learn adaptive wavelet filters through fast discrete wavelet transform, allowing for fully learnable, threshold-free extraction of fine-grained signal patterns. The resulting latent features are then mapped by MIECD into a mutually independent space via independent component analysis (ICA). Without assuming any prior data distribution, MIECD estimates empirical cumulative distributions (ECDs), computes tail probabilities across dimensions, and aggregates them into a unified anomaly score. Experimental results on motor vibration datasets demonstrate the effectiveness of the proposed method, showing average accuracy improvements of 15.85 % for Interturn and 15.16 % for Intercoil fault detection compared to conventional data-driven baselines across various operating conditions.},
  archive      = {J_EAAI},
  author       = {Pinze Ren and Ning Zhu and Dandan Peng and Liyuan Ren and Huan Wang},
  doi          = {10.1016/j.engappai.2025.112446},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112446},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention. <em>EAAI</em>, <em>162</em>, 112444. (<a href='https://doi.org/10.1016/j.engappai.2025.112444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health state prediction of Proton Exchange Membrane Fuel Cells (PEMFCs) is a critical technology to ensure their long-term reliable operation. Prediction accuracy directly influences the effectiveness of maintenance strategies and risk management. However, existing PEMFC degradation prediction methods based on Recurrent Neural Networks (RNNs) or Transformer architectures mostly focus on point estimation while neglecting uncertainty quantification. This limitation makes it difficult to assess the confidence level of predictions in practical engineering applications, reducing the models' reliability in decision support. To address this issue, this paper proposes a novel Bayesian Patch Time Series Transformer (B-PatchTST) method. By deeply integrating Bayesian variational inference with time series patch modeling, the method enables probabilistic prediction of PEMFC degradation trajectories and disentangled analysis of uncertainty sources. Unlike traditional Bayesian Neural Networks (BNNs) that primarily apply Bayesian modeling to fully connected layers, B-PatchTST introduces a Bayesian Self-Attention Mechanism, which models epistemic uncertainty in three stages: patch embedding, uncertainty-aware self-attention computation, and adaptive regularization. This design significantly enhances the credibility of the model. Extensive experiments on the fuel cell datasets demonstrate the proposed method's outstanding performance. It achieves an average reduction of 36.31 % in root mean square error and an average compression of 83.39 % in the 95 % confidence interval, significantly outperforming existing methods. This approach offers a trustworthy basis for predictive maintenance in PEMFC systems, promoting a shift from “experience-based maintenance” to “reliable prognostics” in hydrogen energy applications.},
  archive      = {J_EAAI},
  author       = {Mengyu Liu and Zhe Cheng and Yu Yang and Niaoqing Hu and Guoji Shen and Yi Yang},
  doi          = {10.1016/j.engappai.2025.112444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WeedNet-X: A lightweight field weed detection algorithm. <em>EAAI</em>, <em>162</em>, 112441. (<a href='https://doi.org/10.1016/j.engappai.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately distinguishing field weeds from crops and locating weed positions are critical prerequisites in automated weed control operations. However, weed detection and localization in unstructured field environments with complex lighting remains challenging. Firstly, data-driven deep learning based algorithms usually have a high dependence on a large number of training samples, and there are huge differences between field weeds and crops in different regions, growth cycles, and types. In addition, the conflict between hardware performance and computation cost makes it difficult for existing weed detection algorithms to maintain both detection accuracy and speed on low-performance platforms. All these problems increase the difficulty of detection. To solve the above problems, we first construct a medium-to-large weed dataset using an open-source agricultural image dataset and collect field data. Subsequently, we have proposed a lightweight weed detection algorithm using the ShuffleNetv2 network as the backbone network, with a multi-scale pyramid network, and the overall network algorithm is named WeedNet-X. The number of model parameters and the computational volume of the algorithm are only 0.57 million and 0.48 Giga floating point operations (GFLOPs), respectively. On the two constructed datasets, the mean Average Precision (mAP) of the algorithm can reach 86.31 % and 80.98 %, respectively, which are improved by 0.61 % and 3.10 % compared to the baseline model. Finally, the hardware and software systems for weed detection verify the excellence of the proposed algorithm in terms of practical performance.},
  archive      = {J_EAAI},
  author       = {Yong Li and Ao Ke and Zhiqiang Guo and Qingji Tan and Jingchao Yang},
  doi          = {10.1016/j.engappai.2025.112441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WeedNet-X: A lightweight field weed detection algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts. <em>EAAI</em>, <em>162</em>, 112440. (<a href='https://doi.org/10.1016/j.engappai.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent human-made conflict in 2022 severely damaged Ukraine's infrastructure, causing significant instability in the food supply chain. This crisis was further exacerbated by trade bans imposed on another major global wheat exporter. Since wheat production and export are intrinsically linked, particularly in times of crisis, it is essential to adopt the concept of an intertwined supply chain. Accordingly, this study proposes an intertwined supply chain framework for the production and export of wheat during long-term disruptions. To enhance the viability of this intertwined system, the study introduces three key strategies. First, it addresses long-term disruptions and operational risks by employing redundancies and data-driven robust optimization techniques, where uncertainty sets are generated using a support vector clustering model. Second, the proposed supply chain accounts for freshwater resource limitations by integrating water resilience measures. Third, as the framework operates within a global context, it incorporates a comprehensive model that considers exchange rates, taxation, foreign demand points, and international trade responsibilities. To optimize these strategies, two multi-objective optimization models are developed and solved using an epsilon-constraint method. A cardinality-based measure is introduced to efficiently represent the Pareto front, offering decision-makers valuable insights into non-dominated solutions. The results are divided into analyses of wheat production, export, and their combined network. Individual analyses assess network setup, viability, and uncertainty control, while the integrated analysis examines sensitivity and interdependence. Overall, improving water use, managing risks, and designing a resilient, interconnected system can greatly strengthen the wheat supply chain during long-term crises.},
  archive      = {J_EAAI},
  author       = {Hani Gilani and Mehrdad Mohammadi and Tom Van Woensel and Hadi Sahebi},
  doi          = {10.1016/j.engappai.2025.112440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network. <em>EAAI</em>, <em>162</em>, 112438. (<a href='https://doi.org/10.1016/j.engappai.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of carbon trading prices (CTPs) with spikes is crucial for developing carbon emission reduction policies and planning corporate investments. However, most existing CTP approaches usually focus on designing a cutting-edge model without considering spike prediction. Therefore, this paper presents a novel heuristic optimization-based hybrid model framework for CTP prediction with spikes. First, random forest is exploited to identify the relevant features of spikes and non-spikes for CTPs, and categorical boosting is employed to predict the spike occurrences of CTPs. Then, a novel hybrid model based on multiple linear regression, categorical boosting, and two dimensions convolutional neural network and bidirectional gated recurrent unit with multi-head regularized attention mechanism (2DCNN-BiGRU-MRA) is proposed to predict spikes and non-spikes for CTPs. In this model, multiple linear regression and categorical boosting are respectively applied to capture the linear and complex nonlinear features of the CTPs, in which their prediction results and deviations are integrated into the 2DCNN-BiGRU-MRA model as relevant features. The proposed 2DCNN-BiGRU-MRA can learn the spatiotemporal features and enhance representation capabilities by introducing 2DCNN, BiGRU, and MRA, thereby improving the accuracy of CTP prediction. In addition, to construct appropriate model hyperparameters of 2DCNN-BiGRU-MRA, the strength honey badger algorithm based on the adaptive momentum estimation is proposed to optimize the hyperparameters of 2DCNN-BiGRU-MRA. Finally, the proposed framework is tested on the actual data of European Union emissions trading and the carbon market in Hubei, China, and case studies have confirmed the superiority and achievable local interpretability of the proposed hybrid model framework.},
  archive      = {J_EAAI},
  author       = {Rongquan Zhang and Siqi Bu and Gangqiang Li and Min Zhou},
  doi          = {10.1016/j.engappai.2025.112438},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112438},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time spatiotemporal error compensation framework for face gear grinding. <em>EAAI</em>, <em>162</em>, 112429. (<a href='https://doi.org/10.1016/j.engappai.2025.112429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric and thermal errors critically affect the precision of face gear grinding, yet current modeling approaches are computationally intensive and lack real-time adaptability. This study proposes a real-time spatiotemporal error compensation framework for face gear grinding. A closed-loop feedback mechanism is introduced to adaptively update compensation intensity based on residual error feedback, ensuring robustness and efficiency under fluctuating machining conditions. Moreover, a novel spatial-temporal thermal error model is developed by integrating Taylor-graph convolutional network and modified-long short term memory network to capture both node-level spatial fusion and long-term temporal dependencies. High-order terms in geometric error modeling are eliminated using a vector decomposition and truncation-based approach, significantly reducing computational complexity. Furthermore, a high-efficiency multi-source error-tooth flank mapping model is developed based on vector decomposition and truncation function methods, enabling accurate prediction with reduced computational cost. To identify dominant error contributors, an improved Morris-based sensitivity analysis method is integrated, distinguishing geometric and thermal errors affecting tooth flank deviation. Experimental results demonstrate sub-65 ms real-time response, 24.2 μm maximum error reduction, and robust adaptability under fluctuating machining conditions. Compared with recent gear-flank compensation studies, the proposed closed-loop framework achieves a 63.4 % reduction in maximum normal flank error under real machining and <65 ms response latency. This level is comparable to reported reductions based on grid-aggregated metrics in spiral bevel gears (76.82 % reduction of the sum of absolute grid errors), while additionally ensuring real-time, delay-aware execution. These findings validate the proposed system's potential for precision, real-time compensation in multi-axis manufacturing environments.},
  archive      = {J_EAAI},
  author       = {Jialan Liu and Chi Ma and Mingming Li and Jialong He and Giovanni Totis and Chunlei Hua and Gangwei Cui and Liang Wang and Ruijun Xue and Zhi Tan and Jun Yang and Kuo Liu and Yuansheng Zhou and Jianqiang Zhou and Xiaolei Deng and Shengbin Weng},
  doi          = {10.1016/j.engappai.2025.112429},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112429},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time spatiotemporal error compensation framework for face gear grinding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting. <em>EAAI</em>, <em>162</em>, 112426. (<a href='https://doi.org/10.1016/j.engappai.2025.112426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To optimize joint performance, a finite element (FE) model is developed based on low-cycle reciprocating load tests of latticed concrete-filled steel tubular (CFST) column-composite box girder joints. The FE-predicted hysteresis curves are compared with test results to verify model accuracy, and a data set is established accordingly. Extreme Gradient Boosting (XGBoost) algorithm is used for training and prediction, and compared with the traditional machine learning (ML) algorithm, the superiority of the XGBoost algorithm is manifested. The XGBoost algorithm is then used to predict the damage and energy values of the joint under more different parameter combinations, with the largest ratio of damage value to energy dissipation value selected as the optimal combination of the joints within the variation range of the six parameters. The results show that the FE model correlates well with the test results and can therefore be used to generate a data set. The prediction accuracy of XGBoost algorithm has high accuracy of more than 99 % in predicting damage and energy dissipation values and can thus be used for joint prediction research. Compared with other ML algorithms, XGBoost has the best prediction performance and superiority. Within the variation range of the six parameters, the ratio of damage value to energy dissipation value is the largest when the concrete strength, longitudinal bar diameter, concrete slab thickness, box girder strength, axial compression ratio, and transverse stiffener strength are respectively 30 Mega Pascal (MPa), 12 mm (mm), 90 mm, 390 MPa, 0.3, and 455 MPa.},
  archive      = {J_EAAI},
  author       = {Zhi Huang and Xin Deng and Juan Chen and Xiang Li and Lizhong Jiang and Yohchia Frank Chen and Yuner Huang and Lin Chen},
  doi          = {10.1016/j.engappai.2025.112426},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112426},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions. <em>EAAI</em>, <em>162</em>, 112423. (<a href='https://doi.org/10.1016/j.engappai.2025.112423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is a critical technique for enhancing the reliability and security of rotating machinery. Existing diagnosis methods still have restricted generalization performance under speed variations owing to inadequate utilization of multisensor information. To address this problem, a novel feature-decision dual fusion network is proposed for fault diagnosis of rotating machinery under varying speed conditions. First, for each sensor, the frequency information learner is built to simultaneously extract global and local frequency domain features using global and local feature encoders. These features are then fused through a cross-attention mechanism to generate a sensor-specific initial classification decision. Subsequently, these individual sensor-wise decisions are fed into the decision dynamic ensemble to yield final fault diagnosis result. Moreover, an adaptive optimization strategy is designed to guide model learning generalizable features by flexibly adjusting the sensor loss weights during training. Finally, the effectiveness of the proposed method is validated on bearing and gearbox datasets. Experimental results demonstrate that the proposed method exhibits superior generalization and robustness for fault diagnosis under varying speed conditions.},
  archive      = {J_EAAI},
  author       = {Qi Deng and Zuoxiu Zhang and Xuyuan Tu and Zimuzhi Wang and Jun Wu},
  doi          = {10.1016/j.engappai.2025.112423},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112423},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning based solar cells defect detection using electroluminescence images. <em>EAAI</em>, <em>162</em>, 112421. (<a href='https://doi.org/10.1016/j.engappai.2025.112421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar cells are the fundamental core energy harvesting components in photovoltaic (PV) power generation stations. In view of the capability of detecting the invisible defects, the electroluminescence (EL) imaging is broadly used in the production lines of solar cells, based on which the deep learning technique is introduced to implement automatic defect detection and classification. However, the current deep learning models feature high complexity and require much computation resources, which are difficult to deploy in edge devices for real time applications. To tackle this issue, we proposed a novel lightweight and high-precision deep learning model named Cross Stage Partial Photovoltaic-You Only Look Once (CSPV-YOLO) based on the deep learning framework You Only Look Once v5 (YOLOv5) to enable the real-time solar cell defect detection. Firstly, a new module Cross Stage Partial C5 (CSPC5) is proposed to replace the initial C3 module in the YOLOv5 network to enhance the network accuracy in recognizing different types of defects. Secondly, a novel Spatial Pyramid Pooling with Cross Stage Partial (SPPFCSP) module is designed to replace the original Spatial Pyramid Pooling Fast (SPPF), which boosts the network feature extraction capabilities from defect targets at multiple scales and facilitates a more efficient integration of multiscale features. Finally, the original loss function of YOLOv5 is replaced by the Scylla intersection over union (SIoU) function to optimize the training model. The proposed models have been validated and intensively compared with many other state-of-the-art models on two public datasets. Firstly, results of experiments on the public Pascal Visual Object Classes (PASCAL VOC) 2007 datasets demonstrate that the proposed SPPFCSP block is obviously superior to other Spatial Pyramid Pooling blocks for the most state-of-the-art YOLO detectors, which can significantly improve the detection accuracy. The comparison results of experiments on the public Photovoltaic Electroluminescence Anomaly Detection Dataset (PVEL-AD) that includes 12-class defects obviously indicate that the proposed CSPV-YOLO model is better than many state-of-the-art models and achieves 91.5 % average precision (AP) and frames per second (FPS) of 177.8 on with only 2.2 million (M) parameters. Hence, it is suitable for the deployment on edge devices for real-time applications.},
  archive      = {J_EAAI},
  author       = {Zhicong Chen and Tianxiang Chen and Haoxin Zheng and Lijun Wu and Shuying Cheng and Peijie Lin},
  doi          = {10.1016/j.engappai.2025.112421},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112421},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight deep learning based solar cells defect detection using electroluminescence images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates. <em>EAAI</em>, <em>162</em>, 112416. (<a href='https://doi.org/10.1016/j.engappai.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Light Guide Plate-DETR (LGP-DETR), an end-to-end object detection model tailored for identifying surface defects in light guide plates (LGPs). To address challenges such as low contrast, small target size, and complex backgrounds in industrial settings, LGP-DETR integrates three key components: Deformable Transformer Fusion Layer (DtransFusion), a deformable attention-based fusion module for capturing multi-scale features; Upsampling by Dynamic Sampling (DySample), a dynamic upsampling strategy for edge detail preservation; and OrthoC3, a channel attention module that suppresses background noise through orthogonal feature enhancement. We adopt FasterNet as a lightweight convolutional backbone to achieve a balance between accuracy and efficiency. Experimental results on a real-world LGP defect dataset demonstrate that LGP-DETR achieves a mean Average Precision (mAP) of 97.9 % and inference speed of 60 frames per second (FPS), significantly outperforming existing models. Furthermore, generalization tests on a fiberglass fabric defect dataset confirm the model's adaptability to different industrial domains. These findings validate the practical applicability and robustness of the proposed deep learning framework for industrial visual inspection.},
  archive      = {J_EAAI},
  author       = {Shuangning Liu and Cunling Liu and Junfeng Li},
  doi          = {10.1016/j.engappai.2025.112416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient interactive segmentation of three-dimensional gaussians with optimal view selection. <em>EAAI</em>, <em>162</em>, 112413. (<a href='https://doi.org/10.1016/j.engappai.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) scene representation has advanced rapidly in recent years, drawing the focus of more researchers. One of the main challenges for researchers is quickly and accurately segmenting 3D objects. Previous work has achieved excellent segmentation accuracy, but retraining requires a significant amount of time. Additionally, most methods fail to provide users with an efficient and convenient segmentation experience. To address these issues, we present Efficient Interactive Segmentation of 3D Gaussians (EISG), an efficient interactive segmentation method that eliminates the need for lengthy retraining. We first design an optimal view selection (OVS) method. This method uses 3D Gaussian entropy and image uncertainty to evaluate the quantity of view information. OVS helps users quickly select the optimal segmentation view, thereby enhancing interaction efficiency. Secondly, we use projection to find the target foreground rapidly and then segment the approximate objects using a clustering algorithm. Thirdly, we design a spatial-color background filter (SCBF) using the depth and color of 3D Gaussians. SCBF enables precise segmentation without needing retraining. Our method has been systematically tested on multiple datasets. Compared to other methods, the results demonstrate that EISG achieves ideal accuracy while significantly reducing processing time.},
  archive      = {J_EAAI},
  author       = {Yongtang Bao and Chengjie Tang and Yuze Wang and Yutong Qi and Ruijun Liu},
  doi          = {10.1016/j.engappai.2025.112413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient interactive segmentation of three-dimensional gaussians with optimal view selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification. <em>EAAI</em>, <em>162</em>, 112411. (<a href='https://doi.org/10.1016/j.engappai.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correctly identifying power quality disturbance (PQD) is crucial for the proper functioning of power systems. Deep learning (DL) techniques have been widely used for PQD classification due to their excellent performance. However, DL models are susceptible to adversarial attacks, posing a serious security threat to DL-based PQD classification systems. This issue has received limited attention in current research. In this study, we first utilize a convolutional neural network (CNN) to recognize various types of PQD signals. To evaluate model robustness, we introduce a black-box attack method for PQD classification based on the variance-tuning momentum iterative fast gradient sign method (VMI-FGSM). VMI-FGSM integrates a variance tuning method into the iterative process of the momentum iterative fast gradient sign method (MI-FGSM) , thereby producing more transferable adversarial PQD signals. To defend against such attacks, we propose a perturbation removal defense based on a generative adversarial network (PRD-GAN). This approach is capable of removing perturbations from adversarial PQD signals before they are recognized by the target classification model. Experiments demonstrate that VMI-FGSM produces adversarial perturbations that are nearly identical to those of the advanced MI-FGSM, but its adversarial examples are significantly more effective at misleading the target CNN model. Furthermore, the proposed PRD-GAN effectively reconstructs adversarial PQD signals into clean forms under various black-box attack intensities and outperforms the multi-level denoising autoencoder (ML-DAE) in defense performance due to its superior reconstruction capability.},
  archive      = {J_EAAI},
  author       = {Xiudong Zhang and Congmei Jiang and Mingbiao Yu and Xiankui Wen and Jing Zhang and Na Rong and Song Han},
  doi          = {10.1016/j.engappai.2025.112411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence. <em>EAAI</em>, <em>162</em>, 112409. (<a href='https://doi.org/10.1016/j.engappai.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective resource management is crucial for the operation of dynamic Cyber–Physical Systems (CPS), yet traditional static or rule-based approaches often fail to handle their inherent complexity. This paper presents a novel Artificial Intelligence (AI)-driven framework for adaptive resource management, defined as the capability to autonomously adjust resource allocation by proactively forecasting future demands and dynamically optimizing decisions in real-time. The framework integrates a suite of AI techniques, including time-series models like Long Short-Term Memory (LSTM), chosen for their ability to capture complex temporal dependencies, for demand prediction. For resource allocation, it employs advanced actor–critic reinforcement learning (RL) algorithms like Proximal Policy Optimization (PPO) and Deep Deterministic Policy Gradient (DDPG), selected for their stability and efficiency in complex decision-making tasks. Performance was rigorously evaluated in a simulated dynamic environment. Experimental results demonstrate that combinations leveraging LSTM’s predictive accuracy with the robust optimization of PPO and DDPG achieve superior performance and stability. Specifically, the LSTM+DDPG and LSTM+PPO configurations yielded the highest average rewards (0.964 and 0.942, respectively), significantly outperforming the fixed-strategy baseline (0.497) and other AI pairings. Furthermore, the feasibility of training prediction models in a distributed manner via Federated Learning (FL) is successfully demonstrated. This research highlights that a synergistic integration of suitable AI predictors and advanced RL agents provides a powerful and resilient solution for resource management in dynamic CPS.},
  archive      = {J_EAAI},
  author       = {Xiaofei Zhao and Fangling Guo and Amin Huang and Jieqiong Ding and Chi Yan and Wei Yuan and Yunqi Su and Quanzhou Li and Qianggang Zhang},
  doi          = {10.1016/j.engappai.2025.112409},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112409},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation. <em>EAAI</em>, <em>162</em>, 112408. (<a href='https://doi.org/10.1016/j.engappai.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based segmentation techniques have demonstrated significant potential in defect detection, which is vital for product quality. However, the existing models tend to specialize in detecting specific defect types, reducing their adaptability to a wider range of product defects, most existing methods rely on multi-scale or prototype learning to extract defect features, but still struggle with complex backgrounds, various interferences, and large intra-class variations. Additionally, the rarity of certain defects limits the availability of training samples. Herein, an innovative segmentation network, the Prior Knowledge-based and Texture-Enhanced Network (PTNet), is designed for few-shot industrial segmentation. The model is mainly composed of a self-guidance branch, a cross-guidance branch, and a texture enhancement module, enabling generalization across defect types with minimal labeled samples. Self-guidance extracts prior knowledge from the query image, while the cross-guidance branch extracts prior and prototype features from the masked support image. The texture information in the low-level features of the backbone is then enhanced by proposed texture enhancement module (TEM). Finally, the enhanced low-level texture information are fused with high-level semantic features, allowing the network to fully exploit both local details and global context before being decoded to restore the original image size. This enables the model to handle complex textures and generalize to unseen defect types. Extensive experimental results validate the effectiveness of the proposed modules. State-of-the-art performance is achieved in few-shot defect segmentation, with notable improvements in mean Intersection over Union (mIoU) of 46.05 % and 46.98 % under 1-shot and 5-shot conditions, respectively.},
  archive      = {J_EAAI},
  author       = {Xingyue Liu and Qian Wu and Yahui Cheng and Guojun Wen},
  doi          = {10.1016/j.engappai.2025.112408},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112408},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems. <em>EAAI</em>, <em>162</em>, 112407. (<a href='https://doi.org/10.1016/j.engappai.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of control actions is a critical challenge in industrial systems, especially when dealing with complex and unknown dynamics. Data collected from the environment enables the application of reinforcement learning techniques, which let the controller learn a policy based on data. This work proposes a novel model-free reinforcement learning approach that consists of a value iteration algorithm based on separate policy evaluation and policy improvement phases to provide an accurate control policy estimation. The proposed approach addresses tracking control for quadruple-tank water systems while obtaining minor tracking errors and faster transient responses. The results from the case study reveal better accurate estimation of the value function, up to 86.13% mean improvement in tracking accuracy and faster responses compared to existing methods. Therefore, the proposed approach demonstrates advantages in optimizing control performance and stands as a promising control method for industrial applications.},
  archive      = {J_EAAI},
  author       = {Eva Masero and Giacomo Mussita and Alessio La Bella and Riccardo Scattolini},
  doi          = {10.1016/j.engappai.2025.112407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion. <em>EAAI</em>, <em>162</em>, 112406. (<a href='https://doi.org/10.1016/j.engappai.2025.112406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health management of transmission parameters for railway signal equipment is a key link between intelligent operation and maintenance. As a core parameter of track circuits, ballast resistance significantly affects signal transmission. To accurately and reliably assess its health state, an ensemble learning algorithm (ELA) is introduced, tackling deviations of appraisal decision boundaries. Focusing on issues of complex weight calculation, model homogenization, and severe overfitting in ELA, an integration model based on an automatic weight allocation strategy (AWAS) is innovatively proposed, constructing a method for resistance estimations driven by information fusion, while maximizing its generalization ability. Firstly, for deterioration mechanism analysis of ballast resistance, a transmission state model for vehicle-ground collaboration is established, completing extractions of evolutionary rules. Secondly, the improved ELA leverages heterogeneous classifier optimization and automatic weighted soft voting, with its core ensemble strategy employing a secondary learner to map the fused datasets. Then, by means of data mining techniques, interpolation and denoising algorithms are applied to implement data preprocessing, facilitating the effective fusion of heterogeneous vehicle-ground information. Finally, based on occurrence of adverse conditions, an appropriate particle size is set to achieve state warning. The results indicate that the proposed AWAS for ballast resistance calculations can achieve 98.52 % testing accuracy and outperforms others.},
  archive      = {J_EAAI},
  author       = {Conghui Wang and Shiwu Yang and Chang Liu},
  doi          = {10.1016/j.engappai.2025.112406},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112406},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Future of humanity in an artificial intelligence centric world. <em>EAAI</em>, <em>162</em>, 112405. (<a href='https://doi.org/10.1016/j.engappai.2025.112405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This scholarly article rigorously investigates the transformative and disruptive roles of artificial intelligence (AI) in influencing the trajectory of human society. By concentrating on three fundamental sectors—healthcare, finance, and education—it evaluates the ways in which AI augments operational efficiency, facilitates intricate decision-making processes, and introduces innovative capabilities such as personalized medicine and automated financial systems. Concurrently, the analysis underscores urgent ethical dilemmas, encompassing algorithmic bias, accountability deficiencies, data privacy vulnerabilities, and workforce displacement. Employing real-world examples such as Deepfakes, and Neuralink, the article contextualizes emerging challenges within a dynamic socio-technical framework. The research offers a cohesive conceptual model that amalgamates technical, ethical, and governance aspects of AI, while presenting policy recommendations designed to promote transparency, equity, and human-centered AI development. The study emphasizes the necessity for reliable AI systems that humans can trust. The conclusions accentuate the immediate necessity for robust regulatory frameworks and sector-specific ethical supervision to ensure that advancements in AI are harmonized with the well-being of society.},
  archive      = {J_EAAI},
  author       = {Sunil Baloda and Monika Sharma and Mukesh Kumar},
  doi          = {10.1016/j.engappai.2025.112405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Future of humanity in an artificial intelligence centric world},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel federated deep learning for intrusion detection in smart grid cyber-physical systems. <em>EAAI</em>, <em>162</em>, 112404. (<a href='https://doi.org/10.1016/j.engappai.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of sophisticated computational, communicative, and physical elements in Smart Grid Cyber-Physical Systems (SGCPS) has greatly improved the efficiency and reliability of power grids. However, this complexity introduces enhanced cybersecurity risks, evidenced by significant cyberattacks on the Ukrainian power grid during 2015 and 2016. Despite progress in Artificial Intelligence (AI)-driven security solutions for SGCPS, practical deployment of these technologies is often limited due to a lack of high-quality attack data and owners’ hesitance to distribute sensitive details. This paper introduces an innovative strategy to fortify SGCPS against diverse network threats via a comprehensive intrusion detection system. We present a deep learning model leveraging a temporal convolutional network with multi-feature integration, aimed at robust threat identification. We also propose a federated learning framework enabling various SGCPS to jointly develop an extensive intrusion detection model, ensuring data privacy. Moreover, we incorporate a gradient compression technique utilizing the Long Short Term Memory- β -Total Correlation Variational Autoencoder (LSTM- β -TCVAE) model to enhance and secure model parameters throughout the training phase. Thorough experimental validations confirm the efficacy of our method in recognizing multiple cyber threat types to SGCPS and its advantages over current methods.},
  archive      = {J_EAAI},
  author       = {Rong Xie and Bin Wang and Xin Xu},
  doi          = {10.1016/j.engappai.2025.112404},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112404},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel federated deep learning for intrusion detection in smart grid cyber-physical systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection. <em>EAAI</em>, <em>162</em>, 112403. (<a href='https://doi.org/10.1016/j.engappai.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting crack leakages in shield tunnels is crucial for ensuring structural safety and extending service life, as traditional detection methods are limited by high subjectivity and low accuracy. To address these limitations, this paper proposes Tunnel-YOLO, an improved object detection algorithm based on You Only Look Once version 8 (YOLOv8). This algorithm replaces standard convolutional blocks with a novel Receptive Field Channel Attention Convolution (RFCAConv) module, which leverages dynamic receptive fields to enhance feature capture at different scales. We also introduce a C2f_SGE module, integrating the Spatial Group-wise Enhance (SGE) attention mechanism into the C2f (CSPNet with 2 convolutions) block to significantly improve feature extraction while suppressing background interference. Furthermore, an Edge Feature Enhancement Detection Head (EFE-Head) incorporates deconvolution layers to enhance fine-grained details for more precise boundary localization. To better accommodate the shape-sensitive detection task, our LeShape-IoU (Intersection over Union) loss function is designed to focus on the shape and scale characteristics of target bounding boxes. Experimental results on a public, real-world dataset demonstrate that Tunnel-YOLO significantly outperforms the baseline, increasing Recall, Precision, and mean Average Precision at 0.5 IoU (mAP50) by 15.7%, 10.3%, and 14.8%, respectively. Comparative analysis with other mainstream algorithms further validates the effectiveness and superiority of the proposed Tunnel-YOLO.},
  archive      = {J_EAAI},
  author       = {Ruijun Yang and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112403},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112403},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive active adaptive partial label learning under class distribution mismatch. <em>EAAI</em>, <em>162</em>, 112401. (<a href='https://doi.org/10.1016/j.engappai.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning is an important learning framework where each training sample is associated with a candidate label set and its ground-truth label is included in the candidate label set. Active partial label learning is a variation where training data consists of both labeled and unlabeled samples. However, there exists the problem of class distribution mismatch, wherein the unlabeled sample set contains many instances out of the target categories. In this paper, a contrastive active adaptive partial label learning method under class distribution mismatch which combines active partial label learning with contrastive coding is proposed. A novel active sample selection strategy is first established to use label propagation ability to measure the optimization ability of unlabeled samples to partially labeled samples. Furthermore, to solve the problem of class distribution mismatch, a joint query score based on contrastive coding is utilized to reduce the queries of unlabeled samples out of target categories. Finally, the above two indicators are combined adaptively to select the most valuable unlabeled samples in target categories for manual labeling and the selected samples will be added to the training sample set to train the new classifier. The effectiveness and efficiency of the method are evaluated by performing experiments on the datasets CIFAR10 and CIFAR100.},
  archive      = {J_EAAI},
  author       = {Aohan Zhang and Kezhen Dong and Hongying Zhang},
  doi          = {10.1016/j.engappai.2025.112401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive active adaptive partial label learning under class distribution mismatch},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection. <em>EAAI</em>, <em>162</em>, 112394. (<a href='https://doi.org/10.1016/j.engappai.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT (red-green-blue and thermal) salient object detection (SOD) aims to identify and highlight the most visually salient objects in an image by leveraging the complementary information from both RGB and thermal (TIR) modalities. It is particularly effective for 24/7 intelligent surveillance and autonomous perception in smart city security and traffic monitoring, especially under low light and adverse weather. However, existing methods primarily rely on manually aligned datasets, which are limited in handling the challenges posed by unaligned multi-modal data in real-world applications. Furthermore, these methods usually extract complementary information from both modalities using fixed-size windows (Liuet al., 2022, Wanget al., 2024b). However, such fixed-size windows are not effective in dealing with unaligned multi-modal images due to spatial inconsistencies. Additionally, existing methods often use single-layer high-level feature to represent semantic information, which fails to fully exploit the complementary benefits of multi-level features, thereby reducing the effectiveness of semantic guidance. To address these challenges, we propose a Hierarchical Semantics guided Multi-scale correlation Network (HSMNet) for alignment-free RGBT SOD. A Hierarchical Semantic Fusion Module (HSFM) dynamically assigns weights to features from multiple levels, enabling adaptive fusion of multi-level semantic information. A Multi-scale Asymmetric Correlation Module (MACM) employs windows of various sizes to capture asymmetric correlations between unaligned multi-modal data, enhancing cross-modal complementary information extraction even when data are not perfectly aligned. We conduct extensive experiments on unaligned, weakly aligned and aligned RGBT SOD datasets, with results demonstrating that our method outperforms state-of-the-art algorithms, achieving superior accuracy and robustness in both unaligned and weakly aligned RGBT SOD scenarios.},
  archive      = {J_EAAI},
  author       = {Chengmei Han and Lei Liu and Kunpeng Wang and Fei Xie and Bing Wei},
  doi          = {10.1016/j.engappai.2025.112394},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112394},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scientific machine learning for generic compact model parameter extraction of nanoscale transistors. <em>EAAI</em>, <em>162</em>, 112392. (<a href='https://doi.org/10.1016/j.engappai.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a framework to automate modelcard extraction of industry-standard compact models. This framework presents a Scientific Machine Learning (ScML) approach capable of inverse modeling. It integrates a random forest model with an artificial neural network to produce efficient and precise regression results. This new method is used for parameter extraction in the standard compact models of the semiconductor device industry. Modeling of a multi-gate Field Effective Transistor (FET) with an industry-standard compact model like Berkeley Short-channel Insulated-Gate Field-Effect Transistor Model – Common Multi-Gate (BSIM-CMG) is taken as an example to illustrate and describe the framework and highlight its key advantages. Proposed framework is useful in numerous aspects; it holds vital principles of physics, avoids depending on massive datasets, and has a sparse architecture while avoiding accuracy trade-offs. The framework is tested on production-level experimental devices to evaluate the real-world performance. This framework significantly reduces the time and cost of parameter extraction for the Process Design Kits (PDKs) development. Therefore, this is of immediate importance for fabrication and Electronic Design Automation (EDA) industries.},
  archive      = {J_EAAI},
  author       = {Kumar Sheelvardhan and Surila Guglani and Abhilash Dubey and Shashank Dubey and Sindhu Ramaswamy and Vaidy Subramanian and Kassandra Anderson and Glenn Workman and Sourajeet Roy and Avirup Dasgupta},
  doi          = {10.1016/j.engappai.2025.112392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scientific machine learning for generic compact model parameter extraction of nanoscale transistors},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks. <em>EAAI</em>, <em>162</em>, 112389. (<a href='https://doi.org/10.1016/j.engappai.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in communication technologies, remote monitoring and control of drug delivery are becoming prevalent in bio-medical engineering. In a chemotherapy system, the measurement signals can be wirelessly transferred to the control center by communication networks. Nevertheless, the avenues of communication might be jeopardized by false data injection (FDI), which poses significant risks to the security and stability of biomedical systems. In this work, a defense mechanism is developed to tackle the effect of FDI threats in the networked chemotherapy system. In particular, the effect of FDI attacks on the chemotherapy system is modeled by the Markov chain process. The proposed defense mechanism is designed in two parts: i ) a data-driven sliding mode observer (DDSMO) is utilized to identify the occurrence of cyber attacks in the tumor signals measured by the bio-sensor, and ii ) a mitigation scheme based on a dynamic rejection compensator (DRC) to compensate for the impact of cyber threats. In the mitigation phase, a goal representation heuristic dynamic programming (GrHDP) is adopted to adaptively adjust the parameters of DRC and to dynamically handle the cyber threats. The designed mitigation mechanism not only regulates the cancerous cells against cyber threats but also minimizes the side effects of drug delivery by regulating the output of normal cell and immune cell. Compared to prevalent methodologies, the proposed approach yields significant performance, including a 60.23 % improvement over the without protection, 37.48 % over the DDSMO-based model predictive controller (MPC), 35.95 % over the reinforcement learning (RL) based Kalman filter, and 70.44 % over the proportional integral (PI) based Kalman filter.},
  archive      = {J_EAAI},
  author       = {Mostafa Taheri and Juliang Yin and Zahra Rasooli Berardehi},
  doi          = {10.1016/j.engappai.2025.112389},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112389},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial. <em>EAAI</em>, <em>162</em>, 112386. (<a href='https://doi.org/10.1016/j.engappai.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain adaptive methods are becoming a growing focus of fault diagnosis, which can provide enhanced data support for models using the feature information from various source domains. As a most commonly used method, unsupervised multi-domain adaptive methods (UMA) can eliminate the requirement for the label of the target domain samples. However, the neglect of contributions from different source domains to the target domain and insufficient utilization of diagnostic information from multiple source domains are the widely limitation of UMA. Therefore, a dual-adversarial weighted multi-source domain unsupervised adaptive network (DAWMUN) is proposed to utilize diagnostic information from multi-source domains and consider the contribution of different source domains. Firstly, the shared feature extractor and dual adversarial training with the domain adversarial modules between multi-source domains and source-target domains are used to enhance domain confusion between multi-source and target domains (MSTD). Secondly, based on Multiple Kernel Maximum Mean Discrepancy (MK-MMD), a novel weighting mechanism and the corresponding training framework are constructed to effectively reduce negative transfer. Finally, a novel weighted classifier is proposed to merge the outputs of multiple classifiers and synthesize the impact of each source domain. The performance of the DAWMUN is validated using a rotating machinery dataset across various transfer tasks under different rotational speed and load conditions. The experimental results demonstrate that the diagnostic accuracy using the proposed DAWMUN is superior to existing SSDA and MSDA methods, with the average accuracies of 98.53 % and 98.23 % across six tasks in two separate experimental setups. The comparison to the existing methods results that the DAWMUN still demonstrates superior performance with improvements of 2.54 % and 2.86 %, respectively.},
  archive      = {J_EAAI},
  author       = {Wenqi Wang and Zongzhen Zhang and Jinrui Wang and Baokun Han and Huaiqian Bao and Zhikang Fan and Rongkang Ge},
  doi          = {10.1016/j.engappai.2025.112386},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112386},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information. <em>EAAI</em>, <em>162</em>, 112385. (<a href='https://doi.org/10.1016/j.engappai.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wave prediction is a critical challenge in ocean and coastal engineering, particularly for understanding and mitigating the effects of sea waves on structures such as ships, offshore platforms, and coastal defenses. A novel machine learning model, Twin-Stream Network (TSNet), is proposed to enhance wave prediction accuracy by leveraging temporal and spatial dependencies in historical data. The TSNet model along with other baseline models are evaluated, in both single-point and multi-point forecasting tasks, by various performance metrics across different datasets including one-dimensional-linear, one-dimensional-nonlinear, two-dimensional-linear and two-dimensional-nonlinear water waves. The comprehensive comparative analysis demonstrates that the TSNet model outperforms others, especially in the multi-point forecasting task. This study provides a valuable insight into the effectiveness of machine learning approaches and highlights the potential of the accuracy improvement for wave prediction.},
  archive      = {J_EAAI},
  author       = {Junhao Xu and Zhongying Feng and Zhan Wang and Kun Zheng and Ruipeng Li},
  doi          = {10.1016/j.engappai.2025.112385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning. <em>EAAI</em>, <em>162</em>, 112383. (<a href='https://doi.org/10.1016/j.engappai.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval enables efficient integration of information by linking different data modalities, such as images and text. As data volumes increase rapidly, the need for effective cross-modal interaction grows. Cross-modal hashing is favored for its low storage requirements and fast retrieval speed, but many existing methods depend on accurately labeled data, which can be subjective and expensive to obtain. To address this limitation, we propose Clean-guided Adaptive Weighted Contrastive Hashing (CAWCH), a novel framework designed to improve robustness against noisy labels. CAWCH incorporates two main components: a Gaussian Mixture Model (GMM)-based noise purifier that identifies reliable and noisy samples by modeling sample loss, and a contrastive learning strategy that selectively chooses positive samples and adaptively assigns weights based on multi-label similarity, considering both intra- and inter-modal relationships. Extensive experiments demonstrate that CAWCH significantly outperforms existing methods under noisy label conditions, highlighting its effectiveness and potential for real-world cross-modal retrieval applications.},
  archive      = {J_EAAI},
  author       = {Shuni Jiang and Zhixin Li},
  doi          = {10.1016/j.engappai.2025.112383},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112383},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network. <em>EAAI</em>, <em>162</em>, 112382. (<a href='https://doi.org/10.1016/j.engappai.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic flux leakage (MFL) signal denoising is essential for the nondestructive inspection of oil and gas pipelines, where complex noise interference can severely degrade defect quantification accuracy. Traditional approaches such as mean filtering and wavelet transform offer limited suppression of multi-type mixed noise and often distort critical features, including defect peaks and valleys. Even deep learning–based MFL denoising methods struggle in scenarios with substantial signal-noise overlap due to inadequate feature extraction and limited adaptability.This work presents an advanced denoising framework that combines dynamic feature fusion with a multi-scale autoencoder network. The framework jointly exploits time- and frequency-domain signal components, employing an adaptive weighting mechanism for dynamic feature fusion. Parallel convolutional branches extract multi-scale features, improving the capture of both global structures and fine-grained details, while a Squeeze-and-Excitation (SE) channel attention mechanism enhances defect-sensitive features and suppresses noise. Extensive experiments demonstrate that the proposed model outperforms mean filtering, wavelet denoising, and a baseline autoencoder, achieving notable gains in signal-to-noise ratio (SNR), mean squared error (MSE), and signal similarity. Beyond superior noise suppression, the method preserves critical defect characteristics, providing a robust and reliable foundation for precise defect quantification in pipeline MFL inspection.},
  archive      = {J_EAAI},
  author       = {Lushuai Xu and Shaohua Dong and Haotian Wei and Feng Li and Pengkun Zhang and Cong Zuo and Mingxing Guo and Penghui Liao},
  doi          = {10.1016/j.engappai.2025.112382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight segmentation model based on segment anything model for tongue image segmentation. <em>EAAI</em>, <em>162</em>, 112379. (<a href='https://doi.org/10.1016/j.engappai.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tongue image segmentation plays a crucial role in intelligent of diagnosis of Traditional Chinese Medicine. Accurate, efficient, and lightweight tongue segmentation significantly improves both the quality and practical applicability of intelligent disease diagnosis models. To address this challenge, we propose TongueSAM_Lite, a lightweight and fully automated tongue image segmentation model. Based on the Segment Anything Model. Our approach employs knowledge distillation and parameter-efficient fine-tuning to develop a novel lightweight image encoder, high-parameter modules in the Vision Transformer are partially replaced with lightweight image modules, which facilitate the transfer of its feature extraction capabilities while accelerating inference speed and reducing computational resource requirements. Additionally, to eliminate manual annotation of tongue region bounding boxes, we integrate a YOLOX-based automatic Box-prompt generator, enabling end-to-end fully automated prompting and segmentation of tongue images. To validate our approach, various experiments were conducted in three datasets. The results show that compared to the original large-scale model of the Segment Anything Model, TongueSAM_Lite reduces the size of the model by 42.7% and shortens the inference time to 45.43% while retaining the near-complete segmentation accuracy of few-shot learning. TongueSAM_Lite achieves Mean Intersection over Union scores of 96.48%, 98.36%, and 97.53% in the three datasets, respectively, outperforming state-of-the-art segmentation methods. Further validation confirms that the YOLOX-based prompt encoder yields optimal performance for the generation of tongue image bounding boxes. Our proposed approach provides new research insights to advance tongue diagnosis technology of Traditional Chinese Medicine. All codes in this article are available at https://github.com/ruanqunsheng/TongueSAM_Lite .},
  archive      = {J_EAAI},
  author       = {Qunsheng Ruan and Shan Cao and Zhirong Luo},
  doi          = {10.1016/j.engappai.2025.112379},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112379},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight segmentation model based on segment anything model for tongue image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cross-branch information for semi-supervised remote sensing object detection. <em>EAAI</em>, <em>162</em>, 112378. (<a href='https://doi.org/10.1016/j.engappai.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection (SSOD) provides a promising solution to mitigate the annotation costs in remote sensing applications. Mainstream teacher-student based SSOD methods leverage unlabeled images through pseudo labeling, and their effectiveness is fundamentally limited by the inevitable noise in pseudo labels, particularly for remote sensing (RS) scenarios with complex backgrounds and dense, multi-scale and oriented objects. Current methods primarily focus on reducing pseudo label noise through category, scale and Intersection over Union information mining, as well as designing fine-grained confidence thresholding strategies. However, the inherent discrepancy between classification and localization reliability is neglected. In this study, with analyzing the characteristic discrepancies between the classification and localization branches, We propose artificial intelligence (AI) methodological innovation method named cross-branch information incorporation method (i.e., CBI-SSOD) to utilize these discrepancies to assist the training of the classification branch, and thus improve the performance of SSOD methods. Specifically, our method present two key AI innovations. Firstly, we propose a pretext task to extract cross-branch information, which can improve the classification ability by reinforce the consistent predictions between the classification branch and the pretext task. Besides, we propose a pseudo label reassignment approach to adjust the soft classification pseudo labels, and thus suppress pseudo label noise and improve the detection performance. Extensive experiments on Dataset for Object Detection in Aerial Images (DOTAv1.0) and DOTAv1.5 datasets validate the effectiveness and superiority of our method, and demonstrate the practical engineering impact of our method on RS applications and interpretation systems.},
  archive      = {J_EAAI},
  author       = {Shitian He and Huanxin Zou and Yingqian Wang and Xu Cao and Hao Chen and Ning Jing},
  doi          = {10.1016/j.engappai.2025.112378},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112378},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring cross-branch information for semi-supervised remote sensing object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction. <em>EAAI</em>, <em>162</em>, 112374. (<a href='https://doi.org/10.1016/j.engappai.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The industrial data sequences frequently exhibit irregular sampling frequencies, which pose a number of difficulties for data analysis and modeling. The traditional dynamic models like Recurrent Neural Network (RNN) and Transformer are difficult to model such data sequences. The main reason is that these models assume that data sampling frequency should be constant. To this end, a Sampling Interval-Adaptive Transformer (SIA-Trans) is proposed in this paper to adaptively model the temporal information for heterogeneous sampling sequences in industrial processes. The SIA-Trans uses the sampling interval and position embedding block to address the problem of unequal time intervals and rectify the temporal correlations in time series. Then, the interval-aware self-attention net is designed for dynamic data relationship modeling, taking the processed data through the self-attention mechanism. Finally, the predicted output is obtained after the point-wise feed-forward layer. The proposed SIA-Trans is validated on a real-world hydrocracking process to predict the content of hydrocarbon mixture with five carbon atoms (C5) hydrocarbons in light naphtha, as well as the final boiling point of jet fuel.},
  archive      = {J_EAAI},
  author       = {Zijian Xu and Nuo Xu and Kai Wang and Xiaofeng Yuan and Yalin Wang and Chunhua Yang and Weihua Gui and Shuqiao Cheng and Lingjian Ye},
  doi          = {10.1016/j.engappai.2025.112374},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112374},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. <em>EAAI</em>, <em>162</em>, 112373. (<a href='https://doi.org/10.1016/j.engappai.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of face forgery technology, many forged faces threaten information security. Although existing face forgery detection methods obtain better detection performance on intra-dataset evaluation, the generalization of cross-dataset detection and the robustness against image post-processing operations still need to be improved. To address these issues, we propose a multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. Specifically, a two-branch architecture is designed to extract spatial and frequency features. To realize the interaction and communication of spatial and frequency information, the cross-modality interaction module is designed to explore the inter-modality correlation by applying across self-attention. Subsequently, a multi-scale feature enhancement module is introduced in the spatial branch to enhance the texture and semantic information of spatial features, improving the robustness of tackling image post-processing operations. In addition, to exploit the complementary relationship between the spatial and frequency features, an adaptive fusion module is designed to establish forged feature dependencies by leveraging spatial self-attention, while learning discriminative feature representations by fusing spatial and frequency features in an adaptive weighted manner. Extensive experimental results on four public datasets demonstrate that the proposed method outperforms other state-of-the-art methods for intra-dataset, cross-dataset, and perturbed dataset evaluations.},
  archive      = {J_EAAI},
  author       = {Chunyin Shi and Chengyou Wang and Xiao Zhou and Zhiliang Qin},
  doi          = {10.1016/j.engappai.2025.112373},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112373},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting. <em>EAAI</em>, <em>162</em>, 112370. (<a href='https://doi.org/10.1016/j.engappai.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price forecasting has become a significant and complex research area within financial technology. The dynamic correlations among stocks and the inherent noise in price volatility present considerable challenges in accurately forecasting stock prices and enhancing investment returns. This paper introduces a novel Dynamic Correlation Graph Convolution Network (DyCGCN) with embedded temporal correlation extraction. First, we propose a dual-scale dynamic graph generation method to capture the topological relationships among stocks. Second, we develop a dynamic correlation-temporal convolution module that extracts high-level temporal correlations. Third, we introduce a prospect theory-guided multi-strategy loss function that accommodates the diverse risk preferences of investors. Furthermore, we present a joint regression-classification learning method to extract and leverage stock trend information. Experiments conducted on four real-world datasets demonstrate the superiority of DyCGCN, achieving an average 24.7% reduction in prediction error and a 10.5% improvement in predictive accuracy over baseline models, underscoring its strong potential for practical stock price forecasting.},
  archive      = {J_EAAI},
  author       = {Fang He and Wei Yin and Yilun Jin and Zhengyang Chen},
  doi          = {10.1016/j.engappai.2025.112370},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112370},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach. <em>EAAI</em>, <em>162</em>, 112361. (<a href='https://doi.org/10.1016/j.engappai.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific Emitter Identification (SEI) distinguishes radio-frequency (RF) devices by exploiting hardware-induced signal fingerprints, thereby strengthening wireless-layer security. Existing deep learning-based SEI methods depend heavily on labeled data and fixed confidence thresholds for pseudo-labeling, which limits their effectiveness under label scarcity or open-set conditions. To overcome these issues, we propose a progressive semi-supervised learning (ProSSL) method for SEI that combines iterative clustering with contrastive learning to generate adaptive pseudo-labels. ProSSL introduces an “uncertain” class and employs a dual-constraint selector—prediction stability and class diversity—to suppress noisy pseudo-labels and ensure robust propagation. Experiments on the public real-world long range(LoRa) RF-fingerprint dataset show that ProSSL gains 2.90%–6.01% absolute accuracy over state-of-the-art baselines, reaching 96.48% accuracy with 90% labels and 59.88% with only 5% labels. While on the public automatic dependent surveillance-broadcast(ADS-B) Top-10 dataset, ProSSL achieves 84.40% accuracy with 5% labeled data and 99.40% accuracy with 90%labeled data, again outperforming all competing methods. Open-set evaluations further demonstrate that overall accuracy rises from 18.81% when only two classes are known to 62.25% when eight classes are known, confirming strong generalization to unseen emitters and validating ProSSL’s robustness and practicality in realistic wireless environments.},
  archive      = {J_EAAI},
  author       = {Yiting Gao and Ke Wang and Hao Huang and Jiao Wang and Jiaxu Liu and Yao Zheng and Jianqing Li},
  doi          = {10.1016/j.engappai.2025.112361},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112361},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing scene text image super-resolution via gradient-based graph attention network. <em>EAAI</em>, <em>162</em>, 112360. (<a href='https://doi.org/10.1016/j.engappai.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text image super-resolution is crucial for enhancing text recognition in low-resolution real-world images. Existing methods usually overlook the structured and repetitive layout of text, which can serve as powerful prior knowledge for guiding reconstruction. In this work, we propose a novel framework that incorporates gradient-based graph attention to explicitly model patch-level text layout. The architecture combines a non-local group-wise attention module, a cascaded channel attention module, and a gradient-guided graph attention module to capture both global and local structural dependencies. This design enables more accurate restoration of text contours and layout consistency. Extensive experiments on the benchmark dataset demonstrate that our method achieves superior performance in both image quality and recognition accuracy, outperforming state-of-the-art methods. The code is available at: https://github.com/cvzxy/TSANv2 .},
  archive      = {J_EAAI},
  author       = {Xiangyuan Zhu and Xuchong Liu and Kehua Guo and Wei Zhao},
  doi          = {10.1016/j.engappai.2025.112360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing scene text image super-resolution via gradient-based graph attention network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs. <em>EAAI</em>, <em>162</em>, 112359. (<a href='https://doi.org/10.1016/j.engappai.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern biomedical research and livestock management, accurate multi-organ segmentation in pigs is essential for breeding programs. However, current methods face challenges due to low imaging contrast, size disparities, and organ shape variability. Additionally, the manual annotation of computed tomography (CT) scans is labor-intensive and costly, limiting available labeled samples. To address these issues, we propose a consistency regularization-based network guided by anatomical structural relationships and global organ category representations, specifically designed for multi-organ segmentation using a limited number of annotated CT scan samples from pigs. Specifically, we designed the SpatialLink Gated Recurrent Unit (GRU) module to extract anatomical structural information and capture dynamic spatial relationships between organs, thereby minimizing segmentation biases caused by organ shape variations. Moreover, we developed the Organ Category Coding module and Guidance module, which integrate consistency regularization and attention mechanisms, enabling the network to accurately extract global organ category representations during the decoding phase, even with a small number of labeled samples, significantly improving segmentation consistency across organs of different sizes. Additionally, We are the first to apply the Visual State Space block to multi-organ segmentation in pigs, using it to extract contextual information. Experiments on 60 pigs demonstrate that our method achieves state-of-the-art results, with significant improvements in segmentation accuracy for the gallbladder and bladder, including a 9.8% and 4.2% Dice score increase, respectively, and a 12.4% and 6.2% boost in Jaccard scores compared to compared with a selection of published methods.},
  archive      = {J_EAAI},
  author       = {Xiang Pan and Hang Fan and Jianlan Wang and Yan Fu and Wei Chu and Weipeng Tai and Jing Gu and Jianming Ni},
  doi          = {10.1016/j.engappai.2025.112359},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112359},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast simulation for scattering muography applications using generative adversarial neural networks. <em>EAAI</em>, <em>162</em>, 112357. (<a href='https://doi.org/10.1016/j.engappai.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muography is an emergent non-destructive testing technique that uses cosmic muons to probe the interior of objects and structures. This technique can be employed to perform preventive maintenance of critical equipment in the industry in order to test the structural integrity of the facility. Several muography imaging algorithms based on machine learning methods are being developed in the recent years. These algorithms make exhaustive use of simulated data, usually using packages such as GEANT4 (GEometry ANd Tracking), that exhaustively simulate the detector, to produce training samples. This work presents a faster alternative for the generation of simulated samples based on generative adversarial neural networks. A speed up factor of 80 is observed with this system without any significant degradation of the quality of the simulation.},
  archive      = {J_EAAI},
  author       = {Rubén López Ruiz and Celia Fernández Madrazo and Sergio Sánchez Cruz and Lara Lloret Iglesias and Pablo Martínez Ruiz del Árbol},
  doi          = {10.1016/j.engappai.2025.112357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast simulation for scattering muography applications using generative adversarial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation. <em>EAAI</em>, <em>162</em>, 112356. (<a href='https://doi.org/10.1016/j.engappai.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular and real-time monitoring of corrosion is crucial for ensuring structural safety and extending the service life of infrastructure. With the continuous development of advanced structural health monitoring technologies, intelligent corrosion detection has become an inevitable trend. This study addresses the issues of low accuracy, incomplete detail processing, and missed or false detections in complex scenarios in steel structure corrosion detection, as well as the challenges of high complexity and insufficient real-time performance in deep learning models. We propose a high-performance, lightweight, real-time corrosion detection model, Real-Time Detection Transformer for Corrosion (RT-DETR-Corrosion), based on knowledge distillation. By incorporating lightweight optimization on the RT-DETR-R18 baseline model and a hybrid knowledge distillation approach, the model significantly improves real-time performance and detection accuracy, meeting the application requirements for efficiency and precision in steel structure corrosion detection. Experimental results show that the model exhibits excellent optimization effects in terms of localization accuracy, classification accuracy, and position regression error on both the training and validation sets, while also demonstrating strong generalization ability. In extreme weather conditions (such as rain, fog, snow, and strong light) and complex scenarios (such as occlusion, blur, and low-light environments), the model maintains stable Precision, Recall, and mAP metrics, validating its reliability and applicability in diverse real-world engineering environments. Moreover, visualized heatmap analysis of detection results for different scenarios further confirms the model's precise attention to corrosion regions and its generalization ability, providing essential technical support for steel structure corrosion risk assessment and intelligent monitoring, with significant potential for engineering applications.},
  archive      = {J_EAAI},
  author       = {Jia Hou and Wei Chen and Zhen Duan and Hang Li and Mingyu Yu},
  doi          = {10.1016/j.engappai.2025.112356},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112356},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy. <em>EAAI</em>, <em>162</em>, 112355. (<a href='https://doi.org/10.1016/j.engappai.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval-valued intuitionistic fuzzy set (IVIFS) represents an organic integration of interval-valued fuzzy sets and intuitionistic fuzzy sets, but it fails to meet the requirements of linearity and closure in arithmetic operations, rendering its computations relatively intricate. Consequently, this paper employs an interval partitioning strategy to mitigate the complexity of arithmetic operations, thereby constructing a novel fuzzy set structure characterized by efficient piecewise linear approximation capabilities. Furthermore, the paper presents the structural form of arithmetic operations for the IVIFS with piecewise linear approximation and demonstrates the simplicity of these operations by an numerical example. In addition, we extend the findings on information measures for polygonal interval-valued intuitionistic fuzzy set pertaining to abstract functions that fulfill particular criteria. Furthermore, we delve into the transformation relationships among these information measures, from which a range of structural formats for information measures can be deduced based on functional expressions and transformation relationships. Finally, similarity measures are applied to company site selection. The validity, practicality and stability of proposed measures have been proven through sensitivity analysis and comparative analysis.},
  archive      = {J_EAAI},
  author       = {Le Fu and Chunfeng Suo},
  doi          = {10.1016/j.engappai.2025.112355},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112355},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing. <em>EAAI</em>, <em>162</em>, 112354. (<a href='https://doi.org/10.1016/j.engappai.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-dimensional ensemble dispersion entropy (EDE 1D ) can effectively characterize the nonlinear dynamic characteristics of one-dimensional time series, but the complexity of two-dimensional space is not reflected, and only single-scale features can be captured. Firstly, to comprehensively capture the feature information of two-dimensional space, the symmetrized dot pattern (SDP) is introduced to overcome the shortcomings of the ordinary images lack of physical meaning and the time-frequency distribution methods exhibit incomplete information representation, etc. Simultaneously, the amplitude and frequency information are intuitively expressed by a two-dimensional mirror snowflake symmetrized image (MSSI 2D ). Secondly, to overcome the shortcomings of single-scale and traditional coarse-graining, a two-dimensional refined composite multi-scale coarse-graining method is proposed, which improves the accuracy of feature extraction and reduces the calculation deviation. After that, a new feature extraction method namely two-dimensional refined composite multi-scale revised ensemble dispersion entropy (RCMREDE 2D ) is proposed, whose parameter stability and performance are explored through simulation analysis. The results demonstrate that the RCMREDE 2D exhibits excellent stability and anti-noise interference ability. Based on the advantages of RCMREDE 2D , a novel fault diagnosis method for rolling bearings is developed by integrating RCMREDE 2D and a firefly algorithm optimized support vector machine (FA-SVM) multi-fault classifier for pattern recognition. The proposed method is further validated through two measured bearing data sets and five comparative methods, and the results indicate that the RCMREDE 2D and FA-SVM achieve the highest recognition accuracy while demonstrating superior stability.},
  archive      = {J_EAAI},
  author       = {Wenqing Ding and Jinde Zheng and Haiyang Pan and Jian Cheng and Jinyu Tong},
  doi          = {10.1016/j.engappai.2025.112354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of speaker verification: Methods, network architectures, tasks and challenges. <em>EAAI</em>, <em>162</em>, 112351. (<a href='https://doi.org/10.1016/j.engappai.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker verification is an important branch of biometric recognition, with wide applications in identity authentication, audio monitoring, and other fields. In recent years, deep learning and meta-learning have made remarkable advancements in the field of speaker verification. Therefore, it is necessary to update existing reviews of speaker verification to reflect the latest research developments. We review literature from the past decade to provide a timely and comprehensive survey of the field. First, we outline the concept and system process of speaker verification. Then, we analyze the speech preprocessing process and common acoustic features used in the systems. Next, we present an overview of speaker modeling approaches, covering traditional probabilistic methods, deep learning-based speaker methods, and meta-learning-based speaker methods, focusing on the latter two methods. We provide an in-depth analysis and summary of the characteristics and the latest network architectures of these methods, focusing on the development of Transformer and large-scale pre-trained Transformer. Furthermore, we introduce the datasets and evaluation metrics used in speaker verification systems, focusing on a detailed and fair comparison of the performance of text-dependent and text-independent speaker verification systems. Finally, we explore the challenges faced by speaker verification systems and discuss future research opportunities.},
  archive      = {J_EAAI},
  author       = {Weijie Wang and Hong Zhao and Yikun Yang and Yongjuan Yang},
  doi          = {10.1016/j.engappai.2025.112351},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112351},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of speaker verification: Methods, network architectures, tasks and challenges},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-cost and sparsity for continual semantic segmentation. <em>EAAI</em>, <em>162</em>, 112350. (<a href='https://doi.org/10.1016/j.engappai.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have contributed to significant progress in semantic segmentation tasks. However, deep neural networks exhibit a critical drop in performance due to catastrophic forgetting when they are required to learn new tasks incrementally. The more plastic the network is, the easier it can learn new tasks. Whereas, for continual semantic segmentation, it is more reliable to preserve the knowledge it has learned from previous tasks. Here, gated 0-1 Bernoulli variable is used as a regularization method to optimize performance by enhancing network sparsity. Then, the special case of gated 0-1 Bernoulli variable is applied in the replay-based method of continual semantic segmentation. Specifically, when the value of the sub-network sampling rate reaches 0.5, the network reaches the strongest stability. Finally, the gated 0-1 Bernoulli variable improves the network’s performance in complex scenarios and reduces cost under similar performance. Experimental results indicate that in using 100% samples for incremental training, the Mean Intersection over Union(mIoU) of the old classes improves by up to 4.6% and 5.5% compared to the baseline at the end of the overall training in continual semantic segmentation scenarios 10-1 and 10-2. Furthermore, in using 60% samples for incremental training, the performance for the old tasks only drops by less than a percentage, while the time cost to complete the full setup decreases by 22%.},
  archive      = {J_EAAI},
  author       = {Qing Ji and Bin Li and Shaobo Li and Hongchao An and Jing Yang},
  doi          = {10.1016/j.engappai.2025.112350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Low-cost and sparsity for continual semantic segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos. <em>EAAI</em>, <em>162</em>, 112349. (<a href='https://doi.org/10.1016/j.engappai.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activist video advertisements represent a strategic form of brand communication in which companies express their stance on social or environmental issues through emotionally driven storytelling and slogan-based narratives. Despite their growing prevalence, there is a notable lack of systematic and quantitative methods for evaluating their performance or comparing their effectiveness across competing brands. This research addresses that gap by proposing a comprehensive decision support system (DSS) designed to assess the performance of activist video advertisements in a structured and reproducible manner. The study introduces a novel hybrid multi-criteria decision-making (MCDM) framework: the spherical cubic fuzzy (SCF)–Aczel-Alsina–ranking comparison (RANCOM)–method based on the removal effects of criteria (MEREC)–deviation-based pairwise assessment ratio technique (DEPART). This methodology integrates subjective weights obtained via SCF–RANCOM and objective weights derived through SCF–MEREC, with both sets of weights combined using SCF-based aggregation operators that incorporate Aczel-Alsina t-norm and t-conorm functions. Performance rankings are then generated using the SCF–DEPART method. To demonstrate the model's applicability, a real-world case study involving eight sustainability-oriented activist video advertisements released in Türkiye was conducted. Evaluations were based on input from ten domain experts across eleven criteria. The analysis identified “convincingness and credibility” as the most critical factor, with “The Voice of Nature” campaign achieving the highest performance rating. The model's robustness was confirmed through scenario-based sensitivity analyses, and its consistency was validated by benchmarking against thirteen alternative MCDM approaches. The findings offer meaningful implications for both academic research and advertising practice.},
  archive      = {J_EAAI},
  author       = {Galip Cihan Yalçın and Karahan Kara and Gülcan Işık and Esra Serdar Tekeli and Vladimir Simic and Abdullah Ballı and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112349},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112349},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated clustering with mutual knowledge distillation for traffic flow prediction. <em>EAAI</em>, <em>162</em>, 112347. (<a href='https://doi.org/10.1016/j.engappai.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction plays a critical role in intelligent transportation systems. Conventional traffic flow prediction methods primarily rely on centralized training, which poses a risk of privacy leakage. Federated learning, a privacy-preserving framework to machine learning, enables distributed participants to jointly train a shared model without sharing local private data. However, traffic flow is typically collected from different devices and contains different temporal patterns, leading to non-independent and identically distributed. To address these challenges, we propose a traffic flow prediction method based on federated clustering with mutual knowledge distillation. We first perform temporal decomposition on the traffic flow data and use mutual learning with adaptive distillation loss to facilitate mutual knowledge transfer among local models during training. Then, we apply spectral clustering to cluster clients based on the cosine similarity of model parameters at the server and design a global model aggregation method to improve the performance of federated learning. Finally, the proposed method is evaluated on two real-world traffic datasets, and the experiment results show significant improvements over traditional federated learning approaches and also outperform federated mutual learning. The results demonstrate that the proposed method effectively captures temporal information and mitigates the effect of non-independent and identically distributed issues.},
  archive      = {J_EAAI},
  author       = {Yao Lin and Shengwu Xiong},
  doi          = {10.1016/j.engappai.2025.112347},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112347},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated clustering with mutual knowledge distillation for traffic flow prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques. <em>EAAI</em>, <em>162</em>, 112346. (<a href='https://doi.org/10.1016/j.engappai.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to identify failure types in Reinforced Concrete Shear Walls (RCSWs) by quantifying the contributions of shear and flexural modes in the force-deformation response of the walls. The supporting research database includes images, cyclic curve backbones, and geometric and mechanical characteristics of 253 RCSWs. Initially, the database is manually classified into shear, flexure, and shear-flexure failure modes based on observations of surface damage and the cyclic response of the wall. Subsequently, unsupervised clustering and supervised learning algorithms are employed to probabilistically quantify and predict the participation of flexural and shear modes in the overall seismic response of the walls, respectively. The unsupervised model, utilizing the K-means algorithm, identifies the primary failure modes of the walls, achieving over 90 % concordance with manual expert labeling. Based on the results of unsupervised clustering, a hybridity index is proposed to demonstrate the contributions of shear and flexure failure modes to the overall seismic response. Supervised learning is then used to predict hybridity indices from wall characteristics, with the Extremely Randomized Trees (Extra Trees) model achieving the best results based on a balanced evaluation of multiple performance metrics. SHapley Additive exPlanations (SHAP), a tool for exploring model sensitivity, highlights the aspect ratio as the key influencing factor on failure mode, in accordance with relevant structural engineering codes and standards. Implementation of the proposed framework in exploring the behaviors of four unseen case studies reveals a significant correlation between the predicted hybridity indices and observed damage, consistent with existing guidelines.},
  archive      = {J_EAAI},
  author       = {Pouya Ebrahimi and Amir Hossein Asjodi and Kiarash M. Dolatshahi},
  doi          = {10.1016/j.engappai.2025.112346},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112346},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path multiple attention-guided feature interaction network for camouflaged object detection. <em>EAAI</em>, <em>162</em>, 112345. (<a href='https://doi.org/10.1016/j.engappai.2025.112345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Camouflaged Object Detection (COD) methods rely on features from a pre-trained backbone with a single-encoder structure, leading to initial features biased towards global or local preferences. This affects subsequent feature modeling and degrades COD performance. Some studies use modular or auxiliary flow structures to balance feature preferences but often focus only on interactions between hierarchical features or information flows, ignoring potential redundancy or noise within aggregated features. Therefore, we propose a novel dual-path multiple attention-guided feature interaction network (DMAFI-Net) for COD, which contains four main components: global and local features interaction module (GLFI), intra-feature interaction module (IFI), multi-scale feature enhancement module (MFE), and two decoders including neighbor connection decoder based feature aggregation (NFA) and refine decoder. Specifically, the GLFI is designed to implement the interaction and combination of global and local features, and the combined features will be sent to IFI to mine intra-feature information. Besides, the MFE is introduced to further enrich the extracted features obtained in the IFI. In the feature decoding stage, the NFA module utilizes neighbor connection decoder to fuse multi-scale features and ultimately generates a coarse prediction. Finally, the refine decoder leverages multiple attention modules to refine the initial prediction with the combined features as auxiliary cues and obtain the final camouflaged map. Extensive experiments on four COD benchmark datasets demonstrate the superiority of the proposed framework when compared to 24 state-of-the-art (SOTA) methods in terms of five widely used evaluation metrics. Furthermore, the ablation studies show the effectiveness of main components of our DMAFI-Net.},
  archive      = {J_EAAI},
  author       = {Anzhi Wang and Jintao Wu and Shuang Zhao and Yun Liu},
  doi          = {10.1016/j.engappai.2025.112345},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112345},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-path multiple attention-guided feature interaction network for camouflaged object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection. <em>EAAI</em>, <em>162</em>, 112344. (<a href='https://doi.org/10.1016/j.engappai.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application of speech-based depression detection systems expands, differences in cross-domain data distribution pose significant challenges. This paper proposes the framework of Time–Frequency Calibrated Transfer Learning (TFCTL). This framework first introduces Frequency-Delay Neural Network (FDNN), inspired by Time-Delay Neural Network (TDNN), extending the concept of temporal feature extraction using sliding windows and weight sharing from the time domain to the frequency domain. A multi-level information aggregation module then integrates features of varying abstraction levels from both time-delay and frequency-delay neural networks, balancing global and local speech information. Finally, TFCTL uses transfer learning to calibrate the distribution of the aggregated time–frequency embedding vectors, uncovering commonalities of depression features across different domains. Cross-speaker and cross-corpus experiments were conducted using the Chinese Multimodal Depression Corpus (CMDC) and the Distress Analysis Interview Corpus Wizard-of-Oz (DAIC-WOZ). In cross-speaker scenarios, TFCTL achieved F1 scores of 0.7324 on DAIC and 0.9660 on CMDC, outperforming other methods. In cross-corpus scenarios, TFCTL achieved F1 scores of 0.6743 on DAIC and 0.6879 on CMDC, demonstrating its robustness in addressing domain mismatch issues. The source code used in the paper is available at https://anonymous.4open.science/r/TFCTL-A545/ .},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Li Ding and Zuo Yang and Zhe Wang and Ke Zhao},
  doi          = {10.1016/j.engappai.2025.112344},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112344},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales. <em>EAAI</em>, <em>162</em>, 112342. (<a href='https://doi.org/10.1016/j.engappai.2025.112342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor engineering, high yield of wafers relies on accurate detection and classification of wafer defects. The dataset for detecting wafer defects presents three primary challenges: (i) different background types, (ii) variable image or defect scales, and (iii) imbalanced data with a long-tailed distribution of defect types. These challenges create significant limitations for traditional classification techniques. To address these issues, we propose a stratified framework called Wafer Detection and Classification (WaferDC), designed specifically for detecting and classifying wafer defects from scanning electron microscope (SEM) images. Our framework achieves high defect detection performance on SEM wafer images by utilizing a multi-cluster memory bank, which effectively handles the challenges of (i) variable background types and (ii) differing image or defect scales. Building on this robust detection, we propose Segmentation and Mix (SegMix), a novel defect augmentation technique based on anomaly heatmaps, which enhances the reliability of defect detection and classification in a (iii) long-tailed imbalanced environment. Finally, we pass defect-classified images through a parameter-efficient fine-tuning (PEFT)-based classifier (Shiet al., 2023) utilizing a vision transformer (ViT) architecture, further improving overall defect detection and classification performance. We rigorously tested WaferDC on a proprietary SEM wafer dataset and the public Describable Textures Dataset-Synthetic (DTD-Synthetic) and Magnetic Tile Defect (MTD) datasets. The results confirm the effectiveness of our method in improving defect detection and classification in wafer manufacturing. Our code is available at https://github.com/SpatialAILab/WaferDC .},
  archive      = {J_EAAI},
  author       = {Taekyeong Park and Yongho Son and Sanghyuk Moon and Seungju Han and Je Hyeong Hong},
  doi          = {10.1016/j.engappai.2025.112342},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112342},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators. <em>EAAI</em>, <em>162</em>, 112341. (<a href='https://doi.org/10.1016/j.engappai.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating obstacle-free trajectories for robotic manipulators in unstructured and cluttered environments remains a significant challenge. Existing motion planning methods often require additional computational effort to generate the final trajectory by solving kinematic or dynamic equations. This paper highlights the strong potential of model-free reinforcement learning methods over model-based approaches for obstacle-free trajectory planning in joint space. We propose a fast trajectory planning system for manipulators that combines vision-based path planning in task space with reinforcement learning-based obstacle avoidance in joint space. We divide the framework into two key components. The first introduces an innovative vision-based trajectory planner in task space, leveraging the large-scale fast segment anything (FSA) model in conjunction with basis spline (B-spline)-optimized kinodynamic path searching. The second component enhances the proximal policy optimization (PPO) algorithm by integrating action ensembles (AE) and policy feedback (PF), which greatly improve precision and stability in goal-reaching and obstacle avoidance within joint space. These proximal policy optimization (PPO) enhancements increase the algorithm’s adaptability across diverse robotic tasks, ensuring consistent execution of commands from the first component by the manipulator, while also enhancing both obstacle avoidance efficiency and reaching accuracy. The experimental results demonstrated the effectiveness of proximal policy optimization (PPO) enhancements, as well as simulation-to-simulation (Sim-to-Sim) and simulation-to-reality (Sim-to-Real) transfer, in improving model robustness and planner efficiency in complex scenarios. These enhancements allowed the robot to perform obstacle avoidance and real-time trajectory planning in obstructed environments. https://sites.google.com/view/ftp4rm/home},
  archive      = {J_EAAI},
  author       = {Yongliang Wang and Hamidreza Kasaei},
  doi          = {10.1016/j.engappai.2025.112341},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112341},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm. <em>EAAI</em>, <em>162</em>, 112340. (<a href='https://doi.org/10.1016/j.engappai.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the urgency, timeliness and uncertainty of power batteries recycling, we extend a novel network model for retired battery recycling systems, bi-level capacitated location-routing problem with time windows for heterogeneous battery mixed-load (CLRPTW-HBM). Firstly, the expected interval and linear weighting methods are used to transform and process the lower-level multi-objective function that contains fuzzy variables. Secondly, a Transformer-based improved deep reinforcement learning algorithm (Transformer-IDRL) is proposed. (1) The bi-level CLRPTW-HBM is modeled as Markov decision process, and a policy network model with dual-layer encoder-decoder structure is designed based on Transformer architecture. (2) Randomly generate instance data, and the asynchronous advantage Actor-Critic with adaptive dynamic parameter tuning strategy is employed for training. (3) The action sampling strategy based on roulette reverse selection mechanism, and local search strategy incorporating problem characteristics are introduced to improve solution quality. Finally, extensive experiments are conducted on benchmark datasets and actual cases, and the results demonstrate superior performance of Transformer-IDRL, with an average Gap of 0.22 % and 0.19 %, a 5.30 % reduction in recycling cost, and a 6.06 % reduction in battery exposure risk. These satisfactory results highlight the feasibility and efficiency of the proposed model and method. Additionally, sensitivity analysis of model parameters shows that under different decision-maker preferences and vehicle loading capacity, the sensitivity range of path cost is [5.77 %, 39.85 %] and [16.04 %, 35.54 %], while that of exposure risk is [1.40 %, 3.39 %] and [1.35 %, 5.54 %], indicating that parameter variations significant influence the layout of recycling network and overall path cost. Therefore, decision-makers should flexibly adjust key parameters to balance economic benefits and sustainable development in battery recycling.},
  archive      = {J_EAAI},
  author       = {Mengna Zhao and Shiping Chen},
  doi          = {10.1016/j.engappai.2025.112340},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112340},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instantaneous power prediction for industrial robots using tree-based machine learning methods. <em>EAAI</em>, <em>162</em>, 112339. (<a href='https://doi.org/10.1016/j.engappai.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a tree-based machine learning methodology for instantaneous power prediction designed, tested and validated using data from an articulated industrial robot. The proposed methodology for instantaneous power prediction materializes through a generic system architecture with functionalities consisting of data acquisition, time alignment of data samples, storage, model learning, instantaneous power prediction and integration in time to evaluate energy consumption at robot operation level. This methodology is designed to evaluate offsite energy consumption of robotized workstations for different layouts characterized by relative position of the robot with respect to the serviced and fly-by points. This is important both for offline virtual commissioning of robotized workstations (determine layout) and for online operation for maintenance purposes (determine energy spikes different from normal model). The analyzed operation is the linear motion of the robot Tool Control Point in Cartesian space, characterized by the complexity of the kinematic model: each joint operates in coordinated motion, adjusting its velocity and acceleration continuously to ensure a straight path with constant speed. A custom Internet of things (IoT) device enables synchronized energy and motion data logging for robots, ensuring consistent values for sampled trajectories. Justification for the usage of tree-based methods and experimental results are provided.},
  archive      = {J_EAAI},
  author       = {Ionuţ Lenţoiu and Silviu Răileanu and Theodor Borangiu and Mihnea Constantinescu and Octavian Morariu},
  doi          = {10.1016/j.engappai.2025.112339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instantaneous power prediction for industrial robots using tree-based machine learning methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management. <em>EAAI</em>, <em>162</em>, 112338. (<a href='https://doi.org/10.1016/j.engappai.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wastewater treatment plants (WWTPs) are among the most energy-intensive components of urban infrastructure and bear strict regulatory responsibilities for wastewater quality. These dual challenges, minimizing energy consumption and maintaining environmental compliance, are deeply interrelated and must be managed simultaneously to achieve sustainable plant operation. This study proposes a framework that comprises two customized components. The first component employs a voting ensemble model based on transformer architecture to predict energy consumption. It processes heterogeneous feature domains — including hydraulic, wastewater, and climatic variables — through parallel attention-driven streams. The outputs from these streams are then aggregated using a weighted voting mechanism to produce the final prediction. Second, a multitask Bidirectional Gated Recurrent Unit (Bi-GRU) forecasts wastewater quality indicators concurrently (ammonia, Biochemical Oxygen Demand (BOD), and Chemical Oxygen Demand (COD)), capturing shared temporal dependencies and reducing model complexity. A hybrid preprocessing strategy is applied, incorporating domain-aware outlier detection (z-score and Interquartile Range (IQR)), K-Nearest Neighbors (KNN) Imputation, and feature selection using Extreme Gradient Boosting (XGBoost). Experimental results showed that. The voting ensemble model achieved the best results for energy consumption prediction with 31.61 of Root Mean Squared Error (RMSE). The multitask Bi-GRU achieved the best results for wastewater quality indicators with RMSE at 6.1689, 48.0323, and 88.2214 for ammonia, BOD, and COD, respectively. This work is among the first to integrate transformer ensembles and multitask learning in a unified WWTP forecasting system. Simultaneously addressing energy efficiency and water quality assurance, this offers a practical, scalable, and intelligent decision-support tool for sustainable wastewater management.},
  archive      = {J_EAAI},
  author       = {Hager Saleh and Sherif Mostafa and Shaker El-Sappagh and Abdulaziz AlMohimeed and Michael McCann and Saeed Hamood Alsamhi and Niall O’Brolchain and John G. Breslin and Marwa E. Saleh},
  doi          = {10.1016/j.engappai.2025.112338},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112338},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural model of the adaptive tuned particle impact damper. <em>EAAI</em>, <em>162</em>, 112334. (<a href='https://doi.org/10.1016/j.engappai.2025.112334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a novel approach for the modeling of the Adaptive Tuned Particle Impact Damper (ATPID) using Multilayer Perceptron (MLP). The main motivation was the recognition that such an approach can support the development of novel neural modeling and the optimal determination of damper parameters in terms of mechanical vibration attenuation. The training data were obtained using a theoretical model validated experimentally. The optimally selected MLP was compared with other regression models using 10 different metrics. A hyperparameter tuning of the determined neural network architecture was conducted based on the input parameters such as excitation amplitude, grain mass, and ATPID damper height. The analyses show that the proposed neural network could quickly and accurately estimate the system’s vibration amplitude and efficiently predict the optimal damper height. The ability to effectively determine the correct optimal height is crucial for ATPID damper control. The high efficiency in predicting the system’s vibration amplitude allows for the replacement of the theoretical model with applied time-consuming contact forces. The MLP accurately estimated vibration amplitudes with 1%–10% error for interpolated data and up to 15% for extrapolated cases. The issue raised is particularly important from the perspective of real-time damper control. It was found that computing a single case using the artificial neural network is more than ten times faster compared to the theoretical model. Therefore, the proposed ATPID damper model based on a neural network forms the basis for further considerations and scientific research to finally propose a control algorithm in the future.},
  archive      = {J_EAAI},
  author       = {Mateusz Żurawski and Karolina Grabska and Robert Zalewski and Adam Kulawik},
  doi          = {10.1016/j.engappai.2025.112334},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112334},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural model of the adaptive tuned particle impact damper},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations. <em>EAAI</em>, <em>162</em>, 112333. (<a href='https://doi.org/10.1016/j.engappai.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion-cause pair extraction in conversations (MECPEC) has gradually evolved into an emerging task aimed at discovering deeper causal relationships between emotions and their corresponding causes in conversational contexts. It has widespread application in fields such as human–computer interaction, social media analysis, customer feedback management, and empathetic companion, among others. However, the challenges posed by the oversimplified multimodal feature fusion mechanism and the failure to account for the relative positional relationship between emotions and causes still hinder the performance of MECPEC. In this study, we propose an adaptive hybrid machine reading comprehension (AHMRC) framework to extract potential emotion-cause pairs inherent in conversations. The MECPEC task is first transformed into a two-round hybrid machine reading comprehension task that sequentially enforces the global emotion query and the local cause query with the goal of exploring the relative position constraint specific to conversations. Subsequently, an adaptive multimodal attention module is designed by incorporating features extracted from text, video, and audio modalities, and adaptively fusing them according to their contributions. Extensive experiments were carried out on the benchmark datasets to demonstrate the effectiveness of the proposed AHMRC framework in comparison to other state-of-the-art methods in the literature.},
  archive      = {J_EAAI},
  author       = {Guorui Li and Xufeng Duan and Cong Wang and Sancheng Peng},
  doi          = {10.1016/j.engappai.2025.112333},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112333},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction. <em>EAAI</em>, <em>162</em>, 112332. (<a href='https://doi.org/10.1016/j.engappai.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretical and computational modelling of heat conduction in a functionally graded cylinder has been rigorously investigated in prior studies, owing to its critical significance in high-stakes engineering applications such as nuclear reactor design, aerospace structural systems, and pressure vessel technology. Despite this extensive body of work, the majority of these studies have mostly focused on simplified two-dimensional models, frequently presuming idealized thermal parameters such as isotropic thermal conductivity, constant convection coefficients, and spatially uniform ambient temperatures. These simplifications overlook the crucial role of spatially varying thermal characteristics and three-dimensional (3D) temperature distributions, which are essential for accurately simulating the complex heat conduction behaviors found in real-world engineering. Unlike prior research, this study presents an analytical solution for heat conduction under non-homogeneous generalized Robin boundary conditions, capturing 3D thermal conductivity inhomogeneities along three orthogonal directions using Sturm-Liouville theory and finite integral transforms. However, while such analytical methods are highly accurate for simpler geometries, they often encounter significant challenges when extended to scenarios involving complex material gradients and irregular domains. A gradient-enhanced physics-informed neural network (g-PINN) framework is proposed to tackle these challenges, utilizing neural networks that incorporate physical laws and gradient information to enhance its applicability to complex configurations. This combined approach presents a novel framework that integrates classical theory with machine learning, facilitating precise modelling of thermal phenomena in functionally graded cylinders. The findings indicate that both the analytical and machine learning approaches (g-PINN) align closely with presented solutions, precisely capturing the energy equation and more complex boundary conditions.},
  archive      = {J_EAAI},
  author       = {Palash Das and Md Ashraful Islam and Dipayan Mondal},
  doi          = {10.1016/j.engappai.2025.112332},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112332},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism. <em>EAAI</em>, <em>162</em>, 112331. (<a href='https://doi.org/10.1016/j.engappai.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spurious drug–drug interactions arising from experimental biases can compromise treatment safety and hinder effective clinical decision-making for patients. However, current molecular representation learning methods still face significant challenges in addressing this problem. First, most graph neural network-based approaches consider only single-direction interactive semantic extraction between drug molecules, failing to capture more granular relationships between drugs fully. Moreover, during training, they are vulnerable to noise from negative sampling and cannot sufficiently leverage the complete drug–drug interaction annotations, resulting in reduced robustness and accuracy in downstream tasks. To this end, we propose a robust spurious DDI detection framework that employs chi-square-guided bidirectional attention to capture fine-grained and bidirectional interaction patterns. First, considering their mutual information flow, a two-way cross-attention mechanism is introduced for a more granular extraction of cross-drug molecular interaction semantic representations through bidirectionally perceiving interactive features between drugs. Second, on the basis of robust minimum covariance determinant theory, we propose a chi-square distribution-based spurious detection method to approximate the correctly annotated drug–drug interactive feature space to a chi-square distribution for a complete feature representation. Extensive experiments on benchmark datasets further validate our method’s effectiveness over state-of-the-art methods, particularly in noisy interference scenarios. Our code is available at https://github.com/AlexCostra/cd .},
  archive      = {J_EAAI},
  author       = {Wei-Yu Shi and Yi-Jia Zhang and Jin-Zhong Ning},
  doi          = {10.1016/j.engappai.2025.112331},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112331},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel high-accuracy graph neural network-based rumor detection method. <em>EAAI</em>, <em>162</em>, 112329. (<a href='https://doi.org/10.1016/j.engappai.2025.112329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors spreading on social media platforms result in potential damages. A precise rumor detection mechanism can help form a healthy public opinion environment. In recent years, deep learning-based rumor detection methods, especially graph model-based ones, have risen and reached promising performance. However, there are several defects in existing methods, which limit models from efficiently utilizing the propagation structure. In this paper, we propose a novel rumor detection model, which has high accuracy and reaches state-of-the-art performance. First, we design a powerful comprehensive rumor feature extractor that explicitly overcomes the restriction of previous Graph Neural Networks-based models. Then, by introducing Kernel Subtree features, our model acquires the capability to learn crucial local features from important nodes. Comparative experiments performed on two real-world social media platforms demonstrate that our work reaches state-of-the-art performance, which outperforms the best baseline with 1.6% and 1.9% in accuracy respectively.},
  archive      = {J_EAAI},
  author       = {Xi Xiao and Zeming Wu and Chengzong Cai and Tian Bian and Guangwu Hu and Qing Li and Cheng Huang},
  doi          = {10.1016/j.engappai.2025.112329},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112329},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel high-accuracy graph neural network-based rumor detection method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting. <em>EAAI</em>, <em>162</em>, 112325. (<a href='https://doi.org/10.1016/j.engappai.2025.112325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dependable stock price predictions are vital for optimizing economic policies and investment strategies in both national and corporate settings. However, the intrinsic volatility and intricacy of stock prices pose considerable challenges. Thus, this paper introduces a novel Committee of Multi-scale Nonlinear Learning Frameworks (CoML) that employs a three-stage model: decomposition, reconstruction, and prediction. First, a complete ensemble empirical mode decomposition with adaptive noise is adopted to decompose the original stock prices into multiple intrinsic mode functions. Secondly, a fine-to-coarse algorithm is applied to reconstruct the intrinsic mode functions, so as to effectively extract short-term fluctuations and long-term trends. Finally, an ensemble of nonlinear models including bidirectional long short-term memory (BiLSTM), support vector regression (SVR) and multi-layer perceptron (MLP) is used to learn and forecast features extracted to obtain high performance. Experimental results indicate that the model performs exceptionally well in both emerging and developed markets highlighting the innovative capabilities of CoML in highly complex and volatile financial markets. The proposed model is further validated using Model Confidence Set and the results indicate that the model is statistically significant.},
  archive      = {J_EAAI},
  author       = {Qian He and Yanhui Liang and Yu Lin and Dazhi Pan and Yuying Yue},
  doi          = {10.1016/j.engappai.2025.112325},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112325},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning robust brain tumor segmentation under label corruption and data scarcity. <em>EAAI</em>, <em>162</em>, 112322. (<a href='https://doi.org/10.1016/j.engappai.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models for medical image segmentation often struggle with performance issues when datasets are affected by label noise or annotation errors, commonly introduced during manual process or lack of proficiency. These noisy annotations disrupt the loss function, leading to "partially incorrect" gradients that impair the model's learning and overall performance. Additionally, the limited availability of scanned data for training often makes it challenging to develop a robust model. A common approach to address this issue is to leverage similar large annotated datasets. However, differences in dataset distributions can also lead to inconsistencies, introducing erroneous gradients during training and further impacting model performance. To address these challenges, we propose MGR-DAS (Meta-Gradient Reweighting via Direction-Aware Similarity), a novel meta-learning-based approach that can automatically evaluate the reliability of training samples during training using a small, clean subset easily curated from the noisy dataset. Our method quantifies reliability by measuring the cosine similarity between the gradients of noisy training samples and those of the clean subset. Samples with higher gradient alignment are assigned greater weights during training, effectively reducing the impact of noisy labels and improving model robustness. We evaluate our method using three standard metrics for medical image segmentation: the Dice Similarity Coefficient (DSC), the 95th percentile Hausdorff Distance (HD95), and Intersection over Union (IoU). The proposed MGR-DAS achieved an overall 2.4 % improvement in the DSC on the brain tumor segmentation (BraTS, 2021) dataset. Remarkably, even with only 10 clean annotations used in the reweighting algorithm, our method yielded a 28.7 % gain in DSC. In real-world, data-scarce scenarios, our proposed MGR-DAS also improved the overall DSC score by 2.6 % on BraTS pediatric (BraTS-PEDs) and by 1.0 % on BraTS-Africa, demonstrating strong generalizability and robustness. Experimental results confirm that the proposed method reliably identifies noisy data, prioritizes clean data through adaptive weighting, and outperforms existing fine-tuning, curriculum learning techniques, and other meta-learning frameworks commonly employed in classification tasks.},
  archive      = {J_EAAI},
  author       = {Abdulkhalek Al-Fakih and Abbas Mohamed Rezk and Abdullah Shazly and Kanghyun Ryu and Mohammed A. Al-masni},
  doi          = {10.1016/j.engappai.2025.112322},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112322},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning robust brain tumor segmentation under label corruption and data scarcity},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale embedding with guided attention for medical image analysis. <em>EAAI</em>, <em>162</em>, 112319. (<a href='https://doi.org/10.1016/j.engappai.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of medical images is pivotal for enhancing diagnostic accuracy and optimizing treatment strategies. Traditional methods encounter challenges in delineating clear inter-class boundaries within high-dimensional feature spaces affected by class overlap. This study introduces a Multi-Scale Embedding with Guided Attention (MSEGA) framework based on deep learning autoencoders that integrates innovative guided attention learning mechanisms without explicit target mask supervision for tumor detection and classification. The framework incorporates Multi-scale Feature Extraction Blocks and Depthwise Separable Convolution Blocks to comprehensively capture image features. Through Channel Attention and Spatial Attention mechanisms, the MSEGA method prioritizes critical tumor regions across scales. We also propose a novel interpretable embedding learning loss function to optimize image embeddings, highlighting crucial regions and refining category distinctions. Empirical evaluations on two brain tumor Magnetic Resonance Imaging (MRI) datasets demonstrate our approach surpasses conventional methods including Convolutional Neural Networks and Vision Transformers in classification accuracy and generalizability. These results underscore the framework’s potential as a versatile artificial intelligence-powered tool in medical image analysis.},
  archive      = {J_EAAI},
  author       = {Zeyan Li and Yifei Peng and Yizun Lin},
  doi          = {10.1016/j.engappai.2025.112319},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112319},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale embedding with guided attention for medical image analysis},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient anchor-free model for ore particle size detection. <em>EAAI</em>, <em>162</em>, 112304. (<a href='https://doi.org/10.1016/j.engappai.2025.112304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection of ore size is crucial in mineral processing, directly impacting equipment efficiency and product quality. However, traditional anchor-based models often struggle with the irregular shapes and varying scales of ore particles, resulting in limited performance. To overcome these challenges, an anchor-free detection framework was proposed. It incorporates a cross-stage partial bottleneck and a spatial pyramid pooling cross-stage partial connections (SPPCSCP-DualConv), both enhanced with dual convolution, to improve feature extraction and multi-scale fusion. In the backbone, the dual convolution module combines group convolution with heterogeneous convolution to improve feature diversity. The SPPCSCP-DualConv module further enhances feature representation in complex backgrounds. Additionally, a simplified path aggregation network (simPANet) feature fusion module is employed in the neck to refine the integration of multi-scale features. The proposed model was trained using a combination of binary cross-entropy, complete intersection over union (IoU), and distribution focal loss to optimize detection accuracy. The proposed model achieved a mean average precision of 86.80 % at an IoU threshold of .5 and 78.50 % across IoU thresholds from .5 to .95, surpassing existing methods while maintaining a lightweight architecture with only 10.10 million parameters and 89.45 giga floating point operations per second. Ablation studies confirmed the effectiveness of the simPANet and SPPCSPC-DualConv modules in enhancing feature representation. Generalization tests across mining sites with similar distributions demonstrated strong performance, although limitations remain for exceptionally large ore blocks due to dataset bias. The proposed model significantly improved the accuracy and efficiency of ore particle size detection, providing reliable real-time insights to improve grinding control and mineral processing operations.},
  archive      = {J_EAAI},
  author       = {Kanghui Zhang and Qingkai Wang and Guobin Zou and Jiawei Yang and Tao Song and Yang Liu and Daoxi Liu},
  doi          = {10.1016/j.engappai.2025.112304},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112304},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient anchor-free model for ore particle size detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance. <em>EAAI</em>, <em>162</em>, 112300. (<a href='https://doi.org/10.1016/j.engappai.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wood surface defect segmentation is extremely critical for defect refinement and quality control of wooden products. However, it is a challenging task to develop an efficient method with current algorithms due to the complicated characteristics of wood defects with obscure boundary, intraclass difference and interclass similarity. To address these issues, a lightweight network via multi-dimension boundary perception and guidance is proposed for precise segmentation of wood defects. At first, based on the Segformer, a boundary prediction branch is added to enrich detailed boundary information in the encoder, and supervised by the Gaussian signal and cosine similarity, to balance the effect of the boundary gradient information. Then, a double-flow enhancing module is designed to integrate the adjacent level features, by embedding two enhancing paths, to adaptively generate discriminative information of the defects. Finally, a binary segmentation head following the predicted map is introduced to strengthen the penalty for the false prediction results of the boundary. Experimental results demonstrate the proposed method outperforms the state-of-the-arts on our wood surface defect dataset, as well as on three public datasets.},
  archive      = {J_EAAI},
  author       = {Yuhang Zhu and Ye Lin and Zhezhuang Xu and Dan Chen and Kunxin Zheng and Yazhou Yuan},
  doi          = {10.1016/j.engappai.2025.112300},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112300},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks. <em>EAAI</em>, <em>162</em>, 112295. (<a href='https://doi.org/10.1016/j.engappai.2025.112295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the wood industry, logs are commonly quality screened by discrete X-ray scans on a moving conveyor belt from a few source positions. Typically, the measurements are obtained in a single two-dimensional (2D) plane (a “slice”) by a sequential scanning geometry. The data from each slice alone does not carry sufficient information for a three-dimensional tomographic reconstruction in which biological features of interest in the log are well preserved. In the present work, we propose a learned iterative reconstruction method based on the Learned Primal-Dual neural network, suited for sequential scanning geometries. Our method accumulates information between neighbouring slices, instead of only accounting for single slices during reconstruction. Evaluations were performed by training U-Nets on segmentation of knots (branches), which are crucial features in wood processing. Our quantitative and qualitative evaluations show that with as few as five source positions our method yields reconstructions of logs that are sufficiently accurate to identify biological features like knots (branches), heartwood and sapwood.},
  archive      = {J_EAAI},
  author       = {Buda Bajić and Johannes A.J. Huber and Benedikt Neyses and Linus Olofsson and Ozan Öktem},
  doi          = {10.1016/j.engappai.2025.112295},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112295},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators. <em>EAAI</em>, <em>162</em>, 112285. (<a href='https://doi.org/10.1016/j.engappai.2025.112285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to long-term outdoor exposure, composite insulators are susceptible to degradation and abnormal temperature rise, making Unmanned Aerial Vehicle (UAV)-based infrared inspections essential for effective monitoring. However, traditional manual interpretation of these images is inefficient and subjective. To improve detection automation and accuracy, we propose an intelligent detection method for composite insulators in infrared images based on an improved You Only Look Once version 11 (YOLOv11) model. The proposed approach introduces Oriented Bounding Boxes (OBBs) for annotation and designs an Angle-Enhanced Probabilistic Intersection over Union (AE-ProbIoU) loss function to enhance the model's ability to detect rotated objects. Experimental results demonstrate that the proposed Angle-Enhanced You Only Look Once (AE-YOLO) model achieves a mAP50:95 of 94.0 % and an angle prediction accuracy of 94.3 %. In addition, a temperature extraction module based on the OBBs is developed to accurately derive the temperature profile of the insulator core rod. This method significantly enhances the intelligence level of infrared image analysis for composite insulators and provides technical support for condition assessment and fault prediction in power transmission lines.},
  archive      = {J_EAAI},
  author       = {Xinzhe Yu and Zhenan Zhou and Yu Deng and Kun Zhang and Chen Gu and Zheyuan Liu and Songsong Zhou},
  doi          = {10.1016/j.engappai.2025.112285},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112285},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures. <em>EAAI</em>, <em>162</em>, 112283. (<a href='https://doi.org/10.1016/j.engappai.2025.112283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of vehicle states is a fundamental component of vehicle stability control systems. To address the issue of inaccurate estimation of vehicle state parameters resulting from yaw rate sensor failures, this study proposes a three-mode collaborative fault-tolerant state estimation method based on Bayesian Bidirectional Long Short-Term Memory (BiLSTM) kinematics-dynamics fusion. First, the kinematics-based method is established using the kinematics model. Second, the dynamics-based method is designed by integrating the Unscented Kalman Filter (UKF) with the dynamics model. Subsequently, a BiLSTM network fusion model based on Bayesian optimization is presented. The model utilizes estimates from kinematic and kinetic methods as a priori inputs and combines the bidirectional information capturing capability of BiLSTM with hyperparameter tuning from Bayesian optimization. The results indicate that when the yaw rate sensor fails, the proposed method achieves an average Root Mean Square Error (RMSE) of 0.0276 km per hour (km/h) for longitudinal speed, 0.0008 radian (rad) for side slip angle, and 0.0072 radian per second (rad/s) for yaw rate across all scenarios. This performance demonstrates a superiority over various maneuvers. This paper combines kinematics, dynamics, and deep learning to provide a reliable solution for fault-tolerant estimation of vehicle states.},
  archive      = {J_EAAI},
  author       = {Min Gao and Jiaqi Li and Wei Wang and Renguang Wang and Jin Luo and Jing Li},
  doi          = {10.1016/j.engappai.2025.112283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-vocabulary object detection via neighboring region attention alignment. <em>EAAI</em>, <em>162</em>, 112270. (<a href='https://doi.org/10.1016/j.engappai.2025.112270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nature of diversity in real-world environments necessitates neural network models to expand from closed category settings to accommodate novel emerging categories. In this paper, we study open-vocabulary object detection (OVD), which facilitates the detection of novel object classes under the supervision of only base annotations and open-vocabulary knowledge. However, we find that the inadequacy of distilled information from the detector head during the alignment process inevitably constrains the performance of recent distillation-based OVD strategies. To this end, we propose Neighboring Region Attention Alignment (NRAA), which performs alignment within the attention mechanism to boost the open-vocabulary inference. Specifically, for a given proposal region, we randomly explore the neighboring boxes to capture the surrounding contextual vocabulary knowledge. Then, a set of regional token features, encompassing both the proposal and neighboring regions, utilize our proposed Neighboring Region Attention (NRA) to extract interaction information. Finally, this information is seamlessly provided to the distillation procedure to assist the alignment between the detector and the pre-trained vision-language models (VLMs). Extensive experiments validate that our proposed model exhibits superior performance on open-vocabulary benchmarks.},
  archive      = {J_EAAI},
  author       = {Sunyuan Qiang and Xianfei Li and Yanyan Liang and Wenlong Liao and Tao He and Pai Peng},
  doi          = {10.1016/j.engappai.2025.112270},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112270},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Open-vocabulary object detection via neighboring region attention alignment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration. <em>EAAI</em>, <em>162</em>, 112269. (<a href='https://doi.org/10.1016/j.engappai.2025.112269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of industrial robots, ensuring operational reliability and Long-Term Autonomy hinges on the accurate detection of anomalies. However, this sample difference due to noise, joint random errors and sensor errors increases the challenge of robot anomaly detection. To address this problem, an unsupervised deep learning method based on inertial measurement unit (IMU) error calibration is proposed. Firstly, the attitude signals acquired by the IMU from the end of the robot were calibrated using Kalman filtering. The three dimensional (3D) free acceleration was corrected based on the calibrated attitude signal and the calibrated 3D free acceleration signal was used as a signal sample. Secondly, a time and frequency convolutional autoencoder model (TFCAE) is proposed. And the distribution of the different component signals is fitted by stacking multiple encoder modules and 3D-TFCAE is used for 3D free acceleration signal reconstruction model. Then, the error sphere radius is calculated based on the reconstruction error of the 3D free acceleration signal. And the error sphere radius is used as the anomaly detection threshold to realize the robust detection of different types of anomalies. The model was evaluated on a constructed anomaly dataset. This study contributes an innovative 3D-TFCAE architecture, integrating Kalman filtering with time-frequency feature fusion, markedly enhancing anomaly detection in complex signal environments. Experimental findings reveal that 3D-TFCAE significantly outperforms 18 baseline models, improving detection accuracy by about 20 %–40 %, offering an effective solution for high-precision anomaly detection in industrial robots. The code for this project is available at https://github.com/LJlong977/3DTFCAE .},
  archive      = {J_EAAI},
  author       = {Jianlong Li and Xiaoqin Liu and Xing Wu and Dongxiao Wang and Kai Xu and Yashan Li},
  doi          = {10.1016/j.engappai.2025.112269},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112269},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging. <em>EAAI</em>, <em>162</em>, 112259. (<a href='https://doi.org/10.1016/j.engappai.2025.112259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic tomography (PAT) offers optical contrast, whereas magnetic resonance imaging (MRI) excels in imaging soft tissue and organ anatomy. The fusion of PAT with MRI holds promising application prospects due to their complementary advantages. Existing image fusion has made considerable progress in pre-registered images, yet spatial deformations are difficult to avoid in medical imaging scenarios. More importantly, current algorithms focus on visual quality and statistical metrics, thus overlooking the requirements of high-level tasks. To address these challenges, we propose an unsupervised fusion model, termed PAMRFuse+, which integrates image generation and registration. Specifically, a cross-modal style transfer network is introduced to simplify cross-modal registration to single-modal registration. Subsequently, a multi-level registration network is employed to predict displacement vector fields. Furthermore, a dual-branch feature decomposition fusion network is proposed to address the challenges of cross-modal feature modeling and decomposition by integrating modality-specific and modality-shared features. PAMRFuse+ achieves satisfactory results in registering and fusing unaligned PAT–MRI datasets. Moreover, for the first time, we evaluate the performance of medical image fusion with multi-organ instance segmentation. Extensive experimental demonstrations reveal the advantages of PAMRFuse+ in improving the performance of medical image analysis tasks.},
  archive      = {J_EAAI},
  author       = {Yutian Zhong and Jinchuan He and Zhichao Liang and Shuangyang Zhang and Qianjin Feng and Lijun Lu and Li Qi},
  doi          = {10.1016/j.engappai.2025.112259},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112259},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph neural network with historic-sequential information representation. <em>EAAI</em>, <em>162</em>, 112234. (<a href='https://doi.org/10.1016/j.engappai.2025.112234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s interconnected world, networks, whether social, technological, or biological, are constantly evolving, with relationships forming, shifting, and dissolving over time. Traditional models struggle to capture this fluidity, treating networks as static snapshots rather than living systems. While existing research has made strides in analyzing either spatial–temporal patterns or temporal sequences separately, these approaches often fall short in scalability and fail to unify discrete and continuous-time perspectives. To bridge this gap, we introduce DyGHS (Dynamic Graph Historical-Sequential), an innovative framework that harnesses dynamic graph neural networks to model how nodes, edges, and their historical interactions evolve together. By seamlessly integrating discrete-time and continuous-time graph representations, DyGHS not only captures the richness of real-world networks but also efficiently predicts future connections and node behaviors. Our experiments reveal that combining continuous-time Fourier transform (CTFT) with graph neural networks significantly boosts prediction accuracy, outperforming current methods in tasks like link prediction and node classification. This advancement opens new doors for understanding and anticipating the ever-changing tapestry of networked systems.},
  archive      = {J_EAAI},
  author       = {Adam Abakar Hamid and Anping Zhao and Alladoumbaye Ngueilbaye},
  doi          = {10.1016/j.engappai.2025.112234},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic graph neural network with historic-sequential information representation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing anomaly detection with few-shot fine-tuned long text-to-image models. <em>EAAI</em>, <em>162</em>, 112174. (<a href='https://doi.org/10.1016/j.engappai.2025.112174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial anomaly detection plays a crucial role in the industrial manufacturing field. Currently, utilizing generated data to improve the performance of the anomaly detection model is an effective approach. However, most existing methods often rely on mask-guided synthesis, where the distribution of the generated defects is limited by masks that are typically random or learned by a model. In addition, the scarcity of real anomalous samples makes it difficult for generative models to capture genuine defect patterns and align with the real anomaly distribution. To tackle these issues, we propose DefectGen, the first long-text-guided few-shot text-to-image data generation pipeline for industrial anomaly detection. To improve distribution alignment under limited anomaly samples, DefectGen incorporates a Prompt Generation and Variation Module, which uses MLLMs (Multimodal Large Language Models) to expand few-shot image–text pairs into diverse and semantically rich prompts, and DoKr (Weight- D ecomposed L o w-Rank Adaptation with Kr onecker product), a lightweight fine-tuning strategy with structured low-rank adaptation. To ensure the quality of synthetic data, DefectGen further introduces the Real-Guided Clustering Filter, which selects high-quality generated samples by comparing their features with those of real anomalies. Experiments on the MVTec AD(MVTec AnomalyDetection) dataset show that DefectGen generates more diverse and realistic synthetic anomalies and achieves a 5.58% average improvement in anomaly classification accuracy compared to state-of-the-art methods. Code and data are available at: https://anonymous.4open.science/r/DefectGen-CD04/ .},
  archive      = {J_EAAI},
  author       = {Jiachen Liu and Jiajia An and Junbin Lu and Zhuoqin Yang and Jinbao Wang and Ping Lu and Yuying Wang and Linlin Shen},
  doi          = {10.1016/j.engappai.2025.112174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing anomaly detection with few-shot fine-tuned long text-to-image models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed fine-tuning for physics discovery from random and sparse data. <em>EAAI</em>, <em>162</em>, 112132. (<a href='https://doi.org/10.1016/j.engappai.2025.112132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although significant advances have been made in both numerical methods and machine learning approaches for solving differential equations across various scientific sectors, these methods often rely on complete information about the differential equations, including precise parameter values, which are not easily obtainable in real-world scenarios. To address this challenge, data-driven methods for discovering differential equations have gained growing popularity in recent years. However, many existing approaches demand unrealistic prerequisites, such as extensive high-fidelity data or carefully designed low-fidelity data and functions. In this paper, we propose a novel method: P hysics- I nformed F ine- T uning ( PIFT ) to discover the unknown parameters in differential equations when only randomly distributed sparse data points are available. PIFT consists of three stages; (i) generating low fidelity data from prior knowledge under realistic settings, (ii) pre-training a single neural network with the generated low fidelity data, and (iii) fine-tuning the pre-trained model using physics-informed loss function. PIFT is evaluated on seven scientific problems including five ordinary differential equations and two partial differential equations. We also demonstrate the robustness and generalizability of PIFT to out-of-distribution tasks. PIFT exhibits high accuracy and robustness in discovering unknown parameters of differential equations from randomly distributed sparse data points.},
  archive      = {J_EAAI},
  author       = {Yong Jin Jeong and Taesup Moon},
  doi          = {10.1016/j.engappai.2025.112132},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112132},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed fine-tuning for physics discovery from random and sparse data},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STEval: A framework for evaluating spatio-temporal crime prediction models. <em>EAAI</em>, <em>162</em>, 112123. (<a href='https://doi.org/10.1016/j.engappai.2025.112123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-Temporal predictive models are crucial for forecasting where and when crimes will occur, aiding public security organizations in resource allocation and crime prevention. Despite numerous literature proposals, a lack of standardized evaluation criteria hinders comparability and reliability. To address this, we propose STEval, a comprehensive and flexible evaluation framework for spatio-temporal predictive models. STEval consists of four modules: data preparation, spatial structure definition, model training, and model evaluation. The framework’s robustness was demonstrated using a 40-million-record crime dataset from Minas Gerais State (Brazil) across five experimental scenarios, including variations in temporal granularity, spatial resolution, and distribution shifts. Results demonstrate that no single model is universally superior, and the most appropriate model depends on the specific application context. For instance, Spatio-Temporal Kernel Density Estimation (STKDE) consistently achieved high Hit Rates (HR), often exceeding 0.98 in fine spatial resolutions (e.g., 100-square meters grid) for violent crimes, while Spatial-Temporal Autoregressive Integrated Moving Average (STARIMA) demonstrated strong performance in temporal granularity tests, reaching HRs of up to 0.65 for theft predictions. Conversely, Extra Tree Regressor, though exhibiting significantly lower HRs (e.g., as low as 0.02 in some spatial tests), consistently provided the fastest execution times, often under 5 s, contrasting with STKDE’s execution times that could extend to thousands of seconds in dense spatial grids. The framework’s detailed analysis provides important insights for informed model selection and optimization, revealing each model’s strengths and limitations, and providing a robust foundation for future advancements in spatio-temporal crime prediction research, leveraging Machine Learning (ML) techniques.},
  archive      = {J_EAAI},
  author       = {Gabriel Amarante and Matheus Pimenta and Yan Andrade and Matheus Senna and Rainer Menezes and Antônio Hot Faria and Marcelo Vilas-Boas and Frederico Martins de Paula Neto and João Paulo da Silva and Everton Renato de Sousa and Jamicel da Silva and Wagner Meira Jr. and George Teodoro and Leonardo Rocha and Renato Ferreira},
  doi          = {10.1016/j.engappai.2025.112123},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112123},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STEval: A framework for evaluating spatio-temporal crime prediction models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ejor">EJOR - 25</h2>
<ul>
<li><details>
<summary>
(2026). Dynamic mode decomposition for online portfolio selection task. <em>EJOR</em>, <em>328</em>(1), 349-365. (<a href='https://doi.org/10.1016/j.ejor.2025.04.049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online portfolio selection (OPS) is a complex task aimed at maximizing investment returns through strategic allocation of capital among risky assets. Traditional Follow the Winner (FTW) strategies, grounded in the Best Constant Rebalanced Portfolios strategy, assume market is independent and identically distributed (i.i.d.), which often fails to capture real-world financial market dynamics, leading to sub-optimal performance in practical applications. To address this limitation, we propose integrating Dynamic Mode Decomposition (DMD) into FTW strategies. DMD is a powerful data-driven technique that originated in the field of fluid dynamics. It is designed to extract coherent structures and identify temporal patterns within complex data. By applying DMD to financial market data, we can uncover underlying patterns and trends that are not apparent under the i.i.d. assumption. Significantly, the integrated DMD in this paper allows for efficient recursion, which is particularly crucial for OPS task. To illustrate the effectiveness of the proposed idea, we consider the Exponential Gradient (EG) strategy as an example and proposed Exponential Gradient with Dynamic Mode Decomposition (EGDMD). The results demonstrate that the proposed EGDMD outperforms traditional EG-type strategies, significantly improves risk-adjusted returns, and maintains computational efficiency. The integration of DMD allows for more accurate identification of market patterns, leading to more effective investment decisions and enhanced portfolio performance.},
  archive      = {J_EJOR},
  author       = {Jiahao Li and Yong Zhang and Xiaoteng Zheng},
  doi          = {10.1016/j.ejor.2025.04.049},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {349-365},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic mode decomposition for online portfolio selection task},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Choice-based crowdshipping for next-day delivery services: A dynamic task display problem. <em>EJOR</em>, <em>328</em>(1), 336-348. (<a href='https://doi.org/10.1016/j.ejor.2025.05.046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies integrating the crowd workforce into next-day home delivery services. In this setting, both crowd drivers and contract drivers collaborate in making deliveries. Crowd drivers have limited capacity and can choose not to deliver if the presented tasks do not align with their preferences. The central question addressed is: How can the platform minimize the total task fulfilment cost, which includes payouts to crowd drivers and additional payouts to contract drivers for delivering the unselected tasks by customizing task displays to crowd drivers? To tackle this problem, we formulate it as a finite-horizon Stochastic Decision Problem, capturing crowd drivers’ utility-driven task preferences, with the option of not choosing a task based on the displayed options. An inherent challenge is approximating the non-constant marginal cost of serving orders not chosen by crowd drivers, which are then assigned to contract drivers. We address this by leveraging a common approximation technique, dividing the service region into zones. Furthermore, we devise a stochastic look-ahead strategy that tackles the curse of dimensionality issues arising in dynamic task display execution and a non-linear (problem specifically concave) boundary condition associated with the cost of hiring contract drivers. In experiments inspired by Singapore’s geography, we demonstrate that choice-based crowd shipping can reduce next-day delivery fulfilment costs by up to 16.9%. The observed cost savings are closely tied to the task display policies and the task choice behaviours of drivers.},
  archive      = {J_EJOR},
  author       = {Alp Arslan and Fırat Kılcı and Shih-Fen Cheng and Archan Misra},
  doi          = {10.1016/j.ejor.2025.05.046},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {336-348},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Choice-based crowdshipping for next-day delivery services: A dynamic task display problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When cost metafrontiers are nonconvex in the outputs, then the production metafrontier is nonconvex: The price of a convexification strategy. <em>EJOR</em>, <em>328</em>(1), 324-335. (<a href='https://doi.org/10.1016/j.ejor.2025.05.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metafrontier analysis is widely used to account for technological heterogeneity among producers. The approach involves combining a number of group-specific production possibilities sets to form a production possibilities metaset. Even though the union of the group sets normally results in a nonconvex metaset, most authors proceed as if this metaset is convex. Kerstens, O’Donnell and Van de Woestyne (2019) obtain new results on the union operator on sets under various assumptions and empirically illustrate that the popular convexification strategy is highly questionable. In this paper we transpose their results on the union operator from a production to a cost context: this is new. We then explore the extent to which convexity of the cost function is corroborated using a newly developed test. Furthermore, we check to which extent a convexification strategy is tenable when estimating a cost metafrontier. We use an original banking data set from China and the USA to illustrate the main issues. We establish that the cost function is not convex in the outputs for China and that the convexification strategy leads to potentially-biased estimates of the cost metafrontier and associated measures of efficiency.},
  archive      = {J_EJOR},
  author       = {Kristiaan Kerstens and Christopher O’Donnell and Ignace Van de Woestyne and Shirong Zhao},
  doi          = {10.1016/j.ejor.2025.05.048},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {324-335},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When cost metafrontiers are nonconvex in the outputs, then the production metafrontier is nonconvex: The price of a convexification strategy},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigating adversarial attacks on transformer models in credit scoring. <em>EJOR</em>, <em>328</em>(1), 309-323. (<a href='https://doi.org/10.1016/j.ejor.2025.05.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of unstructured data, such as text created by borrowers, offers new opportunities for improving credit default prediction but also introduces new risks. This study examines the robustness of transformer-based credit scoring models that utilize textual data and assesses their vulnerability to adversarial attacks. Using peer-to-peer lending data, we show that small, semantically neutral changes in loan descriptions can substantially alter model outputs. These vulnerabilities expose lenders and borrowers to economic risks through distorted risk assessments and mispriced loans. We evaluate two mitigation strategies: adversarial training and topic modeling. Adversarial training improves robustness without compromising predictive performance. Topic modeling provides a more interpretable and stable representation of borrower narratives. An economic analysis confirms that robust models reduce mispricing and improve outcomes for all parties. The findings underscore the importance of robustness as the use of unstructured data in credit scoring becomes more accessible.},
  archive      = {J_EJOR},
  author       = {Brandon Schwab and Johannes Kriebel},
  doi          = {10.1016/j.ejor.2025.05.029},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {309-323},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mitigating adversarial attacks on transformer models in credit scoring},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cost-sensitive single-index classification model. <em>EJOR</em>, <em>328</em>(1), 295-308. (<a href='https://doi.org/10.1016/j.ejor.2025.08.058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-index models (SIMs) are a type of semiparametric model in which a response variable is assumed to be related to a linear combination of explanatory variables by an unknown function, on which any restriction is imposed. Thus, they provide both interpretability and flexibility to capture complex data relationships. In this paper, SIMs are extended to the cost-sensitive classification problem by minimizing the different misclassification costs. The flexibility of SIMs combined with a cost-sensitive approach results in a powerful model to minimize losses and optimize decision making. This is demonstrated through an extensive simulation study and the analysis of five real data sets, where the proposed approach outperforms both parametric and semi-parametric previous approaches.},
  archive      = {J_EJOR},
  author       = {Jorge C-Rella and Ricardo Cao and Juan M. Vilar},
  doi          = {10.1016/j.ejor.2025.08.058},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {295-308},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cost-sensitive single-index classification model},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Diverse ensemble cost-sensitive logistic regression. <em>EJOR</em>, <em>328</em>(1), 282-294. (<a href='https://doi.org/10.1016/j.ejor.2025.07.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, cost-sensitive methods have become increasingly crucial for decision-making in various real-world applications. These methods have been developed for the purpose of minimizing costs or risks for stakeholders. Moreover, the interpretability of cost-sensitive methods has gained considerable attention in critical domains such as finance and medical care. In this article, we propose a diverse ensemble of cost-sensitive logistic regression models to reduce costs for binary classification tasks, as well as a novel algorithm based on the partial conservative convex separable quadratic approximation to solve this non-convex optimization problem. The proposed method demonstrates substantial cost savings through extensive simulations and real-world applications, including fraud detection and gene expression analysis. Additionally, unlike other ensembling techniques, the resulting model of the proposed method is fully interpretable as a logistic regression model and achieves a high level of sparsity induced by the proposed algorithm. We believe this approach offers deeper insights into the relationship between predictors and response, enabling more informed decision-making in practical scenarios.},
  archive      = {J_EJOR},
  author       = {Bing Yang and Stefan Van Aelst and Tim Verdonck},
  doi          = {10.1016/j.ejor.2025.07.028},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {282-294},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Diverse ensemble cost-sensitive logistic regression},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view ensemble feature selection via SemiDefinite programming. <em>EJOR</em>, <em>328</em>(1), 269-281. (<a href='https://doi.org/10.1016/j.ejor.2025.07.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning faces significant challenges in selecting discriminative features while managing redundancy and noise across heterogeneous data sources. To address these issues, this paper introduces Multi-view Ensemble Feature Selection (MEFS), a novel framework that systematically integrates view generation (VG) and view selection (VS) through a unified optimization paradigm. By reformulating feature selection as a MaxCut problem and leveraging SemiDefinite Programming (SDP) relaxation, MEFS dynamically balances the generalization capability of individual views with their pairwise diversity, eliminating the need for manual parameter tuning. A key innovation is the proposed pairwise diversity metric, which quantifies inter-view dissimilarity using between-class scatter matrices to ensure complementary feature subsets. Extensive experiments on ten benchmark datasets demonstrate that MEFS consistently outperforms state-of-the-art methods in accuracy, robustness, and computational efficiency. Ablation studies validate the synergistic effect of combining VG and VS modules.},
  archive      = {J_EJOR},
  author       = {Xiaojian Ding and Xin Wang and Pengcheng Shi},
  doi          = {10.1016/j.ejor.2025.07.014},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {269-281},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-view ensemble feature selection via SemiDefinite programming},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the price of diversity for multiwinner elections under (weakly) separable scoring rules. <em>EJOR</em>, <em>328</em>(1), 258-268. (<a href='https://doi.org/10.1016/j.ejor.2025.06.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a model of multi-winner elections, where each voter expresses a linear preference over a finite set of alternatives. Based on voters’ preferences, the primary goal is to select a subset of admissible alternatives, forming what is referred to as a committee. We explore (weakly) separable committee scoring rules, the voting mechanisms that assess each alternative individually using a scoring vector and select the top k alternatives, where k represents the committee’s size. Furthermore, we operate under the assumption that alternatives are categorized based on specific attributes. Within each attribute category, there exists a targeted minimum number of alternatives that the selected committee should encompass, emphasizing the necessity for diversity. In this context, we assess the cost associated with imposing such a diversity constraint on the voting process. This assessment is conducted through two methodologies, referred to as the “price of diversity” and the “individual price of diversity”. We set the upper bounds for both prices across all (weakly) separable committee scoring rules. Additionally, we show how the maximum price of diversity can be used to discriminate between different voting rules in this context. Ultimately, we illustrate that concentrating on the candidates’ performance yields a more accurate estimation of the price of diversity compared to a focus on the enforced diversity constraint.},
  archive      = {J_EJOR},
  author       = {Mostapha Diss and Clinton Gubong Gassi and Eric Kamwa},
  doi          = {10.1016/j.ejor.2025.06.013},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {258-268},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the price of diversity for multiwinner elections under (weakly) separable scoring rules},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonconvex truncated conditional value at risk-based sparse linear regression. <em>EJOR</em>, <em>328</em>(1), 246-257. (<a href='https://doi.org/10.1016/j.ejor.2025.06.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional value at risk (CVaR) is a widely recognized risk measure used to manage data uncertainty within risk management. In this paper, we study a class of sparse linear regression models based on truncated CVaR measure and ℓ 0 -norm regularization. Due to the nonconvexity and nonsmoothness of the objective functions, as well as the NP-hardness of the problem with the ℓ 0 -norm regularization, we propose an approximation model that employs a tight relaxation of the ℓ 0 -norm. The solution equivalence between the proposed model and its approximation model is explored. To efficiently solve the approximation model, we develop a semismooth Newton-based proximal majorization-minimization algorithm. Furthermore, the convergence analysis of the proposed algorithm is presented, and the convergence rate for the reduced CVaR-based sparse linear regression model is established. Moreover, extensive numerical experiments conducted on both synthetic and real datasets validate the stability and effectiveness of the proposed algorithm, demonstrating significant improvements in both sparsity and accuracy compared to existing state-of-the-art methods.},
  archive      = {J_EJOR},
  author       = {Boyi Xie and Zhongming Wu and Min Li},
  doi          = {10.1016/j.ejor.2025.06.004},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {246-257},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nonconvex truncated conditional value at risk-based sparse linear regression},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Designing and computing explanations for comparisons inferred from an additive value model. <em>EJOR</em>, <em>328</em>(1), 232-245. (<a href='https://doi.org/10.1016/j.ejor.2025.05.058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many decision models are based on an additive representation of preferences. Recommendations obtained from such additive decision models are sometimes considered as self-evident. On the contrary, we claim that these recommendations deserve an explanation so as to be fully understood by the user/decision-maker and to foster her trust. We propose to explain a preference statement x preferred to y by decomposing this statement into simpler ones. Arguments in favor of x (Pros), and arguments in favor of y (Cons) are decomposed using a covering scheme in which each Con is covered by a Pro. We use a decomposition language in which elementary self-evident statements involve ( i ) one Pro against one Con, ( ii ) one pro against several Cons, or ( iii ) several Pros against one Con. We prove that computing such explanations is computationally difficult in case ( ii ) and ( iii ), and propose a mathematical programming formulation to solve it. Numerical experiments provide insights on the actual behavior of our algorithm. We also illustrate the usefulness of our approach in the context of multicriteria decision aid but also for machine learning approaches.},
  archive      = {J_EJOR},
  author       = {Manuel Amoussou and Khaled Belahcene and Nicolas Maudet and Vincent Mousseau and Wassila Ouerdane},
  doi          = {10.1016/j.ejor.2025.05.058},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {232-245},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing and computing explanations for comparisons inferred from an additive value model},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bayesian variable selection in kriging metamodeling for quality design. <em>EJOR</em>, <em>328</em>(1), 216-231. (<a href='https://doi.org/10.1016/j.ejor.2025.06.003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of production processes and rapid developments in digital technology have fueled the adoption of metamodels in quality design. Kriging has emerged as one of the most popular emulation methods for both deterministic and stochastic simulations. Conventional Kriging models with predetermined mean functions, such as ordinary or universal Kriging, may exhibit subpar predictive performance when strong trends exist. This paper proposes a novel variable selection procedure for the mean function that ensures prediction accuracy while using only a limited number of variables to capture the potential existing trends in deterministic simulations. The proposed method integrates the benefits of Bayesian variable selection and frequentist statistical tests. Initially, a group of potential models is chosen to build the mean function, employing the Bayesian method with priors designed to guarantee sparsity. This results in a significant reduction in the number of models to be considered in the next stage. Subsequently, each candidate model undergoes rigorous frequentist tests to thoroughly assess its reliability and validity. Extensive simulation studies are conducted using the well-known Borehole function and a real-life case. The results demonstrate the superiority of the proposed method over several existing approaches, establishing its effectiveness in achieving robust parameter design.},
  archive      = {J_EJOR},
  author       = {Baoping Tao and Zifei Han and Wen Shi and Min Wang and Linhan Ouyang},
  doi          = {10.1016/j.ejor.2025.06.003},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {216-231},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bayesian variable selection in kriging metamodeling for quality design},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design and pricing of extended warranty menus with reference effects. <em>EJOR</em>, <em>328</em>(1), 201-215. (<a href='https://doi.org/10.1016/j.ejor.2025.05.056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer durables increasingly come with extended warranty menus—beyond manufacturers’ base warranties—that offer multiple options with differentiated protection lengths and prices. When choosing from an extended warranty menu, consumers might not only evaluate the intrinsic utility of each option but also form a reference point against which the available options are compared. In this paper, we posit that consumers compare the price-length ratios of available options when determining their willingness to pay, and investigate the design and pricing of extended warranty menus under such reference effects. To this end, we adapt the standard multinomial logit choice model to incorporate two types of reference point that are generated endogenously and exogenously, respectively, with respect to the given menu. We show that if the warranty options are ordered in the protection length, then the optimal pricing policies prescribe the same adjusted markup and the same price-length ratio alternately. We further extend our analysis to price competition under reference effects, where multiple firms compete in the aftermarket, each offering a single extended warranty. We prove the existence of a unique Nash equilibrium and develop an efficient method to identify it. Numerical examples are presented to illustrate the analytical findings, and sensitivity analyses are conducted to examine the impact of reference-effect coefficients on the optimal pricing policies. Overall, this work highlights the importance of incorporating reference effects into the design and pricing of extended warranty menus.},
  archive      = {J_EJOR},
  author       = {Xiao-Lin Wang and Chenglong Li and Junjie Wang},
  doi          = {10.1016/j.ejor.2025.05.056},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {201-215},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Design and pricing of extended warranty menus with reference effects},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Planning bayesian reliability demonstration tests via a generalized test statistic. <em>EJOR</em>, <em>328</em>(1), 189-200. (<a href='https://doi.org/10.1016/j.ejor.2025.08.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability demonstration testing (RDT) has been extensively employed to verify whether a product meets specific reliability requirements at a desired confidence level. Driven by intense market competition and constrained test resources, manufacturers are motivated to seek effective strategies to reduce the testing efforts required for RDT. In this paper, we propose a method that utilizes existing knowledge and information obtained from the product design and development phase to construct a Bayesian prior distribution of the product’s reliability. Based on this prior, a preliminary disposition decision on whether to accept or reject the product is made. A subsequent demonstration test is needed only when the prior information is deemed insufficient for an immediate disposition. A RDT planning method is developed based on the posterior distribution of the product’s reliability, which is applicable to general cases involving non-conjugate priors. We study two types of demonstration testing: binomial and exponential. For each, we prove the existence of an optimal test plan and develop an efficient searching algorithm to determine it. Numerical studies are conducted to demonstrate the effectiveness of the proposed method, supplemented by a case study on RDT for systems of different configurations. Overall, this work provides a unified and effective framework for reliability demonstration under the Bayesian paradigm.},
  archive      = {J_EJOR},
  author       = {Zan Li and Jianyu Xu and Chengjie Wang and Xiao-Lin Wang},
  doi          = {10.1016/j.ejor.2025.08.011},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {189-200},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Planning bayesian reliability demonstration tests via a generalized test statistic},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A primal–dual policy iteration algorithm for constrained markov decision processes. <em>EJOR</em>, <em>328</em>(1), 174-188. (<a href='https://doi.org/10.1016/j.ejor.2025.08.038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution algorithms of Constrained Markov Decision Process (CMDP), a widely adopted model for sequential decision-making, have been intensively studied in the literature. Despite increasing effort, the Linear Programming (LP) formulation of CMDP remains the dominant exact method that leads to the optimal solution without constraint violations. However, the LP formulation is computationally inefficient due to the curse of dimensionality in CMDP state and action spaces. In this study, we introduce a novel policy iteration method for CMDP, based on decomposition and row-generation techniques. We design a Primal–Dual Policy Iteration (PDPI) algorithm that utilizes state values and Lagrangian multipliers to improve randomized stationary policies in an iterative fashion. We analytically show that upon convergence, PDPI produces the optimal solution for CMDP. An upper bound of the convergence iterations is also given. To validate the algorithm performance, we conduct comprehensive computational experiments on six benchmarking problems curated from the literature. Results show that PDPI outperforms conventional methods considerably, improving the total algorithm runtime by up to 89.19%. The improvement becomes more significant as the problem size grows larger. We further provide insights and discuss the impact of the developed method.},
  archive      = {J_EJOR},
  author       = {Zeyu Liu and Xueping Li and Anahita Khojandi},
  doi          = {10.1016/j.ejor.2025.08.038},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {174-188},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A primal–dual policy iteration algorithm for constrained markov decision processes},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Controlling antithetic variates. <em>EJOR</em>, <em>328</em>(1), 162-173. (<a href='https://doi.org/10.1016/j.ejor.2025.08.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish and investigate a theoretical framework for controlling covariance matrices in the method of antithetic variates through control variates to further reduce estimator variance. Instead of preemptively and carefully designing an estimator vector with negatively correlated components, the proposed framework starts with a predefined estimator vector that incorporates specified control variates. The weights and control matrix are then analytically determined through matrix algebra. The joint optimality of the resulting estimator variance is ensured with respect to both the weights and the control matrix, with closed-form implementable formulas derived for the optimal parameter pair. Numerical results are provided for various typical examples to illustrate the effectiveness, potential, and challenges of the proposed framework.},
  archive      = {J_EJOR},
  author       = {Reiichiro Kawai},
  doi          = {10.1016/j.ejor.2025.08.027},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {162-173},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Controlling antithetic variates},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust multi-period blood inventory routing under multiple uncertainties. <em>EJOR</em>, <em>328</em>(1), 137-161. (<a href='https://doi.org/10.1016/j.ejor.2025.05.036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a multi-period blood inventory routing problem that integrates production, inventory, and distribution decisions under uncertainties in demand, donation supply, and travel times, all while accounting for the limited shelf life of blood products. Our model captures transportation efficiency through a disutility measure based on vehicles’ arrival times at hospitals, and addresses supply–demand imbalances by allowing selective rejection of service requests at a high penalty cost. We formulate a robust optimization model that simultaneously determines production quantities, inventory levels, hospital service selections, and vehicle routing for each period. The objective is to minimize the total cost over the planning horizon, which includes worst-case inventory holding, wastage, and transportation costs, unserved demand penalties, and overall transportation disutility. To obtain an exact solution, we propose an integrated algorithm within the L -shaped framework that combines Benders decomposition with a branch-and-price-and-cut (BPC) scheme. This approach decomposes the robust model into a master problem and period-specific subproblems. For a given master solution, we first use constraint programming to verify the feasibility of the subproblems, and then, if feasible, solve them with a tailored BPC algorithm to generate Benders cuts that eliminate suboptimal master solutions. Extensive numerical experiments, including a case study at the Blood Center in Chongqing, demonstrate the effectiveness of our approach. Our analysis quantifies the benefits of incorporating uncertainty and robustness while providing managerial insights through a systematic evaluation of various parameters.},
  archive      = {J_EJOR},
  author       = {Ling Qing and Yunqiang Yin and Joshua Ignatius and Dujuan Wang},
  doi          = {10.1016/j.ejor.2025.05.036},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {137-161},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust multi-period blood inventory routing under multiple uncertainties},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-driven joint optimization of maintenance and spare parts provisioning: A distributionally robust approach. <em>EJOR</em>, <em>328</em>(1), 122-136. (<a href='https://doi.org/10.1016/j.ejor.2025.06.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the joint optimization of condition-based maintenance and spare provisioning, incorporating insights obtained from sensor data. Prognostic models estimate components’ remaining lifetime distributions (RLDs), which are integrated into an optimization model to coordinate maintenance and spare provisioning. The existing literature addressing this problem assumes that prognostic models provide accurate estimates of RLDs, thereby allowing a direct adoption of Stochastic Programming or Markov Decision Process methodologies. Nevertheless, this assumption often does not hold in practice since the estimated distributions can be inaccurate due to noisy sensors or scarcity of training data. To tackle this issue, we develop a Distributionally Robust Chance Constrained (DRCC) formulation considering general discrepancy-based ambiguity sets that capture potential distribution perturbations of the estimated RLDs. The proposed formulation admits a Mixed-Integer Linear Programming (MILP) reformulation, where explicit formulas are provided to simplify the general discrepancy-based ambiguity sets. Finally, for the numerical illustration, we test a type- ∞ Wasserstein ambiguity set and derive closed-form expressions for the parameters of the MILP reformulation. The efficacy of our methodology is showcased in a wind turbine case study, where the proposed DRCC formulation outperforms other benchmarks based on stochastic programming and robust optimization.},
  archive      = {J_EJOR},
  author       = {Heraldo Rozas and Weijun Xie and Nagi Gebraeel and Stephen Robinson},
  doi          = {10.1016/j.ejor.2025.06.025},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {122-136},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven joint optimization of maintenance and spare parts provisioning: A distributionally robust approach},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards blockchain-enabled circular closed-loop supply chain and impact of consumers’ distrust in price, product greenness sensitivity and carbon tax and subsidy. <em>EJOR</em>, <em>328</em>(1), 105-121. (<a href='https://doi.org/10.1016/j.ejor.2025.06.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing emphasis on environmental sustainability, both governments and consumers are more concerned than ever about the greenness of products. In this complex landscape, Supply Chains (SCs) face challenges in building trust and avoiding greenwashing accusations. Blockchain technology offers a promising solution by ensuring transparency and circularity within SCs, particularly in identifying customers for product recycling. This study pioneers the exploration of consumers' distrust in pricing and product greenness, alongside the impact of carbon policies (taxes and subsidies) within a closed-loop supply chain (CLSC). Using classical Stackelberg game theory, we develop two models that identify equilibrium decisions for SC members, focusing on pricing, green production investment, circularity, and blockchain adoption. Additionally, we propose an evolutionary game theory model to find the optimal government policies and identify the long-term behaviour of the CLSC and government in two heterogeneous populations. Our findings reveal that if the retailer's share of blockchain costs falls below a certain threshold, blockchain adoption becomes less profitable than exclusive investment in green production. A higher (lower) subsidy rate benefits (harms) the retailer but disadvantages (benefits) the collector. Blockchain adoption is generally more profitable for manufacturers and retailers, though less so for collectors, and it also drives greater investment in green production. While subsidies encourage blockchain adoption, they are not a sustainable long-term strategy for governments. Ultimately, the evolutionarily stable strategy for SCs involves a balanced investment in both green production and blockchain or green production alone, depending on market characteristics and cost-sharing structures.},
  archive      = {J_EJOR},
  author       = {Mohammad Akbarzadeh Sarabi and Ata Allah Taleizadeh and Arijit Bhattacharya},
  doi          = {10.1016/j.ejor.2025.06.030},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {105-121},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Towards blockchain-enabled circular closed-loop supply chain and impact of consumers’ distrust in price, product greenness sensitivity and carbon tax and subsidy},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A split-embedded metaheuristic for the heterogeneous inventory routing problem with batch size. <em>EJOR</em>, <em>328</em>(1), 91-104. (<a href='https://doi.org/10.1016/j.ejor.2025.05.044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling transportation and inventory management simultaneously is a challenging problem. The most famous optimization problem in this domain, known as the Inventory Routing Problem (IRP), aims to determine the routes and quantities to be delivered by a set of vehicles to meet customer demands at a minimum total inventory and transportation cost. The vast majority of works carried out so far on the IRP consider a homogeneous fleet of vehicles. This paper addresses, instead, a new IRP variant that considers intrinsic characteristics of real supply chains, such as a period-dependent heterogeneous fleet of vehicles and batch sizes for the delivered quantities. We model the problem with a Mixed Integer Linear Programming (MILP) formulation and propose a Split-Embedded Metaheuristic with a Post-Optimization phase (SEMPO) to solve it. Extensive computational experiments are conducted on a set of 80 new benchmark instances with up to 183 customers and a challenging time horizon of up 7 to 28 time periods to evaluate the performance of our approaches. The proposed SEMPO algorithm provides high-quality solutions and faster convergence compared to the MILP formulation.},
  archive      = {J_EJOR},
  author       = {Diego Perdigão Martino and Philippe Lacomme and Katyanne Farias},
  doi          = {10.1016/j.ejor.2025.05.044},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {91-104},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A split-embedded metaheuristic for the heterogeneous inventory routing problem with batch size},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The role of scarcity behavior in inventory management. <em>EJOR</em>, <em>328</em>(1), 78-90. (<a href='https://doi.org/10.1016/j.ejor.2025.05.043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-known phenomenon related to inventory, but often neglected in inventory management, is the scarcity effect, i.e., the increase in the demand if inventory is low. We consider a repeated purchase setting with a single firm and multiple buyers and address the question of whether inventory management decisions concerning the control policy and the service configuration (determining when and how much to order) impact scarcity behavior arising from buyers’ stock-out perception. We study common inventory control policies that assume a demand independent of the inventory management, and we challenge this critical assumption of an exogenous demand. This research explores two prevalent classes of inventory policies widely used in practice (periodic and continuous) configured according to fill rates, a popular way of measuring service. We conduct a laboratory experiment with four automated inventory management treatments (2 policies × 2 configurations) where participants act as buyers. We observe stock-out induced scarcity and find support for the hypothesis that the periodic policy leads to a stronger effect compared to the continuous policy if the service level is low. The study also supports the hypothesis that buyers act forward-looking as their demand peaks before the inventory reaches its lowest level. Overall, our research provides a new perspective on inventory management as it reveals that the chosen control policy and the selected service configuration influence stock-out pressure induced inventory runs. Inventory managers should be aware of scarcity effects and its consequences, like the disadvantages of a periodic policy for low service level.},
  archive      = {J_EJOR},
  author       = {Sebastian Schiffels and Christian Jost},
  doi          = {10.1016/j.ejor.2025.05.043},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {78-90},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The role of scarcity behavior in inventory management},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Green scheduling with time-of-use tariffs and machine states: Optimizing energy cost via branch-and-bound and bin packing strategies. <em>EJOR</em>, <em>328</em>(1), 64-77. (<a href='https://doi.org/10.1016/j.ejor.2025.06.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-bound algorithm, enhanced with bin packing strategies, for scheduling under variable energy pricing and power-saving states. The proposed algorithm addresses the 1 , TOU | states | TEC problem, which involves scheduling jobs to minimize total energy cost (TEC) while considering time-of-use (TOU) electricity prices and different machine states (e.g., processing, idle, off). Key innovations include instance pre-processing for rapid lower bound calculations, a novel branching scheme combined with initializations, a block-finding primal heuristic, and a tighter lower bound for jobs with non-coprime processing times. These enhancements result in an efficient algorithm capable of solving benchmark instances with real energy prices with 200 jobs more than 100 times faster than existing state-of-the-art methods.},
  archive      = {J_EJOR},
  author       = {Ondřej Benedikt and István Módos and Antonin Novak and Zdeněk Hanzálek},
  doi          = {10.1016/j.ejor.2025.06.026},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {64-77},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Green scheduling with time-of-use tariffs and machine states: Optimizing energy cost via branch-and-bound and bin packing strategies},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flight test scheduling: A generic model, lower bounds, and iterated local search. <em>EJOR</em>, <em>328</em>(1), 49-63. (<a href='https://doi.org/10.1016/j.ejor.2025.06.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flight tests play a critical role in the R&D process for new aircraft as they help verify the airworthiness and capabilities and expose design and manufacturing defects. During the test course, a large number of tasks need to be scheduled appropriately so that the flight tests can be completed with minimum cost and high efficiency. Therefore, there is a strong need for developing an efficient method that can generate high-quality test schedules. In this paper, we study flight test scheduling to minimize the number of required test flights, thereby decreasing the cost and time required during the entire test course. We establish a mixed-integer programming model to formally describe the problem, propose several computationally efficient lower bounds to help verify the quality of obtained solutions, and develop an iterated local search algorithm for generating a high-quality solution in an effective manner. Comprehensive computational experiments are performed to demonstrate the efficiency of our proposed algorithm. We report some general managerial insights based on the obtained computational results.},
  archive      = {J_EJOR},
  author       = {Hanqiao Tao and Guopeng Song and Roel Leus and Zhe Liang and Jiang Jiang},
  doi          = {10.1016/j.ejor.2025.06.001},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {49-63},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flight test scheduling: A generic model, lower bounds, and iterated local search},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nested logic-based benders decomposition for an integrated home healthcare problem. <em>EJOR</em>, <em>328</em>(1), 32-48. (<a href='https://doi.org/10.1016/j.ejor.2025.06.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we apply nested logic-based Benders decomposition to solve an integrated home healthcare staffing, assignment, routing, and scheduling problem with application in Norway. The proposed method operates at two decomposition levels. Consequently, the entire problem is decomposed into three hierarchical sub-problems: the staffing problem, the assignment problem, and the routing and scheduling problem. These sub-problems are interrelated through two levels of logic-based Benders cuts. Computational experiments on 40 test instances demonstrate the superior performance of nested logic-based Benders decomposition compared to directly solving a mixed-integer linear programming model available in the literature. Specifically, the proposed solution method achieved proven optimality in 28 instances and provided feasible solutions for the remaining 12 instances. In contrast, directly solving the mixed-integer linear programming model yielded proven optimality in 16 instances, provided feasible solutions for 20 instances, and failed to find feasible solutions for 4 instances within the same computational time limit.},
  archive      = {J_EJOR},
  author       = {Abdalrahman Algendi and Sebastián Urrutia and Lars Magnus Hvattum and Rafael A. Melo},
  doi          = {10.1016/j.ejor.2025.06.006},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {32-48},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nested logic-based benders decomposition for an integrated home healthcare problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A reduction approach for the parallel machine scheduling problem with a separate server for loading and unloading operations. <em>EJOR</em>, <em>328</em>(1), 15-31. (<a href='https://doi.org/10.1016/j.ejor.2025.05.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the non-preemptive identical parallel machine scheduling problem with a dedicated loading server and a dedicated unloading server. Each job has to be loaded by the dedicated loading server immediately before being processed on one of the identical parallel machines, and unloaded immediately by the dedicated unloading server after its processing. The objective function involves the minimization of the makespan. This problem arises in the semiconductor industry, plastic injection industry, kitchen production systems, healthcare, container terminals, and many other industrial fields. We prove the problem to be strongly NP-hard, analyze a special case with identical loading, processing, and unloading times, and establish a tight lower bound. In addition, we propose two novel mixed-integer linear programming formulations: one utilizing time-indexed variables with an iterative strengthening algorithm, and the other employing linear-ordering variables along with two enhanced valid inequalities. Given the complexity of the problem, we introduce a reduction approach that simplifies the problem by modifying certain constraints, enabling the determination of a feasible solution much more quickly. Building on this reduction, we provide a linear-time reduction algorithm and a fast formulation based on assignment-and-positional date variables. Furthermore, we study a special case involving regular jobs. To solve large-scale instances of the problem with up to 250 jobs and up to 5 machines, we design a hybrid approach combining an iterated greedy algorithm with variable neighborhood descent. As shown in the computational experiments on two sets of benchmark instances, the reduction approach significantly outperforms all previous methods existing in the literature.},
  archive      = {J_EJOR},
  author       = {Abdelhak Elidrissi and Jatinder N.D. Gupta and Rachid Benmansour and Bertrand M.T. Lin},
  doi          = {10.1016/j.ejor.2025.05.030},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {15-31},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A reduction approach for the parallel machine scheduling problem with a separate server for loading and unloading operations},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cutting stock problem with usable leftovers: A review. <em>EJOR</em>, <em>328</em>(1), 1-14. (<a href='https://doi.org/10.1016/j.ejor.2025.03.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a comprehensive literature review of the Cutting Stock Problem with Usable Leftovers (CSPUL). The most recent review on this topic dates to 2014, covering articles published before 2013. Since then, the number of publications on CSPUL has increased significantly, driven by new applications and more efficient solution approaches. We analyze fifty two relevant articles from twenty four different journals, focusing on works published after 2008 while acknowledging foundational contributions from the 1980s and 1990s. This review categorizes variations of CSPUL based on their dimensions (1D, 2D, and 3D), planning period characteristics (single-period and multi-period), objective functions, and solution methods. The article provides a detailed summary of the key features in the mathematical models and solution methods proposed in these studies. Additionally, it highlights several industrial applications of CSPUL, illustrating its practical relevance. Through this analysis, we identify important applications and propose promising directions for future research. The findings and insights presented here have practical implications for optimizing resource utilization and promoting sustainability in industries facing cutting challenges.},
  archive      = {J_EJOR},
  author       = {Victor Senergues and Nadjib Brahimi and Adriana Cristina Cherri and François Klein and Olivier Péton},
  doi          = {10.1016/j.ejor.2025.03.014},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cutting stock problem with usable leftovers: A review},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="eswa">ESWA - 212</h2>
<ul>
<li><details>
<summary>
(2026). RAFN: A risk-aware feature network for identifying risk factors in supply chain finance. <em>ESWA</em>, <em>298</em>, 129874. (<a href='https://doi.org/10.1016/j.eswa.2025.129874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As supply chain finance businesses expand, traditional risk assessment systems, which rely heavily on manual processes and static rule-based frameworks, are increasingly unable to keep up with the complexity and dynamism of modern risk patterns. This often leads to delayed responses and inefficiencies in risk management. To address key challenges such as difficulties in integrating heterogeneous data, low detection rates for hidden risks, and limited ability to capture dynamic risk patterns, this paper introduces a novel Risk-Aware Feature Network (RAFN) driven by an adaptive attention mechanism. The RAFN model is designed with a dual-channel architecture to process numerical and categorical data separately, employs gated linear units to dynamically merge heterogeneous data streams, and incorporates a multi-head attention mechanism with dynamic coefficients to focus on risk-sensitive features adaptively. Experiments conducted on both public and proprietary datasets show that RAFN outperforms mainstream algorithms, achieving a 1.73%-5.81% improvement in accuracy, recall, and F1-score, while maintaining a strong balance between specificity and recall. Furthermore, this study proposes a closed-loop risk management framework based on RAFN, which integrates “smart contract triggering, off-chain model evaluation, and on-chain consensus validation.” This approach offers an efficient technical solution to break down data silos and enhance the precision of risk identification in supply chain finance, paving the way for more effective and reliable risk control systems.},
  archive      = {J_ESWA},
  author       = {Yang Zhang and Yating Zhao and Wenjuan Lian and Bin Jia},
  doi          = {10.1016/j.eswa.2025.129874},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129874},
  shortjournal = {Expert Syst. Appl.},
  title        = {RAFN: A risk-aware feature network for identifying risk factors in supply chain finance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Photovoltaic cluster power ultra-short-term cross-seasonal prediction integrating multi-channel information probabilistic diffusion generation and improved offset loss strategy. <em>ESWA</em>, <em>298</em>, 129826. (<a href='https://doi.org/10.1016/j.eswa.2025.129826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate photovoltaic (PV) power prediction under complex meteorological conditions remains challenging, particularly given the pronounced seasonal variations that obscure generation patterns. This study presents a novel ultra-short-term prediction framework integrating meteorological volatility analysis with seasonal characteristic modeling. We developed a specialized multi-channel Gram angular summation field (MGASF) transformation matrix to holistically capture meteorological fluctuations, subsequently leveraging denoising diffusion probabilistic model (DDPM) for strategic augmentation of under-represented weather scenarios to enhance similar-day identification. Our hybrid architecture combines multi-channel vision Transformer (VIT) with bidirectional long and short-term memory (BILSTM) networks to synergistically analyze temporal dependencies and spatial patterns in PV similarity recognition. Furthermore, we engineered a seasonal-adaptive prediction system through an improved variable-weight Smooth L1 loss function, establishing an optimized seasonal alignment mechanism that achieves high-precision prediction across varying meteorological conditions with minimal computational overhead. Through rigorous validation using operational data from a utility-scale photovoltaic cluster in Western Inner Mongolia, the proposed method achieved consistent accuracy improvements: 3.02 % reduction in N RMSE , 1.65 % decrease in N MAE , and 2.19 % enhancement in R 2 compared to baseline approaches in PV cluster. These statistically significant enhancements demonstrate our framework’s capability to mitigate seasonal impacts while maintaining prediction reliability in complex meteorological environments.},
  archive      = {J_ESWA},
  author       = {Mao Yang and Yue Jiang and Yunfeng Guo and Jianfeng Che and Wei He and Kang Wu},
  doi          = {10.1016/j.eswa.2025.129826},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129826},
  shortjournal = {Expert Syst. Appl.},
  title        = {Photovoltaic cluster power ultra-short-term cross-seasonal prediction integrating multi-channel information probabilistic diffusion generation and improved offset loss strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sustainable time-dependent intermodal hub-and-spoke logistic network considering hub failure: A mathematical model and a hybrid artificial bee colony algorithm. <em>ESWA</em>, <em>298</em>, 129804. (<a href='https://doi.org/10.1016/j.eswa.2025.129804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the design of a sustainable hub-and-spoke logistics network that integrates intermodal transportation between the hubs, hub failures, time dependency, and environmental parameters. Accordingly, we propose a novel mixed-integer linear programming (MILP) model and a hybrid artificial bee colony-based algorithm (HABCb) to minimize transportation costs and emissions in robust network configurations. The model is the first to simultaneously integrate intermodality, sustainability metrics, and hub disruption scenarios within a single framework. Computational experiments using real-life data from Turkey demonstrate that the proposed HABCb approach outperforms both genetic algorithm (GA) and artificial bee colony (ABC) algorithm. On medium-sized problem sets, it achieves average cost reductions of 7% compared to GA and 10% compared to ABC algorithm, while on large-sized problems the reductions are 10% and 15%, respectively. Furthermore, the HABCb approach provides faster convergence and higher-quality solutions for larger problem sizes. The findings highlight the practical and theoretical insights of incorporating sustainability, intermodality, and robustness into hub-and-spoke network design.},
  archive      = {J_ESWA},
  author       = {Burcu Tokbay Erkek and Salih Himmetoğlu and Yılmaz Delice and Emel Kızılkaya Aydoğan},
  doi          = {10.1016/j.eswa.2025.129804},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129804},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sustainable time-dependent intermodal hub-and-spoke logistic network considering hub failure: A mathematical model and a hybrid artificial bee colony algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated universal information extraction for chinese legal texts. <em>ESWA</em>, <em>298</em>, 129801. (<a href='https://doi.org/10.1016/j.eswa.2025.129801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing knowledge graphs in legal domains requires simultaneous extraction of entities and relations. To reduce repeated modeling in traditional approaches, we adopt the Universal Information Extraction (UIE) model as a foundation and propose an enhanced variant named Adaptive Gated Universal Information Extraction (AGUIE). This study develops a new decoder based on the Adaptive Focusing Gated Attention Unit (AFGAU). This unit enhances the standard Gated Attention Unit (GAU) by integrating two key components—learnable dynamic convolution and reset/update gating mechanisms. Moreover, the study employs a cross-pointer structure as the output layer to better identify information boundaries. To support this study, we construct a domain specific dataset for extracting key information from legal judgment documents. Systematic comparative analysis and ablation studies demonstrate that AGUIE achieves significant performance gains over baseline UIE, with an F1 score of 85.56% on our legal judgment documents dataset. Additionally, we evaluate the model’s generalization on public datasets such as ACE04, ACE05, and CoNLL04, covering both entity recognition and relation extraction tasks. Experimental results indicate that AGUIE demonstrates competitive results with recent studies on ACE04-Ent and CoNLL04, outperforms them on the ACE05 dataset, achieving F1 scores of 87.19% on ACE05-Ent and 79.29% on ACE05-Rel. In conclusion, AGUIE is a reliable and effective solution for universal information extraction in both legal and general domains.},
  archive      = {J_ESWA},
  author       = {Yabo Liu and Yatong Zhou and Kuo-Ping Lin},
  doi          = {10.1016/j.eswa.2025.129801},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129801},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated universal information extraction for chinese legal texts},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatiotemporal online fuzzy modeling with knowledge-driven differential evolution automatic clustering for distributed parameter systems. <em>ESWA</em>, <em>298</em>, 129785. (<a href='https://doi.org/10.1016/j.eswa.2025.129785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed parameter systems are prevalent in various industrial processes and attract significant attention. However, these systems exhibit complex spatiotemporal coupling characteristics, and effectively determining the fuzzy rules of the antecedent set is crucial for improving modeling performance. Traditional clustering methods typically rely on empirical heuristics and are unable to adapt to dynamic system characteristics under changing environments. In high-dimensional and nonlinear scenarios, the number of fuzzy rule combinations grows exponentially, significantly increasing computational complexity. Therefore, an online spatiotemporal three-dimensional fuzzy modeling method based on knowledge-driven differential evolution automatic clustering and extreme learning machine (3D-OSADE-ELM) is proposed for the complex nonlinear distributed parameter system. First, an automatic clustering mechanism based on differential evolution and extreme learning machine initializes the fuzzy rules within the three-dimensional fuzzy system. Subsequently, a knowledge-driven archiving mechanism dynamically updates the fuzzy rules of the antecedent set during the online incremental learning phase. Finally, the spatial basis function is obtained by learning the output weight of the online extreme learning machine. The validation experiments conducted on the rapid thermal chemical vapor deposition reactor system and the nonisothermal packed-bed system demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_ESWA},
  author       = {Gang Zhou and Xianxia Zhang and Bing Wang},
  doi          = {10.1016/j.eswa.2025.129785},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129785},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatiotemporal online fuzzy modeling with knowledge-driven differential evolution automatic clustering for distributed parameter systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-balanced MSE for machinery imbalanced degradation trend prediction. <em>ESWA</em>, <em>298</em>, 129783. (<a href='https://doi.org/10.1016/j.eswa.2025.129783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate degradation trend prediction (DTP) is crucial for optimizing equipment operation and maintenance. With the rapid development of artificial intelligence, many data-driven methods have been applied to machinery degradation trend prediction. In practice, most machineries are in the early stages of degradation, with only a few reaching the final stages, leading to a temporal imbalanced data distribution. Current research on imbalanced distributions mainly focuses on classification tasks. However, DTP involves multiple time-dependent continuous targets, making classification-based methods unsuitable. To address this issue, the degradation trend prediction task is reformulated as a multi-task problem and a novel time-balanced Mean Square Error (TBMSE) loss function is proposed. In each prediction task, the Gaussian Mixture Model (GMM) is used to fit the training label distribution. Additionally, the cumulative information noise for each prediction task is modeled using GMM, and an end-to-end network structure is designed to learn the GMM parameters. Experiments are conducted on the IMS bearing dataset and the turboprop engine dataset, demonstrating that the TBMSE loss effectively mitigates the issue of temporal imbalanced distribution in degradation trend prediction.},
  archive      = {J_ESWA},
  author       = {Yu-Qiang Wang and Yong-Ping Zhao and Tian-Ding Zhang and Yu-Wei Wang},
  doi          = {10.1016/j.eswa.2025.129783},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129783},
  shortjournal = {Expert Syst. Appl.},
  title        = {Time-balanced MSE for machinery imbalanced degradation trend prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RSUTrajRec: Multi-granularity trajectory recovery based on roadside units sensing. <em>ESWA</em>, <em>298</em>, 129780. (<a href='https://doi.org/10.1016/j.eswa.2025.129780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle mobility trajectories, especially fine-grained trajectories, provide valuable insights for understanding urban dynamics and play a crucial role in intelligent transportation systems and urban planning. Obtaining fine-grained vehicle trajectories can be realized by trajectory recovery, but traditional efforts suffer from defects such as poor privacy protection and low recovery accuracy. To address these issues, we propose a new scenario of trajectory recovery based on roadside unit (RSU) sensing. However, this scenario introduces a significant challenge: recovering high-precision trajectories from the incomplete and unevenly distributed sensing data. To tackle this, we design RSUTrajRec , a multi-granularity trajectory recovery framework that comprises a graph neural network-based module for road information prediction, a Transformer-based module for multi-granularity recovery, and an RSU deployment planning module. Extensive real-world dataset evaluations reveal that RSUTrajRec has a significant advantage in recovering missing vehicle trajectories outside the RSU coverage area. In addition, evaluations also verify that the performance of the trajectory recovery task can be effectively improved by optimizing the RSU deployment plan.},
  archive      = {J_ESWA},
  author       = {Xianjing Wu and Xutao Chu and Jianyu Wang and Shengjie Zhao},
  doi          = {10.1016/j.eswa.2025.129780},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129780},
  shortjournal = {Expert Syst. Appl.},
  title        = {RSUTrajRec: Multi-granularity trajectory recovery based on roadside units sensing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system. <em>ESWA</em>, <em>298</em>, 129779. (<a href='https://doi.org/10.1016/j.eswa.2025.129779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology foresight analyses technological trends and potential impacts to provide strategic guidance. However, existing methods either rely on experts to discover emerging directions leading to subjective bias or adopt machine learning to predict without explanation. We propose a Machine Learning and Weak Signal-based Technology Forecasting System (MLWS-TF), which is entirely data-driven to enhance the objectivity of technology foresight and can interpret emerging directions through weak signals. The system adopts a two-phase machine learning model (2P-ML), the first phase identifies papers related to the robotics field, while the second further classifies them into fine-grained research directions. Keywords are extracted from the papers using a Word2Vec-based approach, and a three-dimensional signal classification method (DVI) is developed to quantify the foresight value of keywords across the Diffusion, Visibility, and Impact dimensions, identifying weak signals for technology forecasting. Experiments evaluate various machine learning algorithms, and XGBoost outperforms in constructing the 2P-ML classifier. The model achieved over 90% accuracy, demonstrating its effectiveness in identifying the theme of scientific documents based on textual features. For each research theme, the DVI provides a more comprehensive assessment of signal strength to detect weak signals. Finally, MLWS-TF analyses the growth potential of themes and successfully identifies critical development directions. Our approach offers a novel automated technology foresight system, which completely avoids the subjectivity and dependence on expert judgment that characterize traditional technology foresight approaches, and extends weak signal theory by introducing the Impact dimension to evaluate signal strength.},
  archive      = {J_ESWA},
  author       = {Ruihan Wang and Yuhao Zhu},
  doi          = {10.1016/j.eswa.2025.129779},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129779},
  shortjournal = {Expert Syst. Appl.},
  title        = {Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generating realistic pruning solutions for automated grape vine pruning using graph neural networks. <em>ESWA</em>, <em>298</em>, 129778. (<a href='https://doi.org/10.1016/j.eswa.2025.129778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our prior work we showed that graph neural networks (GNNs) can be trained to generate pruning solutions that could direct robotic pruning robots to perform automated cane pruning of wine grape vines. That study introduced the feasibility of the technology but also showed that there were many open questions and issues with the research results that needed to be addressed. In this study we address some of these questions. For example, we answer the question of how would a model like this perform on real vine architectures compared with pruning solutions from real experienced pruners. Our most notable contributions include moving away from a per-cane classification model that attempts to define a single perfect pruning solution, to a model that ranks multiple good solutions and picks the best one. We addressed a key limitation of the previous training data by moving away from synthetic vine architectures to realistic ones recorded from real vines and using pruning solutions collected by expert pruners as our ground-truth. Our primary goal was to show that learning by example using a GNN-based model was a viable approach to automated pruning, even when compared with experienced pruners. We showed robust performance from our model by training on a dataset of 90 pruning solutions generated by expert pruners in the 2022 season, and testing our performance on 117 pruning solutions from an independent set of pruners from the 2021 season. The model was able to correctly score all the pruning solutions from the 2021 dataset as good to very good and none of the expert solutions were classified as poor .},
  archive      = {J_ESWA},
  author       = {Jaco Fourie and Jeffrey Hsiao and Oliver Batchelor and Kevin Langbroek and Henry Williams and Richard Green and Armin Werner},
  doi          = {10.1016/j.eswa.2025.129778},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129778},
  shortjournal = {Expert Syst. Appl.},
  title        = {Generating realistic pruning solutions for automated grape vine pruning using graph neural networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mining spatiotemporal dominant co-location patterns. <em>ESWA</em>, <em>298</em>, 129775. (<a href='https://doi.org/10.1016/j.eswa.2025.129775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial co-location pattern mining is an important branch of spatial data mining, which can identify spatial features that prevalently occur in proximity. Based on spatial co-location patterns, the research of dominant relationships mining within co-location patterns further considers the influence relationship among features. However, relying solely on spatial data to analyze the positions and distribution of features for mining dominant relationships is insufficient and may lead to incorrect patterns. To address this limitation, this paper introduces the temporal factor into the research of dominant relationships mining and proposes the spatiotemporal dominant co-location pattern mining (STDCPM). At first, we define the concepts of spatiotemporal dominant relationship from both temporal and spatial dimensions, and then propose the spatiotemporal dominant participation index to assess the prevalence of spatiotemporal dominant co-location patterns. Furthermore, we design two algorithms, the spatiotemporal dominant co-location pattern mining algorithm with level-by-level search and its improved version, i.e., the spatiotemporal dominant co-location pattern mining approach based on dual pruning and refining set (STDCPM-DPR), to ensure efficient mining in spatiotemporal datasets. The time complexity, correctness, and completeness of proposed algorithms are discussed. Extensive experiments on real-world datasets demonstrate the effectiveness of STDCPM and the efficiency of STDCPM-DPR algorithm.},
  archive      = {J_ESWA},
  author       = {Jiangchuan Mei and Peizhong Yang and Hongmei Chen and Lizhen Wang},
  doi          = {10.1016/j.eswa.2025.129775},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129775},
  shortjournal = {Expert Syst. Appl.},
  title        = {Mining spatiotemporal dominant co-location patterns},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-scale content adaptive network for three-dimensional multi-object tracking and fish activity quantification. <em>ESWA</em>, <em>298</em>, 129774. (<a href='https://doi.org/10.1016/j.eswa.2025.129774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking and quantifying fish activity are vital for evaluating their health status and adaptability to the environment. However, most current research on fish tracking and activity quantification suffers from the limitation of being two-dimensional, losing crucial vertical or horizontal information. To facilitate tracking and quantitative analysis of fish activity in three-dimensional (3D) space, a cross-scale content-adaptive network-based 3D multi-object tracking method for fish is proposed, through which fish movements are quantified accordingly. Firstly, a cross-scale content-adaptive fusion network is proposed to accurately determine the fish positions from top-down and side views, thereby mitigating the issue of scale variation across different perspectives. Secondly, a hierarchical tracking method is implemented to obtain the 3D trajectories of the fish, addressing the challenge of cross-view identity matching. Finally, activity parameters in 3D space, including the activity quantity and trajectory length for individual fish, as well as the dispersion and cohesion for the fish group, are calculated. The proposed method was validated, achieving a Multi-Object Tracking Accuracy (MOTA) of 97.68% and an Identification F1 Score (IDF1) of 97.93%. For activity quantification, the Mean Absolute Error (MAE) was found to be 0.088 (unit weight·(cm/s) 2 ), and the Root Mean Square Error (RMSE) was 0.1064 (unit weight·(cm/s) 2 ). These results affirm the method’s adaption of fish features across scales for 3D tracking and activity analysis. With its efficient performance, our method presents as an instrument for activities such as fish behavior monitoring, selective breeding, and environmental assessment.},
  archive      = {J_ESWA},
  author       = {Yiran Liu and Dingshuo Liu and Mingrui Kong and Beibei Li and Qingling Duan},
  doi          = {10.1016/j.eswa.2025.129774},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129774},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-scale content adaptive network for three-dimensional multi-object tracking and fish activity quantification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel fuzzy clustering approach with transition matrix for explainable evaluation of social media-based digital literacy interventions. <em>ESWA</em>, <em>298</em>, 129769. (<a href='https://doi.org/10.1016/j.eswa.2025.129769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the effectiveness of digital literacy interventions often relies on raw score comparisons or hard classifications, which may obscure nuanced changes in conceptual understanding and provide limited interpretability. Traditional approaches fail to capture the probabilistic and fuzzy nature of learning progression and do not support transparent analysis of how learners transition across conceptual clusters over time. This study proposes an explainable evaluation framework that integrates fuzzy clustering with a fuzzy transition matrix to model the redistribution of aggregated membership values between pretest and posttest conceptual clusters. The framework applies Fuzzy C-Means (FCM) to derive soft cluster memberships and constructs a transition matrix that represents probabilistic learning progression in a linguistically interpretable form. Unlike conventional methods, this approach enables the analysis of gradual transitions across levels of proficiency rather than binary outcomes. The model was applied to real-world educational data from control and experimental classes, the latter of which received a social media-based instructional intervention. Results indicate that the control class exhibited downward or stagnant patterns, particularly among high-performing learners, while the experimental class showed more coherent upward cluster transitions among low- and moderate-level learners. By enabling interpretable modeling of pre–post cluster transition patterns, the proposed framework contributes to the advancement of explainable machine learning in education. It also highlights the potential of social computing platforms to foster scalable, data-driven digital literacy development.},
  archive      = {J_ESWA},
  author       = {Rustam and Diana Noor Anggraini and Koredianto Usman and Loveleen Gaur},
  doi          = {10.1016/j.eswa.2025.129769},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129769},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel fuzzy clustering approach with transition matrix for explainable evaluation of social media-based digital literacy interventions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting. <em>ESWA</em>, <em>298</em>, 129768. (<a href='https://doi.org/10.1016/j.eswa.2025.129768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively modeling the relations between variables in multivariate time series is of utmost importance for accomplishing accurate predictions. In real-world scenarios, in addition to sequential correlations, the evolution of relations between variables also exhibits nonadjacent correlations at different scales. However, existing methods primarily focus on constructing dynamic graph structures at each time step using temporal features extracted by continuous temporal models, which cannot capture above latent dependencies. In this study, we introduce the Dynamic Graph Structure Correction (DGC) model, leveraging a multi-scale framework with dilated convolution. To take full advantage of nonadjacent correlations in the evolution of relations between variables, we adaptively select history-related graph structures to correct initial graph structure constructed by Gate Recurrent Units. In addition, we design a time-decay-based attention mechanism to address the influence of time intervals between history-related and current time steps. Finally, the evolved graph structures are fed into graph neural networks to handle the multi-scale and complex structural relations. Our proposed model achieves superior performance compared to state-of-the-art methods in multivariate time series forecasting, as evidenced by the evaluation results on four widely used benchmark datasets.},
  archive      = {J_ESWA},
  author       = {Dandan He and Yueyang Wang and Chaoli Lou and Gang Tan and Qingyu Xiong and Guodong Sa},
  doi          = {10.1016/j.eswa.2025.129768},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129768},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimized homomorphic linear computation in privacy-preserving CNN inference. <em>ESWA</em>, <em>298</em>, 129767. (<a href='https://doi.org/10.1016/j.eswa.2025.129767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning as a Service (MLaaS) provides robust solutions for deploying deep learning inference in cloud environments. However, it also raises serious privacy concerns regarding user data and proprietary model parameters. Numerous hybrid cryptographic protocols that integrate homomorphic encryption (HE) and garbled circuits (GC) have been proposed to enable secure inference with low latency. In these protocols, the homomorphic evaluation of linear operations remains the primary performance bottleneck and warrants further optimization. In this work, we propose novel optimizations for HE-based linear computations within the hybrid cryptographic framework for secure neural network inference. Specifically, we devise two efficient strategies for homomorphic matrix-vector multiplication and convolution. For matrix-vector multiplication, we introduce a grouped diagonal extraction technique that encodes the weight matrix more compactly and enables configurable ciphertext rotation reuse, while for homomorphic convolution, we present a group-wise combine-and-merge evaluation method. Both methods significantly reduce the number of required ciphertext rotations. Our approach achieves up to a 3.9 × speedup in matrix-vector multiplication and a 2.9 × improvement in convolution over state-of-the-art (SOTA) solutions. The HE-GC hybrid secure convolutional neural networks (CNN) inference framework incorporating these enhancements yields speedups of 2.5 × on widely used ResNets deep learning architectures.},
  archive      = {J_ESWA},
  author       = {Chenglong Li and Xirong Ma and Xiuhao Wang and Fanyu Kong and Yunting Tao and Chunpeng Ge},
  doi          = {10.1016/j.eswa.2025.129767},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129767},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimized homomorphic linear computation in privacy-preserving CNN inference},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. <em>ESWA</em>, <em>298</em>, 129766. (<a href='https://doi.org/10.1016/j.eswa.2025.129766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding in encrypted images (RDHEI) is a promising technique for multimedia cloud computing that enables the embedding of secret data into encrypted images while preserving confidentiality. However, the existing RDHEI algorithms fail to meet the high-security requirements of distributed storage systems in the cloud. Although, secret sharing based RDHEI (SS-RDHEI) may solve this problem, the current methods have weakness such as insufficient embedding capacity and unsatisfactory balance between image security and redundancy. To enhance the algorithm’s ability to carry information, this paper proposes a SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. Firstly, pixel-difference preservation based modulation (PDPM) ensures secure encryption by modifying all pixels except for a reference block, minimizing damage; moreover, an improved block-level pixel predictor enhances carrier redundancy. Secondly, auxiliary data free coding (ADFC) marks prediction errors directly in the binary sequence of the original pixel without auxiliary information while maintaining accuracy, and reduces the impact of different textures on embedding performance byselecting optimal parameters for each share image. Finally, by combining PDPM with secret sharing, it achieves independent embedding for multiple data hiders while ensuring fair information embedding. Experimental results demonstrate that the proposed algorithm outperforms existing state-of-the-art schemes in terms of information-carrying capability.},
  archive      = {J_ESWA},
  author       = {Zhihua Gan and Zongwei Tang and Yalin Song and Gongyao Cao and Xiuli Chai and Yushu Zhang},
  doi          = {10.1016/j.eswa.2025.129766},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129766},
  shortjournal = {Expert Syst. Appl.},
  title        = {SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved convolutional neural networks for the bullwhip effect in supply chains. <em>ESWA</em>, <em>298</em>, 129764. (<a href='https://doi.org/10.1016/j.eswa.2025.129764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bullwhip Effect (BWE) introduces significant challenges to production systems by amplifying demand and order oscillations. One of the most effective methods for predicting and modeling complex systems is Convolutional Neural Networks (CNNs). However, certain phenomena, such as the BWE in supply chains (SC), are difficult to predict and identify directly. The primary challenge for Machine Learning (ML) algorithms in this context lies in the training phase: the raw demand and order data are fed into the network, yet the desired training outcome is the oscillatory behavior of these data from the perspective of the BWE. Consequently, conventional max pooling, average pooling operators, kernels, and weighted linear combinations of data are insufficient for capturing this type of learning. To address this issue, in this paper, a novel structure containing new pooling operators and kernels of CNNs is proposed to tailor the unique characteristics of the BWE. Specifically: a ) Considering the temporal propagation nature of the BWE, new filters and pooling operators were designed to enable CNNs to predict the BWE accurately. b ) A tensor structure was also proposed for the time signal of demand as inputs of the CNNs to facilitate the analysis of all factors influencing the occurrence of the BWE. c ) To capture the magnitude of the BWE among features, a novel combination of filters and pooling operators was proposed, enabling the CNNs to account for hidden but yet significant feature effects during training. The benefits of the proposed approach lie in its versatility, and it can be applied to train CNNs to model structured fluctuations like the BWE in various dynamic systems.},
  archive      = {J_ESWA},
  author       = {Sajjad Aslani Khiavi and Farzad Hashemzadeh},
  doi          = {10.1016/j.eswa.2025.129764},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129764},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved convolutional neural networks for the bullwhip effect in supply chains},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid risk assessment method combining CatBoost and FAHP-grid search optimized risk matrix for container ship accident. <em>ESWA</em>, <em>298</em>, 129763. (<a href='https://doi.org/10.1016/j.eswa.2025.129763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a dominant mode of maritime transportation with unique risk characteristics, container shipping requires accurate and applicable risk assessment. However, conventional risk matrices oversimplify complex interactions, while pure data-driven models lack operational utility. To address this, a hybrid method for container ship risk assessment is proposed. This method integrates CatBoost-based predictive method, FAHP-grid search optimized risk matrix, and GIS-supported risk mapping. A comprehensive study of maritime casualties and piracy accidents is conducted, utilizing historical incident data sets collected from the Global Integrated Shipping Information System (GISIS). The global maritime accident risk of container ships is then evaluated and mapped. The sensitivity analysis confirms the robustness of the method under varying linguistic distance parameters, while expert weights have a moderate impact on the assessment results. Finally, the effectiveness of the proposed method is validated through comparative analyses on predictive performance, risk discrimination capability, and risk assessment accuracy. CatBoost algorithm outperforms XGBoost, LightGBM, and Random Forest algorithms in predictive metrics. The designed risk matrix shows strong discriminatory ability for container ship risk levels. In historical accident data validation, the proposed method also achieves higher accuracy than combinations involving XGBoost, LightGBM, or Random Forest with the designed risk matrix.},
  archive      = {J_ESWA},
  author       = {Yuqing Xiao and Shilian Han and Xinwang Liu},
  doi          = {10.1016/j.eswa.2025.129763},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129763},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid risk assessment method combining CatBoost and FAHP-grid search optimized risk matrix for container ship accident},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards. <em>ESWA</em>, <em>298</em>, 129762. (<a href='https://doi.org/10.1016/j.eswa.2025.129762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation of quadrotors is a fundamental prerequisite for numerous applications. This work proposes a novel deep reinforcement learning (DRL) framework that explicitly addresses quadrotor attitude dynamics during autonomous navigation, a critical yet underexplored challenge in existing learning-based UAV navigation studies. In the proposed method, high-level velocity commands will be generated by a deep neural network policy and translated by a low-level control algorithm to achieve precise control of both positions and rotations of quadrotors. A specialized network structure is designed to effectively extract environmental obstacle features and quadrotor sequence features to improve navigation performance. In addition, a novel tangent path reward (TPR) calculation method is developed to adequately utilize the known contours and positions of obstacles during the training phase. Experimental results demonstrate that the proposed method enables quadrotors to autonomously navigate complex virtual obstacle environments with superior efficiency compared with other algorithms. Furthermore, the feasibility and adaptability of the proposed method are validated through simulations by varying obstacle density and map size, as well as replicating real-world obstacle distributions.},
  archive      = {J_ESWA},
  author       = {Qizhang Luo and Yuqi Li and Jiaheng Zeng and Guohua Wu and Yalin Wang},
  doi          = {10.1016/j.eswa.2025.129762},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129762},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dynamic tri-stage framework with neural network-assisted search for constrained multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129761. (<a href='https://doi.org/10.1016/j.eswa.2025.129761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems involve the optimization of multiple objective functions and the satisfaction of different constraints, which poses a challenge for algorithms to achieve a good balance between convergence and diversity. However, indiscriminately enhancing diversity can hinder convergence, while solely focusing on convergence may impair the exploration of the objective space, especially when the current stage is not well-defined. To address this issue, we propose a three-stage multi-task framework for constrained multi-objective optimization with dynamically switchable stages. This framework introduces two auxiliary tasks: one that operates during the exploration and transition stages to accelerate convergence towards the boundary of the infeasible regions and assist the population in crossing it, and another that operates in the final convergence stage to guide the population towards the constrained Pareto front. Moreover, a stage detection method is proposed, which evaluates the current stage to determine the appropriate evolutionary direction for the population, thus enabling dynamic stage transitions. In addition, a neural network-assisted search operator is designed for the auxiliary task during the transition stage, which learns the optimal offspring generation process. This operator enhances the ability of the auxiliary population to cross the infeasible regions. Finally, the performance of the proposed algorithm is superior and competitive on three test suites and six real-world engineering problems compared to seven state-of-the-art algorithms.},
  archive      = {J_ESWA},
  author       = {Qianlong Dang and Xinkang Hong and Xianpeng Sun},
  doi          = {10.1016/j.eswa.2025.129761},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129761},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dynamic tri-stage framework with neural network-assisted search for constrained multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A physics-informed neural network surrogate model and many-objective optimization algorithm for coupled multi-energy systems in smart grids. <em>ESWA</em>, <em>298</em>, 129760. (<a href='https://doi.org/10.1016/j.eswa.2025.129760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scope of smart grids is progressively extending toward Integrated Energy Systems (IES) that couple electricity with gas, heating, and cooling. Due to the unsteady-state physical characteristics inherent in the transmission of gas, heat, and cooling resources, IES scheduling must not only balance multiple typical objectives but also account for the dynamic coupling of heterogeneous physical domains. To address these challenges, this paper formulates a Many-objective Optimization Model for Coupled Multi-Energy Flows (MaOCMFM) with partial differential equations (PDEs) in IES, which captures the dynamic physical behaviors of electricity, gas, heat, and cooling subsystems. Building upon this model, we propose a Probabilistic Contributing Many-objective Evolutionary Algorithm enhanced by a Physics-Informed Neural Network surrogate model (PC-MaOEA-PINN). Cubic B-spline functions are employed to achieve a continuous representation of the decision variables, while multi-physics constraints are embedded into the loss function of the surrogate model. This design enables efficient approximation of the objective function with a limited number of samples and facilitates focused exploration in critical evolutionary regions, thereby accelerating population convergence. The effectiveness of the proposed model and algorithm is validated on 9 typical scheduling days across four simulated IES scenarios.},
  archive      = {J_ESWA},
  author       = {Jingbo Zhang and Xingjuan Cai and Zhihua Cui and Jinjun Chen},
  doi          = {10.1016/j.eswa.2025.129760},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129760},
  shortjournal = {Expert Syst. Appl.},
  title        = {A physics-informed neural network surrogate model and many-objective optimization algorithm for coupled multi-energy systems in smart grids},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An emergency scheduling method based on AutoML for space maneuver objective tracking. <em>ESWA</em>, <em>298</em>, 129759. (<a href='https://doi.org/10.1016/j.eswa.2025.129759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large-scale constellations has led to a dramatic increase in the number of Resident Space Objectives (RSOs), significantly intensifying the complexity of Space Situational Awareness (SSA). Furthermore, the maneuver behaviors of non-cooperative RSOs pose potential threats to space safety, making the real-time monitoring of their post-maneuver orbital becomes more critical. In particular, the maneuvering characteristics of large-scale constellation satellites impose more stringent demands on the timeliness and adaptability of existing scheduling algorithms for observation resources. To address the emergency scheduling demands of heterogeneous ground-based observation resources, this paper proposes an Emergency Task Three-phase Scheduling Framework (ETTSF) based on Automated Machine Learning (AutoML) and auction algorithm. The framework collaboratively optimizes resource allocation through three phases: resource matching, task scheduling, and rescheduling. First, AutoML combined with an auction algorithm predicts and assigns emergency tasks to the most appropriate resources, reducing solution space complexity, simultaneously, the auction algorithm’s corrected results are fed back to AutoML for model fine-tuning. Second, a heuristic algorithm with dynamic neighborhood structures efficiently inserts emergency tasks into the routine observation plan. Finally, affected routine tasks are rescheduled to minimize the operational impact. Simulation results demonstrate that compared to baselines-Real-Time Dynamic Scheduling (RTDS) and Improved Adaptive Large Neighborhood Search (IALNS)-ETTSF achieves a 2.82% improvement in Completion Rate of Emergency RSOs (CRER) and a 27.83% reduction in Impact Rate (IR) on routine tasks. Ablation experiments further validate the effectiveness of the resource matching and rescheduling phases.},
  archive      = {J_ESWA},
  author       = {Xi Long and Jinrun Chen and Leping Yang and Huan Huang},
  doi          = {10.1016/j.eswa.2025.129759},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129759},
  shortjournal = {Expert Syst. Appl.},
  title        = {An emergency scheduling method based on AutoML for space maneuver objective tracking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Path-aware routing system for multimodal vigilance estimation: A structured fusion perspective. <em>ESWA</em>, <em>298</em>, 129757. (<a href='https://doi.org/10.1016/j.eswa.2025.129757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver vigilance is a critical cognitive factor in ensuring the safety of intelligent driving systems. With advances in physiological and behavioral sensing technologies, multimodal data have become an essential source for modeling drivers’ cognitive states. However, vigilance, as an implicit cognitive state, is difficult to model accurately using a single modality. Efficient fusion of multiple modalities and structured information interaction remains a core challenge in this task. Existing approaches often rely on strategies such as feature concatenation and attention mechanisms, which lack explicit structural constraints. As a result, heterogeneous modality features are fused in an uncontrolled and entangled manner, making the interaction process opaque and difficult to interpret. To address these issues, we propose the Path-Aware Routing System (PARS), which formulates multimodal fusion as a feature routing task. In PARS, intra-modal enhancement and cross-modal interaction are abstracted into independent semantic channels, and a confidence-aware mechanism is introduced to enable dynamically weighted fusion. PARS explicitly constructs a path space, allowing features to be selectively routed and integrated along semantical pathways, thereby enhancing the model’s discriminative power and robustness. We conduct extensive experiments on a public dataset and a self-constructed driving simulation dataset. The results demonstrate that PARS significantly outperforms existing multimodal fusion methods in the task of driver vigilance estimation, achieving superior performance in terms of accuracy, interpretability, and generalization. These findings highlight the broad potential of PARS in intelligent driving applications. Our code and models are available at: https://github.com/SunYu-Gavin/PARS .},
  archive      = {J_ESWA},
  author       = {Yu Sun and Shiwu Li and Yiming Bie and Linhong Wang and Tongtong Jin and Mengzhu Guo and Zhifa Yang},
  doi          = {10.1016/j.eswa.2025.129757},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129757},
  shortjournal = {Expert Syst. Appl.},
  title        = {Path-aware routing system for multimodal vigilance estimation: A structured fusion perspective},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Homophone-aware offensive language detection via semantic-phonetic collaboration. <em>ESWA</em>, <em>298</em>, 129756. (<a href='https://doi.org/10.1016/j.eswa.2025.129756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of implicit and obfuscated expressions poses significant challenges to offensive language detection in Chinese online platforms. In particular, users often exploit homophone substitutions to bypass keyword-based moderation, making traditional detection systems inadequate. This study addresses the problem of detecting offensive content masked through homophonic substitutions, which retain aggressive intent while altering character representations. Existing methods fall into two main categories: (1) semantic-only models, which struggle with phonetic manipulations due to their reliance on text features alone, and (2) auxiliary-enhanced models, which incorporate phonetic or syntactic signals but lack deep integration between modalities. To overcome these limitations, we propose a lightweight dual-branch model that separately encodes textual semantics and pinyin phonetics under a multi-view learning framework. A Dual-Branch Interactive Training strategy is introduced to enable dynamic cross-modal alignment via contrastive objectives, allowing each modality to mutually refine the other and enhance robustness to adversarial inputs. We conduct experiments on two benchmark datasets, COLD and SWSR, both of which are augmented with varying levels of homophone noise to simulate real-world evasion strategies. The proposed model outperforms all baseline models, achieving an average F1-score improvement of 6.3 % under high-noise conditions, while reducing inference latency and memory usage by more than 60 %, demonstrating both effectiveness and efficiency for real-time deployment. We will release the source code for further use by the community https://github.com/hjhhlc/DBIT .},
  archive      = {J_ESWA},
  author       = {Jiahao Hu and Shanliang Pan},
  doi          = {10.1016/j.eswa.2025.129756},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129756},
  shortjournal = {Expert Syst. Appl.},
  title        = {Homophone-aware offensive language detection via semantic-phonetic collaboration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing traffic signal control through model-based reinforcement learning and policy reuse. <em>ESWA</em>, <em>298</em>, 129755. (<a href='https://doi.org/10.1016/j.eswa.2025.129755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) has shown significant potential in traffic signal control (TSC). However, current MARL-based methods often suffer from insufficient generalization due to the fixed traffic patterns and conditions of the road network used during training. This limitation results in poor adaptability to new traffic scenarios, leading to high retraining costs and complex deployment. To address this challenge, we propose two algorithms: PLight and PRLight. PLight employs a model-based reinforcement learning approach, pretraining control policies, and environment models using predefined source-domain traffic scenarios. The environmental model predicts state transitions, facilitating the comparison of environmental characteristics. PRLight further enhances adaptability by adaptively selecting pre-trained PLight agents based on the similarity between the source and target domains to accelerate the learning process in the target domain. We evaluated the algorithms through two transfer settings: (1) adaptability to different traffic scenarios within the same road network, and (2) generalization across different road networks. The results show that PRLight significantly reduces the adaptation time compared to learning from scratch in new TSC scenarios, achieving optimal performance using similarities between available and target scenarios.},
  archive      = {J_ESWA},
  author       = {Yihong Li and Chengwei Zhang and Furui Zhan and Wanting Liu and Kailing Zhou and Longji Zheng},
  doi          = {10.1016/j.eswa.2025.129755},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129755},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing traffic signal control through model-based reinforcement learning and policy reuse},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated transfer learning for anomaly detection in HPC systems: First real-world validation on a tier-0 supercomputer. <em>ESWA</em>, <em>298</em>, 129754. (<a href='https://doi.org/10.1016/j.eswa.2025.129754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-Performance Computing (HPC) systems increasingly require intelligent, scalable anomaly detection to ensure operational reliability. However, conventional centralized approaches often struggle with data privacy constraints, poor generalization across heterogeneous nodes, and limited scalability. This study presents the first real-world application of federated transfer learning (FTL) for anomaly detection in a production-grade Tier-0 supercomputer. By combining federated learning with transfer learning, the proposed framework enables decentralized model training and personalized adaptation to unseen nodes, without accessing raw data. We validate the approach using two large-scale telemetry datasets collected from 100 nodes of the Marconi100 supercomputer, evaluating its effectiveness across supervised, semi-supervised, and unsupervised learning paradigms. Results show that FTL consistently improves anomaly detection performance on nodes that did not participate in federated training, with F1-score gains reaching up to 0.50. These improvements demonstrate the framework’s ability to generalize across non-identically distributed data and maintain detection accuracy under real-world conditions. This work establishes FTL as a scalable, privacy-preserving solution for fault detection in HPC environments. Its practical deployment on production hardware confirms its readiness for real-time monitoring applications in large-scale, heterogeneous computing systems.},
  archive      = {J_ESWA},
  author       = {Emmen Farooq and Michela Milano and Andrea Borghesi},
  doi          = {10.1016/j.eswa.2025.129754},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129754},
  shortjournal = {Expert Syst. Appl.},
  title        = {Federated transfer learning for anomaly detection in HPC systems: First real-world validation on a tier-0 supercomputer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Security script arrangement based on enhanced BERT for cooperative defense in networked control systems. <em>ESWA</em>, <em>298</em>, 129753. (<a href='https://doi.org/10.1016/j.eswa.2025.129753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the mutual collaboration and in-depth integration among multiple defense technologies through information sharing, the cooperative defense in networked control systems has emerged as a feasible solution to counter increasingly diversified cyber threats under the unique security characteristics and requirements of industrial environments. However, one of the chief challenges is how to automatically and intelligently develop effective cooperative working strategies when an attack occurs. Leveraging the advantages of large-scale AI (Artificial Intelligence) models, this paper defines a new concept named “security script”, and proposes a security script arrangement approach based on enhanced BERT to achieve fine-grained cooperative defense in networked control systems. Furthermore, this approach introduces intrusion detection and industrial firewall as two practical examples, and can automatically arrange effective security scripts to enable the dynamic interaction of two defense technologies. Additionally, to improve efficiency, the encoder structure adjusting and AdamW optimizing are further presented to enhance the traditional BERT. Experimental results clearly demonstrate that: for one thing, these two optimization ways can make greater achievements in reducing unnecessary time consumption and enhancing accuracy of security script arrangement; for another, compared with other typical BERT and large-scale AI models, the proposed approach can exhibit more favorable performance advantages in achieving cooperative defense based on security script arrangement. In particular, through its successful application and verification in one real-world manufacturing control system, our approach may bring a potential opportunity or direction for further research and improvement of AI-based cooperative defense.},
  archive      = {J_ESWA},
  author       = {Ming Wan and Xueqing Liu and Shengbao An and Aiping Tan and Xi Jin and Chuan Sheng},
  doi          = {10.1016/j.eswa.2025.129753},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129753},
  shortjournal = {Expert Syst. Appl.},
  title        = {Security script arrangement based on enhanced BERT for cooperative defense in networked control systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ScSCDT: Self-contrastive neural network with deep topology mining for scRNA-seq data clustering. <em>ESWA</em>, <em>298</em>, 129751. (<a href='https://doi.org/10.1016/j.eswa.2025.129751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in single-cell sequencing technologies have enabled researchers to better identify cells based on gene-level information. Cell clustering is a key task in single-cell analysis and plays an important role in distinguishing cell types. However, due to the high dimensionality and sparsity of scRNA-seq data, single-cell clustering remains a major challenge. Although many methods based on deep learning and machine learning have been developed for single-cell clustering, they often fail to capture the deep topological structure between cells, which limits clustering precision. In addition, most existing clustering approaches cannot effectively construct suitable sample pairs to optimize clustering models. To address these issues, we propose a topology-aware deep contrastive clustering model for single-cell data, named scSCDT. First, scSCDT employs a ZINB-based autoencoder to simultaneously learn cell embeddings and topological information, effectively handling the challenges posed by the high-dimensional and sparse nature of the data. Then, we introduce a dual clustering-guided loss to supervise the clustering task, combining a probabilistic soft assignment strategy and a hard pseudo-labeling strategy for optimization. Finally, based on the topological structure in the low-dimensional embedding space, we construct negative pairs within a single view and design a self-contrastive learning method to further improve clustering performance. We conduct extensive experiments on ten real scRNA-seq datasets and evaluate performance using four clustering metrics. The results indicate that scSCDT achieves strong clustering performance across multiple datasets, thereby facilitating more accurate cell type identification in single-cell transcriptomic analysis.},
  archive      = {J_ESWA},
  author       = {Zhongyang Zhou and Bin Tang and Feiyu Chen and Wei Wang and Shangshang Zhao and Nanjun Yu},
  doi          = {10.1016/j.eswa.2025.129751},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129751},
  shortjournal = {Expert Syst. Appl.},
  title        = {ScSCDT: Self-contrastive neural network with deep topology mining for scRNA-seq data clustering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 3D modeling from a single sketch with multifaceted semantic understanding. <em>ESWA</em>, <em>298</em>, 129748. (<a href='https://doi.org/10.1016/j.eswa.2025.129748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of 3D shape generation from a single sketch. Prior works rely on directly extracted visual features of sketches as guidance for the generation process. However, the sparse visual cues and abstract nature of sketches, which are inherited in the guiding features, lead to semantic ambiguity and geometry incompleteness in the generated shapes, compromising accuracy. To address this, we propose MSU-3D, a diffusion-based framework for sketch-to-3D generation, leveraging Multifaceted Semantic Understanding to explicitly analyze the construction information of sketches from multiple facets before providing fine-grained guidance over 3D shape generation. Specifically, we decompose sketches through three interpretative facets (semantics, depth, and normal), introducing reasoning of three representations to capture 3D features from distinct perspectives: local components, basic 3D geometry, and 3D surface details. One step further, we propose a multifaceted perception module. It aggregates multifaceted feature representations and leverages local component features as a two-pronged guiding representation to jointly guide the perception of basic shapes and surface details. To ensure fine-grained control, the hierarchical perception strategy adaptively injects varying granularity of perception features at different stages of the 3D generation. Extensive experiments and comparisons with state-of-the-art methods on various complex posture datasets validate the effectiveness of our framework in mitigating semantic ambiguity and geometry incompleteness in 3D generation.},
  archive      = {J_ESWA},
  author       = {Yuxiao Zhang and Jin Wang and Yang Zhou and Senyun Jia and Zhi Zheng and Dongliang Zhang and Guodong Lu},
  doi          = {10.1016/j.eswa.2025.129748},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129748},
  shortjournal = {Expert Syst. Appl.},
  title        = {3D modeling from a single sketch with multifaceted semantic understanding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Continuous learning approach to synergize shimmering image enhancement and de-fogging with small sample. <em>ESWA</em>, <em>298</em>, 129747. (<a href='https://doi.org/10.1016/j.eswa.2025.129747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shimmering Image Enhancement and Defogging (SIED) are two important aspects of image recovery. However, most methods are often fail to consider image context information, overexposure of image and the intrinsic correlation between SIED without enough sample. Furthermore, current methods may lead to the amplification of external color interference during image recovery, and can’t fine-tune the model with new samples. Firstly, we propose an Adjustable Multiscale Attention Codec Network (AMACNet) architecture. AMACNet includes variable restorative coder decoder and group channel attention to fuse multi-level contextual and channel information of images, respectively. These components are designed as plug-and-play modules. Secondly, a Continuous Learning with Small Sample (CLS) training method is presented. It utilizes few samples based on a front-and-back stage receding structure. The method synergizes the tasks of SIED, allowing the network to perform both tasks without incresing the number of parameters. It also enables the network to adapt to new tasks with a small number of unpaired samples. Finally, a color adjustment module for image post-processing is designed. The post-processing method is used to balance the impact of color illumination on the inherent color of materials. Extensive experiments demonstrate that training AMACNet by CLS allow the final image recovery results to exceed the GT in terms of ENIQA, FES, PIQE, and other unparameterized metrics.},
  archive      = {J_ESWA},
  author       = {Fenglin Yao and Zhengxiang Liu},
  doi          = {10.1016/j.eswa.2025.129747},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129747},
  shortjournal = {Expert Syst. Appl.},
  title        = {Continuous learning approach to synergize shimmering image enhancement and de-fogging with small sample},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning domain-invariant representation for generalizable iris segmentation. <em>ESWA</em>, <em>298</em>, 129746. (<a href='https://doi.org/10.1016/j.eswa.2025.129746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain iris segmentation (CDIS) seeks to transfer knowledge from a labeled source dataset to an unlabeled target dataset. Existing CNN-based iris segmentation methods commonly assume that training and application stages share the same data distribution and modality setting, thus their performance may decline substantially on open-domain iris datasets unseen before. Furthermore, the process of annotating pixel-wise labels is labor-intensive and time-consuming, resulting in limited applicability of these methods in realistic scenarios. Therefore, we propose a generic domain adaptation iris segmentation framework ( DAIrisSeg ), which can be flexibly incorporated into existing methods. First, a domain-sensitive feature whitening strategy is proposed to effectively mitigate the domain-specific styles while preserving the domain-invariant content, thereby improving the model’s generalizability to unknown domain distribution. We then utilize the prototype estimation and the context-similarity learning adapter to produce reliable segmentation labels. In addition, DAIrisSeg incorporates prior constraints of the iris to further refine the segmentation results. Extensive experiments on three iris datasets demonstrate that the proposed method has shown consistent improvements over state-of-the-art (SOTA) methods.},
  archive      = {J_ESWA},
  author       = {Dawei Lin and Meng Yuan and Ying Chen and Xiaodong Zhu and Yuanning Liu},
  doi          = {10.1016/j.eswa.2025.129746},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129746},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning domain-invariant representation for generalizable iris segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cycle-CFM: An unsupervised framework for robust multimodal anomaly detection in industrial settings. <em>ESWA</em>, <em>298</em>, 129745. (<a href='https://doi.org/10.1016/j.eswa.2025.129745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial multimodal anomaly detection is confronted with three pivotal challenges: cross-modal feature drift, noise sensitivity, and modality imbalance. To address these issues, we propose Cycle-Consistent Cross-Modal Feature Mapping (Cycle-CFM), an unsupervised framework that integrates cycle-consistent cross-modal mapping with channel-attention-guided adaptive loss weighting. Cycle-CFM establishes bidirectional feature alignment between RGB and 3D modalities via reversible cycle mappings, yielding consistent representations robust to vibration and depth noise. To further mitigate dynamic interferences such as illumination variations, we introduce a joint optimization strategy that combines cross-consistency and cycle-consistency losses. Experimental results on our self-constructed SteelDefect-3D-AD dataset demonstrate that Cycle-CFM achieves an AUPRO@1 % of 0.371, outperforming state-of-the-art methods by 17–45 %. It also attains a pixel-level AUROC (P-AUROC) of 0.991 and an image-level AUROC (I-AUROC) of 0.998. On the public MVTec 3D-AD benchmark, Cycle-CFM reaches a mean P-AUROC of 0.960 and improves accuracy by 37.5 % for elongated anomalies. With a runtime of 11.03 FPS and 469.52 MB of parameters, the model highlights both its effectiveness and deployability for real-time industrial inspection.},
  archive      = {J_ESWA},
  author       = {Yikang Shi and Xin Zhan and Yaqian Li and Zhongqiang Wu and Wenming Zhang and Haibin Li},
  doi          = {10.1016/j.eswa.2025.129745},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129745},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cycle-CFM: An unsupervised framework for robust multimodal anomaly detection in industrial settings},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable transfer learning approach to predict carbon emission intensity of coal-fired power plants with multi-source monitoring data. <em>ESWA</em>, <em>298</em>, 129743. (<a href='https://doi.org/10.1016/j.eswa.2025.129743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon mitigation policies and emission trading systems have heightened the need to monitor and predict the carbon emission intensity (CEI) of coal-fired power plants. Leveraging big data and machine learning (ML) technologies, this study trains predictive models of CEI using operational parameters, load rate, and coal-quality data from three Chinese power plants. The performance of Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Support Vector Machine (SVM), and Artificial Neural Network (ANN) was evaluated, and the challenge of limited data in individual plants was mitigated through instance-based transfer learning (ITL) and graft learning (GL) technologies. The results indicate that while traditional ML models struggle with poor data quality and limited samples, transfer learning between different plants will improve predictive accuracy substantially, and GL delivers the greatest gains. Among the most influential features, air supply temperature and load rate critically impact CEI and therefore should be carefully managed to achieve emission reductions. Nevertheless, the effectiveness of transfer learning depends on source data quality and model choice, and the proposed operational strategies require further validation before practical adoption. Our findings offer a robust framework for enhancing the predictive accuracy of plant CEI under data-scarce conditions and inform effective strategies for promoting a low-carbon transition in the energy sector.},
  archive      = {J_ESWA},
  author       = {Xiaodong Jin and Lingzhen Zhang and Fangyi Li and Wu Xie and Dawei Ma and Yan Wu},
  doi          = {10.1016/j.eswa.2025.129743},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129743},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable transfer learning approach to predict carbon emission intensity of coal-fired power plants with multi-source monitoring data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partially view-aligned clustering via data recoupling and elastic bi-consistency learning. <em>ESWA</em>, <em>298</em>, 129741. (<a href='https://doi.org/10.1016/j.eswa.2025.129741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern multi-view data often suffer from partial view alignment issues, yet most existing multi-view clustering (MVC) methods assume that the data are fully aligned, which is rarely the case in real-world scenarios. This misalignment leads to False Negative Pairs (FNPs), disrupting the learning process. While some methods address partial alignment, they often neglect intra-view consistency and multi-scale inter-view relationships, limiting their ability to capture both global and local structural dependencies. Additionally, the prevalent use of Mean Squared Error (MSE) as a reconstruction loss is suboptimal for discrete data, potentially causing severe performance degradation. To overcome these limitations, we propose Partially View-aligned Clustering via Data Recoupling and Elastic Bi-consistency Learning (PVC-DREBL). Our method integrates two key components: (1) a Data Recouple Module, which realigns the data to mitigate the effects of FNPs while leveraging an exponential contrastive loss to enhance learning stability and prevent overfitting; (2) an Elastic Bi-consistency Learning Module, designed to reconstruct diverse data types robustly while enforcing intra-view and multi-scale inter-view consistency. Extensive experiments on six benchmark datasets demonstrate that PVC-DREBL significantly outperforms existing methods, highlighting its effectiveness in handling partially view-aligned clustering tasks.},
  archive      = {J_ESWA},
  author       = {Wenzhe Liu and Jiongcheng Zhu and Jingbo Tan and Huibing Wang and Yong Zhang},
  doi          = {10.1016/j.eswa.2025.129741},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129741},
  shortjournal = {Expert Syst. Appl.},
  title        = {Partially view-aligned clustering via data recoupling and elastic bi-consistency learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china. <em>ESWA</em>, <em>298</em>, 129740. (<a href='https://doi.org/10.1016/j.eswa.2025.129740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsurface lithological distribution is essential for extrapolating geological information from core to block or basin scales. Given the limited availability of core data, there is a critical need to develop a reliable method for establishing robust correlations between logging curves and lithologies in cores, thereby maximizing the value of large historical logging data. Here, we propose a novel attention-based convolutional neural network (ATT-CNN), which employs a 1D-CNN to transform six types of logging curves into high-dimensional feature space at each depth, and applies an attention mechanism to the 1D-CNN outputs along both the depth and feature dimensions. The architecture is designed to mimic human perceptual processing for lithology identification, leveraging curve combination, thresholding, and local pattern recognition within this enriched and high-dimensional feature representation. In addtion, the study employs wavelet-based preprocessing on logging curves to eliminate the impact of compaction-induced data drift on model generalization—an issue rarely considered in prior studies. The result showes that: ① The proposed ATT-CNN model demonstrates superior performance over benchmark models—the bidirectional gated recurrent unit (BiGRU) and an ensemble of machine learning models (En-ML)—across all evaluation metrics; ②Wavelet-based preprocessing enhances the generalization capability of both ATT-CNN and BiGRU, yielding higher metric scores and improved predictions, particularly in shallow-depth intervals; ③ For blind wells, the ATT-CNN outperforms BiGRU and En-ML in both accuracy and its ability to capture lithological variations even from low-amplitude curve deviations. The integration of ATT-CNN with wavelet-based preprocessing demonstrates significant potential for accurately characterizing subsurface lithological distribution, then provides critical support for key petroleum geology workflows, including provenance analysis, sedimentary facies mapping, and reservoir property prediction.},
  archive      = {J_ESWA},
  author       = {Jianguo Yin and Shuai Zhang and Zhixiong Wu and Shouji Pang and Rui Wang},
  doi          = {10.1016/j.eswa.2025.129740},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129740},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models. <em>ESWA</em>, <em>298</em>, 129739. (<a href='https://doi.org/10.1016/j.eswa.2025.129739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a clustering-based framework for the analysis of functional magnetic resonance imaging (fMRI) data, with a particular focus on brain segmentation into functional sub-regions. The proposed approach comprises two key modules: representation learning and brain functional segmentation. To extract meaningful latent representations from high-dimensional fMRI signals while preserving temporal dependencies, we introduce the Spherical Variational Recurrent Autoencoder (SVRAE), a deep generative model built upon the Variational Autoencoder (VAE) architecture. Unlike conventional VAEs that assume a Gaussian prior, SVRAE employs the von Mises-Fisher (vMF) distribution to model latent variables on a unit hypersphere, which is more suitable for L 2 -normalized data. To further enhance temporal modeling, we replace standard fully connected layers with Long Short-Term Memory (LSTM) networks. For the segmentation module, we adopt a Collapsed Nonparametric von Mises-Fisher Mixture Model (Co-vMFMM), formulated within a Bayesian nonparametric framework. This model automatically adapts its complexity to the input data without requiring a predefined number of clusters. An efficient variational Bayes learning algorithm is developed to perform inference in a collapsed parameter space. Extensive experiments on publicly available fMRI datasets demonstrate the effectiveness and robustness of the proposed method in delineating functionally coherent brain sub-regions.},
  archive      = {J_ESWA},
  author       = {Wentao Fan and Wenchuan Zhang and Xiao Dong and Nizar Bouguila},
  doi          = {10.1016/j.eswa.2025.129739},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129739},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An optimized hierarchical path planning method based on deep reinforcement learning for mobile robots. <em>ESWA</em>, <em>298</em>, 129736. (<a href='https://doi.org/10.1016/j.eswa.2025.129736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of elderly mobile robot technology, the training efficiency and path planning of robots have become key issues in research. Current mobile robot training faces challenges such as local optima and slow convergence speeds. To address these issues, this paper proposes a hierarchical path planning method based on deep reinforcement learning (H-DDQN). This method first introduces a global path planning module, which uses a density function to select high-value key points. In areas with dense obstacles, these key points provide the robot with effective global path guidance, enabling it to avoid getting stuck in a local optimum due to reliance solely on local information. In the local path planning module, we introduce a spatial attention mechanism based on global information, which weights global path points to enable the robot to focus on critical areas, thereby enhancing local decision-making capabilities and addressing dynamic obstacles on the basis of global optimality. Finally, this paper designs a new comprehensive reward function that combines path guidance from global key points with goal-oriented dense rewards, avoiding excessive unnecessary exploration and providing timely feedback to accelerate the model’s convergence speed. Experimental results show that compared to other existing algorithms, the H-DDQN algorithm converges more quickly during training and generates shorter and more efficient paths. In dynamic obstacle environments, the algorithm also demonstrates strong adaptability, combining global and local capabilities to achieve superior performance.},
  archive      = {J_ESWA},
  author       = {Jilin Zhang and Jia Qiao and Ke Huang and Menghua Zhang},
  doi          = {10.1016/j.eswa.2025.129736},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129736},
  shortjournal = {Expert Syst. Appl.},
  title        = {An optimized hierarchical path planning method based on deep reinforcement learning for mobile robots},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Assessing the renewable energy sources for sustainable energy generation systems: Interval-valued q-rung orthopair fuzzy SWARA-TOPSIS. <em>ESWA</em>, <em>298</em>, 129735. (<a href='https://doi.org/10.1016/j.eswa.2025.129735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable Energy Sources (RESs) help decarbonize power systems, but selecting among them is a challenging decision problem due to multiple, often conflicting, technical, economic, environmental, and health-related criteria. Consequently, numerous studies in the literature have attempted to address this decision-making issue using objective, subjective, and fuzzy decision-making procedures. However, there are still unaddressed research gaps in the literature, particularly regarding the explicit modeling of expert hesitation and ambiguity in real-world RES selection cases. The current study develops a decision-making model based on Step-wise Weight Assessment Ratio Analysis (SWARA) and Technique of Order Preference Similarity to the Ideal Solution (TOPSIS) methods integrated with Interval-Valued q-Rung Orthopair Fuzzy Sets (IV-q-ROFSs) to fill these gaps. Unlike previous studies that have predominantly applied conventional fuzzy MCDM techniques, our model introduces the first integration of IV-q-ROFS into RES selection. This novelty enables a more accurate representation of expert hesitation and uncertainty. The study is applied to a real industrial case in Turkey, where six RES alternatives are evaluated across 43 criteria by five senior experts under the supervision of a three-member professionals’ board. Furthermore, the structured robustness check and systematic literature mapping ensure that the proposed approach is methodologically robust and practically relevant for policymakers and energy planners. The application results of the developed model demonstrate that the estimated energy production potential of the RES and the effects of carcinogens generated from utilizing these energy sources are the critical factors influencing the selection of the most appropriate RESs. Solar energy ranked first among the alternatives. The applicability and validity of the developed model are examined by a comprehensive robustness check consisting of tests of sensitivity, comparison, and resilience to the rank reversal problem. Overall, the study provides (i) a novel methodological framework integrating IV-q-ROFS with SWARA and TOPSIS, (ii) empirical evidence from a comprehensive real-world RES selection case, and (iii) policy-relevant insights into the drivers of renewable energy adoption.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Ahmet Aytekin and Selçuk Korucuk and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129735},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129735},
  shortjournal = {Expert Syst. Appl.},
  title        = {Assessing the renewable energy sources for sustainable energy generation systems: Interval-valued q-rung orthopair fuzzy SWARA-TOPSIS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer. <em>ESWA</em>, <em>298</em>, 129734. (<a href='https://doi.org/10.1016/j.eswa.2025.129734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver cancer is a complex and life-threatening disease with significant diagnostic and therapeutic challenges. Automated liver cancer detection assists radiologists in identifying tumors and their severity accurately. In recent years, several deep-learning techniques have been implemented for diagnosing liver tumors and classification. Despite advancements in deep learning for medical imaging, existing liver cancer detection approaches continue to face several critical limitations. These include suboptimal diagnostic accuracy due to inadequate feature extraction, excessive computational demands that hinder real-time deployment, significant class imbalance within medical datasets leading to biased predictions, and overfitting caused by limited annotated training data. To address these challenges, this study introduces a novel and automated deep learning framework called CustomLiverNet, specifically designed for accurate and efficient liver cancer diagnosis using Computed Tomography images. The Generative Adversarial Network is introduced for generating realistic synthetic images, effectively improving the performance of the proposed technique and reducing class imbalance problems. The proposed technique integrates the strengths of Residual Networks and Vision Transformer to extract significant information from the input images and further enhance the performance of the proposed framework. The Residual Networks capture both low-level and high-level semantic features, whereas the Vision Transformer derives global and contextual feature representations from the input images. The model designs a customized fusion layer for combining the extracted features from both Residual Networks and Vision Transformer models. The classification layer predicts whether the liver tumor is benign or malignant. Further, Gradient-Weighted Class Activation Mapping is applied to highlight the critical regions of the image to enhance model transparency. The CustomLiverNet framework was trained and validated on two publicly available liver cancer datasets, including the liver tumor segmentation dataset, which contains 131 contrast-enhanced abdominal Computed Tomography scans, and the 3D image reconstruction for comparison of algorithm database, which includes 20 computed tomography scans. Experimental evaluation using standard metrics shows that CustomLiverNet achieved an accuracy of 98.79 %, precision of 98.64 %, recall of 98.58 %, and specificity of 98.35 %. These results demonstrate that the proposed model holds strong potential for enhancing early and accurate liver cancer diagnosis compared to previous studies.},
  archive      = {J_ESWA},
  author       = {Shivani Joshi and Avinash Dwivedi and Rajiv Kumar and Ashish Kumar and Raju Kumar and Amrita},
  doi          = {10.1016/j.eswa.2025.129734},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129734},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unleashing the power of large language models for low-resource relation triplet extraction by structure-to-text data generation. <em>ESWA</em>, <em>298</em>, 129733. (<a href='https://doi.org/10.1016/j.eswa.2025.129733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling language models have revolutionized widespread NLP tasks, yet little investigation has been conducted to assess the ability of Large Language Models (LLMs) to explore low-resource relation triplet extraction. This paper investigates essential methodologies, k -shot demonstration of in-context learning, and many-shot instruction tuning for few-shot and zero-shot relation triplet extraction using FlanT5, supported by exhaustive experiments. To enhance low-resource setting performance, we further propose different types of demonstration examples and task-related instructions for data generation. Specifically, we leverage LLMs to construct a structured prompt template for generating synthetic training data based on structured text and efficiently explore the boundary issues of examples in both instruction tuning and in-context learning, assessing their impact on model performance. To address the challenge of extracting multiple relation triplets from a single sentence, we design a novel Multiple Triplet Search (MTS) algorithm. Furthermore, we find that in-context learning can match the performance of previous prompt learning methods. Additionally, integrating synthetic data with the LLM can improve existing solutions in low-resource scenarios, achieving new state-of-the-art results. Experiments conducted on six relation extraction datasets demonstrate the efficacy of the proposed model for the zero-shot and few-shot RTE tasks. Our source code is publicly available at https://github.com/Phevos75/LLMRTE.},
  archive      = {J_ESWA},
  author       = {Qian Guo and Yi Guo and Jin Zhao},
  doi          = {10.1016/j.eswa.2025.129733},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129733},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unleashing the power of large language models for low-resource relation triplet extraction by structure-to-text data generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LDATA-net: Dynamic feature adaptation for efficient feature learning in resource-limited UAV detection. <em>ESWA</em>, <em>298</em>, 129725. (<a href='https://doi.org/10.1016/j.eswa.2025.129725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) image analysis faces the dual challenges of complex background interference and limited onboard computational resources, particularly when processing extreme scale variations across multiple viewpoints. Existing approaches typically enhance detection accuracy by increasing model complexity, but this often leads to parameter proliferation that exceeds the deployment limits of airborne platforms. To address this fundamental contradiction, we propose LDATA-Net (Lightweight Dynamic Aggregation Task-Aligned Network), which pioneers a “Dynamic Feature Adaptation” design paradigm aimed at achieving synergistic optimization between parameter efficiency and detection accuracy. This framework systematically realizes end-to-end dynamic adaptive capabilities through three core components that operate collaboratively across feature extraction, fusion, and detection stages: (1) Dynamic Multi-Branch Depthwise Block (DMBD-Block), whose core innovation is our proposed novel operator DIDWConv, which adaptively adjusts receptive fields according to input features to capture targets of extreme scales and orientations; (2) Lightweight Dynamic Aggregation Network (LDANet), which effectively preserves critical spatial contextual information through hierarchical fusion architecture and dynamic weighting mechanisms; (3) Dynamic Adaptive Head (DA-Head), which effectively mitigates task conflicts through geometric and semantic dynamic feature alignment. LDATA-Net achieves 35.4 %, 77.9 %, and 51.2 % AP 50 on VisDrone2019, DOTA1.0, and AI-TODv2 datasets respectively with only 2.8M parameters, establishing a new paradigm for designing memory-efficient yet high-performance detection systems, particularly for resource-constrained heterogeneous computing aviation platforms.},
  archive      = {J_ESWA},
  author       = {Shuming Lin and Sang Feng and Junnan Tan},
  doi          = {10.1016/j.eswa.2025.129725},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129725},
  shortjournal = {Expert Syst. Appl.},
  title        = {LDATA-net: Dynamic feature adaptation for efficient feature learning in resource-limited UAV detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach. <em>ESWA</em>, <em>298</em>, 129724. (<a href='https://doi.org/10.1016/j.eswa.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing complexity and scale of technological knowledge ecosystems, organizations face challenges in identifying intra- and inter-organizational collaboration opportunities. In this respect, prior studies have proposed patent-based approaches, but they are subject to several limitations: (1) insufficient consideration of technological relationships within the ecosystem, (2) simplified unit of analysis, and (3) limited organization-centric assessments. This study proposes a network embedding and text-reranking approach to explore potential intra- and inter-organizational collaboration opportunities. First, the technological knowledge ecosystem is represented as a heterogeneous patent network comprising patents, inventors, assignees, and technology classification codes. Second, inventor nodes are embedded using metapath2vec, which performs random walks along predefined metapaths to capture diverse knowledge flows within the ecosystem. Third, potential collaborators are explored through (1) screening candidates based on technological reachability, which measures the possibility of knowledge exploration based on contextual similarity within the network, and (2) reranking candidates based on technological relevance, which quantifies the possibility of knowledge exploitation based on the similarity of technological know-how and experiences. Finally, ten quantitative patent indicators are developed to assess the implications of these opportunities at both the inventor and organization levels. The validity of the proposed approach is demonstrated through a case study involving 28,888 US patents and 9,196 inventors in the field of energy storage technology. This study contributes to advancing the theoretical understanding of technological knowledge ecosystems while also serving as a supplementary tool to explore organizational collaboration opportunities.},
  archive      = {J_ESWA},
  author       = {Jaemin Chung and Jaewoong Choi and Janghyeok Yoon},
  doi          = {10.1016/j.eswa.2025.129724},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129724},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved actor-critic architecture with PPO for the traveling salesman problem. <em>ESWA</em>, <em>298</em>, 129723. (<a href='https://doi.org/10.1016/j.eswa.2025.129723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) is a classic NP-hard problem in combinatorial optimization with extensive practical applications. In this paper, we present an improved Actor-Critic architecture incorporating Proximal Policy Optimization (PPO) to effectively solve TSP. We introduce adaptive temperature scheduling, comprehensive state representation, and layer normalization to enhance learning stability. Experimental results demonstrate our Improved Actor-Critic approach achieves significant improvements ranging from 8.7 % to 55.9 % for different problem sizes compared to established reinforcement learning baselines including Q-Learning, SARSA, Double Q-Learning, Actor-Critic with Experience Replay (ACER), and Trust Region Policy Optimization (TRPO), with particularly strong performance on smaller instances between 20 to 100 cities. When testing on standard TSPLIB benchmarks, our method shows consistent advantages of 12 % to 33 % compared to classical approaches While tabular methods become computationally infeasible beyond 250 cities due to memory constraints, our approach maintains high solution quality for problems up to 1432 cities on our experimental setup (Intel® Core™i9-10900X CPU @ 3.70GHz × 20 with four NVIDIA Quadro RTX 5000 GPUs). Our ablation studies confirm the importance of each component in our proposed architecture, in which the improved state representation provides the most significant contribution to our model performance. This research significantly advances reinforcement learning approaches to combinatorial optimization, with practical implications for logistics, telecommunications, and manufacturing. The developed source code is available at: https://github.com/LetuQingge/TSP_Environment .},
  archive      = {J_ESWA},
  author       = {Hailemicael Lulseged Yimer and Pei Yang and Letu Qingge},
  doi          = {10.1016/j.eswa.2025.129723},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129723},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved actor-critic architecture with PPO for the traveling salesman problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of semi-markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks and its application. <em>ESWA</em>, <em>298</em>, 129718. (<a href='https://doi.org/10.1016/j.eswa.2025.129718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the synchronization issue of the semi-Markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks is addressed, in which the dual-scale hybrid attacks mean that hybrid attacks can be encountered in different time scales transmission channels. Based on mismatched membership functions, a new ϵ -dependent combined synchronization controller is proposed to ensure the synchronization of the master semi-Markov jump two-time-scale fuzzy neural networks and the slave ones while it is capable of resisting independent dual-scale hybrid attacks. Through the development of a Lyapunov function incorporating the singular perturbation parameter ϵ , stability conditions and a computational approach for determining the synchronization controller gain are derived for semi-Markov jump two-time-scale fuzzy neural networks. Finally, some simulations and two encryption and decryption processes are used to show the effectiveness of obtained results.},
  archive      = {J_ESWA},
  author       = {Feng Li and Ya-Nan Wang and Lei Su and Sangmoon Lee},
  doi          = {10.1016/j.eswa.2025.129718},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129718},
  shortjournal = {Expert Syst. Appl.},
  title        = {Synchronization of semi-markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks and its application},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning. <em>ESWA</em>, <em>298</em>, 129717. (<a href='https://doi.org/10.1016/j.eswa.2025.129717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dendritic or cellular morphologies of alloys and metals formed during casting processes significantly influence key properties such as mechanical strength, toughness, hardness, and electrical or thermal conductivities. The literature presents correlations between these properties and the microstructural length scale, which requires accurate characterization at the micrometer level. However, traditional evaluation methods demand extensive experimental efforts, including careful metallographic preparation, high-quality imaging, and a large number of measurements for statistical reliability - often relying on analyst proficiency. This study proposes a machine learning-based workflow tailored for the automated processing of microstructure images. The approach enables the autonomous measurement of key microstructural features while minimizing bias and inconsistencies among analysts. By integrating advanced image processing techniques with object detection algorithms based on Convolutional Neural Networks (CNNs), the method autonomously identifies microstructural morphologies and quantifies their spacing scales. Three model types-Cell, Dendrite, and Hybrid (exhibiting both dendritic and cellular features)-were trained and validated on using a dataset of 200 images. Among them, the Cell detection model achieved the highest performance, with a mean Average Precision (mAP) of 78.77 %, followed by the Hybrid (75.63 %) and Dendrite (72.87 %) models. Finally, the automated measurements models were applied to literature images and compared to reported microstructural growth correlations.},
  archive      = {J_ESWA},
  author       = {Guilherme Marim da Silva and Rafael Kakitani and Carlos Henrique da Silva Santos and Amauri Garcia and Noé Cheung},
  doi          = {10.1016/j.eswa.2025.129717},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129717},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time. <em>ESWA</em>, <em>298</em>, 129716. (<a href='https://doi.org/10.1016/j.eswa.2025.129716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of manufacturing systems, reentrancy has become prevalent in many production environments. This study investigates a bi-objective distributed reentrant flow shop scheduling problem with sequence-dependent setup times (DRFSP-SDST). The objectives are to minimize the total energy consumption (TEC) and the maximum completion time (makespan), simultaneously. First, a bi-objective mathematical model for the DRFSP-SDST is formulated based on practical reentrant production scenarios. Second, the artificial bee colony (ABC) algorithm and its variants are employed to solve the DRFSP-SDST. According to the characteristics of the DRFSP-SDST, six local search operators are specifically designed to enhance the performance of the proposed algorithms. For promoting greener and more energy-efficient production, two speed-scaling strategies are developed. Third, two reinforcement learning (RL) algorithms, Q-learning and State-Action-Reward-State-Action (SARSA), are integrated into the iterative process as online learning strategies to guide the selection of high-quality local search strategies during the iterations of the proposed algorithms. For each RL algorithm, two distinct selection strategies for local search operators are designed. Finally, the effectiveness of the proposed enhancement strategies is evaluated through comprehensive numerical experiments on 36 benchmark instances. The performance of the proposed algorithms is further validated via the Friedman test. The experimental results and analysis demonstrate that the ABC algorithm enhanced by SARSA-based local search exhibits superior competitiveness in solving the DRFSP-SDST.},
  archive      = {J_ESWA},
  author       = {Ao Yao and Kaizhou Gao and Ponnuthurai Nagaratnam Suganthan and Hongyan Sang},
  doi          = {10.1016/j.eswa.2025.129716},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129716},
  shortjournal = {Expert Syst. Appl.},
  title        = {Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Defects inspection system for building facades using drones and deep learning method. <em>ESWA</em>, <em>298</em>, 129715. (<a href='https://doi.org/10.1016/j.eswa.2025.129715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular inspection and maintenance of building facades are essential for preserving structural integrity and aesthetic quality, especially in aging urban high-rises. While drone-based visual inspection powered by artificial intelligence (AI) offers benefits in speed, safety, and scalability, existing methods are typically limited to single defect types or uniform facade categories due to the challenges of detecting multi-scale defects in complex, heterogeneous environments. This study introduces an automated multiclass defects inspection system for building facades by integrating drone technology, an AI-driven segmentation platform, and automatic report generation. Central to the system is a segmentation AI model capable of detecting multiclass defects with orders-of-magnitude differences in scale across diverse facade backgrounds. To handle the pixel imbalance of defects ranging from fine cracks to large spalling and glass breakage, the model is built upon EfficientUNet++, trained on a carefully curated dataset and optimized using adjustable batch sizes and active learning rates to improve multi-scale feature learning and mitigate overfitting. Evaluations on validation and out-of-sample datasets demonstrate that the proposed model achieves superior performance across all defect classes. Real-world drone experiments further confirm the model’s practical applicability, with high recall rates in detecting spalling, water seepage, cracks, and glass breakage across different types of facades. This work pioneers a robust, scalable, and efficient AI-based framework for automated multiclass facade defect inspection, providing actionable information for engineers and supporting urban infrastructure maintenance.},
  archive      = {J_ESWA},
  author       = {Xiaoling Zhou and Robert Lee Kong Tiong},
  doi          = {10.1016/j.eswa.2025.129715},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129715},
  shortjournal = {Expert Syst. Appl.},
  title        = {Defects inspection system for building facades using drones and deep learning method},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects. <em>ESWA</em>, <em>298</em>, 129713. (<a href='https://doi.org/10.1016/j.eswa.2025.129713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative characterization of apparent quality defects in infrastructure is a crucial component of operations and maintenance. It enables rapid assessment of defect severity and supports the timely formulation of preventive strategies. However, a singular visual modality struggles to simultaneously ensure the dual tasks of defect detection and measurement accuracy. To solve these problems, this paper proposes a novel framework for cross-modal multitask learning networks, which comprehensively integrates the advantages of image detection and point cloud measurement. The pixel points identified in the image are mapped to their corresponding three-dimensional coordinates in the point cloud through intensive feature matching. A measurement strategy for the inherent characteristics of the defect is subsequently proposed. Based on prior knowledge of the defect, the area and volume of defects are quantified accurately. Finally, extensive experiments on detection, matching and measurement demonstrate the efficacy of the proposed method. The results provide a valuable reference for the quantitative characterization of infrastructure defects.},
  archive      = {J_ESWA},
  author       = {Yu Wang and Yingchao Dai and Xiaodong Gan and Zhengtao Yang and Zhou Wu},
  doi          = {10.1016/j.eswa.2025.129713},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129713},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language proficiency assessment of autistic children using large language models. <em>ESWA</em>, <em>298</em>, 129712. (<a href='https://doi.org/10.1016/j.eswa.2025.129712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language impairment is a common comorbidity in children with autism spectrum disorder (ASD), and language proficiency assessment is a primary method for identifying such impairments. However, traditional assessment tools are often subjective and inefficient, while existing computer-assisted methods are limited by a narrow focus and insufficient use of natural language samples. To address these issues, this study proposes a framework for assessing children’s language abilities based on large language models (LLMs). We first preprocess the natural language samples from children and design multiple assessment dimensions and workflows. To enhance the stability of the assessment, we introduce a multi-expert voting mechanism and perform a comparative analysis of various large language models’ performance. The experimental results demonstrate a strong correlation between the framework’s assessment results and the Mullen Scales of Early Learning (MSEL) verbal developmental quotients, with a Pearson correlation coefficient of 0.8 ( p < 0.001). Furthermore, the results show that the multi-dimensional evaluation can accurately differentiate between ASD and typically developing (TD) children, achieving a classification accuracy of 0.98. These findings suggest that the proposed framework has significant potential for improving the accuracy of ASD identification.},
  archive      = {J_ESWA},
  author       = {Saige Qin and Min Liu and Tongquan Wei and Qiaoyun Liu},
  doi          = {10.1016/j.eswa.2025.129712},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129712},
  shortjournal = {Expert Syst. Appl.},
  title        = {Language proficiency assessment of autistic children using large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EQUINAS: Equilibrium-guided differentiable neural architecture search. <em>ESWA</em>, <em>298</em>, 129711. (<a href='https://doi.org/10.1016/j.eswa.2025.129711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has significantly mitigated the performance collapse issue in Differentiable Architecture Search (DARTS) by either refining architecture parameters to better reflect the true strengths of operations or developing alternative metrics for evaluating operation significance. However, the actual role and impact of architecture parameters remain insufficiently explored, creating critical ambiguities in the search process. To address this gap, we conduct a rigorous theoretical analysis demonstrating that the change rate of architecture parameters reflects the sensitivity of the supernet’s validation loss in architecture space, thereby influencing the derived architecture’s performance by shaping supernet training dynamics. Building on these insights, we introduce the concept of a Stable Equilibrium State to capture the stability of the bi-level optimization process and propose the Equilibrium Influential ( E I ) metric to assess operation importance. By integrating these elements, we propose EQUINAS, a differentiable NAS approach that leverages the Stable Equilibrium State to identify the optimal state during the search process and derives the final architecture using the E I metric. Extensive experiments across diverse datasets and search spaces demonstrate that EQUINAS achieves competitive test accuracy compared to state-of-the-art methods while significantly reducing search costs. Additionally, EQUINAS shows remarkable performance in Transformer-based architectures and excels in real-world applications such as image classification and text recognition.},
  archive      = {J_ESWA},
  author       = {Weisheng Xie and Xiangxiang Gao and Xuwei Fang and Hui Li and Chen Hang and Shaoyuan Li},
  doi          = {10.1016/j.eswa.2025.129711},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129711},
  shortjournal = {Expert Syst. Appl.},
  title        = {EQUINAS: Equilibrium-guided differentiable neural architecture search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Freq-DETR: Frequency-aware transformer for real-time small object detection in unmanned aerial vehicle imagery. <em>ESWA</em>, <em>298</em>, 129710. (<a href='https://doi.org/10.1016/j.eswa.2025.129710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in unmanned aerial vehicle (UAV) and remote sensing technologies have propelled UAV object detection to the forefront of computer vision research. Despite significant progress in deep learning-based detection algorithms, critical challenges persist in small object detection, including high-frequency information loss, inadequate multiscale feature representation, etc. To address these limitations, this paper proposes Freq-DETR, a frequency-aware real-time transformer detection framework leveraging frequency domain analysis to enhance edge detail preservation and global contextual modeling through three novel innovations. First, the frequency-enhanced convolution module (FECM) synergistically integrates spatial and frequency features via dual-branch processing; Second, the decoupled intra-feature scale interaction module (DSC-Clo block) facilitates the integration of high-frequency local and low-frequency global information; Finally, the attention-guided selective feature pyramid network (AGS-FPN) employs context-aware attention for high-level screening feature fusion. Extensive evaluations on the VisDrone2019 benchmark demonstrate that Freq-DETR outperforms the baseline RT-DETR by 4.9 % m a p @ 50 gain while maintaining computational efficiency. There are also remarkable improvements on both UAVDT and HIT-UAV datasets. Ablation investigations and visual interpretability analyses further confirm the complementary benefits of its frequency-domain components and the framework’s robustness in complex aerial scenarios.},
  archive      = {J_ESWA},
  author       = {Jiayi Chen and Ningzhong Liu and Han Sun and Yu Wang},
  doi          = {10.1016/j.eswa.2025.129710},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129710},
  shortjournal = {Expert Syst. Appl.},
  title        = {Freq-DETR: Frequency-aware transformer for real-time small object detection in unmanned aerial vehicle imagery},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Companion learning networks: A deep reinforcement learning algorithm with partner networks. <em>ESWA</em>, <em>298</em>, 129709. (<a href='https://doi.org/10.1016/j.eswa.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep reinforcement learning (DRL) agents suffer from severe reward instability during late-stage exploration, particularly when encountering novel states in complex continuous environments. A variety of existing studies focus on improving an agent’s reward exploration. However, they ignore the instability problem that arises when the agent faces new states in the later stages of exploration. This paper proposes a novel companion learning network (CLN) based on the idea that the guidance can accelerate human learning efficiency and reduce the risk of making mistakes. The CLN integrates a short-term partner network to intensively learn localized environmental patterns, offering adaptive action guidance for recent states. Simultaneously, a global Q-network dynamically incorporates the partner’s decaying guidance signals, balancing autonomous exploration with error mitigation. As training progresses, the partner’s influence gradually diminishes, allowing the Q-network to solidify robust policies without persistent dependence. Extensive experiments on four OpenAI Gym environments demonstrate that the CLN can significantly improve the exploration stability in most tested scenarios, achieving up to 49% reduction in late-stage reward standard deviation compared to baseline DRL methods.},
  archive      = {J_ESWA},
  author       = {Jin Xu and Jinfeng Bu and Yu Zhang and Jia-Dong Zhang and Chi-Yin Chow},
  doi          = {10.1016/j.eswa.2025.129709},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129709},
  shortjournal = {Expert Syst. Appl.},
  title        = {Companion learning networks: A deep reinforcement learning algorithm with partner networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Expensive multiobjective immune algorithm using a novel differential evolution in objective space. <em>ESWA</em>, <em>298</em>, 129708. (<a href='https://doi.org/10.1016/j.eswa.2025.129708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating offspring solutions with strong convergence and diversity is critical when solving expensive multiobjective optimization problems due to the limited number of objective function evaluations. However, existing algorithms produce offspring solutions in the decision space, causing significant uncertainty in obtaining offspring with strong convergence and diversity. To address this issue, we devise a novel differential evolution based on the objective space rather than the decision space, called Differential Objective Evolution (DOE). Specifically, DOE generates objective values with strong convergence and diversity and then maps these values to the decision space to achieve high-quality offspring. Furthermore, we utilize a multiobjective immune algorithm to produce high-quality samples for effectively training the mapping in DOE. When compared with eleven recently proposed algorithms on 105 expensive multiobjective optimization problems, the experiments demonstrate the superiority of our algorithm and the contributions of DOE in both population convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Yuchao Su and Wu Lin and Daxin Zhu and Anhui Tan and Ka-Chun Wong and Qiuzhen Lin},
  doi          = {10.1016/j.eswa.2025.129708},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129708},
  shortjournal = {Expert Syst. Appl.},
  title        = {Expensive multiobjective immune algorithm using a novel differential evolution in objective space},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation. <em>ESWA</em>, <em>298</em>, 129707. (<a href='https://doi.org/10.1016/j.eswa.2025.129707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User reviews reflect user preferences and item characteristics, optimizing the predictive accuracy and explanation generation of personalized recommendation systems. However, existing models face challenges due to subjective uncertainty in user feedback and a lack of transparency. Reviews often contain ambiguous emotional expressions, with the same product receiving positive, neutral, and negative sentiments. Many recommendation models assume alignment between ratings and review sentiments, but in practice, users may give high ratings while expressing dissatisfaction or vice versa. These inconsistencies complicate accurate modeling of user preferences. To address these issues, a Large Language Model (LLM)-driven sentiment-enhanced heterogeneous graph neural network framework is proposed. This framework jointly models interaction data and fuzzy sentiment information from reviews to improve both recommendation accuracy and explainability. By leveraging LLM with dual-prompt strategies, high-quality sentiment distributions and semantic insights are extracted. Review sentiments are then quantified using intuitionistic fuzzy numbers to address data sparsity and uncertainty, capturing implicit relationships between users, items, and entities in a sentiment-enhanced heterogeneous relational graph. A fuzzy sentiment-weighted graph convolutional network (FSGCN) is introduced for dynamic higher-order feature learning, adjusting sentiment weights based on user-item interactions and emotional context. The framework also integrates LLM-driven query interpretation to generate recommendations with transparent, context-aware rationales. This approach enables users to understand the reasoning behind recommendations, significantly enhancing explainability and trust.},
  archive      = {J_ESWA},
  author       = {Zhinan Li and Zhenyu Liu and Guodong Sa and Mingjie Hou and Jiacheng Sun and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129707},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129707},
  shortjournal = {Expert Syst. Appl.},
  title        = {Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Geodesic-based path planning for port transfer robots on riemannian manifolds. <em>ESWA</em>, <em>298</em>, 129706. (<a href='https://doi.org/10.1016/j.eswa.2025.129706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid intelligent transformation of the automotive industry and the surge in production volume, intelligent autonomous robots equipped with integrated perception and planning systems are playing an increasingly vital role in vehicle transfer operations. Optimizing dispatch paths of robots is essential for improving overall operational efficiency, yet achieving a balance among path length, feasibility, and safety margin remains a significant challenge. To address this issue, we propose a geodesic-based path planning method formulated on Riemannian manifolds. The approach jointly considers directional motion constraints, steering effort, and obstacle accessibility boundaries to construct a Riemannian metric tensor that encodes local path cost structures. This transforms the planning task into a geodesic shortest path problem, which is efficiently solved using the Geometric heat flow (GHF) method. The resulting paths naturally comply with kinematic constraints and exhibit strong obstacle-avoidance capabilities, significantly enhancing safety and executability. Extensive simulations and real-world experiments in high-density port yard environments demonstrate the practicality and robustness of the proposed method under complex spatial constraints and obstacle configurations.},
  archive      = {J_ESWA},
  author       = {Runjiao Bao and Junzheng Wang and Shoukun Wang},
  doi          = {10.1016/j.eswa.2025.129706},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129706},
  shortjournal = {Expert Syst. Appl.},
  title        = {Geodesic-based path planning for port transfer robots on riemannian manifolds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation. <em>ESWA</em>, <em>298</em>, 129705. (<a href='https://doi.org/10.1016/j.eswa.2025.129705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by empirical decision-making (EDM) processes, we propose a novel modeling framework where agents iteratively integrate social neighbors’ opinions into their cognitive inertia sequences (CISs), gradually prioritizing their accumulated CISs over time. This framework simulates the transition from group decision-making (GDM) to EDM through dynamic trust/distrust propagation and aggregation mechanisms grounded in social balance theory–capturing relational scenarios such as “a friend of a friend is a friend”, “a friend of an enemy is an enemy”, “an enemy of a friend is an enemy”, and “an enemy of an enemy is a stranger”. The paradigm incorporates two core mechanisms: (1) an endogenous cognitive inertia mechanism that uses the psychological serial-positioning effect to model cognitive inertia weights, accounting for primacy, recency, and U-shaped memory effects; and (2) an exogenous mechanism that quantifies comprehensive trust/distrust degrees via opinion similarity, stability similarity, and network structure similarity. To prevent followers from falling into cognitive freezing, a cluster leader-based consensus-reaching strategy is introduced. Extensive comparative experiments on real-world network datasets confirm the model’s effectiveness and robustness.},
  archive      = {J_ESWA},
  author       = {Jianglin Dong and Yiyi Zhao and Shangqun Mu and Haixia Mao and Jiangping Hu},
  doi          = {10.1016/j.eswa.2025.129705},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129705},
  shortjournal = {Expert Syst. Appl.},
  title        = {A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features. <em>ESWA</em>, <em>298</em>, 129704. (<a href='https://doi.org/10.1016/j.eswa.2025.129704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is essential for indoor service robots to achieve reliable navigation and mapping. While point and line features have been extensively utilized to enhance the accuracy of visual odometry (VO), current methods often overlook the rich geometric information embedded in the spatial relationships among structural lines. In particular, the parallelism and collinearity within groups of line segments are underexploited, and geometric constraints are typically applied only heuristically or post hoc, limiting robustness in low-texture and repetitive environments. To address these challenges, a robust VO system is proposed that integrates structural feature grouping with adaptive MW tracking. A unified feature extraction strategy is introduced to detect point and line features simultaneously, improving computational efficiency. To mitigate pose drift caused by unreliable line segments, a set of parallel line features is constructed based on local geometric constraints, and a novel reprojection error model is formulated to enhance pose estimation. Furthermore, a tracking strategy based on local Manhattan World (MW) structure is developed to ensure low-drift estimation across various structured indoor scenes. Extensive experiments on multiple public datasets and a custom-built service robot platform demonstrate that the proposed method outperforms existing state-of-the-art approaches under dynamic lighting conditions and in environments rich in lines and planes. The system also operates at a real-time speed of 30 frames per second, meeting the requirements of practical robotic applications.},
  archive      = {J_ESWA},
  author       = {Zhiyu Wang and Weili Ding and Ying Zhang and Changchun Hua},
  doi          = {10.1016/j.eswa.2025.129704},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129704},
  shortjournal = {Expert Syst. Appl.},
  title        = {OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated meta graph retention network: A model for urban traffic flow prediction. <em>ESWA</em>, <em>298</em>, 129703. (<a href='https://doi.org/10.1016/j.eswa.2025.129703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for urban transportation systems. Existing models are still deficient in training efficiency and modeling dynamic spatial-temporal dependencies, various external factors, time-varying topology. Based on this, this paper introduces the Adaptive Gated Meta Graph Retention Network (AGMGRN), a novel model for spatial-temporal traffic flow prediction. Specifically, the AGMGRN integrates the attention mechanism with the retention network to model spatial-temporal dependencies. The AGMGRN proposes a gated dynamic connection block to enhance the model’s dynamic modeling capabilities. The AGMGRN considers the influence of external factors on traffic conditions through meta-learning approaches. The AGMGRN proposes an adaptive graph block to construct time-varying topologies. Experiments on four actual large-scale datasets demonstrate that the AGMGRN achieves superior prediction accuracy and high applicability.},
  archive      = {J_ESWA},
  author       = {Xing Li and Yuequan Bao},
  doi          = {10.1016/j.eswa.2025.129703},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129703},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated meta graph retention network: A model for urban traffic flow prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations. <em>ESWA</em>, <em>298</em>, 129702. (<a href='https://doi.org/10.1016/j.eswa.2025.129702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defensive Counter-Air (DCA) operations are pivotal for modern air defense, but existing studies are limited by static defender populations and oversimplified attacker models. We address these limitations with the Dynamic Agent-Scaling Framework with Game-Augmented Reinforcement Learning (DASF-GRL), which dynamically scales defender populations based on real-time threat levels. Specifically, we introduce a hybrid imitation-reinforcement training strategy that integrates attention mechanisms into critic networks to enable dynamic agent scaling. By incorporating a safety barrier function rooted in differential game theory, we constrain agents’ action spaces and enhance policy reliability. Furthermore, we developed a DCA simulation platform supporting reinforcement learning validation and designed a novel Apollonius-based penetration strategy for attackers to improve algorithmic robustness. Experiments demonstrate that DASF-GRL adaptively adjusts defender populations across scenarios involving 20, 40, and 60 attackers, markedly outperforming baseline methods in convergence speed and defense success rates. This framework offers novel theoretical paradigms and practical tools for intelligent decision-making in DCA environments.},
  archive      = {J_ESWA},
  author       = {Yuxuan Chen and He Luo and Guoqiang Wang},
  doi          = {10.1016/j.eswa.2025.129702},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129702},
  shortjournal = {Expert Syst. Appl.},
  title        = {DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction. <em>ESWA</em>, <em>298</em>, 129701. (<a href='https://doi.org/10.1016/j.eswa.2025.129701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven spatial and temporal distribution of renewable energy resources poses significant challenges for multi-microgrid (MG) systems, resulting in high operational costs and low renewable energy utilization. To overcome these challenges, this work investigates a peer-to-peer electricity transaction and hydrogen-methanol-hydrogen technology-based methanol transaction among multi-MG. Besides, to realize net-zero emissions and carbon cycle utilization, the carbon capture system and hydrogen blending system are introduced into MG to reduce carbon dioxide emissions and capture and reform carbon dioxide for methanol synthesis equipment. Additionally, a cooperative operation model based on the Nash bargaining theory for multi-MGs under the transaction amount and price constraints of electricity and methanol is constructed. Due to the characteristics of non-convex and non-linear, the Nash bargaining is transformed into minimizing operation costs (sub-problem one) and maximizing payment benefits (sub-problem two). During the process of benefit allocation in sub-problem two, this work adopts a nonlinear energy sharing mapping method to quantify the comprehensive contribution rate of each MG to the multi-MG system, thereby achieving fair allocation of benefits. Finally, the alternating direction multiplier method is used to solve the model, effectively protecting the privacy of each MG. The simulation results demonstrate that a multi-MG system considering electricity and methanol transactions can effectively decrease carbon emissions and the total operational costs by 21.53% and 27.01% compared to only considering electricity transactions, respectively. Overall, the proposed electricity and methanol transactions strategy simultaneously reduces the overall system operation costs and carbon emissions, underscoring its advantages and significance.},
  archive      = {J_ESWA},
  author       = {Jiale Li and Bo Yang and Yiming Zhou and Hongchun Shu and Hongbiao Li and Dengke Gao and Lin Jiang},
  doi          = {10.1016/j.eswa.2025.129701},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129701},
  shortjournal = {Expert Syst. Appl.},
  title        = {Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming. <em>ESWA</em>, <em>298</em>, 129700. (<a href='https://doi.org/10.1016/j.eswa.2025.129700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosion in popularity of crowdsourced live streaming (CLS) has led to a huge increase in demand for cloud resources to support real-time video transcoding. CLS transcoding is real-time, geographically distributed and computationally intensive. Therefore, transcoding service providers need to cost-effectively utilize diverse heterogeneous cloud resources, while guaranteeing quality of service standards to ensure a good streaming experience for the viewers. To support the above, we developed a novel proactive-reactive resource allocation framework that optimizes the overall cost of supporting the CLS transcoding service using heterogeneous edge and cloud computing resources. The offline proactive policy evaluator aims to provide a good and adaptable resource usage plan in advance, matching the predicted demand with the heterogeneous resources. The reactive execution module monitors the actual demand online and controls the resource usage to compensate for deviations from the offline prediction. Our experiments show that the proposed approach leads to a cost reduction of 42 % compared to the fixed usage ratio strategy based on expert knowledge.},
  archive      = {J_ESWA},
  author       = {Yinuo Li and Jin-Kao Hao and Kwong Meng Teo and Liwei Song},
  doi          = {10.1016/j.eswa.2025.129700},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129700},
  shortjournal = {Expert Syst. Appl.},
  title        = {Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach. <em>ESWA</em>, <em>298</em>, 129699. (<a href='https://doi.org/10.1016/j.eswa.2025.129699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-robot path planning problem requires algorithms with high convergence speed and accuracy, as well as the completeness of the search probability for the optimal path. The integration of metaheuristic algorithms in path planning has proven to be remarkably efficient. This paper introduces a novel hybrid metaheuristic algorithm, Beluga Whale-Crayfish Optimization (BWCOA), for enhanced global optimization in path planning applications. While the Crayfish Optimization (COA) demonstrates superior convergence speed, its inherent probabilistic path completeness remains suboptimal. To address this limitation, we present three key innovations: a dynamic probability completion mechanism, adaptive convergence acceleration factors, and balanced exploration–exploitation trade-off parameters. The proposed BWCOA synergizes Beluga Whale Optimization (BWO)’s basin-hopping capability with COA’s swarm intelligence through parallel combined exploration strategies. To prove its powerfulness, a series of comparative analyses were conducted between BWCOA and other leading algorithms across two comprehensive test function suites. The numerical experiment results underscore the significant superiority of BWCOA over its counterparts. In the context of path planning simulations, BWCOA demonstrated notable improvements over COA within the same number of function evaluations, with average enhancement rates of 6.49 %, 7.42 %, 15.09 %, 76.42 %, and 0.73 % across five evaluation metrics. Similarly, when compared to BWO on the same set of indicators, BWCOA showed average improvement rates of 22.39 %, 27.71 %, 70.53 %, 260.86 %, and 41.22 %. Furthermore, the running time of BWCOA is comparable to that of similar algorithms.},
  archive      = {J_ESWA},
  author       = {Liguo Yao and Guanghui Li and Taihua Zhang and Abdelazim G. Hussien and Yao Lu},
  doi          = {10.1016/j.eswa.2025.129699},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129699},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm based on hybrid penalty strategy and its application to multi-UAV path planning. <em>ESWA</em>, <em>298</em>, 129698. (<a href='https://doi.org/10.1016/j.eswa.2025.129698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained optimization problems with complex and dynamic constraints pose significant challenges for evolutionary algorithms, as the constraints reshape the solution space and create conflicts between feasibility maintenance and global exploration. To address this issue, this study proposes TSC-PSODE, a two-stage evolutionary algorithm based on a hybrid penalty strategy. The algorithm employs an external penalty in the early stage to preserve population diversity and enhance exploration, while an internal penalty in the later stage accelerates convergence toward high-quality feasible solutions. In addition, a cooperative strategy combining differential evolution operators strengthens robustness and helps the population escape local optima. Experimental evaluations on the CEC2017 benchmark suite (the IEEE Congress on Evolutionary Computation 2017 benchmark) and multi-Unmanned Aerial Vehicle path planning tasks demonstrate that TSC-PSODE consistently outperforms state-of-the-art algorithms. The results confirm that the proposed method not only provides an effective mechanism for constraint handling, but also achieves a favorable balance between exploration and exploitation by maintaining diversity and accelerating convergence. In practical terms, TSC-PSODE is capable of generating safe and feasible flight paths for multiple UAVs in complex environments, highlighting its adaptability and competitiveness for real-world applications.},
  archive      = {J_ESWA},
  author       = {Eryang Guo and Yuelin Gao and Chenyang Hu},
  doi          = {10.1016/j.eswa.2025.129698},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129698},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm based on hybrid penalty strategy and its application to multi-UAV path planning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”. <em>ESWA</em>, <em>298</em>, 129697. (<a href='https://doi.org/10.1016/j.eswa.2025.129697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ESWA},
  author       = {Ngaiming Kwok},
  doi          = {10.1016/j.eswa.2025.129697},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129697},
  shortjournal = {Expert Syst. Appl.},
  title        = {Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time. <em>ESWA</em>, <em>298</em>, 129696. (<a href='https://doi.org/10.1016/j.eswa.2025.129696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of global data volume, the usage of hard disk drives (HDDs) is also increasing rapidly. Consequently, the number of failed disks is continuously rising, which can affect storage service quality and even lead to data loss when failures occur.In recent years, the active fault-tolerant technology, which collects hard disks’ Self Monitoring Analysis and Reporting Technology (SMART) data-set, predicts hard disk failure by machine learning model, and repairs near-failure disks’ data to health disks in advance, has become a common research hotspot in both academia and industry. Aiming at the existing problems such as interference characteristics, inaccurate failure time prediction, competition of system resources between data migration and front service, this paper researches the two-stage prediction model and data migration strategy based on hard disk failure time, including the two-stage hard disk information feature selection method, the two-stage prediction method of hard disk failure time, and the data migration elastic system resource allocation strategy. Feature selection is performed by combining embedding methods with visualization, and the importance of the selected features is evaluated using a random forest model. Based on the feature importance, further refinement is carried out to obtain the final feature set. Before predicting the failure time of hard drives, XGBoost is first used in a voting manner to identify drives predicted to be faulty. Then, a trained Bidirectional Long Short-Term Memory network (Bidirectional LSTM) enhanced with a self-attention mechanism is employed to predict the exact failure time.Experimental results show that on the Backblaze dataset, the model achieves a mean absolute error of 1.24 when predicting failure times. The recall rate for predicting failures within 7 days reaches 98.79 %, the error rate is 0.30 %, the F1 score is 99.24 %, and the precision is 99.69 %. The elastic system resource allocation strategy for data migration improves business IOPS by 47.19 % and reduces latency by 38.68 %.},
  archive      = {J_ESWA},
  author       = {Huiyuan Qiang and Yuequan Li and Hongzhang Yang and Ping Wang and Yaofeng Tu and Shang Yang},
  doi          = {10.1016/j.eswa.2025.129696},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129696},
  shortjournal = {Expert Syst. Appl.},
  title        = {2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG emotion recognition through a domain-adversarial multi-feature fusion network. <em>ESWA</em>, <em>298</em>, 129694. (<a href='https://doi.org/10.1016/j.eswa.2025.129694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate recognition of EEG signals linked to emotions is crucial for neuroscience and human-computer interaction. However, variability in EEG emotion recognition among individuals results in inconsistent feature distributions and limited generalization across subjects. To enhance the robustness of the model, we propose a deep learning approach integrating a domain adversarial migration network with an attention mechanism. Initially, a feature extractor with a hierarchical architecture (low-medium-high levels) is employed to capture multi-scale EEG features, which are then normalized for age and encoded for genderand education before being aligned with EEG features through spatio-temporal replication. Subsequently, global distribution alignment is achieved using multi-kernel maximum mean difference (MK-MMD), subdomain adversarial alignment is accomplished with a gradient inversion layer (GRL), and decision boundary clarity is enhanced through joint emotion classification loss. The generalization capability and effectiveness of the model are validated using the DEAP and DREAMER datasets, offering insights for cross-subject emotion recognition research and applications.},
  archive      = {J_ESWA},
  author       = {Weitong Sun and Yuping Su and Yumei Zhang and Xiaojun Wu},
  doi          = {10.1016/j.eswa.2025.129694},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129694},
  shortjournal = {Expert Syst. Appl.},
  title        = {EEG emotion recognition through a domain-adversarial multi-feature fusion network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm. <em>ESWA</em>, <em>298</em>, 129692. (<a href='https://doi.org/10.1016/j.eswa.2025.129692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time delay and Doppler shift parameters in radar system echo signals serve as effective tools for multi-target identification and localization in covert environments. However, the nonlinear characteristics of stationary targets are often masked by surrounding environmental factors, and traditional joint parameter estimation algorithms tend to suffer from high computational complexity and errors during demodulation. To address these challenges, this paper proposes an acoustic-electromagnetic intermodulation detection system based on a novel atomic-paradigm algorithm, which ensures localization accuracy with minimal computational complexity and zero false alarms. Specifically, the system excites the target by introducing acoustic field energy coupling, generating discernible micromotion features. The resulting acoustically modulated signal is then modeled as a two-dimensional line spectral estimation problem, capturing the target’s time delay and Doppler shift. Furthermore, the joint parameter estimation algorithm is enhanced by relaxing dyadic constraints under sufficient conditions. In our experiments, a harmonic radar physical system is constructed to simultaneously localize and measure multiple non-clustered micromotion targets. The recognition accuracy is quantitatively evaluated using a classical neural network model, achieving 86.9 % accuracy across five classified targets. The improved algorithm’s performance in joint parameter estimation is also assessed under varying signal-to-noise ratios and demodulation error rates, with a detailed time complexity analysis provided.},
  archive      = {J_ESWA},
  author       = {Sheng Wu and Yilin Cai and Yijing Zheng and Dingzhao Li and Hongjun Lai and Haixin Sun},
  doi          = {10.1016/j.eswa.2025.129692},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129692},
  shortjournal = {Expert Syst. Appl.},
  title        = {An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data. <em>ESWA</em>, <em>298</em>, 129691. (<a href='https://doi.org/10.1016/j.eswa.2025.129691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a fundamental task in supervised machine learning. This problem becomes challenging when dealing with imbalanced and overlapping datasets. In such cases, learning algorithms often perform well in identifying the labels of majority class data points but exhibit high error rates in predicting the minority class. This paper proposes an innovative method based on the convex-hull concept to enhance classification for imbalanced and overlapping datasets. Unlike undersampling approaches that may lead to the loss of valuable information, our method focuses on preserving the data. The process begins by clustering the data points for each class separately in such a way that no points from the opposite class fall within the convex-hull of each cluster. Then, the support vector machine (SVM) is used to separate every cluster of a given class from the data points of the opposite class. Afterward, data points inside the SVM boundaries are considered as non-overlapping, while those outside the SVM boundaries are identified as overlapping data. The XGBoost algorithm is then employed to classify the data points within the overlapping region. Extensive experiments on a variety of simulated and real-world datasets confirm the effectiveness of the proposed method in terms of various evaluation metrics, compared to existing relevant algorithms for handling imbalanced and overlapping datasets.},
  archive      = {J_ESWA},
  author       = {Farnaz Hooshmand and Sogol Peik-Mortazavi},
  doi          = {10.1016/j.eswa.2025.129691},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129691},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unbiased representation learning via feature decoupling network for cross-scene hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129690. (<a href='https://doi.org/10.1016/j.eswa.2025.129690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For hyperspectral cross-scene classification (HSIC) tasks, the model is trained on the source domains (SDs) and applied directly to the unseen target domains (TDs). For this domain generalization (DG) challenge, a significant issue is the contradiction between the overparameterized model and the limited training domain, which results in the absorption of spurious correlations from environmental features. To alleviate this contradiction, this study proposes a domain extension generator with a feature decoupling network (FDNet). The generator initially decouples the SD into reflectance and shading components, treating them as causal and environmental features, respectively. Considering possible causal residues in environmental features, the shading components are shuffled by style to eliminate undesired correlations. Then, the reflectance and sparsified shading are reconstructed for extension, enriching the training diversity without environmental interference. In addition, to enhance the stability of class-level causal representation, a supervised aggregation strategy is designed to minimize the intra-class distance of the reflectance domain, and supervised contrastive learning is employed to enhance the class-domain semantic consistency information. Comparative analysis with advanced domain generalization and adaptation approaches on three HSI datasets validates the superiority in accuracy and Kappa coefficient metrics of the proposed method.},
  archive      = {J_ESWA},
  author       = {Hanqing Zhao and Lianlei Lin and Zongwei Zhang and Sheng Gao and Junkai Wang},
  doi          = {10.1016/j.eswa.2025.129690},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129690},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unbiased representation learning via feature decoupling network for cross-scene hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy. <em>ESWA</em>, <em>298</em>, 129689. (<a href='https://doi.org/10.1016/j.eswa.2025.129689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presented an Automatic Role Prompting System that seeks to improve the performance of the Large Language Model (LLM) by allowing models to assume varied roles through role-based prompting and, as a result, qualitatively improve the relevance of outputs. Our Automatic Role Prompting System’s target audience is people who do not have domain knowledge. The guiding framework (consisting of an Automated Script for discovering roles and fields layered on top of prompt engineering, and Natural Language Inference (NLI) models trained in advance), was robustly tested through the use of three datasets: our set of 1990 curated prompts, WikiQA, and the AwesomeChatGPTPrompts. We implemented a novel evaluation strategy using GPT-Eval, which scales prompts according to completeness, clarity, and relevance. We found substantially better performance than traditional rule- and template-based approaches, yielding accuracy improvements as high as 97.6 %. Overall, this work demonstrates the promise of an Automated Role Prompting System to help people engage and work more effectively and efficiently with Large Language Models (LLMs).},
  archive      = {J_ESWA},
  author       = {Samar Hendawi and Tarek Kanan and Mohammed Elbes and Ala Mughaid and Shadi Alzu’bi},
  doi          = {10.1016/j.eswa.2025.129689},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129689},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid fusion network using convolutional vision transformers for landslide identification. <em>ESWA</em>, <em>298</em>, 129688. (<a href='https://doi.org/10.1016/j.eswa.2025.129688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have made great strides in the segmentation of remote sensing images, but they still have certain inherent drawbacks when working with small targets and complex geological structures. These drawbacks include incomplete contextual information integration, blurry edges, and inaccurate target localisation. This study suggests using a hybrid CNN-Transformer network to improve the segmentation of landslide regions in high-resolution remote sensing images in order to overcome these difficulties. A comprehensive investigation has been conducted on the use of CNN and transformers to accomplish the task of semantic segmentation. According to experimental data, our model outperforms the state-of-the-art CNN-based, Transformer-based, and even CNN-plus-Transformer combination models for image segmentation tasks by a large margin. When it comes to landslide area segmentation, it performs exceptionally well.},
  archive      = {J_ESWA},
  author       = {S. Sreelakshmi and S.~S. Vinod Chandra},
  doi          = {10.1016/j.eswa.2025.129688},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129688},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid fusion network using convolutional vision transformers for landslide identification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards intelligent online cross-selling. <em>ESWA</em>, <em>298</em>, 129686. (<a href='https://doi.org/10.1016/j.eswa.2025.129686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquity of online cross-selling for fashion demands a large number of qualified outfit compositions. This paper targets practical and intelligent online cross-selling by providing a more accurate fashion compatibility model and a reliable evaluation protocol for evaluating the fashion compatibility model. Firstly, a Hierarchical Outfit Network (HON) is proposed to leverage multi-layer relations among attributes, items, and outfits. The awareness of multiple relations hidden in various outfits enables the HON to outperform all state-of-the-art methods on fill-in-the-blank (FITB) accuracy and compatibility Area Under Curve (AUC) on the Maryland and Type-aware test sets. Meanwhile, a new evaluation protocol is introduced to assess the fashion compatibility model more objectively and accurately, namely, Aesthetic 100 (A100). A100 possess three desirable characteristics: 1) Completeness . All types of standards in the fashion aesthetic system are covered through two tests, namely LAT (Liberalism Aesthetic Test) and AAT (Academicism Aesthetic Test); 2. Reliability . It is an agnostic protocol and consistent with major indicators. It provides an objective and fair assessment for model comparison. 3. Explainability . A100 assesses the model on more fine-grained dimensions, e.g. , Color, Material, and Balance demonstrating its superiority in identifying essential characteristics of fashion aesthetics. Experimental results demonstrate the progress of A100 in the aspects of Reliability and Explainability. The evaluation results on A100 also show the generalization ability of HON from both quantitative and qualitative perspectives. Finally, solutions for multiple applications in fashion retailing are proposed to show how HON can be utilized to help online cross-selling.},
  archive      = {J_ESWA},
  author       = {Kaicheng Pang and Xingxing Zou and Zowie Broach and Waikeung Wong},
  doi          = {10.1016/j.eswa.2025.129686},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129686},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards intelligent online cross-selling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection. <em>ESWA</em>, <em>298</em>, 129679. (<a href='https://doi.org/10.1016/j.eswa.2025.129679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral Object Detection has shown significant advantages under various lighting and weather conditions, with efficient fusion of RGB and thermal information playing a key role. Previous studies have demonstrated the effectiveness of feature fusion based on convolutional neural networks, but limited local feature interactions hinder the capture of global complementary information. To address these limitations, some methods adopt complex fusion strategies to enhance complementary feature extraction, yet fail to mitigate feature redundancy, which negatively impacts detection performance. In this paper, we propose a novel Global-aware Cross-attention and Mask-guided Fusion (GCMF) module for Multispectral Object Detection, following a fusion-refinement paradigm. In the fusion stage, we first introduce Efficient Channel Attention with Weighted Max-Pooling (ECA-WM) to focus on key information within each modality and achieve implicit alignment before fusion. Subsequently, the Global-aware Cross-Attention Transformer (GCAT) effectively captures complementary cross-modal information and models global features. In the refinement stage, the Mask-guided Refinement Strategy (MRS) generates segmentation masks to distinguish target features from the background. These masks are applied before and after cross-modal interaction to highlight target-relevant information while suppressing irrelevant features, resulting in highly discriminative fused representations. Extensive experimental comparisons demonstrate that the proposed GCMF fusion strategy achieves state-of-the-art performance on the publicly available FLIR, LLVIP and DVTOD datasets, with absolute improvements of 2.8 %, 4.2 % and 4.0 % over the previous methods, respectively. Moreover, the proposed strategy is general and effective, making it adaptable to various detection frameworks.},
  archive      = {J_ESWA},
  author       = {Zhong Qu and Jin Yang and Shufang Xia},
  doi          = {10.1016/j.eswa.2025.129679},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129679},
  shortjournal = {Expert Syst. Appl.},
  title        = {GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Oriented bounding box detection algorithm for dense scenarios of robotic arm operation. <em>ESWA</em>, <em>298</em>, 129678. (<a href='https://doi.org/10.1016/j.eswa.2025.129678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the national promotion of intelligent manufacturing and the ’Industry4.0’ strategy, the demand for intelligent robotic arms in industrial production has steadily increased. However, challenges such as occlusion, significant object scale variations, and strict real-time requirements have made target detection in densely packed environments more challenging. This study, based on the YOLOv11 algorithm, proposes an efficient oriented bounding box detection method aimed at improving the model’s performance in feature extraction, computational efficiency, and network lightweighting to tackle target detection challenges in dense industrial settings. A Dynamic-Cross-Stage-Dual-Conv module was designed to enhance the Bottleneck section, employing a parallel dual-branch structure for local feature extraction and global context fusion. Simultaneously, a CIoU loss function with geometric perception was introduced to improve object localization accuracy and strengthen the network’s ability to handle densely stacked objects. Next, a Modulated-Deform-Conv deformable convolution module was integrated into the Backbone structure, dynamically adjusting the convolution kernel sampling positions, enabling the network to learn deformation features in dense scenes, improving adaptability to shape and scale variations while reducing computational load. Additionally, a C3K2_FasterBlock lightweight structure, utilizing partial convolutions and sparse connections, was proposed to minimize redundant calculations and optimize feature interactions. On a custom-built dense object dataset, the model achieved a 2.9 % increase in mAP@0.5 and reduced computational cost by 14 %. Finally, the improved model was deployed on the Jetson Orin Nano development board, demonstrating its practical value in robotic arm recognition and grasping tasks in dense industrial environments, offering a new paradigm for future applications.},
  archive      = {J_ESWA},
  author       = {Jinshun Dong and Lixia Deng and Dapeng Wan and Chenxu Liu and Jianqin Yin and Meiqi Guo and Hongyu Zhang and Shoujun Lin and Haiying Liu and Lida Liu},
  doi          = {10.1016/j.eswa.2025.129678},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129678},
  shortjournal = {Expert Syst. Appl.},
  title        = {Oriented bounding box detection algorithm for dense scenarios of robotic arm operation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction. <em>ESWA</em>, <em>298</em>, 129677. (<a href='https://doi.org/10.1016/j.eswa.2025.129677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in complex environments, particularly under conditions such as low illumination or adverse weather, remains a significant challenge. Multispectral detection techniques that integrate visible and infrared imagery offer a promising solution by leveraging complementary modality information. However, substantial discrepancies between these modalities hinder traditional fusion strategies, which often fail to adaptively align and integrate features, resulting in information loss and diminished detection performance. To overcome this limitation, we propose CrossModalNet, a novel cross-modal fusion and channel interaction framework. CrossModalNet comprises two key modules: Convolutional Attention Interaction Module (CAIM) and Bidirectional Cross-Modal Attention Module (BiCAM). CAIM enables effective cross-modal integration across varying semantic levels by employing convolutional attention mechanisms combined with pixel-wise channel guidance. In parallel, BiCAM enhances inter-modal feature complementarity by modeling channel-level interactions through bidirectional attention pathways. Extensive experiments conducted on four public multispectral datasets, FLIR, LLVIP, M3FD, and VEDAI, demonstrate that the proposed method consistently outperforms existing state-of-the-art approaches across multiple performance metrics. Moreover, with an inference speed of 12.6 FPS on embedded platforms, the proposed model is suitable for real-time deployment.},
  archive      = {J_ESWA},
  author       = {Hanyun Li and Linsong Xiao and Lihua Cao and Di Wu and Yangfan Liu and Yi Li and Yunfeng Zhang and Haiyang Bao},
  doi          = {10.1016/j.eswa.2025.129677},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129677},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification. <em>ESWA</em>, <em>298</em>, 129676. (<a href='https://doi.org/10.1016/j.eswa.2025.129676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear segmentation and classification play a crucial role in pathological image analysis. However, it is frequently challenged by blurred nuclear boundaries and complex structures in digital pathology slides, due to factors such as staining techniques and imaging methods, posing a significant challenge for accurate segmentation and classification. To this end, we propose a novel and efficient approach for nuclear identification, termed Information Propagation with Multi-Granularity Morphology-Guided Network (IPMMG). Specifically, IPMMG progressively captures edge morphology information from different network layers while simultaneously incorporating structural morphology features at multiple granularities. By explicitly propagating features related to both the edge and the structure, our approach constrains semantic features to focus on contours of the region of interest in the nuclear segmentation task, thus mitigating the challenge of blurred morphology. Experiments on public datasets demonstrate that IPMMG achieves state-of-the-art (SOTA) performance in segmentation, as measured by Dice and IoU scores, while also attaining competitive results in classification with DQ, SQ, and PQ metrics. In particular, our proposal IPMMG excels in handling nuclei with blurred edges and complex structures.},
  archive      = {J_ESWA},
  author       = {Dawei Fan and Jun Li and Chengfei Cai and Lihui Lin and Riqing Chen and Yanping Chen and Lifang Wei},
  doi          = {10.1016/j.eswa.2025.129676},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129676},
  shortjournal = {Expert Syst. Appl.},
  title        = {IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MECA: Modular editing via customized expert networks and adaptors in large language models. <em>ESWA</em>, <em>298</em>, 129675. (<a href='https://doi.org/10.1016/j.eswa.2025.129675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Updating language models with new information through targeted edits without resorting to expensive full model retraining remains a critical challenge, particularly when aiming to preserve pre-existing capabilities. In this work, we introduce M odular E diting via C ustomized expert networks and A daptors) (MECA), a unified framework that selectively integrates new knowledge into language models. MECA employs a module-level deferral router to evaluate whether incoming queries fall within the scope of existing edit requests. Queries are then dynamically routed to either customized editing experts or key-value adaptors. This modular strategy ensures that updates are localized, thereby mitigating risks of unintended alterations on unrelated outputs. We validate our approach on sequential editing tasks using Llama2-7B, Llama2-13B and Falcon 11B, benchmarked across two diverse datasets ZsRE and Hallucination. Experimental results show that MECA consistently outperforms several state-of-the-art knowledge editing techniques, achieving improved integration of new information while preserving the model’s original performance. Our analysis further demonstrates that the deferral routing mechanism for selecting modules effectively balances editing precision with overall model stability.},
  archive      = {J_ESWA},
  author       = {Roseline Nyange and Shanbao Qiao and Seung Hoon Na},
  doi          = {10.1016/j.eswa.2025.129675},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129675},
  shortjournal = {Expert Syst. Appl.},
  title        = {MECA: Modular editing via customized expert networks and adaptors in large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication. <em>ESWA</em>, <em>298</em>, 129674. (<a href='https://doi.org/10.1016/j.eswa.2025.129674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG-based personal identification confronts critical hurdles, including high dimensionality, noise, and real-time variability. While RSVP and P300 paradigms provide cognitive-response-driven security, feature extraction challenges prevent practical deployment. Although deep learning has addressed unstructured EEG data, pinpointing optimal RSVP and P300-specific features remains an unresolved issue. To overcome these limitations, we introduced a hybrid GWO-MSE-XAI framework integrating Grey Wolf Optimization (GWO), Multiscale Entropy (MSE), and SHAP-based Explainable AI (XAI) to select the most relevant features from RSVP-evoked P300 EEG signals. The framework prioritizes discriminative feature selection, improves class separability, and incorporates a hybrid cross-entropy loss function fused with Fisher’s score-based feature selection. Benchmark-driven optimization refines EEG-specific feature subsets, while evaluation using classifiers (Random Forest, LightGBM, CatBoost, XGBoost) demonstrates substantial dimensionality reduction, faster convergence, and superior performance (98.89% accuracy). Experimental results confirm robustness, scalability, and enhanced interpretability, positioning the framework as a viable solution for EEG-based identity authentication in real-world RSVP and P300 applications.},
  archive      = {J_ESWA},
  author       = {S Abinayaa and S.S. Sridhar},
  doi          = {10.1016/j.eswa.2025.129674},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129674},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interlink reconfiguration against cascading failures on cyber-physical power systems based on an improved memetic algorithm. <em>ESWA</em>, <em>298</em>, 129673. (<a href='https://doi.org/10.1016/j.eswa.2025.129673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical power systems (CPPSs) are the deep integration of advanced information and other technologies applied to the grid to achieve fundamental changes in the power industry. Thus, it is very significant to enhance the robustness of the power communication system in order to ensure security. For instance, when an interdependent CPPSs is under attack, the failure can diffuse along interconnect topology to the whole system, even causing a system crash. Recall that most of the existing models are one-to-one coupling structures. Drawing close to reality, we develop a modified memetic algorithm to reconstruct CPPSs with multiple-to-multiple interlinks, called MA-Multiple, which is dedicated to improving the robustness of CPPSs. To improve the accuracy of the optimal solution of the MA-Multiple, we devise a crossover operator (CO) based on the null model to increase population diversity. Further improving the suitability of algorithms on CPPSs, we propose a new Kirchhoff centrality (KIC) based on the approximation of the inverse matrix to measure network connectivity and design a local search operator (LSO). In the experiment, we comprehensively compare the MA-Multiple with four closely relevant methods in different scenarios. The results imply that MA-Multiple performs better in enhancing network robustness and resisting attacks.},
  archive      = {J_ESWA},
  author       = {Wei Lin and Li Xu and Yuexin Zhang and Jie Li},
  doi          = {10.1016/j.eswa.2025.129673},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129673},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interlink reconfiguration against cascading failures on cyber-physical power systems based on an improved memetic algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective portfolio optimization for stock return prediction using machine learning. <em>ESWA</em>, <em>298</em>, 129672. (<a href='https://doi.org/10.1016/j.eswa.2025.129672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach that integrates stock return prediction with the mean–variance (MV) model to enhance the performance of the original model. Firstly, stock returns are predicted using machine learning algorithms, including Robust Linear Regression (OLS-H), Random Forest (RF), and Long Short-Term Memory Networks (LSTM), to select a pre-screened stock pool composed of stocks with high predicted returns. Secondly, a linear weighting method combines the predictions above with the MV model, constructing the Mean-Variance-Forecast Error (MVF) model and determining the investment proportions for the pre-selected stocks. Finally, empirical research is conducted using the components of the CSI 300 Index as sample data. The results indicate that the RF + MVF model outperforms other models and the CSI 300 Index in return and risk metrics. At the same time, a sensitivity analysis of relevant parameters further confirms that considering return uncertainty is beneficial for improving the out-of-sample performance of the MV model.},
  archive      = {J_ESWA},
  author       = {Meiyu Huang and Shili Dang and Miraj Ahmed Bhuiyan},
  doi          = {10.1016/j.eswa.2025.129672},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129672},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective portfolio optimization for stock return prediction using machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKT-ML: An efficient knowledge tracing model with multi-task learning. <em>ESWA</em>, <em>298</em>, 129671. (<a href='https://doi.org/10.1016/j.eswa.2025.129671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) aims to trace a student’s mastery of knowledge, known as knowledge states, and has become a popular research area, with Self-Attention (SA)-based KT models achieving the state-of-the-art performance. However, existing SA-based KT models seem to still have issues that need further investigation. Firstly, there commonly exists incorrect question-knowledge concept (Q-KC) mapping, yet most models fail to address this issue. Secondly, existing SA-based KT models suffer from high time complexity due to their extensive use of the SA mechanism. Finally, from real-world datasets, we observe that there exists a repeated attempts pattern which is often overlooked by existing KT models. Motivated by the above observations, we propose a novel Efficient Knowledge Tracing Model with Multi-task Learning (EKT-ML), an SA-based model with three crucial features. Firstly, we formulate the KT as a Multi-task Learning, with Q-task and KC-task as two tasks; by training them simultaneously and treating Q-KC mapping as shared information, the proposed EKT-ML tends to mitigate the impact of incorrect Q-KC mapping. Moreover, we propose an SVD-MLP component to replace the initial SA layers commonly used in existing SA-based KT models, thereby reducing the time complexity of EKT-ML. Finally, experimental results show that EKT-ML improves performance by up to 8.84 % across four metrics on three widely used datasets. Furthermore, it demonstrates that the EKT-ML has reduced time complexity compared with the benchmark baseline.},
  archive      = {J_ESWA},
  author       = {Wei Liu and Bo Yang and Haotian Su and Yaowei Wang and Qing Li},
  doi          = {10.1016/j.eswa.2025.129671},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129671},
  shortjournal = {Expert Syst. Appl.},
  title        = {EKT-ML: An efficient knowledge tracing model with multi-task learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Curriculum learning for a hybrid approach for aspect-based sentiment analysis. <em>ESWA</em>, <em>298</em>, 129669. (<a href='https://doi.org/10.1016/j.eswa.2025.129669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past years, the amount of unstructured online review data has grown exponentially. Many people express their opinions about different aspects of goods and services on the Web. Aspect-Based Sentiment Analysis (ABSA) automatically extracts the sentiments with respect to aspects given in a sentence. We improve the training procedure of the state-of-the-art Hybrid Approach for Aspect-Based Sentiment Analysis with deep contextual word embeddings and hierarchical attention (HAABSA++). In this method, a domain sentiment ontology is used as a main classifier, and if it is not conclusive, a neural network is employed as a back-up. We extend the training of the neural network by incrementally adding more difficult instances, also known as curriculum learning. Restaurant reviews obtained from the SemEval-2015 and SemEval-2016 datasets are used to evaluate the effect of implementing curriculum learning. Using baby steps curriculum learning and a specific curriculum strategy, the accuracy of HAABSA++ is improved from 86.3 % to 87.5 %.},
  archive      = {J_ESWA},
  author       = {Nana Lange and Flavius Frasincar and Maria Mihaela Truşcǎ},
  doi          = {10.1016/j.eswa.2025.129669},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129669},
  shortjournal = {Expert Syst. Appl.},
  title        = {Curriculum learning for a hybrid approach for aspect-based sentiment analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm. <em>ESWA</em>, <em>298</em>, 129668. (<a href='https://doi.org/10.1016/j.eswa.2025.129668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is a key technique for extracting object structures and region boundaries in images, serving as an important foundation for visual tasks such as image segmentation and object recognition. However, during real-world image acquisition, various types of noise are inevitably introduced into the images. Traditional edge detection methods suffer significant performance degradation in noisy environments, often resulting in false edges or missing true edges. To address this issue, this paper proposes a novel edge detection method for noisy images. The method begins by adaptively selecting an optimal fractional order p , based on the distribution characteristics of the image’s subband modulus coefficients. This order is then used to perform a p -order discrete fractional wavelet transform (DFRWT) on the noisy image. Then, within the DFRWT domain, an enhanced Canny algorithm is applied to detect edges. This algorithm improves upon the standard method by replacing the traditional gradient operator with a more robust fractional-order Sobel operator to compute the gradient magnitude. This detection process is performed on both the low- and high-frequency subbands to capture features at different scales. Finally, the edge images from the low- and high-frequency components are reconstructed to obtain the final edge detection result. Experimental results demonstrate that, compared to four representative edge detection algorithms, the proposed method exhibits superior noise robustness and edge preservation capability in noisy environments.},
  archive      = {J_ESWA},
  author       = {Xiaozhong Yang and Chunmeng Li},
  doi          = {10.1016/j.eswa.2025.129668},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129668},
  shortjournal = {Expert Syst. Appl.},
  title        = {A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning. <em>ESWA</em>, <em>298</em>, 129667. (<a href='https://doi.org/10.1016/j.eswa.2025.129667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electron Backscatter Diffraction (EBSD) is a crucial characterisation method in materials engineering. The reliability of EBSD data is essential in the aerospace, nuclear, and automotive industries, as material performance greatly affects operational safety. While industrial practice makes perfect EBSD data difficult, with sample preparation errors, beam drift, and instrumental noise corrupting up to one-third of datasets. Automated crystallographic fidelity restoration solutions are needed because corrupted data force engineers to abandon valuable experiments or manually restore datasets at risk of errors. Current image inpainting techniques fail to maintain crystallographic constraints, resulting in restorations that violate the basic rules for crystalline materials. A novel physics-constrained framework is proposed to fill this gap. It integrates adversarial learning with graph neural networks (GNNs) for crystallographically consistent EBSD image inpainting. The proposed GTRG method consists of three elements: i ) a generative adversarial network (GAN) for reconstructing grain boundaries; i i ) a crystallography-guided graph transformer (T) that converts pixel data into orientation-boundary graphs; and i i i ) a regression graph convolutional network (RGCN) that links grain, orientation and boundaries to predict missing crystal orientations. The framework mandates a single orientation per grain and preserves grain boundary structure through structured graph representations. A strategy for creating automated EBSD datasets that incorporates realistic corruption patterns supports effective model training and evaluation. Experimental validation shows better performance than current methods, with a 3.5 % improvement in SSIM (0.950 vs. 0.918) and a 63.0 % reduction in FID (16.55 vs. 44.70) compared to AOT-GAN. The study on aerospace niobium alloys further validates practical utility, showing statistically consistent grain orientation and size distributions (Kolmogorov-Smirnov D = 0.02 , p > 0.98 ). This work introduces two key advancements: 1) the first integration of graph neural networks with adversarial learning for topology-aware image inpainting, and 2) a physics-informed framework bridging computer vision and materials science, enabling effective restoration of corrupted EBSD data for subsequent engineering applications.},
  archive      = {J_ESWA},
  author       = {Baiyang Zheng and Jiongran Wen and Yat-Sze Choy and Chengwei Fei},
  doi          = {10.1016/j.eswa.2025.129667},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129667},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks. <em>ESWA</em>, <em>298</em>, 129666. (<a href='https://doi.org/10.1016/j.eswa.2025.129666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gathering and sharing of information lay the groundwork for decision-making, while large-scale group decision-making (LSGDM) strategies address biases, promoting a more comprehensive evaluation of alternatives. Regarding information representation, incomplete multi-scale information systems (MSISs), as an application of granular computing, combine inputs from decision-makers (DMs) and tackle data gaps through multi-level analysis to foster LSGDM. Furthermore, given the interference effect among DMs, quantum social networks (SNs) and three-way decisions (TWD) are vital for effective decision-making. Quantum SNs provide a framework for modeling complex trust relationships among DMs, while TWD offers a structured approach to manage uncertainty. Therefore, this paper seeks to investigate quantum SN-guided three-way LSGDM under incomplete MSISs. First, MSISs are designed to gather information across spatial dimensions. Second, trust propagation paths within SNs are aggregated using quantum theory. Following community clustering through the Leiden algorithm, each community is further divided into core and fringe regions by three-way clustering (TWC), where core alternatives reflect the central members and fringe alternatives represent uncertain members. Third, to achieve intra-group consensus, the weights of DMs in fringe regions and those with low consensus levels are adjusted, while for inter-group consensus, the weight and decision information of community representatives with low consensus levels are modified. Fourth, alternatives are classified using the TWD method, which is grounded in the Dempster-Shafer theory and incorporates the enhanced belief Jensen-Sharma-Mittal ( E B J S M ) divergence. Finally, air quality datasets are used to validate the practicality of this method through sensitivity analysis, simulation analysis, comparative analysis, and statistical analysis.},
  archive      = {J_ESWA},
  author       = {Rui Li and Chao Zhang and Hamido Fujita and Wentao Li and Witold Pedrycz and Oscar Castillo},
  doi          = {10.1016/j.eswa.2025.129666},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129666},
  shortjournal = {Expert Syst. Appl.},
  title        = {Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GDCR: Geometry-enhanced directional consistency representation for point cloud analysis. <em>ESWA</em>, <em>298</em>, 129665. (<a href='https://doi.org/10.1016/j.eswa.2025.129665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds provide discrete representations of 3D scenes. The relative positions and directions between points collectively describe the objects. Variations in sampling angles, distances, or noises can introduce perturbations, disrupting these spatial and directional relationships. These pose significant challenges for achieving robust feature representations. However, research on the robust representation of point clouds is limited. Although advanced models achieve impressive performance, they exhibit poor robustness to perturbations. To address this issue, we propose Geometry-enhanced Directional Consistency Representation (GDCR), a novel method designed to enhance robustness. In GDCR, we introduce Statistic-based Geometric Reasoning (SGR) to achieve precise spatial geometric estimation for discrete point sets, explicitly enriching spatial geometric information. Furthermore, GDCR vectorizes features embedded with SGR information and applies feature rotation and relative direction refinement in the expanded feature space for robust directional representation. GDCR improves the flexibility and directional expressiveness of point cloud features, significantly improving robustness against perturbations. Extensive experiments demonstrate that GDCR exhibits outstanding robustness while surpassing or matching the performance of state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Ziming Wang and Boxiang Zhang and Ming Ma and Yue Wang and Taoli Du and Ying Wang and Wenhui Li},
  doi          = {10.1016/j.eswa.2025.129665},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129665},
  shortjournal = {Expert Syst. Appl.},
  title        = {GDCR: Geometry-enhanced directional consistency representation for point cloud analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement. <em>ESWA</em>, <em>298</em>, 129664. (<a href='https://doi.org/10.1016/j.eswa.2025.129664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-Light Image Enhancement (LLIE) plays a crucial role in computer vision applications. Beyond spatial-based approaches, recent works have explored the Fourier domain. To better preserve structural details in extremely dark scenes, infrared modality has also been introduced as a robust prior for capturing scene geometry. However, existing methods suffer from limited enhancement performance due to the independent modeling of Fourier amplitude and phase, the limitations of cross-modal guidance, and the information loss in sequential feature extraction. To address these challenges, we propose APMoE-Net, a dual-stage Fourier network framework with amplitude-phase joint enhancement and spatial Mixture of Experts (MoE) compensation. Stage one performs coarse enhancement by leveraging infrared images to jointly optimize Fourier amplitude and phase, enabling mutual guidance learning between them. Subsequently, a Modality Refinement Module leverages edge information to refine infrared inputs, producing a refined modality map as a more accurate cross-modal prior for subsequent processing. The second stage employs a dual-branch design for texture refinement. Our key innovation lies in the MoE Compensation Module integrated within the Multi-scale Convolution Branch. This module employs a dynamic routing network to selectively activate specialized experts, enabling the recovery of fine-grained textures that are lost during sequential processing. Meanwhile, the Fourier Branch integrates the refined modality map to improve overall detail and contrast. Comprehensive experiments demonstrate that APMoE-Net surpasses state-of-the-art (SOTA) methods in both qualitative and quantitative evaluations. Notably, APMoE-Net achieves outstanding performance with a lightweight design, offering an efficient LLIE solution.},
  archive      = {J_ESWA},
  author       = {Mengen Cai and Tongshun Zhang and Pingping Liu and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129664},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129664},
  shortjournal = {Expert Syst. Appl.},
  title        = {APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms. <em>ESWA</em>, <em>298</em>, 129663. (<a href='https://doi.org/10.1016/j.eswa.2025.129663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection and identification of harmful algal bloom (HAB) images are crucial for developing effective early warning systems for HABs. However, existing edge detection models, primarily designed for natural scenes, struggle with HAB-specific challenges such as blurred cell contours and interference from impurity bubbles. To address these issues, we propose a novel edge detection approach tailored for marine HABs, integrating a diffusion probability model with Sobel convolutional inter-layer attention mechanisms. Firstly, we develop an image enhancement algorithm specifically for HABs images, significantly improving real-time dynamic sampling data by enhancing contrast, edges, and texture features. Next, we introduce the SIAnet network, which utilizes inter-layer attention and convolutional operations to generate comprehensive global information. This network enhances feature correlation by aggregating shared features across multiple layers and modeling both long-range and short-range dependencies, effectively suppressing noise and background interference. This facilitates precise extraction of algae boundaries and morphological characteristics. Additionally, an improved Sobel operator is employed to generate supplementary edge features, accelerating the training process. Experimental results demonstrate that the proposed method achieves robust performance on the HABs dataset, with an Optimal Dataset Scale (ODS) of 0.645, an Optimal Image Scale (OIS) of 0.702, and an Average Precision (AP) of 0.813. Compared to existing methodologies, our approach demonstrates strong generalization on BSDS and BIPED datasets, significantly enhancing performance and mitigating typical CNN issues of edge thickening and fragmentation. It offers essential technical support for efficient HAB early warning system development.},
  archive      = {J_ESWA},
  author       = {Gengkun Wu and Yining Fan and Xin Tian and Chao Cui and Jiazheng Han},
  doi          = {10.1016/j.eswa.2025.129663},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129663},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches. <em>ESWA</em>, <em>298</em>, 129662. (<a href='https://doi.org/10.1016/j.eswa.2025.129662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring an individual’s BioGeographical Ancestry (BGA) through DNA analysis is a valuable tool in various fields such as forensic science, especially when traditional methods fail to identify suspects or victims. Advances in Next-Generation Sequencing (NGS) have revolutionized genomic data acquisition, enabling the development of comprehensive Single Nucleotide Polymorphism (SNP) panels for ancestry inference. This study assessed the effectiveness of a novel panel containing 3234 SNPs at both inter-continental and a more detailed BGA level, using various supervised Machine Learning (ML) models, including Categorical Naive Bayes, Penalized Multinomial Logistic Regression, Linear Support Vector Machines, Random Forest, and tree-based Gradient Boosting. A nested cross-validation approach was employed for model tuning and evaluation, with balanced accuracy as the main performance metric to address class imbalance. At the inter-continental level, all ML models demonstrated high balanced accuracy, confirming their reliability for BGA inference. However, performance declined at the more detailed continental level, likely due to a combination of factors including increased class imbalance, reduced sample sizes for certain populations, and the inherent complexity of distinguishing genetically and geographically proximate groups. Nonetheless, promising results were observed for South Asians, Northeast Asians, Europeans, and West Africans classes. In contrast, performance was notably lower for underrepresented classes such as Inner Asians. Misclassification patterns at both levels appeared to reflect known geographical and historical relationships, although further analysis revealed that these were often concentrated in underrepresented or genetically complex groups. These findings highlighted the potential of this SNP panel and ML approaches as valuable tools for forensic investigations.},
  archive      = {J_ESWA},
  author       = {Cosimo Grazzini and Giorgia Spera and Stefania Morelli and Daniele Castellana and Giulia Cosenza and Michela Baccini and Giulia Cereda and Elena Pilli},
  doi          = {10.1016/j.eswa.2025.129662},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129662},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image. <em>ESWA</em>, <em>298</em>, 129661. (<a href='https://doi.org/10.1016/j.eswa.2025.129661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting small regions of interest (ROIs) from abdominal CT images presents significant challenges, particularly due to class imbalance and variations in the sizes of foreground objects. A commonly adopted solution is the two-stage segmentation. However, this approach has two key limitations: i) Difficulty in balancing localization accuracy and target preservation. To reduce information loss in the first stage, existing methods typically enlarge the predicted bounding boxes, which improves coverage but compromises localization precision. ii) Independent optimization of the two stages, which lacks a collaborative mechanism. This fragmented pipeline limits the flow of information between stages, thereby constraining performance improvements. To address these limitations, we propose a reinforcement learning-based collaborative localization and segmentation (RL-CoSeg) framework, which comprises three sub-networks: localization network (LN), segmentation network, and localization-segmentation collaboration network (LSCN). The LN integrates prior knowledge and incorporates a dynamic reward mechanism to enhance the accuracy and efficiency of target detection through reinforcement learning (RL) strategies. The LSCN further introduces segmentation predictions as a reward signal, which, together with the localization reward, jointly drives policy learning. In addition, a heuristic exploration strategy is employed to avoid local optima and improve training stability. This design strengthens the information interaction and collaborative performance between the two tasks. Experimental results demonstrate that the proposed method achieves superior collaborative performance in small-target medical image segmentation.},
  archive      = {J_ESWA},
  author       = {Feilong Xu and Feiyang Yang and Xiaoli Zhang and Zhaojun Liu},
  doi          = {10.1016/j.eswa.2025.129661},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129661},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction. <em>ESWA</em>, <em>298</em>, 129660. (<a href='https://doi.org/10.1016/j.eswa.2025.129660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to extract relations between entity pairs across the entirety of a document. Current methods have begun to adopt logical rules to enhance the performance of DocRE models. However, the pipeline’s rule learning framework will suffer from the issue of error propagation, and the end-to-end method may lead to mistakes in rule reasoning. Additionly, they ignore entity type information when learning the rules. To address these issues, we propose a novel framework named Soft-Hard Rules with Entity Type Constraints (SH-ETRs) for improving the rules’ expressiveness and quality. Specifically, we first propose a Hard Entity Type Rules Module (H-ETRs) to learn entity type information and provide hard rule constraints. Then, we propose a Soft Entity Type Rule Reasoning Module (S-ETRs), which parameterizes the rule inference process and reduces error propagation during the process. Furthermore, by applying a rule consistency loss function to S-ETRs, we achieve the learning of soft rules under hard rule constraints, thereby aiming to prevent the learning of inaccurate rules during the training process. The experimental results demonstrate that our method outperforms existing rule learning frameworks, achieving state-of-the-art performance with an F1 score of 74.39 and an IgnF1 score of 67.43 across three public datasets and two baseline models.},
  archive      = {J_ESWA},
  author       = {Haisong Chen and Nisuo Du and Qing He and Yuji Wang},
  doi          = {10.1016/j.eswa.2025.129660},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129660},
  shortjournal = {Expert Syst. Appl.},
  title        = {SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable knowledge tracing with dual-level knowledge states. <em>ESWA</em>, <em>298</em>, 129658. (<a href='https://doi.org/10.1016/j.eswa.2025.129658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is a critical technology for achieving personalized learning. It estimates learners’ knowledge states and predicts future performance using historical interaction data. Despite recent advances, two significant challenges remain. First, the accuracy of knowledge state modeling is limited by the insufficient fusion of multi-scale information across temporal and spatial dimensions. Second, a trade-off persists between improving predictive performance and enhancing interpretability. This paper proposes an interpretable knowledge tracing method based on dual-level knowledge states (DIKT) to address these challenges. From the temporal perspective, DIKT incorporates a forgetting-aware RoLinear Transformer and a semantic similarity-based review mechanism to model learners’ problem-level knowledge states. From the spatial perspective, it leverages a Knowledge Concept (KC) relational graph to propagate influence among related KCs and dynamically update learners’ concept-level knowledge states through three sequential learning phases: forgetting, aggregation, and updating. Student performance is predicted using a two-parameter Item Response Theory (IRT) model, which incorporates guess and slip parameters to account for response anomalies. We conduct extensive comparisons between DIKT and 20 state-of-the-art KT models on five widely used public datasets. Experimental results demonstrate that DIKT achieves superior performance while preserving interpretability, highlighting its practical potential for real-world educational applications. The code is available at https://github.com/ting214/DIKT .},
  archive      = {J_ESWA},
  author       = {Yanting Li and Tao Zhou and Tianyu Cai and Shenggen Ju},
  doi          = {10.1016/j.eswa.2025.129658},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129658},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interpretable knowledge tracing with dual-level knowledge states},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RASpan: Improving toponym recognition through span representation model with retrieval augmentation. <em>ESWA</em>, <em>298</em>, 129657. (<a href='https://doi.org/10.1016/j.eswa.2025.129657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toponym recognition aims to identify place names from natural language texts, which is vital for various applications including geographic information retrieval, emergency response, and natural disaster analysis. Currently, mainstream studies mainly adopt deep learning models for toponym recognition. However, these approaches encounter significant limitations due to the inherent ambiguity, variation, and abbreviation of toponyms. To address these issues, we propose a novel Span Representation Model with R etrieval A ugmentation ( RASpan ) that leverages more accurate span representation and effective external geo-entity information to enhance the semantic representation of place names for improving the performance of toponym recognition. On the one hand, RASpan retrieves diverse geo-entities and concatenates geo-entity knowledge with an input sequence to construct a new prompt sequence. On the other hand, RASpan utilizes the prompt encoder based on the language model to encode this prompt sequence and employs a dedicated span representation module to obtain more accurate span representations. In addition, a new geo-entity prediction task is designed to learn the entire representation of each geo-entity while minimizing noise interference. Experiments on three publicly available datasets demonstrate that our model achieves new state-of-the-art results, highlighting the effectiveness of RASpan in toponym recognition by introducing prior geo-entity knowledge.},
  archive      = {J_ESWA},
  author       = {Hui Wu and Anran Yang and Zhinong Zhong and Ye Wu and Fei Yang and Luo Chen and Ning Jing},
  doi          = {10.1016/j.eswa.2025.129657},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129657},
  shortjournal = {Expert Syst. Appl.},
  title        = {RASpan: Improving toponym recognition through span representation model with retrieval augmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An interpretable automated optimized machine learning for predicting concrete compressive strength. <em>ESWA</em>, <em>298</em>, 129656. (<a href='https://doi.org/10.1016/j.eswa.2025.129656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel, interpretable, and automated machine learning (AutoML) framework for accurately predicting the compressive strength of environmentally sustainable concrete mixtures that incorporate supplementary cementitious materials (SCMs) by addressing the growing need for transparent and data driven tools in structural material design, particularly for concrete mixes enriched with various SCMs. A robust unified dataset of 1,317 samples was curated by integrating peer-reviewed experimental studies for this study. The proposed methodology incorporates feature contribution ranking through mutual information, model screening with AutoML to identify the most effective regression models, Bayesian optimization for fine-tuning model parameters, and interpretability techniques including SHAP and counterfactual analysis. The best performance metrics, in training include R 2 of 0.999, a mean absolute error 0.114, root mean squared error 0.7094, and mean absolute percentage error of 0.51 %, in testing phase R 2 of 0.944, a mean absolute error 3.479, root mean squared error 4.8173, and mean absolute percentage error of 9.86 %. The weakest performance, with a training R 2 of 0.982 and a mean absolute error of 1.911 MPa, root mean squared error 2.7990 and mean absolute percentage error 5.43 %, in testing phase R 2 of 0.786 and a mean absolute error of 5.754 MPa, root mean squared error 9.4336 and mean absolute percentage error 16.16 %. The interpretability analysis values provided insights into the most important features, such as curing time and cement are crucial in predicting the strength. Counterfactual analysis further validated the model by illustrating the significant impact of cement, age and water on concrete strength.},
  archive      = {J_ESWA},
  author       = {Aparna Kamarthi and Baskar Kaliyamoorthy},
  doi          = {10.1016/j.eswa.2025.129656},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129656},
  shortjournal = {Expert Syst. Appl.},
  title        = {An interpretable automated optimized machine learning for predicting concrete compressive strength},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT. <em>ESWA</em>, <em>298</em>, 129655. (<a href='https://doi.org/10.1016/j.eswa.2025.129655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI paraphrased text can be used for copyright infringement and the AI paraphrased content can deprive substantial revenue from original content creators. Despite this recent surge of malicious use of generative AI, there are few academic publications that research this threat. In this article, we demonstrate the ability of pattern-based similarity detection for AI paraphrased news recognition. We propose an algorithmic scheme, which is not limited to detect whether an article is an AI paraphrase, but, more importantly, to identify that the source of infringement is the ChatGPT. The proposed method is tested with a benchmark dataset specifically created for this task that incorporates real articles from BBC, incorporating a total of 2,224 articles across five different news categories, as well as 2,224 paraphrased articles created with ChatGPT. Results show that our pattern similarity-based method, that makes no use of deep learning, can detect ChatGPT assisted paraphrased articles at percentages 96.23% for accuracy, 96.25 for precision, 96.21% for sensitivity, 96.25% for specificity and 96.23% for F1 statistic.},
  archive      = {J_ESWA},
  author       = {Konstantinos F. Xylogiannopoulos and Petros Xanthopoulos and Panagiotis Karampelas and Georgios A. Bakamitsos},
  doi          = {10.1016/j.eswa.2025.129655},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129655},
  shortjournal = {Expert Syst. Appl.},
  title        = {The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition. <em>ESWA</em>, <em>298</em>, 129654. (<a href='https://doi.org/10.1016/j.eswa.2025.129654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant progress has been made in emotion recognition research based on electroencephalogram (EEG) signals. However, existing methods face two key limitations: on one hand, the reliance on fixed physical connections or static topological relationships makes it difficult to effectively represent the dynamic non-Euclidean spatial characteristics between EEG electrodes; on the other hand, spatiotemporal feature extraction is often conducted independently. This lack of a collaborative mechanism for spatiotemporal features results in insufficient fine-grained emotional representation capability. To address these issues, a dynamic collaborative evolutionary network (DCENet) is proposed based on graph-aware enhancement and global convolutional Transformer for EEG emotion recognition. DCENet constructs the causal relationship between electrodes by constructing the graph-aware enhancement (GAE) module, obtains spatial features with the causal relationship, and enhances key features. At the same time, DCENet constructs the global convolutional Transformer (GCT) module, which utilizes the global modeling advantage of the Transformer and the local perception ability of the convolutional operation to capture the temporal features with different scales. In addition, DCENet adaptively fuses temporal and spatial features through the local differential fusion (LDF) module to achieve cross-domain feature alignment and feature alignment of emotion categories to collaboratively evolve emotion representation features with more fine-grained information. This paper conducts experiments on the SEED, SEED-IV, and MPED datasets to validate the effectiveness of DCENet. The experimental results show that the model achieves cross-subject average accuracies of 87.55 %, 73.04 %, and 27.72 % on SEED, SEED-IV, and MPED, respectively, outperforming the state-of-the-art methods. The source code is publicly available at: https://github.com/cvmdsp/DCENet .},
  archive      = {J_ESWA},
  author       = {Shuaiqi Liu and Zhihui Gu and Yuan Zhang and Yanling An and Shuhuan Zhao and Bing Li and Yudong Zhang},
  doi          = {10.1016/j.eswa.2025.129654},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129654},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trust in recommender systems: A survey. <em>ESWA</em>, <em>298</em>, 129653. (<a href='https://doi.org/10.1016/j.eswa.2025.129653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust-based recommender systems incorporate interpersonal trust relationships into the recommendation process, operating on the principle that users are more likely to accept suggestions from people they trust. Empirical studies have shown that trust-aware approaches often deliver more accurate recommendations than their trust-unaware counterparts. In this comprehensive, up-to-date survey, we analyze a variety of trust-based recommendation methods, categorize different trust inference techniques, and examine how trust is integrated into recommendation algorithms. We then organize the investigated approaches according to a clear taxonomy, explore their underlying concepts, and highlight the key challenges and open issues that remain in the field.},
  archive      = {J_ESWA},
  author       = {Imane Akdim and Loubna Mekouar and Youssef Iraqi},
  doi          = {10.1016/j.eswa.2025.129653},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129653},
  shortjournal = {Expert Syst. Appl.},
  title        = {Trust in recommender systems: A survey},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Composite human activity recognition utilizing knowledge distillation and sensor fusion focusing on resource constrained microcontrollers. <em>ESWA</em>, <em>298</em>, 129652. (<a href='https://doi.org/10.1016/j.eswa.2025.129652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a cost-effective, low-computation system for composite Human Activity Recognition (HAR) that leverages knowledge-distilled neural networks on a Microcontroller Unit (MCU) to minimize reliance on cloud processing. A key contribution of this work is the investigation of plantar pressure sensor data within a knowledge distillation framework, addressing a notable gap in the existing literature. The proposed solution centers around the ESP32-S3 DevKit C1, equipped with a dual-core 240 MHz Tensilica chip, 320 KiB of usable Static Random Access Memory (SRAM), and built-in Wi-Fi and Bluetooth. Significantly, both the teacher and the student models surpass existing state-of-the-art methods, achieving F1-scores of 99.33 %, 98.36 %, and 97.68 % respectively, in classifying a comprehensive set of 21 activities (15 composite and 6 simple). The distilled student models demonstrate remarkable efficiency, with execution times of 1.83 and 0.64 s, memory footprints of only 62 KB and 82 KB, and flash memory usage of approximately 209 KB and 127 KB, while maintaining low power consumption of 210 mW and 215 mW, respectively. Furthermore, we have developed an end-to-end prototype that integrates the ESP32-S3 with a WitMotion Inertial Measurement Unit (IMU) sensor. This system autonomously manages data acquisition, feature extraction, and inference in under 7 s with a total power consumption of approximately 295 mW.},
  archive      = {J_ESWA},
  author       = {Athar Noor Mohammad Rafee and John Clear and Jannatun Noor},
  doi          = {10.1016/j.eswa.2025.129652},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129652},
  shortjournal = {Expert Syst. Appl.},
  title        = {Composite human activity recognition utilizing knowledge distillation and sensor fusion focusing on resource constrained microcontrollers},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation. <em>ESWA</em>, <em>298</em>, 129651. (<a href='https://doi.org/10.1016/j.eswa.2025.129651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synthesis of cross-modal medical images plays a vital role in bridging diagnostic gaps between imaging modalities such as CT, MRI, and PET. This integration enables a more comprehensive evaluation of a patient’s condition, improving diagnostic accuracy and aiding clinical decision-making. However, the performance of conditional denoising diffusion probabilistic models is often hindered by pronounced structural and intensity discrepancies between modalities, as well as the inherently slow nature of the diffusion process. To address these challenges, this paper proposes Wavelet-Based Diffusion in the Difference Domain for Cross-Modality Medical Image Generation (Med-D3CG), a novel framework that transforms the synthesis process by emphasizing the difference domain. Instead of directly generating target images like conventional methods, Med-D3CG models the residual information between conditioned and target images. This strategy allows the framework to accurately capture essential structural and intensity variations between modalities, leading to more precise and realistic image synthesis. Additionally, Med-D3CG integrates the Discrete Wavelet Transform (DWT) to improve efficiency, accelerating the diffusion process while maintaining high image fidelity. On SynthRAD2023 and HMIFD datasets, state-of-the-art performance is achieved on pelvis and HMIFD using Med-D3CG , with the best Learned Perceptual Image Patch Similarity (LPIPS) and competitive FID observed on brain. Code and pretrained models are provided at https://github.com/ZgzTTTer/Med-D3CG .},
  archive      = {J_ESWA},
  author       = {Guangzhen Zhu and Midi Wan and Wenming Cao and Zhiwen Yu and Jin Hu and Bing Li and Xiaotao Fan},
  doi          = {10.1016/j.eswa.2025.129651},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129651},
  shortjournal = {Expert Syst. Appl.},
  title        = {Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search. <em>ESWA</em>, <em>298</em>, 129650. (<a href='https://doi.org/10.1016/j.eswa.2025.129650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set model(NRSM) has shown its powerful capacity in feature selection. However, a challenge still exists in describing the diversity between the attributes deeply while avoiding the impact caused by the neighborhood parameters. To address this problem, in this paper, we propose a two-stage feature selection by utilizing a three-way adaptive characteristic measure and an optimal combination search. First, we define a fitness function for applying the Stochastic Fractal Search(SFS) to design an novel adaptive neighborhood rough set model(ANRSM). To better utilize the construction characteristic of the adaptive model and reduce the computational cost, the lower and upper approximations of the SFS-based ANRSM are redefined through the fitness function. Second, based on the two approximations, we analyze the fitness function thresholds that can partition the universe into three regions and design the three-way adaptive neighborhood characteristic regions, which provide a more direct classification of samples without the inclusion and union operations. Third, we design different measures for the samples in diverse regions based on their corresponding characteristic. Afterward, a three-way adaptive characteristic measure is designed by integrating the three measures to evaluate the uncertainty of attributes. Then, we apply the measure to design a feature selection approach with greedy search. Considering that the greedy strategy may output redundant attributes, we introduce an optimal combination search approach through a novel wrapper technology to explore the potential optimal feature combinations. Compared with nine algorithms on fourteen public datasets, the experimental results show the effectiveness of our algorithm.},
  archive      = {J_ESWA},
  author       = {Bowen Lin and Duoqian Miao and Caihui Liu and Hongyun Zhang and Ruizhi Wang and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.129650},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129650},
  shortjournal = {Expert Syst. Appl.},
  title        = {Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm. <em>ESWA</em>, <em>298</em>, 129648. (<a href='https://doi.org/10.1016/j.eswa.2025.129648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering leverages prior information to improve algorithm performance and is widely valued by researchers. This paper analyzes the traditional semi-supervised fuzzy C-means (SFCM) objective function, noting that as a labeled sample’s membership degree aligns with its prior information, the impact of this information on the deviation constraint weakens. This reduces its supervisory effect on optimizing the membership partition matrix, especially with a large regularization factor. To overcome this, we propose a novel semi-supervised fuzzy C-means method based on an asymmetric deviation constraint and develop a two-level alternating iterative optimization algorithm, supported by theoretical convergence analysis using Zangwill’s theorem and the bordered Hessian matrix. To address the slow convergence and high computational cost typical of semi-supervised fuzzy clustering, we further enhance the algorithm with affinity filtering and a membership scaling scheme for improved efficiency. Experimental results demonstrate that our methods significantly outperform existing state-of-the-art techniques, advancing semi-supervised fuzzy C-means clustering.},
  archive      = {J_ESWA},
  author       = {Chengmao Wu and Jun Hou},
  doi          = {10.1016/j.eswa.2025.129648},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129648},
  shortjournal = {Expert Syst. Appl.},
  title        = {New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BayesAHDD: A new bayesian rule-based adaptive hypersphere data description for few-shot one-class classification. <em>ESWA</em>, <em>298</em>, 129647. (<a href='https://doi.org/10.1016/j.eswa.2025.129647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot one-class classification (FS-OCC) is a challenging classification problem that involves learning from a very limited number of training samples, all from a single class. Recently, several data description methods have been proposed to address the FS-OCC problem. Unlike conventional one-class classification problems, the few-shot setting requires the model to generalize to novel tasks with previously unseen positive classes. Most existing methods learn decision boundaries in the feature space without explicitly modeling the underlying data distributions, which limits the generalization ability of the learned representations. To address this issue, we propose Bayesian Rule-based Adaptive Hypersphere Data Description (BayesAHDD), a probabilistic framework that represents data with multivariate Gaussian distributions and performs classification according to the Bayes decision rule. Based on the assumption that negative samples are more dispersed in the feature space, BayesAHDD models the negative class by scaling the positive class variance vector element-wise using a learnable vector. To address the challenges of exploding gradients and numerical overflow, we impose a lower bound on the positive class variance vector and introduce a trainable parameter that integrates the class prior probability ratio with the normalization constants of the Gaussian class-conditional densities. Experimental results on both benchmark and domain-specific datasets show that BayesAHDD consistently outperforms existing baselines and state-of-the-art FS-OCC methods. Moreover, quantitative analysis demonstrates that the learned feature representations exhibit superior discriminative ability compared to those produced by previous approaches.},
  archive      = {J_ESWA},
  author       = {Yuchen Ren and Xiabi Liu and Yan Pei and Yunlong Li and Yongxia Wei},
  doi          = {10.1016/j.eswa.2025.129647},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129647},
  shortjournal = {Expert Syst. Appl.},
  title        = {BayesAHDD: A new bayesian rule-based adaptive hypersphere data description for few-shot one-class classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A network selection algorithm for space-air-ground integrated network based on location prediction model and multi-attribute decision making. <em>ESWA</em>, <em>298</em>, 129646. (<a href='https://doi.org/10.1016/j.eswa.2025.129646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an indispensable component of 5G and even the future 6G networks, the Space-Air-Ground Integrated Network (SAGIN) is envisioned to provide ubiquitous network connectivity and services by integrating satellite, aerial, and terrestrial networks. However, due to the frequent network selection of in-vehicle terminals, the user’s Quality of Service (QoS) can significantly deteriorate. To address this issue, a network selection algorithm based on terminal location prediction has been proposed. Firstly, we enhanced the Particle Swarm Optimization (PSO) algorithm to optimize the hyper-parameters of the Long Short-Term Memory (LSTM) network, thereby improving the accuracy of terminal location prediction. After constructing the network sets of the current terminal position and the predicted position, respectively, we designed a network selection judgment mechanism with a dynamically adjustable switching threshold based on Fuzzy Logic and K-Means theory. Finally, through the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) algorithm, we have achieved robust network selection in fast-moving scenarios. The simulation results show that the proposed algorithm can adaptively adjust the switching threshold and provide precise positions. Compared to existing algorithms, it can significantly reduce the number of candidate networks and the number of selections, thereby reducing the computational load and increasing the throughput of users.},
  archive      = {J_ESWA},
  author       = {Jianli Xie and Weicheng Pan and Lei Wu and Zishan Wu},
  doi          = {10.1016/j.eswa.2025.129646},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129646},
  shortjournal = {Expert Syst. Appl.},
  title        = {A network selection algorithm for space-air-ground integrated network based on location prediction model and multi-attribute decision making},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anomaly detection based on graph neural networks incorporating with domain knowledge for industrial cyber-physical systems. <em>ESWA</em>, <em>298</em>, 129645. (<a href='https://doi.org/10.1016/j.eswa.2025.129645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective anomaly detection heavily relies on accurately modeling the normal behavior of the industrial cyber-physical systems (ICPSs). Current popular data-driven black-box methods’ performance depends on the quantity and quality of data from the ICPS, rather than integrating with the intrinsic characteristics of the system, such as mass conservation and structural dependencies of industrial processes. The data used to train these models often fails to cover all operating conditions of ICPSs, resulting in a distributional mismatch between training and testing data. This limitation significantly reduces the generalization capability of trained data-driven models for detecting anomalies under unseen and unknown operational conditions. Meanwhile, constructing well-generalized behavior models using white-box mechanism models (MM)–which represent the internal behavior of controllers and physical processes using first-principles equations or physical laws, such as conservation principles and kinetic dynamics–is not always feasible in real-world industrial applications. To address this issue, this paper presents a novel anomaly detection approach employing a domain knowledge-embedded hybrid graph neural network (HGNN) that integrates control, physical, and structural characteristics of ICPSs into a data-driven modeling framework. It establishes a domain knowledge-based MM to predict the behavior of controllers and physical processes, and utilizes a HGNN model with embedded state topology and spatial distribution knowledge to compensate for the predictive error of MM, forming a hybrid model called mechanism-embedded HGNN (MEHGNN). This model can detect anomalies in unknown operational conditions by analyzing the predictive error of MEHGNN. In the experiments, MEHGNN raises the detection accuracy of GNNs from 36.6 %–82.4 % to 79.4 %–96.3 % under distribution shift scenarios, achieving the best detection performance among all compared methods.},
  archive      = {J_ESWA},
  author       = {Xin Du and Chunjie Zhou and Yu-Chu Tian and Bo Xu},
  doi          = {10.1016/j.eswa.2025.129645},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129645},
  shortjournal = {Expert Syst. Appl.},
  title        = {Anomaly detection based on graph neural networks incorporating with domain knowledge for industrial cyber-physical systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm. <em>ESWA</em>, <em>298</em>, 129644. (<a href='https://doi.org/10.1016/j.eswa.2025.129644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In screw whirling milling, the relationship between machining quality and processing parameters exhibits highly nonlinear characteristics. The traditional multiple regression models may not be able to capture this complex relationship accurately. Therefore, it is necessary to consider more flexible and applicable algorithms to establish their connections and optimize processing parameters. It can improve the accuracy and reliability of products, and provide more scientific method guidance for screw whirling milling processing. The originality of this article lies in proposing an adaptive dynamic optimization hybrid model. This model combines improved sparrow search algorithm optimized backpropagation (ISSA-BP) and non-dominated sorting genetic algorithm (NSGA-III). It can effectively adapt to dynamic data and find the optimal balance point among multiple objectives to better predict and optimize responses (cutting force, vibration, roughness, and residual compressive stress) in screw whirling milling. Firstly, a suitable network structure is identified by comparing the effects of five improvement strategies, population size, and the ratio of producers to scouters on the sparrow search algorithm. Then, an ISSA-BP prediction model is developed for four responses based on this structure. On this basis, the superiority of the established ISSA-BP model is verified by comparing prediction performance of five algorithms, and the relative prediction errors are all within 2%. The R 2 values of the models are all above 0.99, and they also perform well in indicators such as MAE (Mean Absolute Error), MSE (Mean Squared Error), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Squared Error). Then, ISSA-BP model is encapsulated and embedded into the optimization algorithm as the fitness function of NSGA-III. Finally, with the processing parameters of whirling milling as constraints, the NSGA-III algorithm is used to solve the proposed model and obtain the Pareto optimal solution set. Choosing appropriate processing parameters according to different needs in actual machining can help improve the quality and efficiency of screw machining.},
  archive      = {J_ESWA},
  author       = {Chao Liu and Hao Ding and Juanjuan Zheng and Yan He and Shaofu Huang and Junbo Tuo and Zuqing Luo and Gang Shen},
  doi          = {10.1016/j.eswa.2025.129644},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129644},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of large language models for data challenges in graphs. <em>ESWA</em>, <em>298</em>, 129643. (<a href='https://doi.org/10.1016/j.eswa.2025.129643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. While graph learning has achieved remarkable progress, real-world graph data presents a number of challenges that significantly hinder the learning process. In this survey, we focus on four fundamental data-centric challenges: (1) Incompleteness , real-world graphs have missing nodes, edges, or attributes; (2) Imbalance , the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity , graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability , graphs evolve over time in unpredictable ways. Recently, Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey focuses on how LLMs can address four fundamental data-centric challenges in graph-structured data, thereby improving the effectiveness of graph learning. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges: https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges .},
  archive      = {J_ESWA},
  author       = {Mengran Li and Pengyu Zhang and Wenbin Xing and Yijia Zheng and Klim Zaporojets and Junzhou Chen and Ronghui Zhang and Yong Zhang and Siyuan Gong and Jia Hu and Xiaolei Ma and Zhiyuan Liu and Paul Groth and Marcel Worring},
  doi          = {10.1016/j.eswa.2025.129643},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129643},
  shortjournal = {Expert Syst. Appl.},
  title        = {A survey of large language models for data challenges in graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129642. (<a href='https://doi.org/10.1016/j.eswa.2025.129642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic multi-objective optimization problems, effectively predicting and tracking the Pareto optimal front (POF) under environmental changes has been one of the core challenges. In this paper, we propose a region-aware prediction strategy based on shared points and multiple scales (RADMOEA) that combines global and local characteristics, aiming to enhance the algorithm’s ability to sense and adapt to POF. Firstly, the center-point movement strategy is used to move the non-dominated solution set from the previous moment to obtain the non-dominated solution set after the movement. The actual non-dominated solution set at the current moment and the non-dominated solution set after the movement share points in the objective space, and these shared points divide the non-dominated solution set at the current moment into several subregions. Within each region, all individuals are appropriately rescaled, and a local coordinate system is established. Then, within the local coordinate system, each individual is associated with the nearest post-movement non-dominated individual. Finally, new populations adapted to environmental changes are generated by combining centroid movement directions, Gaussian perturbations, and multi-scale individual association relationships. The proposed strategy is compared with six advanced algorithms, and the experimental results demonstrate that RADMOEA is effective in tracking the POF under dynamic environments.},
  archive      = {J_ESWA},
  author       = {Yaru Hu and Sitong Wang and Junwei Ou and Zhenlin Mei and Juan Zou and Shengxiang Yang},
  doi          = {10.1016/j.eswa.2025.129642},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129642},
  shortjournal = {Expert Syst. Appl.},
  title        = {Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion. <em>ESWA</em>, <em>298</em>, 129641. (<a href='https://doi.org/10.1016/j.eswa.2025.129641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passive microwave remote sensing plays a vital role in Earth observation, with applications in soil moisture, ocean salinity, and atmospheric monitoring. However, improving spatial resolution at low frequencies remains challenging. Recently, combining multiple small antenna arrays into a larger one has emerged as a technological approach to enhance spatial resolution. Nevertheless, aperture synthetic radiometers formed by such combinations usually consist of non-uniform antenna arrays (one-dimensional, two-dimensional, or three-dimensional). Compared with regular antenna arrays, they complicate the inversion of brightness temperature (BT) images. This paper proposes NASRT, a transformer-based inversion method designed for multi-dimensional non-uniform ASRs. The network extracts and fuses spectral and UVW spatial distribution features from the visibility function (VF), and introduces a learnable position weight matrix during training to capture spatial information of the non-uniform array. Through supervised learning, NASRT effectively maps the VF to BT images. Simulations across 1-D, 2-D, and 3-D NASR scenes demonstrate that NASRT achieves higher accuracy and stability than traditional methods. In a 1-D NASR indoor experiment, the proposed method also shows improved inversion accuracy and lower sidelobes, validating its effectiveness.},
  archive      = {J_ESWA},
  author       = {Jian Dong and Jiaxin Li and Chengwang Xiao and Rigeng Wu and Haofeng Dou and Wenjing Wang and Yuanchao Wu and Liangbing Chen},
  doi          = {10.1016/j.eswa.2025.129641},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129641},
  shortjournal = {Expert Syst. Appl.},
  title        = {A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OceanAgent: A small-scale multi-modal assistant for ocean exploration. <em>ESWA</em>, <em>298</em>, 129640. (<a href='https://doi.org/10.1016/j.eswa.2025.129640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of key information and the subsequent generation of actionable knowledge from multimodal data are critical for ocean exploration. Traditional knowledge generation methods rely heavily on expert experience and are labor-intensive. Recently, Large Multimodal Models (LMMs) have shown exceptional capabilities for knowledge generation from multimodal data in many complex tasks. These models also have potential to assist knowledge mining in ocean exploration. However, two major challenges faced by the LMMs when used in ocean exploration include the scarcity of ocean instruction-following data and the degradation of underwater visual environments. In this paper, a small-scale LMM for ocean exploration, named the OceanAgent, is designed. First, a swarm-intelligence-based leaderless multi-agent collaboration framework is proposed to generate visual instruction-following data. Subsequently, we present a visual-language connector to simultaneously extract multi-scale features. It is formed by integrating a multi-scale residual network with a multi-layer perceptron, which can enhance the model’s performance on severely low-quality images. Experiments show that the proposed method for constructing visual instruction-following datasets improves both the textual quality and visual dialogue. When severely degraded ocean visual data are processed using the trained OceanAgent, the image description accuracy and image comprehension are improved by 23.6 % and 21.6 %, respectively, compared to existing models. Additionally, the model demonstrates superior domain expertise, with a 95.7 % win rate in dialogue quality assessments.},
  archive      = {J_ESWA},
  author       = {Yun Xu and Yue Liu and Junpeng Shang and Jianmin Lin and Dongfang Ma},
  doi          = {10.1016/j.eswa.2025.129640},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129640},
  shortjournal = {Expert Syst. Appl.},
  title        = {OceanAgent: A small-scale multi-modal assistant for ocean exploration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs. <em>ESWA</em>, <em>298</em>, 129639. (<a href='https://doi.org/10.1016/j.eswa.2025.129639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection(GAD) plays a critical role in fields such as fraud detection and network security. Although existing graph anomaly detection methods have achieved promising performance, most graph neural networks (GNNs) rely on the homophily assumption, which presumes that connected nodes share similar labels. However, real-world graphs frequently exhibit pronounced heterophily. Owing to class imbalance, normal nodes tend to have lower heterophily while anomalous nodes display higher heterophily. Furthermore, feature inconsistency induced by node camouflage exacerbates the detection challenge, rendering many existing approaches ineffective. To overcome these limitations, we propose SPS-GAD, a spectral-spatial graph structure learning framework specifically designed for detecting anomalous nodes in heterophilic graphs. First, to alleviate the feature inconsistency resulting from node camouflage, we develop a node reconstruction module that learns intermediate node representations to mitigate camouflage-induced bias, and applies spectral filters to extract the graph’s inherent structural features. Second, to address the heterophily disparities arising from class imbalance, we introduce a subgraph-type-aware spectral filtering module that leverages edge scores generated by an edge partitioner to segregate the graph into homophilic, ambiguous, and heterophilic subgraphs. Distinct spectral filters are subsequently applied to capture features across various frequency bands. Additionally, we integrate a neighbor-type-aware graph attention module that employs edge scores within an attention mechanism to guide the feature aggregation process, thereby enhancing spatial representation learning. Experimental evaluations on six real-world datasets reveal that SPS-GAD significantly outperforms all baseline methods in key metrics such as F1-Macro and AUC, thereby confirming its effectiveness in graph anomaly detection. The source code is publicly available at https://github.com/cozy24/SPS-GAD .},
  archive      = {J_ESWA},
  author       = {Chen Zhu and Yaying Zhang},
  doi          = {10.1016/j.eswa.2025.129639},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129639},
  shortjournal = {Expert Syst. Appl.},
  title        = {SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pareto optimization of two-agent scheduling on parallel batch machines. <em>ESWA</em>, <em>298</em>, 129637. (<a href='https://doi.org/10.1016/j.eswa.2025.129637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a Pareto optimization problem of scheduling jobs of two competing agents on parallel batch machines. The jobs have equal processing times and non-identical job sizes. The objective is to find Pareto optimality and the corresponding schedules for minimizing both agents’ makespans. We analyze and identify an approximate Pareto region with a guarantee of 2-approximate Pareto optimal. We propose an integrated algorithm to find the approximate Pareto optimal points. Our computational study shows that the proposed algorithm outperforms the widely used non-dominated sorting genetic algorithm (NSGA-II), and that the obtained approximate Pareto optimal front is very close to the Pareto optimal front.},
  archive      = {J_ESWA},
  author       = {Cui-Lin Zhang and Guo-Qiang Fan},
  doi          = {10.1016/j.eswa.2025.129637},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129637},
  shortjournal = {Expert Syst. Appl.},
  title        = {Pareto optimization of two-agent scheduling on parallel batch machines},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach. <em>ESWA</em>, <em>298</em>, 129636. (<a href='https://doi.org/10.1016/j.eswa.2025.129636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the dual pressure of explosive growth in cross-border e-commerce demand and increasing timeliness requirements from overseas customers, cross-border logistics service providers are compelled to establish logistics facilities and deploy fleets across multiple regions to ensure rapid response. However, during freight transportation, the lack of effective management over these complex and heterogeneous fleets—particularly in terms of fleet composition and routing decisions—has led to high transportation costs and low operational efficiency. This study is grounded in the practical operational context of cross-border logistics in the Guangdong–Hong Kong–Macau Greater Bay Area and models a multi-level, multi-node cross-border transportation network. To minimize the overall operational cost, the problem is addressed from two interrelated decision-making perspectives: fleet composition at the strategic level and routing planning at the operational level. Thus, a bi-level programming model is proposed to systematically capture the hierarchical structure and the logical relationship between these two decision layers. Furthermore, the model incorporates cost differences among trucks with different functional capabilities to reflect the significant disparity in logistics cost structures between domestic and overseas operations. To address the above multi-objective mixed-integer linear programming (MILP) problem, a tailored Non-dominated Sorting Genetic Algorithm II (MNSGA-II) is developed. Several key components of the algorithm are modified and enhanced to improve its search efficiency and solution quality in handling the problem’s complexity. Comparative experiments against classical algorithms demonstrate the superior solution quality and robustness of the proposed approach. The influence of cost differentials on composition and scheduling decisions is further analyzed, providing practical insights for the strategic planning of cross-border logistics systems.},
  archive      = {J_ESWA},
  author       = {Zhi Tang and Ting Qu and Yanghua Pan and George Q. Huang},
  doi          = {10.1016/j.eswa.2025.129636},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129636},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems. <em>ESWA</em>, <em>298</em>, 129635. (<a href='https://doi.org/10.1016/j.eswa.2025.129635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) has long been a fundamental challenge in the field of optimization. Due to the existence of multiple roots, such problems often exhibit complex and multimodal characteristics. Although numerous differential evolution-based algorithms have been developed to solve NESs, most of them employ only a single mutation operator, which is not adaptable to different problem scenarios. To this end, a diversity-based niching differential evolution with neighborhood competition (DNDE) is proposed to solve NESs. First, a control mechanism that takes into account population diversity and the evolutionary stage is proposed to adaptively assign appropriate mutation strategies to each subpopulation (niche), thereby enhancing the efficiency of root-finding. Second, a neighborhood priority competition mechanism is proposed to reduce cross-peak competition between populations, which ensures local convergence while improving global convergence. Finally, a reinitialization strategy based on opposition learning is introduced to guide the population toward more promising areas of the search space. Experimental results on 18 complex NESs and two real-world engineering problems show that DNDE outperforms many advanced algorithms in both root rate and success rate, demonstrating its effectiveness and value in practical applications.},
  archive      = {J_ESWA},
  author       = {Jianwei Li and Xinchao Zhao and Lingyu Wu and Yizhan Wu and Lingjuan Ye},
  doi          = {10.1016/j.eswa.2025.129635},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129635},
  shortjournal = {Expert Syst. Appl.},
  title        = {A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGNet: Texture-enhanced guidance network for RGB-D salient object detection. <em>ESWA</em>, <em>298</em>, 129633. (<a href='https://doi.org/10.1016/j.eswa.2025.129633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection achieves salient region localization in complex scenes by fusing RGB images and depth images. Existing methods typically employ two-stream networks to extract features separately followed by cross-modal fusion. However, differences between heterogeneous modalities can easily lead to feature degradation during cross-modal fusion, while the inherent noise interference in low-quality depth maps may generate cumulative effects during multi-stage propagation, severely constraining detection performance. To address these challenges, this paper proposes a texture-enhanced guided network. The core innovations lie in three aspects: during the feature encoding stage, a texture-enhanced module is constructed to utilize high-frequency texture information from RGB images through attention mechanisms for hierarchical optimization of depth features; in the feature fusion stage, a dual-path adaptive interaction module is designed to establish cross-modal semantic correlations via channel-spatial cooperative driving mechanisms, effectively suppressing redundant feature interference; for the decoding reconstruction stage, a dynamic hierarchical guidance mechanism is proposed to drive progressive calibration of low-level spatial details by high-level semantic features through learnable cross-scale transformation modules. Extensive experiments conducted on five benchmark datasets demonstrate that our method achieves competitive performance compared to other approaches.},
  archive      = {J_ESWA},
  author       = {Xiaogang Song and Hexiang Huang and Qin Zhao and Xinwei Guo and Xinhong Hei},
  doi          = {10.1016/j.eswa.2025.129633},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129633},
  shortjournal = {Expert Syst. Appl.},
  title        = {TGNet: Texture-enhanced guidance network for RGB-D salient object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling. <em>ESWA</em>, <em>298</em>, 129632. (<a href='https://doi.org/10.1016/j.eswa.2025.129632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake, as a generative technology, has opened up new avenues for the development of the film, television, and art industries. However, its abusive use has triggered serious social security threats, such as infringement of portrait rights and the spread of misinformation, which has drawn widespread attention to research on deepfake detection techniques. Current deep learning-based face forgery detection methods face critical challenges: 1) insufficient focus on common forgery traces leads to poor generalization performance on datasets generated by unknown forgery methods; 2) traditional spatio-temporal feature fusion mechanisms struggle to balance the representational weights of spatial details and temporal dynamics, and exhibit inadequate robustness against post-processing operations like compression and cropping. To address these issues, this paper first designs a phase consistency edge artifact mining module is designed to extract common forgery traces from edge textures by leveraging the deep-phase information of images, significantly enhancing the model’s generalization ability. Second, a multi-frame synthesis strategy is designed to effectively integrate spatial and temporal features while balancing the network’s attention to these two feature domains. Third, a visual state-space model based on 3D scanning is designed, which for the first time employs the Mamba model to analyze spatio-temporal forgery patterns, notably improving the robustness of the model against unknown perturbations. Experimental results on standard benchmarks–FaceForensics++, Celeb-DFv2, WildDeepfake and DFDC(Preview)–demonstrate that the proposed method achieves state-of-the-art performance in three core dimensions: detection accuracy, cross-dataset generalization, and robustness against perturbations.},
  archive      = {J_ESWA},
  author       = {Zhong Chen and Siyang Wang and Zuxi Wang},
  doi          = {10.1016/j.eswa.2025.129632},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129632},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LSTT: Long short-term feature enhancement transformer for video small object detection. <em>ESWA</em>, <em>298</em>, 129631. (<a href='https://doi.org/10.1016/j.eswa.2025.129631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging temporal information is crucial for small object detection in videos. Existing methods typically incorporate long-term or short-term temporal information uniformly, neglecting distinct cues from different frames that are essential for small object detection. In this paper, we propose LSTT, an end-to-end multi-frame fusion network that concurrently extracts global scene context from long-term frames and fine-grained appearance and motion cues from short-term frames. First, we introduce a progressive spatiotemporal sampling module that sparsely samples long-range frames and densely samples short-range frames. Second, we design a spatiotemporal alignment encoder module to extract frame-level temporal and spatial pixel features. Finally, We propose a long short-term feature aggregation module that employs a dynamic query generator to derive adaptive queries by implicitly modeling motion relationships among short-term frames, and guides a cascaded fusion of aggregated features from long-term, short-term, and current frames to fuse temporal information. Compared to state-of-the-art methods, our LSTT achieves absolute gains of 1.4 % and 2.1 % in detection precision on VisDrone-VID and UAVDT datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jinsheng Xiao and Wenbo Liu and Ruidi Chen and Yuchen Yan and Wei Yang},
  doi          = {10.1016/j.eswa.2025.129631},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129631},
  shortjournal = {Expert Syst. Appl.},
  title        = {LSTT: Long short-term feature enhancement transformer for video small object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scale-invariant information bottleneck for domain generalization. <em>ESWA</em>, <em>298</em>, 129628. (<a href='https://doi.org/10.1016/j.eswa.2025.129628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One significant challenge in deep learning is the inability to effectively generalize to new data whose distribution differs from that of the training data. Hence, domain generalization has received increasing attention in related fields. Classical methods aim to identify an invariant predictor that can recognize invariant representations across all the training domains. However, these methods limit the model to rely solely on invariant representations, which hinders the learning of important finer details. To address this challenge, we propose a Scale-invariant Information Bottleneck (SIB) method to identify both invariant and scale-invariant features. We subsequently introduce a tractable loss function derived from the variational analysis. This novel method captures more detailed information, including fine textures and unique characteristics, while also eliminating irrelevant or spurious representations by using information bottleneck. Finally, extensive experiments conducted on Rotated MNIST, Colored MNIST, Colored Fashion-MNIST, PACS, Office-Home and Camelyon17-WILDS validate the effectiveness of our SIB method in addressing the domain generalization problems. Notably, our approach outperforms 14 existing methods with an average improvement of 4.74 %. More significantly, it surpasses 6 recent, related methods by an average of 2.21 %. Furthermore, we demonstrate the superiority of our method through the analysis of hidden feature maps and representations.},
  archive      = {J_ESWA},
  author       = {Mengyao Li and Jiangshe Zhang and Chunxia Zhang and Junmin Liu and Lizhen Ji},
  doi          = {10.1016/j.eswa.2025.129628},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129628},
  shortjournal = {Expert Syst. Appl.},
  title        = {Scale-invariant information bottleneck for domain generalization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading. <em>ESWA</em>, <em>298</em>, 129627. (<a href='https://doi.org/10.1016/j.eswa.2025.129627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific and rational prices are determinant for the success of transfer of development rights (TDR). Nevertheless, previous studies largely overlook the multifaceted impacts of risks on pricing, hampering market participation and value revelation. This is especially relevant in the context of China’s inter-provincial construction land quota trading due to its broader scope and dynamic complexities. This study addresses this gap by proposing an integrated decision-making framework to identify TDR risk factors and determine the optimal pricing for TDR under risk sharing. Results show that among 28 identified risk factors across the trading lifecycle, pre-transaction (remediation application and remediation acceptance) risk factors exhibit lower weights (0.017 and 0.218) but demand greater responsibility from quota-sending governments (80.5% and 73.0%); quota transfer risk factors hold the highest weight (0.306), with nearly balanced responsibility sharing between trading parties; while post-transaction (remediation acceptance and post monitoring) risk factors (weighted at 0.215 and 0.218) should be borne mainly by quota-receiving governments (64.1% and 60.9%). A paradigmatic trading case study between Muli and Jiashan Counties empirically reveals that risk factors elevate the optimal price to 621171.89 yuan/mu—24.23% above the current national standard price—by increasing costs, reducing profits, decreasing the supply–demand ratio, and complicating ecological compensation. These findings underscore the importance of risk responsibility management and risk-based pricing mechanisms.},
  archive      = {J_ESWA},
  author       = {Jia-He Zhou and Yu-Jia Wei and Yu-Ming Zhu and Hong-Li Lin},
  doi          = {10.1016/j.eswa.2025.129627},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129627},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent urban on-street parking space management for autonomous vehicles. <em>ESWA</em>, <em>298</em>, 129626. (<a href='https://doi.org/10.1016/j.eswa.2025.129626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curbside lanes are valuable spatial assets, with on-street parking, driving, and other travel modes competing for the space. Autonomous vehicle (AV) transport is expected to park at the curbside for diverse purposes, raising conflicts between driving and parking in the city centre. This study presents a framework to determine on-street parking configurations under different traffic flow and parking supply scenarios for the downtown region. The main contribution stems from solving the macro-level parking configuration problem using customised metaheuristics while considering microscopic AV operations. We tested the framework using a road network comprising a downtown central business district and adjacent urban areas. Among the considered metaheuristics, the discrete particle swarm optimisation outperformed the genetic algorithm in minimising network-level travel delays but at the cost of higher computational time. Three main empirical findings are derived. First , parking lanes are more likely to be assigned to edges in downtown areas or those with lower traffic and driving speeds. Second , high parking supply negatively affects the macroscopic fundamental diagram by increasing congestion and reducing flow efficiency, but such an effect diminishes in congested networks. Third , there exists an optimal parking supply level (40 % in the case study) for most flow rate conditions that can help reduce congestion. The proposed framework was validated through a case study in Midtown Manhattan, New York City. This study provides valuable insights for urban and transportation agencies to manage on-street parking lane assignments to balance parking and driving demands in the AV transport era. The approach has broader applicability as it is transferable to human-driven vehicles and mixed autonomy scenarios.},
  archive      = {J_ESWA},
  author       = {Qiming Ye and Prateek Bansal and Yuxiang Feng and Simon Hu and Panagiotis Angeloudis},
  doi          = {10.1016/j.eswa.2025.129626},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129626},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent urban on-street parking space management for autonomous vehicles},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-session interest extraction for recommendation. <em>ESWA</em>, <em>298</em>, 129625. (<a href='https://doi.org/10.1016/j.eswa.2025.129625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, due to device privacy restrictions, sometimes we can only obtain anonymous users’ interaction behavior within a single session. This type of recommendation is called session-based recommendation. Modeling users’ interest based on session data is one of the core issues in session-based recommendation. However, most existing methods only model users’ interest within individual sessions, neglecting information propagation across sessions. This paper addresses this challenge by designing a contrastive learning module based on clustering to model inter-session information propagation. Specifically, in addition to propagating information within sessions using hypergraph convolution, a cluster algorithm is applied to group all nodes across sessions. Then a contrastive learning loss is designed based on the clustering results to facilitate information propagation across sessions, thereby explicitly modeling the semantic similarity of similar items across different sessions. We call our model Clustering Hypergraph Neural Network (CluHNN). CluHNN explicitly learns the correlation between similar items across different sessions, improving the quality of item representations and, consequently, yielding better interest representations through cross-session information propagation. Experimental results on two real-world datasets show the effectiveness of the proposed CluHNN. For example, in terms of MRR@20, CluHNN achieves significant improvements of 1.3 % and 2.0 % relative gains over the strongest baseline, respectively.},
  archive      = {J_ESWA},
  author       = {Jin Jin and Chaoqun Li and Liangxiao Jiang},
  doi          = {10.1016/j.eswa.2025.129625},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129625},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-session interest extraction for recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images. <em>ESWA</em>, <em>298</em>, 129624. (<a href='https://doi.org/10.1016/j.eswa.2025.129624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a burgeoning theme in optical remote sensing image (ORSI) analysis, salient object detection (SOD) plays a vital role in traffic monitoring, agriculture, disaster management, and other fields. However, the existing ORSI-SOD methods are all single-modal (RGB images primarily), which suffer from performance drop when facing complex scenes (e.g., intricate backgrounds, low contrast scenes, and similar objects). To address this challenge, we introduce estimated depth map to complement RGB image in ORSI-SOD for the first time, which provides 3D geometric cues to improve detection accuracy in complex scenes, thus advancing ORSI-SOD from single-modal to multi-modal. Furthermore, we design a novel pretraining framework: multi-modal reconstructed image pretraining (MMRIP) to pretrain SOD model in multi-modal ORSI-SOD. MMRIP initially utilizes a masked autoencoder (MAE) to restore the masked RGB image; subsequently, it feeds the restored RGB image and clean depth map to the SOD model to generate the saliency map, which can help SOD model more effectively integrate cross modal information and extract better feature. Besides, we present a simple RGB-D SOD model, namely SimSOD, which is pretrained by MMRIP for ORSI-SOD. SimSOD has two major components: DFormer (encoder) and MLP head (decoder). Specifically, we first input RGB image and depth data into the encoder to generate four multi-scale features, then use the decoder to fuse these features and yield the prediction result. Without bells and whistles, our proposed method outperforms the state-of-the-art methods on three public ORSI-SOD datasets. The code can be accessed at: https://github.com/Voruarn/MMRIP .},
  archive      = {J_ESWA},
  author       = {Yuxiang Fu and Wei Fang},
  doi          = {10.1016/j.eswa.2025.129624},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129624},
  shortjournal = {Expert Syst. Appl.},
  title        = {Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An approach for linking dynamic network information models based on ontology matching. <em>ESWA</em>, <em>298</em>, 129622. (<a href='https://doi.org/10.1016/j.eswa.2025.129622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic network information models are typically heterogeneous and isolated systems that impede effective interoperability, significantly hindering end-to-end service integration and data sharing across network segments. To address this challenge, we propose a new approach for linking heterogeneous dynamic network models based on ontology matching, which can be applied in various domains utilizing dynamic networks. For ontologies matching we use different existing duplicate detection algorithms but we reduce the computational complexity of ontology matching due to splitting initial set of matched entities into a number of subsets using domain knowledge. Using telecommunications as case study, we represent operator networks as knowledge graphs and match them with standardized model ontologies using business process context to create an Extended Operator Network Ontology. Our approach ensures linking of dynamic network models used in operators information systems that is of primary importance for implementing complex business processes, and providing integrated services while maintaining existing models.},
  archive      = {J_ESWA},
  author       = {Tianxing Man and Igor Kulikov and Jiafeng Yang and Nataly Zhukova},
  doi          = {10.1016/j.eswa.2025.129622},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129622},
  shortjournal = {Expert Syst. Appl.},
  title        = {An approach for linking dynamic network information models based on ontology matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem. <em>ESWA</em>, <em>298</em>, 129621. (<a href='https://doi.org/10.1016/j.eswa.2025.129621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional irregular layout problem, which involves placing convex or non-convex components within a confined boundary without overlaps, is NP-complete and widely encountered in industrial applications such as glass cutting, garment manufacturing, and packaging. To overcome the limitations of existing methods in computational efficiency and material utilization, we propose a new hybrid algorithm IDE-V-NFP-MIP: (1) An improved differential evolution (IDE) algorithm combines the memory mechanism to guide the crossover and mutation operations; (2) A vector No-Fit Polygon (V-NFP) algorithm effectively handles complex geometric constraints, including voids and degradation; (3) A mixed-integer programming (MIP) model ensures accurate layout and non-overlapping constraints. Experimental results demonstrate superior performance: IDE ranked first in CEC2022 Friedman tests, while practical applications show 22.10% reduction in board length and 41.47% improvement in filling rate. The framework successfully handles real-world garment cutting applications and large-scale problems up to 1,280 polygons, demonstrating significant improvements in both computational efficiency and solution quality for industrial layout optimization. The source code for the algorithm is available at https://github.com/xhj-6/IDE-V-NFP-MIP .},
  archive      = {J_ESWA},
  author       = {Huijie Xu and Qifang Luo and Yongquan Zhou},
  doi          = {10.1016/j.eswa.2025.129621},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129621},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach. <em>ESWA</em>, <em>298</em>, 129620. (<a href='https://doi.org/10.1016/j.eswa.2025.129620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of smart grid security, the precise identification of False Data Injection Attack (FDIA) is crucial for ensuring the stable operation of power systems. Existing approaches for handling measurement data often overlook the correlation between local time–frequency variations caused by FDIA nodes and global spatial information in analyzing measurement data, leading to inaccurate localization. To address this issue, we propose a novel approach: a multilevel wavelet spatio-temporal map embedded FDIA localization method. Initially, a multi-resolution time–frequency signal decomposition model is utilized to separate the time–frequency mutation signals induced by FDIA from the measurement data using fast wavelet transform. Subsequently, a multi-channel time–frequency feature extraction technique is developed to capture the mutation characteristics of FDIA in time–frequency signals. This involves extracting detailed features of the time–frequency signals pre and post-attack via a multi-channel convolution operation encompassing “temporal-local-global” aspects. Finally, we propose an FDIA localization model based on multi-level graph wavelet embedding. The model embeds spatio-temporal information into time–frequency features via graph wavelet convolution and builds a spatio-temporal dependency map through multi-level neighborhood sampling. To mitigate measurement loss and noise, graph smoothing regularization and graph dropout are introduced during training. A graph attention mechanism further captures spatio-temporal dependencies among nodes, enabling accurate FDIA localization. Experimental results verify the effectiveness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhaoyang Qu and Feng Liang and Nan Qu and Tao Jiang and Xiaoyu Xu},
  doi          = {10.1016/j.eswa.2025.129620},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129620},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management. <em>ESWA</em>, <em>298</em>, 129619. (<a href='https://doi.org/10.1016/j.eswa.2025.129619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the integration of the 5G-enabled Internet of Things has revolutionized through high-speed data transmission, ultra-low latency, and interconnectivity of massive devices. However, the proliferation of 5G-enabled Internet of Things introduces major challenges, such as energy inefficiency and unreliable data delivery in the resource constrained Internet of Things devices. This research proposes a novel Q-Learning-based optimization framework tailored to address these challenges by integrating Radio Frequency energy harvesting, adaptive beamforming, and dynamic resource allocation within the massive Multiple-Input-Multiple-Output system. The proposed model utilizes reinforcement learning to manage the network resources including modulation schemes, beamforming, and energy allocation. By modeling the optimization problem as a Markov Decision Process, the proposed framework dynamically adapts to real-time network conditions to enhance energy efficiency, reliable data delivery, and throughput. The experimental validation demonstrates that the Q-Learning-based strategy effectively optimizes the energy efficiency as well as data transmission and achieves a higher energy efficiency of 98.87 %, higher packet delivery ratio of 98.85 %, lower latency of 1.5 ms, and higher throughput of 200Mbps compared to existing methodologies. This result indicates that the proposed Q-Learning-based framework has the potential to enhance the sustainability and reliability of the 5G-enabled Internet of Things.},
  archive      = {J_ESWA},
  author       = {Bavethra Murthy and Palani Uthirapathy},
  doi          = {10.1016/j.eswa.2025.129619},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129619},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-behavioral recommendation algorithm based on decoupled graph convolution. <em>ESWA</em>, <em>298</em>, 129618. (<a href='https://doi.org/10.1016/j.eswa.2025.129618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation models primarily rely on display feedback and typically utilize a single type of user-item interaction data, which often results in significant data sparsity issues. In contrast, multi-behavioral recommendation models leverage various behaviors such as browsing, favoriting, and other interactions. These additional behaviors help improve the prediction of user-item interactions. Existing multi-behavioral recommendation methods often overlook the potential factors influencing multi-behavioral interactions and the differences between various behavior types. In this study, we introduce a multi-behavioral recommendation algorithm utilizing decoupled graph convolution (MBR-DGC), which effectively mitigates the data sparsity of the target behaviors and improves recommender system performance by capturing the differences between the semantics of different behaviors. Specifically, we construct multiple non-overlapping independent isomorphic graphs and separate potential factors affecting the interactions among users, items, and behaviors using decoupled convolutional networks to reconstruct the node features of users in different behaviors. Afterwards, multi-behavioral features of users are aggregated using contrastive learning to achieve personalized multi-behavioral information aggregation. Experimental results on multiple datasets show that MBR-DGC effectively leverages multi-behavioral data, significantly enhancing recommendation performance compared to other state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xu Yu and Pengju Ding and Jie Yu and Junyu Lin and Lei Guo and Guanfeng Liu and Liang Xi},
  doi          = {10.1016/j.eswa.2025.129618},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129618},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-behavioral recommendation algorithm based on decoupled graph convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy. <em>ESWA</em>, <em>298</em>, 129617. (<a href='https://doi.org/10.1016/j.eswa.2025.129617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swarm intelligence aggregation system represents a key capability in current-generation UAV swarm, demonstrating robust collective intelligence. Currently, leveraging Multi-Agent Deep Reinforcement Learning (MADRL) offers a promising approach for building UAV swarm intelligence aggregation systems. However, the MADRL methods are difficult to cope with the challenge of exponential increase in computation when facing the collaboration problem of large-scale swarms, and the agents also have the problem of partial observability of the environment. This paper proposes an Information Aggregation Decision Method for UAV swarm based on Joint Communication and Proximal Strategy (IADM-JCPS). This method designs a communication information aggregation (CIA) network to enable UAVs to gather observation information from neighbor UAVs, and uses the attention mechanism to screen important information. Then, the aggregated information is used as part of the input of the policy network to increase the information diversity of the decision-making process. Finally, the gradient clipping mechanism is used to trim the policy gradient to enhance the stability of the training process. A UAV swarm multi-target tracking (MTT) mission scenario is designed to verify the effectiveness of the proposed IADM-JCPS algorithm. Experimental results show that the proposed algorithm is superior to the baseline algorithm in terms of task collaboration and scalability.},
  archive      = {J_ESWA},
  author       = {Zhaotian Wei and Ruixuan Wei},
  doi          = {10.1016/j.eswa.2025.129617},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129617},
  shortjournal = {Expert Syst. Appl.},
  title        = {An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-based trajectory planning for AGVs in dynamic environment. <em>ESWA</em>, <em>298</em>, 129616. (<a href='https://doi.org/10.1016/j.eswa.2025.129616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a learning-based framework for rapid trajectory planning of autonomous ground vehicles (AGVs) in dynamic environments. The approach integrates optimization techniques with deep learning to design a real-time planner capable of generating kinematically feasible trajectories. A continuous iterative method is first developed for dataset construction, enabling efficient generation of optimal trajectory sets. Based on this dataset, a neural network is trained to learn the mapping between AGV states and actions while capturing their temporal dependencies. During online planning, the trained model produces decision actions from the current state and sensor feedback, enabling real-time planning of safe and feasible trajectories. Results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_ESWA},
  author       = {Runda Zhang and Zhida Xing and Senchun Chai and Yuanqing Xia and Runqi Chai},
  doi          = {10.1016/j.eswa.2025.129616},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129616},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning-based trajectory planning for AGVs in dynamic environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Model-agnostic post-hoc explainability for recommender systems. <em>ESWA</em>, <em>298</em>, 129608. (<a href='https://doi.org/10.1016/j.eswa.2025.129608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems often benefit from complex feature embeddings and deep learning algorithms, which deliver sophisticated recommendations that enhance user experience, engagement, and revenue. However, these methods frequently reduce the interpretability and transparency of the system. In this research, we develop a systematic application, adaptation, and evaluation of deletion diagnostics in the recommender setting. The method compares the performance of a model to that of a similar model trained without a specific user or item, allowing us to quantify how that observation influences the recommender, either positively or negatively. To demonstrate its model-agnostic nature, the proposal is applied to both Neural Collaborative Filtering (NCF), a widely used deep learning-based recommender, and Singular Value Decomposition (SVD), a classical collaborative filtering technique. Experiments on the MovieLens and Amazon Reviews datasets provide insights into model behavior and highlight the generality of the approach across different recommendation paradigms.},
  archive      = {J_ESWA},
  author       = {Irina Arévalo and Jose L. Salmeron},
  doi          = {10.1016/j.eswa.2025.129608},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129608},
  shortjournal = {Expert Syst. Appl.},
  title        = {Model-agnostic post-hoc explainability for recommender systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS. <em>ESWA</em>, <em>298</em>, 129607. (<a href='https://doi.org/10.1016/j.eswa.2025.129607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable assessment of precipitation is crucial for incorporating meteorological and hydrological research into industrial and agricultural applications. Accurately estimating precipitation is a challenging task. In addressing this problem, we propose to develop AERO-Net, a novel deep learning framework designed to correct spatial, temporal, and amplitude biases in WRF-ROMS precipitation data. The integration of the Weather Research and Forecasting (WRF) model with the Regional Ocean Modeling System (ROMS) makes it a valuable tool for precipitation forecasting. AERO-Net incorporates autoencoders (AEs) for handling fluctuation and generalizing latent space representations, a latent module (LM) for transforming WRF-ROMS data into bias-corrected representations, a residual module (RM) for error minimization via boost, and a calibration module (CM) for improving near-zero precipitation. Empirical results show that AERO-Net achieves a balanced error reduction across precipitation cohorts grouped by intensity, reducing the macro-averaged root mean square error (macro RMSE) by 3.6 mm/day and the macro-averaged mean absolute deviation (macro MAD) by 0.68 mm/day compared to the original WRF-ROMS. AERO-Net is seen to improve the correlation coefficient (CC) by 26.32 %, increasing it from 0.38 to 0.48, in comparison to the original WRF-ROMS. These findings underscore its potential as an effective solution for enhancing precipitation estimates in high-resolution modeling systems.},
  archive      = {J_ESWA},
  author       = {Passin Pornvoraphat and Kanoksri Sarinnapakorn and Ken-Ichi Fukui and Peerapon Vateekul},
  doi          = {10.1016/j.eswa.2025.129607},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129607},
  shortjournal = {Expert Syst. Appl.},
  title        = {AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography. <em>ESWA</em>, <em>298</em>, 129606. (<a href='https://doi.org/10.1016/j.eswa.2025.129606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are now achieving strong results for segmentation tasks, and the standard metric for evaluating methods is the Intersection over Union (IOU). However, we show in this paper that IOU is not efficient in evaluating the quality of segmentation for electron tomography (ET) images of zeolites. We perform a physics-oriented evaluation to ensure that the segmentation results yield coherent physical measures. We also formalize Mixed Supervised / Self-Supervised Contrastive Learning Segmentation (M3S-CLS), a semi-supervised approach using a contrastive learning approach that uses expert annotations to train the neural network model. A detailed comparison of this method with a standard cross-entropy-based model is provided. In addition, we publish a database of five fully segmented ET volumes along with corresponding baseline results. The code and the database is available at http://gitlab.univ-st-etienne.fr/labhc-iscv/M3S-CLS .},
  archive      = {J_ESWA},
  author       = {Cyril Li and Christophe Ducottet and Maxime Moreaud and Sylvain Desroziers and Valentina Girelli Consolaro and Virgile Rouchon and Ovidiu Ersen},
  doi          = {10.1016/j.eswa.2025.129606},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129606},
  shortjournal = {Expert Syst. Appl.},
  title        = {Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy. <em>ESWA</em>, <em>298</em>, 129605. (<a href='https://doi.org/10.1016/j.eswa.2025.129605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged objects often closely resemble their surroundings, causing standard RGB images to be confounded by background, texture, and color variations. This often leads to incomplete or absent target segmentation, reducing overall accuracy. To address this issue, we present a Deep Surrounding-Awareness Mirror Network (DSANet) for camouflaged object detection, leveraging depth information to expose objects incongruent with their environment, thus improving localization accuracy. First, a Convolutional Spatial Gating module processes batched RGB and depth inputs, suppressing extraneous background noise while isolating fine-grained segmentation and structural features and unifying channel representation. Subsequently, a Deep Surrounding-Awareness Localization module and a Contour-Guided Integrity Aggregation module collaboratively refine and merge multi-level features, focusing on the global form of camouflaged objects while iteratively enhancing segmentation detail. Finally, a Guided Residual Channel Attention module further refines low-layer structural cues. Extensive experiments on ten challenging benchmark datasets using four widely used evaluation metrics demonstrate that our method exhibited superior performance, outperforming 40 state-of-the-art methods. The results demonstrate the versatility of our model. The source code and results of our method are available at https://github.com/lixu11/DSANet.},
  archive      = {J_ESWA},
  author       = {Xu Li and Xiaosheng Yu and Peng Chen},
  doi          = {10.1016/j.eswa.2025.129605},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129605},
  shortjournal = {Expert Syst. Appl.},
  title        = {DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FTUAttack: Feature truncation unrestricted attack based on stable diffusion model. <em>ESWA</em>, <em>298</em>, 129604. (<a href='https://doi.org/10.1016/j.eswa.2025.129604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of adversarial example generation and defense, compared to restricted attacks with L p -norm constraints, unrestricted attacks without L p -norm constraints emanate better visual imperceptibility. Existing unrestricted attacks typically manipulate the semantic content of examples (e.g. texture or color) to generate adversarial examples. However, current works usually ignore multifaceted features or loss optimization strategy, which limits attack performance. In this paper, we draw inspiration from stable diffusion model and propose a unrestricted attack method called Feature Truncation Unrestricted Attack (FTUAttack) to achieve both better transferability and imperceptibility. Specifically, we promote the performance of unrestricted attacks from the perspectives of both diffusion principle and feature truncation for the first time. Firstly, we propose a Global Deep Feature Extractor (GDFE) module to truncate global feature for the subsequent diffusion denoising process. Secondly, to further boost the transferability, we design a novel Critical Latent Feature Extractor (CLFE) module to obtain critical local feature that need to be truncated during the denoising process and investigate the influence of the different segmentation ways on critical local feature. Thirdly, we propose Multi-Loss Fusion (MLF) strategy to balance the conflict between perturbations and examples’ quality by guiding the optimization direction. Extensive experiments on various model structures and datasets demonstrate the superiority of our attack over the existing attack methods.},
  archive      = {J_ESWA},
  author       = {Shaojie Han and Gangzheng Zhai and Kun Chen and Shihui Zhang},
  doi          = {10.1016/j.eswa.2025.129604},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129604},
  shortjournal = {Expert Syst. Appl.},
  title        = {FTUAttack: Feature truncation unrestricted attack based on stable diffusion model},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram. <em>ESWA</em>, <em>298</em>, 129603. (<a href='https://doi.org/10.1016/j.eswa.2025.129603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of labeling Electrocardiogram (ECG) has prompted researchers to use self-supervised learning to enhance diagnostic performance. Masked autoencoders (MAE) are a mainstream paradigm where models learn a latent representation of the signal by reconstructing masked portions of the ECG. However, existing methods lack a specific design for the spatial–temporal characteristics of ECG. Specifically, leads represent spatial projections of cardiac activity, while timestamps capture temporal patterns, and the two correspond to different axes of information. Existing MAE frameworks tend to unify them prematurely, potentially weakening critical local dependencies. In this paper, we propose a Spatial-Temporal Hierarchical Decoupled Masked Autoencoder (STHD-MAE). This framework decouples ECG into isolated leads or time steps in the shallow layer to capture local dependencies with different views, then aligns spatial–temporal representations and re-establishes global dependencies in the deep layer to comprehensively represent pathological information. We also design a medical report fusion module during pre-training, which uses cross-attention to align the ECG report text encoded by a medical language model with the signal’s latent representation, thereby guiding the encoder to focus on pathological information through implicit cross-modal learning. We validate the effectiveness of STHD-MAE on multiple downstream classification and reconstruction tasks. The results show that STHD-MAE outperforms existing self-supervised learning methods by approximately 2% in F1-scores for both coarse-grained and fine-grained classification performance, and its reconstruction quality also exceeds the baseline generative model.},
  archive      = {J_ESWA},
  author       = {Xiaoyang Wei and Zhiyuan Li and Yuanyuan Tian and Mengxiao Wang and Yanrui Jin and Weiping Ding and Chengliang Liu},
  doi          = {10.1016/j.eswa.2025.129603},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129603},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching. <em>ESWA</em>, <em>298</em>, 129602. (<a href='https://doi.org/10.1016/j.eswa.2025.129602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The local correspondence learning has gained increasing attention in image-text matching, which establishes fine-grained alignments between image regions and textual words to improve both interpretability and accuracy. While these approaches have made significant progress in identifying meaningful semantic correspondences, one critical limitation persists in current methods, i.e., overlooking the crucial spatial position information of visual regions in cross-modal interaction. To address this challenge, we propose a novel Geometric contextual Aggregation and Regional contextual Enhancement Network (GARE-Net) that introduces two innovative components: the Geometric Contextual Feature Aggregation (GCFA) module and the Regional Contextual Feature Enhancement (RCFE) module. Specifically, GCFA generates the spatial geometric information of visual regions to enhance the region features by feature aggregation. RCFE further refines the aggregated region features by constructing a region graph and graph convolution. Extensive experiments and analyses are conducted on Flickr30k and MSCOCO to evaluate the importance of our framework. The results demonstrate the superiority of our method in image-text matching. Moreover, the ablation studies and visualization case studies also highlight the importance of geometric contextual feature aggregation and regional contextual feature enhancement. The code is available at https://github.com/chinaBoy123/GARE-Net .},
  archive      = {J_ESWA},
  author       = {Fangming Zhong and Tao Zhou and Zhikui Chen and Suhua Zhang},
  doi          = {10.1016/j.eswa.2025.129602},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129602},
  shortjournal = {Expert Syst. Appl.},
  title        = {GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation. <em>ESWA</em>, <em>298</em>, 129600. (<a href='https://doi.org/10.1016/j.eswa.2025.129600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing quantum group decision-making models face significant challenges in the bid evaluation of engineering projects, including the strong subjectivity of expert evaluations, the difficulty in aggregating expert opinions, the large gap of expert opinions, and the complexity of expert psychological behaviors. To address these issues, this paper proposes a novel quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation. Firstly, a quantum Bayesian network is constructed to aggregate expert opinions and capture the interference effect among experts. Secondly, the matrix fluctuation grey correlation degree is defined and applied to the calculation of quantum interaction terms that reflect the intricate psychological behavior of experts. Subsequently, a decision item search model is proposed and applied to adjust preferences during the consensus reaching process, thereby narrowing the gap of expert opinions. The consensus effect optimization model is utilized to determine optimal values for unknown parameters within this process, effectively reducing the subjectivity of expert evaluations. Finally, the proposed model is applied to a bid evaluation of bridge anti-collision engineering project, which verifies the feasibility and effectiveness of the model, and evaluates the stability and superiority of the model through sensitivity analysis and comparative analysis.},
  archive      = {J_ESWA},
  author       = {Jiuru Zhu and Xinping Xiao and Congjun Rao},
  doi          = {10.1016/j.eswa.2025.129600},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129600},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks. <em>ESWA</em>, <em>298</em>, 129599. (<a href='https://doi.org/10.1016/j.eswa.2025.129599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical node detection is an important tool for measuring network robustness. The main purpose of critical node detection is to detect a set of nodes that cause the greatest damage to the network connectivity, and it has been applied in many fields such as social network analysis and traffic network management. As a classic non-deterministic polynomial time complete problem, critical node detection faces enormous challenges with the continuous expansion of network size. The existing methods are difficult to achieve a good balance between effectiveness and efficiency, especially when the scale of complex networks becomes larger. To this end, this paper proposes a dual population based critical node detection method (DPCND) to effectively and efficiently obtain a set of critical nodes, which utilizes the co-evolution of auxiliary population generated from reduced graph and main population generated from original graph to find the optimal solution. In the proposed algorithm, a dual population interaction mechanism consists of influence and expansion strategies is proposed for information exchange, where the influence strategy transfers candidate good solutions from the auxiliary population to the main population to improve search efficiency, and the expansion strategy provides node information of the main population to guide the expansion of search space for the auxiliary population. Finally, the experimental results on 20 real-world complex networks clearly demonstrate the effectiveness of the proposed algorithm comparing to the state-of-the-arts.},
  archive      = {J_ESWA},
  author       = {Lei Zhang and Xinyi Feng and Yuanyuan Ge and Zhanpeng Wang and Haipeng Yang},
  doi          = {10.1016/j.eswa.2025.129599},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129599},
  shortjournal = {Expert Syst. Appl.},
  title        = {DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem. <em>ESWA</em>, <em>298</em>, 129598. (<a href='https://doi.org/10.1016/j.eswa.2025.129598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern agriculture, efficiently picking and distributing fresh product is crucial for the competitiveness of smart farms within the globalized agricultural market. However, the integrated scheduling problem involving both picking and distribution processes has received limited attention in existing research. To bridge this gap, this study establishes a mathematical model with dual objectives: (1) minimizing the picking completion time and (2) reducing penalties incurred due to early or delayed deliveries. A novel two-stage evolutionary algorithm incorporating a restart mechanism is proposed to effectively balance the optimization of these objectives with a high degree of consistency. The algorithm features an efficient encoding scheme and advanced genetic operators, specifically designed to enhance exploration and exploitation based on the characteristics of the problem. A comprehensive set of test instances is generated and the proposed method is benchmarked against several state-of-the-art metaheuristics from the literature. Experimental results demonstrate that the proposed algorithm outperforms the competing approaches by a significant margin for solving the problem under consideration.},
  archive      = {J_ESWA},
  author       = {Yiran Pan and Xuan He and Nan Li and Zhonghua Miao},
  doi          = {10.1016/j.eswa.2025.129598},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129598},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm. <em>ESWA</em>, <em>298</em>, 129597. (<a href='https://doi.org/10.1016/j.eswa.2025.129597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful simulation of constrained differential evolution (CDE) algorithm for solving phase equilibrium calculation has first verified that heuristic optimization algorithms are effective ways to solve this kind of problems. Their insensitivity to initial values overcomes the limitations associated with two kinds of traditional methods, i.e., direct solution methods based on Newton’s method and indirect solution methods based on thermodynamic principles. This article proposes a constrained quadratic interpolation optimization algorithm (CQIO) for obtaining the satisfactory solutions of phase equilibrium calculation under given volume, temperature, and moles (NVT-flash). The proposed CQIO regards the total Helmholtz free energy of a NVT-flash problem as its objective function, while the moles vector and volume of a certain phase as its decision variables. The consistency between the four cases’ experimental results of CQIO and those of published articles demonstrates the effectiveness of CQIO in solving NVT-flash problems. Then the computational overhead and algorithmic stability of CQIO were analyzed. In Cases 1, 2 and 3, the average CPU time of CQIO compared to CDE has increased by 46.98 % , 54.56 % and 21.02 % respectively. The Std values of CQIO are significantly smaller than those of CDE in all cases except for Example 2. The proposed CQIO greatly promotes the application of heuristic algorithm in the field of phase equilibrium calculation.},
  archive      = {J_ESWA},
  author       = {Wangyu Tong and Baoduo Su and Yaqian Zhan},
  doi          = {10.1016/j.eswa.2025.129597},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129597},
  shortjournal = {Expert Syst. Appl.},
  title        = {An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge graph life cycle for cognitive agents – A case study on automated negotiation in smart grids. <em>ESWA</em>, <em>298</em>, 129596. (<a href='https://doi.org/10.1016/j.eswa.2025.129596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) can enhance cognitive artificial agents by improving their semantic understanding, adaptability to dynamic contexts, explainability, continuous learning, and informed, case-based decision-making. However, the development of any KG rarely follows an explicit and structured procedure to improve its consistency, modifiability, and interoperability. This ultimately restricts the utility of KGs for real-world agentic AI systems. To overcome this limitation, this paper proposes a life cycle for developing and evolving KGs in domain-specific applications, encompassing three phases to i) conceptualize the problem domain and competency questions, ii) formalize a schema using ontologies, and iii) implement the KG to foster agents’ cognition through queries and graph data science. The proposed approach is validated with a case study on context-aware automated negotiations within smart grids, where agents negotiate for energy trading while considering private and contextual circumstances. Agents may take actions with or without the aid of a KG, and can adopt one of three negotiation strategy configurations: heuristic, metaheuristic, or reinforcement learning-based. Negotiation outcomes consistently indicate that, regardless of the configuration employed, the use of a KG improves agents’ rewards by at least 1.21 % and up to 90.91 %. Results highlight that the proposed life cycle enables the integration of contextual and domain-specific data and metadata into a KG that enhances agents’ learning, while also allowing for the development and selection of relevant queries and graph data science algorithms to improve the strategic behavior of negotiation agents with cognitive abilities.},
  archive      = {J_ESWA},
  author       = {Dan E. Kröhling and Ernesto C. Martínez},
  doi          = {10.1016/j.eswa.2025.129596},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129596},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge graph life cycle for cognitive agents – A case study on automated negotiation in smart grids},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets. <em>ESWA</em>, <em>298</em>, 129595. (<a href='https://doi.org/10.1016/j.eswa.2025.129595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a novel VRP variant integrating seasonal demand fluctuations, heterogeneous vehicle sources, and multi-endpoint constraints, focusing on the distribution of seasonal products in a steel parts enterprise. It tackles the complex vehicle routing problem with time windows involving heterogeneous fleets, which encompass different vehicle sources (owned and rented), types (fuel-powered and electric), capacities, ranges, and endpoints. To balance enterprise profitability, greenhouse gas emissions, and environmental quality, we develop a mathematical model centered on optimizing distribution costs, greenhouse gas emissions, and vehicle utilization. Drawing inspiration from ancient competitive activities, we propose a novel Huashan Swords Algorithm (HSSA). Through simulations using real enterprise data, we demonstrate the HSSA’s effectiveness, with comparative experiments against existing advanced algorithms highlighting its superiority. Applying the algorithm to design logistics distribution schemes, we conduct in-depth tests considering different customer groups and fuel station distributions. Analyzing the results from the perspectives of profitability, emissions, and environmental quality, we offer targeted operational suggestions for the enterprise based on its situation, geographical characteristics, and fiscal policies. Moreover, we provide recommendations to local governments on fuel station construction and vehicle subsidy policies, contributing practical solutions to both enterprise operations and regional development.},
  archive      = {J_ESWA},
  author       = {Zhang Yanhu and Yan Lijuan and Kong ShuMei and Miao Decheng},
  doi          = {10.1016/j.eswa.2025.129595},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129595},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch. <em>ESWA</em>, <em>298</em>, 129594. (<a href='https://doi.org/10.1016/j.eswa.2025.129594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting gold prices through the analysis of key economic indicators such as inflation rates, Government Bond Yields, and the U.S. Dollar Index, alongside historical Gold Prices, is crucial for enabling investors to better understand market dynamics and make vital decisions to maximize returns. However, previous studies have faced challenges in extracting hidden factors related to gold price prediction from diverse economic indicators, and the comprehensive exploration of gold price data is yet to be fully achieved. To address this, the present study introduces a mid to long-term gold price prediction model named DPformer. This model utilizes a patching strategy to investigate the relationships between different economic indicators and Gold Prices. It also employs a decomposition approach to discover the mid to long-term trend characteristics and yearly seasonal patterns of Gold Prices. The core of the model integrates a Transformer module, which is solely based on an Encoder structure, and enhances it with multiple attention mechanisms and convolutions. This enhancement allows the improved Transformer model to more effectively capture the long-term dependencies of Gold Prices. The empirical results demonstrate that DPformer consistently outperforms a suite of advanced models widely adopted in terms of mid to long-term forecasting accuracy, including LSTM, GRU, Transformer, DLinear, and PatchTST. Notably, for the 30-step gold price prediction task, DPformer achieves a 21.78 % reduction in Mean Squared Error compared to PatchTST. Moreover, by quantitatively analyzing how various economic indicators influence gold price forecasts, this study provides substantial support for investors in making informed decisions at critical moments.},
  archive      = {J_ESWA},
  author       = {Guanhao Bao and Yunbo Niu and Baisheng Cui and Wanying Ji},
  doi          = {10.1016/j.eswa.2025.129594},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129594},
  shortjournal = {Expert Syst. Appl.},
  title        = {Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches. <em>ESWA</em>, <em>298</em>, 129592. (<a href='https://doi.org/10.1016/j.eswa.2025.129592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a systematic mapping of machine learning in class imbalance scenarios, offering a broad overview of key challenges, promising emerging techniques, and established methodologies across various application domains. The investigation stands out by employing a hybrid search and selection protocol that combines methodological rigor with technical innovation. The adopted strategy integrated manual searches in reference sources with automated processes based on machine learning, semantic embeddings, and graph-based ranking algorithms. To enhance selection quality, the Quasi-Golden Set (QGS) method was used to build a reference set from manually selected articles – a critical foundation for calibrating and evaluating automated search strings. This combination ensured broad coverage of the topic while improving sensitivity and precision in identifying relevant studies. The initial analysis reviewed 25,593 publications. After screening and applying eligibility criteria, 468 articles were included in the final dataset. The results indicate that 55 % of the studies address multiple domains, with a strong predominance of tabular data ( 84 % ). SMOTE and hybrid approaches were among the most common techniques, present in 61 % of the studies. In terms of evaluation metrics, ROC-AUC was the most frequently used, followed by F1-score and accuracy – the latter noted for limitations in highly imbalanced scenarios. Building on these findings, we derive an empirically grounded taxonomy that links problem context, solution algorithms, and scenario-appropriate evaluation metrics, and we provide a minimal selection guideline table to support applied use. While sampling-based methods remain prevalent, deep learning approaches such as convolutional neural networks and graph-based models are increasingly adopted. Additionally, federated, contrastive, and semi-supervised learning are emerging as relevant paradigms, particularly suited for privacy-aware or low-label environments. This study consolidates current knowledge, identifies methodological and application gaps, and highlights trends that are likely to shape future research. It contributes both a comprehensive synthesis of the field and strategic insights for advancing machine learning techniques in the presence of class imbalance.},
  archive      = {J_ESWA},
  author       = {Gilberto Sussumu Hida and André Câmara Alves Do Nascimento},
  doi          = {10.1016/j.eswa.2025.129592},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129592},
  shortjournal = {Expert Syst. Appl.},
  title        = {Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches. <em>ESWA</em>, <em>298</em>, 129591. (<a href='https://doi.org/10.1016/j.eswa.2025.129591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process planning in reconfigurable manufacturing systems usually considers a single product, this reduces the efficiency of the overall production plan when multiple products are combined. This paper tackles the Multi-Product Process Planning Problem (MPPP), optimizing both individual process plans and their sequencing. We propose a 0–1 LP model, the model is relaxed by fixing the product sequencing variables and implemented in a Normal-Boundary Intersection method (NBI-es), the method uses a function for iteratively updating β values. Three metaheuristics are also developed: NSGA-II, and two variants of MOEA/D, one enhanced by Opposition-based learning (OBL). Computational experiments show that the update function enhances the performance of NBI over simple Normalized-Weighted Sum (NWS) method. Additionally, NBI-es performs better in HV metric for small size instances if it is given enough CPU times, while MOEA/D significantly outperforms NSGA-II on larger instances on most convergence and spread based metrics. OBL further enhances solution diversity for MOEA/D, albeit with less convergence. A special case of the MPPP is investigated, involving identical products: the Multi-Unit Process Planning (MUPP). An integrated approach was compared with a sequential separated approach. Results indicate that the integrated approach outperforms the separated method for smaller problem instances. Moreover, the analysis of high-quality MUPP solutions revealed a tendency towards diverse process plan combinations rather than repetitive identical ones.},
  archive      = {J_ESWA},
  author       = {Abdelkader Mechaacha and Fayçal Belkaid and Nadjib Brahimi},
  doi          = {10.1016/j.eswa.2025.129591},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129591},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs. <em>ESWA</em>, <em>298</em>, 129590. (<a href='https://doi.org/10.1016/j.eswa.2025.129590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing has attracted increasing attention for its environmental and economic benefits. Since it is difficult to achieve economies of scale when processing small amounts of remanufacturing jobs alone, these jobs are processed in the same job-shop for new jobs in some enterprises. The processing times of remanufacturing jobs are uncertain due to unpredictable status, leading to certain impacts on scheduling performance. Therefore, we address a flexible job-shop scheduling problem with new and remanufacturing jobs to minimize makespan. To solve this problem, a slack-based two-stage improved particle optimization algorithm is proposed. The first stage aims to yield a solution set with minimum makespan, while the second stage aims to search the best robust solution with maximum total slack from the set. Both stages are executed alternately to optimize makespan and total slack. Moreover, a position updating mechanism with genetic operators and a tabu search inspired local search strategy are implemented to improve algorithmic performance. Computational experiments are conducted using adapted benchmark problems and an industrial case to validate the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Jun Liu and Zhui Gui and An Li and Qiong Liu},
  doi          = {10.1016/j.eswa.2025.129590},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129590},
  shortjournal = {Expert Syst. Appl.},
  title        = {A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach. <em>ESWA</em>, <em>298</em>, 129589. (<a href='https://doi.org/10.1016/j.eswa.2025.129589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates and predicts green economic efficiency (GEE) across 248 Chinese cities from 2010 to 2021 using a three-stage network SBM model based on subsystems of economic production, social development, and environmental governance. To enhance accuracy in both assessment and forecasting, machine learning methods are incorporated, and the Dagum Gini coefficient is employed to analyze regional disparities. This study innovatively proposes a three-stage network SBM model to resolve the “black box” limitation of conventional DEA approaches, while a DEA-ML model is developed to achieve enhanced prediction accuracy. The results reveal that GEE in Chinese cities remains low, with the eastern region leading and the western region trailing. However, efficiency has improved since 2016, primarily driven by advancements in environmental governance. Regional disparities, largely attributed to interregional differences, are gradually decreasing. Among forecasting models, the backpropagation neural network (BPNN) delivers the highest accuracy, predicting sustained leadership in the east, strong growth in the northeast, and a reduction in national disparities. This study offers a comprehensive framework for evaluating and predicting GEE, providing valuable insights for sustainable development policies.},
  archive      = {J_ESWA},
  author       = {Zhishuo Zhang and Hu Liu and Yunpeng Gong and Huayong Niu},
  doi          = {10.1016/j.eswa.2025.129589},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129589},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization. <em>ESWA</em>, <em>298</em>, 129587. (<a href='https://doi.org/10.1016/j.eswa.2025.129587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid algorithm integrating a couple of individual evolutionary algorithms (sub-algorithms) is widely recognized as an effective approach to enhance both robustness and optimization performance. Nevertheless, such integration often destroys the structure of the sub-algorithm and makes it difficult to incorporate additional evolutionary algorithms. To address these limitations, this study introduces a novel framework, the Heterogeneous Alternating Evolutionary Algorithm (HAEA), designed to integrate multiple evolutionary algorithms while enabling the flexible addition, removal, and replacement of internal sub-algorithms. To facilitate the integration of a broad spectrum of sub-algorithms, this study draws inspiration from the particle swarm optimization algorithm to devise a suite of information indicators for the transmission of optimization information between sub-algorithms with disparate structures. Furthermore, HAEA is endowed with an adaptive mechanism that dynamically modifies the selection probabilities of its sub-algorithms based on their long-term and short-term performance throughout the evolutionary process. We conducted a comparative analysis of HAEA against all its sub-algorithms across three widely recognized function test sets: CEC2013, CEC2017, and CEC2022. Meanwhile, we applied the HAEA separately to basic metaheuristic algorithms and advanced evolutionary algorithms in recent years and conducted two comparative experiments. Both experimental results show that HAEA outperforms all sub-algorithms in terms of robustness and optimization performance. Its distinctive flexibility allows for the incorporation of additional superior evolutionary algorithms in the future, thereby enhancing its overall performance.},
  archive      = {J_ESWA},
  author       = {Taiyong Li and Tianhao Yi and Zhenda Hu and Wu Deng and Donglin Zhu and Zhilong Xie and Jiang Wu},
  doi          = {10.1016/j.eswa.2025.129587},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129587},
  shortjournal = {Expert Syst. Appl.},
  title        = {HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients. <em>ESWA</em>, <em>298</em>, 129586. (<a href='https://doi.org/10.1016/j.eswa.2025.129586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, free quadratic coefficients are proposed in order to deeply study the flexible criteria of synchronization problem for two kinds of fractional-order higher-dimension-valued neural networks (FOHDVNN) with usual neurons and threshold ones, respectively. First, the uniform system is constructed for two kinds of FOHDVNN which contains both fractional-order octonion-valued neural networks (FOOVNN) and fractional-order quaternion-valued neural networks (FOQVNN). Based on higher-dimension algebra multiplication rules, the studied FOHDVNN are directly decomposed into the eight or four subsystems in real-valued field. Subsequently, free quadratic coefficients are taken into the establishment of two types of Lyapunov-Krasovskii functional (LKF) which is newer and more general. Then, mainly based on the very recent lemmas and Lyapunov theories, the flexible criteria are generally acquired for the global Mittag-Leffler synchronization (MLSY) problem of FOHDVNN. The final criteria have the advantage in being easily calculated and widely used. It is worth noting that the optimal solutions of these criteria can be obtained through the genetic algorithm and the synchronization performance can be improved by optimizing the quadratic coefficients. Finally, three simulation examples are presented to express the availability and progress of the derived results.},
  archive      = {J_ESWA},
  author       = {Jianying Xiao and Yongtao Li},
  doi          = {10.1016/j.eswa.2025.129586},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129586},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex-order darwinian particle swarm optimization. <em>ESWA</em>, <em>298</em>, 129584. (<a href='https://doi.org/10.1016/j.eswa.2025.129584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Particle Swarm Optimization (PSO) algorithm has been one of the most effective methods for solving various complex optimization problems. However, non-adaptive versions of the PSO do not use historical information for performance enhancement and suffer from performance degradation problems. This paper presents a Complex-Order Darwinian PSO (CoDPSO) algorithm, which effectively enhances the performance of the PSO. A complex-order derivative mechanism is introduced into the velocity update rule to improve local exploitation using historical velocity information. Additionally, a Degradation Elimination (DE) strategy is designed to mitigate performance drop during the optimization process. Sensitivity analysis is conducted to evaluate the impact of control parameters on the algorithm’s behavior, demonstrating its robustness across a wide range of settings. Comparative experiments on CEC 2022 benchmark functions show that the CoDPSO outperforms other PSO variants in terms of accuracy, stability, and convergence. Wilcoxon statistical tests further confirm the significance of these improvements. The experimental results indicate the feasibility and efficiency of the CoDPSO.},
  archive      = {J_ESWA},
  author       = {Xiaobo Wu and Liping Chen and Huafeng Li and António M. Lopes and Chuang Liu and Yangquan Chen and Yi Chai},
  doi          = {10.1016/j.eswa.2025.129584},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129584},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complex-order darwinian particle swarm optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions. <em>ESWA</em>, <em>298</em>, 129583. (<a href='https://doi.org/10.1016/j.eswa.2025.129583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting public opinion trends during major infectious disease outbreaks is critical for guiding effective public health responses. However, predicting public opinion remains challenging because it is influenced by socio-economic, psychological, and media factors. This paper presents a novel framework for predicting public opinion trends related to significant infectious diseases, with a focus on COVID-19 as a case study. The proposed framework identifies the key factors influencing public opinion development and enables both point and interval predictions. The framework uses information ecology theory and applies the NSGA-II algorithm to select the features that best drive public opinion trends. By incorporating this framework, accurate point forecasts are produced alongside prediction intervals, effectively quantifying the uncertainty inherent in public opinion dynamics. This approach minimizes the quality-driven loss function to generate precise prediction intervals, providing decision-makers with critical insights into public opinion fluctuations during epidemics. The results offer valuable, real-time public sentiment warnings, supporting timely and effective interventions in epidemic prevention and control efforts.},
  archive      = {J_ESWA},
  author       = {Futian Weng and Meng Su and Petr Hajek and Mohammad Zoynul Abedin},
  doi          = {10.1016/j.eswa.2025.129583},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129583},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism. <em>ESWA</em>, <em>298</em>, 129581. (<a href='https://doi.org/10.1016/j.eswa.2025.129581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge for multimodal multi-objective problem (MMOP) resolution lies in maintaining synergistic interactions between convergence and diversity. However, the existing algorithms usually consider convergence-first, which neglect to consider both diversity and convergence into account during the evolutionary process. Likewise, the optimization methods tend to gravitate toward locally optimal regions rapidly, leading to lose diversity for the local PS. This paper proposes a Deep Reinforcement Learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism (DRLMMEA) to investigate the impact of different operator selection on the performance of MMEAs, which greatly helps to balance the convergence and diversity. DRLMMEA utilizes Q-Network to select the operator with the highest reward to enhance the population’s search ability. An improved sorting method (ISM) based on neighborhood dominance updates the population by sorting individuals according to their convergence quality, thereby enhancing convergence performance in the objective space. Moreover, this study proposes a series-parallel mechanism, a series structure enhances the diversity in the decision space, while the parallel structure reduces the computational burden of the algorithm evidently. The proposed Deep Reinforcement Learning-assisted operator selection mechanism, which enables effective balance between diversity and convergence, and an improved crowding distance approach that enhances convergence performance. DRLMMEA undergoes comprehensive testing against 6 contemporary approaches using MMF and IDMP benchmark problems, achieving supremacy in 4 principal performance metrics according to experimental findings. The multimodal gearbox parameter optimization is addressed using the proposed DRLMMEA, which demonstrates superior performance against 6 algorithms in comparative evaluations. It has demonstrated a significant role in solving the MMOPs with the imbalance between convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Ying Huang and Xiaojian Cao and Benben Zhou and Wei Li and Shuling Yang and S.M. Shafi and Zhou Yang},
  doi          = {10.1016/j.eswa.2025.129581},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129581},
  shortjournal = {Expert Syst. Appl.},
  title        = {A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evolutionary multitasking optimization based on cross-task association mapping strategy. <em>ESWA</em>, <em>298</em>, 129580. (<a href='https://doi.org/10.1016/j.eswa.2025.129580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multitasking optimization, knowledge transfer between tasks through subspace generation has been widely employed to enhance the convergence performance of algorithms. However, this approach fails to account for the inter-task knowledge mapping relationships. Therefore, cross-task knowledge transfer during the optimization process remains inherently blind, potentially leading to mismatched subspace information and consequently degrading the algorithm’s performance. To address this issue, this paper proposes a multitask evolutionary algorithm based on an association mapping strategy and an adaptive population reuse mechanism, namely PA-MTEA. Specifically, to fully represent the correlations between multitask domains and enhance the adaptability of transfer solutions in target tasks, this paper introduces a subspace projection strategy based on partial least squares, which achieves the correlation mapping between the source and target tasks during the dimensionality reduction of the search space. Additionally, to further enhance knowledge transfer across tasks, an alignment matrix is obtained by adjusting the subspace Bregman divergence after deriving the respective subspaces, minimizing variability between task domains. Finally, to balance the global exploration of algorithms with local exploitation, an adaptive population reuse mechanism based on the residual structure is designed. This mechanism reuses historically successful individuals to guide the evolutionary direction of the population, thus improving the algorithm’s convergence performance. Experimental results on various benchmark suites and real-world cases demonstrate that PA-MTEA exhibits significantly superior performance compared to six other advanced multitask optimization algorithms.},
  archive      = {J_ESWA},
  author       = {Tao Yin and Lizhong Yao and Xin Zong and Pengjie Qin and Haoming Dong},
  doi          = {10.1016/j.eswa.2025.129580},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129580},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evolutionary multitasking optimization based on cross-task association mapping strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation. <em>ESWA</em>, <em>298</em>, 129578. (<a href='https://doi.org/10.1016/j.eswa.2025.129578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of different tissues within blastocysts is essential for embryologists to objectively observe and evaluate embryos, thereby contributing to a higher success rate of in vitro fertilization treatment. Inspired by the primary observation of skeletal patterns and boundary information by clinical doctors, we present an interesting task-aware view for blastocyst segmentation with semi-supervised learning, focusing on task-invariant and task-specific dependencies of segmentation. Firstly, we explore one strong-correlation task with bidirectional transformation between its outputs and the segmentation results, and another weak-correlation task with monodirectional transformation from segmentation maps. The correlation among different tasks inspires us to propose Task-Aware Smoothness (TAS) Assumption , thereby deducing different types of task-aware consistency. Then, a new Unified Task-aware Consistency Interaction (UniTask+) framework is developed to unify and fully take advantage of these strong, weak, and strong-to-weak task-aware consistency. It is comprised of a medical segmentation (MS) branch to implement segmentation and two extra branches performing strong/weak-correlation tasks based on the same backbone. Concretely, a level-set (LS) branch promotes the strong consistency while a point-set (PS) branch stimulates the weak consistency with underlying task perturbations. Numerous experiments have been conducted on the inner cell mass (ICM), blastocyst, proving the effectiveness of our tactics. Furthermore, we have also conducted experiments with datasets from the left atrium (LA), which shares similar structural features with embryos, to validate the robustness of the model. Our methods have shown prominent improvements over up-to-date SSL methods, which advocates our precedent hypothesis.},
  archive      = {J_ESWA},
  author       = {Hua Wang and Linwei Qiu and Jingfei Hu and Jicong Zhang},
  doi          = {10.1016/j.eswa.2025.129578},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129578},
  shortjournal = {Expert Syst. Appl.},
  title        = {UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval. <em>ESWA</em>, <em>298</em>, 129577. (<a href='https://doi.org/10.1016/j.eswa.2025.129577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has been widely used in large-scale multimedia retrieval due to its advantages in terms of low storage cost and computational efficiency. Deep hashing algorithms can jointly learn semantic features and hash functions, encoding the original data into compact binary codes with significant discriminative power. However, in multi-label scenarios, especially when the number of samples is extremely large, a high negative-positive imbalance may occur, particularly when the proportion of negative samples is too high, which can lead to bias in the semantic relationships between the learned images. To solve this problem, symmetric losses such as focal loss were proposed, which treat positive and negative samples equally, but the retrieval results are suboptimal. This may be because the equal-weighted processing strategy causes the model to over-focus on hard negative samples and ignore the learning of positive sample features. Besides, mislabeled negative samples, especially those with a probability close to 1, can lead the model to learn incorrect features, harming its discrimination ability, reducing accuracy and recall, and causing overfitting and poor generalization. Accordingly, this paper proposes a novel hashing model, Deep Asymmetric Semantic Hashing with Probability Shifting framework (DASH-PS), for discriminative binary code learning. Specifically, by combining asymmetric focusing strategy and probability shifting strategy, asymmetric semantic loss is designed to solve negative-positive imbalance and ground-truth mislabeling. To keep the contribution of positive samples while focusing on hard negative samples, asymmetric focusing strategy is proposed to decouple negative and positive samples and assign different attenuation factors. By offsetting the probability of negative samples, probability shifting strategy completely discards easy negative samples and very hard negative samples suspected of being mislabeled. Additionally, an adaptive asymmetric learning mechanism is proposed to reduce the fixed difference in average probabilities between positive and negative samples, thereby simplifying hyperparameter selection and improving retrieval efficiency. Extensive experimental results on multiple benchmark datasets validate that our DASH-PS outperforms various state-of-the-art hashing methods. The code for the implementation of our DASH-PS framework is available at https://github.com/QinLab-WFU/DASH-PS.},
  archive      = {J_ESWA},
  author       = {Yongyue Fu and Qibing Qin and Jinkui Hou and Congcong Zhu and Lei Huang and Wenfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129577},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129577},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed tensor autoencoder with memory for video anomaly detection. <em>ESWA</em>, <em>298</em>, 129576. (<a href='https://doi.org/10.1016/j.eswa.2025.129576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video data can be naturally represented as tensors. Despite great progress in anomaly detection with memory-augmented autoencoders, the memory module therein can only handle vectors and inevitably breaks tensor structures, thus leading to performance degradation. Moreover, after the mapping of the encoder, some abnormal features may directly fall into the normal convex polytope, as autoencoders only use the output error to guide the construction of latent variables without imposing any constraint. The memory module can not handle these abnormal features, so that the abnormal observations may not be identified. To solve these problems, we propose a Physics-Informed Tensor AutoEncoder (PITAE) framework, which incorporates both neural networks and physical laws, i.e., tensor operation rules. Specifically, we design a tensor decomposition network followed by an explicit tensor operation to decompose the latent variable into low-rank and sparse components, and only the low-rank component is inputted to the decoder. In this way, we reserve the tensor structure and meanwhile impose a low-rank constraint on the latent variable, thereby compressing the features of normal samples into a ”smaller” region where anomalies are less likely to fall into. Consequently, the non-low-rank anomalies can be identified. But the low-rank anomalies may still not be identified. To further solve this problem, we design a tensor Memory module, and the overall model is named as PITAEM. Finally, based on the proposed framework, we design a novel composite anomaly score to identify anomalies of various kinds. Experiments on various video datasets demonstrate the effectiveness of the proposed method, especially in the small data regime.},
  archive      = {J_ESWA},
  author       = {Jianan Liu and Chunguang Li},
  doi          = {10.1016/j.eswa.2025.129576},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129576},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-informed tensor autoencoder with memory for video anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust medical image encryption technique using inverse cosine chaotic map. <em>ESWA</em>, <em>298</em>, 129574. (<a href='https://doi.org/10.1016/j.eswa.2025.129574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid proliferation of digital imaging technologies, the need for robust and lightweight image encryption techniques has become increasingly critical, particularly for medical, military, and personal data applications. In this paper, we propose a novel image encryption scheme based on a one-dimensional inverse cosine chaotic map (1D-ICC), which introduces a highly sensitive and structurally complex nonlinear dynamical system. The proposed method integrates a dynamic Josephus-based intra-block scrambling mechanism, a global zigzag permutation strategy, and an adaptive diffusion process guided by chaotic sequences, thereby enhancing the confusion and diffusion characteristics of the cipher. Unlike conventional approaches, our scheme dynamically derives the encryption key from the SHA-512 hash of the original image, ensuring both sensitivity to plaintext changes and resistance to known-plaintext and chosen-plaintext attacks. The use of the 1D-ICC map, featuring a tunable control parameter r 5 enables rich chaotic behavior even in one dimension, reducing computational complexity without sacrificing security. Comprehensive experiments validate the robustness and efficiency of the encryption scheme, with performance metrics including correlation coefficients below 0.003, information entropy of 7.9993, a Number of Pixels Change Rate (NPCR) of 99.61 %, and a Unified Averaged Changed Intensity (UACI) of 33.42 %. These results demonstrate that our method surpasses several existing techniques in both security strength and computational performance, underscoring the potential of the 1D-ICC map for practical image encryption applications.},
  archive      = {J_ESWA},
  author       = {Jackson J and Perumal R},
  doi          = {10.1016/j.eswa.2025.129574},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129574},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust medical image encryption technique using inverse cosine chaotic map},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing text classification with neural label embedding and weakly-supervised learning. <em>ESWA</em>, <em>298</em>, 129569. (<a href='https://doi.org/10.1016/j.eswa.2025.129569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the widespread adoption of deep-learning-based models in a range of linguistic tasks including the fundamental text classification. These deep neural networks, however, often face challenges due to the limited availability of large-scale training data with high-quality label annotations. Furthermore, while supervised learning has proven to be superior in training sentence representations for downstream tasks like text classification, this aspect has received relatively little attention. In this study, a novel model named L abel Em bedding joint with We akly-supervised C lassification ( LemWec ) is proposed, which aims to establish a unified framework by combining supervised sentence embedding with multiclass classification. For supervised sentence embeddings, the model incorporates seed information such as label names and designs an encoder network with a new pooling layer. Additionally, the model adopts a pseudo-labeling approach to leverage a substantial amount of unlabeled samples. This approach specifically addresses the drawback of generating pseudo-labels with the highest confidence and introduces a noise adaptation method to mitigate this issue. The results of extensive experiments conducted on four real-world datasets demonstrate that the proposed LemWec model can significantly enhance the performance of text classification when compared to a comprehensive set of baselines.},
  archive      = {J_ESWA},
  author       = {Xiao Jing and Zhe Li and Zhiang Wu and Dejun Mu},
  doi          = {10.1016/j.eswa.2025.129569},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129569},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing text classification with neural label embedding and weakly-supervised learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data. <em>ESWA</em>, <em>298</em>, 129568. (<a href='https://doi.org/10.1016/j.eswa.2025.129568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell clustering plays a vital role in single-cell RNA sequencing (scRNA-seq) data analysis. Although many deep cell clustering methods have been proposed to cluster the scRNA-seq data, they overlook the structural partitioning objectives during the representation learning process, leading to challenges with non-linearly separable structures. In this paper, we present a novel end-to-end deep kernel cell clustering model for scRNA-seq data based on self-supervised ZINB-based kernel representation learning, named scDKC, which simultaneously learns cell kernel representations and identifies cell clusters. Specifically, a kernel-aid hybrid representation learning encoder is developed to effectively learn the separable kernel representation of cells, consisting of cells’ expression characteristics and cell-cell topological interactions. To guide the direction of kernel representation learning, a ZINB-based kernel representation learning decoder is designed by capturing the global probabilistic structure, the representation and the cell graph structure of the scRNA-seq data. By leveraging the clustering self-supervised strategy, representation self-supervised strategy, ZINB-based distribution self-supervised strategy, and kernel self-supervised strategy, scDKC optimizes cell cluster label assignment and learns cell kernel representations through a joint mutual self-supervised mechanism. Extensive experiments on 15 real scRNA-seq datasets, comparing scDKC with 10 competing methods, highlight its competitive advantages.},
  archive      = {J_ESWA},
  author       = {Lina Ren and Maoxuan Yao and Ruizhang Huang and Yongbin Qin},
  doi          = {10.1016/j.eswa.2025.129568},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129568},
  shortjournal = {Expert Syst. Appl.},
  title        = {Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dual uncertainty-aware fusion framework for face expression recognition in the wild. <em>ESWA</em>, <em>298</em>, 129567. (<a href='https://doi.org/10.1016/j.eswa.2025.129567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition(FER) is a key task in the broader landscape of affective computing and human-computer interaction, enabling machines to interpret human emotions. To better learn discriminative features under complex facial variations, recent FER research has increasingly adopted multi-branch fusion architectures that aim to capture complementary features from diverse perspectives. However, existing multi-branch fusion strategies, including static weighting, simple concatenation, or uncertainty-aware modeling, lack the capacity to comprehensively capture and reconcile the reliability variations across both individual instances and structural branches. To overcome these limitations, we propose a novel multi-branch fusion strategy, named Dual Uncertainty-Aware Fusion Framework(DUAFF), which improves the discriminability of integrated features by simultaneously modeling instance-wise uncertainty and inter-branch correlations. Specifically, the proposed method comprises two complementary modules: Instance-Discrepant Uncertainty-Aware Fusion Module (ID-UAFM) and Branch-Discrepant Uncertainty-Aware Fusion Module (BD-UAFM). ID-UAFM is introduced to perform channel-wise entropy analysis between semantically distinct samples to estimate instance-level uncertainty, enabling selective channel-wise fusion that emphasizes reliable representations while suppressing uncertain responses. BD-UAFM is further proposed to capture structural uncertainty by evaluating the relative reliability of features across multiple branches and adaptively weighting their contributions based on inter-branch discrepancies. Experimental results demonstrate that the proposed DUAFF consistently outperforms POSTER across three benchmark datasets, achieving accuracy improvements of 0.23 % on RAF-DB, 0.69 % on FER2013, and 0.29 % on AffectNet (7-class), thereby confirming its effectiveness in enhancing the reliability and discriminability of facial representations.},
  archive      = {J_ESWA},
  author       = {Wenfeng Jiang and Ziyi Zhao and Lin Wang and Fang Liu and Chunmei Qing and Xiaofen Xing and Xiangmin Xu and Weiquan Fan and Zhanpeng Jin},
  doi          = {10.1016/j.eswa.2025.129567},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129567},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dual uncertainty-aware fusion framework for face expression recognition in the wild},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data. <em>ESWA</em>, <em>298</em>, 129566. (<a href='https://doi.org/10.1016/j.eswa.2025.129566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel multiscale and multivariable deep learning framework for tourism stock index forecasting. To address the research gap concerning emerging media’s impact on the tourism sector, our study innovatively integrate multi-source data, including Douyin (China’s prominent short video platform), into our predictive model. Our methodology employs a multiscale decomposition strategy to streamline feature extraction complexity, coupled with an enhanced temporal convolutional network model incorporating soft-thresholding denoising to mitigate noise interference. Furthermore, we implement an adaptive differentiated prediction strategy to optimize model flexibility. Empirical analysis utilizing the CSI Tourism Stock Index demonstrates that our proposed model outperforms benchmark models in both predictive accuracy and stability, thereby validating its efficacy in tourism stock index forecasting.},
  archive      = {J_ESWA},
  author       = {Feng Shen and Shuai Huang and Wanqing Zhao and Dao Lan},
  doi          = {10.1016/j.eswa.2025.129566},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129566},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing adversarial transferability through frequency-domain boundary samples tuning. <em>ESWA</em>, <em>298</em>, 129565. (<a href='https://doi.org/10.1016/j.eswa.2025.129565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer-based attacks evaluate the robustness of deep learning models and advance adversarial research to improve the security and reliability of deep learning and its applications. Previous efforts have improved the transferability through advanced gradients, augmented models, or augmented data. In this paper, we understand and enhance the transferability from a new perspective. Delving into intermediate features, we empirically find a difference between the distances of adversarial and original samples from cluster centers of the original classes. The adversarial samples are simultaneously far from both the original samples and the cluster centers, close to generalized decision boundaries. Based on this observation, we propose a novel spectrum tuning attack. Boundary samples are utilized to guide the generation of adversarial samples that are far away from the cluster centers. Specifically, randomized boundary samples are generated by frequency-domain transformations. With the gradients of the diverse boundary samples, the adversarial perturbation moves the examples away from cluster centers, thus approaching generalized decision boundaries. In the optimization process, conjugate directions are employed to avoid oscillations and stabilize the update direction. Given the strong Wolfe parameters, the analysis of the descent direction and current gradient further ensures the convergence speed and stability of the optimization. In addition, Gaussian preprocessing is introduced to smooth the update direction, further stabilize the direction and enhance the transferability. The proposed method is flexible enough to be combined with existing methods to further improve the transferability. Experiments conducted on the ImageNet-compatible dataset validate the effectiveness of the proposed method, e.g., 92.6 % success rate against nine defense methods.},
  archive      = {J_ESWA},
  author       = {Shuyan Cheng and Peng Li and Keji Han and Yangjun Xiong and He Xu and Ruchuan Wang},
  doi          = {10.1016/j.eswa.2025.129565},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129565},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing adversarial transferability through frequency-domain boundary samples tuning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When graph anomaly breaks the coherence: A multi-evidence approach with language models. <em>ESWA</em>, <em>298</em>, 129557. (<a href='https://doi.org/10.1016/j.eswa.2025.129557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is critical in domains such as healthcare and economics, where identifying deviations can prevent substantial losses. However, current detection methods, primarily reliant on Graph Neural Networks (GNNs), suffer from a critical limitation: they make judgment on a single piece of evidence – the classification of learned node representations. This “single-verdict” approach is inherently susceptible to misjudgments arising from noisy or biased representations. To address this limitation, we introduce Multi-AD, a novel Multi-evidence-based graph Anomaly Detection framework that leverages the power of Language Models (LMs) to enable more robust and reliable anomaly detection. We provide a paradigm shift by constructing multiple evidence sequences for each target node, and employing LMs to assess the coherence of these sequences. By aggregating coherence scores across multiple sequences, Multi-AD leverages converging evidence to make more informed decisions about anomaly status as the presence of anomalous nodes disrupts coherence. Furthermore, we introduce a coherence-aware edge representation method to enhance the discriminative power of the constructed sequences and a multi-round adaptive integration strategy to handle challenging scenarios where normal nodes might be surrounded by anomalies. Extensive experiments demonstrate that Multi-AD consistently outperforms state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xuan Cheng and Jiahui Lu and Chunjing Xiao and Meiyi Yang and Meihui Zhong and Fan Zhou},
  doi          = {10.1016/j.eswa.2025.129557},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129557},
  shortjournal = {Expert Syst. Appl.},
  title        = {When graph anomaly breaks the coherence: A multi-evidence approach with language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal joint subspace model for parkinson’s disease diagnosis. <em>ESWA</em>, <em>298</em>, 129556. (<a href='https://doi.org/10.1016/j.eswa.2025.129556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is an irreversible neurodegenerative disorder that significantly impacts patients’ lives. Accurate early diagnosis prediction is crucial for providing timely treatment to delay disease progression. However, current diagnostic methods predominantly rely on the experience and judgment of clinicians, introducing subjectivity and a lack of standardized, quantitative measures. Sparse subspace learning, as a machine learning technique, can extract critical information from multimodal data while addressing issues such as noise, high-dimensional complexity, and class imbalance. Our study utilizes longitudinal, multimodal neuroimaging data collected at multiple time points to develop a diagnostic model for PD. The approach involves extracting latent local features and leveraging deep learning techniques to generate a comprehensive global feature subset. Adaptive sparse selection is employed to reduce feature redundancy. Finally, support vector machine is used for classification and regression tasks, specifically for PD diagnosis and disease progression score prediction. Extensive experiments were conducted on the PPMI dataset, achieving an accuracy of 90.78 % for Scan Without Evidence of Dopaminergic Deficit (SWEDD) vs. Normal Control (NC) classification, 83.79 % for PD vs. NC, and 91.50 % for PD vs. SWEDD. The results demonstrate that the proposed method improves PD classification and prediction performance, showing promise for early diagnostic applications.},
  archive      = {J_ESWA},
  author       = {Haojie Song and Haijun Lei and Yukang Lei and Zhongwei Huang and Jiaqiang Li and Tianfu Wang and Peng Yang and Baiying Lei},
  doi          = {10.1016/j.eswa.2025.129556},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129556},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal joint subspace model for parkinson’s disease diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spectral relevance analysis approach to pattern recognition of financial time series. <em>ESWA</em>, <em>298</em>, 129555. (<a href='https://doi.org/10.1016/j.eswa.2025.129555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding patterns in financial time series is crucial for improving prediction accuracy in algorithmic trading and risk management. This paper presents a novel AI-based computer vision approach for classifying financial time series. Historical price sequences are transformed into Gramian Angular Difference Field (GADF) images and fed into a convolutional neural network (CNN) for pattern recognition. To interpret the CNN’s decision-making process, we apply Spectral Relevance Analysis (SpRAy), enabling the identification of distinct clusters based on relevance maps. Clustering the images according to their relevance profiles reveals groups with significantly higher predictive performance compared to the full dataset. The corresponding relevance patterns highlight favorable price movement structures and are identified via the associated clusters.},
  archive      = {J_ESWA},
  author       = {Christine Distler and Yarema Okhrin and Jonathan Pfahler},
  doi          = {10.1016/j.eswa.2025.129555},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129555},
  shortjournal = {Expert Syst. Appl.},
  title        = {A spectral relevance analysis approach to pattern recognition of financial time series},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector. <em>ESWA</em>, <em>298</em>, 129554. (<a href='https://doi.org/10.1016/j.eswa.2025.129554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object identification is one of the computer vision-based methods used in locating and labelling objects in images. Object detection has been greatly advanced as it is now applicable for detecting night vision images with great accuracy. Most accurate object detection at night can be useful in many applications like nighttime driving, regulating harsh traffic in harsh weather conditions, and surveillance. Object detection in normal conditions can be smoother, but low illumination and harsh weather can lead to low versatility. Images captured at night can reflect a lot of noise with low visual features. Due to its challenging nature, a highly effective object detection model is a challenge for high-level applications. Traditional models still face issues and challenges related to uneven light conditions, brightness variations, different light sources, and noisy backgrounds that need to be addressed. Thus, it is necessary to develop an object detection model for dealing with images with low illumination and varying light conditions. Hence, in this work, an effective object detection framework is implemented for night vision images. At first, from the standard datasets, the significant night vision images are fetched and fed into the proposed model as a Residual 3D Transformer-based YoloV8 with an Adaptive Gated Recurrent Unit (R3DT-YAGRU) for detecting the objects. This includes combining spatial–temporal modelling capabilities into YOLOv8, particularly using 3D transformers for improved feature extraction and an adaptive GRU to manage temporal dependencies at night. Here, the Modified Random Variable-based Dollmaker Optimization Algorithm (MRV-DOA), which is a metaheuristic algorithm motivated by the doll-making procedure. Also, it helps in balancing the exploration phase and exploitation phase to discover the best solutions and is used for tuning the parameters of the R3DT-YAGRU model. At last, the experimental validation is carried out for the recommended object detection process by comparing with other models to establish the supremacy of the suggested work. From the study, the suggested framework achieves an accuracy of 96%, leading to enhanced decision making and better accuracy than other conventional models. The work has prepared its implementation accessible at https://github.com/charlesvprabhu56/Object-Detection .},
  archive      = {J_ESWA},
  author       = {V.Charles Prabu and Queen Mary Vidya. M and V. Sathiyamoorthi and P. Durgadevi and M. Gowthami},
  doi          = {10.1016/j.eswa.2025.129554},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129554},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning diversified features for pulmonary hypertension detection using chest X-ray. <em>ESWA</em>, <em>298</em>, 129553. (<a href='https://doi.org/10.1016/j.eswa.2025.129553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional Computed Tomography (CT) scans and floatation catheters, chest X-ray offers an efficient, safe and timely examination paradigm, with broader range of scenarios (including intensive care units), for the detection of Pulmonary Arterial Hypertension (PAH). However, it is difficult to learn the variable radiological features of PAH from X-rays due to its low resolution and low contrast. To address the above issues, we propose a diversified features learning framework to fully explore the PAH-related representation from chest X-ray. We first employ a Chest Feature Enhancement Attention (CFEA) module to enhance the initial feature representation. Then, we employ the Deep Temporal Anti-Interference Metric Learning (TAIML) module to fully explore the PAH-related features. We incorporate the information on the temporal evolution of patients’ conditions. Specifically, a patient x , after undergoing treatment, may exhibit two possible states: x + (ill) and x − (cured). Therefore, we can define the distance d ( x , x + ) as the intra-class structural distance, and the distance d ( x , x − ) as the inter-class safe distance. Unlike existing metric learning, we adopt a new strategy: we push positive samples towards negative samples, but ensure distance between them is no less than d ( x , x − ) , thereby enhancing intra-class diversity while maintaining discriminability. Meanwhile, we ensure that the distance between positive samples is greater than d ( x , x + ) , thereby preserving the intra-class structure. Through these two steps, we can learn a diversified but discriminative representation of PAH. Comprehensive experiments showed the our model achieved an impressive accuracy of 86.27 % and an AUC of 0.857 in identifying PAH patients. The code is available at https://github.com/zgfdmn/PAH .},
  archive      = {J_ESWA},
  author       = {Chengjin Yu and Huanghui Wang and Yuanting Yan and Zhuyang Chu and Dongsheng Ruan},
  doi          = {10.1016/j.eswa.2025.129553},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129553},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning diversified features for pulmonary hypertension detection using chest X-ray},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data. <em>ESWA</em>, <em>298</em>, 129552. (<a href='https://doi.org/10.1016/j.eswa.2025.129552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the emergency triage has faced several challenges, including insufficient manual triage with physicians, limited medical resources contributing to incorrect triage, overcrowding in the emergency department (ED), and extended patient waiting time. Hence, the Medical Emergency prediction remains the major research area that identifies emergencies about specific diseases using the Medical Transcriptions (MT) provided by physicians. However, the existing methods face the challenges of handling the ambiguity of words, unstructured data, and increased computation complexity. Consequently, this research proposes the Tri-Head Attention-based Bidirectional Encoder Representations from Transformers enabled Distributed Bidirectional Long-Short Term Memory (TriHAtt-BERT-DBiLSTM) for predicting medical emergencies. Specifically, the proposed approach integrates the Tri-Head Attention mechanisms into BERT, which is further hybridized with the DBiLSTM model that offers the synergic strength of providing the dense feature representations to capture the complex dependencies, and enhancement of model ability with the structured parameters to facilitate the medical emergency prediction. Besides, the utilization of BERT in the proposed approach assists in capturing more complex language representations and further executes a better embedding representation of words. The TriHAtt-BERT-DBiLSTM model surpasses other state-of-the-art techniques and achieves 96.40% of accuracy, 96.12% of F1-score, 96.09% of precision, and 96.15% of recall for medical emergency prediction.},
  archive      = {J_ESWA},
  author       = {Amita Mishra and Sunita Soni},
  doi          = {10.1016/j.eswa.2025.129552},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129552},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing. <em>ESWA</em>, <em>298</em>, 129551. (<a href='https://doi.org/10.1016/j.eswa.2025.129551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contact ring seals (CRSs) used in electroplating processes during semiconductor manufacturing are susceptible to degradation through chemical etching, electrochemical dissolution, and mechanical wear mechanisms. Despite the implementation of state-of-the-art surface treatment and coating technologies to mitigate CRS corrosion, manual intervention remains frequently required to address this problem. Conventional static defect detection systems for CRSs rely on predefined regions of interest (ROIs) and threshold-based defect area calculations, with surface anomalies identified by comparing the percentage of defective areas within these ROIs. However, this approach exhibits detection failures for millimeter-scale defects, low-contrast anomalies, and geometrically irregular patterns, especially under complex or dynamic environmental conditions. To address these systematic detection failures, we developed a dynamic defect detection system for CRSs by integrating artificial intelligence and traditional computer vision algorithms, achieving a 5.2x improvement in defect detection sensitivity. This system achieved detection accuracy and recall values of over 99 % as well as a response time of 1.43 s average latency, thereby demonstrating a substantial performance improvement compared to a static system, which achieved a recall rate of 18.9 % on the adopted dataset. The system satisfies real-time processing requirements while substantially reducing the need for manual intervention in defect detection and increases production efficiency. Finally, the experimental results of this study indicated that the postprocessing approaches used in the developed system enabled it to flexibly adapt to the different requirements of various production environments.},
  archive      = {J_ESWA},
  author       = {Ting-Han Chen and Hsin-Hung Chou and Shuang Zou and Yu-Han Chen and Sun-Yuan Hsieh},
  doi          = {10.1016/j.eswa.2025.129551},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129551},
  shortjournal = {Expert Syst. Appl.},
  title        = {System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification. <em>ESWA</em>, <em>298</em>, 129549. (<a href='https://doi.org/10.1016/j.eswa.2025.129549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of land remote sensing using single-modal data has reached a bottleneck, which has spurred significant interest in the joint utilization of multimodal remote sensing data to enhance classification performance. However, existing methods exhibit limitations in extracting intricate local and global features. Furthermore, achieving effective information interaction and deep fusion between multimodal datasets remains an unresolved challenge. To address these issues, we propose a Complementary Information-Guided Interactive Fusion Network (CIGIF-Net) for the classification of hyperspectral image (HSI) and light detection and ranging (LiDAR) data. The core idea of our approach leverages the capability of Convolutional Neural Networks (CNNs) to extract local spatial features while utilizing the strengths of Transformers in modeling long-range dependencies. Furthermore, our method facilitates deep fusion by designing mechanisms for the interactive integration of multimodal local spatial features, complemented by guidance from multimodal data during long-range dependency modeling, thereby improving overall classification performance. Specifically, CIGIF-Net incorporates multiscale feature learning, interactive feature fusion, and the complementary information-guided attention mechanism. Initially, CNNs are used to learn multiscale local spatial features. Subsequently, we perform an interactive fusion of multimodal spatial information based on channel attention techniques. Finally, the complementary information-guided attention mechanism dynamically utilizes complementary insights to inform deeper attention distributions, which guide global feature construction and enable efficient information aggregation. This methodology allows for the comprehensive extraction and synergistic utilization of complementary information across multimodal datasets. Extensive experiments conducted on three widely recognized HSI and LiDAR datasets demonstrate that the proposed CIGIF-Net achieves superior classification performance.},
  archive      = {J_ESWA},
  author       = {Shufang Xu and Qiyuan Xue and Zhonghao Chen and Shuyu Fei and Hongmin Gao},
  doi          = {10.1016/j.eswa.2025.129549},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129549},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach. <em>ESWA</em>, <em>298</em>, 129544. (<a href='https://doi.org/10.1016/j.eswa.2025.129544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced Decision Support System (DSS) for long-term open-pit mine planning that integrates established optimization techniques—Large Neighborhood Search (LNS), Simulated Annealing (SA), and Dantzig-Wolfe decomposition—within a novel GPU-accelerated framework addressing geological uncertainty and computational complexity. The key methodological contributions include dynamic uncertainty modelling with time-dependent factors capturing geological confidence degradation and GPU-parallelized evaluation architecture enabling industrial-scale mine planning. Validation using 50,000 blocks across 10 geological scenarios demonstrates robust economic performance, achieving mean NPV of $1.514 billion with limited variability (standard deviation $16 million). The GPU-parallelized architecture achieves 29.6 % average computational speedup with peaks of 37 % compared to CPU implementations, enabling concurrent evaluation of 262,144 mining scenarios. Risk analysis reveals P90 Value-at-Risk of $1.488 billion, indicating strong downside protection. The system maintains profit margins exceeding 95 % across all scenarios with cumulative cash flow reaching $1.789.4 million by period 6. Narrow risk envelopes (P10-P90 spread <$60 M) demonstrate robust performance under uncertainty, providing mining companies with practical tools for risk-informed strategic decision-making.},
  archive      = {J_ESWA},
  author       = {Iman Rahimi},
  doi          = {10.1016/j.eswa.2025.129544},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129544},
  shortjournal = {Expert Syst. Appl.},
  title        = {A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment. <em>ESWA</em>, <em>298</em>, 129543. (<a href='https://doi.org/10.1016/j.eswa.2025.129543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of IoT devices in daily applications, securing them against intrusions has become increasingly critical. Domain adaptation (DA)-based intrusion detection is a promising approach that transfers knowledge from a source domain to improve detection in a target IoT domain. However, effective DA methods must address various types of domain heterogeneity - such as differences in feature representation, intrusion distribution, and attack strategies. Existing intrusion detection datasets rarely consider these aspects, limiting their utility for evaluating heterogeneous DA approaches. To bridge this gap, we introduce TriHID , a new dataset specifically designed to capture heterogeneities from three perspectives. We evaluate four types of DA-based IoT intrusion detectors - multi-source, semi-supervised, unsupervised, and open-set on TriHID. Experimental results demonstrate that TriHID enables robust training and comprehensive evaluation of DA-based intrusion detection methods in heterogeneous IoT settings.},
  archive      = {J_ESWA},
  author       = {Jiashu Wu and Yang Wang},
  doi          = {10.1016/j.eswa.2025.129543},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129543},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning. <em>ESWA</em>, <em>298</em>, 129542. (<a href='https://doi.org/10.1016/j.eswa.2025.129542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing environments, job shop scheduling systems are characterized by heightened complexity and ever-changing dynamics, often involving multi-objective optimization and the need to accommodate unanticipated events like new job insertions and uncertain machine availability, underscores the necessity for effective real-time multi-objective scheduling approaches. Therefore, to tackle the multi-objective dynamic flexible job shop scheduling problem (MODFJSP) involving new job insertions, this paper introduces an online scheduling framework called multi-head deep Q network (MHDQN), designed to simultaneously minimize both total tardiness and total machine idle time. The core architecture of MHDQN framework is an innovative multi-head network agent based on Dueling deep Q network (Deuling DQN), consisting of a shared network layer and objective-specific network layers. The shared network layer extracts and transforms the input global state features layer by layer, generating a high-dimensional, semantically rich shared feature. This provides a unified input foundation for the objective-specific network layers, which are responsible for extracting the specialized information related to each objective from the shared features and calculating the corresponding Q -values, thereby enabling the parallel optimization of each objective. Six combined scheduling rules are developed to form the action set, each incorporating both job and machine selection. An improved multi-objective action selection strategy is proposed, incorporating inverse sigmoid ϵ decay and Q -value maximum absolute (max-abs) normalization to optimize decision-making. Additionally, a multi-head network training mechanism leveraging the Double deep Q network (Double DQN) architecture has been developed. Extensive computational experiments demonstrate that the MHDQN outperforms widely used traditional scheduling rules, multi-objective metaheuristic algorithms, and other reinforcement learning (RL) based scheduling methods, showing significant advantages and strong generalizability in multi-objective optimization tasks.},
  archive      = {J_ESWA},
  author       = {Kai Li and Bao Zheng and Liping Xu and Fulong Xie and Zhicheng Wang},
  doi          = {10.1016/j.eswa.2025.129542},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129542},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain. <em>ESWA</em>, <em>298</em>, 129539. (<a href='https://doi.org/10.1016/j.eswa.2025.129539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing platelet supply chains poses significant challenges due to the product’s short shelf life, highly uncertain demand, and the critical nature of its medical use. Previous studies in the blood supply chain rely on fixed-order quantities and ignore collaborative inventory-sharing strategies, which can lead to either excessive waste or severe shortages. However, in many real-world situations, fixed order quantities are often insufficient to accommodate fluctuating demand, especially in healthcare systems. Moreover, existing distribution models in the literature often overlook the equitable allocation of services across hospitals, leading to disparities in access to critical healthcare resources. This study proposes a novel two-phase decision-making framework that integrates a fuzzy periodic review inventory model with a cluster-based reactive transshipment strategy to optimize platelet supply and distribution. In Phase I, a fuzzy periodic review model determines optimal order quantities under uncertain demand using a possibilistic chance-constrained programming approach. In Phase II, hospitals are clustered based on service levels, enabling equitable transshipment among facilities to reduce disparities and improve overall responsiveness. A real-world case study from Tehran province is used to evaluate the model’s effectiveness. Results show an approximate 6% reduction in total shortages and a 2% improvement in average service levels. The proposed framework offers actionable insights for healthcare managers aiming to enhance resilience, equity, and efficiency in critical medical supply chains.},
  archive      = {J_ESWA},
  author       = {Seyyed-Mahdi Hosseini-Motlagh and Mohammad Reza Ghatreh Samani and Hannaneh Kordhaghi},
  doi          = {10.1016/j.eswa.2025.129539},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129539},
  shortjournal = {Expert Syst. Appl.},
  title        = {A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-insights guided evolutionary algorithm for optimization. <em>ESWA</em>, <em>298</em>, 129538. (<a href='https://doi.org/10.1016/j.eswa.2025.129538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are a class of optimization algorithms inspired by the theory of biological evolution. They solve optimization problems by emulating the processes of natural selection. EAs produce abundant data during evolution, which contains valuable information that reflects their evolutionary patterns. Effectively utilizing this information can enhance the algorithms’ effectiveness and efficiency. Deep learning excels at extracting knowledge from data. Inspired by this, we propose a novel insights-infused framework that utilizes deep neural networks to learn the evolutionary processes of EAs and extract useful synthesis insights from the evolutionary data. These synthesis insights not only guide the algorithm to evolve in a better direction on the original problems, but also improve its performance on new problems. The choice of neural networks is important. During pre-training, to reduce the inductive bias introduced by human prior knowledge, we design an MLP model to process the data. Additionally, we develop a variable-length encoding method to enable MLP networks to handle variable-length data. To verify the transfer evolution ability of synthesis insights, we devise a self-evolution strategy that fine-tunes the network using only the data generated by the algorithm itself, without introducing any external knowledge, when dealing with new problems. Experimental results demonstrate that the synthesis insights extracted from the CEC2014 dataset guide the algorithms to evolve in a better direction for the CEC2014 problems, and in addition enhance their performance on new problems like CEC2017, CEC2022 and the real-world optimization problems.},
  archive      = {J_ESWA},
  author       = {Kun Bian and Juntao Zhang and Hong Han and Jun Zhou and Yifei Sun and Shi Cheng},
  doi          = {10.1016/j.eswa.2025.129538},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129538},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-insights guided evolutionary algorithm for optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MambaGen: Efficient visual representation learning for automatic radiology report generation. <em>ESWA</em>, <em>298</em>, 129537. (<a href='https://doi.org/10.1016/j.eswa.2025.129537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation focuses on producing comprehensive and clinically precise medical reports based on radiographic images, thereby improving medical efficiency and alleviating the burden on radiologists. Although existing deep learning methods have demonstrated superior performance, they are constrained by the local receptive field of convolutional neural networks and are inadequate for modeling long-range dependencies, making it challenging to detect critical lesion features in medical images. Recently, State Space Models (SSMs), particularly Mamba, have shown great potential in modeling long-range dependencies with linear computational complexity. Inspired by this, we propose MambaGen, the enhanced Mamba model specifically designed for radiology report generation tasks. Specifically, we design a Mamba-Visual Recalibration Module (MVRM), which utilizes a two-stage training strategy to effectively capture the efficient visual representation of medical images. This first stage combines convolutional layers with SSMs to model long-sequence dependencies and learn multi-level visual feature information. This second stage introduces local convolution and a channel attention mechanism to further recalibrate the local feature and mitigate channel redundancy. Comprehensive experiments on widely available datasets, such as IU X-Ray and MIMIC-CXR, demonstrate our model’s superior performance compared to existing methods, particularly with an improvement of 2.7 % on the BLEU-4 metric. The code is available at https://github.com/Eleanorhxd/MambaGen.git .},
  archive      = {J_ESWA},
  author       = {Xiaodi Hou and Xiaobo Li and Simiao Wang and Mingyu Lu and Hongfei Lin and Yijia Zhang},
  doi          = {10.1016/j.eswa.2025.129537},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129537},
  shortjournal = {Expert Syst. Appl.},
  title        = {MambaGen: Efficient visual representation learning for automatic radiology report generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction. <em>ESWA</em>, <em>298</em>, 129532. (<a href='https://doi.org/10.1016/j.eswa.2025.129532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling nitrogen oxide (NO x ) emissions from diesel vehicles is a critical environmental challenge. Advanced SCR strategies depend on accurate multistep forecasting of NO x and ammonia (NH 3 ), but existing models often struggle with error accumulation and the non-stationary dynamics of emissions data. In this work, we first establish a new benchmark for this task, confirming that handling data non-stationarity is essential for robust prediction. Building on this insight, we propose FiTformer, a novel Transformer architecture that adopts an encoder-only framework to jointly forecast both NO x and NH 3 concentrations, where we introduce Intra-series Temporal-Frequency Fusion mechanism to capture intrinsic emissions dynamics and Inter-series Covariate Interaction mechanism to model external influences. Validated on real-world engine data, FiTformer consistently outperforms baseline models across all evaluated prediction horizons, with up to 44.1 % MAE and 36.9 % SMAPE reductions in 24-step NO x prediction and similarly strong gains for NH 3 prediction, compared to the state-of-the-art baseline TimesNet. Its high computational efficiency (0.30G MACs and 8.3 ms/iter) along with robust generalization and high resilience to data imperfections, underscores its suitability for real-time embedded SCR control, enabling more effective strategies for NO x reduction and NH 3 slip minimization.},
  archive      = {J_ESWA},
  author       = {Yuhan Luo and Yujun Zhang and Ying He and Kun You and Wei Huang and Wenqing Liu and Hao Xie},
  doi          = {10.1016/j.eswa.2025.129532},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129532},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes. <em>ESWA</em>, <em>298</em>, 129530. (<a href='https://doi.org/10.1016/j.eswa.2025.129530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-limited epilepsy with centrotemporal spikes (SeLECTS) is the most common form of focal epilepsy in childhood, accounting for 20–25 % of all childhood epilepsy cases and may be associated with cognitive dysfunction and behavioral issues. Accurate detection and assessment of epileptic discharges in EEG signals, particularly the spike-wave index (SWI), are crucial for timely intervention and treatment. Manual analysis of EEG data is labor-intensive and prone to errors, underscoring the need for automated methods. In the present study, we propose a novel D ual-Str e am Sp a tial- S pectral- T emporal L arge model (DeaSTL) that leverages a large-scale EEG architecture to effectively capture the multidimensional characteristics of EEG signals associated with SeLECTS syndrome. Our model integrates multi-view temporal representations and spatial-spectral representations through a dual-stream approach, enhancing the learning of complex patterns in EEG data. We introduce the S JTU Se L ECTS E EG D ataset (SLED), a comprehensive EEG dataset from 212 patients diagnosed with SeLECTS, including annotations for abnormal discharge detection, wake-sleep period classification, and SWI estimation. Addressing the previously unexplored problem of SWI prediction, we provide a novel method for quantifying the severity of epileptic discharges during sleep. Extensive experiments demonstrate that our DeaSTL model significantly outperforms several state-of-the-art methods across multiple tasks, showcasing its potential for clinical application in assisting diagnosis and treatment planning.},
  archive      = {J_ESWA},
  author       = {Lin Zhang and Yun Ren and Fang Yuan and Xuqin Chen and Shikui Tu and Lei Xu},
  doi          = {10.1016/j.eswa.2025.129530},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129530},
  shortjournal = {Expert Syst. Appl.},
  title        = {An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic learning of sample ambiguity-driven sample weighting for medical image classification. <em>ESWA</em>, <em>298</em>, 129527. (<a href='https://doi.org/10.1016/j.eswa.2025.129527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have delivered impressive results in medical image classification tasks. However, their performance is still challenging in medical scenarios with limited data, where training set biases such as label noise or class imbalance impede model learning. Dynamic learning based sample weighting achieves adaptive adjustment of sample importance through learnable weight functions and shows great potential in improving model robustness. Nevertheless, existing methods directly employ model states such as loss value or training accuracy to evaluate sample importance, ignoring the role of ambiguous samples in model optimization. This limitation hinders the performance of dynamic learning based sample weighting in medical image classification. In this paper, we propose a new sample weighting approach based on sample ambiguity and dynamic learning for improving medical image classification, named DLSA-SW. We introduce a dual-space sample ambiguity method by evaluating the category proximity in the feature space and the prediction confidence in the label space. Subsequently, to dynamically calculate sample weights according to sample ambiguity, a learnable sample weighting network is developed to adaptively adjust the weights during training to guide the task model. DLSA-SW performs alternate optimization to enable mutual adaptation of the sample weighting network and the task network. We evaluate the effectiveness of our approach on three medical image classification benchmarks: PatchCamelyon for lymph node histopathology classification, ISIC 2020 for skin lesion classification, and MTC for medullary thyroid cancer classification. DLSA-SW outperforms existing state-of-the-art sample weighting methods on all three datasets and yields substantial improvements over methods without sample weighting. These results demonstrate the robustness and practical applicability of our approach in clinical diagnostic tasks.},
  archive      = {J_ESWA},
  author       = {Guanxiu Yi and Xiabi Liu and Ling Ma and Mengqiao Han and Lijuan Niu},
  doi          = {10.1016/j.eswa.2025.129527},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129527},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic learning of sample ambiguity-driven sample weighting for medical image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement. <em>ESWA</em>, <em>298</em>, 129526. (<a href='https://doi.org/10.1016/j.eswa.2025.129526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact manner of measuring heart rate variability (HRV) by deriving blood volume pulse (BVP) signals from facial videos. The performance of rPPG-based HRV measurement is challenging due to short-range noises (e.g., head movements) suppression and sufficient-duration BVP signal generation. Recent Transformer-based rPPG methods have shown advantages of global spatio-temporal feature modeling in eliminating noise and recovering high-quality BVP signals. However, these methods often face significant computational and memory constraints, limiting duration scalability of the generated BVP signals that might decrease HRV measurement performance. To address the above issue, this paper proposes a duration-scalable Transformer-based rPPG method, capable of global Long-range Spatio-Temporal modelling (LST), termed LST-rPPG, to generate high-quality BVP signals with a much longer duration. On the one hand, by employing spatial and temporal encoders, the original image-based rPPG issue is converted to a time-series problem. Besides, a sparse computation mechanism is integrated into the temporal encoder. This combination allows LST-rPPG to recover flexible-duration BVP signals, supporting continuous modeling of segments beyond 30 s with low computation and memory overhead. On the other hand, a dynamic loss function with stringent temporal constraints is designed to guarantee the quality of the generated BVP signals. Comprehensive experiments are performed on two public datasets, PURE and UBFC-RPPG, and the results demonstrate the feasibility of LST-rPPG for generating high-quality BVP signals with a much longer duration while requiring substantially fewer computational resources. Besides, LST-rPPG achieves at least the second-best results during all experiments.},
  archive      = {J_ESWA},
  author       = {Jiajie Li and Juan Cheng and Rencheng Song and Yu Liu},
  doi          = {10.1016/j.eswa.2025.129526},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129526},
  shortjournal = {Expert Syst. Appl.},
  title        = {LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel scheme integrating graph-based analysis and opposition-based learning for S-box optimization by population-based metaheuristics. <em>ESWA</em>, <em>298</em>, 129524. (<a href='https://doi.org/10.1016/j.eswa.2025.129524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-linearity of symmetric block cryptographic algorithms, which is crucial for resisting linear and differential cryptanalysis, depends on the design of substitution boxes. This work proposes a novel scheme, named GOM, combining opposition-based learning with graph-based representation to be integrated into three population-based metaheuristics. This scheme is applied to address the 8 × 8 S-box design problem. The GOM-enhanced metaheuristics improve population diversity and convergence, achieving a non-linearity of 112. Hardware simulations indicate that GOM-based designs require similar resources to AES, while side-channel evaluations confirm their resilience against power analysis attacks. Scalability is supported by successful results on 10 × 10 and 12 × 12 S-boxes. The design of GOM, leveraging generalizable components such as opposition-based learning and graph-based representations, suggests its potential applicability to other population-based metaheuristics and optimization problems.},
  archive      = {J_ESWA},
  author       = {Francisco González and Ricardo Soto and José M. Lanza-Gutiérrez and Broderick Crawford},
  doi          = {10.1016/j.eswa.2025.129524},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129524},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel scheme integrating graph-based analysis and opposition-based learning for S-box optimization by population-based metaheuristics},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking. <em>ESWA</em>, <em>298</em>, 129523. (<a href='https://doi.org/10.1016/j.eswa.2025.129523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding models have demonstrated strong performance in tasks like clustering, retrieval, and feature extraction while offering computational advantages over generative models and cross-encoders. Benchmarks such as MTEB have shown that text embeddings from large language models (LLMs) capture rich semantic information, but their ability to reflect code-level functional semantics remains unclear. Existing studies largely focus on code clone detection, which emphasizes syntactic similarity and overlooks functional understanding. In this paper, we focus on the functional consistency of LLM code embeddings, which determines if two code snippets perform the same function regardless of syntactic differences. We propose a novel data synthesis framework called Functionality-Oriented Code Self-Evolution to construct diverse and challenging benchmarks. Specifically, we define code examples across four semantic and syntactic categories and find that existing datasets predominantly capture syntactic properties. Our framework generates four unique variations from a single code instance, providing a broader spectrum of code examples that better reflect functional differences. Extensive experiments on three downstream tasks-code clone detection, code functional consistency identification, and code retrieval-demonstrate that embedding models significantly improve their performance when trained on our evolved datasets. These results highlight the effectiveness and generalization of our data synthesis framework, advancing the functional understanding of code.},
  archive      = {J_ESWA},
  author       = {Zhuohao Li and Wenqing Chen and Jianxing Yu and Zhichao Lu},
  doi          = {10.1016/j.eswa.2025.129523},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129523},
  shortjournal = {Expert Syst. Appl.},
  title        = {Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129522. (<a href='https://doi.org/10.1016/j.eswa.2025.129522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have demonstrated the effectiveness for hyperspectral image (HSI) classification, but still face challenges, such as insufficient exploitation of data structure information, limited labeled samples, and high susceptibility to noise and outliers. To address these issues, a semisupervised graph U-Net with graph convolutional long short-term memory is proposed for HSI classification, abbreviated as SSGU-Net. Specifically, we design a novel graph convolutional long short-term memory feature extractor to learn discriminative spatial-spectral joint features by simultaneously modeling the correlations in the spatial and spectral domains. Then, we develop a semisupervised graph U-Net with mutually inverse operation of the graph pooling and the graph unpooling modules which uses both labeled samples and unlabeled samples to train a well-parameterized network for HSI classification. In particular, to suppress the effects of noise and outliers, the graph pooling module is designed to selectively retain discriminative samples and fully learn the optimal correlation between these retained samples. Meanwhile, the graph unpooling module employs the local spatial context to reconstruct the reduced samples, thus restoring the pooled data to its original scale for classification task. Extensive experiments show the effectiveness of the proposed method, achieving overall accuracy gains of 5.22 %, 1.58 %, and 1.57 % over the state-of-the-art competitors on the Indian Pines, University of Pavia, and Houston datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jin-Yu Yang and Heng-Chao Li and Xin-Ru Feng and Feng Gao and Qian Du and Antonio Plaza},
  doi          = {10.1016/j.eswa.2025.129522},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129522},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems. <em>ESWA</em>, <em>298</em>, 129521. (<a href='https://doi.org/10.1016/j.eswa.2025.129521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet, building a multilingual dialogue generation system to attract more users while reducing costs in the global market has become increasingly important. However, current end-to-end multilingual approaches often face semantic disparity issues across languages. When given parallel queries with the same semantics but in different languages, the generated responses may vary in meaning across languages, which may greatly affect the stability and reliability of multilingual systems in different language scenarios. We attribute this issue to open-domain/model uncertainty and language differences. To mitigate this issue, we first propose a novel Anchor-based Semantic Constraint (ASC) designed to reduce semantic disparity across languages for Encoder-Decoder Transformers. ASC employs language-independent anchor signal to guide the behaviors in both the encoder and decoder, thereby reducing uncertainty. Additionally, ASC incorporates a two-stage tuning process to further minimize the impact of language differences by ensuring the encoder remains language-independent. Extensive experiments and in-depth analyses conducted on XDailyDialog demonstrate that ASC can effectively mitigate semantic disparity across languages and will not compromise dialogue response quality like the previous related baselines.},
  archive      = {J_ESWA},
  author       = {Sixing Wu and Jiahao Chen and Jiong Yu and Wei Zhou},
  doi          = {10.1016/j.eswa.2025.129521},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129521},
  shortjournal = {Expert Syst. Appl.},
  title        = {Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards CPU performance prediction: New challenge benchmark dataset and novel approach. <em>ESWA</em>, <em>298</em>, 129520. (<a href='https://doi.org/10.1016/j.eswa.2025.129520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CPU performance prediction based on hardware characteristics is crucial for system design and resource management. However, this field faces two major challenges. First, collecting real-world data is challenging due to the diversity of CPU products and the specialized nature of hardware characteristics. This field lacks a standard dataset with unified hardware characteristics, wide data coverage, and comprehensive benchmarks. Second, existing methods based on hardware simulation models or machine learning exhibit notable shortcomings, such as lengthy simulation test cycles and low prediction accuracy. To bridge these gaps, we first collect, preprocess, and standardize historical data from the 4th Generation Intel® Xeon® Scalable Processors across multiple benchmark suites to create a new dataset, named PerfCastDB. Subsequently, we design a deep learning based model called Nova CPU Performance Predictor (NCPP) as the baseline for this new dataset. The NCPP network is designed based on group attention mechanism. It effectively quantifies the implicit relationships between hardware characteristics within and across groups and comprehensively models the impact of various hardware characteristics on CPU performance prediction. We conduct comparative experiments using the proposed PerfCastDB dataset. Compared to existing approaches, NCPP achieves superior evaluation results, demonstrating its effectiveness. Furthermore, we have open-sourced part of the dataset and the NCPP network code to facilitate subsequent research. The resources can be accessed at https://github.com/xiaoman-liu/NCPP .},
  archive      = {J_ESWA},
  author       = {Xiaoman Liu},
  doi          = {10.1016/j.eswa.2025.129520},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129520},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards CPU performance prediction: New challenge benchmark dataset and novel approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Glyph graph isomorphism network for structure recognition of oracle bone inscription. <em>ESWA</em>, <em>298</em>, 129519. (<a href='https://doi.org/10.1016/j.eswa.2025.129519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure recognition of oracle bone inscription glyphs plays an important role in studying the evolutionary process of oracle bone inscriptions and the history of the Shang Dynasty. Currently, most methods have decomposed oracle bone inscription glyphs into multilevel features, which are used to recognize hierarchical feature fusion. This strategy cannot recognize the primitive internal structures of keypoints, strokes, and components. Moreover, mainstream graph neural networks cannot fully utilize the rich structural information of oracle bone inscription glyphs, resulting in their inability to meet the needs of structure recognition. So we have developed a graph structure recognition method to implement structure recognition of oracle bone inscription glyphs. A graph extraction method is given to get the structure of oracle bone inscription glyphs; each graph structure’s representation vector can be learned by a glyph graph isomorphism network, which is developed to recognize the graph of oracle bone inscription glyphs to enhance the discriminability representation of the structure. Our model has achieved advanced results across structure recognition experiments in the HWOBC dataset and the Oracle-50K dataset.},
  archive      = {J_ESWA},
  author       = {Zhan Zhang and Hanbin Liu and Xingkun Zhang and Yiyuan Wang and Feng Gao and An Guo and Han Zhang and Qingju Jiao and Bang Li and Yongge Liu},
  doi          = {10.1016/j.eswa.2025.129519},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129519},
  shortjournal = {Expert Syst. Appl.},
  title        = {Glyph graph isomorphism network for structure recognition of oracle bone inscription},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation. <em>ESWA</em>, <em>298</em>, 129516. (<a href='https://doi.org/10.1016/j.eswa.2025.129516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overweight and oversized transport (O&OT) has become one of the most critical elements of project logistics, driven by advancements in transportation and lifting technologies that now allow high-volume loads to be moved across long distances. This type of transportation operation, also called abnormal transportation, is greatly affected by technical factors such as the weight and geometry of the load, road surface, axle load limitations, slope, and ground strength, as well as external variables such as weather conditions, traffic density, and legal regulations. In planning and operational processes, Decision-Makers (DMs) and practitioners who plan and execute operations without adequately considering these factors and variables can lead to delays in operations, serious risks, and loss of productivity. This research proposes a flexible decision support model that integrates Step-wise Weight Assessment Ratio Analysis (SWARA) and Logarithmic Percentage Change-driven Objective Weighting (LOPCOW), and a ranking technique; i.e., Mixed Aggregation by Comprehensive Normalization Technique (MACONT) techniques to address the decision problems related to route selection, one of the most critical problems in transporting heavy and bulky loads, and to produce reasonable solutions. The proposed model significantly reduces information losses by processing subjective and objective information and integrating subjective (SWARA) and objective (LOPCOW) methods. Unlike traditional ranking approaches, the MACONT method combines three different normalization techniques to determine the ranking performance of alternatives. In this way, it provides more reliable and accurate results by reducing the deviations of the results provided by the single normalization technique. In addition, it shows each alternative’s good and bad performance compared to the others and is more convincing about the results obtained. According to the results obtained by applying the proposed model, fuel consumption (0.096) is determined as the most effective and critical factor in selecting the route on which heavy and bulky loads will be transported. In this context, choosing routes that allow lower fuel consumption can contribute to reducing carbon emissions and external costs arising from transportation. The extensive robustness and validation check to test the proposed model prove that the proposed model is a reliable, robust, and practical decision-making tool for making reasonable and rational decisions in O&OT.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Pradip Kundu and Hande Küçükönder and Gürkan Doğan and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129516},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129516},
  shortjournal = {Expert Syst. Appl.},
  title        = {An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EvoMapX: An explainable framework for metaheuristic optimization algorithms. <em>ESWA</em>, <em>298</em>, 129514. (<a href='https://doi.org/10.1016/j.eswa.2025.129514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based optimization algorithms (POAs) are widely adopted solutions for NP-hard and complex high-dimensional optimization problems. However, their internal dynamics often remain opaque, limiting trust and insight into how solutions evolve. This paper introduces EvoMapX, a novel explainable framework designed to interpret the internal dynamics of population-based optimization algorithms. EvoMapX includes three interpretable structures to visualize evolutionary optimization dynamics: the Operator Attribution Matrix (OAM) quantifies the contribution of specific operators over iterations; the Population Evolution Graph (PEG) traces the ancestry and transformation of candidate solutions; and the Convergence Driver Score (CDS) identifies which operators drive convergence, helping interpret why the algorithm improved. EvoMapX was evaluated across four POAs on the CEC 2021 test suite in order to demonstrate how it reveals meaningful textual and graphical insights into algorithm behavior. EvoMapX paves the way for interpretable metaheuristic optimization. The source code of EvoMapX is available at https://www.github.com/Bilal20252025/EvoMapX},
  archive      = {J_ESWA},
  author       = {Bilal H. Abed-Alguni},
  doi          = {10.1016/j.eswa.2025.129514},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129514},
  shortjournal = {Expert Syst. Appl.},
  title        = {EvoMapX: An explainable framework for metaheuristic optimization algorithms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set. <em>ESWA</em>, <em>298</em>, 129513. (<a href='https://doi.org/10.1016/j.eswa.2025.129513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random permutation set (RPS) extends Dempster-Shafer evidence theory by incorporating event order information, providing a powerful framework for modeling uncertainty. However, existing orthogonal sum methods within the RPS framework may encounter loss of order information and counterintuitive belief distribution during permutation event fusion. To address these two issues, this paper proposes a new method termed belief-distance-based orthogonal sum (BDOS). BDOS operates through three core mechanisms: order-information preservation via mathematical constructs like order-space and inverse mapping; belief-value weighting that prioritizes events with high belief mass for rational outcomes; and element-distance weighting that incorporates dissimilarity among permutations to improve ordinal accuracy. Numerical examples validate the effectiveness of BDOS in permutation event fusion, with comparative results demonstrating its advantages in order retention and belief distribution. Furthermore, BDOS is applied to threat assessment, illustrating its rationality and effectiveness in handling uncertainty and threat ranking.},
  archive      = {J_ESWA},
  author       = {Xiaoyan Su and Xu Chen and Hong Qian and Cheng Jiang},
  doi          = {10.1016/j.eswa.2025.129513},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129513},
  shortjournal = {Expert Syst. Appl.},
  title        = {BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks. <em>ESWA</em>, <em>298</em>, 129510. (<a href='https://doi.org/10.1016/j.eswa.2025.129510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objective With the rapid growth in the number of medical images, the need for content- based medical image retrieval (CBMIR) in clinical aid diagnosis is becoming increasingly important. Most current content-based CT image similarity retrieval methods use the entire CT image, ignoring the fact that the localized lesion region is the main target of similarity retrieval; Methods To address this issue, the paper proposes a fine-grained similarity retrieval method for lung CT images based on image block( IB ) similarity matching, taking lung CT images as an example. In this method, two enabling techniques are introduced: 1) a hybrid Convolution and Vision Transformer Model(CVTM) that effectively captures both local texture and global context features of lesion regions; 2) the iDS high-dimensional index designed to accelerate retrieval among IB ; Results With the aid of these techniques, fine-grained similarity retrieval optimization of lung CT images can be achieved, which facilitates more accurate lesion-level comparison and supports clinical decision-making; Conclusions Extensive experiments are conducted to indicate that the proposed fine-grained similarity retrieval method achieves excellent performance, with a mAP of 91.33%. Meanwhile, the retrieval efficiency of the iDS high-dimensional index is about 150% higher than that of sequential retrieval, especially when the retrieval radius is large and the database size is substantial.},
  archive      = {J_ESWA},
  author       = {Yi Zhuang and Jiayu Zhang and Yujia Ge and Nan Jiang},
  doi          = {10.1016/j.eswa.2025.129510},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129510},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traffic prediction using an active causality recurrent graph convolutional network. <em>ESWA</em>, <em>298</em>, 129506. (<a href='https://doi.org/10.1016/j.eswa.2025.129506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of our daily lives is significantly influenced by traffic conditions, highlighting the importance of incorporating complex spatiotemporal dependencies in interconnected traffic data for effective prediction. Although recent advancements have demonstrated prediction accuracy using graph convolutional networks, their depends heavily on the accuracy of the graph structures that represent the spatial relationships within the traffic network. To address this challenge, we introduce a novel approach to traffic prediction, the Active Causal Recurrent Graph Convolution Network (ACRGCN), as shown in Fig. 2. ACRGCN offers a new framework that effectively integrates a causal-embedded approach for traffic prediction, leveraging both structural and feature information from correlated traffic time series. Additionally, it incorporates a time-varying dynamic Bayesian network to capture the intricate spatiotemporal topology of traffic data. The model extracts spatiotemporal dependencies from traffic signals using the Active Causality Graph Recurrent Module (ACGRM), while efficiently modeling nonlinear traffic propagation patterns. Furthermore, ACRGCN employs a deep learning-based module that functions as a hyper-network, progressively generating dynamic causal graphs. Finally, extensive experiments on multiple real-world traffic graph datasets validate ACRGCN, and the results demonstrate its superiority over state-of-the-art method},
  archive      = {J_ESWA},
  author       = {Jinde Zhu and Junhao Yuan and Fulan Ye and Trong-The Nguyen and Ruoxi Wang and Wu Zeng and Chien-Chun Liu},
  doi          = {10.1016/j.eswa.2025.129506},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129506},
  shortjournal = {Expert Syst. Appl.},
  title        = {Traffic prediction using an active causality recurrent graph convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system. <em>ESWA</em>, <em>298</em>, 129502. (<a href='https://doi.org/10.1016/j.eswa.2025.129502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical computing architecture of cloud-edge-client (CEC) formed with the combination of cloud computing and edge computing can provide processing, storage and low-latency services close to end devices. To protect data privacy, federated learning (FL), as a novel intelligent edge computing framework with localized training mechanisms, has been integrated into edge computing to form a system called CEC-FL and is widely studied. However, they are susceptible to potential poisoning attacks. Existing poisoning attack methods are mostly explored by performing malicious operations on training samples or labels directly and implementing corresponding defense strategies: they are designed to ignore the label transferability and diverse attack environments and are not work against stealthy security threats, mainly because they do not take into account the inherent vulnerabilities of the attack environment. Yet few general defense schemes have been developed. In response to the above vulnerabilities, in this work, we explore a B arycenter Po isoning method with L abel T ransferability (BPoLT) initiated by malicious attackers, resulting in a dynamic attack capability on the CEC-FL system. To address poisoning attacks, we provide a two-phase defense algorithm Res isting L abel T ransferability Pois oning called ResLT-Pois to distinguish malicious attackers from benign participants. Extensive experimental results demonstrate that our scheme is feasible and effective in dealing with the vulnerability of the CEC-FL system.},
  archive      = {J_ESWA},
  author       = {Yaru Zhao and Yihao Cao and Jianbiao Zhang and Zhaoqian Zhang and Weiru Wang},
  doi          = {10.1016/j.eswa.2025.129502},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129502},
  shortjournal = {Expert Syst. Appl.},
  title        = {Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting. <em>ESWA</em>, <em>298</em>, 129498. (<a href='https://doi.org/10.1016/j.eswa.2025.129498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting faces significant challenges due to the variability and complexity of real-world data. Traditional methods often require manual adjustments of wavelet transform parameters, which are labor-intensive and prone to over-fitting or inadequate feature extraction. To address these limitations, this study proposes SAMForecast, a novel hybrid model that integrates Adaptive Wavelet Transform, self-attention mechanisms, and the selective state space model. We introduce an Adaptive Wavelet Block that dynamically adjusts decomposition levels and basis functions using a Mixture of Experts network and lifting scheme, eliminating the need for manual parameter tuning. Furthermore, the model deeply integrates the attention mechanism of the Transformer architecture, leveraging its advantages in capturing complex dependencies to identify correlations between time series data. By combining self-attention with Mamba, SAMForecast effectively captures both global dependencies and local key features in time series, enhancing robustness against noise and redundant information. SAMForecast demonstrates promising performance in multivariate time series forecasting tasks, showcasing an average 2 % performance improvement compared to existing models across datasets in energy, transportation, and other fields. The code is available at https://github.com/Kiki-V/SAMForecast-main .},
  archive      = {J_ESWA},
  author       = {Dunlu Peng and Qiqi Lin},
  doi          = {10.1016/j.eswa.2025.129498},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129498},
  shortjournal = {Expert Syst. Appl.},
  title        = {SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting. <em>ESWA</em>, <em>298</em>, 129497. (<a href='https://doi.org/10.1016/j.eswa.2025.129497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate PM2.5 prediction is crucial for effective environmental management and public health protection, yet current models show limited dynamic adaptability to complicated air pollution scenarios. Robust models are essential to support timely interventions in response to sudden pollution events or rapidly changing air quality patterns. However, existing models predominantly rely on predefined graph structures and pairwise spatial relationships, limiting their ability to capture the complex and dynamic interactions inherent in PM2.5 pollution. Furthermore, such models often assume equal contributions from neighboring nodes, neglecting heterogeneity and compromising predictive accuracy. To address these limitations, we propose an Adaptive Hypergraph-based Convolution Network with a Dual Spatiotemporal Attention mechanism (AHCN-DA) for PM2.5 forecasting. This framework leverages representation learning and hypergraph structures to capture and integrate pairwise as well as higher-order spatial interactions, producing richer spatial-feature representations. The dual spatiotemporal attention mechanism dynamically assigns time-varying weights to neighboring nodes based on their relevance to target nodes, effectively mitigating the impact of irrelevant inputs. Additionally, AHCN-DA integrates a dilated convolution network with multi-scale kernels to capture temporal patterns effectively across varying scales. Extensive experiments on the 2023 China National Air Quality Dataset show significant improvements in predictive accuracy, particularly in enhancing the proportion of high-precision monitoring stations, with an R 2 of 0.9224, outperforming baseline models. Our findings underscore the effectiveness of AHCN-DA in enhancing prediction accuracy under complex pollution response patterns, contributing to more informed decision-making in environmental management.},
  archive      = {J_ESWA},
  author       = {Haipeng Gao and Chonghui Qian and Yang Su and Wei Zhang and Hengjun Huang},
  doi          = {10.1016/j.eswa.2025.129497},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129497},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans. <em>ESWA</em>, <em>298</em>, 129496. (<a href='https://doi.org/10.1016/j.eswa.2025.129496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial team games represent scenarios where cooperation and competition coexist and hold numerous applications in the real world. These scenarios are particularly challenging due to asymmetric information among team members and limited communication capabilities. Fictitious team-play extend self-play algorithms to these scenarios, offering a novel approach to obtain equilibrium. However, it depends on normal-form team plans, which expand exponentially with game size, significantly constraining their applicability in large games. To overcome the challenge of computing equilibrium in large scale imperfect information team games, we propose a team self-play algorithm that utilizes refined team plans. Specifically, we pre-solve the equilibrium in a perfect recall environment to extract essential team plans from the original strategy space. To adapt these plans to an imperfect recall environment, we construct an auxiliary game with transformed ex ante coordinated information based on the original game and then solve equilibrium in auxiliary game to derive equilibrium for the original game. The experiments demonstrate the effectiveness of our team self-play algorithm in eight different Kuhn poker scenarios. Compared to existing team self-play algorithms, our method efficiently handles large games and exhibits superior convergence compared to reinforcement learning based algorithms. Additionally, our experiments offer valuable insights and guidance on adapting equilibrium strategies from perfect recall environments to those with imperfect recall.},
  archive      = {J_ESWA},
  author       = {Jinheng Xiao and Chen Qiu and Yingying Xu and Jiajia Zhang and Shuhan Qi and Xuan Wang},
  doi          = {10.1016/j.eswa.2025.129496},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129496},
  shortjournal = {Expert Syst. Appl.},
  title        = {Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images. <em>ESWA</em>, <em>298</em>, 129490. (<a href='https://doi.org/10.1016/j.eswa.2025.129490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma detection identifies the early signs of eye conditions that can lead to vision loss by analyzing the retinal images to detect abnormalities, such as increased intraocular pressure, changes in the optic nerve head, or structural alterations in the retina. The challenges faced by the existing models include the difficulty in detecting subtle features, variability in image quality, and complex patterns that may resemble normal variations. Moreover, the traditional models struggle to adapt to the evolving patient data, capture long-term dependencies, and often suffer from lower accuracy. Hence, this research proposes the Proactive Hybridized Bidirectional Long Short-Term Memory (BiLSTM) model for Glaucoma detection. The proactive hybridized BiLSTM model is designed to enhance the detection of glaucoma by processing the retinal images. The proactive hybridized BiLSTM model enables the model to capture complex temporal dependencies and relationships within the data, which are crucial for identifying subtle patterns indicative of glaucoma, for which multifaceted feature extraction is employed. Moreover, the Proactive Hybridized BiLSTM model adapts to dynamic changes in the data to learn and predict glaucoma-related features, ultimately improving detection performance over time. The proposed Proactive hybridized BiLSTM model attains higher accuracy, sensitivity, and specificity of 96.65%, 96.51%, and 96.79% using the OCT and FUNDUS image dataset.},
  archive      = {J_ESWA},
  author       = {M.Kiran Mayee and M.Humera Khanam and Shaik Lathifa Tabasum},
  doi          = {10.1016/j.eswa.2025.129490},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129490},
  shortjournal = {Expert Syst. Appl.},
  title        = {Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks. <em>ESWA</em>, <em>298</em>, 129487. (<a href='https://doi.org/10.1016/j.eswa.2025.129487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current deep learning methods for community detection in attributed networks face a critical limitation: they often fail to identify communities that are both structurally cohesive and semantically similar, thereby falling short of the balance typically observed in human-labeled partitions. This shortcoming stems from the absence of explicit mechanisms to jointly optimize these two objectives. In this paper, this challenge is addressed by proposing Deep Balanced Community Detection (DBCD), a novel unsupervised framework for community detection that balances topology and semantics. DBCD first constructs a powerful topology-semantic clustering consensus by integrating insights from both structural and attribute spaces. This consensus then steers a Graph Neural Network to simultaneously maximize global neural modularity and local cross-view consistency, while adaptively determining the number of communities. Extensive experiments reveal a striking result: DBCD consistently discovers communities that surpass the topology-semantic balance of the ground truth across multiple real-world networks. An empirical Pareto frontier analysis further validates that DBCD achieves a non-dominated solution, establishing it as a strong competitor among state-of-the-art methods. The source code of DBCD is available at https://github.com/wy980125/DBCD .},
  archive      = {J_ESWA},
  author       = {Yan Wang and Yupeng Liu and Xiaojie Sun and Jun Fu},
  doi          = {10.1016/j.eswa.2025.129487},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129487},
  shortjournal = {Expert Syst. Appl.},
  title        = {DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Network traffic forecasting with transfer learning-based algorithm for long continuous missing data. <em>ESWA</em>, <em>298</em>, 129484. (<a href='https://doi.org/10.1016/j.eswa.2025.129484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate network traffic forecasting is critical for power dispatch networks. Network traffic forecasting aims to use historical data to predict future network traffic trends. Different from other networks, the traffic data of the power dispatch network is mainly composed of the port traffic from routers and switches. However, network accidents in power enterprises can cause long periods of missing network traffic data, reducing the number of learning samples for network traffic prediction models and making the forecasting results unreliable. Due to the long periods of missing data, this paper uses transfer learning (TL) to impute missing data with the knowledge from a relevant task, which has ample samples. However, the imputation result contains complex source and target data characteristics. Therefore, this paper introduces the idea of frequency decomposition to decompose the imputation results into different sub-sequences through variational mode decomposition (VMD). Additionally, this paper uses long short-term memory (LSTM) networks to extract the potential features of decomposition results. Finally, this paper combines TL, VMD, and LSTM to design the TL-VMD-LSTM algorithm. The effectiveness of the proposed algorithm is validated using inflow and outflow traffic data from two State Grid Corp. of China networks. The results demonstrate that TL-VMD-LSTM has excellent generalization performance, with mean absolute percentage errors (MAPEs) of 0.380 % and 0.734 % for the Provincial access network and Information region network, respectively.},
  archive      = {J_ESWA},
  author       = {Yang Yang and Zhihao Chen and Yuchao Gao and Zijin Wang and Zhe Ding and Jinran Wu},
  doi          = {10.1016/j.eswa.2025.129484},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129484},
  shortjournal = {Expert Syst. Appl.},
  title        = {Network traffic forecasting with transfer learning-based algorithm for long continuous missing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional multi-objective feature selection with niche-based binary differential evolution. <em>ESWA</em>, <em>298</em>, 129478. (<a href='https://doi.org/10.1016/j.eswa.2025.129478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a critical step in machine learning and data mining, aiming to identify the most relevant features from a dataset to improve model performance while reducing computational costs. In high-dimensional data, as the dimensionality of data increases rapidly, feature selection faces an enormous search space, limiting the efficiency and effectiveness of traditional methods. To address these challenges, multi-objective optimization algorithms have emerged as a promising strategy for feature selection due to their ability to optimize multiple conflicting objectives simultaneously. We propose a niche-based binary differential evolution algorithm (MONBDE) for high-dimensional multi-objective feature selection. MONBDE enhances feature selection performance through several mechanisms: a niche-based binary differential evolution operator, redundant solution repair mechanism and an environmental selection strategy. In experiments, the proposed algorithm was compared with five advanced multi-objective optimization algorithms and tested on 15 benchmark datasets using three common metrics. Experimental results show that the MONBDE algorithm outperforms comparative algorithms in terms of classification accuracy and feature subset size across most datasets. The proposed strategy effectively eliminates redundant and irrelevant solutions in feature selection, leading to a significant improvement in model classification performance.},
  archive      = {J_ESWA},
  author       = {Xuezhi Yue and Xiang Zuo and Pengfei Ling and Chao Xiong and Hu Peng and Yuan Zeng},
  doi          = {10.1016/j.eswa.2025.129478},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129478},
  shortjournal = {Expert Syst. Appl.},
  title        = {High-dimensional multi-objective feature selection with niche-based binary differential evolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation. <em>ESWA</em>, <em>298</em>, 129477. (<a href='https://doi.org/10.1016/j.eswa.2025.129477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and rapid segmentation of the clinical target volume (CTV) is essential for cervical cancer radiotherapy. However, due to the soft boundaries of CTV, complex connections with surrounding tissues, and high interpatient variability, existing deep learning methods still face significant challenges, particularly for image slices that lack clear boundary information or where applicators are distant from CTV edges. Hence, we introduce DFCNet, a dual-path fusion network with cross-slice consistency constraints for CTV segmentation. The first path employs a dual-stream intra-slice feature encoding module to capture local and inter-regional details, thereby refining boundary delineation amidst the complex interplay with adjacent tissues. The second path integrates a cross-slice consistency constraint module to address soft boundaries and high interpatient variability, while ensuring the coherence and smoothness of the segmentation results. A feature fusion and decoding module combines semantic features from both paths, improving CTV region accuracy. Tests on 432 cervical cancer brachytherapy cases show DFCNet outperforms eighteen state-of-the-art segmentation methods, with Dice score improvements over two percentage points. The second path and feature fusion module can enhance other U-Net-based models, boosting their CTV segmentation performance. DFCNet excels in high-precision CTV segmentation, particularly for challenging slices, demonstrating its potential to improve cervical cancer radiotherapy accuracy, efficiency, and patient outcomes.},
  archive      = {J_ESWA},
  author       = {Mingxu Huang and Deyu Sun and Chaolu Feng and Ming Cui and Dazhe Zhao and Yuhua Gao},
  doi          = {10.1016/j.eswa.2025.129477},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129477},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users. <em>ESWA</em>, <em>298</em>, 129466. (<a href='https://doi.org/10.1016/j.eswa.2025.129466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of data, numerous e-commerce platforms are actively collecting consumer data to obtain business insights. However, consumers and merchants on platforms exhibit diverse attribution behaviors, including single-homing and multi-homing (access to only one platform/multiple platforms), not only affecting the platform’s market scale but also complicating their data provision strategies and data pricing strategies. Inspired by this practice, this paper considers varying attribution behaviors and studies the data operation strategies of competitive platforms. By constructing a two-period game model, we capture the entire process of platform’s data collection and provision, and solve the equilibrium decisions by reverse solution method. This research aims to identify the impact of attribution behaviors on platforms’ data strategies, thereby filling the gap in analyzing this issue from the perspective of two-sided platforms. Results show that when both groups of users (consumers and merchants) are multi-homing, platform facing higher operational costs may benefit more from implementing low data provision but high data pricing strategy, while more cost-efficient platform may choose the opposite strategy. This strategy is still applicable when only one group of users (consumers) becomes single-homing. However, once both groups of users are single-homing, both platforms’ strategies will change. Specifically, when merchant’s cross-side network effect (CNE) intensity is relatively low (high), compared with less cost-efficient platform, platform enjoying cost efficiencies should provide more (less) data at a relatively high (low) price. Moreover, platforms should cautiously provide data when both groups of users are single-homing, as it may hurt profits.},
  archive      = {J_ESWA},
  author       = {Wei Chen and Yijia Hu and Ronghua Sui and Zili Guan and Yi Liu},
  doi          = {10.1016/j.eswa.2025.129466},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129466},
  shortjournal = {Expert Syst. Appl.},
  title        = {Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration. <em>ESWA</em>, <em>298</em>, 129465. (<a href='https://doi.org/10.1016/j.eswa.2025.129465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the multi-trip vehicle routing problem with time windows (MTVRPTW) and its variants have been extensively studied, their application in natural disaster contexts remains underexplored. This study addresses this gap by developing a model and solution algorithm for the MTVRPTW with limited trip duration (MTVRPTW-LD), tailored to emergency supplies distribution in the early post-disaster phase. First, we replace the service-dependent loading time in traditional models with service-dependent unloading time and formulate an MTVRPTW-LD model to minimize total operational time, encompassing travel, service, and unloading times, based on the characteristics of emergency supplies distribution. Furthermore, a more practical method for calculating travel time is proposed to enhance the model’s applicability. Subsequently, a branch-and-price algorithm is designed to solve the MTVRPTW-LD model, in which the cumulative relative deprivation cost (CRDC) is introduced to improve equity in emergency supplies distribution. Finally, we conduct numerical experiments on Solomon instances and test instances generated based on emergency scenarios. The results show that, in the test instances, incorporating CRDC can improve the equity by up to 34.3 %.},
  archive      = {J_ESWA},
  author       = {Longfei Fan and Zhongming Wu and Zaiwu Gong and David Z.W. Wang},
  doi          = {10.1016/j.eswa.2025.129465},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129465},
  shortjournal = {Expert Syst. Appl.},
  title        = {Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy. <em>ESWA</em>, <em>298</em>, 129460. (<a href='https://doi.org/10.1016/j.eswa.2025.129460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pareto set (PS) of a continuous multi-objective optimization problem exhibit a distribution along a low-dimensional manifold structure. This regularity property significantly contributes to generating high-quality offspring in large-scale multi-objective evolutionary algorithms (LSMOEAs). However, conventional regularity model-based algorithms face several challenges when dealing with large-scale multi-objective optimization problems (LSMOPs), including high computational costs for modeling, difficulty in capturing the true PS structure, and neglecting individual directional information. To address these challenges, we propose a dual-information offspring reproduction strategy that considers both the distribution information of the population and the directional information of the outstanding individuals. Specifically, this strategy comprises a sampling approach based on an augmented regularity model specifically designed for LSMOPs. Leveraging this model, we explore and exploit the decision space to sample a promising set of solutions. Additionally, the strategy also involves a search method based on competitive learning among individuals. By assigning a positive evolutionary direction to losing solutions, we update the losing solutions to generate high-quality offspring. We continuously refine the proposed regularity model to approximate the true PS more closely. In extensive experiments on large-scale multi-objective benchmark functions, we compare our algorithm with eight state-of-the-art algorithms. The results demonstrate that our approach excels in handling LSMOPs.},
  archive      = {J_ESWA},
  author       = {Ying Wu and Ziliang Du and Gonglin Yuan and Zhenzhou Tang and Ferrante Neri and Yaqing Hou},
  doi          = {10.1016/j.eswa.2025.129460},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129460},
  shortjournal = {Expert Syst. Appl.},
  title        = {Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning. <em>ESWA</em>, <em>298</em>, 129448. (<a href='https://doi.org/10.1016/j.eswa.2025.129448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying product defects and process anomalies in manufacturing processes is a critical task for product quality and system stability. Although the existing unsupervised anomaly detection methods do not require the annotation of anomalies, they are difficult to deal with the zero-shot scenario faced by multi-variety and small-batch production where there is no available data. In addition, many zero-shot detection algorithms need to represent the image features in tensor form with multiple local feature vectors, and then measure each local feature to infer the overall anomaly of the object. In this paper, we propose GlobalCLIP, a novel approach for zero-shot anomaly detection using only global feature vectors to enhance performance. Specifically, we use CLIP model to aggregate the global features, and design two kinds of adaptive modules from the error level and uncertainty level to realize the series integration of different discriminant models. The adaptive modules encourage the model to learn both normal and abnormal patterns with different granularity, and the self-cyclic training progressively improves model performance. Experiments show that compared to many unsupervised/weakly supervised methods, the performance of GlobalCLIP maintains its advantage even without known samples, and achieves significant improvement over available zero-shot methods.},
  archive      = {J_ESWA},
  author       = {Haoyuan Shen and Enrico Zio and Jiawei Xiong and Yizhong Ma},
  doi          = {10.1016/j.eswa.2025.129448},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129448},
  shortjournal = {Expert Syst. Appl.},
  title        = {GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Key performance indicator-related process monitoring for irregular scenarios with incomplete data. <em>ESWA</em>, <em>298</em>, 129440. (<a href='https://doi.org/10.1016/j.eswa.2025.129440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industries exhibit irregular characteristics due to factors such as mode transitions, incomplete data and outliers. Accurate monitoring of key performance indicators (KPIs) in irregular processes is essential for improving product quality and reducing scrap rates. This paper proposes a novel KPI-related process monitoring method that leverages the multiple kernel learning (MKL) technique, designed specifically for irregular scenarios with incomplete data. First, a novel MKL-based nonlinear matrix completion is proposed that utilizes a hierarchical strategy-based algorithm to estimate the missing values in incomplete data and the linear coefficients of multiple kernels. In addition, the corresponding convergence analysis is given. Based on the estimated completed data matrix, a novel MKL-based feature correlation analysis is proposed for indirect prediction of KPIs. Two statistics are established for detecting KPI-related and KPI-unrelated faults, respectively. A numerical case and an industrial example demonstrate that the proposed method not only accurately identifies the missing data, but also effectively detects the KPI-related faults.},
  archive      = {J_ESWA},
  author       = {Yanyu Chen and Hao Ma and Yan Wang and Xiang Liu},
  doi          = {10.1016/j.eswa.2025.129440},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129440},
  shortjournal = {Expert Syst. Appl.},
  title        = {Key performance indicator-related process monitoring for irregular scenarios with incomplete data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm. <em>ESWA</em>, <em>298</em>, 129437. (<a href='https://doi.org/10.1016/j.eswa.2025.129437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, practical machine learning methodologies are extensively employed for the automation of detecting the intrusion available in the network. In key infrastructure scenarios involving communication strategies, the interplay between different industrial control systems and the inherent connection to the Internet environment through the Internet of Things renders them vulnerable to cyber threats. Considering the substantial volume of network traffic within critical Cyber-Physical Systems, conventional machine-learning approaches utilized for detecting anomalies prove to be ineffective. Hence, newly designed machine learning methods, with a focus on deep learning, are demonstrating effective applications in identifying and categorizing anomalies on both network and individual device levels. This article introduces an innovative Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm designed for the identification of cyber threats. To augment the effectiveness of the suggested method, it employs a dual-step process for the detection of network irregularities. During the initial phase, the approach involves data pre-processing and dimensionality reduction through the application of Kernel Principal Component Analysis to select the most suitable features. In the subsequent stage, the novel Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm is employed for classification. The effectiveness of the approach presented in this study is evaluated on diverse datasets, encompassing information collected within the Internet of Things context, specifically IoT-23 and LITNET-2020 datasets. The findings of the assessment of the suggested method are deliberated upon, including the examination of statistical significance and a comparative analysis with contemporary approaches in the field of network anomaly detection. Evaluations confirmed this robust model attained 98.56% accuracy, 97.78% precision, 98.2% F1-score, and produced less FPR of 1.55%.},
  archive      = {J_ESWA},
  author       = {Prabakeran Saravanan and Annamalai Balaji and Hemalatha Murugan and Manickam Muruganantham and Indumathi Varadharajan},
  doi          = {10.1016/j.eswa.2025.129437},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129437},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved DQN-based recommender system on three-way decision. <em>ESWA</em>, <em>298</em>, 129431. (<a href='https://doi.org/10.1016/j.eswa.2025.129431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems, which utilize algorithms and data analysis to provide personalized suggestions to users, have become an indispensable part of modern life. However, traditional recommendation algorithms face challenges such as the cold start problem, lack of diversity, and limited scalability. Reinforcement learning (RL), particularly deep reinforcement learning (DRL), emerges as a promising solution to these problems by allowing agents to learn optimal strategies through interaction with their environment. Nevertheless, as the scale of data increases, RL-based recommendation systems often struggle to achieve a good balance between exploration and exploitation, impacting the overall performance of the algorithms. In this paper, we propose a reinforcement learning-based recommendation algorithm enhanced by a three-way decision (3WD) framework to address the exploration-exploitation balance challenge. The 3WD algorithm, rooted in rough set theory, categorizes decision outcomes into acceptance, rejection, and uncertainty regions. By applying 3WD in the action selection process of RL, we optimize the trade-off between exploration and exploitation, thereby improving the quality and computational efficiency of recommendations. Additionally, we introduce a dynamic threshold adjustment mechanism to adaptively refine the decision boundary during the action selection process in reinforcement learning, further enhancing the algorithm’s performance. Using the MovieLens dataset as a foundation, we conduct extensive experiments with several randomly generated data sets to evaluate the proposed method. Our results demonstrate that the 3WD-based RL algorithm outperforms traditional methods, such as epsilon-greedy and Softmax, in terms of runtime, recommendation accuracy, and error rate. Notably, the dynamic threshold adjustment model exhibits greater stability and surpasses static methods in recommendation success rates. These findings highlight the effectiveness of combining 3WD with RL in recommendation systems, providing a powerful and efficient solution to the challenges faced by traditional methods. Finally, we analyze the limitations of the model based on the experimental results and propose avenues for future research.},
  archive      = {J_ESWA},
  author       = {Zian Chen and Bao Qing Hu},
  doi          = {10.1016/j.eswa.2025.129431},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129431},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved DQN-based recommender system on three-way decision},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports. <em>ESWA</em>, <em>298</em>, 129429. (<a href='https://doi.org/10.1016/j.eswa.2025.129429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an Integral Gaussian Process (IntegralGP) framework for volumetric estimation of subterranean properties in mineral deposits. It provides a unified representation for data with different spatial supports, which enables blasthole geochemical assays to be properly modelled as interval observations rather than points. This approach is shown to improve regression performance and boundary delineation. A core contribution is a description of the mathematical changes to the covariance expressions which allow these benefits to be realised. The gradient and anti-derivatives are obtained to facilitate learning of the kernel hyperparameters. Numerical stability issues are also discussed. To illustrate its application, an IntegralGP data fusion algorithm is described. The objective is to assimilate line-based blasthole assays and update a block model that provides long-range prediction of Fe concentration beneath the drilled bench. Heteroscedastic GP is used to fuse chemically compatible but spatially incongruous data with different resolutions and sample spacings. Domain knowledge embodied in the structure and empirical distribution of the block model must be generally preserved while local inaccuracies are corrected. Using validation measurements within the predicted bench, our experiments demonstrate an improvement in bench-below grade prediction performance. For material classification, IntegralGP fusion reduces the absolute error and model bias in categorical prediction, especially instances where waste blocks are mistakenly classified as high-grade.},
  archive      = {J_ESWA},
  author       = {Anna Chlingaryan and Arman Melkumyan and Raymond Leung},
  doi          = {10.1016/j.eswa.2025.129429},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129429},
  shortjournal = {Expert Syst. Appl.},
  title        = {IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer. <em>ESWA</em>, <em>298</em>, 129406. (<a href='https://doi.org/10.1016/j.eswa.2025.129406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a Deep Multi-view Least Squares Support Vector Machine with Consistency and Complementarity Principles based on Cross-Output Knowledge Transfer (MDCTM), which has four distinctive features: 1) It integrates the idea of deep stacking architecture, which is the first attempt to use transfer learning to form deep architectures in multi-view learning. It can enhance the ability to handle complex problems. Starting from the second layer, it incorporates extra input attributes that consider the predictions made by all preceding layers, effectively revealing the manifold structure of the original data. 2) Each layer follows the consistency and complementarity principles, which can fully excavate the information in multi-view data. In each layer, the model is solved by an alternating optimization strategy. 3) Cross-output knowledge transfer leverages predictions from earlier layers to improve the learning of subsequent ones, which can improve the classification performance of the model. Additionally, the extent of cross-output knowledge transfer between sequential layers can be assessed autonomously and effectively by utilizing a fast leave-one-out cross-validation method. 4) The model allows random assignment of model parameters in each layer, such as weights and kernel widths, boosting learning speed. Numerical experiments demonstrate the model’s effectiveness and efficiency.},
  archive      = {J_ESWA},
  author       = {Shuangrui Jia and Sijie Liang and Ziyi Mo and Chunxiao Liu and Huiru Wang and Chen Chen},
  doi          = {10.1016/j.eswa.2025.129406},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129406},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting. <em>ESWA</em>, <em>298</em>, 129388. (<a href='https://doi.org/10.1016/j.eswa.2025.129388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Koopman operator provides a new way to model complex data patterns, revealing the intrinsic dynamics of time series from a dynamical system perspective. Despite its potential, the Koopman operator has received limited attention in time series forecasting, particularly in addressing these complex, real-world challenges such as carbon emission dynamics characterized by nonlinearity, non-stationarity, and multi-scale coupling effects. To this end, this study proposes a novel forecasting paradigm, Fourier-Enhanced adaptive Koopman operator for carbon emission forecasting (F-KOCE). This approach conceptually extends traditional Koopman frameworks by embedding a spectral-decoupled time series representation into a dual Koopman learning structure, which enables the model to linearize nonlinear dynamics across multiple time scales in a theoretically grounded and practically adaptive manner. By integrating Fourier filter decomposition into Koopman operator theory, F-KOCE separates raw emissions into long-term trends and short-term fluctuations while achieving global linearization of system dynamics. A learnable Koopman operator captures intrinsic temporal structures, while a multi-granularity adaptive weight learning strategy enhances resilience against data variability. To further improve robustness, we introduce an adaptive residual fusion structure for block-level feature compression, noise suppression, and cross-scale information fusion. Additionally, the effective Trend Corrector mechanism dynamically modulates the influence of trend and fluctuation components, refining predictive accuracy. Beyond point forecasting, the framework is also extended to interval forecasting, providing uncertainty-aware predictions. Extensive experiments conducted on 36 Carbon Monitor datasets across six regions and six sectors demonstrate the superiority of F-KOCE over advanced existing models across multiple evaluation metrics. These results confirm the framework’s efficacy in capturing high-dimensional emission dynamics and underscore the potential of Koopman operator theory in carbon forecasting. By offering a robust, interpretable, and data-driven approach, F-KOCE provides valuable insights for climate policy formulation.},
  archive      = {J_ESWA},
  author       = {Jinxing Che and Wei Dong and Qian Sun and Yuhua Zhang},
  doi          = {10.1016/j.eswa.2025.129388},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129388},
  shortjournal = {Expert Syst. Appl.},
  title        = {A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems. <em>ESWA</em>, <em>298</em>, 129364. (<a href='https://doi.org/10.1016/j.eswa.2025.129364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 0–1 knapsack problem (KP) is a well-known combinatorial optimization problem with wide real-world applications. While evolutionary algorithms have demonstrated promise in solving 0–1 KPs, their performance deteriorates as the problem dimension increases. Cooperative co-evolution (CC) is an algorithmic framework based on a divide-and-conquer strategy, which has been used in solving large-scale optimization problems. Inspired by the similarity between item grouping in the 0–1 KP and decomposition strategies in CC, this paper proposes a novel grouping strategy that uses the position information of break items and profit-to-weight ratio to solve large-scale 0–1 KP. The strategy aims to divide the large-scale 0–1 KP into multiple subproblems, thus having a reduced search space for each subproblem. To enhance population diversity and search efficiency, the profit-to-weight ratio is used to generate an initial elite population. Additionally, to obtain the complete solution for the original large-scale KP, a subgroup merging method is designed to accelerate convergence and further improve population diversity. A three-phase repair operator is developed to fix infeasible solutions directly to create more feasible solutions. The resulting cooperative co-evolutionary algorithm is compared with ten state-of-the-art algorithms for solving 0–1 KPs with variables ranging from 100 to 5,000, including EAs, CC-based approaches, and a deep reinforcement learning method. Experimental results show that the proposed algorithm exhibits higher solution accuracy and faster convergence than other competing algorithms. The CC framework takes considerably less running time than high-performing algorithms, providing an overall novel approach for solving large-scale 0–1 KPs.},
  archive      = {J_ESWA},
  author       = {Xiaotong Li and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.eswa.2025.129364},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129364},
  shortjournal = {Expert Syst. Appl.},
  title        = {A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing forecast accuracy and switching costs in online optimization of energy management systems. <em>ESWA</em>, <em>298</em>, 129305. (<a href='https://doi.org/10.1016/j.eswa.2025.129305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the integration of forecasting and optimization in energy management systems, focusing on how switching costs, penalties incurred from frequent operational adjustments, affect the balance between forecast accuracy and stability in online decision-making. We develop a theoretical framework analyzing Fixed Horizon Control (FHC) algorithms under switching costs, deriving performance bounds that reveal trade-offs between commitment periods and forecast properties. We introduce a novel Scenario Distribution Change (SDC) metric for measuring temporal consistency in probabilistic forecasts. The framework is validated through empirical evaluation using a real-world battery scheduling case study based on the CityLearn 2022 challenge, comparing deterministic and stochastic optimization approaches across different commitment periods. Theoretical analysis reveals that switching costs create a U-shaped relationship between commitment period and performance, with optimal commitment depending on forecast stability. Empirical results demonstrate that switching costs significantly alter the accuracy-stability trade-off: while traditional approaches favor frequent updates (1-hour commitment), incorporating switching costs makes longer commitment periods (3+ hours) optimal when combined with stable forecasts. Stochastic optimization with scenario averaging reduces forecast error sensitivity by up to 2.9 % in grid costs compared to deterministic approaches. This work contributes the first theoretical bounds linking forecast stability to switching costs in energy systems, the SDC metric for evaluating probabilistic forecast stability, empirical evidence that longer commitment periods can outperform frequent updates under switching costs, and practical guidelines showing that forecast stability should be factored into decision-making frameworks for energy management systems in the presence of switching costs.},
  archive      = {J_ESWA},
  author       = {Evgenii Genov and Julian Ruddick and Christoph Bergmeir and Majid Vafaeipour and Thierry Coosemans and Salvador García and Maarten Messagie},
  doi          = {10.1016/j.eswa.2025.129305},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129305},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing forecast accuracy and switching costs in online optimization of energy management systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation. <em>ESWA</em>, <em>298</em>, 129267. (<a href='https://doi.org/10.1016/j.eswa.2025.129267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arm trajectory planning of crack repair is critical for automated road maintenance. However, existing crack repair face two main challenges: loss of trajectory edge information and redundant planned distances. This study introduces an automated pavement crack repair system that integrates a lightweight crack segmentation model (Lightweight Focal Modulation, LFM-Net) and a repair trajectory planning algorithm (Fixed Neighborhood Search-Artificial Bee Colony, FNS-ABC). Specifically, LFM-Net incorporates conformer-based focal modulation attention (CFMA), enhancing the detailed information during the decoding phase. Additionally, the FNS-ABC enhances the ABC algorithm by incorporating a fixed neighborhood search strategy, effectively reducing redundant planning paths. The system is executed using a self-developed robotic arm with an edge computing unit. Extensive testing in three typical road scenarios-independent cracks, intersection cracks, and complex cracks-demonstrated that the system achieved a mean Intersection over Union (mIoU) of 83.93 %. Finally, the system exhibited an idle trajectory of 79.51 mm when addressing complex cracks, highlighting its superior performance in repair trajectory planning.},
  archive      = {J_ESWA},
  author       = {Jianqi Zhang and Xu Yang and Wei Wang and Yuhang Zhao and Hainian Wang and Yixue Chen},
  doi          = {10.1016/j.eswa.2025.129267},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129267},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-learning based big data analysis for developing a smart supply chain for increased efficiency. <em>ESWA</em>, <em>298</em>, 129246. (<a href='https://doi.org/10.1016/j.eswa.2025.129246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analysis (BDA) in supply chain management (SCM) is receiving growing attention in the present business environment. This is due to the fact that BDA has a wide range of applications in SCM, including customer behaviour analysis, trend analysis, and demand prediction. The increase in information volume has caused the efficiency and effectiveness of traditional procedures to decline, considering this, researchers have developed techniques that have a high capacity to investigate and comprehend vast amounts of data due to the limitations of these tactics in dissecting and interpreting a lot of information. This study represents a hybrid paper that combines a systematic literature review, a methodological proposal using BP neural networks. The main objective of this paper is to recognize the uses of deep learning in SCM. By fostering a calculated system, this paper recognizes the commitments of deep learning strategies in choosing and sectioning providers, foreseeing store network gambles, and assessing requests and deals, creation, stock administration, transportation and circulation, manageable turn of events, and roundabout economy. The novelty in this paper is the Backpropagation (BP) neural networks with big data-driven demand forecasting in supply chains. This method can improve the accuracy of demand forecasting in supply chain management. The study includes a thorough survey of the applications of predictive BDA in SC request gauging. The review highlighted the BDA methodologies used for production network request estimation and comparatively classified them. We collected and analysed these studies as tactics and methodologies for the popular forecast. Seven standard tactics were selected and studied, along with their benefits and drawbacks. Finally, the box-cox transformation representation over years in which for the year 2011–01, it starts with a box-cox value of 9.7 and it inclined till 2011–06 and then declined very exponentially in 2012–07 at 9 and then it keeps on incrementing and reached at 11 at the year 2013–07. Then from 2014 to 2015, the pattern didn’t lower below the box-cox value 10.},
  archive      = {J_ESWA},
  author       = {Sreekumar Narayanan and Sudhir Ramadass and K. Thilagavathi and Rajiv Kumar},
  doi          = {10.1016/j.eswa.2025.129246},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129246},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-learning based big data analysis for developing a smart supply chain for increased efficiency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="iandc">IANDC - 11</h2>
<ul>
<li><details>
<summary>
(2025). K-universality of regular languages. <em>IANDC</em>, <em>307</em>, 105357. (<a href='https://doi.org/10.1016/j.ic.2025.105357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A subsequence of a word w is a word u such that u = w [ i 1 ] w [ i 2 ] … w [ i k ] , for some set of indices 1 ≤ i 1 < i 2 < … < i k ≤ | w | . A word w is k -subsequence universal over an alphabet Σ if every word in Σ k appears in w as a subsequence. In this paper, we study the intersection between the set of k -subsequence universal words over some alphabet Σ and regular languages over Σ. We call a regular language L k- ∃ -subsequence universal if there exists a k -subsequence universal word in L , and k- ∀ -subsequence universal if every word of L is k -subsequence universal. We give algorithms solving the problems of deciding if a given regular language, represented by a finite automaton recognising it, is k- ∃ -subsequence universal and, respectively, if it is k- ∀ -subsequence universal , for a given k . The algorithms are FPT w.r.t. the size of the input alphabet, and their run-time does not depend on k ; they run in polynomial time in the number n of states of the input automaton when the size of the input alphabet is O ( log ⁡ n ) . Moreover, we show that the problem of deciding if a given regular language is k- ∃ -subsequence universal is NP-complete, when the language is over a large alphabet. Further, we provide algorithms for counting the number of k -subsequence universal words (paths) accepted by a given deterministic (respectively, non-deterministic) finite automaton, and ranking an input word (path) within the set of k -subsequence universal words accepted by a given finite automaton.},
  archive      = {J_IANDC},
  author       = {Duncan Adamson and Pamela Fleischmann and Annika Huch and Tore Koß and Florin Manea and Dirk Nowotka},
  doi          = {10.1016/j.ic.2025.105357},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105357},
  shortjournal = {Inf. Comput.},
  title        = {K-universality of regular languages},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent algorithmic advances in simple temporal networks with uncertainty: From faster controllability checking to faster execution. <em>IANDC</em>, <em>307</em>, 105356. (<a href='https://doi.org/10.1016/j.ic.2025.105356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper advances the state of the art in the dynamic controllability (DC) and dispatchability of Simple Temporal Networks with Uncertainty (STNUs) through four key contributions. First, findSRNC is an algorithm that identifies semi-reducible negative cycles in non-dynamically controllable STNUs. Running in O ( m n + k 2 n + k n log ⁡ n ) time (matching the fastest DC-checking algorithms), it handles repeated edges and uses polynomial space, even when cycles might contain exponentially many edges. Second, minDisp ESTNU + is an algorithm that improves dispatchability computation for STNUs from O ( k n 3 ) to O ( n 3 + k 2 n log ⁡ n ) time. It outputs dispatchable Extended STNUs (ESTNUs) having minimal numbers of edges, which is crucial for subsequent real-time execution. Third, the Canonical Form of Nested Diamond Structures in Dispatchable ESTNUs is a rigorous theory that facilitates correctness proofs for dispatchability algorithms. It also helped reveal and correct a flaw in a previously published algorithm. Fourth, our empirical evaluation using improved open-source implementations demonstrates the practical effectiveness of our algorithms. These contributions address fundamental computational bottlenecks in temporal planning systems, enabling more efficient reasoning about uncertain timing constraints while providing real-time guarantees required for robotics, scheduling, and automated planning applications.},
  archive      = {J_IANDC},
  author       = {Luke Hunsberger and Roberto Posenato},
  doi          = {10.1016/j.ic.2025.105356},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105356},
  shortjournal = {Inf. Comput.},
  title        = {Recent algorithmic advances in simple temporal networks with uncertainty: From faster controllability checking to faster execution},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polynomial turing compressions for some graph problems parameterized by modular-width. <em>IANDC</em>, <em>307</em>, 105355. (<a href='https://doi.org/10.1016/j.ic.2025.105355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A polynomial Turing compression (PTC) for a parameterized problem L is a polynomial time Turing machine that has access to an oracle for a problem L ′ such that a polynomial in the input parameter bounds each query. Meanwhile, a polynomial compression (PC) can be regarded as a restricted variant of PTC where the machine can query the oracle exactly once and must output the same answer as the oracle. Bodlaender et al. (ICALP 2008) and Fortnow and Santhanam (STOC 2008) initiated an impressive hardness theory for PC under the assumption coNP ⊈ NP/poly. Let C be the set of all problems with PTCs but without PCs assuming coNP ⊈ NP/poly. Fernau et al. (STACS 2009) identified Leaf Out-tree( k ) as the first problem in C . However, little is known about C , with only a dozen problems confirmed in it over the last fifteen years. Open questions remain, such as whether CNF-SAT( n ) and k -path are in C , requiring novel ideas to clarify the differences between PTCs and PCs. In this paper, we enrich our knowledge about C by demonstrating that 17 problems parameterized by modular-width ( mw ), such as Chromatic Number( mw ) and Hamiltonian Cycle( mw ) , belong to C . Additionally, we develop a general recipe to prove the existence of PTCs for a class of problems, including these 17.},
  archive      = {J_IANDC},
  author       = {Weidong Luo},
  doi          = {10.1016/j.ic.2025.105355},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105355},
  shortjournal = {Inf. Comput.},
  title        = {Polynomial turing compressions for some graph problems parameterized by modular-width},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On cardinalities of rogers semilattices for families in the ershov hierarchy. <em>IANDC</em>, <em>307</em>, 105354. (<a href='https://doi.org/10.1016/j.ic.2025.105354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of numberings provides classification results for families of sets in various computability-theoretic hierarchies. The algorithmic content of numberings is typically calibrated via the reducibility between numberings. For a given family of sets S , this reducibility gives rise to an upper semilattice of degrees that is often called the Rogers semilattice of S . This paper studies the cardinalities of Rogers semilattices for families of sets at finite levels of the Ershov hierarchy. The classical result of Khutoretskii (1971) shows that the Rogers semilattice of a family of c.e. sets is either one-element or countably infinite. Badaev and Lempp (2009) constructed a family of d.c.e. sets that demonstrates that the methods of Khutoretskii cannot be applied to obtain a similar result for Rogers semilattices already at the second level of the Ershov hierarchy. We prove that for any finite family of sets S at any finite level of the Ershov hierarchy, the corresponding Rogers semilattice is either one-element or countably infinite. We also obtain another sufficient condition for a Rogers semilattice to be infinite. This condition implies that the Rogers semilattice of Badaev and Lempp is also infinite.},
  archive      = {J_IANDC},
  author       = {Keng Meng Ng and Nikolay Bazhenov and Birzhan Kalmurzayev and Dias Nurlanbek},
  doi          = {10.1016/j.ic.2025.105354},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105354},
  shortjournal = {Inf. Comput.},
  title        = {On cardinalities of rogers semilattices for families in the ershov hierarchy},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact counting of subtrees with diameter no more than d in trees: A generating function approach. <em>IANDC</em>, <em>307</em>, 105353. (<a href='https://doi.org/10.1016/j.ic.2025.105353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network motifs, regarded as fundamental building blocks, offer crucial insights into the structure and function of complex networks, with broad applications across disciplines including sociology, computer science, bioinformatics, chemoinformatics, and pharmaceutics. However, the identification of network motifs remains a significant and computationally challenging problem. Among various motifs, subtree enumeration has garnered substantial attention in recent years, particularly due to its relevance in network science and bioinformatics. For an n -vertex tree T , by introducing novel generating functions with ( d + 2 ) variables, we propose an innovative algorithm for the exact enumeration of T 's subtrees rooted at fixed vertex v , where the distance between v and the farthest leaf is k = 0 , 1 , … , d , and the distance between any two leaves is no more than d . Building on this algorithm, we develop novel recursive algorithms for exact enumerating various diameter no more than d subtrees (abbreviated as DNMT- d subtrees) of T . As applications, we apply these algorithms to derive the number of DNMT- d subtrees in a full binary tree B h with h ≥ 2 levels, and briefly discuss the density of DNMT- d subtrees in general trees. Our research generalizes the work of Frank Ruskey on Listing and Counting Subtrees of a Tree in 1981 and makes it a special case of our study where d equals the diameter of the tree T . Moreover, the proposed O ( d n 2 ) algorithms introduce new approaches for enumerating subtrees under diameter constraints and lay the groundwork for counting diameter-constrained subgraphs (motifs) in complex networks.},
  archive      = {J_IANDC},
  author       = {Yu Yang and Bang-Bang Jin and Xiaoming Sun and Xiao-Dong Zhang and Bo Li and Kai Zhao and Hua Wang},
  doi          = {10.1016/j.ic.2025.105353},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105353},
  shortjournal = {Inf. Comput.},
  title        = {Exact counting of subtrees with diameter no more than d in trees: A generating function approach},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision problems for systems of language equations and inequations. <em>IANDC</em>, <em>307</em>, 105344. (<a href='https://doi.org/10.1016/j.ic.2025.105344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems of language equations φ ( X 1 , … , X n ) = ψ ( X 1 , … , X n ) and inequations φ ( X 1 , … , X n ) ≠ ψ ( X 1 , … , X n ) are studied, where φ and ψ may contain Boolean operations and concatenation. It is proved that the problem whether such a system has a solution is Σ 2 0 -complete in the arithmetical hierarchy (cf. the earlier studied case of equations only, where it is co-r.e.-complete), the problem whether it has a unique solution is in Σ 3 0 ∩ Π 3 0 , and is both Σ 2 0 -hard and Π 2 0 -hard, existence of a finite or regular solution is an r.e.-complete problem, while testing whether a system has finitely many solutions is Σ 3 0 -complete. Furthermore, it is shown that the class of languages representable by unique solutions of such systems is exactly the class of recursive sets, but decision procedures for the set cannot be algorithmically constructed out of a system. All results hold already for equations over a unary alphabet.},
  archive      = {J_IANDC},
  author       = {Alexander Okhotin},
  doi          = {10.1016/j.ic.2025.105344},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105344},
  shortjournal = {Inf. Comput.},
  title        = {Decision problems for systems of language equations and inequations},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards a theoretical understanding of why local search works for clustering with fair-center representation. <em>IANDC</em>, <em>307</em>, 105343. (<a href='https://doi.org/10.1016/j.ic.2025.105343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The representative k -median problem generalizes the classical clustering formulations in that it partitions the data points into ℓ disjoint demographic groups and imposes a lower-bound constraint on the number of opened facilities from each group, such that all the groups are fairly represented by the opened facilities. Due to its simplicity, the local-search heuristic, which iteratively swaps a bounded number of closed facilities for the same number of opened ones to improve the solution, has been frequently used in the representative k -median problem. It is known that the local-search heuristic, when restricted to constant-size swaps, yields a constant-factor approximation if ℓ = 2 , and has an unbounded approximation ratio if ℓ is super-constant. However, for any constant ℓ > 2 , the existence of a constant-factor approximation under constant-size swaps remained an open question for a long time. In response to this question, we demonstrate that the local-search heuristic guarantees a ( 4 ℓ + 5 ) -approximation when up to ℓ ( ℓ + 1 ) facilities are allowed to be swapped in each iteration, thus providing an affirmative answer to the question. Our main technical contribution is a novel approach for theoretically analyzing the local-search heuristic, which bounds its approximation ratio by linearly combining the clustering cost increases induced by a set of hierarchically organized swaps. Our techniques also generalize to the k -means clustering formulation and reveal similar approximation guarantees for the local-search heuristic.},
  archive      = {J_IANDC},
  author       = {Zhen Zhang and Junfeng Yang and Limei Liu and Xuesong Xu and Guozhen Rong and Qilong Feng},
  doi          = {10.1016/j.ic.2025.105343},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105343},
  shortjournal = {Inf. Comput.},
  title        = {Towards a theoretical understanding of why local search works for clustering with fair-center representation},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The billaud conjecture for alphabet size 4. <em>IANDC</em>, <em>307</em>, 105342. (<a href='https://doi.org/10.1016/j.ic.2025.105342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Billaud Conjecture, first stated in 1993, is a fundamental problem on finite words and their heirs, i.e., the words obtained by a projection deleting a single letter. The conjecture states that every morphically primitive word, i.e., a word that is not a fixed point of any non-identity morphism, has at least one morphically primitive heir. The correctness of the conjecture has so far been established in a few special cases, which mainly restrict the alphabet size. In this paper we give a proof for the next such case, i.e., for alphabet size 4.},
  archive      = {J_IANDC},
  author       = {Szymon Łopaciuk and Daniel Reidenbach},
  doi          = {10.1016/j.ic.2025.105342},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105342},
  shortjournal = {Inf. Comput.},
  title        = {The billaud conjecture for alphabet size 4},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The g-good-neighbor diagnosability of product networks under the PMC model. <em>IANDC</em>, <em>307</em>, 105341. (<a href='https://doi.org/10.1016/j.ic.2025.105341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of neighbor connectivity originated from the assessment of the subversion of espionage networks caused by underground resistance movements, and it has now been applied to measure the disruption of networks caused by cascading failures through neighbors. In this paper, we give two necessary and sufficient conditions of the existence of g -good-neighbor diagnosability. We introduce a new concept called g -good neighbor cut-component number (gc number for short), which has close relation with g -good-neighbor diagnosability. Sharp lower and upper bounds of the gc number of general graphs in terms of the g -good neighbor connectivity have been proposed, which provide a formula to compute the g -good-neighbor diagnosability for general graphs (therefore for Cartesian product graphs). As their applications, we get the exact values or bounds for the gc numbers and g -good-neighbor diagnosability of grid, torus networks and generalized cubes.},
  archive      = {J_IANDC},
  author       = {Zhao Wang and Yaping Mao and Sun-Yuan Hsieh and Ralf Klasing},
  doi          = {10.1016/j.ic.2025.105341},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105341},
  shortjournal = {Inf. Comput.},
  title        = {The g-good-neighbor diagnosability of product networks under the PMC model},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-state spin systems with negative interactions. <em>IANDC</em>, <em>307</em>, 105340. (<a href='https://doi.org/10.1016/j.ic.2025.105340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the approximability of computing the partition functions of two-state spin systems. The problem is parameterized by a 2 × 2 symmetric matrix. Previous results on this problem were restricted either to the case where the matrix has non-negative entries, or to the case where the diagonal entries are equal, i.e. Ising models. In this paper, we study the generalization to arbitrary 2 × 2 interaction matrices with real entries. We show that in some regions of the parameter space, it's #P-hard to even determine the sign of the partition function, while in other regions there are fully polynomial approximation schemes for the partition function. Our results reveal several new computational phase transitions.},
  archive      = {J_IANDC},
  author       = {Yumou Fei and Leslie Ann Goldberg and Pinyan Lu},
  doi          = {10.1016/j.ic.2025.105340},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105340},
  shortjournal = {Inf. Comput.},
  title        = {Two-state spin systems with negative interactions},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competition among parallel contests. <em>IANDC</em>, <em>307</em>, 105339. (<a href='https://doi.org/10.1016/j.ic.2025.105339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the model of multiple rank-order contests held in parallel, where each contestant only selects one contest to join and each contest designer decides the prize structure to compete for the participation of contestants. We first analyze the strategic behaviors of contestants and completely characterize the symmetric Bayesian Nash equilibrium. As for the strategies of contest designers, when other designers' strategies are known, we show that computing the best response is NP-hard and propose a fully polynomial time approximation scheme to output the ϵ -approximate best response. When other designers' strategies are unknown, we provide a worst-case analysis on one designer's strategy. We give an upper bound on the worst-case utility of any strategy and propose a method to construct a strategy whose utility can guarantee a constant ratio of this upper bound in the worst case.},
  archive      = {J_IANDC},
  author       = {Xiaotie Deng and Ningyuan Li and Weian Li and Qi Qi},
  doi          = {10.1016/j.ic.2025.105339},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105339},
  shortjournal = {Inf. Comput.},
  title        = {Competition among parallel contests},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="icv">ICV - 12</h2>
<ul>
<li><details>
<summary>
(2025). Test-time adaptation for object detection via dynamic dual teaching. <em>ICV</em>, <em>163</em>, 105740. (<a href='https://doi.org/10.1016/j.imavis.2025.105740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Test-Time Adaptation (TTA) is a practical setting in real-world applications, which aims to adapt a source-trained model to target domains with online unlabeled test data streams. Current approaches often rely on self-training, utilizing supervision signals from the source-trained model, suffering from poor adaptation due to diverse domain shifts. In this paper, we propose a novel test-time adaptation method for object detection guided by dual teachers, termed D ynamic D ual T eaching ( DDT ). Inspired by the generalization potentials of Vision-Language Models (VLMs), we integrate the VLM as an additional language-driven instructor. This integration exploits the domain-robustness of language prompts to mitigate domain shifts, collaborating with the teacher of source information within the teacher–student framework. Firstly, we utilize an ensemble prompt to guide the prediction process of the language-driven instructor. Secondly, a dynamic fusion strategy of the dual teachers is designed to generate high-quality pseudo-labels for student learning. Moreover, we incorporate a dual prediction consistency regularization to further mitigate the sensitivity of the adapted detector to domain shifts. Experiments on diverse domain adaptation benchmarks demonstrate that the proposed DDT method achieves state-of-the-art performance on both online and offline domain adaptation settings.},
  archive      = {J_ICV},
  author       = {Siqi Zhang and Lu Zhang and Zhiyong Liu},
  doi          = {10.1016/j.imavis.2025.105740},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105740},
  shortjournal = {Image Vis. Comput.},
  title        = {Test-time adaptation for object detection via dynamic dual teaching},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining fine-grained attributes for vision–semantics integration in few-shot learning. <em>ICV</em>, <em>163</em>, 105739. (<a href='https://doi.org/10.1016/j.imavis.2025.105739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Few-Shot Learning (FSL) have been significantly driven by leveraging semantic descriptions to enhance feature discrimination and recognition performance. However, existing methods, such as SemFew, often rely on verbose or manually curated attributes and apply semantic guidance only to the support set, limiting their effectiveness in distinguishing fine-grained categories. Inspired by human visual perception, which emphasizes crucial features for accurate recognition, this study introduces concise, fine-grained semantic attributes to address these limitations. We propose a Visual Attribute Enhancement (VAE) mechanism that integrates enriched semantic information into visual features, enabling the model to highlight the most relevant visual attributes and better distinguish visually similar samples. This module enhances visual features by aligning them with semantic attribute embeddings through a cross-attention mechanism and optimizes this alignment using an attribute-based cross-entropy loss. Furthermore, to mitigate the performance degradation caused by methods that supply semantic information exclusively to the support set, we propose a semantic attribute reconstruction (SAR) module. This module predicts and integrates semantic features for query samples, ensuring balanced information distribution between the support and query sets. Specifically, SAR enhances query representations by aligning and reconstructing semantic and visual attributes through regression and optimal transport losses to ensure semantic–visual consistency. Experiments on five benchmark datasets, including both general datasets and more challenging fine-grained Few-Shot datasets consistently demonstrate that our proposed method outperforms state-of-the-art methods in both 5-way 1-shot and 5-way 5-shot settings.},
  archive      = {J_ICV},
  author       = {Juan Zhao and Lili Kong and Deshang Sun and Deng Xiong and Jiancheng Lv},
  doi          = {10.1016/j.imavis.2025.105739},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105739},
  shortjournal = {Image Vis. Comput.},
  title        = {Mining fine-grained attributes for vision–semantics integration in few-shot learning},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable deepfake detection across different modalities: An overview of methods and challenges. <em>ICV</em>, <em>163</em>, 105738. (<a href='https://doi.org/10.1016/j.imavis.2025.105738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of deepfake technology enables the creation of realistic and deceptive content, raising concerns about several serious issues, including biometric authentication, misinformation, politics, privacy, and trust. Many Deepfake Detection (DD) models are entering the market to combat the misuse of deepfakes. With these developments, one primary issue occurs in ensuring the explainability of the proposed detection models to understand the rationale of the decision. This paper aims to investigate the state-of-the-art explainable DD models across multiple modalities, including image, video, audio, and text. Unlike existing surveys that focus on detection methodologies with minimal attention to explainability and limited modality coverage, this paper directly focuses on these gaps. It offers a comprehensive analysis of advanced explainability techniques, including Grad-CAM, LIME, SHAP, LRP, Saliency Maps, and Anchors, for detecting deceptive content across the modalities. It identifies the strengths and limitations of existing models and outlines research directions to enhance explainability and interpretability in future works. By exploring these models, we aim to enhance transparency, provide deeper insights into model decisions, and bridge the gap between detection accuracy with explainability in DD models.},
  archive      = {J_ICV},
  author       = {MD Sarfaraz Momin and Abu Sufian and Debaditya Barman and Marco Leo and Cosimo Distante and Naser Damer},
  doi          = {10.1016/j.imavis.2025.105738},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105738},
  shortjournal = {Image Vis. Comput.},
  title        = {Explainable deepfake detection across different modalities: An overview of methods and challenges},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MITS: A large-scale multimodal benchmark dataset for intelligent traffic surveillance. <em>ICV</em>, <em>163</em>, 105736. (<a href='https://doi.org/10.1016/j.imavis.2025.105736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General-domain large multimodal models (LMMs) have achieved significant advances in various image-text tasks. However, their performance in the Intelligent Traffic Surveillance (ITS) domain remains limited due to the absence of dedicated multimodal datasets. To address this gap, we introduce MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale multimodal benchmark dataset specifically designed for ITS. MITS includes 170,400 independently collected real-world ITS images sourced from traffic surveillance cameras, annotated with eight main categories and 24 subcategories of ITS-specific objects and events under diverse environmental conditions. Additionally, through a systematic data generation pipeline, we generate high-quality image captions and 5 million instruction-following visual question-answer pairs , addressing five critical ITS tasks : object and event recognition, object counting, object localization, background analysis, and event reasoning. To demonstrate MITS’s effectiveness, we fine-tune mainstream LMMs on this dataset, enabling the development of ITS-specific applications. Experimental results show that MITS significantly improves LMM performance in ITS applications, increasing LLaVA-1.5’s performance from 0.494 to 0.905 (+83.2%), LLaVA-1.6’s from 0.678 to 0.921 (+35.8%), Qwen2-VL’s from 0.584 to 0.926 (+58.6%), and Qwen2.5-VL’s from 0.732 to 0.930 (+27.0%). We release the dataset, code, and models as open-source , providing high-value resources to advance both ITS and LMM research.},
  archive      = {J_ICV},
  author       = {Kaikai Zhao and Zhaoxiang Liu and Peng Wang and Xin Wang and Zhicheng Ma and Yajun Xu and Wenjing Zhang and Yibing Nan and Kai Wang and Shiguo Lian},
  doi          = {10.1016/j.imavis.2025.105736},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105736},
  shortjournal = {Image Vis. Comput.},
  title        = {MITS: A large-scale multimodal benchmark dataset for intelligent traffic surveillance},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UNIR-net: A novel approach for restoring underwater images with non-uniform illumination using synthetic data. <em>ICV</em>, <em>163</em>, 105734. (<a href='https://doi.org/10.1016/j.imavis.2025.105734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoring underwater images affected by non-uniform illumination (NUI) is essential to improve visual quality and usability in marine applications. Conventional methods often fall short in handling complex illumination patterns, while learning-based approaches face challenges due to the lack of targeted datasets. To address these limitations, the Underwater Non-uniform Illumination Restoration Network (UNIR-Net) is proposed. UNIR-Net integrates multiple components, including illumination enhancement, attention mechanisms, visual refinement, and contrast correction, to effectively restore underwater images affected by NUI. In addition, the Paired Underwater Non-uniform Illumination (PUNI) dataset is introduced, specifically designed for training and evaluating models under NUI conditions. Experimental results on PUNI and the large-scale real-world Non-Uniform Illumination Dataset (NUID) show that UNIR-Net achieves superior performance in both quantitative metrics and visual outcomes. UNIR-Net also improves downstream tasks such as underwater semantic segmentation, highlighting its practical relevance. The code is available at https://github.com/xingyumex/UNIR-Net .},
  archive      = {J_ICV},
  author       = {Ezequiel Pérez-Zarate and Chunxiao Liu and Oscar Ramos-Soto and Diego Oliva and Marco Pérez-Cisneros},
  doi          = {10.1016/j.imavis.2025.105734},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105734},
  shortjournal = {Image Vis. Comput.},
  title        = {UNIR-net: A novel approach for restoring underwater images with non-uniform illumination using synthetic data},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFENet: A frequency fusion and enhancement network for camouflaged object detection. <em>ICV</em>, <em>163</em>, 105733. (<a href='https://doi.org/10.1016/j.imavis.2025.105733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of camouflaged object detection (COD) is to accurately find camouflaged objects hidden in their surroundings. Although most of the existing frequency-domain based COD models can boost the performance of COD to a certain extent by utilizing the frequency domain information, the frequency feature fusion strategies they adopt tend to ignore the complementary effects between high-frequency features and low-frequency features. In addition, most of the existing frequency-domain based COD models also do not consider enhancing camouflaged objects using low-level frequency-domain features. In order to solve these problems, we present a frequency fusion and enhancement network (FFENet) for camouflaged object detection, which mainly includes three stages. In the frequency feature extraction stage, we design a frequency feature learning module (FLM) to extract corresponding high-frequency features and low-frequency features. In the frequency feature fusion stage, we design a frequency feature fusion module (FFM) that can increase the representation ability of the fused features by adaptively assigning weights to the high-frequency features and the low-frequency features using a cross-attention mechanism. In the frequency feature guidance information enhancement stage, we design a frequency feature guidance information enhancement module (FGIEM) to enhance the contextual information and detail information of camouflaged objects in the fused features under the guidance of the low-level frequency features. Extensive experimental results on the COD10K, CHAMELEON, NC4K and CAMO datasets show that our model is superior to most existing COD models.},
  archive      = {J_ICV},
  author       = {Haishun Du and Wenzhe Zhang and Sen Wang and Zhengyang Zhang and Linbing Cao},
  doi          = {10.1016/j.imavis.2025.105733},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105733},
  shortjournal = {Image Vis. Comput.},
  title        = {FFENet: A frequency fusion and enhancement network for camouflaged object detection},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UpAttTrans: Upscaled attention based transformer for facial image super-resolution. <em>ICV</em>, <em>163</em>, 105731. (<a href='https://doi.org/10.1016/j.imavis.2025.105731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) aims to reconstruct high-quality images from low-resolution inputs, a task particularly challenging in face-related applications due to extreme degradations and modality differences (e.g., visible, low-resolution, near-infrared). Conventional convolutional neural networks (CNNs) and GAN-based approaches have achieved notable success; however, they often struggle with preserving identity and fine structural details at high upscaling factors. In this work, we introduce UpAttTrans, a novel attention mechanism that connects original and upsampled features for better detail recovery based on vision transformer for SR. The core generator leverages a custom UpAttTrans module that translates input image patches into embeddings, processes them through transformer layers enhanced with connector-up attention, and reconstructs high-resolution outputs with improved detail retention. We evaluate our model on the CelebA dataset across multiple upscaling factors ( 4 × , 8 × , 16 × , 32 × , and 64 × ). UpAttTrans achieves a 24.63% increase in PSNR, 21.56% in SSIM, and 19.61% reduction in FID for 4 × and 8 × SR, outperforming state-of-the-art baselines. Additionally, for higher magnification levels, our model maintains strong performance, with average gains of 6.20% in PSNR and 21.49% in SSIM, indicating its robustness in extreme SR settings. These findings suggest that UpAttTrans holds significant promise for real-world applications such as face recognition in surveillance, forensic image enhancement, and cross-spectral matching, where high-quality reconstruction from severely degraded inputs is critical.},
  archive      = {J_ICV},
  author       = {Neeraj Baghel and Shiv Ram Dubey and Satish Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105731},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105731},
  shortjournal = {Image Vis. Comput.},
  title        = {UpAttTrans: Upscaled attention based transformer for facial image super-resolution},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation. <em>ICV</em>, <em>163</em>, 105729. (<a href='https://doi.org/10.1016/j.imavis.2025.105729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation is a vital early detection method for several severe ocular diseases. Despite significant progress in retinal vessel segmentation with the advancement of Neural Networks, there are still challenges to overcome. Specifically, retinal vessel segmentation aims to predict the class label for every pixel within a fundus image, with a primary focus on intra-image discrimination, making it vital for models to extract more discriminative features. Nevertheless, existing methods primarily focus on minimizing the difference between the output from the decoder and the label, but ignore fully using feature-level fine-grained representations from the encoder. To address these issues, we propose a novel Attention U-shaped Kolmogorov–Arnold Network named AttUKAN along with a novel Label-guided Pixel-wise Contrastive Loss for retinal vessel segmentation. Specifically, we implement Attention Gates into Kolmogorov–Arnold Networks to enhance model sensitivity by suppressing irrelevant feature activations and model interpretability by non-linear modeling of KAN blocks. Additionally, we also design a novel Label-guided Pixel-wise Contrastive Loss to supervise our proposed AttUKAN to extract more discriminative features by distinguishing between foreground vessel-pixel pairs and background pairs. Experiments are conducted across four public datasets including DRIVE, STARE, CHASE_DB1, HRF and our private dataset. AttUKAN achieves F1 scores of 82.50%, 81.14%, 81.34%, 80.21% and 80.09%, along with MIoU scores of 70.24%, 68.64%, 68.59%, 67.21% and 66.94% in the above datasets, which are the highest compared to 11 networks for retinal vessel segmentation. Quantitative and qualitative results show that our AttUKAN achieves state-of-the-art performance and outperforms existing retinal vessel segmentation methods. Our code will be available at https://github.com/stevezs315/AttUKAN .},
  archive      = {J_ICV},
  author       = {Shuang Zeng and Chee Hong Lee and Micky C. Nnamdi and Wenqi Shi and J. Ben Tamo and Hangzhou He and Xinliang Zhang and Qian Chen and May D. Wang and Lei Zhu and Yanye Lu and Qiushi Ren},
  doi          = {10.1016/j.imavis.2025.105729},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105729},
  shortjournal = {Image Vis. Comput.},
  title        = {Novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence content detection techniques using watermarking: A survey. <em>ICV</em>, <em>163</em>, 105728. (<a href='https://doi.org/10.1016/j.imavis.2025.105728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement in AI-generated content has catalyzed artistic creation, advertising, and media dissemination. Despite their widespread applications across several domains, AI-generated content inherently poses risks of identity fraud, copyright violation and unauthorized use. Watermarking has emerged as a critical tool for copyright protection, allowing embedding of identification information in AI-generated content, and enhances traceability and verification without hurting user experience. In this study, we provide a systematic literature review of the technique for detecting AI content, especially text and images, using watermarking, spanning studies from 2010 to 2025. Studies included in this review were peer-reviewed articles that applied watermarking to effectively distinguish AI-generated content from real or human-written content. We report strong past and current approaches to detecting watermarking-based AI content, especially text and images. This includes an analysis of how watermarking methods are used on AI-generated content, their role in enhancing performance, and a detail comparative analysis of notable techniques. Furthermore, we discuss how these methods have been evaluated, identify the research gaps and potential solutions. Our findings provide valuable insights for future watermarking-based AI content detection researchers, applications and organizations seeking to implement watermarking solutions in potential applications. To the best of our knowledge, we are the first to explore the detection of AI content, especially text and image, detection using watermarking.},
  archive      = {J_ICV},
  author       = {Nishant Kumar and Amit Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105728},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105728},
  shortjournal = {Image Vis. Comput.},
  title        = {Artificial intelligence content detection techniques using watermarking: A survey},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Your image generator is your new private dataset. <em>ICV</em>, <em>163</em>, 105727. (<a href='https://doi.org/10.1016/j.imavis.2025.105727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative diffusion models have emerged as powerful tools to synthetically produce training data, offering potential solutions to data scarcity and reducing labelling costs for downstream supervised deep learning applications. However, existing approaches for synthetic dataset generation face significant limitations: previous methods like Knowledge Recycling rely on label-conditioned generation with models trained from scratch, limiting flexibility and requiring extensive computational resources, while simple class-based conditioning fails to capture the semantic diversity and intra-class variations found in real datasets. Additionally, effectively leveraging text-conditioned image generation for building classifier training sets requires addressing key issues: constructing informative textual prompts, adapting generative models to specific domains, and ensuring robust performance. This paper proposes the Text-Conditioned Knowledge Recycling (TCKR) pipeline to tackle these challenges. TCKR combines dynamic image captioning, parameter-efficient diffusion model fine-tuning, and Generative Knowledge Distillation techniques to create synthetic datasets tailored for image classification. The pipeline is rigorously evaluated on ten diverse image classification benchmarks. The results demonstrate that models trained solely on TCKR-generated data achieve classification accuracies on par with (and in several cases exceeding) models trained on real images. Furthermore, the evaluation reveals that these synthetic-data-trained models exhibit substantially enhanced privacy characteristics: their vulnerability to Membership Inference Attacks is significantly reduced, with the membership inference AUC lowered by 5.49 points on average compared to using real training data, demonstrating a substantial improvement in the performance-privacy trade-off. These findings indicate that high-fidelity synthetic data can effectively replace real data for training classifiers, yielding strong performance whilst simultaneously providing improved privacy protection as a valuable emergent property. The code and trained models are available in the accompanying open-source repository .},
  archive      = {J_ICV},
  author       = {Nicolò Francesco Resmini and Eugenio Lomurno and Cristian Sbrolli and Matteo Matteucci},
  doi          = {10.1016/j.imavis.2025.105727},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105727},
  shortjournal = {Image Vis. Comput.},
  title        = {Your image generator is your new private dataset},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the noise robustness of class activation maps: A framework for reliable model interpretability. <em>ICV</em>, <em>163</em>, 105717. (<a href='https://doi.org/10.1016/j.imavis.2025.105717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class Activation Maps (CAMs) are one of the important methods for visualizing regions used by deep learning models. Yet their robustness to different noise remains underexplored. In this work, we evaluate and report the resilience of various CAM methods for different noise perturbations across multiple architectures and datasets. By analyzing the influence of different noise types on CAM explanations, we assess the susceptibility to noise and the extent to which dataset characteristics may impact explanation stability. The findings highlight considerable variability in noise sensitivity for various CAMs. We propose a robustness metric for CAMs that captures two key properties: consistency and responsiveness. Consistency reflects the ability of CAMs to remain stable under input perturbations that do not alter the predicted class, while responsiveness measures the sensitivity of CAMs to changes in the prediction caused by such perturbations. The metric is evaluated empirically across models, different perturbations, and datasets along with complementary statistical tests to exemplify the applicability of our proposed approach.},
  archive      = {J_ICV},
  author       = {Syamantak Sarkar and Revoti P. Bora and Bhupender Kaushal and Sudhish N. George and Kiran Raja},
  doi          = {10.1016/j.imavis.2025.105717},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105717},
  shortjournal = {Image Vis. Comput.},
  title        = {Assessing the noise robustness of class activation maps: A framework for reliable model interpretability},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InceptionWTMNet: A hybrid network for alzheimer’s disease detection using wavelet transform convolution and mixed local channel attention on finely fused multimodal images. <em>ICV</em>, <em>163</em>, 105693. (<a href='https://doi.org/10.1016/j.imavis.2025.105693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has emerged as a critical technique for the diagnosis of Alzheimer’s Disease (AD), with the aim of effectively extracting and utilising complementary information from diverse modalities. Current fusion methods frequently cause the precise alignment of source images and do not adequately address parallax issues. This oversight can result in artifacts during the fusion process when images are misaligned. In response to this challenge, we propose a refined registration fusion technique, termed MURF, which integrates multimodal image registration and fusion within a cohesive framework. The Vision Transformer (ViT) has inspired the application of large-kernel convolutions in the diagnosis of Alzheimer’s disease (AD) because of its ability to model long-range dependencies. This approach aims to expand the receptive field and enhance the performance of diagnostic models. Despite requiring a minimal number of floating-point operations (FLOPs), these deep operators encounter challenges associated with over-parameterisation because of high memory access costs, which ultimately compromises computational efficiency. By utilising wavelet transform convolutions (WTConv), we decompose large-kernel depth-wise convolutions into four parallel branches. One branch employs a wavelet-transform convolution with square kernels, while the other two branches incorporate orthogonal wavelet-transform kernels with an identity mapping. This innovative method, with a Mixed Local Channel Attention mechanism, has facilitated the development of the InceptionWTConvolutions network. This network maintains a receptive field comparable to that of large-kernel convolutions, while concurrently minimising over-parameterisation and enhancing computational efficiency. InceptionWTMNet classified AD, MCI, and NC using MRI and PET data from ADNI dataset with 98.69% accuracy, 98.65% recall, 98.70% F1-score, and 98.98% AUC. and provide Graphical abstract in correct format.},
  archive      = {J_ICV},
  author       = {Zenan Xu and Zhengyao Bai and Han Ma and Mingqiang Xu and Qiqin Huang and Tao Lin},
  doi          = {10.1016/j.imavis.2025.105693},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105693},
  shortjournal = {Image Vis. Comput.},
  title        = {InceptionWTMNet: A hybrid network for alzheimer’s disease detection using wavelet transform convolution and mixed local channel attention on finely fused multimodal images},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijar">IJAR - 1</h2>
<ul>
<li><details>
<summary>
(2026). Choosing the center of star-shaped set-valued data compatible with measure-preserving arithmetic. <em>IJAR</em>, <em>188</em>, 109575. (<a href='https://doi.org/10.1016/j.ijar.2025.109575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set-valued data has traditionally been represented by considering non-empty compact and convex subsets of R d with the usual Minkowski addition. An alternative and flexible setting that admits a functional representation are the star-shaped sets. A framework based on a center-radial characterization has been introduced to treat these sets from a statistical point of view. The arithmetic is defined directionally, which is more natural for representing imprecision propagation in higher dimensions. Nevertheless, the problem of determining a center for star-shaped sets coherent with the arithmetic and sound for statistical purposes has not been fully addressed yet. The aim is to advance on the directional characterization for star-shaped sets by considering a measure-preserving arithmetic together with a center selection fully compatible with this arithmetic. The practicability of the new framework will be illustrated using a classical dataset in set-valued statistics.},
  archive      = {J_IJAR},
  author       = {Gil González-Rodríguez},
  doi          = {10.1016/j.ijar.2025.109575},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109575},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Choosing the center of star-shaped set-valued data compatible with measure-preserving arithmetic},
  volume       = {188},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="ipl">IPL - 10</h2>
<ul>
<li><details>
<summary>
(2026). Tighter bounds on non-clairvoyant parallel machine scheduling with prediction to minimize makespan. <em>IPL</em>, <em>191</em>, 106598. (<a href='https://doi.org/10.1016/j.ipl.2025.106598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the non-clairvoyant parallel machine scheduling problem with prediction, with the objective of minimizing the makespan. Improved lower bounds for the problem and competitive ratios of online algorithms with respect to the prediction error are presented for both the non-preemptive and preemptive cases on m identical machines.},
  archive      = {J_IPL},
  author       = {Tianqi Chen and Zhiyi Tan},
  doi          = {10.1016/j.ipl.2025.106598},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106598},
  shortjournal = {Inf. Process. Lett.},
  title        = {Tighter bounds on non-clairvoyant parallel machine scheduling with prediction to minimize makespan},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Note on pancake sorting. <em>IPL</em>, <em>191</em>, 106597. (<a href='https://doi.org/10.1016/j.ipl.2025.106597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present generalized approach to the proof of the lower bound for unburnt pancake sorting problem, where we search for the number f ( n ) of prefix reversals required to sort a stack (permutation) of n pancakes. For this purpose we introduce a new concept of guarded pancake blocks. Gates and Papadimitriou proved that f ( n ) ≥ 17 n / 16 for n a multiple of 16. Heydari and Sudborough improved this bound to f ( n ) ≥ 15 n / 14 for n a multiple of 14. We extend that result to f ( n ) ≥ ⌊ ( 15 n + 9 ) / 14 ⌋ for every n ≥ 6 .},
  archive      = {J_IPL},
  author       = {Marcin Peczarski},
  doi          = {10.1016/j.ipl.2025.106597},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106597},
  shortjournal = {Inf. Process. Lett.},
  title        = {Note on pancake sorting},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Logical characterization of branching bisimilarity over random processes. <em>IPL</em>, <em>191</em>, 106596. (<a href='https://doi.org/10.1016/j.ipl.2025.106596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative aspects like probabilities play an important role in concurrent processes. Providing a (modal) logic for a randomized concurrency model can augment the toolbox of analyzing probabilistic processes, and thus is a frequent topic in the field. In this paper, we are interested in logically characterizing uniformly randomized processes, whose semantical behavior is defined in a model-independent manner. Specifically, we present two modal logics for the uniformly randomized version of finite-state CCS (RCCS fs for short). Our logics extend the Hennessy-Milner logic, and one of them is equipped with the μ operator. Indeed, we prove that both logics characterize the branching bisimilarity for RCCS fs , i.e., two RCCS fs processes are branching bisimilar if and only if they are logically equivalent. To facilitate the proof, we also develop for RCCS fs an up-to proof method, which may be of independent interest.},
  archive      = {J_IPL},
  author       = {Xian Xu and Wenbo Zhang},
  doi          = {10.1016/j.ipl.2025.106596},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106596},
  shortjournal = {Inf. Process. Lett.},
  title        = {Logical characterization of branching bisimilarity over random processes},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Notes about the linear complexity of quaternary cyclotomic sequences of order four. <em>IPL</em>, <em>191</em>, 106595. (<a href='https://doi.org/10.1016/j.ipl.2025.106595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the linear complexity of quaternary cyclotomic sequences with period p , where p > 2 is a prime. Considered sequences are based on classical cyclotomic classes of order four modulo p . We show that any balanced quaternary cyclotomic sequence of order four with period p has high linear complexity over finite ring of order four. Our results generalize those obtained earlier by other authors.},
  archive      = {J_IPL},
  author       = {Vladimir Edemskiy and Zeyu Cao},
  doi          = {10.1016/j.ipl.2025.106595},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106595},
  shortjournal = {Inf. Process. Lett.},
  title        = {Notes about the linear complexity of quaternary cyclotomic sequences of order four},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finding the cyclic covers of a string. <em>IPL</em>, <em>191</em>, 106594. (<a href='https://doi.org/10.1016/j.ipl.2025.106594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the concept of cyclic covers, which generalizes the classical notion of covers in strings. Given any string X , a factor W of X is called a cyclic cover if each position of X belongs to an occurrence of a cyclic shift of W in X . Two cyclic covers are distinct if one is not a cyclic shift of the other. The cyclic covers problem asks for all distinct cyclic covers of an input string X . We present an algorithm that solves the cyclic covers problem in O ( n log ⁡ n ) time, where n is the length of X . It is based on finding a well-structured set of standard occurrences of a constant number of factors of a cyclic cover candidate W , computing the regions of X covered by cyclic shifts of W , extending those factors, and taking the union of the results.},
  archive      = {J_IPL},
  author       = {Roberto Grossi and Costas S. Iliopoulos and Jesper Jansson and Zara Lim and Wing-Kin Sung and Wiktor Zuba},
  doi          = {10.1016/j.ipl.2025.106594},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106594},
  shortjournal = {Inf. Process. Lett.},
  title        = {Finding the cyclic covers of a string},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rank-2 module-LIP with special matrices. <em>IPL</em>, <em>191</em>, 106593. (<a href='https://doi.org/10.1016/j.ipl.2025.106593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice isomorphism problem (LIP) has been studied since 1990s. In 2023, a post-quantum signature scheme known as HAWK was submitted in the NIST standardization of additional signature scheme, which is based on the module lattice isomorphism problem (module-LIP). Module-LIP was formally defined by Mureau et al. at Eurocrypt'24 and Luo et al. reduced the problem of solving module-LIP over CM number fields to a problem of finding the special type of symplectic automorphism. In this paper, we extend this idea further by establishing a reduction of the module-LIP to a problem of finding special types of matrices.},
  archive      = {J_IPL},
  author       = {Manoj Gyawali},
  doi          = {10.1016/j.ipl.2025.106593},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106593},
  shortjournal = {Inf. Process. Lett.},
  title        = {Rank-2 module-LIP with special matrices},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “On the complexity of co-secure dominating set problem” [Inf. process. lett. 185 (2024) 106463]. <em>IPL</em>, <em>191</em>, 106592. (<a href='https://doi.org/10.1016/j.ipl.2025.106592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We correct an error in Theorem 4 in our published paper Panda et al. [3] .},
  archive      = {J_IPL},
  author       = {Bhawani Sankar Panda and Soumyashree Rana and Sounaka Mishra},
  doi          = {10.1016/j.ipl.2025.106592},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106592},
  shortjournal = {Inf. Process. Lett.},
  title        = {Corrigendum to “On the complexity of co-secure dominating set problem” [Inf. process. lett. 185 (2024) 106463]},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On some families of binary codes. <em>IPL</em>, <em>191</em>, 106591. (<a href='https://doi.org/10.1016/j.ipl.2025.106591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give further results on the weight distributions of the two families of binary codes recently constructed by simplicial complexes by (Wu, Lee, 2020), and show that the converse of the above results is also correct, that is, the binary codes with such weight distributions properties must be these two families of codes. Based on the above results, we also construct another family of binary self-orthogonal codes and present their separating properties and applications to the secret sharing scheme, cryptography and other aspects of information security.},
  archive      = {J_IPL},
  author       = {Zihui Liu},
  doi          = {10.1016/j.ipl.2025.106591},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106591},
  shortjournal = {Inf. Process. Lett.},
  title        = {On some families of binary codes},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The complexity of computing the period and the exponent of a digraph. <em>IPL</em>, <em>191</em>, 106590. (<a href='https://doi.org/10.1016/j.ipl.2025.106590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The period of a strongly connected digraph is the greatest common divisor of the lengths of all its cycles. The period of a digraph is the least common multiple of the periods of its strongly connected components. These notions play an important role in the theory of Markov chains and the analysis of powers of nonnegative matrices. While the time complexity of computing the period is well-understood, little is known about its space complexity. We show that the problem of computing the period of a digraph is NL -complete, even if all its cycles are contained in the same strongly connected component. However, if the digraph is strongly connected, we show that this problem becomes L -complete. For primitive digraphs (that is, strongly connected digraphs of period one), there always exists a number m such that there is a path of length exactly m between every two vertices. We show that computing the smallest such m , called the exponent of a digraph, is NL -complete. The exponent of a primitive digraph is a particular case of the index of convergence of a nonnegative matrix, which we also show to be computable in NL , and thus NL -complete.},
  archive      = {J_IPL},
  author       = {Stefan Kiefer and Andrew Ryzhikov},
  doi          = {10.1016/j.ipl.2025.106590},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106590},
  shortjournal = {Inf. Process. Lett.},
  title        = {The complexity of computing the period and the exponent of a digraph},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A simple supercritical tradeoff between size and height in resolution. <em>IPL</em>, <em>191</em>, 106589. (<a href='https://doi.org/10.1016/j.ipl.2025.106589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe CNFs in n variables which, over a range of parameters, have small resolution refutations but are such that any small refutation must have height larger than n (even exponential in n ), where the height of a refutation is the length of the longest path in it. This is called a supercritical tradeoff between size and height because, if we do not care about size, every CNF is refutable in height n . Our proof method uses a simple construction, based on or-ification and base d representations of integers, to reduce the number of variables. A similar result appeared in [Fleming, Pitassi and Robere, ITCS '22], for different formulas using a more complicated construction for reducing the number of variables. Small refutations of our formula are necessarily highly irregular, making it a plausible candidate to separate resolution from pool resolution, which amounts to separating CDCL with restarts from CDCL without restarts. We are not able to show this. In the other direction, we show that a simpler version of our formula, with a similar irregularity property, does have polynomial size pool resolution refutations and thus does not provide such a separation for CDCL.},
  archive      = {J_IPL},
  author       = {Sam Buss and Neil Thapen},
  doi          = {10.1016/j.ipl.2025.106589},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106589},
  shortjournal = {Inf. Process. Lett.},
  title        = {A simple supercritical tradeoff between size and height in resolution},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="isat">ISAT - 39</h2>
<ul>
<li><details>
<summary>
(2025). Voltage tracking and regulation of vehicle PEMFC system under low load condition based on fuzzy LQG hybrid strategy. <em>ISAT</em>, <em>165</em>, 510-523. (<a href='https://doi.org/10.1016/j.isatra.2025.06.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In automotive fuel cell systems, high-voltage operation accelerates carbon support and platinum catalyst degradation, significantly compromising system durability. This study develops a dynamic system model with active cathode recirculation to capture the transient response of voltage, and proposes a hybrid control scheme that combines a proportional compensator with a fuzzy LQG controller to effectively enhance voltage regulation and disturbance tracking capabilities. Extensive simulation and hardware-in-the-loop (HiL) confirm the precision and rapid response of the developed controller. Compared to single LQG and fuzzy LQG controllers, the error reduction achieved is 49.3 % and 40.3 %, respectively, and the overall control benefit ratio improves by 19.2 % and 11 %. This method balances dynamic response with control efforts, effectively reducing the risk of high voltage-induced degradation under low-load conditions.},
  archive      = {J_ISAT},
  author       = {Ze Liu and Sichuan Xu and Baitao Zhang and Sida Guo},
  doi          = {10.1016/j.isatra.2025.06.008},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {510-523},
  shortjournal = {ISA Trans.},
  title        = {Voltage tracking and regulation of vehicle PEMFC system under low load condition based on fuzzy LQG hybrid strategy},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade alarm systems: A study on singular value analysis. <em>ISAT</em>, <em>165</em>, 497-509. (<a href='https://doi.org/10.1016/j.isatra.2025.06.023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel alarm system designed for use with both Independent and Identically Distributed (IID) and non-IID variables. The proposed algorithm, termed the Cascade Alarm System (CAS), utilizes the largest singular value of the signal as the basis for fault detection, employing k alarm subsystems. The greatest singular values extracted from the Lagged Covariance Matrix (LCM) of a sliding window constitute the output of the first alarm subsystem. The CAS offers two primary advantages. First, each subsystem independently generates its own alarm signal, resulting in a more flexible multilevel architecture. Second, the multilevel structure, founded on singular value decomposition (SVD), exhibits a filtering property that enhances its resilience to noise and inaccuracies. The maximum singular value effectively captures the essential information of the signal, ensuring that the filtering capabilities of the proposed method do not significantly compromise the performance of the alarm system or the integrity of critical signal information. The experimental results from the implementation of the proposed alarm system under various fault conditions demonstrate satisfactory performance. Additionally, the performance of the Cascade Alarm System has been compared with leading contemporary alarm system design methodologies, including median, moving average filters, delay timers, Cumulative Sum Control Chart (CUSUM), and serial method.},
  archive      = {J_ISAT},
  author       = {J. Taheri-Kalani and M. Aliyari-Shoorehdeli and Gh. Latif-Shabgahi},
  doi          = {10.1016/j.isatra.2025.06.023},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {497-509},
  shortjournal = {ISA Trans.},
  title        = {Cascade alarm systems: A study on singular value analysis},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow pulsation compensation based composite adaptive active disturbance rejection control for electro-hydrostatic actuators. <em>ISAT</em>, <em>165</em>, 486-496. (<a href='https://doi.org/10.1016/j.isatra.2025.06.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the residual pressure accumulated during the reciprocating movement of the plunger pump, there is a deviation between the flow pulsation and the theoretical calculation value. Current nonlinear control methods for the electro-hydrostatic actuator (EHA) often oversimplify and compensate for flow pulsation linearly, neglecting its nonlinear characteristics and deviation effects. This approach increases matching uncertainties and amplifies noise due to higher control gains, thus limiting the improvement of control performance. To address this issue, this paper proposes a composite adaptive disturbance rejection control method based on flow pulsation compensation for the EHA. This method equates the flow pulsation model of the pump to a combination of a theoretical flow pulsation control input term and a bounded disturbance term (the difference between the theoretical and actual flow pulsation), followed by the design of a composite adaptive law to handle parameter uncertainties, and the design of the expanded state observers based on position and pressure signals to estimate and compensate for the uncertainties nonlinearly. Finally, the effectiveness of the proposed method is verified by comparing with other control methods through experiments.},
  archive      = {J_ISAT},
  author       = {Yaowen Ge and Xiaowei Yang and Weilin Zhu and Wenxiang Deng and Jianyong Yao},
  doi          = {10.1016/j.isatra.2025.06.014},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {486-496},
  shortjournal = {ISA Trans.},
  title        = {Flow pulsation compensation based composite adaptive active disturbance rejection control for electro-hydrostatic actuators},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polytopic inclusion-based model predictive control for quasi-LPV systems using vertex system models and gain scheduling. <em>ISAT</em>, <em>165</em>, 474-485. (<a href='https://doi.org/10.1016/j.isatra.2025.05.051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Model Predictive Control (MPC) strategy for a class of Quasi-Linear Parameter-Varying (quasi-LPV) systems characterized by a measurable time-varying parameter. The core of the proposed quasi-LPV-MPC controller lies in the utilization of a polytopic representation along with a gain-scheduled controller. A terminal cost that depends explicitly on the scheduling parameter is used. However, for the implementation, a complementary cost function is used to frame the optimization problem at each vertex level so that the requirement of updating the varying parameters over the prediction horizon is relaxed. Though the resulting suboptimal controller involves more computational burden, the proposed method demonstrates improvement in control performance over traditional MPC schemes. Experimental validation on a cascaded coupled tank system underscores the practical efficacy of the proposed quasi-LPV-MPC controller, while simulation studies on a twin rotor multi-input multi-output system serve as an additional demonstration example case. Comparative performance evaluations against both linear and nonlinear MPCs clearly illustrate that the quasi-LPV-MPC offers better control precision, adaptability, and the overall system responsiveness, thus positioning it as an effective solution for quasi-LPV systems.},
  archive      = {J_ISAT},
  author       = {Rangoli Singh and Sandip Ghosh and Devender Singh},
  doi          = {10.1016/j.isatra.2025.05.051},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {474-485},
  shortjournal = {ISA Trans.},
  title        = {Polytopic inclusion-based model predictive control for quasi-LPV systems using vertex system models and gain scheduling},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the global energy optimization of multi-source and multi-actuator hydraulic systems based on dynamic programming and improved adaptive genetic algorithm. <em>ISAT</em>, <em>165</em>, 450-473. (<a href='https://doi.org/10.1016/j.isatra.2025.06.010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source and multi-actuator hydraulic systems (MSAHSs) are widely used in high-power energy transmission and construction machinery. However, individual control of each component without considering the overall power matching leads the system to the low-efficiency zone, results in environmental pollution and huge economic loss. Therefore, it is highly desirable to find a way of obtaining energy-saving green MSAHSs. In this paper, the power consumption model of closed MSAHSs is established firstly to analyze theoretical factors affecting the component efficiency and find that the hydraulic pressure is the key factor. On this basis, a multi-algorithm integration global power matching method is then proposed, which consist of back propagation (BP) neural network, dynamic programming (DP) and improved adaptive genetic algorithm (IAGA). BP is used to construct efficiency prediction models for power elements (pumps, motors and engines) respectively, DP is used for elements’ high efficiency zone preliminary search, and IAGA is used to realize the global power matching of the multiple power units with energy conversion and transfer finally through optimal control parameters precise searching. Experiment is conducted on the closed MSAHS in a hydraulic fracturing vehicle. Results demonstrate that the MSAHS applied with multi-algorithm integration method improves the overall efficiency to a highest fuel savings of 35.5 % under normal conditions compared with local power matching control.},
  archive      = {J_ISAT},
  author       = {Yuhang Zhong and Wenting Chen and Zihao Chen and Guanyu Zhai and Chao Ai and Gexin Chen},
  doi          = {10.1016/j.isatra.2025.06.010},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {450-473},
  shortjournal = {ISA Trans.},
  title        = {Research on the global energy optimization of multi-source and multi-actuator hydraulic systems based on dynamic programming and improved adaptive genetic algorithm},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent energy adaptive control of loader shoveling system. <em>ISAT</em>, <em>165</em>, 437-449. (<a href='https://doi.org/10.1016/j.isatra.2025.06.021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loaders are often faced with various working objects during the shoveling process. The differences in working resistance and its time-varying unpredictability when shoveling different objects are the main causes of high energy consumption during the shoveling stage. In this paper, through the analysis of the shoveling process, the influence of the compacted layer on the working resistance is obtained. The constructed Discrete Element Method (DEM) simulation model is used to elucidate that the timely lifting of the boom can have a destructive effect on the compacted layer. Moreover, considering the diversity of working objects, a study was carried out on the effect of different boom lifting ranges on the destruction of the compacted layer. The loader shoveling system's intelligent Energy Adaptive Control (EAC) strategy is constructed by integrating the material recognition model based on the Back Propagation (BP) neural network algorithm. This control strategy can output the set pilot pressure according to the material type, realize the intelligent adjustment of the lifting range of the boom with the change of material type, and reduce the working resistance during the shoveling stage. The peak engine power consumed while shoveling sand, gravel, and boulders decreased by 20.6 %, 19.1 %, and 10.9 %, respectively, improving the energy utilization rate of the loader shoveling system when facing different working objects.},
  archive      = {J_ISAT},
  author       = {Bingwei Cao and Changhao Mu and Jiaqi Dong and Guangliang Tian and Yuqi Wang},
  doi          = {10.1016/j.isatra.2025.06.021},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {437-449},
  shortjournal = {ISA Trans.},
  title        = {Intelligent energy adaptive control of loader shoveling system},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis and design of oscillation frequency correction for servo resonance suppression. <em>ISAT</em>, <em>165</em>, 422-436. (<a href='https://doi.org/10.1016/j.isatra.2025.06.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical resonance poses significant hazards to the normal operation of the servo systems. To mitigate mechanical resonance, online adaptive notch filter is extensive used, thus the precise determination of resonant frequency holds significant importance. However, in certain scenarios involving the high-bandwidth servo system, a phenomenon known as frequency shift can make the notch filter ineffective in addressing servo resonance. To solve this problem, an oscillation frequency correction scheme based on two improved sliding-mode observers (ISMOs) utilizing a dual-power approximation law is proposed. First, the oscillation frequency shift is analyzed around the system delay, which can be equivalently modeled using a Pade approximation method. Subsequently, a feedback loop featuring two adaptive feedback coefficients is designed to automatically tune the time factor. Remarkably, the scheme can dynamically correct oscillation frequency, thereby promoting resonance suppression. At the same time, ISMOs-identified mechanical parameters provide critical foundations for feedback coefficient adjustment. It is worth noting that the dual-power approximation law effectively suppresses high-frequency chatter while maintaining parameter identification accuracy. Finally, the effectiveness of the scheme is validated through simulation and experimental results.},
  archive      = {J_ISAT},
  author       = {Yanan Tang and Shaowu Lu and Puliang Yu and Bao Song},
  doi          = {10.1016/j.isatra.2025.06.011},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {422-436},
  shortjournal = {ISA Trans.},
  title        = {Analysis and design of oscillation frequency correction for servo resonance suppression},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A segmented model based internal model control scheme of electromagnetic micro-mirror systems. <em>ISAT</em>, <em>165</em>, 408-421. (<a href='https://doi.org/10.1016/j.isatra.2025.06.003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a segmented internal model control (SIMC) scheme based on the segmented combination model of the electromagnetic micro-mirror system (EMMS) is established. Notice that highly underdamped oscillation and rate-dependent hysteresis exist in the EMMS, so it is a complex nonlinear dynamic system. In order to control the deflection angle of the EMMS using the internal model control strategy, it is necessary to establish the inverse model of the EMMS. Therefore, a new model structure that is convenient for inversion is proposed in this paper to describe the characteristics of the EMMS with underdamped and rate-dependent hysteresis. In the proposed scheme, the model is a combination of a group of weighted sub-models based on the segmentation of the system's operating frequency. The weight of each segmented sub-model is not a constant but a new type of function which is also called the smoothing factor. Its function is to smooth the switching between sub-models, thereby reducing the dynamic error caused by model switching. In addition, the particle swarm optimization (PSO) algorithm is used to determine the optimal frequency segmentation points, which helps to obtain the optimal model for describing the system characteristics. Based on the proposed segmented combination model, the corresponding segmented internal model control with two-degree-of-freedom filters is proposed, and the corresponding filters in the internal model control are designed based on the small gain theorem. Finally, the proposed control strategy is applied to the control of the deflection angle of the electromagnetic micro-mirror to verify the proposed control method. Moreover, the non-smooth internal model control strategy is also used for comparison in the experiments.},
  archive      = {J_ISAT},
  author       = {Ruili Dong and Qingyuan Tan and Yonghong Tan and Xiaoli Song and Tianyu Wang},
  doi          = {10.1016/j.isatra.2025.06.003},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {408-421},
  shortjournal = {ISA Trans.},
  title        = {A segmented model based internal model control scheme of electromagnetic micro-mirror systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PPAC-pilot: Prescribed-performance augmented control for fixed-wing autopilots. <em>ISAT</em>, <em>165</em>, 395-407. (<a href='https://doi.org/10.1016/j.isatra.2025.06.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a Prescribed-Performance Augmented Control (PPAC) framework designed for fixed-wing Unmanned Aerial Vehicle (UAV) autopilots. The PPAC strategy aims to enhance, rather than replace, existing PID control loops in open-source autopilots. Although traditional autopilots effectively manage routine tasks in most applications, their reliance on meticulous tuning remains a limitation. To address this, PPAC leverages historical flight data, a frequently overlooked resource, to derive dynamic linearization models and control laws without requiring explicit UAV models. The PPAC framework is then integrated with the Total Energy Control System (TECS) for practical deployment in takeoff and cruising scenarios. Comprehensive numerical simulations and Hardware-in-the-Loop (HIL) tests validate the strategy by comparing baseline autopilot performance with PPAC-augmented systems. Results confirm that PPAC ensures prescribed performance bounds for altitude tracking errors across evaluated scenarios, demonstrating its effectiveness in augmenting autopilots with minimized redesign efforts.},
  archive      = {J_ISAT},
  author       = {Qiuyang Tian and Zelin Wang and Tianjiang Hu},
  doi          = {10.1016/j.isatra.2025.06.001},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {395-407},
  shortjournal = {ISA Trans.},
  title        = {PPAC-pilot: Prescribed-performance augmented control for fixed-wing autopilots},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hysteresis observer enhanced integral terminal sliding mode control of piezoelectric platform for precision tracking applications. <em>ISAT</em>, <em>165</em>, 384-394. (<a href='https://doi.org/10.1016/j.isatra.2025.06.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinearity of piezo-actuated positioning platforms significantly impacts their performance in high-precision applications. In this work a dynamic model of piezoelectric platform was developed firstly with the asymmetric Bouc-Wen model. Next, a terminal sliding mode observer with the super-twisting mechanism was designed to accurately estimate the state of the system. Then, a novel control strategy named Hysteresis Observer Enhanced Integral Terminal Sliding Mode Controller (HO-ITSMC) was proposed to achieve precise displacement tracking. Its stability is theoretically proved by the Lyapunov theorem. A key feature of this controller lies in its ability to drive the state of the system into zero in finite time, regardless of the initial state. Extensive experiments have thoroughly validated the effectiveness of the proposed control method, demonstrating its superior precision-tracking performance compared to traditional controllers.},
  archive      = {J_ISAT},
  author       = {Jie Chen and Lei Ni and Xuan Liao and Geng Wang and Lanqiang Zhang and Na Yao and Yijun Li and Sumeet S. Aphale},
  doi          = {10.1016/j.isatra.2025.06.022},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {384-394},
  shortjournal = {ISA Trans.},
  title        = {Hysteresis observer enhanced integral terminal sliding mode control of piezoelectric platform for precision tracking applications},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive robust control for ball-screw drives with flexible transmission and nonlinear friction via dynamic surface control approach. <em>ISAT</em>, <em>165</em>, 372-383. (<a href='https://doi.org/10.1016/j.isatra.2025.05.050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible deformation and nonlinear friction in ball-screw drive systems are important factors that restrict the improvement of tracking performance. In this paper, a high-performance adaptive controller is presented for ball screw drives to suppress vibration and improve tracking accuracy. A two-inertia model with torsional vibration state is established to fit the dynamics of the drive system while the continuously differentiable LuGre model characterizes the nonlinear friction disturbance. Based on the established nonlinear model, an adaptive robust controller (ARC) is designed by using the backstepping approach to overcome the parametric uncertainties and hard-to-model dynamics. The dual-observer is employed in the controller to observe and compensate for the nonlinear friction, which improves the low-velocity tracking performance of the ball-screw drives. Meanwhile, first-order filters are introduced by dynamic surface control (DSC) technique to eliminate the “complexity explosion” problem caused by the backstepping method. The controller theoretically guarantees that all signals of the closed-loop system are bounded, and the convergence of tracking error is also ensured via Lyapunov analysis. The effectiveness of the proposed controller is verified through simulation and experimental results.},
  archive      = {J_ISAT},
  author       = {Yanliang Sheng and Guofeng Wang and Fei Wang and Decai Li and Mantang Hu},
  doi          = {10.1016/j.isatra.2025.05.050},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {372-383},
  shortjournal = {ISA Trans.},
  title        = {Adaptive robust control for ball-screw drives with flexible transmission and nonlinear friction via dynamic surface control approach},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-sensing framework for weak fault detection of planetary gearbox. <em>ISAT</em>, <em>165</em>, 358-371. (<a href='https://doi.org/10.1016/j.isatra.2025.06.009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planetary gearbox fault detection has attracted wide attention due to the planetary gearbox’s key role in modern electro-mechanic equipment. However, traditional fault detection technologies still heavily rely on additional sensors. The resulting enormous cost of sensors restricts the application of those technologies. Given this situation, a self-sensing fault detection framework to explore the weak fault impulses of the planetary gearbox is presented without additional sensors. In this framework, we first capture the preliminary signals from the servo control systems. Then, the hole control model of the motor driving planetary gearbox is constructed. After this step, the feasibility of fault detection for the planetary gearbox through the motor servo control signals is investigated. With the measured servo control signals, a multi-signal assisting adaptive time synchronous averaging method is first proposed to explore fault impulses. This method first introduces a periodic enhanced Gini to select optimal parameters adaptively. Finally, experiments on a weak fault of three components in the planetary gearbox are carried out separately, certifying our framework's validation of planetary gearbox fault detection. This framework hopes to provide a novel scheme for the weak fault self-sensing of planetary gearboxes.},
  archive      = {J_ISAT},
  author       = {Dexin Chen and Ming Zhao and Shudong Ou and Sen Li and Xiaolong Han},
  doi          = {10.1016/j.isatra.2025.06.009},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {358-371},
  shortjournal = {ISA Trans.},
  title        = {A self-sensing framework for weak fault detection of planetary gearbox},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear self-triggered MPC without terminal conditions for trajectory tracking. <em>ISAT</em>, <em>165</em>, 347-357. (<a href='https://doi.org/10.1016/j.isatra.2025.06.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a trajectory tracking problem for a class of nonlinear discrete-time systems is investigated by a model predictive control (MPC) strategy. Compared with the standard MPC strategy, the proposed MPC strategy removes terminal conditions, including terminal penalty terms and terminal state constraints. This novel design requires fewer parameters to be determined, which leads to high practicability. Moreover, to reduce the computational burden, a self-triggered mechanism is presented by using the discrepancy in the cost function between adjacent time instants. Then, an additional compensation variable is designed for the redundancy from the self-triggered mechanism. Finally, we present a mathematical proof for the recursive feasibility of the optimization problem. The effectiveness and practicality of the proposed self-triggered MPC strategy are verified through simulation examples and experimental results on a mobile vehicle experimental platform.},
  archive      = {J_ISAT},
  author       = {Hai Zhao and Hongjiu Yang and Yuanqing Xia and Jinhui Zhang},
  doi          = {10.1016/j.isatra.2025.06.005},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {347-357},
  shortjournal = {ISA Trans.},
  title        = {Nonlinear self-triggered MPC without terminal conditions for trajectory tracking},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control of multi-bus DC microgrids based on distributed dual-projection-layer recurrent neural network considering bus voltage regulation. <em>ISAT</em>, <em>165</em>, 335-346. (<a href='https://doi.org/10.1016/j.isatra.2025.06.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the broad application of plug-and-play loads, it brings new challenges to conventional control issues in DC microgrids. This work addresses the joint optimization of generation costs and transmission line power losses considering bus voltage regulation. Specifically, the concept of virtual load nodes is first introduced so that loads can be implemented as plug-and-play. Through Kron Reduction, bus voltage of load nodes is indirectly controlled by DG nodes. Then, a distributed dual-projection-layer recurrent neural network (DRNN) is proposed for real-time optimal control. The coupled voltage and current are simultaneously maintained within safe bounds. By using Lyapunov synthesis, the convergence of the DRNN is demonstrated. The effectiveness of the proposed methods is evaluated by simulations in terms of plug-and-play test and comparative analysis.},
  archive      = {J_ISAT},
  author       = {Yuanyuan Zhu and Fan Yang and Guoyu Lin},
  doi          = {10.1016/j.isatra.2025.06.029},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {335-346},
  shortjournal = {ISA Trans.},
  title        = {Optimal control of multi-bus DC microgrids based on distributed dual-projection-layer recurrent neural network considering bus voltage regulation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic nonlinear system modelling and parametric oscillation response characteristics of gas turbines. <em>ISAT</em>, <em>165</em>, 320-334. (<a href='https://doi.org/10.1016/j.isatra.2025.06.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas turbines, as highly complex thermal systems, exhibit significant nonlinearity and stochastic coupling in process control. Under closed-loop automatic speed regulation, persistent parametric oscillations may arise, posing serious threats to system reliability and safety. Aiming to reveal the stochastic response characteristics of parametric oscillations in gas turbines, this paper proposes a novel framework for analyzing the evolution law of parametric oscillation and multi-source stochastic excitations based on stochastic dynamics model, which is derived from thermodynamic equations and verified by measurement data. The internal stochastic excitation is determined by information entropy, while the form of the stochastic process of the external stochastic excitation is identified through data-driven reverse identification. The PDF evolution law of parametric oscillation is studied for different excitation forms, and the bifurcation behavior and sensitivity analysis of them are carried out. Under typical operating conditions, the synergistic effect of internal and external stochastic excitations reduces parametric oscillation amplitude by approximately 31 % compared to internal excitation alone. Moreover, the originally tri-modal distribution evolves into a unimodal pattern, revealing the transition trend of parametric oscillation behavior in gas turbines. These findings offer an effective approach to analyze parametric oscillation.},
  archive      = {J_ISAT},
  author       = {Xingyun Jia and Dengji Zhou},
  doi          = {10.1016/j.isatra.2025.06.028},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {320-334},
  shortjournal = {ISA Trans.},
  title        = {Stochastic nonlinear system modelling and parametric oscillation response characteristics of gas turbines},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy modal time-scheduled control and l2-gain analysis for switched nonlinear systems. <em>ISAT</em>, <em>165</em>, 308-319. (<a href='https://doi.org/10.1016/j.isatra.2025.06.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the fuzzy modal time-scheduled control problem for switched nonlinear systems with L 2 -gain performance. Combined with the hybrid dwell time method, we propose a switched fuzzy modal time-scheduled control (FMTSC) strategy, and establish a criterion for H ∞ performance in systems comprising both unstable and stable subsystems. Meanwhile, we further develop a class of time-scheduled multiple discontinuous Lyapunov functions (TMDLFs) for the switched Takagi-Sugeno (T-S) fuzzy system with L 2 -gain property. Finally, comparative and practical examples are provided to demonstrate the validity of derived theoretical result.},
  archive      = {J_ISAT},
  author       = {Jinling Wang and Jun-Guo Lu and Jiarong Li and Qinghao Zhang and Cheng Hu},
  doi          = {10.1016/j.isatra.2025.06.026},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {308-319},
  shortjournal = {ISA Trans.},
  title        = {Fuzzy modal time-scheduled control and l2-gain analysis for switched nonlinear systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving a class of resource allocation problem under dynamic constraints: A predefined-time distributed optimization scheme. <em>ISAT</em>, <em>165</em>, 295-307. (<a href='https://doi.org/10.1016/j.isatra.2025.05.045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a predefined-time distributed optimization algorithm is designed to solve the resource allocation problem (RAP) with dynamic constraints. This algorithm updates auxiliary variables in real time through a distributed approach and allocates resources to each node based on dynamic constraints. Its advantages include ensuring all nodes quickly converge to the optimal value within a predefined time, thereby enhancing algorithm efficiency. Moreover, the auxiliary variables exchanged between nodes do not contain any real physical information, effectively preventing privacy data leakage. In addition, the convergence of the algorithm is analyzed strictly by the Lyapunov method, which ensures the accuracy of the algorithm. Finally, application examples in smart grids and multi-UAV dynamic collaboration are provided to demonstrate the effectiveness and advantages of the algorithm in different application scenarios.},
  archive      = {J_ISAT},
  author       = {Chuxiong Su and Zhongxu Chen and Zhengyuan Zhu and Hao Dai and Jing Chang},
  doi          = {10.1016/j.isatra.2025.05.045},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {295-307},
  shortjournal = {ISA Trans.},
  title        = {Solving a class of resource allocation problem under dynamic constraints: A predefined-time distributed optimization scheme},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-optimal global path planning and collision-avoidance local path planning for USVs in traffic separation scheme-implemented coastal waters. <em>ISAT</em>, <em>165</em>, 280-294. (<a href='https://doi.org/10.1016/j.isatra.2025.06.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under multiple constraints including unmanned surface vehicle (USV) dynamics, traffic separation scheme (TSS) requirements, navigable water boundaries, and safety thresholds for collision risks, time-optimal path planning and collision-avoidance (COLAV) path planning for USVs in TSS-implemented coastal waters remain challenging. To overcome this challenge, we innovatively develop a hierarchical Gaussian-process-based nonlinear programming (GPNLP) approach for the USV time-optimal global path planning and COLAV local path planning. We model irregular static obstacles using Gaussian process regression for the first time, such that navigable waters are more sufficiently utilized for path planning. A TSS compliance assessment function is created to output violation penalties for the TSS requirements that should be satisfied as far as practicable. Accordingly, we plan the time-optimal global path and the COLAV local path hierarchically by minimizing two integral objective functions (with respect to the TSS violation penalties) subject to the multiple constraints. Simulations and simulation comparison results demonstrate that both the planned USV time-optimal global path and COLAV local path under the proposed hierarchical GPNLP approach are USV dynamics compliant and TSS compliant.},
  archive      = {J_ISAT},
  author       = {Yihan Tao and Jialu Du},
  doi          = {10.1016/j.isatra.2025.06.030},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {280-294},
  shortjournal = {ISA Trans.},
  title        = {Time-optimal global path planning and collision-avoidance local path planning for USVs in traffic separation scheme-implemented coastal waters},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time switching tracking control for unmanned helicopter with multiple constraints. <em>ISAT</em>, <em>165</em>, 268-279. (<a href='https://doi.org/10.1016/j.isatra.2025.06.017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a fixed-time switching tracking control scheme based on the fixed-time disturbance observer (FTDO) is proposed for a 6-DOF unmanned helicopter (UH) with multiple constraints and composite disturbances. The developed fixed-time controller guarantees that the system tracks the desired trajectory within a certain time, regardless of initial conditions. The multiple constraints include input saturation and time-varying output constraints. An improved fixed-time auxiliary system is applied to compensate for the effects of input saturation nonlinearity. By developing a novel switching boundary protection algorithm, a switching control scheme is further designed to solve the output constraints better. An improved FTDO is developed to estimate composite disturbances containing saturation function approximation errors and external disturbances. On this basis, a fixed-time switching back-stepping control method is employed for the position and attitude loops, which enables the UH to track the desired trajectory within the flight path constraints. The experimental results verify the effectiveness of the proposed scheme.},
  archive      = {J_ISAT},
  author       = {Haibo Wang and Shuang Shi and Ziyang Zhen and Ju Jiang},
  doi          = {10.1016/j.isatra.2025.06.017},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {268-279},
  shortjournal = {ISA Trans.},
  title        = {Fixed-time switching tracking control for unmanned helicopter with multiple constraints},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leaderless attitude synchronization control of multiple flexible spacecraft on SO(3). <em>ISAT</em>, <em>165</em>, 254-267. (<a href='https://doi.org/10.1016/j.isatra.2025.06.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents adaptive controllers for leaderless attitude synchronization of multiple flexible spacecraft on S O ( 3 ) under communication topologies containing spanning tree(s). To provide a reference attitude for each spacecraft, distributed observers in 9-dimensional Euclidean space are proposed based on a smooth mapping from Euclidean space ℝ 3 × 3 to Lie group S O ( 3 ) . Both the scenarios with arbitrary and almost zero final angular velocities are considered. Subsequently, adaptive continuous controllers on S O ( 3 ) are presented to achieve the leaderless attitude synchronization subject to external disturbance, while guaranteeing boundedness of flexible vibration. Rigorous proofs are presented to show the convergence of the proposed control methods. The effectiveness of the proposed strategies is further demonstrated by numerical simulations.},
  archive      = {J_ISAT},
  author       = {Chenlu Feng and Weicheng Jin and Ti Chen and Lifeng Wang},
  doi          = {10.1016/j.isatra.2025.06.031},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {254-267},
  shortjournal = {ISA Trans.},
  title        = {Leaderless attitude synchronization control of multiple flexible spacecraft on SO(3)},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust predefined fixed-time formation-containment control for multiple unmanned surface vehicles with input saturation. <em>ISAT</em>, <em>165</em>, 241-253. (<a href='https://doi.org/10.1016/j.isatra.2025.06.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predefined fixed-time formation-containment (PFTFC) control problem for unmanned surface vehicles (USVs) under unknown disturbances and input saturation is investigated, where the leaders form a formation configuration and the followers converge to the predefined convex hull formed by the leaders within a fixed time. To address this issue, a two-layer framework is introduced, decomposing the problem into trajectory estimation and trajectory tracking components. In the first layer, a novel fixed-time trajectory estimator is proposed for the leaders and the followers to estimate the desired trajectory. In the second layer, to eliminate the effects of unknown disturbances and input saturation, a fixed-time disturbance observer and an auxiliary system are proposed. Then combining fixed-time Lyapunov stability and integral sliding mode control, fixed-time control laws are proposed for both the leaders and the followers, respectively. Finally, a numerical simulation example is presented to illustrate the effectiveness of the method introduced in this paper.},
  archive      = {J_ISAT},
  author       = {Yong Chen and Jinlong Huang and Fuxi Niu and Xunhua Dai and Haoyue Huang},
  doi          = {10.1016/j.isatra.2025.06.019},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {241-253},
  shortjournal = {ISA Trans.},
  title        = {Robust predefined fixed-time formation-containment control for multiple unmanned surface vehicles with input saturation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-following control for follow-up support systems under model deviation and time delay. <em>ISAT</em>, <em>165</em>, 232-240. (<a href='https://doi.org/10.1016/j.isatra.2025.06.015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Follow-up support technology can flexibly and effectively suppress machining chatter in thin-walled components. This paper proposes a servo collaborative constraint handling scheme that focuses on achieving coordinated control for the follow-up support system under multi-source coupled constraints and uncertainties. Firstly, a four-point constraint method is introduced, which simplifies the description of pose coordination through the introduction of auxiliary points, and constructs the coordinated relationship of the dual robots’ end-effectors under complex geometric constraints in an intuitive and analytical manner. Secondly, a robust controller based on constraint-following theory is designed, providing an effective means to parameterize the total uncertainty boundary structure caused by model deviation and time delay. Finally, the practical stability of the control algorithm is proven, and its effectiveness and strong robustness are validated through comparative simulations.},
  archive      = {J_ISAT},
  author       = {Fangfang Dong and Zhao Liu and Xiaomin Zhao and Jiang Han and Xiaoyong Huang},
  doi          = {10.1016/j.isatra.2025.06.015},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {232-240},
  shortjournal = {ISA Trans.},
  title        = {Constraint-following control for follow-up support systems under model deviation and time delay},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability analysis of delayed neural networks via novel delay-dependent LKF and integral inequality. <em>ISAT</em>, <em>165</em>, 222-231. (<a href='https://doi.org/10.1016/j.isatra.2025.06.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current paper is concerned with the stability analysis of delayed neural networks. In the case that the delay derivative is restricted with an upper bound only, the augmented LKFs often contain high-degree terms of the time-varying delay, resulting in the non-convex derivatives of LKFs, which can be solved by introducing extra delay-multiplied state variables to transform the non-convex delay-dependent terms into convex ones. To make fuller use of the delay-multiplied state variables and the delay-derivative-dependent information, these delay-multiplied state variables are introduced into an LKF and the integral inequality through the proper augmentation in this paper. Meanwhile, some free-matrix-based zero equations are introduced into this delay-dependent inequality to provide more freedom. By applying the augmented LKF and the novel integral inequality, a delay-dependent stability criterion of delayed neural networks with less conservatism is established, whose advantages are verified by three examples.},
  archive      = {J_ISAT},
  author       = {Fei Long and Chuan-Ke Zhang and Yanjun Shen and Qicheng Mei and Qing Chen},
  doi          = {10.1016/j.isatra.2025.06.027},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {222-231},
  shortjournal = {ISA Trans.},
  title        = {Stability analysis of delayed neural networks via novel delay-dependent LKF and integral inequality},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predefined-time adaptive learning control of nonlinear strict-feedback systems via dynamic regressor extension and mixing. <em>ISAT</em>, <em>165</em>, 209-221. (<a href='https://doi.org/10.1016/j.isatra.2025.06.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a parameter identification algorithm and a novel adaptive tracking control strategy for a specific group of nonlinear strict-feedback systems incorporating the concept of predefined time under model uncertainties. A three-layer transformation-based parameter estimation method with predefined-time convergence properties is proposed to relax the strict persistent excitation condition imposed by conventional approaches. The singular terms that may occur in traditional backstepping design procedures are avoided by using a hyperbolic tangent function to design new control laws and filters. Composite learning control approach that incorporates the algorithm for parameter identification into the framework for adaptive dynamic surface control can achieve error convergence within a practical predefined time. By using Lyapunov analysis, the semi-global uniformly predefined-time boundedness for the closed-loop dynamics is demonstrated. Numerical experiments demonstrate the viability of developed control scheme.},
  archive      = {J_ISAT},
  author       = {Zhonghua Wu and Kuncheng Ma and Junkang Ni},
  doi          = {10.1016/j.isatra.2025.06.016},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {209-221},
  shortjournal = {ISA Trans.},
  title        = {Predefined-time adaptive learning control of nonlinear strict-feedback systems via dynamic regressor extension and mixing},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive PI nonlinear cooperative control for motor cluster. <em>ISAT</em>, <em>165</em>, 191-208. (<a href='https://doi.org/10.1016/j.isatra.2025.05.047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the effects of nonlinearities and uncertainties in the speed regulation of permanent magnet synchronous motors (PMSMs), an adaptive PI nonlinear control strategy is introduced. First, a nonlinear system model is developed using the PMSM mathematical model, and an adaptive PI nonlinear control approach is designed. Numerical simulations are conducted to demonstrate that this control method effectively tracks the system’s desired values. Then, through a group of comparative simulation experiments, the comparison effect of the designed adaptive PI nonlinear control method and the traditional PI control method is analyzed and compared. Additionally, four PMSM collaborative control system models, including the speed tracking and speed synchronization control structures, are constructed. Finally, a simulation model for a cooperative PMSM control system is developed to evaluate the system’s speed tracking capability and the synchronization between multiple motors. The results show that in the designed motor cluster cooperative control system, the PMSM motor cluster using adaptive PI nonlinear control method can achieve cooperative control in speed tracking and speed synchronization, and can maintain stable operation against nonlinear problems and unknown disturbances.},
  archive      = {J_ISAT},
  author       = {Yiting Chen and Yushen Wu and Kairui Chen and Jianhui Wang and Zian Wang},
  doi          = {10.1016/j.isatra.2025.05.047},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {191-208},
  shortjournal = {ISA Trans.},
  title        = {Adaptive PI nonlinear cooperative control for motor cluster},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven parallel linear controllers for reference tracking in nonlinear systems. <em>ISAT</em>, <em>165</em>, 183-190. (<a href='https://doi.org/10.1016/j.isatra.2025.05.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference tracking control for nonlinear systems presents significant challenges, particularly when system models are unavailable and real-time computation is required. We present a purely data-driven approach for reference tracking control, referred to as parallel linear controllers (PLIC), which leverages an architecture composed of two linear controllers operating concurrently in distinct dimensional spaces. These controllers are employed for inverse control and mismatch error compensation, respectively. The first controller utilizes the Koopman operator for lifting the system to a high dimension and solves a quadratic program that facilitates constraint handling. The second controller, which works in the original state space, employs the direct data-driven virtual reference tuning approach with some appropriate modifications. The closed-loop properties of the proposed PLIC are analyzed, and the efficacy of the proposed method is exemplified through benchmark simulation.},
  archive      = {J_ISAT},
  author       = {Yao Shi and José M. Maestre and Lei Xie and Hongye Su},
  doi          = {10.1016/j.isatra.2025.05.048},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {183-190},
  shortjournal = {ISA Trans.},
  title        = {Data-driven parallel linear controllers for reference tracking in nonlinear systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time random reference tracking nonlinear model predictive control: A case study on wind turbines. <em>ISAT</em>, <em>165</em>, 170-182. (<a href='https://doi.org/10.1016/j.isatra.2025.06.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a research effort to extend nonlinear model predictive control methods from setpoint stabilization to reference tracking has been felt increasingly. On the other hand, uncertainty in the reference signal and the requirement for its dynamic forecasting in applications such as wind turbine control motivate the need for robust tracking nonlinear model predictive control approaches more and more. Therefore, this study proposes a random reference tracking nonlinear model predictive control with dynamic forecasting of stochastic references. Convergence to a robust invariant set is guaranteed by an additional constraint limiting the previous step’s tracking stage cost function. The proposed predictive approach is implemented using a parallel Newton-type method to make it more efficient and applicable. The proposed approach for wind turbine control is designed considering the random wind speed reference. Simulations are performed for extreme and fatigue load scenarios. The results show that the proposed controller performs more robustly than the nominal nonlinear model predictive control approach, performing better in optimal power extraction and reducing aerodynamic loads.},
  archive      = {J_ISAT},
  author       = {Mohammad Soleymani and Nooshin Bigdeli and Mehdi Rahmani},
  doi          = {10.1016/j.isatra.2025.06.018},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {170-182},
  shortjournal = {ISA Trans.},
  title        = {Real-time random reference tracking nonlinear model predictive control: A case study on wind turbines},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel MPC-based cascaded control for multi-area smart grids: Tackling renewable energy and EV integration challenges. <em>ISAT</em>, <em>165</em>, 143-169. (<a href='https://doi.org/10.1016/j.isatra.2025.06.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced cascaded control scheme for load frequency regulation in multi-area power systems incorporating renewable energy sources (RES) and electric vehicles (EVs). The proposed design (Model predictive control cascaded with one plus proportional-integral control cascaded with tilt control in parallel with one plus fractional-order integral derivative controller (MPC-((1+PI)-(T+(1+I λ D μ )))) combines predictive, tilt, and fractional-order dynamics to improve adaptability and robustness under uncertainties. Controller parameters are tuned using the Lyrebird Optimization Algorithm (LOA), ensuring fast convergence and effective global search. Simulation results under varying operational conditions, including nonlinearity effects such as Generation Rate Constraints (GRC), Governor Dead Band (GDB), and Communication Time Delays (CTD), confirm the controller’s superiority. It achieves a 96.4 % ITAE reduction, 98.6 % undershoot mitigation, and a settling time of just 5.8 s outperforming existing benchmark strategies (GOA: PDf+(0.75+PI), CBOA: PI-PD, JSA: PI, and ARA: 1+PID).},
  archive      = {J_ISAT},
  author       = {Muhammad S. Tolba and Muhammad Majid Gulzar and Ali Arishi and Mohamed Soliman and Ali Faisal Murtaza},
  doi          = {10.1016/j.isatra.2025.06.024},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {143-169},
  shortjournal = {ISA Trans.},
  title        = {A novel MPC-based cascaded control for multi-area smart grids: Tackling renewable energy and EV integration challenges},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency handling by reinforcement of predictive 2DoF-MPC and state observer LADRC for smart power system. <em>ISAT</em>, <em>165</em>, 128-142. (<a href='https://doi.org/10.1016/j.isatra.2025.05.046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preservation of stability is essential for the efficient and reliable functioning of the electrical transmission system. Frequency oscillations are prevalent in interconnected power systems (IPS) and may lead to instability; therefore, it is crucial to monitor and examine them meticulously. Effective frequency management is essential for regulating frequency output in an interconnected smart power system (ISPS) that includes renewable energy sources (RESs), redox flow batteries (RFBs) and static synchronous series compensators (SSSCs). In view of the challenge presented, this research introduces an efficient control architecture that utilizes a 2 degree of freedom-based model predictive controller (2DoF-MPC) to enhance system performance. Additionally, it integrates a linear active disturbance rejection control (LADRC) to employ a state observer alongside the evolving frequency management. The convergence of the predictive and state observer frameworks results in a robust 2DoF-MPC-LADRC to manage frequency disturbances and uncertainties in the power system. The suggested technique is thoroughly validated across several parameters for ISPS, instilling confidence in its capacity to attain minimal frequency variation in multiple scenarios. The performance of the proposed controller design shows that the frequency performance in area 1 and area 2 settles in 5.085 sec and 3.965 sec, when the load changes by 3 %, and it settles in 4.655 sec and 4.050 sec, respectively, when the load changes by 5 %.},
  archive      = {J_ISAT},
  author       = {Muhammad Majid Gulzar},
  doi          = {10.1016/j.isatra.2025.05.046},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {128-142},
  shortjournal = {ISA Trans.},
  title        = {Frequency handling by reinforcement of predictive 2DoF-MPC and state observer LADRC for smart power system},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional-order sliding mode coordinated controller using super-twisting disturbance observer for an NSSS with predefined-time stability. <em>ISAT</em>, <em>165</em>, 111-127. (<a href='https://doi.org/10.1016/j.isatra.2025.06.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a fractional-order sliding mode coordinated control (FOSMCC) strategy incorporating dual super-twisting disturbance observers (STDOs) to enhance the control performance, stability, and reliability of the nuclear steam supply system (NSSS) under complex, time-varying operating conditions and compound disturbances. The FOSMCC strategy synthesizes the fractional-order control and predefined-time theory with sliding mode control, augmented by the disturbance feedforward compensation loop driven by dual STDOs. Such control framework provides enhanced control performance guarantees, including fast transient response, high steady-state precision, and reinforced disturbance rejection. Furthermore, by employing Lyapunov’s direct approach, it is theoretically demonstrated that the entire NSSS, under the developed coordinated strategy, achieves superior predefined-time stability. Finally, comprehensive numerical validation and comparative studies reveal that the developed FOSMCC strategy with STDOs significantly outperforms both the latest fractional-order fixed-time sliding mode controller (FOFTSMC) and the practically adopted coordinated controller (PACC), exhibiting better transient/steady-state control response and stronger robustness against disturbances. Simulation results validate that, in the presence of compound disturbances, the proposed FOSMCC strategy reduces the integral absolute control error of nuclear power and water level by 89.37 % and 87.67 %, respectively, compared to FOFTSMC, and by 99.97 % and 99.99 %, respectively, compared to PACC.},
  archive      = {J_ISAT},
  author       = {Jiuwu Hui},
  doi          = {10.1016/j.isatra.2025.06.032},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {111-127},
  shortjournal = {ISA Trans.},
  title        = {Fractional-order sliding mode coordinated controller using super-twisting disturbance observer for an NSSS with predefined-time stability},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time observer-based saturated nonsingular terminal sliding mode controller design for an over-actuated ROV with time-varying saturation limits. <em>ISAT</em>, <em>165</em>, 98-110. (<a href='https://doi.org/10.1016/j.isatra.2025.06.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Input saturation is critical in over-actuated systems when multiple degrees of freedom (DOF) with different levels of disturbance rejection are controlled simultaneously by a set of actuators. The current study introduces a novel saturated non-singular terminal sliding mode controller to address input saturation for an over-actuated remotely-operated vehicle (ROV). The proposed controller consists of a tuning algorithm to ensure that the control commands do not violate the time-varying saturation limits of each DOF. In addition, a fixed-time extended-state observer is designed to estimate the vehicle’s velocity along with the lumped unknown dynamics of the system. The observer is also employed as a tool to maintain the orientation of the ROV in extreme environmental conditions. The stability analysis shows that all system’s states, except for yaw angle, are globally finite-time stable and the yaw angle is globally asymptotically stable. Several sets of simulations are carried out and the results demonstrate the superiority of the proposed controller in terms of positioning accuracy, saturation compensation and transient behaviour under different environmental conditions.},
  archive      = {J_ISAT},
  author       = {Alireza Hosseinnajad and Navid Mohajer},
  doi          = {10.1016/j.isatra.2025.06.025},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {98-110},
  shortjournal = {ISA Trans.},
  title        = {Fixed-time observer-based saturated nonsingular terminal sliding mode controller design for an over-actuated ROV with time-varying saturation limits},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonsingular fast terminal sliding mode control scheme for robust trajectory tracking of the underactuated EvoBot modular mobile robot in the vertical plane. <em>ISAT</em>, <em>165</em>, 83-97. (<a href='https://doi.org/10.1016/j.isatra.2025.06.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust control strategy for the vertical plane motion of an underactuated EvoBot mobile robot, modeled as a serial double inverted pendulum, is presented in this study. The control objectives include controlling both the directly actuated generalized coordinates and the non-actuated generalized coordinate, which is controllable through dynamic coupling with the actuated coordinates. In this regard, the system's dynamic equations are derived using the Lagrangian approach. A new nonlinear and nonsingular sliding manifold is introduced, based on which a nonsingular fast terminal sliding mode control scheme is proposed for the trajectory tracking control of the robot. This approach addresses the challenges posed by underactuation, system nonlinearities, instability, parameter uncertainties, and external disturbances. Through Lyapunov stability analysis, it is proven that finite-time asymptotic convergence of the tracking error to zero is ensured when the uncertainty upper bound is known, and convergence to a residual set is achieved when the upper bound is unavailable. The theoretical guarantees provided by the proposed control scheme are further validated through comprehensive MATLAB simulations, where its effectiveness is demonstrated under both low- and high-frequency disturbances as well as parameter uncertainties.},
  archive      = {J_ISAT},
  author       = {H. Jokar and S. Amini Serajgah},
  doi          = {10.1016/j.isatra.2025.06.013},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {83-97},
  shortjournal = {ISA Trans.},
  title        = {A nonsingular fast terminal sliding mode control scheme for robust trajectory tracking of the underactuated EvoBot modular mobile robot in the vertical plane},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time event-triggered sliding mode control for fuzzy singular systems under cyber-attacks. <em>ISAT</em>, <em>165</em>, 72-82. (<a href='https://doi.org/10.1016/j.isatra.2025.06.012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a novel secure control scheme for a particular class of Takagi–Sugeno (TS) fuzzy singular systems susceptible to deception attacks. During these attacks, adversaries can randomly introduce erroneous data into the output and control signals. The proposed strategy addresses the impact of attacks and disturbances using an observer-based sliding mode control (SMC) approach. Moreover, an event-triggering protocol is implemented to manage network resources efficiently. Furthermore, by employing the stochastic Lyapunov theory and the finite-time analysis method, sufficient conditions are established to ensure the finite-time boundedness of the resulting closed-loop system throughout both the reaching and sliding motion phases. To mitigate the attack’s effects and improve the system’s performance, the Secretary Bird Optimization Algorithm (SBOA) with the linear matrix inequality (LMI) is explored as a new approach for designing the optimal gains of controllers and observers. Finally, a simulation study based on a disc rolling on a surface is performed to showcase the efficacy and resilience of the proposed control scheme.},
  archive      = {J_ISAT},
  author       = {Mourad Kchaou and Rabeh Abassi and Houssem Jerbi},
  doi          = {10.1016/j.isatra.2025.06.012},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {72-82},
  shortjournal = {ISA Trans.},
  title        = {Finite-time event-triggered sliding mode control for fuzzy singular systems under cyber-attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-based dynamic event-triggered secure control of active suspension systems against deception attacks. <em>ISAT</em>, <em>165</em>, 64-71. (<a href='https://doi.org/10.1016/j.isatra.2025.06.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study deals with the issue of a memory-based dynamic event-triggered control strategy for active quarter-vehicle suspension systems (QVSSs). The main objective is to design an effective event-triggered mechanism (ETM) that ensures suspension performance while reducing network resource usage, even under deception attacks. To this end, an innovative memory-based dynamic ETM is proposed to coordinate sensor data transmission efficiently in the presence of such attacks. The proposed transmission scheme integrates historical release information, which helps suppress false triggering by utilizing averaged data. Additionally, the proposed ETM dynamically updates triggering conditions over time, facilitating dynamic scheduling of network data transmission. Sufficient conditions are derived to guarantee satisfactory performance of the QVSS under the proposed control strategy. A numerical example is provided to validate the effectiveness of the approach.},
  archive      = {J_ISAT},
  author       = {Wangrui Cheng and Tingting Yin and Zhou Gu},
  doi          = {10.1016/j.isatra.2025.06.007},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {64-71},
  shortjournal = {ISA Trans.},
  title        = {Memory-based dynamic event-triggered secure control of active suspension systems against deception attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-varying formation control for heterogeneous multi-agent systems in the presence of actuator faults and deception attacks. <em>ISAT</em>, <em>165</em>, 54-63. (<a href='https://doi.org/10.1016/j.isatra.2025.06.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the control of time-varying formations in a class of heterogeneous multi-agent systems. The key innovation lies in the simultaneous consideration of hybrid actuator faults and deception attacks. To achieve the control objective, a novel distributed double-layer control scheme, comprising a network layer and a physical layer, is proposed. In the network layer, a distributed observer with secure output feedback control is developed to mitigate severe deception attacks, ensuring that the mean square observer error remains within an acceptable range. In the physical layer, fault compensators are designed to address both additive and multiplicative faults. As a result, the followers achieve time-varying formation control, and closed-loop stability analysis is conducted using the Lyapunov method. Finally, to verify the validity of the theoretical findings, numerical simulations are subsequently conducted.},
  archive      = {J_ISAT},
  author       = {Shicheng Cao and Yanhui Yin and Wenyu Li and Zhongxin Liu and Zengqiang Chen},
  doi          = {10.1016/j.isatra.2025.06.004},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {54-63},
  shortjournal = {ISA Trans.},
  title        = {Time-varying formation control for heterogeneous multi-agent systems in the presence of actuator faults and deception attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered consensus of multi-agent systems with uncertain control gain via distributed fuzzy logic observer. <em>ISAT</em>, <em>165</em>, 40-53. (<a href='https://doi.org/10.1016/j.isatra.2025.06.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An event-triggered adaptive backstepping control methodology is proposed to achieve leader-following consensus of uncertain nonlinear high-order multi-agent systems with unknown control gains. In light of the partial observability limitation, adaptive distributed observers are employed to estimate the unobservable states of the leader, whereas local state observers are utilized to reconstruct the states of the followers. By integrating fuzzy logic systems, the unknown nonlinear dynamics are modeled, guaranteeing reliable state prediction in complex and partially observable scenarios. Moreover, the novel relative threshold event-triggered scheme is designed to reduce the frequency of data interactions while ensuring that the tracking error approaches near-zero. Eventually, the effectiveness and superiority of the devised controller are clearly demonstrated through comprehensive simulation results.},
  archive      = {J_ISAT},
  author       = {Konghao Xie and Xiujuan Zhao and Shiming Chen and Zheng Zhang and Yuanshi Zheng},
  doi          = {10.1016/j.isatra.2025.06.020},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {40-53},
  shortjournal = {ISA Trans.},
  title        = {Event-triggered consensus of multi-agent systems with uncertain control gain via distributed fuzzy logic observer},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consensus seeking in large-scale multi-agent systems with homogeneous connections by incorporating two-hop neighbor states. <em>ISAT</em>, <em>165</em>, 27-39. (<a href='https://doi.org/10.1016/j.isatra.2025.06.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of multi-agent consensus raises the importance of network topology. As the number of agents increases, multi-agent systems (MAS) in a large-scale and high-density topology demand higher resources, which consequently degrades efficiency of consensus. Existing approaches that consider only direct point-to-point neighbors may overlook potential topological information, further hindering consensus performance. To achieve fast consensus in large-scale and high-density topologies, a framework named Homogeneous Connections Based on Agents State Fusions MAS (HCASFMAS) is proposed. The framework extracts broader topology information of consensus degree by fusing states of two-hop neighbors. Leveraging homogeneous idea, agents establish homogeneous connections with neighbors that exhibit a higher consensus degree, ultimately accelerating the consensus process while preserving connectivity. First, a neighbor selection strategy based on consensus degree of agent state fusion is introduced to construct candidate neighbors, aiming to reduce redundant connections. Second, an adaptive consensus algorithm is formulated to flexibly adapt to the distribution of neighbors. Finally, a candidate constraints set is established to accelerate consensus by expanding the scope of constraints while preserving connectivity. In this study, connectivity and convergence of the system are theoretically analyzed from a geometric perspective. Simulation experiments are conducted to compare the proposed method with existing approaches under different densities and topologies. Simulation results demonstrate the superiority of this method in achieving fast convergence, particularly in large-scale and high-density scenarios.},
  archive      = {J_ISAT},
  author       = {Guangqiang Xie and Chaohao Shen and Yang Li and Yanda Feng and Fengyang Qiu},
  doi          = {10.1016/j.isatra.2025.06.002},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {27-39},
  shortjournal = {ISA Trans.},
  title        = {Consensus seeking in large-scale multi-agent systems with homogeneous connections by incorporating two-hop neighbor states},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic formation tracking and fault-tolerant control of multi-agent systems based on distance and topology reconstruction methods. <em>ISAT</em>, <em>165</em>, 15-26. (<a href='https://doi.org/10.1016/j.isatra.2025.06.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a distributed approach for dynamic formation tracking and formation fault-tolerant control within the port-Hamiltonian energy framework for multi-agent system (MAS) affected by Coulomb friction. The coupling relationships between agents are equivalently modeled as virtual springs, which simulate the interaction forces between agents to reflect the relative positions and motion states of the agents. A distance-based distributed control scheme is designed, to ensure that the formation composed of multiple agents can continuously adjust the direction and size of the formation while achieving target tracking. Additionally, considering the possibility of communication failure due to agent motion faults, a fault-tolerant algorithm based on topological reconstruction is proposed to reconstruct the formation topology after faults. The feasibility of this control method is verified through numerical simulations.},
  archive      = {J_ISAT},
  author       = {Lu Liu and Yu Cui and Yonghua Wang and Jinglong Wen and Shuaishuai Kong and Yuhang Ma and Dan Liu and Peng Shi and Chenyang Xue},
  doi          = {10.1016/j.isatra.2025.06.006},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {15-26},
  shortjournal = {ISA Trans.},
  title        = {Dynamic formation tracking and fault-tolerant control of multi-agent systems based on distance and topology reconstruction methods},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast actuator fault-tolerant control for a class of nonlinear sampled-data systems via deterministic learning. <em>ISAT</em>, <em>165</em>, 1-14. (<a href='https://doi.org/10.1016/j.isatra.2025.05.049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the fast fault-tolerant control (FTC) problem based on deterministic learning approach (DLA) for a class of nonlinear sampled-data systems with actuator faults, which consist of two stages: incipient faults with small magnitudes and faults with larger magnitudes. First, a learning controller and a learning identifier are constructed. Based on DLA and the exponential stability of a class of linear time-varying (LTV) discrete-time systems, the control knowledge and the diagnosis knowledge of the actuator faults are obtained. Second, a set of controllers and a set of diagnosis estimators are constructed based on the learnt control and diagnosis knowledge. When an incipient actuator fault occurs, fast fault detection and isolation (FDI) can be achieved using the diagnosis estimators. Then, the pattern-based FTC scheme is implemented to improve the control performance. When the small fault grows to a larger one, the rapid FDI and FTC are implemented again, providing fast responses to the occurred larger fault. The advantages of the proposed method are that: (i) a simple adaptive learning controller with the filtering technique is designed, in which the exponential convergence of the tracking error and parameter estimation errors can be achieved simultaneously; (ii) the sensitivity to small actuator faults is enhanced, and the fast FTC to larger actuator faults is achieved by utilizing the learnt knowledge. Simulation results are also included to illustrate the effectiveness of these schemes.},
  archive      = {J_ISAT},
  author       = {Yu Zeng and Tianrui Chen and Fukai Zhang and Cong Wang},
  doi          = {10.1016/j.isatra.2025.05.049},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {1-14},
  shortjournal = {ISA Trans.},
  title        = {Fast actuator fault-tolerant control for a class of nonlinear sampled-data systems via deterministic learning},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="isci">ISCI - 37</h2>
<ul>
<li><details>
<summary>
(2026). Robust partial 3D point cloud registration via confidence estimation under global context. <em>ISCI</em>, <em>723</em>, 122705. (<a href='https://doi.org/10.1016/j.ins.2025.122705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial point cloud registration is essential for autonomous perception and 3D scene understanding, yet it remains challenging owing to structural ambiguity, partial visibility, and noise. We address these issues by proposing Confidence Estimation under Global Context (CEGC), a unified, confidence-driven framework for robust partial 3D registration. CEGC enables accurate alignment in complex scenes by jointly modeling overlap confidence and correspondence reliability within a shared global context. Specifically, the hybrid overlap confidence estimation module integrates semantic descriptors and geometric similarity to detect overlapping regions and suppress outliers early. The context-aware matching strategy mitigates ambiguity by employing global attention to assign soft confidence scores to correspondences, improving robustness. These scores guide a differentiable weighted singular value decomposition solver to compute precise transformations. This tightly coupled pipeline adaptively down-weights uncertain regions and emphasizes contextually reliable matches. Experiments on ModelNet40, ScanObjectNN, and 7Scenes 3D vision datasets demonstrate that CEGC outperforms state-of-the-art methods in accuracy, robustness, and generalization. Overall, CEGC offers an interpretable and scalable solution to partial point cloud registration under challenging conditions.},
  archive      = {J_ISCI},
  author       = {Yongqiang Wang and Weigang Li and Wenping Liu and Zhe Xu and Zhiqiang Tian},
  doi          = {10.1016/j.ins.2025.122705},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122705},
  shortjournal = {Inf. Sci.},
  title        = {Robust partial 3D point cloud registration via confidence estimation under global context},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Long- and short-term preferences modeling based on dual-frequency self-attention network for sequential recommendation. <em>ISCI</em>, <em>723</em>, 122700. (<a href='https://doi.org/10.1016/j.ins.2025.122700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation aims to analyze users’ interaction sequences to capture their sustained long-term preferences and dynamically changing short-term preferences for the next item recommendation. Recent studies have shifted their focus to the frequency domain to further mine users’ complex historical interaction behaviors. However, most existing frequency-based methods cannot explicitly distinguish the low-frequency information associated with long-term preferences from the high-frequency information associated with short-term preferences in user sequences. Consequently, they are unable to accurately model these preferences, thereby limiting the performance of the models. To this end, we propose a novel yet simple model based on Dual-Frequency Self-Attention Network (DFSNet) for sequential recommendation. DFSNet comprises low- and high-frequency self-attention modules that separately extract the corresponding components from user sequences to model long- and short-term preferences. Additionally, considering the limited frequency information available within sequences, we introduce contrastive learning to generate self-supervised signals from the preference representations produced by DFSNet. This approach further strengthens the modeling of both long-term and short-term preferences without disrupting the sequence structure, thereby positively impacting the recommendation performance. Extensive experiments on four public datasets indicate that DFSNet outperforms strong baselines while balancing accuracy and efficiency, confirming its effectiveness.},
  archive      = {J_ISCI},
  author       = {Kaiwei Xu and Yongquan Fan and Jing Tang and Xianyong Li and Yajun Du and Xiaomin Wang},
  doi          = {10.1016/j.ins.2025.122700},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122700},
  shortjournal = {Inf. Sci.},
  title        = {Long- and short-term preferences modeling based on dual-frequency self-attention network for sequential recommendation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FedWAPR: Bridging theory and practice in probability-driven weighted aggregation for federated learning. <em>ISCI</em>, <em>723</em>, 122697. (<a href='https://doi.org/10.1016/j.ins.2025.122697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a machine learning paradigm emphasizing data privacy, widely adopted for handling sensitive data. Federated Averaging (FedAvg) is the most commonly implemented FL aggregation technique due to its simplicity and effectiveness. However, FedAvg suffers from information loss during the aggregation stage. This study theoretically and empirically analyzes the Weighted Aggregation via Probability-based Ranking (FedWAPR) technique, an enhancement to FedAvg that retains its simplicity while addressing its limitations. FedWAPR employs a weighted aggregation strategy based on Log-Cauchy and Exponential probability density functions, assigning weights to local models based on their performance. This approach ensures accurate aggregation that reflects the contributions of individual clients. FedWAPR was tested across various model architectures, including Dense Neural Networks, Long Short-Term Memory networks, and Convolutional Neural Networks with results showing performance equal to or surpassing FedAvg. The Log-Cauchy and Exponential distribution functions allow customization of aggregation based on the number of participating clients, with exponential distribution excelling in smaller client setups and Log-Cauchy in larger ones. FedWAPR’s ability to integrate with advanced aggregation techniques like FedProx, makes it a robust solution to enhance FL. Additionally, a theoretical analysis confirms the convergence of FedWAPR under standard FL assumptions and thereby ensuring method’s robustness and reliability.},
  archive      = {J_ISCI},
  author       = {Abdullah Abdul Sattar Shaikh and M.S. Bhargavi and Pavan Kumar C},
  doi          = {10.1016/j.ins.2025.122697},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122697},
  shortjournal = {Inf. Sci.},
  title        = {FedWAPR: Bridging theory and practice in probability-driven weighted aggregation for federated learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPRO-GNN: Bridging differential privacy and advanced optimization for privacy-preserving graph learning. <em>ISCI</em>, <em>723</em>, 122695. (<a href='https://doi.org/10.1016/j.ins.2025.122695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have demonstrated exceptional performance in modeling structured data, yet their application in sensitive domains inevitably raises privacy concerns. Existing Differentially Private GNN (DPGNN) frameworks primarily rely on Differentially Private Stochastic Gradient Descent (DP-SGD) to enforce privacy guarantees. However, DP-SGD inherits its inherent limitations, such as training instability and slow convergence, which are particularly problematic for complex graph learning tasks. Although advanced optimizers like Ranger offer a promising alternative, their naive integration into DPGNN frameworks introduces bias, specifically in the second-moment estimation, due to the additive noise required for DP. To address this challenge, we propose the Differentially Private Ranger-Optimized Graph Neural Network (DPRO-GNN) to protect users’ sensitive data when training the GNN tasks. To mitigate DP noise and capture multi-scale structure, DPRO-GNN applies hierarchical pooling to aggregate nodes into progressively coarser subgraphs, yielding robust, multi-resolution embeddings. Meanwhile, our approach introduces DP-RangerBC, a bias-corrected variant of the Ranger optimizer that mitigates the noise-induced bias in second-order moment estimation, thereby enabling more stable and efficient training under DP constraints. Furthermore, the theoretical analysis of DPRO-GNN, including its correctness and security, is also provided. Extensive experiments on real-world datasets demonstrate that DPRO-GNN achieves superior performance in terms of classification accuracy and convergence speed, compared to state-of-the-art DPGNN methods. The code of DPRO-GNN is available at the following link: https://github.com/Silbermondlel/DPRO-GNN .},
  archive      = {J_ISCI},
  author       = {Yanan Bai and Liji Xiao and Hongbo Zhao and Xiaoyu Shi},
  doi          = {10.1016/j.ins.2025.122695},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122695},
  shortjournal = {Inf. Sci.},
  title        = {DPRO-GNN: Bridging differential privacy and advanced optimization for privacy-preserving graph learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PUWR-TSSG: A CMAB-based post-unknown worker recruitment scheme for three-stage stackelberg games in mobile crowd sensing. <em>ISCI</em>, <em>723</em>, 122693. (<a href='https://doi.org/10.1016/j.ins.2025.122693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous Three-Stage Stackelberg Games (TSSG) have been proposed to model the strategic interactions among the requesters, the platform, and the workers in Mobile Crowd Sensing (MCS). However, most existing studies unrealistically assume that the platform possesses prior knowledge of the workers’ credibility either beforehand or after receiving their data. Conversely, in practical scenarios, the credibility of workers remains uncertain even after the submission of their data, which is known as the Post-Unknown Worker Recruitment (PUWR) problem. Given this context, conventional models designed for TSSG cannot be applied to real-world MCS. In this paper, we present the PUWR-TSSG scheme for quality-enhanced worker recruitment in TSSG. Specifically, we avoid the unreasonable assumption in previous works and propose a Double-level Credibility Discovery (DCD) approach with bipartite graph-based matrix completion for accurate credibility verification. Subsequently, based on the DCD approach, we further propose a meticulously designed combinatorial multi-armed bandit mechanism to solve the exploration–exploitation dilemma in untrusted environments. Furthermore, we formulate the payment computation issue as a TSSG, while simultaneously considering the workers’ credibility and verification costs incurred by the PUWR problem. Theoretical analyses validate the existence of Stackelberg Equilibrium in our scheme, ensuring that no participant has an incentive to unilaterally deviate from its optimal strategy. Extensive simulations on a real-world dataset validate the effectiveness of our proposed PUWR-TSSG scheme, significantly enhancing the overall data quality and leading to a remarkable average reduction in regret of up to 85.9% compared to baseline methods.},
  archive      = {J_ISCI},
  author       = {Kejia Fan and Jianheng Tang and Yaohui Han and Yuhao Zheng and Yajiang Huang and Anfeng Liu and Neal N. Xiong and Shaobo Zhang and Tian Wang and Mianxiong Dong},
  doi          = {10.1016/j.ins.2025.122693},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122693},
  shortjournal = {Inf. Sci.},
  title        = {PUWR-TSSG: A CMAB-based post-unknown worker recruitment scheme for three-stage stackelberg games in mobile crowd sensing},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach for shortest optimal reduct computation. <em>ISCI</em>, <em>723</em>, 122692. (<a href='https://doi.org/10.1016/j.ins.2025.122692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory has emerged as a robust soft computing paradigm for feature selection, commonly known as reduct computation. A decision system may contain multiple reducts of varying sizes, all offering equivalent classification capabilities. However, when model performance is a critical factor, the shortest reduct is generally preferred due to its simplicity and interpretability. The discernibility matrix method is a widely used technique for computing such reducts. Despite its effectiveness, this method is computationally intensive and classified as NP-hard, limiting its scalability for datasets where discernibility matrix computation becomes infeasible. This study addresses the limitations of traditional discernibility matrix-based approaches by introducing a novel method that combines a Breadth-First Search control strategy with an incremental approach to compute the absorbed discernibility matrix. The Breadth First Search strategy enables efficient exploration of the search space to identify the shortest optimal reduct early, while the incremental absorbed discernibility matrix enhances the computational scalability of the algorithm. To validate the proposed method, an experimental evaluation was conducted against two state-of-the-art algorithms: Breadth-First Search, representing the discernibility matrix-based strategy, and MinReduct, a benchmark for absorbed discernibility matrix-based approaches. Results demonstrate superior computational performance and earlier discovery of shortest reducts without compromising correctness or optimality.},
  archive      = {J_ISCI},
  author       = {G.Y. Phani Kumar and Abhimanyu Bar and P.S.V.S. Sai Prasad},
  doi          = {10.1016/j.ins.2025.122692},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122692},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach for shortest optimal reduct computation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Existence of nash equilibrium in single-leader multiple-follower games with min-max interval payoffs. <em>ISCI</em>, <em>723</em>, 122691. (<a href='https://doi.org/10.1016/j.ins.2025.122691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In decision-making problems with hierarchical structures, leader–follower games are highly prevalent. As a core concept in game theory, the existence of Nash equilibrium is crucial. However, in reality, complex uncertainties often lead to imprecise game outcomes, and interval representations are an effective tool for capturing such uncertainties. To address the issue of imprecise payoffs in complex environments, this paper proposes the concept of min-max interval (for short, MMI) and studies the existence of Nash equilibrium in single-leader multiple-follower (for short, SLMF) games with MMI payoffs. MMI is an appropriate extension of the traditional interval-providing a more flexible tool for representing uncertain payoffs. We propose an MMI expected payoff ranking method to address the issue of players ranking MMIs. Based on this, operational rules for MMIs and concepts such as limits, continuity, and concavity of MMI-valued functions (for short, MIVFs) are defined. After extending key theorems of real-valued functions to the case of MIVFs, we combine these extended theorems with set-valued mapping theory and Kakutani’s fixed point theorem to prove the existence of Nash equilibrium in SLMF MMI-valued games. Additionally, we compare existing works to verify the innovativeness of the proposed method and provide numerical examples to demonstrate its applicability.},
  archive      = {J_ISCI},
  author       = {Daping Zhang and Yanlong Yang and Xicai Deng},
  doi          = {10.1016/j.ins.2025.122691},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122691},
  shortjournal = {Inf. Sci.},
  title        = {Existence of nash equilibrium in single-leader multiple-follower games with min-max interval payoffs},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data stream clustering via fuzzy similarity and diffusion-enhanced contextual affinity. <em>ISCI</em>, <em>723</em>, 122690. (<a href='https://doi.org/10.1016/j.ins.2025.122690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream clustering provides an effective method for recognizing underlying patterns in potentially unbounded sequences of data objects. Existing data stream clustering methods primarily encounter two key issues: (1) the inadequate evaluation of relationships between data objects within fixed-size landmark windows, leading to degraded clustering quality; and (2) the absence of efficient mechanisms for transferring useful knowledge from previous windows to the current window, weakening the model’s adaptability to data stream evolution. To address these issues, a data stream clustering method based on axiomatic fuzzy set theory via a diffusion process is first proposed. First, the proposed method employs axiomatic fuzzy set theory to measure the relationships between data objects within the window, capturing similarity information to more accurately reveal the underlying data distribution. Second, an efficient diffusion process enhances pairwise affinities through contextual propagation, which significantly improves connectivity within clusters. Finally, the learned affinity matrix is applied to spectral clustering for data stream clustering. Over time, we update the dynamic set according to the distance between data objects and cluster centers. This dynamic set retains representative data objects and effectively transfers previously learned knowledge to the current landmark window. Experimental results on four datasets and seven algorithms demonstrate the effectiveness and robustness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yao Li and Ming Chi and Wei Lu and Xiaodong Liu and Witold Pedrycz},
  doi          = {10.1016/j.ins.2025.122690},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122690},
  shortjournal = {Inf. Sci.},
  title        = {Data stream clustering via fuzzy similarity and diffusion-enhanced contextual affinity},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large language model assisted hierarchical reinforcement learning training. <em>ISCI</em>, <em>723</em>, 122688. (<a href='https://doi.org/10.1016/j.ins.2025.122688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional reinforcement learning (RL) cannot solve complex long-sequence decision tasks, especially when the environment rewards are sparse. Large language models (LLMs) can perform well in long-sequence decision tasks by leveraging their powerful inference capabilities. Although LLMs possess a large amount of general knowledge, LLM-based agents lack expertise in solving specific target problems. Considering that reinforcement learning models are smaller than LLMs and can be trained specifically to perform well on specific tasks, this paper proposes a hierarchical reinforcement learning framework assisted by a large language model, called LLMHRL. In this framework, the LLM acts as a teacher agent to guide the exploration of high-level policy in hierarchical reinforcement learning. The low-level policy consists of a library of selection-based policies. The agent executes specific actions based on the low-level policy chosen by the high-level policy. Furthermore, to reduce the action space of high-level policy, this paper decomposes it into skill options and target options. The two types of options are combined to obtain a high-level policy. This paper evaluates LLMHRL against baseline methods using both public and custom-built harder tasks across three environments: MiniGrid for key-door pairing, ManiSkill for tabletop sorting, and real-world scenarios. The results show that LLMHRL outperforms existing methods in success rate, convergence speed, and average return.},
  archive      = {J_ISCI},
  author       = {Qianxi Li and Bao Pang and Yong Song and Hongze Fu and Qingyang Xu and Xianfeng Yuan and Xiaolong Xu and Chengjin Zhang},
  doi          = {10.1016/j.ins.2025.122688},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122688},
  shortjournal = {Inf. Sci.},
  title        = {Large language model assisted hierarchical reinforcement learning training},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A relation classification and aggregation algorithm for bipartite-type multi-relational heterogeneous graphs. <em>ISCI</em>, <em>723</em>, 122687. (<a href='https://doi.org/10.1016/j.ins.2025.122687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Heterogeneous Graph Neural Networks (HGNNs) are multi-oriented and single-relational heterogeneous graphs, and cannot effectively function on Bipartite-type Multi-relational Heterogeneous Graphs (BMHGs) with multiple relationships. At the same time, existing meta-path-based HGNNs cannot fully consider the differences between meta-paths during the aggregation process, and this difference is even more prominent in BMHGs. The main manifestation is that the number of neighbor nodes connected by various meta-relation paths differs significantly, causing some paths to carry too much noise information, which affects the algorithm performance. In order to solve the problem of the complex relationships in BMHG and the significant disparity in the number of neighbors between paths, this paper proposes a Relation Classification and Aggregation Algorithm for Bipartite-type Multi-Relational Heterogeneous Graphs (RCAA-BMHG). The RCAA-BMHG algorithm consists of three modules: the same-type aggregation module, the across-type aggregation module, and the cross-category feature aggregation layer, which perform differentiated processing of different types of association information between nodes in a Bipartite-type Multi-relational Heterogeneous Graph. Specifically, the same-type aggregation module first introduces a same-type node association filter to distinguish between the densely coupled path and the sparsely coupled path, and then uses a global average strategy and an adaptive weight allocation method to aggregate the information of the two types of coupled paths. The across-type aggregation module is filtered by an across-type node association filter, and then the weighted sum mechanism and the neighborhood feature propagation technology are used to aggregate the information of the two types of coupled paths. Finally, RCAA-BMHG uses a category-level attention mechanism to fuse the semantic and feature information of the same and cross types to generate the final node embedding for downstream tasks. Experimental verification shows that RCAA-BMHG not only performs feature aggregation and classification tasks when processing complex heterogeneous graph data, but also shows significant advantages over existing HGNNs algorithms on multiple evaluation metrics. The complete reproducible code and data have been published at: https://github.com/Dylanwsd24/RCAA-BMHG .},
  archive      = {J_ISCI},
  author       = {Hua Duan and Shiduo Wang and Yufei Zhao and Hua Liu and Xiaotong Li},
  doi          = {10.1016/j.ins.2025.122687},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122687},
  shortjournal = {Inf. Sci.},
  title        = {A relation classification and aggregation algorithm for bipartite-type multi-relational heterogeneous graphs},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust watermarking for diffusion model generated images. <em>ISCI</em>, <em>723</em>, 122686. (<a href='https://doi.org/10.1016/j.ins.2025.122686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of diffusion models in the field of image generation, image copyright protection and traceability have become increasingly complex and challenging. To address these problems, this paper proposes a robust watermarking method for diffusion model generated images to achieve their copyright protection and traceability. The method designs an invertible mapping module to replicate and cryptographically map the watermark information into an approximately Gaussian distributed noise, which is highly consistent with the distribution of the original generation model. The mapped watermark noise serves as the latent space vector of the generative model, preserving both image generation quality and model performance. In the watermark extraction stage, the original watermark information can be accurately recovered from the generated image through the reverse extraction and voting mechanism. Experimental results show that the proposed method demonstrates excellent performance in terms of image watermark extraction accuracy, robustness and watermark image generation quality. It can still maintain 99 % true positive rate and 97.5 % bit accuracy under various attacks, and the overall performance in the detection and traceability scenarios is significantly better than the existing baseline methods.},
  archive      = {J_ISCI},
  author       = {Ziqi Liu and Yuan Guo and Liansuo Wei},
  doi          = {10.1016/j.ins.2025.122686},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122686},
  shortjournal = {Inf. Sci.},
  title        = {Robust watermarking for diffusion model generated images},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis. <em>ISCI</em>, <em>723</em>, 122684. (<a href='https://doi.org/10.1016/j.ins.2025.122684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on enhancing the extraction of sentiment quadruples consisting of target, aspect, opinion, and sentiment from multi-turn dialogs, which remains a challenging problem in conversational sentiment analysis. Existing methods frequently encounter challenges with complex sentence structures, presence of multiple sentiment quadruples, and interference from irrelevant contextual information. These challenges often result in suboptimal performance. These limitations are addressed by introducing Schrödinger equation-based adaptive dropout multi-granular feature enhancement network (SEAD-MGFE-Net), a novel framework that synergizes multigranular feature extraction with quantum-inspired adaptive regularization. The proposed methodology incorporates a multi-layer tree structure to segment sentences into semantically coherent fragments, thereby improving the alignment between aspect and opinion terms while simultaneously mitigating noise impact. Moreover, we engineer a multi-angle dynamic adjacency learning enhancement module that adeptly captures both local and global features inherent in graph-structured representations. Additionally, we devise an adaptive dropout mechanism based on the Schrödinger equation, facilitating automatic modulation of the regularization strength throughout training. Extensive evaluations on benchmark datasets in both Chinese and English validate the state-of-the-art effectiveness of our proposed SEAD-MGFE-Net model, achieving Micro-F1 scores of 46.53 % (Chinese) and 40.97 % (English), surpassing the strongest baseline models by 2.04 % and 1.57 %, respectively. SEAD-MGFE-Net exhibits efficacy in extracting cross-utterance quadruples and managing long-range dependencies. These findings confirm the effectiveness and broad applicability of SEAD-MGFE-Net for conversational sentiment analysis.},
  archive      = {J_ISCI},
  author       = {Wei Liu and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
  doi          = {10.1016/j.ins.2025.122684},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122684},
  shortjournal = {Inf. Sci.},
  title        = {SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy. <em>ISCI</em>, <em>723</em>, 122682. (<a href='https://doi.org/10.1016/j.ins.2025.122682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing concerns regarding data privacy exacerbate the challenges associated with “data silos”. Federated learning (FL) effectively addresses these issues by facilitating distributed machine learning without necessitating direct data exchange. However, the dependence on a central server in conventional FL architectures exacerbates privacy risks and limits cross-domain data sharing. Existing blockchain-based FL frameworks often employ static consensus protocols, such as classical Practical Byzantine Fault Tolerance (PBFT), which typically rely on fixed weight aggregation strategies. While these methods simplify implementation, they fail to adaptively adjust aggregation weights according to heterogeneous privacy budgets. Attempts to implement adaptive weight aggregation often require achieving consensus for each individual weight, significantly reducing efficiency and creating scalability challenges in large-scale networks. To address these gaps, we propose DSM-PBFT, a variant PBFT consensus enhanced with dynamic scoring matrices (DSM), which enables parallelized validation of multiple models while adaptively adjusting aggregation weights based on differential privacy budgets. Our noise-aware aggregation mechanism dynamically reweights models through cross-validation of accuracy, F1 score, and loss-transformed metrics, effectively decoupling privacy guarantees from model utility degradation. Security analyses affirm the robustness of this framework against Byzantine attacks, with experimental results on MNIST, FashionMNIST and CIFAR-10 demonstrating superior model accuracy across diverse privacy budgets while effectively curbing accuracy degradation under attack scenarios.},
  archive      = {J_ISCI},
  author       = {Wentai Yang and Xian Xu and Kai Yu and Guoqiang Li},
  doi          = {10.1016/j.ins.2025.122682},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122682},
  shortjournal = {Inf. Sci.},
  title        = {Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Subsequence heterogeneity contrastive learning for time series anomaly detection. <em>ISCI</em>, <em>723</em>, 122680. (<a href='https://doi.org/10.1016/j.ins.2025.122680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is widely applied across various real-world scenarios. Recently, contrastive learning has shown remarkable ability in learning discriminative representations for detecting anomalies. However, most existing contrastive-based methods rely on complex contrastive mechanisms and specially designed model architectures, which make it difficult to maintain efficiency and flexibility across various application scenarios. To address this limitation, we introduce Subsequence-Heterogeneity that defined as the discrepancies in variation patterns and statistical characteristics between subsequences obtained through fixed-interval sampling, which are more pronounced in anomalous sequences than in normal ones. It can serve as a natural discrimination criterion and eliminate the need for complex contrastive mechanisms and specialized model architectures. Specifically, we adopt an efficient temporal hierarchical masking strategy with linear complexity to construct two branches for learning representations at different granularities. The Subsequence-Heterogeneity Contrastive Learning (SHCL) is implemented with different neural networks and enables flexible application to anomaly detection across diverse scenarios. Experiments on eight benchmark datasets demonstrate that SHCL not only achieves state-of-the-art performance with reduced time and resource costs but also significantly improves the ability of different neural networks to distinguish normal from anomalous patterns. The source code is publicly available at https://github.com/Zhangzzbzzb/SHCL/ .},
  archive      = {J_ISCI},
  author       = {Zhibin Zhang and Xiaohong Zhang and Qiang Li and Chun Huang and Tao Yin and Meng Yan},
  doi          = {10.1016/j.ins.2025.122680},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122680},
  shortjournal = {Inf. Sci.},
  title        = {Subsequence heterogeneity contrastive learning for time series anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Escrow-free attribute based signature with constant-size for the internet of things. <em>ISCI</em>, <em>723</em>, 122679. (<a href='https://doi.org/10.1016/j.ins.2025.122679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute based signature (ABS) provides a promising solution for anonymous authentication. However, numerous prevailing ABS algorithms are ill-suited for anonymous authentication in the Internet of Things (IoT), due to problems such as key escrow, high computational overhead, inflexible access policies, and vulnerability to collusion attacks. Considering these shortcomings, we present an escrow-free attribute based signature with constant-size signature for IoT. Our proposal uses the linear secret-sharing scheme (LSSS) and the notion of certificateless cryptography to restrict the authorities of each attribute authority and the system authority. In addition, it generates a constant-size signature and achieves high verification efficiency by aggregating attribute keys. Theoretical analyses demonstrate that our proposal achieves anonymous authentication and is provably secure under the standard model. Simulation experiments show that the execution time of our algorithm is less than 50 ms to run during both the signature and verification phases, making it well-suited for applications with limited resources.},
  archive      = {J_ISCI},
  author       = {Xudong Liu and Xiaojun Tong and Yihui Wang},
  doi          = {10.1016/j.ins.2025.122679},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122679},
  shortjournal = {Inf. Sci.},
  title        = {Escrow-free attribute based signature with constant-size for the internet of things},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep dual contrastive learning for multi-view subspace clustering. <em>ISCI</em>, <em>723</em>, 122678. (<a href='https://doi.org/10.1016/j.ins.2025.122678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) aims to learn a consistent shared self-representation by utilizing the consistency and complementarity of all views, numerous MVSC algorithms have attempted to obtain the optimal representation directly from raw features. However, they might overlook the noisy or redundant information in raw feature space, resulting in learning suboptimal self-representation and poor performance. To address this limitation, an intuitive idea is introducing deep neural networks to eliminate the noise and redundancy, yielding a potential embedding space. Nevertheless, existing deep MVSC methods merely focus on either the embeddings or self-expressions to explore the complementary information, which hinders subspace learning. In this paper, we present a deep multi-view dual contrastive subspace clustering framework to exploit the complementarity to learn latent self-representations effectively. Specifically, multi-view encoders are constructed to eliminate noise and redundancy of the original features and capture low-dimensional subspace embeddings, from which the self-representations are learned. Moreover, two diverse specific fusion methods are conducted on the latent subspace embeddings and the self-expressions to learn shared self-representations, and dual contrastive constraints are proposed to fully exploit the complementarity among views. Extensive experiments are conducted to verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xincan Lin and Jie Lian and Zhihao Wu and Jielong Lu and Shiping Wang},
  doi          = {10.1016/j.ins.2025.122678},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122678},
  shortjournal = {Inf. Sci.},
  title        = {Deep dual contrastive learning for multi-view subspace clustering},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parameter-free discrete clustering via adaptive hypergraph fusion. <em>ISCI</em>, <em>723</em>, 122677. (<a href='https://doi.org/10.1016/j.ins.2025.122677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering has garnered significant attention due to its outstanding performance in uncovering sample structures. However, existing graph-based methods face two major challenges: 1) In graph construction, they typically focus only on direct connections between samples or an exact high-order relationship, neglecting the impact of hidden complex relationships on clustering performance; 2) The separation of spectral analysis and category acquisition into two distinct stages often results in a loss of effectiveness. To handle these problems, we propose a parameter-free discrete clustering method, called parameter-free discrete clustering via adaptive hypergraph fusion (DCAHF). Specifically, DCAHF first produces multiple different hypergraphs, each serving as a biased approximation of the data's intrinsic manifold. These complementary approximations capture distinct local-to-global geometric patterns. Then, it introduces an adaptive fusion strategy that learns optimal weights to combine them into a single consensus hypergraph on manifold space, effectively reconstructing the real manifold structure with reduced bias and improved integrity. Finally, discrete spectral analysis is performed directly on the consensus hypergraph to generate discrete sample categories, thereby avoiding the performance loss associated with two-stage approaches. Thus, DCAHF is a high-performance, parameter-free clustering model that can flexibly adapt to various clustering tasks. Since the DCAHF model cannot be solved using gradient descent methods, we develop a coordinate descent-based optimization algorithm to efficiently solve the model. Extensive experimental results demonstrate that DCAHF significantly enhances clustering effectiveness while maintaining comparable efficiency to state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Ben Yang and Xuetao Zhang and Badong Chen},
  doi          = {10.1016/j.ins.2025.122677},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122677},
  shortjournal = {Inf. Sci.},
  title        = {Parameter-free discrete clustering via adaptive hypergraph fusion},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-branch semantic alignment for few-shot image classification. <em>ISCI</em>, <em>723</em>, 122676. (<a href='https://doi.org/10.1016/j.ins.2025.122676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable progress of deep learning in computer vision has significantly stimulated research interest in few-shot image classification. This field aims to transfer knowledge from previous experiences to recognize new concepts with limited samples. However, most existing approaches primarily concentrate on aligning semantic information at high-level features, neglecting the importance of middle-level or low-level feature representations. In this paper, we propose a novel approach called Multi-Branch Semantic Alignment (MBSA) for few-shot image classification, with the objective of investigating the role of multi-level features. Instead of using standard convolutional layers, we employ diverse convolutional layers to generate enhanced representations in each branch. These representations are then utilized by a dense classifier, which is supervised by a powerful guidance mechanism to incorporate semantic information into their spatial locations. During the inference stage, the multi-branch semantic alignment is designed to align multi-level features between query images and support images. This alignment process effectively establishes semantic correspondences between representations at different levels, thereby enhancing the ability to recognize novel categories. Comprehensive experiments are conducted on various few-shot benchmarks to demonstrate the superiority of our approach compared to those of several previous approaches, and ablation studies are performed to analyze the impact of different components.},
  archive      = {J_ISCI},
  author       = {Zijun Zheng and Heng Wu and Laishui Lv and Changchun Zhang and Hongcheng Guo and Shanzhou Niu and Gaohang Yu},
  doi          = {10.1016/j.ins.2025.122676},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122676},
  shortjournal = {Inf. Sci.},
  title        = {Multi-branch semantic alignment for few-shot image classification},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partition-based differentially private synthetic data generation. <em>ISCI</em>, <em>723</em>, 122675. (<a href='https://doi.org/10.1016/j.ins.2025.122675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private synthetic data sharing is beneficial as it better retains the distribution and nuances of the original data compared to summary statistics such as means and frequencies. Current state-of-the-art methods follow a select-measure-generate paradigm, but measuring large-domain marginals often leads to significant errors, and managing the privacy budget poses challenges. Our partition-based approach addresses these issues, effectively reducing errors and improving the quality of synthetic data, even with a limited privacy budget. Experimental results show that our method outperforms existing approaches, yielding synthetic data with enhanced quality and utility, making it a preferred option for private data sharing.},
  archive      = {J_ISCI},
  author       = {Meifan Zhang and Dihang Deng and Lihua Yin},
  doi          = {10.1016/j.ins.2025.122675},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122675},
  shortjournal = {Inf. Sci.},
  title        = {Partition-based differentially private synthetic data generation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transferable adversarial attacks on human pose estimation: A regularization and pruning framework. <em>ISCI</em>, <em>723</em>, 122674. (<a href='https://doi.org/10.1016/j.ins.2025.122674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Pose Estimation (HPE) is a core component in real-time decision systems, supporting critical applications such as healthcare monitoring, autonomous driving, and sports analytics. While deep learning models—particularly CNNs and Transformer-based architectures—have significantly improved HPE accuracy, they remain vulnerable to adversarial perturbations that subtly distort keypoint localization, thereby undermining system reliability. To address this challenge, we propose regularization and pruning transferable adversarial attack (RPA), a novel framework designed to enhance the transferability of adversarial samples in Transformer-based HPE models. RPA integrates two synergistic strategies: gradient regularization, which suppresses dominant feature correlations to reduce overfitting, and adaptive weight pruning, which removes redundant parameters to reduce model-specific noise. This dual mechanism enables the generation of transferable adversarial attacks that are effective across diverse model architectures. Extensive experiments on state-of-the-art HPE networks demonstrate that RPA consistently outperforms existing attack methods. In white-box settings, RPA reduces average precision (AP) by 0.05-0.30; in black-box scenarios, it yields AP drops of 0.01-0.04. These findings expose critical vulnerabilities in IoT-enabled HPE applications and establish a new benchmark for evaluating adversarial robustness in real-time perception systems.},
  archive      = {J_ISCI},
  author       = {Renguang Chen and Xuechao Yang and Xun Yi and Zhide Chen and Chen Feng and Xu Yang and Kexin Zhu and Iqbal Gondal},
  doi          = {10.1016/j.ins.2025.122674},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122674},
  shortjournal = {Inf. Sci.},
  title        = {Transferable adversarial attacks on human pose estimation: A regularization and pruning framework},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection. <em>ISCI</em>, <em>723</em>, 122673. (<a href='https://doi.org/10.1016/j.ins.2025.122673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) aims to automatically identify anomalous events in surveillance videos that are significantly different from the normal pattern. Most existing methods learn the spatial-temporal distribution of normal features and detect deviations as anomalies. Typically, they employ autoencoders to independently learn appearance and motion features, but this separate learning limits the exploitation of their interrelation in real-world scenarios. To enhance the representation of normal patterns by capturing feature interrelation, we propose a cross-feature fusion and memory-constraint network (CF 2 M-Net) for VAD. Specifically, inspired by the representational ability of cross-attention in multimodal fusion, we design a cross-attention and memory-constraint (CM) module to enrich appearance features with motion information. To prevent overfitting to anomalous events, the memory-constraint module further constrains fused features within the distribution of normal patterns. We design an attention fusion (AF) decoder to predict normal features closer to the normal distribution, enhancing their separability from anomalies. By jointly modeling appearance and motion through feature fusion and memory constraints, CF 2 M-Net provides more discriminative normal representations for anomaly detection. Experimental evaluations on three benchmark datasets show that the CF 2 M-Net performs comparably with leading approaches. Moreover, the detailed evaluations indicate the effectiveness of normal representation based appearance-motion fusion features for VAD.},
  archive      = {J_ISCI},
  author       = {Qiming Ma and Chengyou Wang and Xiao Zhou},
  doi          = {10.1016/j.ins.2025.122673},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122673},
  shortjournal = {Inf. Sci.},
  title        = {CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method. <em>ISCI</em>, <em>723</em>, 122672. (<a href='https://doi.org/10.1016/j.ins.2025.122672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed data-driven event-triggered secure consensus control issue for model-free multi-agent systems (MASs) under sensor faults and denial-of-service (DoS) attacks, while satisfying prescribed performance constraints. First, a global preset-time performance function (PTPF) is constructed to guarantee the global stability of model-free MASs within the preset time. The proposed PTPF ensures that the preset time remains unaffected by variations in the sampling period. Second, a proportional-integral-derivative (PID) sliding surface is designed to enhance MAS performance regulation, while a novel generalized fuzzy hyperbolic model (GFHM) is constructed to eliminate the dependency on fault information and achieve high-accuracy estimation of unknown fault signals. Third, a hybrid event-triggered mechanism integrating both dynamic and memory features is developed to optimize communication resource utilization while guaranteeing robust performance at extremes. Furthermore, an event-triggered secure control scheme leveraging the memory feature is proposed to reduce communication overhead while avoiding the dangerous open-loop scenario, where control inputs must be zeroed under DoS attacks as in the existing methods. Finally, the stability proof together with simulations confirms the feasibility of the control strategy.},
  archive      = {J_ISCI},
  author       = {Run-Ze Chen and Xiang-Gui Guo and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2025.122672},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122672},
  shortjournal = {Inf. Sci.},
  title        = {Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization. <em>ISCI</em>, <em>723</em>, 122671. (<a href='https://doi.org/10.1016/j.ins.2025.122671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimization problems (MaOPs) are widely used in scientific research and engineering practices, which mainly consider joint optimization of multiple objectives simultaneously. Despite the numerous multi-objective evolutionary algorithms proposed in recent years, they often struggle with challenges in fitness assignment arising from objective conflicts. Meanwhile, they tend to perform well in only one aspect of convergence, diversity, and computational complexity. To address these issues, this paper proposes an improved multi-population co-evolutionary algorithm for many-objective optimization (termed MPCMO), which leverages the advantages of multi-population co-evolutionary techniques. The primary objective of MPCMO is to achieve a more balanced performance across convergence, diversity, and complexity. MPCMO comprises three essential components. Initially, an adaptive evolutionary strategy is employed to dynamically allocate evolutionary opportunities to subpopulations so as to conserve computational resources and enhance convergence. Subsequently, a migration strategy is developed to ensure a more global approximation of whole Pareto front. Additionally, an archive update-truncation strategy, based on angle selection and shift-based density estimation, is adopted to enhance diversity. We conduct comprehensive comparative experiments on a variety of many-objective benchmark problems with complicated characteristics. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art algorithms in terms of both diversity and convergence.},
  archive      = {J_ISCI},
  author       = {Weichao Ding and Jiahao Liu and Wenbo Dong and Fei Luo and Chunhua Gu},
  doi          = {10.1016/j.ins.2025.122671},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122671},
  shortjournal = {Inf. Sci.},
  title        = {MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforced heterogeneous graphlet design for knowledge graph representation learning. <em>ISCI</em>, <em>723</em>, 122670. (<a href='https://doi.org/10.1016/j.ins.2025.122670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are practical tools that represent and integrate plentiful structural and semantic information in mainstream industrial scenarios. Despite their potential, the heterogeneity and complexity of KGs pose a formidable obstacle, especially for graph representation learning. Most existing KG embedding models omit dynamic high-order connectivity patterns to gain insights into heterogeneous networks and heavily rely on handcrafted patterns to handle complex semantic relationships, which limits their capability to adaptively capture the nuanced and intricate relationships of KGs in different tasks. To fill this gap, we present Reinforced Heterogeneous Graphlet Design (ReHGD)—a model designed for KGs that focuses on the adaptive design of typed graphlets (heterogeneous chains and motifs) through a cooperative multi-agent reinforcement learning algorithm. This task-driven approach can learn discriminative graph representations tailored to specific downstream tasks. Specifically, ReHGD engages in the creation of typed graphlets through a two-stage process: it (1) establishes a reinforced chain design module to generate chains without predefined rules and (2) employs a buffer-aware sampling technique to derive episodic chains from prior experiences. Subsequently, motifs are deduced through the application of commute count and Hadamard product operations to the episodic chain-based subgraphs. In the final step toward learning graph representations, ReHGD undertakes chain and motif aggregations. Experimental results and analyses reveal that ReHGD outperforms strong baselines on three real-world graph data and practical tasks.},
  archive      = {J_ISCI},
  author       = {Jibing Gong and Yuting Lin and Yi Zhao and Tianyu Lin and Xiaohan Fang and Xinchao Feng and Jiquan Peng},
  doi          = {10.1016/j.ins.2025.122670},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122670},
  shortjournal = {Inf. Sci.},
  title        = {Reinforced heterogeneous graphlet design for knowledge graph representation learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis. <em>ISCI</em>, <em>723</em>, 122669. (<a href='https://doi.org/10.1016/j.ins.2025.122669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture analysis is crucial for understanding images by extracting features that define spatial patterns. Recently, bi-dimensional extensions of entropy measures have gained attention due to their simplicity and strong theoretical foundations. However, existing methods primarily operate in the spatial domain and thus overlook frequency-domain and multiscale information. To address this, we introduce bidimensional wavelet increment entropy (wavelet IncrEn 2 D ). A one-level discrete wavelet transform (DWT) with the Haar wavelet decomposes each image into approximation (low-frequency) and, for some neuroimaging data, detail (high-frequency) subbands; IncrEn 2 D is then applied both to capture global structural patterns and fine, detailed texture variations. We evaluated wavelet IncrEn 2 D on synthetic and real datasets, demonstrating its effectiveness in distinguishing between different noise types (white Gaussian, salt-and-pepper, and speckle noise). Comparisons between periodic and synthesized images revealed lower wavelet IncrEn 2 D values for periodic textures. Tests on real texture datasets highlight the method's ability to differentiate various patterns. In particular, wavelet IncrEn 2 D achieved 86.69% accuracy in distinguishing MRI images of healthy versus multiple sclerosis–affected brains. Overall, wavelet IncrEn 2 D offers a robust, frequency-aware descriptor that outperforms existing 2D entropy methods.},
  archive      = {J_ISCI},
  author       = {Muqaddas Abid and Muhammad Suzuri Hitam and Rozniza Ali and Hamed Azami and Anne Humeau-Heurtier},
  doi          = {10.1016/j.ins.2025.122669},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122669},
  shortjournal = {Inf. Sci.},
  title        = {Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved query specialization for transformer-based visual relationship detection. <em>ISCI</em>, <em>723</em>, 122668. (<a href='https://doi.org/10.1016/j.ins.2025.122668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Relationship Detection (VRD) has significantly advanced with Transformer-based architectures. However, we identify two fundamental drawbacks in conventional label assignment methods used for training Transformer-based VRD models, where ground-truth (GT) annotations are matched to model predictions. In conventional assignment, queries are trained to detect all relations rather than specializing in specific ones, resulting in ‘unspecialized’ queries. Also, each ground-truth (GT) annotation is assigned to only one prediction under conventional assignment, suppressing other near-correct predictions by labeling them as ‘no relation’. To address these issues, we introduce a novel method called Groupwise Query Spe ci a lization and Q uality-Aware Multi-Assignment (SpeaQ). Groupwise Query Specialization clusters queries and relations into exclusive groups, promoting specialization by assigning a set of relations only to a corresponding query group. Quality-Aware Multi-Assignment enhances training signals by allowing multiple predictions closely matching the GT to be positively assigned. Additionally, we introduce dynamic query reallocation, which transfers queries from high- to low-performing groups for balanced training. Experimental results demonstrate that SpeaQ+, combining SpeaQ with dynamic query reallocation, consistently improves performance across seven baseline models on five benchmarks without additional inference cost.},
  archive      = {J_ISCI},
  author       = {Jongha Kim and Jihwan Park and Jinyoung Park and Jinyoung Kim and Sehyung Kim and Hyunwoo J. Kim},
  doi          = {10.1016/j.ins.2025.122668},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122668},
  shortjournal = {Inf. Sci.},
  title        = {Improved query specialization for transformer-based visual relationship detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling. <em>ISCI</em>, <em>723</em>, 122656. (<a href='https://doi.org/10.1016/j.ins.2025.122656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modeling of spatio-temporal dynamic systems, tasks such as fluid dynamics, weather forecasting, and traffic flow prediction face highly complex spatio-temporal dependencies and nonlinear dynamics. These characteristics make it challenging for traditional physical models and data-driven methods to balance accuracy and computational efficiency. To address these challenges, we propose a multi-scale spatio-temporal convolutional network named ConvDiff, optimized specifically for dynamic system modeling tasks by integrating a latent space denoising diffusion model. ConvDiff effectively captures complex spatio-temporal features and handles uncertainties in physical systems by introducing multi-scale convolutional modules combined with a physics-guided diffusion mechanism. Specifically, our model incorporates eight temporal modules and four spatial modules, using a hierarchical convolutional and diffusion structure to capture the intricate dynamics of physical systems. The experiments involved different spatio-temporal data, such as those from TaxiBJ and the Navier-Stokes dataset. According to the findings, ConvDiff demonstrates substantial improvements in essential performance indicators. For example, in the TaxiBJ dataset, ConvDiff obtained a mean squared deviation of 0.29 and a PSNR value of 40.31, outperforming the best-performing models. Moreover, on the Navier-Stokes dataset, ConvDiff reduced the MSE by 51.15% compared to the best baseline model. These results indicate that ConvDiff effectively captures complex spatio-temporal dependencies and improves prediction accuracy, particularly in physics-driven dynamic systems. Our code is available at https://github.com/Ray-zyy/ConvDiff .},
  archive      = {J_ISCI},
  author       = {Yuyang Zhao and Yuhan Wu and Yongmei Wang},
  doi          = {10.1016/j.ins.2025.122656},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122656},
  shortjournal = {Inf. Sci.},
  title        = {ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis. <em>ISCI</em>, <em>723</em>, 122655. (<a href='https://doi.org/10.1016/j.ins.2025.122655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing influence of investor sentiment on market dynamics, sentiment analysis has emerged as an effective tool for enhancing financial forecasting models. This study proposes a diversity-enhanced semi-heterogeneous ensemble forecasting framework that integrates sentiment analysis into the forecasting of stock index returns. A supervised stock market sentiment index set is constructed, in which prior knowledge regarding term importance is integrated into the data augmentation process. This enables higher weights to be assigned to sentiment-related terms with superior predictive capacity, thereby allowing the model to prioritize more informative features and enhance its forecasting performance. A series of diverse base models are generated through the integration of multiple attention-PCA techniques and forecasting algorithms based on variable perturbation strategies. These base models are subsequently combined through a suite of ensemble strategies, forming a semi-heterogeneous ensemble model for forecasting S&P 500 returns. The experiment results demonstrate that the proposed approaches significantly outperform benchmark methods, with notable improvements in both accuracy and diversity.},
  archive      = {J_ISCI},
  author       = {Xiao Zhang and Peide Liu and Jing Feng},
  doi          = {10.1016/j.ins.2025.122655},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122655},
  shortjournal = {Inf. Sci.},
  title        = {A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-related controllability of corona product networks. <em>ISCI</em>, <em>723</em>, 122654. (<a href='https://doi.org/10.1016/j.ins.2025.122654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the energy-related controllability for a category of ‘large’ composite networks generated by ‘small’ simple factor networks with Laplacian dynamics under a leader-follower framework via corona product. Different from most existing literature on network controllability, this work characterizes the controllability of corona product networks (CPNs) from an energy point of view. This can quantify the difficulty of controlling CPNs based on controllability Gramian measures, involving average controllability and volumetric control energy, etc., where the energy is triggered by the leaders. The energy-related controllability of a CPN can be explored from the eigenvalues and eigenvectors of its factor networks. An algorithm for solving the maximum average controllability is provided, which can help one select the leaders to optimize network control and be applied in practice.},
  archive      = {J_ISCI},
  author       = {Qiang Zhang and Junjie Huang and Bo Liu and Housheng Su and Alatancang Chen},
  doi          = {10.1016/j.ins.2025.122654},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122654},
  shortjournal = {Inf. Sci.},
  title        = {Energy-related controllability of corona product networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SeqRFM: Fast RFM analysis in sequence data. <em>ISCI</em>, <em>723</em>, 122652. (<a href='https://doi.org/10.1016/j.ins.2025.122652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data mining technologies have been well applied to many domains, including e-commerce. In customer relationship management (CRM), the Recency-Frequency-Monetary (RFM) analysis model is one of the most effective approaches to increase the profits of major enterprises. However, with the rapid development of e-commerce, the diversity and abundance of e-commerce data pose a challenge to mining efficiency. Moreover, in actual market transactions, the chronological order of transactions reflects customer behavior and preferences. To address these challenges, we develop an effective algorithm called SeqRFM, which combines sequential pattern mining with RFM models. SeqRFM considers each customer's R, F, and M scores to represent the significance of the customer and identifies sequences with high recency, high frequency, and high monetary value. A series of experiments demonstrates the superiority and effectiveness of the SeqRFM algorithm compared to the most advanced RFM algorithms based on sequential pattern mining. Moreover, another algorithm named MSeqRFM is developed to compress the result of SeqRFM. The experiments demonstrate the effectiveness of MSeqRFM in compressing sequences. The source code and datasets are available at GitHub https://github.com/DSI-Lab1/SeqRFM .},
  archive      = {J_ISCI},
  author       = {Yanxin Zheng and Wensheng Gan and Zefeng Chen and Pinlyu Zhou and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2025.122652},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122652},
  shortjournal = {Inf. Sci.},
  title        = {SeqRFM: Fast RFM analysis in sequence data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems. <em>ISCI</em>, <em>723</em>, 122651. (<a href='https://doi.org/10.1016/j.ins.2025.122651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a finite-time dynamic event-triggered actor-critic-identifier (FT-DET-ACI) framework for the optimal control problem of nonlinear systems with uncertain drift dynamics. A theoretical foundation is established by reformulating the value function within a finite-time stable space, which facilitates system state stabilization within predetermined temporal constraints. The proposed approach derives finite-time optimal controllers through a transformed Hamilton-Jacobi-Bellman (HJB) equation. To address unknown system dynamics, an integrated actor-critic-identifier architecture is constructed to concurrently approximate the value function, synthesize the finite-time optimal controller, and identify system parameters. A dynamic event-triggering rule is designed to reduce computational and communication loads by selectively updating the control signal. Lyapunov stability analysis is provided to demonstrate the finite-time convergence properties of the closed-loop system. Numerical experiments are conducted to validate the efficacy of the proposed FT-DET-ACI methodology.},
  archive      = {J_ISCI},
  author       = {Shuangsi Xue and Junkai Tan and Zihang Guo and Qingshu Guan and Hui Cao and Badong Chen},
  doi          = {10.1016/j.ins.2025.122651},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122651},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Set membership filter with nonlinear state inequality constraints. <em>ISCI</em>, <em>723</em>, 122650. (<a href='https://doi.org/10.1016/j.ins.2025.122650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set membership filter is a promising method to provide a bounding estimation containing the true state for dynamic systems with unknown but bounded noises. In this paper, we investigate the state bounding estimation problem of nonlinear dynamic systems with nonlinear state inequality constraints. Three types of ellipsoidal state bounding estimation methods are proposed by incorporating nonlinear state inequality constraints into nonlinear set membership filter. They are called model reduction method, system measurement method, and constraint dimension reduction method, respectively. We analyze the computation complexity of the three methods, which decrease in the order of model reduction method, system measurement method, and constraint dimension reduction method. Due to the nonlinearity of the dynamic systems, all the three methods are approximation algorithms and the state estimation accuracy cannot be analyzed explicitly. Consequently, a typical illustrative numerical experiment is conducted to compare the performance of the three methods. The results show that the accuracy increases in the order of the model reduction method, the constraint dimension reduction method, and the system measurement method.},
  archive      = {J_ISCI},
  author       = {Xiaowei Li and Xuqi Zhang and Zhiguo Wang and Xiaojing Shen},
  doi          = {10.1016/j.ins.2025.122650},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122650},
  shortjournal = {Inf. Sci.},
  title        = {Set membership filter with nonlinear state inequality constraints},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration. <em>ISCI</em>, <em>723</em>, 122649. (<a href='https://doi.org/10.1016/j.ins.2025.122649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-to-grid (V2G) technology leverages the distributed energy-storage potential of electric vehicles (EVs), transforming the challenges of large-scale EV integration into opportunities to enhance grid flexibility and reliability. This study investigates the optimization of EV charging-discharging schedules by exploiting V2G capabilities. First, considering the spatiotemporal distribution of EVs, a Markov chain is constructed to describe probabilistic transitions between spatiotemporal states, which is then embedded in a traffic-network-based path decision model. Second, a dynamic battery energy consumption model is established, incorporating multiple factors that influence battery performance. Using Monte Carlo simulation results, a bi-objective optimization model is formulated to schedule charging and discharging, simultaneously minimizing (i) total cost — including user recharging time and battery degradation — and (ii) grid-load fluctuation. Given the NP-hard nature of the problem, an improved multi-objective bitterling fish optimization (IMOBFO) algorithm is developed to balance global exploration and local exploitation. Empirical studies in a region of Shanghai compare three strategies: disordered charging, ordered charging, and the proposed optimized charging–discharging strategy. Experimental results confirm the feasibility of the proposed model and the effectiveness of IMOBFO. Comparative analysis with seven other algorithms further validates the superior performance and stability of IMOBFO according to multiple multi-objective evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Bing Yu and Yong Liu and Liang Ma},
  doi          = {10.1016/j.ins.2025.122649},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122649},
  shortjournal = {Inf. Sci.},
  title        = {Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified graph-based framework for visual explainability in convolutional neural networks. <em>ISCI</em>, <em>723</em>, 122648. (<a href='https://doi.org/10.1016/j.ins.2025.122648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, understanding the decision-making processes of complex models is essential for advancing interpretability and trust in artificial intelligence systems. We introduce Causal Relational Attribution Graph (C-RAG), designed to deliver comprehensive, multi-perspective explanations of convolutional neural networks (CNNs) via a graph representation. C-RAG integrates gradient-based local attribution with global feature importance by constructing a graph-based representation that captures hierarchical feature inter-dependencies. In this framework, feature clusters are represented as graph nodes, and their interactions are quantified through combined localized and global attribution metrics, ensuring interpretable insights into model behavior. We evaluate C-RAG across diverse benchmark datasets (ImageNet, CIFAR-10, MNIST) and CNN architectures (ResNet18, VGG19, DenseNet201, LeNet), demonstrating significant advancements over state-of-the-art explainability methods in faithfulness, robustness, and computational efficiency. The proposed approach facilitates accurate spatial feature localization, robust dependency mapping, and efficient explanation generation, making it a valuable tool for critical applications such as medical imaging and autonomous systems. We provide a novel graph-based explainability framework, which bridges the gap between local and global interpretability, C-RAG addresses key limitations in existing methods, establishing a robust foundation for explainable AI in computer vision.},
  archive      = {J_ISCI},
  author       = {Basim Azam and Pubudu Sanjeewani and Brijesh Verma and Ashfaqur Rahman and Lipo Wang},
  doi          = {10.1016/j.ins.2025.122648},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122648},
  shortjournal = {Inf. Sci.},
  title        = {Unified graph-based framework for visual explainability in convolutional neural networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting. <em>ISCI</em>, <em>723</em>, 122647. (<a href='https://doi.org/10.1016/j.ins.2025.122647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) has been a significant research focus across various domains. Recent studies have utilized deep neural networks to identify pattern relationships in MTSF. Despite these developments, accurately forecasting multivariate time series remains challenging due to the trend of time series and spatial-temporal heterogeneity. In this paper, we propose a unified multivariate time series forecasting framework for long-term, short-term, and spatial-temporal forecasting with attention-based spatial-temporal interactive coupled neural networks (ASTIC). Specifically, we proposed a spatial-temporal interactive couple block that contains both temporal and spatial branches to investigate the relationships between global and local patterns in temporal and spatial perspectives. In the temporal branch, we design a hybrid network module capable of enhancing representation learning using convolution and attention mechanisms, which dynamically capture the local trendiness and long-term time dependence implicit in time series. In the spatial branch, a novel dynamic graph learners are designed to learn global and local spatial patterns. Then a novel interactive coupling method is proposed to link the two branches together. ASTIC predicts time series effectively by using a multilevel structure to model the trendiness of the series and mining the spatial-temporal heterogeneity. Experimental results show that our method outperforms state-of-the-art baseline methods on nine real-world datasets.},
  archive      = {J_ISCI},
  author       = {Bingsheng Wei and Yonghua Hei and Yuan Wan},
  doi          = {10.1016/j.ins.2025.122647},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122647},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New solutions based on the generalized eigenvalue problem for the data collaboration analysis. <em>ISCI</em>, <em>723</em>, 122642. (<a href='https://doi.org/10.1016/j.ins.2025.122642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the data collaboration (DC) analysis, a privacy-preserving method for analyzing decentralized datasets held by multiple parties. In this method, privacy-preserving intermediate representations of original datasets are collected from multiple parties and then converted into collaboration representations for collaborative data analysis. However, conventional methods for creating collaboration representations suffer from several challenges; namely, the optimization problem being considered is not well defined, and the process of solving it is very difficult to understand. We thus propose a new solution for creating high-quality collaboration representations for the DC analysis. Specifically, we formulate a revised optimization problem for creating collaboration representations and then transform this optimization problem into a generalized eigenvalue problem. We also propose a reduction of the generalized eigenvalue problem to a singular value decomposition through the QR decomposition. Computational experiments using publicly available datasets demonstrate that our method can outperform the conventional methods for the DC analysis in terms of both prediction accuracy and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Yuta Kawakami and Yuichi Takano and Akira Imakura},
  doi          = {10.1016/j.ins.2025.122642},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122642},
  shortjournal = {Inf. Sci.},
  title        = {New solutions based on the generalized eigenvalue problem for the data collaboration analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data. <em>ISCI</em>, <em>723</em>, 122641. (<a href='https://doi.org/10.1016/j.ins.2025.122641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear causal discovery from observational data imposes strict identifiability assumptions on the formulation of structural equations utilized in the data-generating process. However, in real-life settings, the ground-truth mechanism responsible for cause-effect transformations is unknown. Thus, it is impossible to verify its identifiability. This is the first research to assess the performance of structure learning algorithms from seven different families in non-identifiable settings with an increasing degree of nonlinearity. The evaluation of structure learning methods under assumption violations requires a rigorous and interpretable approach that quantifies both the structural similarity of the estimation with the ground truth and the capacity of the discovered graphs to be used for causal inference. Motivated by the lack of a unified performance assessment indicator, we propose an interpretable, multidimensional evaluation framework, specifically tailored to the field of causal discovery from i.i.d. data. In particular, we introduce a six-dimensional evaluation metric, called distance to the optimal solution, which aims at providing a holistic overview of the performance of structure learning techniques. Our large-scale simulation study, which incorporates seven experimental factors, shows that hybrid Bayesian networks outperform most recently introduced continuous optimization techniques under certain conditions. Additionally, causal order-based methods yield results with comparatively high proximity to the optimal solution.},
  archive      = {J_ISCI},
  author       = {Georg Velev and Stefan Lessmann},
  doi          = {10.1016/j.ins.2025.122641},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122641},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jaim">JAIM - 16</h2>
<ul>
<li><details>
<summary>
(2025). Solution of all quartic matrix models. <em>JAIM</em>, <em>481</em>, 110551. (<a href='https://doi.org/10.1016/j.aim.2025.110551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the quartic analogue of the Kontsevich model, which is defined by a measure exp ⁡ ( − N Tr ( E Φ 2 + ( λ / 4 ) Φ 4 ) ) d Φ on Hermitian N × N -matrices, where E is any positive matrix and λ a scalar. It was previously established that the large- N limit of the second moment (the planar two-point function) satisfies a non-linear integral equation. By employing tools from complex analysis, in particular the Lagrange-Bürmann inversion formula, we identify the exact solution of this non-linear problem, both for finite N and for a large- N limit to unbounded operators E of spectral dimension ≤4. For finite N , the two-point function is a rational function evaluated at the preimages of another rational function R constructed from the spectrum of E . Subsequent work has constructed from this formula a family ω g , n of meromorphic differentials which obey blobbed topological recursion. For unbounded operators E , the renormalised two-point function is given by an integral formula involving a regularisation of R . This allowed a proof, in subsequent work, that the λ Φ 4 4 -model on noncommutative Moyal space does not have a triviality problem.},
  archive      = {J_JAIM},
  author       = {Harald Grosse and Alexander Hock and Raimar Wulkenhaar},
  doi          = {10.1016/j.aim.2025.110551},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110551},
  shortjournal = {Adv. Math.},
  title        = {Solution of all quartic matrix models},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear reedy categories, quasi-hereditary algebras and model structures. <em>JAIM</em>, <em>481</em>, 110550. (<a href='https://doi.org/10.1016/j.aim.2025.110550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study linear versions of Reedy categories in relation with finite dimensional algebras and abelian model structures. We prove that, for a linear Reedy category C over a field, the category of left C –modules admits a highest weight structure, which in case C is finite corresponds to a quasi-hereditary algebra with an exact Borel subalgebra. We also lift complete cotorsion pairs and abelian model structures to certain categories of additive functors indexed by linear Reedy categories, generalizing analogous results from the hereditary case.},
  archive      = {J_JAIM},
  author       = {Georgios Dalezios and Jan Šťovíček},
  doi          = {10.1016/j.aim.2025.110550},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110550},
  shortjournal = {Adv. Math.},
  title        = {Linear reedy categories, quasi-hereditary algebras and model structures},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational principles for hausdorff and packing dimensions of fractal percolation on self-affine sponges. <em>JAIM</em>, <em>481</em>, 110549. (<a href='https://doi.org/10.1016/j.aim.2025.110549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish variational principles for the Hausdorff and packing dimensions of a class of statistically self-affine sponges, including in particular fractal percolation sets obtained from Barański and Gatzouras-Lalley carpets and sponges. Our first step is to compute the Hausdorff and packing dimensions of non-degenerate inhomogeneous Mandelbrot measures supported on the associated random limit sets. This is not a straightforward combination of the existing approaches for the deterministic inhomogeneous Bernoulli measures and the Mandelbrot measures on random Sierpiński sponges; it reveals new structural features. The variational principles rely on a specific subclass of inhomogeneous Mandelbrot measures, which are connected to localized digit frequencies in the underlying coding space. This connection makes it possible to construct effective coverings of the random limit set, leading to sharp upper bounds for its Hausdorff and packing dimensions.},
  archive      = {J_JAIM},
  author       = {Julien Barral and Guilhem Brunet},
  doi          = {10.1016/j.aim.2025.110549},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110549},
  shortjournal = {Adv. Math.},
  title        = {Variational principles for hausdorff and packing dimensions of fractal percolation on self-affine sponges},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The consistency strength of determinacy when all sets are universally baire. <em>JAIM</em>, <em>481</em>, 110548. (<a href='https://doi.org/10.1016/j.aim.2025.110548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that the large cardinal strength of the Axiom of Determinacy when enhanced with the hypothesis that all sets of reals are universally Baire is much stronger than the Axiom of Determinacy itself. Sargsyan conjectured it to be as strong as the existence of a cardinal that is both a limit of Woodin cardinals and a limit of strong cardinals. Larson, Sargsyan and Wilson used a generalization of Woodin's derived model construction to show that this conjectured result would be optimal. In this paper we introduce a new translation procedure for hybrid mice extending work of Steel, Zhu and Sargsyan and apply it to prove Sargsyan's conjecture.},
  archive      = {J_JAIM},
  author       = {Sandra Müller},
  doi          = {10.1016/j.aim.2025.110548},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110548},
  shortjournal = {Adv. Math.},
  title        = {The consistency strength of determinacy when all sets are universally baire},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eigenvalues of supersymmetric shimura operators and interpolation polynomials. <em>JAIM</em>, <em>481</em>, 110547. (<a href='https://doi.org/10.1016/j.aim.2025.110547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Shimura operators are a certain distinguished basis for invariant differential operators on a Hermitian symmetric space. Answering a question of Shimura, Sahi and Zhang showed that the Harish-Chandra images of these operators are specializations of certain BC -symmetric interpolation polynomials that were defined by Okounkov. We consider the analogs of Shimura operators for the Hermitian symmetric superpair ( g , k ) where g = gl ( 2 p | 2 q ) and k = gl ( p | q ) ⊕ gl ( p | q ) and we prove their Harish-Chandra images are specializations of certain BC -supersymmetric interpolation polynomials introduced by Sergeev and Veselov.},
  archive      = {J_JAIM},
  author       = {Siddhartha Sahi and Songhao Zhu},
  doi          = {10.1016/j.aim.2025.110547},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110547},
  shortjournal = {Adv. Math.},
  title        = {Eigenvalues of supersymmetric shimura operators and interpolation polynomials},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stationary completeness: The N-body short-range case. <em>JAIM</em>, <em>481</em>, 110544. (<a href='https://doi.org/10.1016/j.aim.2025.110544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a general class of N -body Schrödinger operators with short-range pair-potentials the wave and scattering matrices as well as the restricted wave operators are all defined at any non-threshold energy. This holds without imposing any a priori decay condition on channel eigenstates and even for models including long-range potentials of Dereziński-Enss type. In this paper we improve for short-range models on the known weak continuity properties in that we show that all non-threshold energies are stationary complete , resolving in this case a conjecture from [21] . A consequence is that the above scattering quantities depend strongly continuously on the energy parameter at all non-threshold energies (improving on previously almost everywhere proven properties). Another consequence is that the scattering matrix is unitary at any such energy. As a side result we obtain a new and purely stationary proof of asymptotic completeness for N -body short-range systems.},
  archive      = {J_JAIM},
  author       = {E. Skibsted},
  doi          = {10.1016/j.aim.2025.110544},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110544},
  shortjournal = {Adv. Math.},
  title        = {Stationary completeness: The N-body short-range case},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-archimedean theory of complex spaces and the cscK problem. <em>JAIM</em>, <em>481</em>, 110543. (<a href='https://doi.org/10.1016/j.aim.2025.110543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we develop an analogue of the Berkovich analytification for non-necessarily algebraic complex spaces. We apply this theory to generalize to arbitrary compact Kähler manifolds a result of Chi Li, [42] , proving that a stronger version of K-stability implies the existence of a unique constant scalar curvature Kähler metric.},
  archive      = {J_JAIM},
  author       = {Pietro Mesquita-Piccione},
  doi          = {10.1016/j.aim.2025.110543},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110543},
  shortjournal = {Adv. Math.},
  title        = {A non-archimedean theory of complex spaces and the cscK problem},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Persistence of rademacher-type and sobolev-to-lipschitz properties. <em>JAIM</em>, <em>481</em>, 110542. (<a href='https://doi.org/10.1016/j.aim.2025.110542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Rademacher- and Sobolev-to-Lipschitz-type properties for arbitrary quasi-regular strongly local Dirichlet spaces. We discuss the persistence of these properties under localization, globalization, transfer to weighted spaces, tensorization, and direct integration. As byproducts, we obtain: necessary and sufficient conditions to identify a quasi-regular strongly local Dirichlet form on an extended metric topological σ -finite possibly non-Radon measure space with the Cheeger energy of the space; the tensorization of intrinsic distances; the tensorization of the Varadhan short-time asymptotics.},
  archive      = {J_JAIM},
  author       = {Lorenzo Dello Schiavo and Kohei Suzuki},
  doi          = {10.1016/j.aim.2025.110542},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110542},
  shortjournal = {Adv. Math.},
  title        = {Persistence of rademacher-type and sobolev-to-lipschitz properties},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rigidity of analytic and smooth bi-cubic multicritical circle maps with bounded type rotation numbers. <em>JAIM</em>, <em>481</em>, 110541. (<a href='https://doi.org/10.1016/j.aim.2025.110541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that if two analytic multicritical circle maps with the same bounded type rotation number are topologically conjugate by a conjugacy which matches the critical points of the two maps while preserving the orders of their criticalities, then the conjugacy necessarily has C 1 + α regularity, where α depends only on the bound on the type of the rotation number. We then extend this rigidity result to C 3 -smooth bi-cubic circle maps.},
  archive      = {J_JAIM},
  author       = {Igors Gorbovickis and Michael Yampolsky},
  doi          = {10.1016/j.aim.2025.110541},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110541},
  shortjournal = {Adv. Math.},
  title        = {Rigidity of analytic and smooth bi-cubic multicritical circle maps with bounded type rotation numbers},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An almost kurepa suslin tree with strongly non-saturated square. <em>JAIM</em>, <em>481</em>, 110540. (<a href='https://doi.org/10.1016/j.aim.2025.110540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For uncountable downwards closed subtrees U and W of an ω 1 -tree T , we say that U and W are strongly almost disjoint if their intersection is a finite union of countable chains. The tree T is strongly non-saturated if there exists a strongly almost disjoint family of ω 2 -many uncountable downwards closed subtrees of T . In this article we construct a Knaster forcing which adds a Suslin tree together with a family of ω 2 -many strongly almost disjoint automorphisms of it (and thus the square of the Suslin tree is strongly non-saturated). To achieve this goal, we introduce a new idea called ρ-separation , which is an adaptation to the finite context of the notion of separation which was recently introduced by Stejskalová and the first author for the purpose of adding automorphisms of a tree with a forcing with countable conditions.},
  archive      = {J_JAIM},
  author       = {John Krueger and Eduardo Martinez Mendoza},
  doi          = {10.1016/j.aim.2025.110540},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110540},
  shortjournal = {Adv. Math.},
  title        = {An almost kurepa suslin tree with strongly non-saturated square},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The weakly nonlinear schrödinger equation in higher dimensions with quasi-periodic initial data. <em>JAIM</em>, <em>481</em>, 110539. (<a href='https://doi.org/10.1016/j.aim.2025.110539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, under the exponential/polynomial decay condition in Fourier space, we prove that the nonlinear solution to the quasi-periodic Cauchy problem for the weakly nonlinear Schrödinger equation in higher dimensions will asymptotically approach the associated linear solution within a specific time scale. The proof is based on a combinatorial analysis method presented through diagrams. Our results and methods apply to arbitrary space dimensions and general power-law nonlinearities of the form ± | u | 2 p u , where 1 ≤ p ∈ N .},
  archive      = {J_JAIM},
  author       = {Fei Xu},
  doi          = {10.1016/j.aim.2025.110539},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110539},
  shortjournal = {Adv. Math.},
  title        = {The weakly nonlinear schrödinger equation in higher dimensions with quasi-periodic initial data},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extendability of foliations. <em>JAIM</em>, <em>481</em>, 110538. (<a href='https://doi.org/10.1016/j.aim.2025.110538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a foliation F on X and an embedding X ⊆ Y , is there a foliation on Y extending F? Using formal methods, we show that this question has an affirmative answer whenever the embedding is sufficiently positive with respect to ( X , F ) and the singularities of F belong to a certain class. These tools also apply in the case where Y is the total space of a deformation of X. Regarding the uniqueness of the extension, we prove a foliated version of a statement by Fujita and Grauert ensuring the existence of tubular neighborhoods. We also give sufficient conditions for a foliation to have only trivial unfoldings, generalizing a result due to Gómez-Mont.},
  archive      = {J_JAIM},
  author       = {Pablo Perrella and Sebastián Velazquez},
  doi          = {10.1016/j.aim.2025.110538},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110538},
  shortjournal = {Adv. Math.},
  title        = {Extendability of foliations},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sharp localized weighted inequality related to gagliardo and sobolev seminorms and its applications. <em>JAIM</em>, <em>481</em>, 110537. (<a href='https://doi.org/10.1016/j.aim.2025.110537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we establish a nearly sharp localized weighted inequality related to Gagliardo and Sobolev seminorms, respectively, with the sharp A 1 -weight constant or with the specific A p -weight constant when p ∈ ( 1 , ∞ ) . As applications, we further obtain a new characterization of Muckenhoupt weights and, in the framework of ball Banach function spaces, an inequality related to Gagliardo and Sobolev seminorms on cubes, a Gagliardo–Nirenberg interpolation inequality, and a Bourgain–Brezis–Mironescu formula. All these obtained results have wide generality and are proved to be (nearly) sharp.},
  archive      = {J_JAIM},
  author       = {Pingxu Hu and Yinqin Li and Dachun Yang and Wen Yuan},
  doi          = {10.1016/j.aim.2025.110537},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110537},
  shortjournal = {Adv. Math.},
  title        = {A sharp localized weighted inequality related to gagliardo and sobolev seminorms and its applications},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-moduli spaces of log del pezzo pairs. <em>JAIM</em>, <em>481</em>, 110536. (<a href='https://doi.org/10.1016/j.aim.2025.110536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish the full explicit wall-crossings for K-moduli space P ‾ K ( c ) of degree 8 del Pezzo pairs ( X , c C ) , where generically X ≅ F 1 and C ∼ − 2 K X . We also show that the K-moduli spaces P ‾ K ( c ) coincide with the Hassett-Keel-Looijenga (HKL) models F ( s ) of an 18-dimensional locally symmetric space associated with the lattice E 8 ⊕ U 2 ⊕ E 7 ⊕ A 1 under the transformation s ( c ) = 1 − 2 c 56 c − 4 . This implies that the K-moduli spaces interpolate the GIT partial compactification and the Baily-Borel compactification for the moduli space of smooth Del Pezzo pairs. Some discussions concerning the relationship to KSBA moduli spaces are also provided.},
  archive      = {J_JAIM},
  author       = {Long Pan and Fei Si and Haoyu Wu},
  doi          = {10.1016/j.aim.2025.110536},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110536},
  shortjournal = {Adv. Math.},
  title        = {K-moduli spaces of log del pezzo pairs},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrality of mirror maps and arithmetic homological mirror symmetry for Greene–Plesser mirrors. <em>JAIM</em>, <em>481</em>, 110535. (<a href='https://doi.org/10.1016/j.aim.2025.110535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the ‘integrality of Taylor coefficients of mirror maps’ conjecture for Greene–Plesser mirror pairs as a natural byproduct of an arithmetic refinement of homological mirror symmetry. We also prove homological mirror symmetry for Greene–Plesser mirror pairs in all characteristics such that the B-side family has good reduction, generalizing work of the fifth author and Smith over the complex numbers. A key technical ingredient is a new versality argument which allows us to work throughout over a Novikov-type ring with integer coefficients.},
  archive      = {J_JAIM},
  author       = {Sheel Ganatra and Andrew Hanlon and Jeff Hicks and Daniel Pomerleano and Nick Sheridan},
  doi          = {10.1016/j.aim.2025.110535},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110535},
  shortjournal = {Adv. Math.},
  title        = {Integrality of mirror maps and arithmetic homological mirror symmetry for Greene–Plesser mirrors},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intermediate subalgebras of cartan embeddings in rings and c*-algebras. <em>JAIM</em>, <em>481</em>, 110534. (<a href='https://doi.org/10.1016/j.aim.2025.110534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let D ⊆ A be a quasi-Cartan pair of algebras. Then there exists a unique discrete groupoid twist Σ → G whose twisted Steinberg algebra is isomorphic to A in a way that preserves D . In this paper, we show there is a lattice isomorphism between wide open subgroupoids of G and subalgebras C such that D ⊆ C ⊆ A and D ⊆ C is a quasi-Cartan pair. We also characterize which algebraic diagonal/algebraic Cartan/quasi-Cartan pairs have the property that every subalgebra C with D ⊆ C ⊆ A has D ⊆ C a diagonal/Cartan/quasi-Cartan pair. In the diagonal case, when the coefficient ring is a field, it is all of them. Beyond that, only pairs that are close to being diagonal have this property. We then apply our techniques to C*-algebraic inclusions and give a complete characterization of which Cartan pairs D ⊆ A have the property that every C*-subalgebra C with D ⊆ C ⊆ A has D ⊆ C a Cartan pair.},
  archive      = {J_JAIM},
  author       = {Jonathan H. Brown and Lisa Orloff Clark and Adam H. Fuller},
  doi          = {10.1016/j.aim.2025.110534},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110534},
  shortjournal = {Adv. Math.},
  title        = {Intermediate subalgebras of cartan embeddings in rings and c*-algebras},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jat">JAT - 2</h2>
<ul>
<li><details>
<summary>
(2026). Asymptotics of the humbert functions Ψ1 and Ψ2. <em>JAT</em>, <em>314</em>, 106233. (<a href='https://doi.org/10.1016/j.jat.2025.106233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A compilation of new results on the asymptotic behaviour of the Humbert functions Ψ 1 and Ψ 2 , and also on the Appell function F 2 , is presented. As a by-product, we confirm a conjectured limit which appeared recently in the study of the 1 D Glauber–Ising model. We also propose two elementary asymptotic methods and confirm through some illustrative examples that both methods have great potential and can be applied to a large class of problems of asymptotic analysis. Finally, some directions of future research are pointed out in order to suggest ideas for further study.},
  archive      = {J_JAT},
  author       = {Peng-Cheng Hang and Malte Henkel and Min-Jie Luo},
  doi          = {10.1016/j.jat.2025.106233},
  journal      = {Journal of Approximation Theory},
  month        = {3},
  pages        = {106233},
  shortjournal = {J. Approx. Theory},
  title        = {Asymptotics of the humbert functions Ψ1 and Ψ2},
  volume       = {314},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nevai’s condition for measures with unbounded supports. <em>JAT</em>, <em>314</em>, 106232. (<a href='https://doi.org/10.1016/j.jat.2025.106232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study Nevai’s condition from the theory of orthogonal polynomials on the real line. We prove that a large class of measures with unbounded Jacobi parameters satisfies Nevai’s condition locally uniformly on the support of the measure away from a finite explicit set. This allows us to give applications to relative uniform and weak asymptotics of Christoffel–Darboux kernels on the diagonal and to limit theorems for unconventionally normalized global linear statistics of orthogonal polynomial ensembles.},
  archive      = {J_JAT},
  author       = {Grzegorz Świderski},
  doi          = {10.1016/j.jat.2025.106232},
  journal      = {Journal of Approximation Theory},
  month        = {3},
  pages        = {106232},
  shortjournal = {J. Approx. Theory},
  title        = {Nevai’s condition for measures with unbounded supports},
  volume       = {314},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jde">JDE - 9</h2>
<ul>
<li><details>
<summary>
(2026). Internal control of the transition kernel for stochastic lattice dynamics. <em>JDE</em>, <em>453</em>, 113798. (<a href='https://doi.org/10.1016/j.jde.2025.113798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In [4] , we initiated the first study of control problems for kinetic equations arising from harmonic chains. Specifically, we developed impulsive and feedback control mechanisms for harmonic chains coupled with a point thermostat, effectively enabling control over the boundary conditions of the corresponding kinetic equations. However, the more intricate and fundamental challenge of internal control - namely, the design of control strategies that influence the collision operators within the kinetic framework - remained open. In the present work, we address the internal control problem for stochastic lattice dynamics, with the objective of controlling the transition kernel of the limiting kinetic equation. A central innovation of our approach is the development of a novel geometric-combinatorial framework, which enables the systematic construction of control pathways within the microscopic dynamics. This methodology opens a new avenue for the internal control of kinetic equations.},
  archive      = {J_JDE},
  author       = {Amirali Hannani and Minh-Nhat Phung and Minh-Binh Tran and Emmanuel Trélat},
  doi          = {10.1016/j.jde.2025.113798},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113798},
  shortjournal = {J. Diff. Equ.},
  title        = {Internal control of the transition kernel for stochastic lattice dynamics},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonlinear bound states with prescribed angular momentum in the mass supercritical regime. <em>JDE</em>, <em>453</em>, 113796. (<a href='https://doi.org/10.1016/j.jde.2025.113796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the existence, orbital stability/instability and regularity of bound state solutions to nonlinear Schrödinger equations with super-quadratic confinement in two and three spatial dimensions for the mass supercritical case. Such solutions, which are given by time-dependent rotations of a non-radially symmetric spatial profile, correspond to critical points of the underlying energy function restricted on the double constraints consisting of the mass and the angular momentum. The study exhibits new pictures for rotating Bose-Einstein condensates within the framework of Gross-Pitaevskii theory. It is proved that there exist two non-radial symmetric solutions, one of which is local minimizer and the other is mountain pass type critical point of the underlying energy function restricted on the constraints. Moreover, we derive conditions that guarantee that local minimizers are regular, the set of those is orbitally stable and mountain pass type solutions are strongly unstable. The results extend and complement the recent ones in [17] , where the consideration is undertaken in the mass subcritical case.},
  archive      = {J_JDE},
  author       = {Tianxiang Gou and Xiaoan Shen},
  doi          = {10.1016/j.jde.2025.113796},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113796},
  shortjournal = {J. Diff. Equ.},
  title        = {Nonlinear bound states with prescribed angular momentum in the mass supercritical regime},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Wave breaking criteria for a generalized fornberg-whitham equation. <em>JDE</em>, <em>453</em>, 113795. (<a href='https://doi.org/10.1016/j.jde.2025.113795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The blowup features for a generalized Fornberg-Whitham equation are investigated on the line. Using the L 2 conservation law and the method to construct Lyapunov functions, sufficient conditions ensuring that wave breaking occurs for the equation are provided. Under certain assumptions, our wave breaking results improve the wave breaking criteria in Wei (2023) [25] .},
  archive      = {J_JDE},
  author       = {Changtai Zhou and Shaoyong Lai},
  doi          = {10.1016/j.jde.2025.113795},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113795},
  shortjournal = {J. Diff. Equ.},
  title        = {Wave breaking criteria for a generalized fornberg-whitham equation},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Boundedness of weak solutions to degenerate kolmogorov equations of hypoelliptic type in bounded domains. <em>JDE</em>, <em>453</em>, 113794. (<a href='https://doi.org/10.1016/j.jde.2025.113794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish the boundedness of weak subsolutions for a class of degenerate Kolmogorov equations of the hypoelliptic type, compatible with a homogeneous Lie group structure, within bounded product domains using the De Giorgi iteration. We employ the renormalization formula to handle boundary values and provide energy estimates. An L 1 – L p type embedding estimate derived from the fundamental solution is utilized to incorporate lower-order divergence terms. This work naturally extends the boundedness theory for uniformly parabolic equations, with matching exponents for the coefficients.},
  archive      = {J_JDE},
  author       = {Mingyi Hou},
  doi          = {10.1016/j.jde.2025.113794},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113794},
  shortjournal = {J. Diff. Equ.},
  title        = {Boundedness of weak solutions to degenerate kolmogorov equations of hypoelliptic type in bounded domains},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Convergence towards discontinuous patterns for a degenerate reaction-diffusion system with a non-monotone term. <em>JDE</em>, <em>453</em>, 113793. (<a href='https://doi.org/10.1016/j.jde.2025.113793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish new results on the dynamics of a degenerate reaction-diffusion system with hysteresis. Our model determines the evolution of a biological system characterized by the interaction between a sedentary species and a diffusive species. It can be notably applied in forest ecology and in microbiology. We prove the existence of an infinite family of discontinuous stationary solutions using a generalized Mountain Pass Theorem, and analyze the continuity of this family, through an original method based on the convergence of generalized Clarke gradients. We show that the discontinuity interface of the heterogeneous patterns is very sensitive with respect to a variation of the initial condition. Furthermore, we prove a new theorem of convergence towards discontinuous patterns, which shows that the basin of attraction of each pattern contains a non-trivial set of initial conditions.},
  archive      = {J_JDE},
  author       = {Guillaume Cantin},
  doi          = {10.1016/j.jde.2025.113793},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113793},
  shortjournal = {J. Diff. Equ.},
  title        = {Convergence towards discontinuous patterns for a degenerate reaction-diffusion system with a non-monotone term},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gauge transformation for the kinetic derivative nonlinear schrödinger equation on the torus. <em>JDE</em>, <em>453</em>, 113792. (<a href='https://doi.org/10.1016/j.jde.2025.113792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the kinetic derivative nonlinear Schrödinger equation, which is a one-dimensional nonlinear Schrödinger equation with a cubic derivative nonlinear term containing the Hilbert transformation. In our previous work, we proved small-data global well-posedness of the Cauchy problem on the torus in Sobolev space H s for s > 1 / 2 by combining the Fourier restriction norm method with the parabolic smoothing effect, which is available in the periodic setting. In this article, we improve the regularity range to s > 1 / 4 for the global well-posedness by constructing an effective gauge transformation. Moreover, we remove the smallness assumption by making use of the dissipative nature of the equation.},
  archive      = {J_JDE},
  author       = {Nobu Kishimoto and Yoshio Tsutsumi},
  doi          = {10.1016/j.jde.2025.113792},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113792},
  shortjournal = {J. Diff. Equ.},
  title        = {Gauge transformation for the kinetic derivative nonlinear schrödinger equation on the torus},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Smoothness of the inertial manifold via the spatial averaging principle. <em>JDE</em>, <em>453</em>, 113790. (<a href='https://doi.org/10.1016/j.jde.2025.113790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the C n , ε | { n ≥ 2 , ε ∈ ( 0 , 1 ) } -smoothness of the inertial manifold for an abstract semilinear parabolic equation. Compared with the known results, the required spectral gap condition has been relaxed by applying the principle of spatial averaging initially proposed by J. Mallet-Paret and G. Sell in 1988.},
  archive      = {J_JDE},
  author       = {Ziqi Niu and Xinhua Li and Chunyou Sun},
  doi          = {10.1016/j.jde.2025.113790},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113790},
  shortjournal = {J. Diff. Equ.},
  title        = {Smoothness of the inertial manifold via the spatial averaging principle},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Smooth koopman eigenfunctions. <em>JDE</em>, <em>453</em>, 113786. (<a href='https://doi.org/10.1016/j.jde.2025.113786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any dynamical system, whether it is generated by a differential equation or a transformation map on a manifold, induces a dynamics on functional-spaces. The choice of functional-space may vary, but the induced dynamics is always linear, and codified by the Koopman operator. The eigenfunctions of the Koopman operator are of extreme importance in the study of the dynamics. They provide a clear distinction between the mixing and non-mixing components of the dynamics, and also reveal embedded toral rotations. The usual choice of functional-space is L 2 , a class of square integrable functions. A fundamental problem with eigenfunctions in L 2 is that they are often extremely discontinuous, particularly if the system is chaotic. There are some prototypical systems called skew-product dynamics in which L 2 Koopman eigenfunctions are also smooth. The article shows that under general assumptions on an ergodic system, these prototypical examples are the only possibility. Moreover, the smooth eigenfunctions can be used to create a change of variables which explicitly characterizes the weakly mixing component too.},
  archive      = {J_JDE},
  author       = {Suddhasattwa Das},
  doi          = {10.1016/j.jde.2025.113786},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113786},
  shortjournal = {J. Diff. Equ.},
  title        = {Smooth koopman eigenfunctions},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonexistence of solutions to parabolic problems with a potential on weighted graphs. <em>JDE</em>, <em>453</em>, 113782. (<a href='https://doi.org/10.1016/j.jde.2025.113782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate nonexistence of nontrivial nonnegative solutions to a class of semilinear parabolic equations with a positive potential, posed on weighted graphs. Assuming an upper bound on the Laplacian of the distance and a suitable weighted space-time volume growth condition, we show that no global solutions exist. We also discuss the optimality of the hypotheses, thus recovering a critical exponent phenomenon of Fujita type.},
  archive      = {J_JDE},
  author       = {Dario D. Monticelli and Fabio Punzo and Jacopo Somaglia},
  doi          = {10.1016/j.jde.2025.113782},
  journal      = {Journal of Differential Equations},
  month        = {2},
  pages        = {113782},
  shortjournal = {J. Diff. Equ.},
  title        = {Nonexistence of solutions to parabolic problems with a potential on weighted graphs},
  volume       = {453},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jmaa">JMAA - 3</h2>
<ul>
<li><details>
<summary>
(2026). Killing mean curvature solitons from riemannian submersions. <em>JMAA</em>, <em>556</em>(1), 130088. (<a href='https://doi.org/10.1016/j.jmaa.2025.130088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new general construction of mean curvature flow solitons on manifolds admitting a nowhere-vanishing Killing vector field. Using Riemannian submersion techniques, we reduce the problem from a PDE to an ODE. As an application, we obtain new examples of rotators in hyperbolic space.},
  archive      = {J_JMAA},
  author       = {Diego Artacho and Marie-Amélie Lawn and Miguel Ortega},
  doi          = {10.1016/j.jmaa.2025.130088},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130088},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Killing mean curvature solitons from riemannian submersions},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Boundedness in an attraction-repulsion chemotaxis system with indirect repulsion-signal production. <em>JMAA</em>, <em>556</em>(1), 130087. (<a href='https://doi.org/10.1016/j.jmaa.2025.130087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the following attraction-repulsion chemotaxis system involving nonlinear indirect signal mechanism { u t = Δ u − ξ ∇ ⋅ ( u ∇ v ) + χ ∇ ⋅ ( u ∇ z ) + f ( u ) , x ∈ Ω , t > 0 , 0 = Δ v − v + u γ 1 , x ∈ Ω , t > 0 , z t = Δ z − z + w γ 2 , x ∈ Ω , t > 0 , 0 = Δ w − w + u γ 3 , x ∈ Ω , t > 0 , under homogeneous Neumann boundary conditions, where Ω ⊂ R n ( n ≥ 1 ) is a smoothly bounded domain and ξ , χ , γ 1 , γ 2 , γ 3 > 0 . • When f ≡ 0 , it is shown that the solution of the above system is global and uniformly bounded if max ⁡ { γ 1 , γ 2 γ 3 } < 2 n . Moreover, if max ⁡ { γ 1 , γ 2 γ 3 } = 2 n , the boundedness of solution can be derived provided that the initial mass ∫ Ω u 0 ( x ) d x is small. • When f ( u ) ≤ u ( a − b u k ) with a , b , k > 0 , it is proved that if one of the following conditions holds: (i) k > max ⁡ { γ 1 , γ 2 γ 3 } , (ii) k = max ⁡ { γ 1 , γ 2 γ 3 } , (iii) max ⁡ { γ 1 , γ 2 γ 3 } < 2 n , then the solution is globally bounded in time provided that b is large enough.}},
  archive      = {J_JMAA},
  author       = {Wei Wang and Pan Zheng},
  doi          = {10.1016/j.jmaa.2025.130087},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130087},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Boundedness in an attraction-repulsion chemotaxis system with indirect repulsion-signal production},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of velocities in pipeline flow of blended gas. <em>JMAA</em>, <em>556</em>(1), 130078. (<a href='https://doi.org/10.1016/j.jmaa.2025.130078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the pipeline flow of blended gas. The flow is governed by a coupled system where for each component we have the isothermal Euler equations with an additional velocity coupling term that couples the velocities of the different components. Our motivation is hydrogen blending in natural gas pipelines, which will play a role in the transition to renewable energies. We show that with suitable boundary conditions the velocities of the gas components synchronize exponentially fast, as long as the L 2 -norm of the synchronization error is outside of a certain interval where the size of the interval is determined by the order of the interaction terms. This indicates that in some cases for a mixture of n components it is justified to use a drift-flux model where it is assumed that all components flow with the same velocity. For the proofs we use an appropriately chosen Lyapunov function which is based upon the idea of relative energy.},
  archive      = {J_JMAA},
  author       = {Martin Gugat},
  doi          = {10.1016/j.jmaa.2025.130078},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {4},
  number       = {1},
  pages        = {130078},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Synchronization of velocities in pipeline flow of blended gas},
  volume       = {556},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jocs">JOCS - 18</h2>
<ul>
<li><details>
<summary>
(2025). Heuristic custom similarity index (HCSI): A novel machine learning approach for link prediction. <em>JOCS</em>, <em>92</em>, 102719. (<a href='https://doi.org/10.1016/j.jocs.2025.102719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is a fundamental task in network analysis, aiming at predicting missing or future connections between nodes in a network. With the growing availability of complex network data in fields like social networks, biological systems, the Internet, and scientific collaboration networks, accurate link prediction methods are becoming increasingly critical. Neighborhood or graph based link prediction algorithms are applied identically to different types of networks so that any differences in their structures are not exploited efficiently. Machine or deep learning based link prediction algorithms apply to each kind of network differently depending on the type of network, due to the unique characteristics of each domain, but frequently, most of them give poor results. In this paper, we propose a novel approach for link prediction, leveraging the power of machine learning and evolutionary algorithms. Our method utilizes local network information by encoding the network topology into link embeddings through a heuristic machine learning architecture. We introduce a novel tool to extract features from network structure effectively and combine them in an effective way through an evolutionary algorithm improving the discriminative power of link embeddings. We evaluate our method on eleven benchmark datasets and demonstrate its superior performance compared to a series (eleven in total) of effective and state-of-the-art algorithms. Our approach advances the state-of-the-art in link prediction yielding better results than other methods in all the networks we have applied it to.},
  archive      = {J_JOCS},
  author       = {Paraskevas Dimitriou and Vasileios Karyotis},
  doi          = {10.1016/j.jocs.2025.102719},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102719},
  shortjournal = {J. Comput. Sci.},
  title        = {Heuristic custom similarity index (HCSI): A novel machine learning approach for link prediction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approach to global path planning and optimization for mobile robots based on multi-local gravitational potential fields bias-P-RRT*. <em>JOCS</em>, <em>92</em>, 102718. (<a href='https://doi.org/10.1016/j.jocs.2025.102718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sampling-based method has strong environmental adaptability and probability completeness, providing an effective solution for mobile robot path planning. However, the conventional rapidly-exploring random trees (RRT) algorithm often presents slow convergence and inefficient search paths. In this sense, this paper proposes a mobile robot path planning and optimization algorithm based on P-RRT* that incorporates multi-local gravitational potential fields and bias sampling, i.e., multi-local gravitational potential fields Bias-P-RRT* (MLGPFB-P-RRT*). The algorithm adds a local gravitational field between the starting point and the target point to better guide the direction of random tree growth, and directly connects the center of the last local gravitational field to the target point to accelerate the convergence of the random tree at the target point. Meanwhile, the introduction of bias sampling based on local potential fields to optimize the generation quality of random points, thereby improving the generation position of new nodes and reducing the randomness of sampling for mobile robots in the workspace. Then, a collision detection method between sampling nodes and obstacles was developed, which can quickly determine the feasibility of the sampling path. Finally, the generated path is optimized and smoothed through pruning optimization and quadratic B-spline function. A series of simulation studies and mobile robot experiments demonstrate the superior performance of the proposed algorithm.},
  archive      = {J_JOCS},
  author       = {Leiwen Yuan and Jingwen Luo},
  doi          = {10.1016/j.jocs.2025.102718},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102718},
  shortjournal = {J. Comput. Sci.},
  title        = {Approach to global path planning and optimization for mobile robots based on multi-local gravitational potential fields bias-P-RRT*},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic deep-ritz for parametric uncertainty quantification. <em>JOCS</em>, <em>92</em>, 102717. (<a href='https://doi.org/10.1016/j.jocs.2025.102717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific machine learning has become an increasingly important tool in materials science and engineering. It is particularly well suited to tackle material problems involving many variables or to allow rapid construction of surrogates of material models, to name just a few. Mathematically, many problems in materials science and engineering can be cast as variational problems. However, handling of uncertainty, ever present in materials, in the context of variational formulations remains challenging for scientific machine learning. In this article, we propose a deep-learning-based numerical method for solving variational problems under uncertainty. Our approach seamlessly combines deep-learning approximation with Monte Carlo sampling. The resulting numerical method is powerful yet remarkably simple. We assess its performance and accuracy on a number of variational problems.},
  archive      = {J_JOCS},
  author       = {Ting Wang and Jaroslaw Knap},
  doi          = {10.1016/j.jocs.2025.102717},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102717},
  shortjournal = {J. Comput. Sci.},
  title        = {Stochastic deep-ritz for parametric uncertainty quantification},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid nutcracker optimization algorithm for multi-objective energy scheduling in grid-connected microgrid systems. <em>JOCS</em>, <em>92</em>, 102716. (<a href='https://doi.org/10.1016/j.jocs.2025.102716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for clean and sustainable energy has driven rapid advancements in hybrid microgrid systems to mitigate climate change and environmental degradation. This paper proposes a novel multi-objective scheduling framework for hybrid microgrids aimed at minimizing operational costs while maximizing environmental benefits. To efficiently solve this complex optimization problem, we introduce a Hybrid Nutcracker Optimization Algorithm (HNOA), which combines the recently developed Nutcracker Optimization Algorithm (NOA) with the Bat Algorithm (BAT). This hybridization enhances NOA’s exploration–exploitation balance and search capability, as demonstrated by rigorous validation on 12 benchmark functions. HNOA achieves superior accuracy and computational efficiency compared to several state-of-the-art metaheuristics. The proposed HNOA is then applied to solve the scheduling of a grid-connected hybrid microgrid under various scenarios to evaluate its performance. Simulation results indicate that the optimal microgrid configuration, consisting of PV/WT/turbine/diesel/battery, achieves an investment cost of 80,789.02 yuan. The findings of this study offer valuable insights for advancing renewable energy integration and promoting environmental sustainability.},
  archive      = {J_JOCS},
  author       = {Yiwei Liu and Yinggan Tang and Changchun Hua},
  doi          = {10.1016/j.jocs.2025.102716},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102716},
  shortjournal = {J. Comput. Sci.},
  title        = {Hybrid nutcracker optimization algorithm for multi-objective energy scheduling in grid-connected microgrid systems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Darcy-scale digital core models for rock properties upscaling and computational domain reduction. <em>JOCS</em>, <em>92</em>, 102715. (<a href='https://doi.org/10.1016/j.jocs.2025.102715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Digital Rock Physics (DRP) requires the elaboration of robust techniques for closing the gaps between different scales of rock studies (upscaling). The upscaling workflows are especially needed to support the applicability of DRP for heterogeneous rocks. Basically, DRP involves two primary stages: model construction and simulation of physical processes on the models created. For heterogeneous rocks, there is an inherent trade-off between the spatial resolution of the data and the representativeness of the model size. The primary objective of this study was to implement and test a technique for upscaling digital core models from microscale to macroscale, enabling the computation of rock properties while accounting for heterogeneity of various scales. The upscaling is based on establishing correlations between tomography data of different resolutions and transforming low-resolution tomography into a multi-class model according to the defined correlation. The convolutional neural network for high-resolution tomography data was considered as the optimal algorithm for transforming low-resolution tomography into a multi-class model. The output of the neural network was an upscaled model of lower resolution than the original tomography image. Each cell in the upscaled model belonged to one of several types of formation, whose generalized characteristics were determined on the basis of the analysis of high-resolution tomography data. To validate the upscaling technique, we constructed a digital model of a complex carbonate reservoir based on data from multi-scale microtomography ( μ CT). A Darcy-scale model has been used and validated as a multi-class model, enabling the computation of flows in pore samples of various scales. By incorporating diverse pore space structures as different classes in the Darcy-scale model, it is possible to preserve the substantial physical size of the model while enhancing its level of complexity.},
  archive      = {J_JOCS},
  author       = {Denis Orlov and Batyrkhan Gainitdinov and Dmitry Koroteev},
  doi          = {10.1016/j.jocs.2025.102715},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102715},
  shortjournal = {J. Comput. Sci.},
  title        = {Darcy-scale digital core models for rock properties upscaling and computational domain reduction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical study of two-dimensional sediment transport using momentum-conserving staggered grid scheme. <em>JOCS</em>, <em>92</em>, 102714. (<a href='https://doi.org/10.1016/j.jocs.2025.102714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sediment transport plays a crucial role in the evolution of bed morphology through deposition and erosion. This study presents numerical simulations of two-dimensional sediment transport induced by fluid flow. The fluid-sediment interaction is governed by a capacity model, i.e., the coupled system of shallow water and Exner equations, a simplification of more physically advanced non-capacity models. The system is solved using a momentum-conserving staggered grid (MCS) scheme. Model validation is performed using the Meyer-Peter and Müller (MPM) bedload transport formula, applied to experimental data from dam-break flows in various channel configurations. The proposed method successfully reproduces trends in the evolution of the water surface and quasi-steady sediment profiles. In general, the MCS scheme provides more accurate water level predictions than the numerical benchmark schemes. Although the predictions of maximum depths of deposition and erosion are less accurate, the overall results are consistent with those obtained from non-capacity models. Furthermore, the model is applied to the Kampar River estuary to simulate sediment transport due to the tidal bore.},
  archive      = {J_JOCS},
  author       = {Riski Kurniawan and Sri Redjeki Pudjaprasetya and Rani Sulvianuri},
  doi          = {10.1016/j.jocs.2025.102714},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102714},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical study of two-dimensional sediment transport using momentum-conserving staggered grid scheme},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cellular automaton towards structural balance—Long cycles of link dynamics. <em>JOCS</em>, <em>92</em>, 102712. (<a href='https://doi.org/10.1016/j.jocs.2025.102712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cellular automaton is defined on a line graph of a fully connected network. The automaton rule drives the system to a structural balance in most cases. Here, we investigate cycles with special symmetries, the so-called ’perfect cycles’ Burda et al. (2022). Two new characteristics of the cycles are investigated, as potential markers of perfect cycles: an equivalence of sets of states attained after external damage of links, and the homogeneity of the distribution of phase shifts between local trajectories. Only the second characteristic works as a criterion of the perfectness of the cycles. The results can be useful for generating pseudorandom numbers.},
  archive      = {J_JOCS},
  author       = {Malgorzata J. Krawczyk and Krzysztof Kułakowski},
  doi          = {10.1016/j.jocs.2025.102712},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102712},
  shortjournal = {J. Comput. Sci.},
  title        = {A cellular automaton towards structural balance—Long cycles of link dynamics},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hamiltonian circuit of virtual sample generation for a small dataset. <em>JOCS</em>, <em>92</em>, 102711. (<a href='https://doi.org/10.1016/j.jocs.2025.102711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small datasets often lead to poor performance of data-driven prediction models due to uneven data distribution and large data spacing. One popular approach to address this issue is to use virtual samples during machine learning (ML) model training. This study proposes a Hamiltonian Circuit Virtual Sample Generation (HCVSG) method to distribute virtual samples generated using interpolation techniques while integrating the K-Nearest Neighbors (KNN) algorithm in model development. The Hamiltonian circuit is chosen because it doesn’t depend on the distribution assumption and provides multiple circuits that allow adaptive sample distribution, allowing the selection of circuits that produce minimum errors. This method supports improving feature-target correlation, reducing the risk of overfitting, and stabilizing error values as model complexity increases. Applying this method to three datasets in material research (MLCC, PSH, and EFD) shows that HCVSG significantly improves prediction accuracy compared to conventional KNN and eight MTD-based methods. The distribution of virtual samples along the Hamiltonian circuit helps fill the information gap and makes the data distribution more even, ultimately improving the predictive model's performance.},
  archive      = {J_JOCS},
  author       = {Totok Sutojo and Supriadi Rustad and Muhamad Akrom and Wahyu Aji Eko Prabowo and De Rosal Ignatius Moses Setiadi and Hermawan Kresno Dipojono and Yoshitada Morikawa},
  doi          = {10.1016/j.jocs.2025.102711},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102711},
  shortjournal = {J. Comput. Sci.},
  title        = {An adaptive hamiltonian circuit of virtual sample generation for a small dataset},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tuning sensitivity of black phosphorene surface doped SnS, SnSe, GeS, and GeSe quantum dots toward water molecule and other small toxic molecules. <em>JOCS</em>, <em>92</em>, 102707. (<a href='https://doi.org/10.1016/j.jocs.2025.102707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, Density Functional Theory (DFT) was employed to investigate the impact of SnS, GeS, SnSe, and GeSe quantum dots doped black phosphorene on the sensitivity of black phosphorene toward various adsorbed gas molecules namely NO 2 and H 2 S. The interaction of H 2 O molecule with doped black phosphorene surface is also investigated to evaluate the impact of humidity on the sensing response. The results revealed the large electronic changes in bands distribution upon exposure to the selected gas molecules, giving rise to a variation in the electronic band nature from hole to electron doping which can promote the electrical conductivity and the sensing properties of the doped phosphorene structures.},
  archive      = {J_JOCS},
  author       = {Mamori Habiba and Moatassim Hajar and El Kenz Abdallah and Benyoussef Abdelilah and Taleb Abdelhafed and Abdel Ghafour El Hachimi and Zaari Halima},
  doi          = {10.1016/j.jocs.2025.102707},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102707},
  shortjournal = {J. Comput. Sci.},
  title        = {Tuning sensitivity of black phosphorene surface doped SnS, SnSe, GeS, and GeSe quantum dots toward water molecule and other small toxic molecules},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CKDTA: A chemical knowledge-enhanced framework for drug–target affinity prediction. <em>JOCS</em>, <em>92</em>, 102706. (<a href='https://doi.org/10.1016/j.jocs.2025.102706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate drug–target affinity (DTA) prediction is a cornerstone of efficient drug discovery, as it directly accelerates the screening of potential therapeutic candidates, reduces the cost of preclinical experiments, and shortens the development cycle of new drugs. However, existing deep learning-based methods face two main challenges: (I) Purely data-driven approaches struggle to capture the functional semantics of molecules, such as the role of specific functional regions and chemical element properties in binding interactions, due to the lack of integration with chemical prior knowledge, leading to unreliable predictions; (II) the integration of topological structure from graphs and long-range dependencies from sequences is insufficient, often failing to capture complementary features, limiting the model’s generalization ability, especially for novel drugs or targets commonly encountered in early drug discovery . To address these issues, we propose CKDTA , a C hemical K nowledge Enhanced framework for D rug- T arget A ffinity prediction. Our framework introduces two key innovations: (1) a chemical knowledge-enhanced molecular modeling approach, which constructs a multi-layer molecular graph incorporating atom-level features, chemical element information, and functional regions, enabling the capture of functional semantics through a hierarchical attention mechanism, while leveraging chemical prior knowledge; (2) a co-attention module designed to optimize sequence interaction information by leveraging graph-based interaction data, compensating for the lack of spatial structural information in sequence data. This module fully exploits the topological structure of graphs and the long-range dependencies in sequences, capturing complementary features. Extensive experiments on benchmark datasets demonstrate that CKDTA outperforms state-of-the-art methods. Furthermore, cold-start experiments validate its generalizability, highlighting its potential for drug discovery applications.},
  archive      = {J_JOCS},
  author       = {Xingran Zhao and Yanbu Guo and Bingyi Wang and Weihua Li},
  doi          = {10.1016/j.jocs.2025.102706},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102706},
  shortjournal = {J. Comput. Sci.},
  title        = {CKDTA: A chemical knowledge-enhanced framework for drug–target affinity prediction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient numerical simulation of variable-order fractional diffusion processes with a memory kernel. <em>JOCS</em>, <em>92</em>, 102705. (<a href='https://doi.org/10.1016/j.jocs.2025.102705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion equations are fundamental in modeling the transport of heat, mass, or contaminants in porous media. However, classical models often fail to capture the anomalous diffusion behavior inherent in heterogeneous and memory-dependent materials. To address this, we investigate a fractional diffusion integro-differential equation involving variable-order derivatives in both time and space, subject to suitable conditions. The solutions are shown to exist and be unique through the rigorous application of fixed-point theorems. A finite difference-based numerical scheme is formulated to handle the variable-order fractional operators and convolution-type integral terms efficiently. Stability analysis confirms the accuracy and robustness of the method. In addition, approximate solutions are computed for three representative cases:(i) constant-order fractional diffusion ( α = constant ), (ii) time-dependent order α ( t ) , and (iii) fully variable-order α ( x , t ) . By incorporating variable order dynamics and integro-differential structures, this work extends conventional models and provides a unified framework for simulating complex transport processes in porous media.},
  archive      = {J_JOCS},
  author       = {Sabita Bera and Mausumi Sen and Sujit Nath},
  doi          = {10.1016/j.jocs.2025.102705},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102705},
  shortjournal = {J. Comput. Sci.},
  title        = {Efficient numerical simulation of variable-order fractional diffusion processes with a memory kernel},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical solution of the biological SIR model for COVID-19 with convergence analysis. <em>JOCS</em>, <em>92</em>, 102704. (<a href='https://doi.org/10.1016/j.jocs.2025.102704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the numerical solution of the biological Susceptible–Infectious–Recovered model for COVID-19 over extended time intervals using the shifted Chebyshev polynomial collocation method. Initially, the original problem is reformulated into a nonlinear Volterra integral equation for the susceptible population. The shifted Chebyshev polynomials are then employed to derive the numerical solution. A comprehensive convergence analysis of the collocation method is conducted to ensure the reliability and accuracy of the proposed approach. Finally, numerical simulations are performed for various parameter configurations that influence the system’s coefficients. Our method is compared with existing approaches, providing insights into the model’s dynamics under different conditions.},
  archive      = {J_JOCS},
  author       = {Walid Remili and Wen-Xiu Ma},
  doi          = {10.1016/j.jocs.2025.102704},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102704},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical solution of the biological SIR model for COVID-19 with convergence analysis},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decomposition based imputation algorithm for long consecutive missing atmospheric pollution data and its application. <em>JOCS</em>, <em>92</em>, 102697. (<a href='https://doi.org/10.1016/j.jocs.2025.102697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the intensification of environmental air pollution, the impact of air pollutants on both the ecological environment and human health has attracted widespread attention. However, due to the relatively late introduction of environmental monitoring systems, there were long consecutive missing values in early pollutant data. In this paper, we propose a decomposition-based imputation method for long consecutive missing pollution data. Firstly, wavelet coherence analysis is employed to investigate the periodic relationship between the pollution data and the relevant air data, decomposing them into periodic and non-periodic components. Then, machine learning and transfer learning are used to impute the periodic and non-periodic components, respectively. Furthermore, the effectiveness of the method is validated on artificially missing NO 2 and SO 2 concentration data from five regions of China. Comparison results show that the proposed method significantly outperforms some other imputation methods in the literature in terms of both mean absolute error and mean absolute percentage error. Finally, the proposed imputation method is applied in the study of accelerated aging of polycarbonate materials. Experimental results show that the predictive accuracy of the aging model is improved when using the imputed pollutant data.},
  archive      = {J_JOCS},
  author       = {Xinyi Wei and Hao Meng and Lizhen Shao and Dongmei Fu and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.jocs.2025.102697},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102697},
  shortjournal = {J. Comput. Sci.},
  title        = {A decomposition based imputation algorithm for long consecutive missing atmospheric pollution data and its application},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Helium focused ion beam damage in silicon: Physics-informed neural network modeling of helium bubble nucleation and early growth. <em>JOCS</em>, <em>92</em>, 102696. (<a href='https://doi.org/10.1016/j.jocs.2025.102696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the time and cost required to obtain large datasets limit the application of data-driven machine learning in nanoscale manufacturing. Here, we focus on predicting the nanoscale damage induced by helium focused ion beams (He-FIBs) on silicon substrates. We briefly review the most relevant atomistic defects and the partial differential equations (PDEs), or rate equations, that describe the mutual creation and annihilation of the defects, eventually leading to the amorphization of the substrate and, the nucleation and early growth of helium bubbles. The novelty comes from the use of a physics-informed neural network (PINN) to simulate quantitatively the evolution of the bubbles, thus bypassing the dataset availability problem. As usual, the proposed PINN learns the underlying physics through the incorporation of the residuals of the PDEs and corresponding Initial Conditions (ICs) and Boundary Conditions (BCs) in the network’s loss function. Meanwhile, the system of PDEs poses some challenges to the PINN modeling strategy. We find that (i) hard constraints need to be imposed on the network output in order to satisfy both BCs and ICs, (ii) all the inputs and outputs of the PINN need to be cautiously normalized to ensure convergence during training, and (iii) customized weights need to be carefully applied to all the PDE loss terms in order to balance their contributions, thus improving the accuracy of the PINN predictions. Once trained, the network achieves good prediction accuracy over the entire space-time domain for various ion beam energies and doses. Comparisons are provided against previous experiments and traditional numerical simulations, which are also implemented in this study using the Finite Difference Method (FDM). While the L2 relative errors for all collocated points remain below 10%, the accuracy of the PINN decreases at lower beam energies and larger ion doses, due to the presence of higher numerical gradients.},
  archive      = {J_JOCS},
  author       = {Shupeng Gao and Qi Li and M.A. Gosalvez and Xi Lin and Yan Xing and Zaifa Zhou and Qianhuang Chen},
  doi          = {10.1016/j.jocs.2025.102696},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102696},
  shortjournal = {J. Comput. Sci.},
  title        = {Helium focused ion beam damage in silicon: Physics-informed neural network modeling of helium bubble nucleation and early growth},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the dopant diffusion dynamics with physics-informed neural networks. <em>JOCS</em>, <em>92</em>, 102695. (<a href='https://doi.org/10.1016/j.jocs.2025.102695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation plays a crucial role in the semiconductor chip manufacturing. In particular, process simulation is primarily used to solve the dopant diffusion dynamics, which describes the temporal evolution of doping profiles during the thermal annealing process. The diffusion dynamics constitutes a multiscale problem, formulated as a set of coupled partial differential equations (PDEs) with respect to the concentration of dopants and point defects. In this paper, we demonstrate that Physics-Informed Neural Networks (PINNs) can accurately predict not only the evolution of the doping profile, but also the unknown physical parameters, specifically the diffusivities appearing as PDE coefficients. Furthermore, we propose a physics-informed calibration method, which performs PDE-constrained optimization by leveraging a pre-trained PINN model. We experimentally verify that this post-processing significantly improves the accuracy of coefficients fine-tuning. To the best of our knowledge, this is the first demonstration of an annealing simulation for the semiconductor diffusion process using a physics-informed machine learning approach. This framework is expected to enable more efficient calibration of simulation parameters based on measurement data.},
  archive      = {J_JOCS},
  author       = {Sungyeop Lee and Jisu Ryu and Young-Gu Kim and Dae Sin Kim and Hiroo Koshimoto and Jaeshin Park},
  doi          = {10.1016/j.jocs.2025.102695},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102695},
  shortjournal = {J. Comput. Sci.},
  title        = {Solving the dopant diffusion dynamics with physics-informed neural networks},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on pest control models based on nonlinear threshold control. <em>JOCS</em>, <em>92</em>, 102694. (<a href='https://doi.org/10.1016/j.jocs.2025.102694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pest number trigger threshold strategy has been widely used in the control of pests in agricultural production. In this study, pest populations are managed by using an integrated nonlinear threshold function and a saturation function. The existence conditions of various equilibrium points and sliding sections in the system are derived. Theoretical analysis and numerical simulation results show the existence of boundary equilibrium bifurcations, tangency bifurcations and limit cycle bifurcations caused by discontinuous boundary. It is worth noting that persistence and non-smooth folding can be observed in the boundary equilibrium bifurcations. At the same time, because the nonlinear threshold control strategy is adopted in this study, the change of the sliding section of the model is more complicated. The numerical simulation results show that if there is an unstable focus in the model, a sliding homoclinic cycle will appear with the occurrence of boundary saddle point bifurcation, and then form a crossing limit cycle. The sensitivity analysis results of the system show that if the threshold level is too low, the control measures do not achieve the desired results. Too high threshold selection will cause unnecessary economic losses. Therefore, our results show that an appropriate threshold should be set to reduce economic losses while ensuring that the number of pests is in a lower stable state.},
  archive      = {J_JOCS},
  author       = {Yongfeng Li and Leyan Liang and Zhong Zhao},
  doi          = {10.1016/j.jocs.2025.102694},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102694},
  shortjournal = {J. Comput. Sci.},
  title        = {A study on pest control models based on nonlinear threshold control},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private linear equation solving: An application to federated learning and extreme learning machines. <em>JOCS</em>, <em>92</em>, 102693. (<a href='https://doi.org/10.1016/j.jocs.2025.102693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, multiple devices compute each a part of a common machine learning model using their own private data. These partial models (or their parameters) are then exchanged in a central server that builds an aggregated model. This sharing process may leak information about the data used to train them. This problem intensifies as the machine learning model becomes simpler, indicating a higher risk for single-hidden-layer feedforward neural networks, such as extreme learning machines. In this paper, we establish a mechanism to disguise the input data to a system of linear equations while guaranteeing that the modifications do not alter the solutions, and propose two possible approaches to apply these techniques to federated learning. Our findings show that extreme learning machines can be used in federated learning with an extra security layer, making them attractive in learning schemes with limited computational resources.},
  archive      = {J_JOCS},
  author       = {Daniel Heinlein and Anton Akusok and Kaj-Mikael Björk and Leonardo Espinosa-Leal},
  doi          = {10.1016/j.jocs.2025.102693},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102693},
  shortjournal = {J. Comput. Sci.},
  title        = {Private linear equation solving: An application to federated learning and extreme learning machines},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BAHA: Binary artificial hummingbird algorithm for feature selection. <em>JOCS</em>, <em>92</em>, 102686. (<a href='https://doi.org/10.1016/j.jocs.2025.102686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Datasets classification accuracy depends on their features. The presence of irrelevant and redundant features in the dataset leads to the reduction of classification accuracy. Identifying and removing such features is the main purpose in feature selection, which is an important step in the data science lifecycle. The objective of the Wrapper feature selection method is to reduce the number of selected feature (NSF) while improving the classification accuracy by working on a set of features. The feature selection is a challenging and computationally expensive problem that falls under the NP-complete category, so it requires computationally cheap and efficient algorithm to solve it. The artificial hummingbird algorithm (AHA) is a biological inspired optimization technique that mimics the unique flight capabilities and intelligent foraging tactics of hummingbirds in nature. Since feature selection is inherently a binary problem. In this paper, the binary form of the AHA meta-heuristic algorithm is proposed to show that binarizing the AHA meta-heuristic algorithm improves its performance for solving feature selection problems. The proposed method is tested on a standard benchmark dataset and compared with four state-of-the-art feature selection algorithms: Automata-based improved equilibrium optimizer with U-shaped transfer function (AIEOU), Whale optimization approaches for wrapper feature selection (WOA-CM), Ring theory-based harmony search (RTHS), and Adaptive switching gray-whale optimizer (ASGW). The results show the effectiveness of the proposed algorithm in searching for optimal features subset. The source code for the algorithm being proposed is accessible to the public on https://github.com/alihamdipour/baha .},
  archive      = {J_JOCS},
  author       = {Ali Hamdipour and Abdolali Basiri and Mostafa Zaare and Seyedali Mirjalili},
  doi          = {10.1016/j.jocs.2025.102686},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102686},
  shortjournal = {J. Comput. Sci.},
  title        = {BAHA: Binary artificial hummingbird algorithm for feature selection},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joe">JOE - 6</h2>
<ul>
<li><details>
<summary>
(2025). Nonparametric regression under cluster sampling. <em>JOE</em>, <em>252</em>, 106102. (<a href='https://doi.org/10.1016/j.jeconom.2025.106102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a general asymptotic theory for nonparametric kernel regression in the presence of cluster dependence. We examine nonparametric density estimation, Nadaraya–Watson kernel regression, and local linear estimation. Our theory accommodates growing and heterogeneous cluster sizes. We derive asymptotic conditional bias and variance, establish uniform consistency, and prove asymptotic normality. Our findings reveal that under heterogeneous cluster sizes, the asymptotic variance includes a new term reflecting within-cluster dependence, which is overlooked when cluster sizes are presumed to be bounded. We propose valid approaches for bandwidth selection and inference, introduce estimators of the asymptotic variance, and demonstrate their consistency. In simulations, we verify the effectiveness of the cluster-robust bandwidth selection and show that the derived cluster-robust confidence interval improves the coverage ratio. We illustrate the application of these methods using a policy-targeting dataset in development economics.},
  archive      = {J_JOE},
  author       = {Yuya Shimizu},
  doi          = {10.1016/j.jeconom.2025.106102},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106102},
  shortjournal = {J. Econ.},
  title        = {Nonparametric regression under cluster sampling},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inference on model parameters with many L-moments. <em>JOE</em>, <em>252</em>, 106101. (<a href='https://doi.org/10.1016/j.jeconom.2025.106101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies parameter estimation using L-moments, an alternative to traditional moments with attractive statistical properties. The estimation of model parameters by matching sample L-moments is known to outperform maximum likelihood estimation (MLE) in small samples from popular distributions. The choice of the number of L-moments used in estimation remains ad-hoc , though: researchers typically set the number of L-moments equal to the number of parameters, which is inefficient in larger samples. In this paper, we show that, by properly choosing the number of L-moments and weighting these accordingly, one is able to construct an estimator that outperforms MLE in finite samples, and yet retains asymptotic efficiency. We do so by introducing a generalised method of L-moments estimator and deriving its properties in an asymptotic framework where the number of L-moments varies with sample size. We then propose methods to automatically select the number of L-moments in a sample. Monte Carlo evidence shows our approach can provide mean-squared-error improvements over MLE in smaller samples, whilst working as well as it in larger samples. We consider extensions of our approach to the estimation of conditional models and a class semiparametric models. We apply the latter to study expenditure patterns in a ridesharing platform in Brazil.},
  archive      = {J_JOE},
  author       = {Luis A.F. Alvarez and Chang Chiann and Pedro A. Morettin},
  doi          = {10.1016/j.jeconom.2025.106101},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106101},
  shortjournal = {J. Econ.},
  title        = {Inference on model parameters with many L-moments},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural periodic vector autoregressions. <em>JOE</em>, <em>252</em>, 106099. (<a href='https://doi.org/10.1016/j.jeconom.2025.106099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While seasonality inherent to raw macroeconomic data is commonly removed by seasonal adjustment techniques before it is used for structural inference, this may distort valuable information in the data. As an alternative method to commonly used structural vector autoregressions (SVARs) for seasonally adjusted data, we propose to model potential periodicity in seasonally unadjusted (raw) data directly by structural periodic vector autoregressions (SPVARs). This approach does not only allow for periodically time-varying intercepts, but also for periodic autoregressive parameters and innovations variances. As this larger flexibility leads to an increased number of parameters, we propose linearly constrained estimation techniques. Moreover, based on SPVARs, we provide two novel identification schemes and propose a general framework for impulse response analyses that allows for direct consideration of seasonal patterns. We provide asymptotic theory for SPVAR estimators and impulse responses under flexible linear restrictions and introduce a test for seasonality in impulse responses. For the construction of confidence intervals, we discuss several residual-based (seasonal) bootstrap methods and prove their bootstrap consistency under different assumptions. A real data application shows that useful information about the periodic structure in the data may be lost when relying on common seasonal adjustment methods.},
  archive      = {J_JOE},
  author       = {Daniel Dzikowski and Carsten Jentsch},
  doi          = {10.1016/j.jeconom.2025.106099},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106099},
  shortjournal = {J. Econ.},
  title        = {Structural periodic vector autoregressions},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Misspecification-robust bootstrap t-test for irrelevant factor in linear stochastic discount factor models. <em>JOE</em>, <em>252</em>, 106097. (<a href='https://doi.org/10.1016/j.jeconom.2025.106097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the applicability of the bootstrap approach to test for irrelevant risk factors that are potentially useless in misspecified linear stochastic discount factor (SDF) models. In the literature, the misspecification-robust inference with useless factors is known to give rise to nonstandard limiting distributions bounded stochastically to compute critical values. We show how and to what extent the wild bootstrap yields a more accurate approximation of the distribution of t -statistics when testing for an unpriced factor in the context of linear SDF models. Simulation experiments and empirical tests are also used to document the relevance of the bootstrap method.},
  archive      = {J_JOE},
  author       = {Antoine A. Djogbenou and Ulrich Hounyo},
  doi          = {10.1016/j.jeconom.2025.106097},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106097},
  shortjournal = {J. Econ.},
  title        = {Misspecification-robust bootstrap t-test for irrelevant factor in linear stochastic discount factor models},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On-line detection of changes in the shape of intraday volatility curves. <em>JOE</em>, <em>252</em>, 106089. (<a href='https://doi.org/10.1016/j.jeconom.2025.106089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise an on-line detector for temporal instability in the shape of average intraday volatility curves under a general semimartingale setup for the price-volatility dynamics. We adopt a block-based strategy to estimate volatility nonparametrically from the intraday observations over local time windows with asymptotically shrinking size. Our detector then tracks sequential changes in running means of the intraday volatility curve estimates. Asymptotic size and power properties of the detector follow from a weak form invariance principle, which is established under the strong mixing condition aligned with our semimartingale setup. Simulation and empirical results demonstrate good finite-sample performance of the proposed detection method.},
  archive      = {J_JOE},
  author       = {Torben G. Andersen and Yingwen Tan and Viktor Todorov and Zhiyuan Zhang},
  doi          = {10.1016/j.jeconom.2025.106089},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106089},
  shortjournal = {J. Econ.},
  title        = {On-line detection of changes in the shape of intraday volatility curves},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High dimensional factor analysis with weak factors. <em>JOE</em>, <em>252</em>, 106086. (<a href='https://doi.org/10.1016/j.jeconom.2025.106086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the principal components (PC) estimator for high dimensional approximate factor models with weak factors in that the factor loading ( Λ 0 ) scales sublinearly in the number N of cross-section units, i.e., Λ 0 ⊤ Λ 0 / N α is positive definite in the limit for some α ∈ ( 0 , 1 ) . While the consistency and asymptotic normality of these estimates are by now well known when the factors are strong, i.e., α = 1 , the statistical properties for weak factors remain less explored. Here, we show that the PC estimator maintains consistency and asymptotic normality for any α ∈ ( 0 , 1 ) , provided suitable conditions regarding the dependence structure in the noise are met. This complements earlier result by Onatski (2012) that the PC estimator is inconsistent when α = 0 , and the more recent work by Bai and Ng (2023) who established the asymptotic normality of the PC estimator when α ∈ ( 1 / 2 , 1 ) . Our proof strategy integrates the traditional eigendecomposition-based approach for factor models with leave-one-out analysis similar in spirit to those used in matrix completion and other settings. This combination allows us to deal with factors weaker than the former and at the same time relax the incoherence and independence assumptions often associated with the later.},
  archive      = {J_JOE},
  author       = {Jungjun Choi and Ming Yuan},
  doi          = {10.1016/j.jeconom.2025.106086},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106086},
  shortjournal = {J. Econ.},
  title        = {High dimensional factor analysis with weak factors},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joma">JOMA - 8</h2>
<ul>
<li><details>
<summary>
(2026). A novel martingale difference correlation via data splitting with applications in feature screening. <em>JOMA</em>, <em>211</em>, 105508. (<a href='https://doi.org/10.1016/j.jmva.2025.105508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel sample martingale difference correlation via data splitting to measure the departure of conditional mean independence between a response variable Y and a vector predictor X . The proposed correlation converges to zero and has an asymptotically symmetric sampling distribution around zero when Y and X are conditionally mean independent. In contrast, it converges to a positive value when Y and X are conditionally mean dependent. Leveraging these properties, we develop a new model-free feature screening method with false discovery rate (FDR) control for ultrahigh-dimensional data. We demonstrate that this screening method achieves FDR control and the sure screening property simultaneously. We also extend our approach to conditional quantile screening with FDR control. To further enhance the stability of the screening results, we implement multiple splitting techniques. We evaluate the finite sample performance of our proposed methods through simulations and real data analyses, and compare them with existing methods.},
  archive      = {J_JOMA},
  author       = {Zhengyu Zhu and Jicai Liu and Riquan Zhang},
  doi          = {10.1016/j.jmva.2025.105508},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105508},
  shortjournal = {J. Multi. Anal.},
  title        = {A novel martingale difference correlation via data splitting with applications in feature screening},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tree pólya splitting distributions for multivariate count data. <em>JOMA</em>, <em>211</em>, 105507. (<a href='https://doi.org/10.1016/j.jmva.2025.105507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop a new class of multivariate distributions adapted for count data, called Tree Pólya Splitting. This class results from the combination of a univariate distribution and singular multivariate distributions along a fixed partition tree. Known distributions, including the Dirichlet-multinomial, the generalized Dirichlet-multinomial and the Dirichlet-tree multinomial, are particular cases within this class. As we will demonstrate, these distributions offer some flexibility, allowing for the modeling of complex dependence structures (positive, negative, or null) at the observation level. Specifically, we present theoretical properties of Tree Pólya Splitting distributions by focusing primarily on marginal distributions, factorial moments, and dependence structures (covariance and correlations). A dataset of abundance of Trichoptera is used, on one hand, as a benchmark to illustrate the theoretical properties developed in this article, and on the other hand, to demonstrate the interest of these types of models, notably by comparing them to other approaches for fitting multivariate data, such as the Poisson-lognormal model in ecology or singular multivariate distributions used in microbial analysis.},
  archive      = {J_JOMA},
  author       = {Samuel Valiquette and Jean Peyhardi and Éric Marchand and Gwladys Toulemonde and Frédéric Mortier},
  doi          = {10.1016/j.jmva.2025.105507},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105507},
  shortjournal = {J. Multi. Anal.},
  title        = {Tree pólya splitting distributions for multivariate count data},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficiency of markov chains for bayesian linear regression models with heavy-tailed errors. <em>JOMA</em>, <em>211</em>, 105506. (<a href='https://doi.org/10.1016/j.jmva.2025.105506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider posterior simulation for a linear regression model when the error distribution is given by a scale mixture of multivariate normals. We first show that a sampler given in the literature for the case of the conditionally conjugate normal-inverse Wishart prior continues to be geometrically ergodic even when the error density is heavier-tailed. Moreover, we prove that the ergodicity is uniform by verifying the minorization condition. In the second half of this note, we treat an improper case and, using a simple energy function, show that a data augmentation algorithm in the literature is geometrically ergodic under a significantly different condition.},
  archive      = {J_JOMA},
  author       = {Yasuyuki Hamura},
  doi          = {10.1016/j.jmva.2025.105506},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105506},
  shortjournal = {J. Multi. Anal.},
  title        = {Efficiency of markov chains for bayesian linear regression models with heavy-tailed errors},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified selection consistency theorem for information criterion-based rank estimators in factor analysis. <em>JOMA</em>, <em>211</em>, 105498. (<a href='https://doi.org/10.1016/j.jmva.2025.105498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, numerous rank estimators for factor models have been proposed in the literature. This article focuses on information criterion-based rank estimators and investigates their consistency in rank selection. The gap conditions serve as necessary and sufficient conditions for rank estimators to achieve selection consistency under the general assumptions of random matrix theory. We establish a unified theorem on selection consistency, presenting the gap conditions for information criterion-based rank estimators with a unified formulation. To validate the theorem’s assertion that rank selection consistency is solely determined by the gap conditions, we conduct extensive numerical simulations across various settings. Additionally, we undertake supplementary simulations to explore the strengths and limitations of information criterion-based estimators by comparing them with other types of rank estimators.},
  archive      = {J_JOMA},
  author       = {Toshinari Morimoto and Hung Hung and Su-Yun Huang},
  doi          = {10.1016/j.jmva.2025.105498},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105498},
  shortjournal = {J. Multi. Anal.},
  title        = {A unified selection consistency theorem for information criterion-based rank estimators in factor analysis},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On nonparametric functional data regression with incomplete observations. <em>JOMA</em>, <em>211</em>, 105497. (<a href='https://doi.org/10.1016/j.jmva.2025.105497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider the problem of nonparametric estimation of a regression function m ( χ ) = E ( Y | χ = χ ) with the functional covariate χ when the response Y may be missing according to a missing-not-at-random (MNAR) setup, i.e., when the underlying missing probability mechanism can depend on both χ and Y . Our proposed estimator is based on a particular representation of the regression function m ( χ ) in terms of four associated conditional expectations that can be estimated nonparametrically. To assess the theoretical performance of our estimators, we study their convergence properties in general L p norms where we also look into their rates of convergence. Our numerical results show that the proposed estimators have good finite-sample performance. We also explore the applications of our results to the problem of statistical classification with missing labels and establish a number of convergence results for new kernel-type classification rules.},
  archive      = {J_JOMA},
  author       = {Majid Mojirsheibani},
  doi          = {10.1016/j.jmva.2025.105497},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105497},
  shortjournal = {J. Multi. Anal.},
  title        = {On nonparametric functional data regression with incomplete observations},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Matérn and generalized wendland correlation models that parameterize hole effect, smoothness, and support. <em>JOMA</em>, <em>211</em>, 105496. (<a href='https://doi.org/10.1016/j.jmva.2025.105496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A huge literature in statistics and machine learning is devoted to parametric families of correlation functions, where the correlation parameters are used to understand the properties of an associated spatial random process in terms of smoothness and global or compact support. However, most of current parametric correlation functions attain only non-negative values. This work provides two new families of correlation functions that can have some negative values (aka hole effects), along with smoothness, and global or compact support. They generalize the celebrated Matérn and Generalized Wendland models, respectively, which are obtained as special cases. A link between the two new families is also established, showing that a specific reparameterization of the latter includes the former as a special limit case. Their performance in terms of estimation accuracy and goodness of best linear unbiased prediction is illustrated through synthetic and real data.},
  archive      = {J_JOMA},
  author       = {Xavier Emery and Moreno Bevilacqua and Emilio Porcu},
  doi          = {10.1016/j.jmva.2025.105496},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105496},
  shortjournal = {J. Multi. Anal.},
  title        = {Matérn and generalized wendland correlation models that parameterize hole effect, smoothness, and support},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust semi-functional censored regression. <em>JOMA</em>, <em>211</em>, 105491. (<a href='https://doi.org/10.1016/j.jmva.2025.105491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a robust methodological framework for analyzing randomly censored responses within the semi-functional partial linear regression models, utilizing the exponential squared loss criterion. The proposed methodology capitalizes on the robustness of the exponential squared loss function against outliers and heavy-tailed error distributions, while preserving the flexibility and interpretability of semi-functional regression, which accommodates scalar and functional predictors in a unified framework. To account for the divergent convergence rates of the parametric and nonparametric components, we introduce a novel three-step estimation procedure designed to enhance computational efficiency, ensure model robustness, and achieve asymptotically optimal estimation performance. The parametric component is estimated through a quasi-Newton algorithm, for which we establish global convergence under standard regularity conditions using a Wolfe-type line search strategy. Additionally, we suggest a cross-validation criterion based on the exponential squared loss function to guide the data-driven selection of tuning parameters. The theoretical properties, including consistency and asymptotic normality of the proposed estimators, are established under mild conditions. The efficacy and robustness of the method are demonstrated through a series of simulation studies and an empirical application to Alzheimer’s disease progression, highlighting its practical applicability in addressing complex and censored data structures.},
  archive      = {J_JOMA},
  author       = {Tao Wang},
  doi          = {10.1016/j.jmva.2025.105491},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105491},
  shortjournal = {J. Multi. Anal.},
  title        = {Robust semi-functional censored regression},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical structure-guided high-dimensional multi-view clustering. <em>JOMA</em>, <em>211</em>, 105488. (<a href='https://doi.org/10.1016/j.jmva.2025.105488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data clustering is pivotal for comprehending the heterogeneous structure of data by integrating information from diverse aspects. Nevertheless, practical challenges arise due to the differences in the granularity from different views, resulting in a hierarchical clustering structure within these distinct data types. In this work, we consider such structure information and propose a novel high-dimensional multi-view clustering approach with a hierarchical structure across views. The proposed non-convex problem is effectively tackled using the Alternating Direction Method of Multipliers algorithm, and we establish the statistical properties of the estimator. Simulation results demonstrate the effectiveness and superiority of our proposed method. In the analysis of the histopathological imaging data and gene expression data related to lung adenocarcinoma, our method unveils a hierarchical clustering structure that significantly diverges from alternative approaches.},
  archive      = {J_JOMA},
  author       = {Jiajia Jiang and Kuangnan Fang and Shuangge Ma and Qingzhao Zhang},
  doi          = {10.1016/j.jmva.2025.105488},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105488},
  shortjournal = {J. Multi. Anal.},
  title        = {Hierarchical structure-guided high-dimensional multi-view clustering},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jomp">JOMP - 3</h2>
<ul>
<li><details>
<summary>
(2025). Experiment-based calibration in psychology: Foundational and data-generating model. <em>JOMP</em>, <em>127</em>, 102950. (<a href='https://doi.org/10.1016/j.jmp.2025.102950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experiment-based calibration is a novel method for measurement validation, which – unlike classical validity metrics – does not require stable between-person variance. In this approach, the latent variable to be measured is manipulated by an experiment, and its predicted scores – termed standard scores – are compared against the measured scores. Previous work has shown that under plausible boundary conditions, the correlation between standard and measured scores – termed retrodictive validity – is informative about measurement accuracy, i.e. combined trueness and precision. Here, I expand these findings in several directions. First, I formalise the approach in a probability-theoretic framework with the concept of a standardised calibration space. Second, I relate this framework to classical validity theory and show that the boundary conditions in fact apply to any form of criterion validity, including classical convergent validity. Thus, I state precise and empirically quantifiable boundary conditions under which criterion validity metrics are informative on validity. Third, I relate these boundary conditions to confounding variables, i.e. correlated latent variables. I show that in the limit, calibration will converge on the latent variable that is most closely related to the standard. Finally, I provide a framework for modelling the data-generating process with Markov kernels, and identify sufficient conditions under which the data generation model results in a calibration space. In sum, this article provides a formal probability-theoretic framework for experiment-based calibration and facilitates modelling and empirical assessment of the data generating processes.},
  archive      = {J_JOMP},
  author       = {Dominik R. Bach},
  doi          = {10.1016/j.jmp.2025.102950},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102950},
  shortjournal = {J. Math. Psychol.},
  title        = {Experiment-based calibration in psychology: Foundational and data-generating model},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On iverson’s law of similarity. <em>JOMP</em>, <em>127</em>, 102943. (<a href='https://doi.org/10.1016/j.jmp.2025.102943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iverson (2006b) proposed the law of similarity ξ s ( λ x ) = γ ( λ , s ) ξ η ( λ , s ) ( x ) for the sensitivity functions ξ s ( s ∈ S ) . Compared to the former models, the generality of this one lies in that here γ and η can also depend on the variables λ and s . In the literature, this model (or its special cases) is usually considered together with a given psychophysical representation (e.g. Fechnerian, subtractive, or affine). Our goal, however, is to study at first Iverson’s law of similarity on its own. We show that if certain mild assumptions are fulfilled, then ξ can be written in a rather simple form containing only one-variable functions. The obtained form proves to be very useful when we assume some kind of representation. Motivated by Hsu and Iverson (2016) , we then study the above model assuming that the mapping η is multiplicatively translational. First, we show how these mappings can be characterized. Later we turn to the examination of Falmagne’s power law. According to our results, the corresponding function ξ can have a Fechnerian representation, and also it can have a subtractive representation. We close the paper with the study of the shift invariance property.},
  archive      = {J_JOMP},
  author       = {Eszter Gselmann and Christopher W. Doble and Yung-Fong Hsu},
  doi          = {10.1016/j.jmp.2025.102943},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102943},
  shortjournal = {J. Math. Psychol.},
  title        = {On iverson’s law of similarity},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal analysis of absolute and relative risk reductions. <em>JOMP</em>, <em>127</em>, 102942. (<a href='https://doi.org/10.1016/j.jmp.2025.102942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any medical innovation must first prove its benefits with reliable evidence from clinical trials. Evidence is commonly expressed using two metrics, summarizing treatment benefits based on either absolute risk reductions (ARRs) or relative risk reductions (RRRs). Both metrics are derived from the same data, but they implement conceptually distinct ideas. Here, we analyze these risk reductions measures from a causal modeling perspective. First, we show that ARR is equivalent to Δ P , while RRR is equivalent to causal power, thus clarifying the implicit causal assumptions. Second, we show how this formal equivalence establishes a relationship with causal Bayes nets theory, offering a basis for incorporating risk reduction metrics into a computational modeling framework. Leveraging these analyses, we demonstrate that under dynamically varying baseline risks, ARRs and RRRs lead to strongly diverging predictions. Specifically, the inherent assumption of a linear parameterization of the underlying causal graph can lead to incorrect conclusions when generalizing treatment benefits (e.g, predicting the effect of a vaccine in new populations with different baseline risks). Our analyses highlight the shared principles underlying risk reduction metrics and measures of causal strength, emphasizing the potential for explicating causal structure and inference in medical research.},
  archive      = {J_JOMP},
  author       = {Björn Meder and Charley M. Wu and Felix G. Rebitschek},
  doi          = {10.1016/j.jmp.2025.102942},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102942},
  shortjournal = {J. Math. Psychol.},
  title        = {Causal analysis of absolute and relative risk reductions},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jpdc">JPDC - 1</h2>
<ul>
<li><details>
<summary>
(2026). A scalable tensor-based MDTW approach for multi-modal time series patterns clustering. <em>JPDC</em>, <em>207</em>, 105173. (<a href='https://doi.org/10.1016/j.jpdc.2025.105173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal Time Series (MTS) is a vital ingredient to Predictive Multi-modal Artificial Intelligence (PMAI). MTS systems capture varying temporal modalities and their inherent dependencies for their accurate analytics. However, efficiently exploring these cross-modalities relationships is a challenging research due to their complexity facets and information redundancies. MTS patterns' pairwise similarity measures precede PMAI. Multi-modal Dynamic Time Warping (MDTW) is frequently explored to quantify similar MTS. Yet, it's reliant on the orthogonal conditioned local similarity measures that ignore the contributions of MTS' underlying structural relationships in the warping process and, hence, susceptible to unrealistic matching. This paper addresses the setbacks by recommending a scalable MTS recognition model, named Tensor-Slices Distance (TSD)-based MDTW (TSD-MDTW), that's subsequently advanced to two more distinct models termed Weighted modality and TSD (WmTSD-MDTW) and TSD-Mahalanobis (TSDMaha-MDTW). To quantify an alignment's cost, TSD-MDTW incorporates intrinsic spatial dependencies between modalities' coordinates, while WmTSD-MDTW relaxes information redundancies through weighing modalities based on information richness, whereas TSDMaha-MDTW embodies modalities dependencies and their coordinates' innate spatial dependencies. Besides, it proposes a scalable Tensor-based DTW (TDTW) model that re-formulates MDTW into multiple dimensions that are found paralleling warping processes. Theoretical and empirical experimental results on MTS multi-modal datasets encompassing load patterns and meteorological modalities reveal TDTW's efficiency and proposals' superior performances in terms of cluster compactness and separation over MDTW employing the state-of-the-art local similarity measures.},
  archive      = {J_JPDC},
  author       = {Bahati Alam Sanga and Laurence T. Yang and Shunli Zhang and Zecan Yang and Nicholaus Gati},
  doi          = {10.1016/j.jpdc.2025.105173},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {1},
  pages        = {105173},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {A scalable tensor-based MDTW approach for multi-modal time series patterns clustering},
  volume       = {207},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jtb">JTB - 11</h2>
<ul>
<li><details>
<summary>
(2026). Adaptive dynamic resource allocation can cause tragedy of the commons in plants with nutrient competition. <em>JTB</em>, <em>616</em>, 112279. (<a href='https://doi.org/10.1016/j.jtbi.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plants exhibit plastic responses to the absence or presence of competitors. When competing for soil nutrients, plants often show root overproliferation compared to when they grow without competitors. This excessive investment in roots to acquire more nutrients can reduce reproductive yield (e.g., seed mass), a phenomenon known as the tragedy of the commons (TOC). The mechanisms of this phenomenon have been investigated theoretically, focusing on resource allocation strategies between the aboveground (shoot) and the belowground (roots) parts. The previous studies have primarily considered these strategies in terms of sizes of those parts or static allocation rates to those over the season, overlooking dynamic change of allocation within the season. In this study, we introduced a concept of dynamic resource allocation into the plant competition game and investigate the optimal resource allocation strategy using Pontryagin’s maximum principle. Based on the solutions of schedules, we explored the mechanism causing TOC in nutrient competition. Our findings reveal that plants adopt the singular control (i.e., simultaneous allocation to shoot and root), where the control trajectory is identical regardless of the presence or absence of competitors, although the period of simultaneous allocation become longer in the presence of competitors. This trend associates with increasing the root size and decreasing the shoot size at the end of season in the competitive case. Our analysis demonstrates that TOC in plant nutrient competition arises from differences in the allocation period to roots in the competitive scenario.},
  archive      = {J_JTB},
  author       = {Bo-Moon Kim and Atsushi Yamauchi},
  doi          = {10.1016/j.jtbi.2025.112279},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112279},
  shortjournal = {J. Theor. Biol},
  title        = {Adaptive dynamic resource allocation can cause tragedy of the commons in plants with nutrient competition},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gaussian process modelling of infectious diseases using the greta software package and GPUs. <em>JTB</em>, <em>616</em>, 112278. (<a href='https://doi.org/10.1016/j.jtbi.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian process are a widely-used statistical tool for conducting non-parametric inference in applied sciences, with many computational packages available to fit to data and predict future observations. We study the use of the Greta software for Bayesian inference to apply Gaussian process regression to spatio-temporal data of infectious disease outbreaks and predict future outbreaks. Greta builds on Tensorflow, making it comparatively easy to take advantage of the significant gain in speed offered by GPUs. In these complex spatio-temporal models, we show a reduction of up to 70% in computational time relative to fitting the same models on CPUs. We show how the choice of covariance kernel impacts the ability to infer spread and extrapolate to unobserved spatial and temporal units. The inference pipeline is applied to weekly incidence data on tuberculosis in the East and West Midlands regions of England over a period of two years.},
  archive      = {J_JTB},
  author       = {Eva Gunn and Nikhil Sengupta and Ben Swallow},
  doi          = {10.1016/j.jtbi.2025.112278},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112278},
  shortjournal = {J. Theor. Biol},
  title        = {Gaussian process modelling of infectious diseases using the greta software package and GPUs},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Effective decoupling of mutations and the resulting loss of biodiversity caused by environmental change. <em>JTB</em>, <em>616</em>, 112277. (<a href='https://doi.org/10.1016/j.jtbi.2025.112277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many biological populations exhibit diversity in their strategy for survival and reproduction in a given environment, and microbes are an example. We explore the fate of different strategies under sustained environmental change by considering a mathematical model for a large population of asexual organisms. Fitness is a bimodal function of a quantitative trait, with two local optima, separated by a local minimum, i.e., a mixture of stabilising and disruptive selection. The optima represent two locally ‘best’ trait values. We consider regimes where, when the environment is unchanging, the equilibrium distribution of the trait is bimodal. A bimodal trait distribution generally requires, for its existence, mutational coupling between the two peaks, and it indicates two coexisting clones with distinct survival and reproduction strategies. When subject to persistent environmental change, the population adapts by utilising mutations that allow it to track the changing environment. The faster the rate of change of the environment, the larger the effect of the mutations that are utilised. Under persistent environmental change, the distribution of trait values takes two different forms. At low rates of change, the distribution remains bimodal. At higher rates, the distribution becomes unimodal. This loss of a clone/biodiversity is driven by a novel mechanism where environmental change decouples a class of mutations.},
  archive      = {J_JTB},
  author       = {Ruixi Huang and David Waxman},
  doi          = {10.1016/j.jtbi.2025.112277},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112277},
  shortjournal = {J. Theor. Biol},
  title        = {Effective decoupling of mutations and the resulting loss of biodiversity caused by environmental change},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A kinetic study of multi-substrate uniporters. <em>JTB</em>, <em>616</em>, 112267. (<a href='https://doi.org/10.1016/j.jtbi.2025.112267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transporters play key roles in regulating the movement of molecules into and out of cells. Uniporters, the simplest class of transporters, use facilitated diffusion to translocate molecules across membranes down their concentration gradient. This process can be affected by the presence of additional substrates in the intra- and extracellular environment, which can either increase the net transport rate of a molecule via trans acceleration or decrease it via competitive inhibition. In this study, we derived mathematical models to describe the net transport rate of uniporters in the presence of multiple extracellular substrates or inhibitors. Analyses of these models identified four possible states for the system when two substrates are present, with two states leading to trans acceleration and the other two states resulting in inhibition. Finally, we found that the relation between kinetic constants that controls the fraction of transporters in the inward-facing open state is responsible for these behaviors. Our theoretical results provide a mathematical framework for understanding the dynamic response of uniporters in the presence of multiple substrates and inhibitors, which could have implications for various processes, from nutrient utilization to metabolic engineering.},
  archive      = {J_JTB},
  author       = {Ana S. de Pereda and Jihyun Park and Lily S. Cheung},
  doi          = {10.1016/j.jtbi.2025.112267},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112267},
  shortjournal = {J. Theor. Biol},
  title        = {A kinetic study of multi-substrate uniporters},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Drug-loaded nanoparticles for cancer therapy: A high-throughput multicellular agent-based modeling study. <em>JTB</em>, <em>616</em>, 112266. (<a href='https://doi.org/10.1016/j.jtbi.2025.112266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactions between biological systems and engineered nanomaterials have become an important area of study due to their application in medicine. In particular, the opportunity to apply nanomaterials for cancer diagnosis and treatment presents a challenge due to the complex biology of this disease, which spans multiple time and spatial scales. A systems-level analysis from mathematical modeling and computational simulation to explore the interactions between anticancer drug-loaded nanoparticles (NPs), cells, and tissues, and the associated system parameters and patient response would be of benefit. Although a number of models have explored these interactions in the past, few have focused on simulating individual cell-NP interactions. This study develops a multicellular agent-based model of cancer nanotherapy that simulates NP internalization, drug release within the cell cytoplasm, inheritance of NPs by daughter cells at cell division, cell pharmacodynamic response to intracellular drug levels, and overall drug effect on tumor growth. A large-scale parallel computational framework is used to investigate the impact of pharmacokinetic design parameters (NP internalization rate, NP decay rate, anticancer drug release rate) and therapeutic strategies (NP doses and injection frequency) on tumor growth. In particular, through the exploration of NP inheritance at cell division, the results indicate that cancer treatment may be improved when NPs are inherited at cell division for cytotoxic chemotherapy. Moreover, smaller dose of cytostatic chemotherapy may also improve inhibition of tumor growth when cell division is not completely inhibited. This work suggests that slow delivery by heritable NPs can drive new dimensions of nanotherapy design for more sustained therapeutic response.},
  archive      = {J_JTB},
  author       = {Yafei Wang and John Metzcar and Elmar Bucher and Heber L. Rocha and Vikram Jadhao and Randy Heiland and Hermann B. Frieboes and Paul Macklin},
  doi          = {10.1016/j.jtbi.2025.112266},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112266},
  shortjournal = {J. Theor. Biol},
  title        = {Drug-loaded nanoparticles for cancer therapy: A high-throughput multicellular agent-based modeling study},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stably encoding phylogenetic trees with folios of leaf addresses. <em>JTB</em>, <em>616</em>, 112265. (<a href='https://doi.org/10.1016/j.jtbi.2025.112265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As genome sequencing data continue to expand, a persistent research challenge is to accommodate the growth of a phylogeny. This situation arises in molecular epidemiology, for example, where new taxonomic groups can appear in real time as pathogen isolates are sequenced. Efficient computational methods have been developed to place new leaves in existing trees, which removes the need to reconstruct trees from scratch. But for these tree extensions to be fully integrated with classification schemes requires a stable encoding of trees that keeps existing tree structures intact as new branches appear. Here, we propose a tree encoding, which we call a folio , that records the path from a reference vertex to each leaf, giving each leaf an address . We present a simple set of rules to assign new addresses to added leaves. The encoding is stable in the sense that it does not change as further leaf addresses are added to the folio. The tree can be uniquely recovered from a folio of addresses. We illustrate the methods using Salmonella genome data. Due to the properties of our encoding framework, we anticipate that it can be used for a range of different phylogenetic analyses.},
  archive      = {J_JTB},
  author       = {Mark M. Tanaka and Ruiting Lan and Andrew R. Francis},
  doi          = {10.1016/j.jtbi.2025.112265},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112265},
  shortjournal = {J. Theor. Biol},
  title        = {Stably encoding phylogenetic trees with folios of leaf addresses},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Phenomenological modeling of gene transcription by approximating cooperativity of transcription factors improves prediction and reduces complexity in gene regulatory network models. <em>JTB</em>, <em>616</em>, 112264. (<a href='https://doi.org/10.1016/j.jtbi.2025.112264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several computational models are available for representing the gene expression process, with each having their advantages and disadvantages. Phenomenological models are widely used as they make appropriate simplifications that aim to find a middle ground between accuracy and complexity. The existing phenomenological models compete in terms of how the transcription initiation process is approximated, to achieve high accuracy while having the lowest complexity possible. However, most current models still suffer from high parameter complexity in the case of complex promoters. Herein, we formally derive a phenomenological approach to model RNA polymerase recruitment, stating approximations on cooperativity between transcription factors that are applicable to promoters requiring multifactorial input, which reduces parameter complexity. We then apply this method to biologically relevant networks of varying complexities to show that the approximations improved predictive ability compared to existing models. In summary, our reduced parameter model (RPM) had lower complexity while maintaining high accuracy, which leads to better scalability for complex networks.},
  archive      = {J_JTB},
  author       = {Thiruvickraman Jothiprakasam and Siddharth Jhunjhunwala},
  doi          = {10.1016/j.jtbi.2025.112264},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112264},
  shortjournal = {J. Theor. Biol},
  title        = {Phenomenological modeling of gene transcription by approximating cooperativity of transcription factors improves prediction and reduces complexity in gene regulatory network models},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mathematical model suggests current CAR-macrophage dosage is efficient to low pre-infusion tumour burden but refractory to high tumour burden. <em>JTB</em>, <em>616</em>, 112263. (<a href='https://doi.org/10.1016/j.jtbi.2025.112263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chimeric antigen receptor (CAR)-macrophage therapy is a promising approach for tumour treatment due to antigen-specific phagocytosis and tumour clearance. However, the precise impact of tumour burden, dose and dosing regimens on therapeutic outcomes remains poorly understood. We developed ordinary differential equation (ODE) mathematical modelling and utilised parameter inference to analyse in vitro FACS-based phagocytosis assay data testing CD19-positive Raji tumour cell against CAR-macrophage, and revealed that phagocytosing efficiency of CAR-macrophage increases but saturates as both Raji cell and CAR-macrophage concentrations increase. This interaction resulted in bistable Raji cell kinetics; specifically, within a particular range of CAR-macrophage concentration, low tumour burdens are effectively inhibited, while high tumour burdens remain refractory. Furthermore, our model predicted that CAR-macrophage dosages typically suggested by current clinical trials yield favourable therapeutic outcomes only when tumour burden is low. For split CAR-macrophage infusion with fixed total dosage, the first infusion with high CAR-macrophage dose delivers superior treatment outcomes. Finally, we identified alternative infusion regimens: five billion cells administered monthly for three months, or seven billion cells every two months for six months, can efficiently suppress Raji cell replication irrespective of tumour burden. Our findings highlight CAR-macrophage therapeutic outcomes are strongly influenced by both tumour burden and different dosing regimens. This work underscores that reducing tumour burden, increasing CAR-macrophage dose in the first infusion and prolonging CAR-macrophage persistence are key strategies for achieving durable responses.},
  archive      = {J_JTB},
  author       = {Shilian Xu and Maoxuan Liu},
  doi          = {10.1016/j.jtbi.2025.112263},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112263},
  shortjournal = {J. Theor. Biol},
  title        = {Mathematical model suggests current CAR-macrophage dosage is efficient to low pre-infusion tumour burden but refractory to high tumour burden},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergent microtubule properties in a model of filament turnover and nucleation. <em>JTB</em>, <em>616</em>, 112254. (<a href='https://doi.org/10.1016/j.jtbi.2025.112254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microtubules (MTs) are dynamic protein filaments essential for intracellular organization and transport, particularly in long-lived cells such as neurons. The plus and minus ends of neuronal MTs switch between growth and shrinking phases, and the nucleation of new filaments is believed to be regulated in both healthy and injury conditions. We propose stochastic and deterministic mathematical models to investigate the impact of filament nucleation and length-regulation mechanisms on emergent properties such as MT lengths and numbers in living cells. We expand our stochastic continuous-time Markov chain model of filament dynamics to incorporate MT nucleation and capture realistic stochastic fluctuations in MT numbers and tubulin availability. We also propose a simplified partial differential equation (PDE) model, which allows for tractable analytical investigation into steady-state MT distributions under different nucleation and length-regulating mechanisms. We find that the stochastic and PDE modeling approaches show good agreement in MT length distributions, and that both MT nucleation and the catastrophe rate of large-length MTs regulate MT length distributions. In both frameworks, multiple mechanistic combinations achieve the same average MT length. The models proposed can predict parameter regimes where the system is scarce in tubulin, the building block of MTs, and suggest that low filament nucleation regimes are characterized by high variation in MT lengths, while high nucleation regimes drive high variation in MT numbers. These mathematical frameworks have the potential to improve our understanding of MT regulation in both healthy and injured neurons.},
  archive      = {J_JTB},
  author       = {Anna C. Nelson and Scott A. McKinley and Melissa M. Rolls and Maria-Veronica Ciocanel},
  doi          = {10.1016/j.jtbi.2025.112254},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112254},
  shortjournal = {J. Theor. Biol},
  title        = {Emergent microtubule properties in a model of filament turnover and nucleation},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modelling phylogeny in 16S rRNA gene sequencing datasets using string-based kernels. <em>JTB</em>, <em>616</em>, 112249. (<a href='https://doi.org/10.1016/j.jtbi.2025.112249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bacterial microbiome is increasingly being recognised as a key factor in human health, driven in large part by datasets collected using 16S rRNA (ribosomal ribonucleic acid) gene sequencing, which enable cost-effective quantification of the composition of an individual’s bacterial community. One of the defining characteristics of 16S rRNA datasets is the evolutionary relationships that exist between taxa (phylogeny). Here, we demonstrate the utility of modelling these phylogenetic relationships in two statistical tasks (the two sample test and host trait prediction) and propose a novel family of kernels for analysing microbiome datasets by leveraging string kernels from the natural language processing literature. We show via simulation studies that a kernel two-sample test using the proposed kernel is sensitive to the phylogenetic scale of the difference between the two populations. In a second set of simulations we also show how Gaussian process modelling with string kernels can infer the distribution of bacterial-host effects across the phylogenetic tree and apply this approach to a real host-trait prediction task. The results in the paper can be reproduced by running the code at https://github.com/jonathanishhorowicz/modelling_phylogeny_in_16srrna_using_string_kernels .},
  archive      = {J_JTB},
  author       = {Jonathan Ish-Horowicz and Sarah Filippi},
  doi          = {10.1016/j.jtbi.2025.112249},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112249},
  shortjournal = {J. Theor. Biol},
  title        = {Modelling phylogeny in 16S rRNA gene sequencing datasets using string-based kernels},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Approximate bayesian computation for markovian binary trees in phylogenetics. <em>JTB</em>, <em>616</em>, 112246. (<a href='https://doi.org/10.1016/j.jtbi.2025.112246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phylogenetic trees describe the relationships between species in the evolutionary process, and provide information about the rates of diversification. To understand the mechanisms behind macroevolution, we consider a class of multitype branching processes called Markovian binary trees (MBTs). MBTs allow for trait-based variation in diversification rates, and provide a flexible and realistic probabilistic model for phylogenetic trees. We develop an approximate Bayesian computation (ABC) scheme to infer the rates of MBT parameters by exploiting the information in the shapes of phylogenetic trees. We evaluate the accuracy of this inference method using simulation studies, and find that our method is able to detect variation in the diversification rates, with accuracy comparable to, and generally better than, likelihood-based methods. In an application to a real-life phylogeny of squamata, we reinforce conclusions drawn from earlier studies, in particular supporting the existence of ovi-/viviparity transitions in both directions. Our method demonstrates the potential for more complex models of evolution to be employed in phylogenetic inference, in conjunction with likelihood-free schemes.},
  archive      = {J_JTB},
  author       = {Mingqi He and Sophie Hautphenne and Yao-ban Chan},
  doi          = {10.1016/j.jtbi.2025.112246},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112246},
  shortjournal = {J. Theor. Biol},
  title        = {Approximate bayesian computation for markovian binary trees in phylogenetics},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="kbs">KBS - 42</h2>
<ul>
<li><details>
<summary>
(2025). Selective embedding for deep learning. <em>KBS</em>, <em>330</em>, 114535. (<a href='https://doi.org/10.1016/j.knosys.2025.114535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has revolutionized many industries by enabling models to automatically learn complex patterns from raw data, reducing dependence on manual feature engineering. However, deep learning algorithms are sensitive to input data, and performance often deteriorates under nonstationary conditions and across dissimilar domains, especially when using time-domain data. Conventional single-channel or parallel multi-source data loading strategies either limit generalization or increase computational costs. This study introduces selective embedding, a novel data loading strategy, which alternates short segments of data from multiple sources within a single input channel. Drawing inspiration from cognitive psychology, selective embedding mimics human-like information processing to reduce model overfitting, enhance generalization, and improve computational efficiency. Validation is conducted using six time-domain datasets, demonstrating that the proposed method consistently achieves high classification accuracy for many deep learning architectures while significantly reducing training times. Across multiple datasets, selective embedding consistently improves test accuracy by 20 to 30 percent compared to traditional single-channel loading strategies, while also matching or exceeding the performance of parallel multi-source loading methods. Importantly, these gains are achieved while significantly reducing training times, demonstrating both efficiency and scalability across simple and complex architectures. The approach proves particularly effective for complex systems with multiple data sources, offering a scalable and resource-efficient solution for real-world applications in healthcare, heavy machinery, marine, railway, and agriculture, where robustness and adaptability are critical.},
  archive      = {J_KBS},
  author       = {Mert Sehri and Zehui Hua and Francisco de Assis Boldt and Patrick Dumond},
  doi          = {10.1016/j.knosys.2025.114535},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114535},
  shortjournal = {Knowl. Based Syst.},
  title        = {Selective embedding for deep learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization. <em>KBS</em>, <em>330</em>, 114514. (<a href='https://doi.org/10.1016/j.knosys.2025.114514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern autonomous driving systems rely heavily on deep learning-based perception models for object detection; yet, their computational and energy demands remain critical bottlenecks. The existing adaptive-perception strategies often lack the ability to dynamically balance the detection accuracy and energy consumption, in real-time, particularly under varying environmental conditions. To address this challenge, we first construct a large-scale autonomous driving dataset based on the CARLA simulator. Then, we propose a novel metric—the balanced efficiency index—to annotate each image with the most suitable you-only-look-once version 8 (YOLOv8) model size (i.e., n, s, m, l, or x). This index is governed by two critical parameters, which are efficiently optimized using our proposed constrained stochastic DIviding RECTangles (DIRECT) algorithm. Finally, we propose a lightweight dynamic mixed receptive field transformer (DynaMixFormer), which is trained using the labelled dataset, to select the appropriate YOLOv8 model adaptively. Our results show that: (1) the constrained stochastic DIRECT algorithm determines cost-effective parameters with very limited simulation overhead; (2) DynaMixFormer achieves a high classification accuracy of 96.56 % with only 0.017 M parameters, outperforming the state-of-the-art image-classification networks; and (3) the well-trained DynaMixFormer effectively extracts real-time contextual features, such as traffic density, weather conditions, and road complexity, to intelligently select the optimal model from various YOLOv8 variants. Extensive simulations demonstrate that our approach achieves up to 70.20 % reduction in the energy consumption, compared to the static deployment of the YOLOv8x model, with only a marginal decrease of approximately 2 % in the mean average precision. Taking China as an example, this translates to an estimated energy saving of 2.73 × 10 14 W. This work not only advances energy-efficient autonomous perception but also provides a generalizable framework for adaptive model selection in resource-constrained edge-computing systems. For ease of comprehension, some key nomenclature used in this paper are summarized in Table 1.},
  archive      = {J_KBS},
  author       = {Yanzhan Chen and Fan Yu and Qian Zhang and Mahardhika Pratama},
  doi          = {10.1016/j.knosys.2025.114514},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114514},
  shortjournal = {Knowl. Based Syst.},
  title        = {Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph. <em>KBS</em>, <em>330</em>, 114507. (<a href='https://doi.org/10.1016/j.knosys.2025.114507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As language models are used in more applications, a key problem has become clear: their numerical embeddings are hard to interpret because it is unclear how each part of the vector relates to real-world meanings in specific fields. The prevailing embedding methods are inadequate in their current state, as they are unable to effectively bridge the gap between mathematical representations and human-understandable knowledge structures. The present study proposes a novel framework that explicitly links ontology classes to specific embedding dimensions through a dual-component architecture combining a text encoder that produces the target embedding dimensions with domain knowledge graphs. The Area Under the Interpretability Curve (AUIC) metric is introduced as a means to systematically evaluate model-alignment with ontological concepts. The analysis reveals that targeted dimensional mapping enables direct interpretation of individual vector components through ontological terms. The practical applications of this framework are illustrated through case studies in biomedical contexts, demonstrating enhanced model transparency without compromising performance. This approach establishes a measurable pathway for reconciling statistical language representations with structured domain knowledge, particularly benefiting fields requiring precise concept alignment like biomedicine. The implementation is publicly available at: https://github.com/Mellandd/DEIBO .},
  archive      = {J_KBS},
  author       = {Jose L. Mellina-Andreu and Alejandro Cisterna-García and Juan A. Botía},
  doi          = {10.1016/j.knosys.2025.114507},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114507},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity facial aesthetic evaluation model based on image-text modality. <em>KBS</em>, <em>330</em>, 114502. (<a href='https://doi.org/10.1016/j.knosys.2025.114502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Beauty Prediction (FBP) is an emerging research direction at the intersection of artificial intelligence and aesthetics, which has attracted increasing attention in recent years. However, most existing methods rely solely on unimodal data and fail to comprehensively capture the multi-dimensional information of facial aesthetics. To address this challenge, we propose a multigranularity facial aesthetic evaluation model based on image-text modality (ITM-MGFA). By incorporating multi-granularity cognitive theory into the FBP task, the model effectively integrates both coarse-grained and fine-grained aesthetic features extracted from the CLIP encoder through a multigranularity representation module, a task-oriented dynamic alignment module, and a hierarchical interaction optimization module. This facilitates deep cross-modal interaction and fusion, significantly enhancing the model’s capability to model complex aesthetic attributes. Experimental results demonstrate that ITM-MGFA, leveraging the fusion of cross-modal information, achieves higher accuracy in facial aesthetic assessment task compared to traditional unimodal methods, offering a new direction for FBP research. Furthermore, the model can be applied in various scenarios, such as: simulation postoperative assessment of personalized cosmetic surgery in the medical aesthetics; selection of optimal facial aesthetic enhancement solutions on social media; and recommendation of matching solutions in cosmetic recommendation.},
  archive      = {J_KBS},
  author       = {Huanyu Chen and Yong Wang and Weisheng Li and Bin Xiao},
  doi          = {10.1016/j.knosys.2025.114502},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114502},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-granularity facial aesthetic evaluation model based on image-text modality},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments. <em>KBS</em>, <em>330</em>, 114501. (<a href='https://doi.org/10.1016/j.knosys.2025.114501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking plays a critical role in airborne autonomous systems, supporting applications such as disaster response, agricultural monitoring, and military surveillance. However, existing tracking methods often exhibit poor generalization in real-world deployments due to domain shifts between the training and target environments. We propose DGTrack, a novel single-source domain generalization framework for UAV visual tracking. DGTrack integrates a Frequency-Aware Learning (FAL) module that separates and adaptively modulates low- and high-frequency components to reduce stylistic interference while enhancing content representation. In addition, a Target-Aligned Augmentation (TAA) module is introduced to improve source domain diversity through multi-level transformations and to align predictions between original and augmented frames by maximizing mutual information. Extensive experiments on the UAVDT and VisDrone2019 datasets demonstrate that DGTrack achieves superior generalization to unseen domains and consistently outperforms state-of-the-art UAV trackers in single-source settings.},
  archive      = {J_KBS},
  author       = {Erfeng Liu and Xinde Li and Heqing Li and Guoliang Wu and Tao Shen},
  doi          = {10.1016/j.knosys.2025.114501},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114501},
  shortjournal = {Knowl. Based Syst.},
  title        = {A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data. <em>KBS</em>, <em>330</em>, 114500. (<a href='https://doi.org/10.1016/j.knosys.2025.114500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a feature-augmented multivariate LSTM model for real-time Forex market forecasting. By incorporating engineered financial indicators—such as Close_Change, RSI, and gold price—alongside traditional OHLCV data, the model captures nonlinear temporal dynamics and macro-financial interactions. A sliding window approach structures input sequences for a stacked LSTM network optimized for short-term prediction. Experimental results on major currency pairs demonstrate that the proposed model outperforms baseline LSTM, GRU, and classical machine learning methods in RMSE, MAE, and MAPE metrics. Statistical validation using the Wilcoxon signed-rank test confirms the improvements are significant. The model's robustness under volatility stress and noisy inputs highlights its practical relevance for real-time decision-making. Potential extensions include incorporating news-based sentiment and multimodal signals to enhance adaptability.},
  archive      = {J_KBS},
  author       = {Duong Thi Kim Chi and Ho Ngoc Trung Kien and Thanh Q. Nguyen},
  doi          = {10.1016/j.knosys.2025.114500},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114500},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-generalized token linking in vision foundation models for semantic segmentation. <em>KBS</em>, <em>330</em>, 114497. (<a href='https://doi.org/10.1016/j.knosys.2025.114497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {[S U M M A R Y] Vision Foundation Models (VFMs) achieve remarkable performance compared with traditional methods based on convolutional neural networks and vision transformer networks in Domain-Generalized Semantic Segmentation (DGSS). These VFM-based DGSS methods focus on adopting efficient parameter fine-tuning strategies that use a set of learnable tokens to fine-tune VFMs to the downstream DGSS task, yet struggle to mine domain-invariant information from VFMs since the backbone of VFMs is frozen during the fine-tuning stage. To address this issue, a Domain-Generalized Token Linking (DGTL) approach is proposed to mine domain-invariant information from VFMs for improving the performance in unseen target domains, which contains a Text-guided Dual Token Linking (TDTL) module and a Text-guided Distribution Normalization (TDN) strategy. For the TDTL module, first, a set of learnable tokens is linked to the text embeddings for building the relations between the learnable tokens and text embeddings, which is beneficial for learning domain-invariant tokens since the text embeddings generated from the CLIP model are domain-invariant. Second, the feature-level and mask-level linking strategies are proposed to link the learned domain-invariant tokens to the features and masks to guide the mining of domain-invariant information from the VFM. For the TDN strategy, the pairwise similarity between the predictive masks associated with the learnable tokens and the text embeddings is utilized to explicitly align the semantic distribution of visual features in the learnable tokens with the text embeddings. Extensive experiments demonstrate that the DGTL approach achieves superior performance to recent methods across multiple DGSS benchmarks. The code is released on GitHub: https://github.com/seabearlmx/DGTL .},
  archive      = {J_KBS},
  author       = {Muxin Liao and Jiayang Wang and Hong Deng and Yingqiong Peng and Hua Yin and Yinglong Wang and Guoguang Hua},
  doi          = {10.1016/j.knosys.2025.114497},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114497},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain-generalized token linking in vision foundation models for semantic segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive exploration for few-shot incremental learning. <em>KBS</em>, <em>330</em>, 114496. (<a href='https://doi.org/10.1016/j.knosys.2025.114496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) poses a challenging problem in computer vision, where conventional deep models suffer from catastrophic forgetting and overfitting to novel classes. Inspired by the dynamic learning processes observed in human cognition when adapting to unfamiliar scenarios, we propose a deep exploratory incremental learning framework that incrementally refines the classifier model through a trial-and-error decision making process. A joint distribution-aware reward function is introduced to guide learning, incorporating three key factors: intra-class compactness, inter-class dispersion, and cross-session consistency, enabling balanced knowledge retention and acquisition. Furthermore, we design a dynamic gradient guidance module that adaptively adjusts gradient updates within a Gaussian-derived policy space, enhancing training stability and mitigating overfitting risks in the few shot regime. Extensive experiments conducted on three publicly available datasets demonstrate the effectiveness of the proposed method, achieving state-of-the-art performance in the FSCIL setting.},
  archive      = {J_KBS},
  author       = {Cao Han and Ziqi Gu and Chunyan Xu and Zhen Cui},
  doi          = {10.1016/j.knosys.2025.114496},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114496},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive exploration for few-shot incremental learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings. <em>KBS</em>, <em>330</em>, 114495. (<a href='https://doi.org/10.1016/j.knosys.2025.114495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the thermomechanical responses of refractory linings in steel ladles is critical to optimizing production efficiency and ensuring safety in the iron and steel smelting industry. However, traditional numerical simulation methods suffer challenges of high computational costs and insufficient generalizability, while data-driven models are limited by a lack of physical rationality and poor interpretability. Aiming at overcoming these challenges, an artificial intelligence (AI) model, named the steel ladle Kolmogorov–Arnold network (SLKAN), is designed to predict the thermomechanical behavior of ladle linings. Based on the Kolmogorov–Arnold theorem and material constitutive equations, SLKAN precisely predicts the thermomechanical behavior of ladle linings. The model offers substantial advantages in predicting the maximum tensile stress in the steel shell and the maximum compressive stress at the working lining hot face: the coefficient of determination (R 2 ) value for compressive stress prediction reaches 0.9942, with a mean absolute error (MAE) of 9.4136 and a root mean squared error (RMSE) of 0.0192; the R 2 value for tensile stress prediction is 0.9578, with an MAE of 41.4855 and an RMSE of 0.0385. Further analysis indicates that the function expressions of SLKAN hold clear physical significance. This study provides an interpretable, efficient AI solution for multiphysics coupling modeling in complex industrial scenarios and offers theoretical guidance for the application of AI in predicting the lifespan of steel-smelting equipment.},
  archive      = {J_KBS},
  author       = {Yi Yin and Zongxian Long and Shengli Jin and Yawei Li and Fang Wang and Xin Xu},
  doi          = {10.1016/j.knosys.2025.114495},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114495},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation. <em>KBS</em>, <em>330</em>, 114490. (<a href='https://doi.org/10.1016/j.knosys.2025.114490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation Systems (RSs) aim to provide personalized recommendations by modeling user-item interaction patterns. Current attribute-enhanced RSs leverage user archival attributes to improve predictive performance. However, the use of attribute information introduces two critical challenges: 1) the risk of privacy leakage, as sensitive user attributes can be inferred from learned representations, and 2) high computational complexity, primarily due to the quadratic complexity of attention mechanisms. To address the accuracy-privacy-efficiency trilemma, we propose an Archive Knowledge Graph-enhanced Native Sparse Attention network (AKG-NSA) for privacy-preserving lightweight recommendation. Specifically, AKG-NSA introduces a two-stage privacy protection mechanism. First, we pseudonymize user identities in the archive knowledge graph, breaking the direct linkage between users and their attributes. Second, we design a Multi-channel Native Sparse Attention (MNSA) network that utilizes compressed user representations as queries to retrieve attribute patterns from the archive knowledge graph in a privacy-preserved manner. Moreover, we also construct a parallel user-item bipartite graph and operate graph convolutions to learn the representations for users and items. By employing the native sparse attention mechanism, AKG-NSA refines the learned representations while maintaining a low computational complexity. Extensive experiments on three real-world datasets demonstrate that AKG-NSA outperforms nine state-of-the-art baselines in terms of prediction accuracy, privacy preservation, and computational efficiency. The data and source codes of this work are available at https://github.com/juandu113/AKG-NSA .},
  archive      = {J_KBS},
  author       = {Juan Du and Chenxi Ma and Yaobin Wang and Limei Sun},
  doi          = {10.1016/j.knosys.2025.114490},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114490},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions. <em>KBS</em>, <em>330</em>, 114488. (<a href='https://doi.org/10.1016/j.knosys.2025.114488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online chatter detection is a critical technology in intelligent manufacturing systems, essential for ensuring high-quality and efficient milling operations. Although artificial intelligence models have been developed to automatically identify chatter, the accuracy improvement is limited by the use of single sensor signals. Therefore, a multi-source heterogeneous sensor information fusion framework is proposed for intelligent online chatter detection in this paper. To effectively mitigate noise and eliminate interference from milling parameters, a heterogeneous sensor signal processing strategy is proposed based on wavelet packet decomposition and successive variational mode decomposition. Next, a multi-source, multi-stage, and multi-scale spatial-temporal fusion attention network is proposed for extracting chatter features and achieving high-precision chatter detection. It is noteworthy that multi-source signals are fused at the feature level, and comprehensive chatter features are extracted through the multi-source information fusion module, the multi-stage spatial-temporal feature extraction and fusion module, and the multi-scale gated channel attention module. In milling experiments across different conditions, the chatter detection performance of the proposed framework is evaluated in three scenarios. The results indicate that this framework can provide more accurate and reliable detection results compared to other methods.},
  archive      = {J_KBS},
  author       = {Liangshi Sun and Xianzhen Huang and Zhiyuan Jiang and Jiatong Zhao and Xu Wang},
  doi          = {10.1016/j.knosys.2025.114488},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114488},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-conditional image synthesis with intra-class relation preservation. <em>KBS</em>, <em>330</em>, 114487. (<a href='https://doi.org/10.1016/j.knosys.2025.114487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling class-conditional data distributions remains challenging, since the intra-class variation may be very large. Different from generic class-conditional Generative Adversarial Networks (GANs), we take inspiration from the observation that there may exist multiple modes with diverse visual appearances in a single class, and propose an Intra-class Prototype-based Relation Preservation (IPRP) approach to improve class-conditional image synthesis. Toward this end, a generator is designed to learn class-specific data distribution, conditioned on intra-class prototype-based relation. To associate label embeddings with the cluster prototypes, we incorporate an auxiliary prototypical network to perform adversarial interpolation, and the synthesized data are required to encapsulate their relation to the corresponding prototypes in the form of interpolation coefficients. The prototypical network can be further leveraged to improve the class-conditional real-fake identification performance by injecting semantics-aware features into a discriminator. This design allows the generator to better capture intra-class modes We conduct extensive experiments to demonstrate that IPRP outperforms the competing class-conditional GANs in terms of data diversity and semantic accuracy.},
  archive      = {J_KBS},
  author       = {Yunfei Zhang and Xiaoyang Huo and Tianyi Chen and Si Wu and Hau-San Wong},
  doi          = {10.1016/j.knosys.2025.114487},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114487},
  shortjournal = {Knowl. Based Syst.},
  title        = {Class-conditional image synthesis with intra-class relation preservation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems. <em>KBS</em>, <em>330</em>, 114485. (<a href='https://doi.org/10.1016/j.knosys.2025.114485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of new-generation artificial intelligence technologies, machines can process and analyze large-scale data more accurately and efficiently and for more complex tasks. Enhancing the usability and value of the information derived from various information systems across multiple dimensions is essential. However, traditional data dominance relationships cannot reflect people’s different levels of attention to antithetic features, leading to higher complexity and lower classification accuracy. Therefore, it is necessary to consider the weight relationships between attributes in the data, which refers to the degree of correlation between each attribute and the decision in multi-source information systems. Based on these weights and dominance relationships, we consider an entropy-based weighted information fusion method for processing supervised data in multi-source ordered decision systems. We intend four incremental fusion mechanisms to adjust information sources and attribute changes to save running time. Furthermore, experiments are conducted on nine real datasets to demonstrate our method’s effectiveness. The results show that the inevitable accuracy comparisons by the proposed method are superior to most fusion methods. In addition, the dynamic mechanisms, compared to static mechanisms, can significantly reduce running time.},
  archive      = {J_KBS},
  author       = {Xiaoyan Zhang and Jiajia Lin},
  doi          = {10.1016/j.knosys.2025.114485},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114485},
  shortjournal = {Knowl. Based Syst.},
  title        = {A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning. <em>KBS</em>, <em>330</em>, 114483. (<a href='https://doi.org/10.1016/j.knosys.2025.114483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop knowledge graph reasoning aims to leverage the relations between multiple nodes in a knowledge graph to reason information about an event or entity. This reasoning process requires traversing multiple interconnected facts or knowledge points, which aids in understanding the model’s decision-making process. Multi-hop knowledge graph reasoning has driven the development of knowledge-based technologies, such as question-answering systems and recommendation systems. However, multi-hop reasoning relies on the connectivity between different entities in the knowledge graph. This characteristic makes multi-hop reasoning lack robustness when dealing with sparse data. To address the challenges of sparsity, recent studies pre-train knowledge graph embedding models to complete potential triples. The completion methods introduce noisy triples, which increases the risk of model selection errors and spurious paths. In this work, we propose a framework based on potential subgraph rule and reasoning context enhancement to mitigate the challenges of sparsity. On one hand, we leverage reasoning context to enhance state information and the reasoning process; on the other hand, we design an action perceptron based on the importance of reasoning context to reduce the introduction of noisy triples. Additionally, we analyze the phenomenon of data augmentation introducing spurious paths, and further utilize data augmentation-based potential subgraph rules to guide the reasoning process. This dual mechanism demonstrates stronger robustness in addressing sparsity challenges and spurious paths. Diverse experiments demonstrate that our model outperforms the existing multi-hop reasoning models across five datasets. Our implementations will be publicly available at: https://github.com/jianruichen/PreKGR .},
  archive      = {J_KBS},
  author       = {Congcong Sun and Jianrui Chen and Deguang Chen and Junjie Huang},
  doi          = {10.1016/j.knosys.2025.114483},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. <em>KBS</em>, <em>330</em>, 114482. (<a href='https://doi.org/10.1016/j.knosys.2025.114482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful self-supervised approach for learning generalized graph representations, achieving remarkable advancements in recent years. However, most existing GCL methods ignore the noise of the augmented global structure and the dynamic change in training, and lack detailed consideration in calculating local structural homogeneity. These limitations may lead to the model’s insufficient performance in capturing fine-grained semantic features at the node level, making it difficult to fully explore the potential semantic associations between adjacent nodes. Meanwhile, on a global scale, there is also a lack of the ability to model complex topological structures. To this end, we propose a new multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. This method dynamically adjusts the global structure via graph reconstruction and adaptively learns node representations; Meanwhile, a mutual rectification module is designed to predict the support scores of neighbors relative to anchors and quantify each neighbor’s contribution to view agreement. Both reconstruction and rectification are integrated into the training objective and effectively capture the graph structure information from both global and local scales, improving the quality and robustness of graph representations. We conduct extensive experiments on three downstream tasks: node classification, node clustering, and link prediction. The experimental results demonstrate that our method outperforms existing GCL methods across multiple tasks and datasets, validating the effectiveness and generalizability of the proposed model.},
  archive      = {J_KBS},
  author       = {Dengdi Sun and Zhixiang Wu and Mingwei Cao and Zhifu Tao and Zhuanlian Ding},
  doi          = {10.1016/j.knosys.2025.114482},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114482},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P-EVFL: Efficient verifiable federated learning with privacy. <em>KBS</em>, <em>330</em>, 114480. (<a href='https://doi.org/10.1016/j.knosys.2025.114480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has recently become popular and widely used in various areas. However, it still faces challenges like the leakage of the client’s local model updates and the server forging aggregation results. To address these issues, we propose an efficient verifiable federated learning scheme with privacy (P-EVFL), which seeks to ensure privacy and verifiability with a lower overhead. Specifically, we first design a lightweight masking technique to protect the honest clients’ local model updates. Next, we introduce homomorphic hash functions to develop a verifiable method to ensure the integrity of the aggregation results. Besides, to reduce the overhead of the verification process, a verification algorithm based on a Merkle tree is proposed. We also conduct comprehensive experiments and compare our scheme with other state-of-the-art schemes. The experimental results show that in a scenario with 100 clients, our scheme reduces the computational overhead by up to 8.15 % and the communication overhead by up to 67.38 %.},
  archive      = {J_KBS},
  author       = {Juan Ma and Xiangshen Ma and Yuling Chen},
  doi          = {10.1016/j.knosys.2025.114480},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114480},
  shortjournal = {Knowl. Based Syst.},
  title        = {P-EVFL: Efficient verifiable federated learning with privacy},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to extract and aggregate contexts for link prediction in heterogeneous graphs. <em>KBS</em>, <em>330</em>, 114478. (<a href='https://doi.org/10.1016/j.knosys.2025.114478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many diverse real-world graph datasets are heterogeneous graphs, and link prediction on these graphs is a fundamental task. The current trends of link prediction on heterogeneous graphs emphasize leveraging contextual information from either a path between a source node and a target node, or a sub-graph sampled around these two nodes. However, these approaches face limitations in identifying only beneficial contextual nodes around source and target and then effectively aggregating the representations of these nodes for improving overall prediction accuracy. To address these limitations, we claim that carefully-extracted context nodes can aid in accurate link prediction, and these context nodes should be similar to a source node or a target node in a representation space. To this end, we propose a new link prediction framework LEACH which learns to extract the beneficial context nodes and to aggregate their representations in heterogeneous graphs. Specifically, our approach involves three steps to learn: (i) generating heterogeneity-aware representations of nodes in the heterogeneous graph, (ii) selecting the context nodes based on the relatedness to the source and target nodes; and (iii) aggregating the representations of the context nodes to obtain the source and target representations. Extensive experiments demonstrate that LEACH significantly outperforms existing baselines on three publicly available heterogeneous graph datasets. We provide analytical insights into the rationale behind the superior performance of LEACH on link prediction.},
  archive      = {J_KBS},
  author       = {Jimin Woo and Minbae Park and Hyunjoon Kim},
  doi          = {10.1016/j.knosys.2025.114478},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114478},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning to extract and aggregate contexts for link prediction in heterogeneous graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation. <em>KBS</em>, <em>330</em>, 114477. (<a href='https://doi.org/10.1016/j.knosys.2025.114477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the integration of advanced data analytics techniques within People Analytics and Human Resource Information Systems (HRIS), emphasizing their application in both organizational and sports performance contexts. By synthesizing Tournament Theory, Human Capital Theory, and Social Network Theory, this research provides a comprehensive framework for understanding skill dissemination, performance evaluation, and wage determination. Utilizing the NBA 2 K dataset, this study quantifies both tangible and intangible player attributes, incorporating digital engagement and social media metrics to enhance traditional performance metrics. Employing community detection algorithms and the Independent Cascade Model, the research uncovers hidden competencies and their influence on team dynamics and organizational effectiveness. The results contest established HRIS approaches, suggesting a holistic talent management strategy that takes into account the multifacetedness of skills propagation through networks. This work offers significant implications for HR professionals, providing novel insights into strategic HR planning, talent acquisition, and performance management in the digital age.},
  archive      = {J_KBS},
  author       = {Tianzi Zheng and Riyaz Sikora},
  doi          = {10.1016/j.knosys.2025.114477},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114477},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer. <em>KBS</em>, <em>330</em>, 114471. (<a href='https://doi.org/10.1016/j.knosys.2025.114471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied in optimization because of their flexibility and ability to address complex and high-dimensional problems. Nevertheless, they face persistent challenges, including susceptibility to local optima, limited parameter adaptability, and premature convergence. Leadership-based metaheuristics, in which leaders guide the search process, encounter additional difficulties such as limited exploration capacity, leader stagnation, and reduced diversity, often stemming from underutilization of data generated during the search. To overcome these limitations, this study proposes a reinforcement learning–based approach, RL-LGWO, which enhances the Grey Wolf Optimizer (GWO) by integrating multi-agent reinforcement learning. In RL-LGWO, agents share experiences to improve decision-making, and reinforcement learning is employed to decouple and adapt the leader update mechanism, thereby improving the exploration–exploitation balance and enabling leaders to dynamically escape local optima. The proposed method was evaluated against two GWO-enhancing algorithms, three RL-based GWO variants, PSO, WOA, and the original GWO across 23 well-known benchmark functions, in addition to the recent CEC2022 benchmark suite. Experimental results show that RL-LGWO achieved the best solutions on 17 of the 23 benchmark functions, with superior convergence speed and improved stability, while incurring only a minor runtime increase compared with the original GWO. Furthermore, on the CEC2022 suite, RL-LGWO outperformed competing algorithms on 10 of 12 test functions, underscoring its robustness and adaptability to recent and challenging benchmarks. Overall, the findings indicate that RL-LGWO delivers a substantive improvement over state-of-the-art alternatives and holds strong potential to advance leadership-based metaheuristics for a wide range of optimization problems.},
  archive      = {J_KBS},
  author       = {Afifeh Maleki and Mehdy Roayaei and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.114471},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment. <em>KBS</em>, <em>330</em>, 114470. (<a href='https://doi.org/10.1016/j.knosys.2025.114470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large language models (LLMs) has advanced natural language processing by improving contextual understanding and generalization abilities. However, despite these advances, determining event causality remains a challenging task. When LLMs are applied to this task, they frequently exhibit significant inconsistencies in recognizing causal representations, resulting in the phenomenon known as causal hallucinations. Specifically, LLMs perform well in predicting events with causal relationships but struggle with events without such relationships, frequently failing to achieve balanced performance across different causal scenarios. In this study, we propose MRBalance, a novel framework that uses role-based multi-agent debates to improve event causality identification. Our method transforms the task into a single-choice question-answering task, prompting LLM-based agents to engage in structured debates and justify their answers using their unique role-based perspectives. In addition, we introduce a mechanism for optimizing team members that selects the best agents to participate in the next debate when the debate rounds are lengthy. Extensive experiments on two benchmark datasets demonstrate significant performance improvements, highlighting the effectiveness of MRBalance in reducing causal hallucinations and increasing robustness.},
  archive      = {J_KBS},
  author       = {Xiang Zou and Xuanhong Li and Po Hu and Ming Dong},
  doi          = {10.1016/j.knosys.2025.114470},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114470},
  shortjournal = {Knowl. Based Syst.},
  title        = {MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIAFEx: An attention-based feature extraction method for medical image classification. <em>KBS</em>, <em>330</em>, 114468. (<a href='https://doi.org/10.1016/j.knosys.2025.114468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction techniques are crucial in medical image classification; however, classical feature extractors, in addition to traditional machine learning classifiers, often exhibit significant limitations in providing sufficient discriminative information for complex image sets. While Convolutional Neural Networks (CNNs) and Vision Transformer (ViT) have shown promise in feature extraction, they are prone to overfitting due to the inherent characteristics of medical imaging data, including small sample sizes or high intra-class variance. In this work, the Medical Image Attention-based Feature Extractor (MIAFEx) is proposed, a novel method that employs a learnable refinement mechanism to enhance the classification token within the Transformer encoder architecture. This mechanism adjusts the token based on learned weights, improving the extraction of salient features and enhancing the model’s adaptability to the challenges presented by medical imaging data. The MIAFEx output feature quality is compared against classical feature extractors using traditional and hybrid classifiers. Also, the performance of these features is compared against modern CNN and ViT models in classification tasks, demonstrating their superiority in accuracy and robustness across multiple complex medical imaging datasets. This advantage is particularly pronounced in scenarios with limited training data, where traditional and modern models often struggle to generalize effectively. The source code of this proposal can be found at github.com/Oscar-RamosS/Medical-Image-Attention-based-Feature-Extractor-MIAFEx .},
  archive      = {J_KBS},
  author       = {Oscar Ramos-Soto and Jorge Ramos-Frutos and Ezequiel Pérez-Zarate and Diego Oliva and Sandra E. Balderas-Mata},
  doi          = {10.1016/j.knosys.2025.114468},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114468},
  shortjournal = {Knowl. Based Syst.},
  title        = {MIAFEx: An attention-based feature extraction method for medical image classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling. <em>KBS</em>, <em>330</em>, 114454. (<a href='https://doi.org/10.1016/j.knosys.2025.114454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of supervised medical image segmentation models, relying on a large amount of labeled data is impractical in real-world situations. Semi-supervised learning approaches aim to alleviate this challenge using unlabeled data through pseudo-label generation. Yet, existing semi-supervised segmentation methods still suffer from noisy pseudo-labels and insufficient supervision within the feature space. To solve these challenges, this paper proposes a novel semi-supervised 3D medical image segmentation framework based on a dual-network architecture. Specifically, we investigate a Cross Consistency Enhancement module using both cross pseudo and entropy-filtered supervision to reduce the noisy pseudo-labels, while we design a dynamic weighting strategy to adjust the contributions of pseudo-labels using an uncertainty-aware mechanism (i.e., Kullback–Leibler divergence). In addition, we use a self-supervised contrastive learning mechanism to align uncertain voxel features with reliable class prototypes by effectively differentiating between trustworthy and uncertain predictions, thus reducing prediction uncertainty. Extensive experiments are conducted on three 3D segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed approach consistently exhibits superior performance across various settings (e.g., 89.95 % Dice score on left Atrial with 10 % labeled data) compared to the state-of-the-art methods. Furthermore, the usefulness of the proposed modules is further validated via ablation experiments. The code repository is available at https://github.com/AIPMLab/Semi-supervised-Segmentation .},
  archive      = {J_KBS},
  author       = {Yunyao Lu and Yihang Wu and Ahmad Chaddad and Tareef Daqqaq and Reem Kateb},
  doi          = {10.1016/j.knosys.2025.114454},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. <em>KBS</em>, <em>330</em>, 114452. (<a href='https://doi.org/10.1016/j.knosys.2025.114452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of transfer learning strategies to solve cross-domain fault diagnosis problems has achieved significant results. However, most existing multi-source domain generalization fault diagnosis methods use a single classifier or introduce auxiliary classifiers, focusing on learning domain-invariant features or global feature distribution matching. Furthermore, since the data distributions of different source domains may be significantly different, this may lose the data distribution information specific to each source domain. In addition, how to reduce the variation in risk between samples within the same domain training is also a challenging issue. Finally, it is also crucial to balance the predictive outputs of multiple classifiers to adapt them to the data distribution of the target domain. Based on the above challenges, this paper proposes a multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. Feature weakly decoupled mechanism is achieved by employing multiple classifiers and incorporating the variance of samples within the same sample domain as a penalty term. This reduces the model’s sensitivity to changes in the extreme distribution of samples within the domain. Classifier weakly decoupled mechanism, on the other hand, reduces the inter-domain risk variance by minimizing the loss of variance in the predicted output of the source domain classifiers. This improves the robustness of the model to inter-domain distributional changes and covariate changes. Experimental results on three datasets validate the effectiveness and general applicability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Yawei Sun and Hongfeng Tao and Vladimir Stojanovic},
  doi          = {10.1016/j.knosys.2025.114452},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114452},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing large language models for bitcoin time series forecasting. <em>KBS</em>, <em>330</em>, 114449. (<a href='https://doi.org/10.1016/j.knosys.2025.114449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.},
  archive      = {J_KBS},
  author       = {Owen Chaffard and Pablo Mollá and Marc Cavazza and Helmut Prendinger},
  doi          = {10.1016/j.knosys.2025.114449},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing large language models for bitcoin time series forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction. <em>KBS</em>, <em>330</em>, 114447. (<a href='https://doi.org/10.1016/j.knosys.2025.114447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality identification and extraction are crucial in understanding causal relationships in text. Current studies heavily rely on datasets annotated with causal relationships. However, acquiring such datasets poses a challenge due to substantial costs, hindering progress in this research field. To address this, we introduce CausalEnhance, a novel approach designed to bridge this gap by combining weakly-guided pre-training with external causal knowledge. Our method starts with a rule-based system that automates causal annotation, enriching external data with explicit causal knowledge and creating pseudo labels. These pseudo-labels are then incorporated into a weakly supervised pre-training framework. We introduce three innovative pre-training tasks: the Pre-training Causal Clues Fill-Mask task (PCM) to pinpoint causality origins, the Pre-training Causality Identification task (PCI) to capture general causal patterns, and the Pre-training Causality Extraction task (PCE) for understanding explicit causal pairs and inferring implicit ones. Our experiments, conducted across eight datasets in two languages, English and Chinese, demonstrate CausalEnhance’s effectiveness in both identifying and extracting causality, highlighting its potential as a robust method for textual causality analysis in different linguistic contexts.},
  archive      = {J_KBS},
  author       = {Meiyun Wang and Kiyoshi Izumi and Hiroki Sakaji},
  doi          = {10.1016/j.knosys.2025.114447},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114447},
  shortjournal = {Knowl. Based Syst.},
  title        = {CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis. <em>KBS</em>, <em>330</em>, 114446. (<a href='https://doi.org/10.1016/j.knosys.2025.114446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated domain generalization (FDG) as a solution to address the cross-client data heterogeneity problem in privacy-sensitive scenarios has drawn extensive attention in the field of intelligent fault diagnosis of industrial equipment in recent years. Nevertheless, most of the existing FDG-based diagnosis methods rely on client feature distribution alignment or data augmentation strategies, risking data leakage caused by the transmission of deep features and statistical information. To overcome the above-mentioned issues, a margin-guided parameter decoupling-consensus (MGPDC) framework is proposed to decouple the dependence of conventional federated domain generalization methods on features and data distributions and realize the extraction of common knowledge across clients. This framework initially employs a federated meta-learning-driven universal feature extractor to create a transferable shared feature space amidst heterogeneous client data, effectively enhancing the generalization ability of the model for unknown working conditions. Next, a parameter decoupling-consensus synergy (PDCS) mechanism is proposed. In this mechanism, an isolation module is established based on the consistency of parameter updates for parameter decoupling, effectively suppressing model update conflict. Subsequently, an implicit alignment mapping approach is devised for the screened parameters with strong consistency to achieve the extraction of cross-domain common knowledge. Then, an adaptive global margin guidance (AGMG) strategy is proposed to mitigate the interference of the blurred class boundaries during the federated process on common knowledge extraction. Finally, extensive experiments using real wind turbine gearbox data demonstrate the effectiveness and advancement of the MGPDC framework.},
  archive      = {J_KBS},
  author       = {Linhan Gou and Qikang Li and Baoping Tang and Xiaolong Zhang and Zihao Li and Yonggang Liu},
  doi          = {10.1016/j.knosys.2025.114446},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114446},
  shortjournal = {Knowl. Based Syst.},
  title        = {Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network to surrogate computational bone remodelling in the calcaneus. <em>KBS</em>, <em>330</em>, 114445. (<a href='https://doi.org/10.1016/j.knosys.2025.114445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a data-driven approach using surrogate models based on Multi-Layer Perceptrons to predict bone remodelling outcomes in the calcaneus, both with and without fractures. The objective is to develop and train a neural network that accurately captures the biomechanical factors influencing the problem and predicts the resulting bone density distribution in the calcaneus. Given the complexity of bone healing processes, a comprehensive dataset was collected to train and validate the models under two distinct scenarios: an intact calcaneus and a fractured calcaneus treated with a surgical screw. Key parameters of the surrogate model, namely, the number of hidden layers, hidden layer size, and activation function, were optimized to enhance model performance. Additionally, training parameters such as learning rate and batch size were tuned. The hyperbolic tangent activation function was found to yield a lower mean squared error compared to the rectified linear units. Larger batch sizes and learning rates were found to improve model performance. The neural network designed to predict bone density in the intact model outperformed the one used for the fractured calcaneus with a screw, largely due to the increased variability in the fractured data. When the fracture did not significantly alter the trabecular distribution, prediction accuracy improved. Finally, the structural response of the models was evaluated, and it was observed that the trabecular arrangement inferred by the neural network tended to produce less stiff responses compared to those from the finite element method, likely due to the smoother density field predicted by the network.},
  archive      = {J_KBS},
  author       = {Ana Pais and Jorge Lino Alves and Jorge Belinha},
  doi          = {10.1016/j.knosys.2025.114445},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114445},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network to surrogate computational bone remodelling in the calcaneus},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAT: Federated causal adversarial training. <em>KBS</em>, <em>330</em>, 114440. (<a href='https://doi.org/10.1016/j.knosys.2025.114440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference has been proven to be a crucial technique for improving the efficacy and explainability of adversarial training (AT). However, its applicability in the decentralized adversarial training paradigm has not been fully explored. Where one potential challenge is to apply the causal inference in the settings of non-independent and identically distributed (Non-IID) federated learning. In particular, the imbalanced data distributions among various clients will unavoidably hinder the efficacy and adaptability of causal inference. To address this issue, this paper proposes a novel yet practical method dubbed Federated Causal Adversarial Training (FCAT), which seeks to improve causal models via calibrated correction information. Additionally, we introduce a lightweight slack aggregation method aimed at addressing client model disparities and minimizing the communication overhead in each iteration. Extensive experimental results demonstrate that FCAT significantly improves the efficacy of causal models in federated adversarial training, and remarkably outperforms the current state-of-the-art (SOTA) competitors on multiple widely-adopted benchmarks.},
  archive      = {J_KBS},
  author       = {Yunhao Feng and Yanming Guo and Mingrui Lao and Yulun Wu and Yishan Li and Yuxiang Xie},
  doi          = {10.1016/j.knosys.2025.114440},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114440},
  shortjournal = {Knowl. Based Syst.},
  title        = {FCAT: Federated causal adversarial training},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem. <em>KBS</em>, <em>330</em>, 114439. (<a href='https://doi.org/10.1016/j.knosys.2025.114439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The polynomial robust knapsack problem (PRKP) is a variant of the classic knapsack problem by incorporating uncertain costs and benefits from item combinations, leading to a nonlinear objective function and exponential solution space. These complexities make the PRKP suitable for real-world scenarios where interactions between items unpredictably impact outcomes. However, existing algorithms struggle to efficiently solve large instances of the PRKP due to its computational complexity. Therefore, this paper presents an iterative heuristic algorithm leveraging a neural network (NN) to address the PRKP, reducing the solution space and enabling efficient resolution of subproblems. The framework integrates an NN trained in two steps: general training and fine-tuning. The trained model is then embedded in the iterative heuristic algorithm to tackle the PRKP. A synthetic dataset comprising 2500 instances, ranging from 100 to 1500 items, is created to train the NN. Comparative evaluations are conducted using 1600 benchmark instances from the literature and 140 larger instances containing between 2000 and 15,000 items. We compare our approach against two state-of-the-art algorithms for the PRKP: a genetic algorithm and a random forest-based heuristic. Computational results demonstrate that the proposed algorithm outperforms the genetic algorithm, providing superior solution quality with significantly reduced computing times. Meanwhile, against random forest-based heuristic, it delivers better solution quality with only a moderate increase in computing time. For larger instances, it maintains its advantage in solution quality while remaining computationally efficient. These results highlight the algorithm’s scalability, effectiveness, and potential to address the PRKP.},
  archive      = {J_KBS},
  author       = {José González-Cortés and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114439},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114439},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interplay between bayesian neural networks and deep learning: A survey. <em>KBS</em>, <em>330</em>, 114438. (<a href='https://doi.org/10.1016/j.knosys.2025.114438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning models have seen significant success across various domains, their black-box learning nature and lack of interpretability affect their reliability in safety-critical applications like medical diagnostics and autonomous vehicles. In an attempt to address these limitations, Bayesian neural networks (BNNs) offer a promising alternative by incorporating uncertainty estimation into model predictions, enhancing transparency and decision-making. However, BNN development has primarily focused on efficient, high-fidelity approximate inference and guaranteed convergence in asymptotic settings. These are unsuitable for modern high-dimensional, multi-modal, and non-asymptotic deep learning applications, undermining their theoretical advantages. To bridge this gap, this paper provides in-depth reviews on how approximate Bayesian inference leverages deep learning optimization to achieve high efficiency and fidelity in high-dimensional spaces and multi-modal loss landscapes. It also reconciles Bayesian consistency with generalization objectives in non-asymptotic settings and investigates the generalization capabilities of BNNs. Additionally, this survey examines the often-overlooked expressiveness of BNNs, emphasizing how weight uncertainty and the absence of in-between uncertainty affect their performance. This survey aims to inspire BNN practitioners to adopt a deep learning perspective and offer valuable insights to propel further advancements in the field.},
  archive      = {J_KBS},
  author       = {Yinsong Chen and Samson S. Yu and Zhong Li and Jason K. Eshraghian and Chee Peng Lim},
  doi          = {10.1016/j.knosys.2025.114438},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114438},
  shortjournal = {Knowl. Based Syst.},
  title        = {Interplay between bayesian neural networks and deep learning: A survey},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TWDT: Training-free word-level controllable diffusion model for text generation. <em>KBS</em>, <em>330</em>, 114437. (<a href='https://doi.org/10.1016/j.knosys.2025.114437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controlled text generation (CTG) methods typically require the training of additional components, whereas diffusion models have already achieved fine control in image generation by adjusting latent feature information during the inference process. However, existing diffusion models still face issues such as “attribute leakage” and “overgeneration” when applied to text generation, leading to generated texts lacking precise control. To address these problems, we propose a training-free word-level controllable diffusion language network (TWDT). This network achieves fine-grained control of text generation by adjusting latent space features during the inference process. Specifically, TWDT introduces an Alignment and Word Evaluation (AWE) module, which ensures accurate mapping of the text to a predefined set of feature words through syntactic segmentation and multi-level semantic alignment. At the same time, a similarity threshold filtering mechanism is applied to inject Gaussian noise into low-consistency nodes, ensuring semantic consistency and stability during generation. To evaluate the rigor and accuracy of the model, we have developed a high-quality multi-disease dental diagnostic dataset, all of which are annotated by experienced dental experts, serving as the benchmark for model evaluation. Experimental results show that TWDT outperforms existing diffusion models in terms of generation accuracy and rigor.},
  archive      = {J_KBS},
  author       = {Nan Gao and Yangjie Lu and Peng Chen and Guodao Sun and Ronghua Liang and Yilong Zhang},
  doi          = {10.1016/j.knosys.2025.114437},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114437},
  shortjournal = {Knowl. Based Syst.},
  title        = {TWDT: Training-free word-level controllable diffusion model for text generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network. <em>KBS</em>, <em>330</em>, 114436. (<a href='https://doi.org/10.1016/j.knosys.2025.114436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern vehicles depend on the Controller Area Network (CAN) for electronic control unit (ECU) communication, but its inherent vulnerabilities necessitate robust intrusion detection systems (IDS). Current machine learning and deep learning IDS solutions struggle with limited labeled data, class imbalances, and costly data collection processes. Few-shot learning, effective with few labeled samples, remains underexplored for in-vehicle networks (IVNs) despite its potential in data-scarce automotive cybersecurity scenarios. To bridge this gap, we introduce the first few-shot learning approach for multi-class intrusion detection in IVNs, leveraging a novel, lightweight Convolutional Anomaly Transformer. By integrating a 1D convolutional layer with an Anomaly Transformer, our model effectively classifies diverse attack types with minimal training data, mitigating class imbalance. Experiments on the widely-used real-world Car Hacking dataset, the complex ROAD dataset, and the distinct CAN-ML dataset validate its efficacy. On the Car Hacking dataset, we achieve an exceptional F1 score of 0.9994 with only 2 % of training data, improving to 0.9999 with 10 %. On the challenging ROAD dataset, characterized by diverse attacks and high variability, the model achieves an F1 score of up to 0.9980 using just 10 % of training data. Demonstrating strong generalization capabilities, the model also attains an impressive F1 score of 0.9918 on the CAN-ML dataset, which features entirely different vehicles and attack distributions. Furthermore, the lightweight architecture of our proposed IDS enables practical deployment in resource-constrained automotive environments.},
  archive      = {J_KBS},
  author       = {Nguyen Thanh Minh Duy and Truong Hoang Bao Huy and Pham Van Phu and Tien-Dat Le and Daehee Kim},
  doi          = {10.1016/j.knosys.2025.114436},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterophily-aware dynamic hypergraph for semi-supervised classification. <em>KBS</em>, <em>330</em>, 114435. (<a href='https://doi.org/10.1016/j.knosys.2025.114435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph neural networks, as high-order graph neural networks, excel in handling intricate relationships within non-Euclidean infinite-dimensional spaces. However, conventional homophily assumption-based hypergraph methods exhibit limited effectiveness in semi-supervised classification scenarios involving heterophily problem, where neighboring nodes often belong to dissimilar categories. To address this challenge, this paper proposes a Heterophily-Aware Dynamic Hypergraph (HADHG) framework grounded in heterophily assumption through label domain analysis. The framework comprises three key components: a hypergraph-oriented label propagation method for deriving class-specific label features, a label tensor construction approach characterizing node-level heterophily intensity via 2D tensors, and a center attention mechanism that dynamically optimizes hypergraph structures. By enabling nodes to dynamically reconfigure the local graph structure based on microscopic heterophily intensity, HADHG effectively mitigates heterophily interference. Comprehensive experiments using real-flight data from Unmanned Aerial Vehicles and the public Gear dataset highlight the framework’s superiority over state-of-the-art methods. The codes and datasets are openly available at https://github.com/DL-LEO/HADHG .},
  archive      = {J_KBS},
  author       = {Shaojun Liang and Ying Zheng and Housheng Su and Lei Zhang and Yi Yang},
  doi          = {10.1016/j.knosys.2025.114435},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114435},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterophily-aware dynamic hypergraph for semi-supervised classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining. <em>KBS</em>, <em>330</em>, 114434. (<a href='https://doi.org/10.1016/j.knosys.2025.114434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have displayed their effectiveness in predicting sequence modelling compared to various systems. Nevertheless, some limitations of existing methods are the demand for enormous databases, computational expense, and the risk of overfitting. To address these problems, this study proposes a novel DL technique using knowledge distillation and sequence illness pattern recognition from medical databases. Firstly, the input data is pre-processed using the data cleaning method. The size of the sequence dataset and the duration of the sequential patterns are both considered during the process of using PREFIXSPAN to manage long sequential patterns. In the proposed strategy, a lightweight student network is employed to train a strong teacher network, which is produced by a Knowledge Distillation framework. A teacher network is assessed by the Attention Based Densely Connected Capsule Model (Attention-DC). An efficient, low-weight Depthwise Separable Convolutional Neural Network (DSCNN) model is then chosen as the student network. This study uses three datasets to solve enormous database issues. The KD helps prevent the student model from overfitting to noise or specific patterns in the training data. The Improved Coot Optimization Algorithm (ICOA) is applied to adjust the parameter. The hyperparameters used to optimize the performance of the proposed model are Epochs (300), learning rate (0.001), and batch size (32), respectively. The experiments use the resources of three different datasets, and Python is employed to analyze the results. The proposed technique achieves accuracy of 99.512 %, 99.329 % and 99.351 % for the heart disease, cardiovascular disease, and Diabetes dataset.},
  archive      = {J_KBS},
  author       = {Dinesh Kumar Bhawnani and Sunita Soni and Arpana Rawal},
  doi          = {10.1016/j.knosys.2025.114434},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural chain of thoughts for radiology education. <em>KBS</em>, <em>330</em>, 114433. (<a href='https://doi.org/10.1016/j.knosys.2025.114433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology education requires trainees to develop both perceptual and interpretive expertise. However, refinement of these skills is often impeded by the limited availability of mentorship, a consequence of the demanding schedules of experienced radiologists. This lack of personalized guidance makes it difficult for learners to recognize the mistakes they make, understand why those errors occurred and how to refine their perceptual processes. Many of these errors arise from subtle differences in visual attention, such as failing to fixate on an abnormality, allocating an insufficient fixation time, or overlooking an abnormality despite scanning the correct region. Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been explored for radiology tasks, they often struggle to detect such fine-grained multimodal variations, particularly when comparing gaze behavior between experts and trainees. To address these limitations, we introduce Structural Chain of Thoughts (SCoT), a novel framework that enhances LLMs and LMMs sensitivity to nuanced multimodal differences by structuring gaze data and radiology report into a thought graph. By leveraging a structural prior, SCoT systematically identifies key perceptual and interpretive discrepancies, allowing models to provide targeted, context-aware feedback. This structured approach not only highlights missed findings but also explains the reasoning behind perceptual errors, turning them into learning opportunities. Applied within radiology education, SCoT bridges the gap between expert and novice performance, offering a scalable solution for AI-driven diagnostic training. We further contribute a simulated dataset of perceptual errors in chest X-ray (CXR) interpretation, facilitating future research into multimodal reasoning and AI-driven medical education. Unlike conventional Chain-of-Thought approaches, SCoT explicitly integrates gaze and textual information into a structured reasoning process, yielding interpretable, fine-grained, and personalized feedback tailored to the unique needs of radiology training. The code and data will be available here: GitHub Repository .},
  archive      = {J_KBS},
  author       = {Akash Awasthi and Brandon Chung and Anh Mai Vu and Saba Khan and Ngan Le and Zhigang Deng and Rishi Agrawal and Carol C. Wu and Hien Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114433},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural chain of thoughts for radiology education},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing. <em>KBS</em>, <em>330</em>, 114431. (<a href='https://doi.org/10.1016/j.knosys.2025.114431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables the efficient execution of compute-intensive tasks by offloading them to edge servers. However, frequent user mobility in 5 G urban networks leads to increased latency, energy consumption, and resource wastage due to continuous handovers. To address these challenges, Energy Efficient Communication and Optimal Offloading Network, a framework is proposed that combines user mobility prediction and hybrid optimization for task offloading. Energy Efficient Communication and Optimal Offloading Network utilizes a modified Long Short-Term Memory model to predict user movement with high accuracy, achieving an accuracy improvement from 65 % to 95 % over ten iterations. Additionally, a Hybrid Grey Wolf Optimization Algorithm optimizes task allocation, resulting in a 30 % reduction in energy consumption and a 25 % improvement in server utilization compared to baseline methods. The framework achieves latency as low as 5 milliseconds for augmented reality tasks while maintaining scalability in high-traffic 5 G environments. The proposed model also outperforms baseline approaches in terms of task completion time, throughput, and communication efficiency, and it achieves a 94.5 % offloading success rate and 98 % augmented reality delay compliance. The proposed model provides a scalable and useful solution for real-time Augmented Reality by combining energy-constrained task allocation with mobility-aware predictions.},
  archive      = {J_KBS},
  author       = {Anitha Jebamani Soundararaj and Godfrey Winster Sathianesan},
  doi          = {10.1016/j.knosys.2025.114431},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified multi-subgraph pre-training framework for spatio-temporal graph. <em>KBS</em>, <em>330</em>, 114428. (<a href='https://doi.org/10.1016/j.knosys.2025.114428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph (STG) learning has shown great potential in capturing complex spatio-temporal dependencies and has achieved significant success in various fields such as traffic flow prediction, climate forecasting, and epidemiological spread research. By learning general features from spatio-temporal graphs, pre-trained graph models can capture hidden semantic information in the data, thereby enhancing the learning effect of downstream tasks and improving overall model performance. However, most existing spatio-temporal graph learning methods use the entire graph for training, which may not fully capture local structure and feature information. In addition, existing methods usually adopt sequence modeling techniques without fully considering the time decay effect, i.e., the need to apply decaying attention to distant time steps. To address these issues, this paper proposes a u nified dual-phase m ulti- s ubgraph pre-training s patio- t emporal graph framework (UMSST). Specifically, in the first phase, the framework learns the global representation of the spatio-temporal graph and locates key graph nodes, while learning the “unit representations” of these key nodes. In the second phase, multiple spatio-temporal subgraphs are constructed based on these “unit representations” to further capture the implicit encoding information of more general features around the corresponding subgraphs, thereby helping the model make full use of general features. Experimental results on real datasets show that the proposed pre-trained spatio-temporal graph framework significantly improves the performance of downstream tasks and demonstrates its effectiveness in comparison with recent strong baseline models.},
  archive      = {J_KBS},
  author       = {Mingze Zhong and Zexuan Long and Xinglei Wang and Tao Cheng and Meng Fang and Ling Chen},
  doi          = {10.1016/j.knosys.2025.114428},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114428},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified multi-subgraph pre-training framework for spatio-temporal graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provide explainable clues: A generative traceable method for knowledge graph completion. <em>KBS</em>, <em>330</em>, 114426. (<a href='https://doi.org/10.1016/j.knosys.2025.114426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a G enerative T raceable M ethod, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.},
  archive      = {J_KBS},
  author       = {Ziqi Ma and Jinpeng Li and Hang Yu},
  doi          = {10.1016/j.knosys.2025.114426},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114426},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provide explainable clues: A generative traceable method for knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability. <em>KBS</em>, <em>330</em>, 114405. (<a href='https://doi.org/10.1016/j.knosys.2025.114405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents xLLMBench, a transparent, decision-centric benchmarking framework that empowers decision-makers to rank large language models (LLMs) based on their preferences across diverse, potentially conflicting performance and non-performance criteria, e.g., domain accuracy, model size, energy consumption, CO 2 emissions. Existing LLM benchmarking methods often rely on individual performance criteria (metrics) or human feedback, so methods systematically combining multiple criteria into a single interpretable ranking lack. Methods considering human preferences typically rely on direct human feedback to determine rankings, which can be resource-intensive and not fully aligned with application-specific requirements. Motivated by current limitations of LLM benchmarking, xLLMBench leverages multi-criteria decision-making methods to provide decision-makers with the flexibility to tailor benchmarking processes to their requirements. It focuses on the final step of the benchmarking process (robust analysis of benchmarking results) which in LLMs’ case often involves their ranking. The framework assumes that the selection of datasets, metrics, and LLMs involved in the experiment is conducted following established best practices. We demonstrate xLLMBench’s usefulness in two scenarios: combining LLM results for one metric across different datasets and combining results for multiple metrics within one dataset. Our results show that while some LLMs maintain stable rankings, others exhibit significant changes when correlated datasets are removed, when the focus shifts to contamination-free datasets or fairness metrics. This highlights that LLMs have distinct strengths/weaknesses, going beyond overall performance. Our sensitivity analysis reveals robust rankings, while the diverse visualizations enhance transparency. xLLMBench can be used with existing platforms to support transparent, reproducible, and contextually-meaningful LLM benchmarking.},
  archive      = {J_KBS},
  author       = {Ana Gjorgjevikj and Ana Nikolikj and Barbara Koroušić Seljak and Tome Eftimov},
  doi          = {10.1016/j.knosys.2025.114405},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114405},
  shortjournal = {Knowl. Based Syst.},
  title        = {User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRTF: A new tensor factorization for irregular multidimensional data recovery. <em>KBS</em>, <em>330</em>, 114372. (<a href='https://doi.org/10.1016/j.knosys.2025.114372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorizations, although serving as paramount tools for exploiting prior knowledge of multidimensional data, are unsuitable for emerging irregular multidimensional data with the arbitrary shape spatial domain (i.e., spatial-irregular tensor), such as superpixels and spatial transcriptomics. Developing new tensor factorizations suitable for spatial-irregular tensors poses a compelling challenge. To meet this challenge, we introduce a novel Irregular Tensor Factorization (IRTF), which can fully capture the intrinsic spatial and channel information behind the spatial-irregular tensor. Concretely, a spatial-irregular tensor can be decomposed into the product of an intrinsic regular tensor, learnable channel transform matrices, and a learnable spatial transform matrix. Accompanying IRTF, we suggest the Total Variation on Channel and Spatial Transforms (TV-CST) to exploit the local information of spatial-irregular tensors, which is hardly excavated by traditional total variation methods. Combining the proposed IRTF and TV-CST, we built a spatial-irregular tensor recovery model. Extensive experiments on real-world spatial-irregular tensors demonstrate the promising performance of our IRTF and its significant advantages on downstream tasks.},
  archive      = {J_KBS},
  author       = {Jin-Yu Xie and Hao Zhang and Xi-Le Zhao and Yi-Si Luo},
  doi          = {10.1016/j.knosys.2025.114372},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114372},
  shortjournal = {Knowl. Based Syst.},
  title        = {IRTF: A new tensor factorization for irregular multidimensional data recovery},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Creative style transfer for image stylization via learning neural permutation. <em>KBS</em>, <em>330</em>, 114368. (<a href='https://doi.org/10.1016/j.knosys.2025.114368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating novel artistic styles from a single style poses a significant challenge for traditional style transfer techniques, which typically focus on emulating the given style without introducing novel, surprising and value elements—fundamental criteria for evaluating creativity. In this paper, we propose Creative Style transFer (CSFer), a new style transfer approach for producing creative artistic styles. We first introduce a neural permutation network (PerNet) to rearrange the feature maps of a single-style image, thus producing new style features. These features are then transferred to the feature maps of a content image, yielding stylized outputs. To evaluate creativity, we employ metrics encompassing style perception distance and artistic aesthetics to assess novelty, surprise, and aesthetic value, respectively. Using this evaluation, we select the most creative style from various stylized results generated via random permutation matrices and an input style. Finally, we effectively train PerNet using both the original and selected creative styles. Extensive experimental results demonstrate that CSFer can generate creative stylized results. Furthermore, CSFer exhibits robust generalization capabilities by seamlessly inserting PerNet into existing style transfer methods.},
  archive      = {J_KBS},
  author       = {Shimin Li and Zedong Zhang and Gan Sun and Li-Wei H. Lehman and Jian Yang and Jun Li},
  doi          = {10.1016/j.knosys.2025.114368},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114368},
  shortjournal = {Knowl. Based Syst.},
  title        = {Creative style transfer for image stylization via learning neural permutation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-driven deep learning network for image splicing forgery detection. <em>KBS</em>, <em>330</em>, 114365. (<a href='https://doi.org/10.1016/j.knosys.2025.114365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image splicing is a widely used technique for manipulating images in various social activities. Detecting splicing forgery is crucial in digital forensics to identify malicious image manipulation and protect information security. However, existing methods for detecting splicing forgery typically learn features in the spatial domain and struggle to effectively capture subtle features indicative of forgery, resulting in insufficient image splicing forgery detection accuracy. To address this challenge, we propose a novel deep-learning network named the frequency-driven deep-learning network (FreNet). Specifically, FreNet comprises three innovative modules: the frequency learnable module (FLM), the spatial-aware frequency learning module (SFLM), and the high-level feature-enhancement module (HFEM). The FLM effectively extracts high- and low-frequency features, thus enhancing frequency-domain representation and capturing subtle tampered features in splicing forgery images. The SFLM utilizes spatial information to guide frequency feature learning, thus enabling spatial-aware frequency feature learning. The HFEM enhances rich contextual and high-level semantic information through multilevel and multipath extraction and fusion. Extensive experiments on five benchmark datasets indicate that FreNet can achieve superior performance. Additionally, robustness experiments demonstrate the superior robustness of FreNet against various common attacks.},
  archive      = {J_KBS},
  author       = {Enji Liang and Kuiyuan Zhang and Zhongyun Hua and Xiaohua Jia},
  doi          = {10.1016/j.knosys.2025.114365},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114365},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-driven deep learning network for image splicing forgery detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="matdes">MATDES - 73</h2>
<ul>
<li><details>
<summary>
(2025). Unveiling microstructure evolution and mechanical properties of silicide-strengthened (TiZrHfNb)100-xSix (x = 0, 1, 5, 7, 10 and 15) refractory high-entropy alloys. <em>MATDES</em>, <em>259</em>, 114825. (<a href='https://doi.org/10.1016/j.matdes.2025.114825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ductile TiZrHfNb refractory high-entropy alloy is selected to form silicide-strengthened (TiZrHfNb) 100-x Si x (x = 0, 1, 5, 7, 10 and 15, in at. %) alloys, and the influence of Si content on the microstructure and mechanical properties was systematically investigated. The solidification microstructure and the type of silicide show strong dependence on Si content from 1 % to 15 %, with the former changing from hypoeutectic to hypereutectic structure, and the latter evolving from M 3 Si-type to tetragonal-M 5 Si 3 -type silicide, and finally to the co-existence of both tetragonal- and hexagonal- M 5 Si 3 -type silicide. The formation of silicide phase enhances the strength both at the ambient and elevated temperatures, and a significant improvement of peak compressive strength from 221.3 MPa to 511.59 MPa at 800℃ was obtained after alloying 15 % Si to the prototype TiZrHfNb alloy. It was found that heterodeformation-induced strengthening, resulting from dislocation pile-ups at phase boundaries, was responsible for the enhancement in the strength. During hot deformation, the flow stress begins to decrease after reaching the peak value due to the presence of the dynamic recovery and dynamic recrystallization, which becomes more pronounced at higher Si content.},
  archive      = {J_MATDES},
  author       = {Xiaolei Han and Binbin Liu and Shuyi Xie and Cong Zhang and Li Huang and Wei Liu and Huaping Xiong and Feng Ye},
  doi          = {10.1016/j.matdes.2025.114825},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114825},
  shortjournal = {Mater. Des.},
  title        = {Unveiling microstructure evolution and mechanical properties of silicide-strengthened (TiZrHfNb)100-xSix (x = 0, 1, 5, 7, 10 and 15) refractory high-entropy alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigation on indentation scaling relationships of ITO thin films considering the indenter tip rounding defect. <em>MATDES</em>, <em>259</em>, 114818. (<a href='https://doi.org/10.1016/j.matdes.2025.114818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the applications of indium tin oxide (ITO) films, higher measurement requirements are implemented due to the significant effects of more complicated stress states and limitations of testing conditions on the mechanical properties. In this work, the effect of the tip bluntness on indentation responses and scaling relationships for film/substrate composite systems is investigated via finite-element (FE) simulations and dimensional analysis. A novel indentation method is proposed to measure the intrinsic elastic modulus of thin films based on the scaling relationship among the curvature of the loading segment in P - h curves and material properties. FE simulations indicate the significant effect of tip bluntness on indentation responses. However, the curvature is essentially independent of the dimensionless parameter of h m / t . Furthermore, the tilt effect during the direct calibration procedure is corrected through spatial mapping transformation of atomic force microscopy data. Herein, the measured tip rounding radius fitted by 2D profile and 3D topography are 70 ± 4.8 nm and ∼72.83 nm, respectively. The indentation data acquired with the actual Berkovich indenter are used to verify the scaling relationships. The elastic modulus of ITO films is calculated as ∼135.26 GPa, and the measured error is only ∼3.59 %.},
  archive      = {J_MATDES},
  author       = {Zhaoxin Wang and Lijia Li and Zongyang Zhang and Wei Ji and Ming Li and Xiangyu Zong and Cong Li and Han Wang and Jibing Wang},
  doi          = {10.1016/j.matdes.2025.114818},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114818},
  shortjournal = {Mater. Des.},
  title        = {Investigation on indentation scaling relationships of ITO thin films considering the indenter tip rounding defect},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ZnO@MXene nanoplatform for near infrared induced elimination of drug resistant bacteria and acceleration of infected wound healing. <em>MATDES</em>, <em>259</em>, 114816. (<a href='https://doi.org/10.1016/j.matdes.2025.114816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-resistant bacterial wound infections, especially those caused by methicillin-resistant Staphylococcus aureus (MRSA), pose a critical clinical challenge with limited effective therapeutic options. Here, we report a photothermally responsive nanoplatform, (ZWMx), engineered via hydrothermal synthesis to integrate efficient photothermal conversion, reactive oxygen species generation, and bacterial membrane disruption. The composite leverages the broad absorption in the near infrared region and excellent electrical conductivity of tungsten carbide MXene to overcome the photoinstability of ZnO, achieving a photothermal conversion efficiency of approximately 29.78 % and strong catalytic activity through reactive oxygen species. Upon irradiation at 808 nm, ZWMx rapidly eliminates over 90 % of MRSA in vitro within five minutes and disrupts established biofilms, indicating a synergistic and multifaceted bactericidal mechanism. In vivo , ZWMx promotes near-complete healing of MRSA-infected wounds within twelve days, with minimal thermal damage to surrounding tissues, high biocompatibility, and increased expression of vascular endothelial growth factor receptor one, suggesting enhanced angiogenesis. These findings establish a light-responsive therapeutic strategy for the targeted elimination of drug-resistant infections and effective stimulation of wound repair, providing a promising alternative to conventional antibiotic therapies.},
  archive      = {J_MATDES},
  author       = {Ruofeng Yin and Enoch Obeng and Zhixing Li and Akmal Ergashev and Wei Wang and Rongbing Chen and Wei Wu and Da Sun and Qingqing Yao and Wencan Wu and Yunzhong Zhan},
  doi          = {10.1016/j.matdes.2025.114816},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114816},
  shortjournal = {Mater. Des.},
  title        = {ZnO@MXene nanoplatform for near infrared induced elimination of drug resistant bacteria and acceleration of infected wound healing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Patterned preparation of high-quality graphene film based on solution coating. <em>MATDES</em>, <em>259</em>, 114811. (<a href='https://doi.org/10.1016/j.matdes.2025.114811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphene has excellent electronic mobility, high electrical conductivity, and strong thermal conductivity. These properties make it suitable for use in electronic devices, sensors, and energy storage systems. However, current methods for producing graphene films face several problems. They are often expensive, require specific substrates, and have low success rates during transfer. These issues limit the large-scale use of graphene films. In this study, we propose a low-cost method to prepare graphene films. The method uses a flexible polyimide (PI) mask. Laser etching is used to create specific patterns on the PI mask. Then, a printing technique is applied to deposit graphene films onto quartz substrates. Compared to traditional approaches, this method is cheaper, works with various substrates. We used systematic characterization to evaluate the method. The results show that it can produce uniform and high-quality graphene films. We also studied the effects of film thickness, substrate treatment, and vacuum annealing on film performance. Hydrophilic treatment improves the dispersion of the graphene slurry. This helps the film become more uniform and improves its adhesion to the substrate. Vacuum annealing removes some dopants and makes the film cleaner. This method provides a promising solution for low-cost and large-scale production of graphene films.},
  archive      = {J_MATDES},
  author       = {Junwei Yin and Shuai Deng and Yuchang Zhang and Yunxian Cui and Mingfeng E},
  doi          = {10.1016/j.matdes.2025.114811},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114811},
  shortjournal = {Mater. Des.},
  title        = {Patterned preparation of high-quality graphene film based on solution coating},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive framework to study the influence of beam shaping in laser metal fusion processes. <em>MATDES</em>, <em>259</em>, 114805. (<a href='https://doi.org/10.1016/j.matdes.2025.114805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beam shaping is considered a technology capable of dramatically improving quality and robustness of Laser Metal Fusion (LMF) processes. However, systematic investigations of its effects on melt-pool dynamics, temperature field and microstructure are still required. In this work, we propose an integrated approach combining a Computational Fluid Dynamics (CFD) model, in-situ temperature measurements and metallographic analysis to explore programmable ring beam profiles, ranging from Gaussian-dominant to ring-dominant configurations. This method, initially proposed on Ti-6Al-4V bead-on-plate tracks, validates melt-pool temperatures measured in-process by a dual-wavelength pyrometer against CFD predictions, which are in turn validated with metallographic cross-sections. Ring modes lowered peak temperature by up to 35 %, transforming deep-narrow pools (aspect ratio ≈0.9) into shallow-wide ones (≈0.4). This suppressed humping at line energies ≥ 0.28 J mm − 1, whereas lower energies produced only superficial melting. Simulations matched pyrometer data within 5 % whenever pool width equalled the pyrometers’ sensing spot; all tracks solidified into ultrafine α with retained β, independent of beam mode. Therefore, the combination of in-situ, ex-situ and CFD tools offers a practical workflow for assisting data-driven process optimization and can be easily extended to other LMF processes, with its potential implementation in industrial Laser Powder Bed Fusion.},
  archive      = {J_MATDES},
  author       = {Marida Pontrandolfi and Linda Squillaci and Jonas Olsson and Pradip Aryal and Robert Pederson and Isabelle Choquet and Antonio Ancona},
  doi          = {10.1016/j.matdes.2025.114805},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114805},
  shortjournal = {Mater. Des.},
  title        = {A comprehensive framework to study the influence of beam shaping in laser metal fusion processes},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electrospun P(VDF-TrFE)/ceria nanoparticle scaffolds for skeletal muscle regeneration. <em>MATDES</em>, <em>259</em>, 114804. (<a href='https://doi.org/10.1016/j.matdes.2025.114804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volumetric muscle loss (VML) presents a significant clinical challenge due to the limited regenerative capacity of skeletal muscle. Piezoelectric scaffolds have shown promise in enhancing muscle repair by converting mechanical cues into bioelectric signals. In this study, we investigate the regenerative potential of electrospun scaffolds composed of poly(vinylidene fluoride-trifluoroethylene) [P(VDF-TrFE)] and polycaprolactone (PCL), with or without cerium dioxide nanoparticles (Ce NPs), in a VML mouse model. Hyaluronic acid functionalization was employed to improve scaffold biocompatibility. In vitro experiments confirmed the biocompatibility of these scaffolds, while in vivo assessments over eight weeks demonstrated significant efficacy in restoring muscle function. Compared with PCL-Ce scaffolds, mice implanted with piezoelectric scaffolds exhibited faster grip strength recovery, more mature muscle regeneration, a more hierarchical arrangement of muscle fibers, and increased fiber diameter. Additionally, the antioxidant properties of Ce NPs reduced adipocyte infiltration and excessive collagen deposition and were associated with enhanced angiogenesis. Grip strength measurements further highlighted the superior regenerative performance of P(VDF-TrFE) scaffolds combined with Ce NPs. Overall, these findings underscore the potential of piezoelectric scaffolds integrated with antioxidants in promoting structural and functional muscle regeneration following VML.},
  archive      = {J_MATDES},
  author       = {Shengjing Xu and Muge Gu and Yihui Zhang and Yuanye Guan and Wei Yu and Xiangqi Zhang and Liyuan Kang and Zhen Zeng and Yanjie He and Wei-En Yuan},
  doi          = {10.1016/j.matdes.2025.114804},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114804},
  shortjournal = {Mater. Des.},
  title        = {Electrospun P(VDF-TrFE)/ceria nanoparticle scaffolds for skeletal muscle regeneration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crashworthiness of antiprism thin-walled structures under quasi-static and dynamic loading. <em>MATDES</em>, <em>259</em>, 114802. (<a href='https://doi.org/10.1016/j.matdes.2025.114802'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the quasi-static and dynamic crushing behavior of a novel antiprism thin-walled structure designed to enhance energy absorption for crashworthiness applications. Unlike conventional cylindrical, polygonal, and origami-inspired tubes, which do not fully exploit wall folding to generate plastic hinges, the antiprism configuration promotes the formation and propagation of multiple plastic hinge lines, enabling stable progressive collapse and extended plateau stages. The structures were fabricated from 316L stainless steel using laser powder bed fusion and evaluated through quasi-static compression, Split Hopkinson Pressure Bar tests, and finite element simulations with the Johnson–Cook model. Compared with conventional counterparts of equal mass and thickness, the antiprism tubes achieved 6.4–14 % higher specific energy absorption (SEA), 7–79 % higher crushing force efficiency (CFE), and 7–68 % lower undesired load-carrying capacity (ULC). Under dynamic impact, they also exhibited the lowest initial peak crushing force. These results highlight the antiprism design as a lightweight and efficient solution for energy-absorbing components in sandwich panels and protective liners.},
  archive      = {J_MATDES},
  author       = {Bin Xu and Wenjun Bai},
  doi          = {10.1016/j.matdes.2025.114802},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114802},
  shortjournal = {Mater. Des.},
  title        = {Crashworthiness of antiprism thin-walled structures under quasi-static and dynamic loading},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based multimodal learning for predicting mechanical properties in heat-treated stainless steel. <em>MATDES</em>, <em>259</em>, 114800. (<a href='https://doi.org/10.1016/j.matdes.2025.114800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting mechanical properties of heat-treated materials is critical for intelligent process control and advanced manufacturing. This study proposes a Transformer-based multimodal learning framework for predicting the hardness and wear behavior of carburized steel after vacuum carburizing. By integrating microstructural images, material compositions, and process parameters, the proposed model effectively captures complex cross-modal relationships. Experimental results show that the multimodal model achieves high prediction accuracy, with an R 2 of 0.98 and MAE of 5.23 HV for hardness prediction. Furthermore, Variational Mode Decomposition (VMD) is introduced to preprocess the wear curve, reducing noise and improving the robustness of friction performance prediction. The results demonstrate the effectiveness and generalizability of the proposed approach, offering a practical AI-based solution for intelligent material property evaluation and process optimization.},
  archive      = {J_MATDES},
  author       = {Xuefei Wang and Shijie Zhang and Di Jiang and Wei Yu and Yihao Zheng and Chunyang Luo and Haojie Wang and Zhaodong Wang},
  doi          = {10.1016/j.matdes.2025.114800},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114800},
  shortjournal = {Mater. Des.},
  title        = {Transformer-based multimodal learning for predicting mechanical properties in heat-treated stainless steel},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ai-driven optimization of woven composite via integrated deep and reinforcement learning. <em>MATDES</em>, <em>259</em>, 114798. (<a href='https://doi.org/10.1016/j.matdes.2025.114798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Woven carbon fiber composites are increasingly adopted in advanced structural applications due to their exceptional strength-to-weight ratio and tunable design features. However, high-fidelity simulations of their complex woven architecture are computationally intensive. This study presents a hybrid deep learning framework that combines a dual-input Convolutional Neural Network (CNN) for mechanical property prediction with a Deep Q-Network (DQN) for reinforcement learning-based optimization. The CNN achieves R 2 values above 0.96 for elastic deformation, plastic deformation, and strain energy density prediction. Using the DQN, the optimized design achieves a 2.37-fold improvement in strain energy density, increasing from 3590.78 J/m 3 to 8527.85 J/m 3 . Furthermore, by replacing the original woven geometry with a reduced model using stress–strain behavior, simulation time is reduced from 534 min to 2 min, a 267-fold speedup. This approach significantly enhances efficiency in composite design and optimization workflows, enabling rapid exploration of high-performance configurations.},
  archive      = {J_MATDES},
  author       = {Mao-Ken Hsu and Bo-Yu Huang and Chi-Hua Yu},
  doi          = {10.1016/j.matdes.2025.114798},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114798},
  shortjournal = {Mater. Des.},
  title        = {Ai-driven optimization of woven composite via integrated deep and reinforcement learning},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyclic etching of SiO2 contact holes using heptafluoropropyl methyl ether having low global-warming potential. <em>MATDES</em>, <em>259</em>, 114797. (<a href='https://doi.org/10.1016/j.matdes.2025.114797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SiO 2 contact holes having high aspect ratios were etched using a cyclic-etching process employing heptafluoropropyl methyl ether (HFE-347mcc3) which exhibits a low global-warming potential (GWP ≈530) compared with conventional perfluorocarbons (PFCs) and hydrofluorocarbons (HFCs). In this cyclic process, the etching steps involving HFE-347mcc3/O 2 /Ar plasmas were alternated with deposition steps involving HFE-347mcc3/Ar plasmas to precisely control the fluorocarbon passivation films on the sidewalls. The effects of the deposition- and etching-step durations on the contact-hole profiles were systematically investigated. Increasing the duration of the deposition step initially improved sidewall protection, thereby significantly reducing bowing and enhancing anisotropy; however, excessively long deposition-step durations caused narrowing. Similarly, the duration of the etching step was optimized to achieve sufficient fluorocarbon-film hardening to prevent bowing while avoiding excessive narrowing. The degree of exposure to fluorocarbon plasma was introduced as a critical parameter to optimize the anisotropy. Under optimized conditions, a nearly vertical and highly anisotropic SiO 2 contact hole having a diameter of 100 nm and an aspect ratio of 24 was successfully obtained with minimal bowing (1 nm). The results revealed that HFE-347mcc3 is a viable and environmentally sustainable alternative to high-GWP PFCs or HFCs and provide both environmental benefits and excellent etching performance.},
  archive      = {J_MATDES},
  author       = {Sanghyun You and Minuk Kim and Inkyoung Cho and Junyoung Kim and Sangheon Lee and Chang-Koo Kim},
  doi          = {10.1016/j.matdes.2025.114797},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114797},
  shortjournal = {Mater. Des.},
  title        = {Cyclic etching of SiO2 contact holes using heptafluoropropyl methyl ether having low global-warming potential},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accurate analytical post-buckling solutions for simply supported square plates under biaxial compression with varying stress ratios. <em>MATDES</em>, <em>259</em>, 114796. (<a href='https://doi.org/10.1016/j.matdes.2025.114796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenge of obtaining accurate analytical post-buckling solutions for simply supported square plates under biaxial compression, a long-standing problem in nonlinear plate mechanics. The research question focuses on how to rigorously capture large deflections and bending–membrane interactions to establish reliable benchmarks beyond the critical load. A series expansion method within the von Kármán framework is employed to derive analytical solutions with high numerical accuracy. Compared with existing analytical and numerical approaches, the present solutions achieve five to six significant digits of accuracy, representing a substantial improvement in precision and reliability. A comprehensive parametric study demonstrates how varying the biaxial compression ratio influences post-buckling responses, providing deeper insight into boundary-sensitive and load-dependent behaviors. The results establish new analytical benchmarks that can be directly used to validate approximate and numerical methods, thereby improving the robustness of computational models. In addition, they offer practical guidance for the safe and efficient design of thin-walled plate structures in aerospace, civil, and mechanical engineering. This work highlights both the novelty of deriving truly accurate, verifiable analytical solutions and their dual value as theoretical milestones and engineering tools.},
  archive      = {J_MATDES},
  author       = {Da-Guang Zhang},
  doi          = {10.1016/j.matdes.2025.114796},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114796},
  shortjournal = {Mater. Des.},
  title        = {Accurate analytical post-buckling solutions for simply supported square plates under biaxial compression with varying stress ratios},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring structure–property relations in dual phase steels using crystal plasticity and variance based global sensitivity analysis. <em>MATDES</em>, <em>259</em>, 114794. (<a href='https://doi.org/10.1016/j.matdes.2025.114794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel framework to quantify the relationships between microstructural features and damage mechanisms in DP800 steel through high-fidelity three-dimensional sRVE simulations with novel damage indicators, which were integrated with variance-based global sensitivity analysis for the calculation of Sobol indices. The developed methodology suggests that the martensite-to-ferrite phase ratio has a stronger impact on damage tolerance than martensite strength, while the elongation of martensite is the dominant parameter for martensite fracture. For the newly introduced phase boundary decohesion indicator, the grain sizes of both phases exhibit the highest influence. A homogenized indicator for overall damage resistance and a trade-off for the two damage mechanisms further revealed the importance of phase morphology, providing insights into additional influencing factors not captured by individual mechanisms. Convergence analyses confirmed that 200–250 datapoints suffice for stable determination of the Sobol indices, confirmed by different surrogate modeling approaches. Radar chart analyses indicated that optimal microstructures for enhanced damage tolerance consist of smaller fractions of strong martensite combined with fine, spheroidal grains in both phases, aligning with established knowledge on DP steels. This approach establishes a validated basis for future optimization of microstructures and loading paths to improve damage tolerance under complex forming conditions.},
  archive      = {J_MATDES},
  author       = {Niklas C. Fehlemann and Irene Biermann and Sebastian Münstermann},
  doi          = {10.1016/j.matdes.2025.114794},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114794},
  shortjournal = {Mater. Des.},
  title        = {Exploring structure–property relations in dual phase steels using crystal plasticity and variance based global sensitivity analysis},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stress-constrained topology optimization of heterogeneous lattice structures for additive manufacturing. <em>MATDES</em>, <em>259</em>, 114792. (<a href='https://doi.org/10.1016/j.matdes.2025.114792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a topology optimization method for heterogeneous lattice structures subject to stress constraints. The proposed approach extends the ordered SIMP (Solid Isotropic Material with Penalization) framework to incorporate a composite material failure criterion. Specifically, a modified Tsai–Hill yield criterion is employed to characterize the anisotropic yielding behavior of the heterogeneous lattice, which is subsequently integrated into the optimization as a stress constraint. To address the variation in yield strength across different lattice configurations, a normalization strategy is applied to the stress field. Additionally, a P-norm aggregation scheme is introduced to efficiently handle local stress constraints while reducing computational cost. The equivalent elastic tensor and yield strength of each lattice configuration are obtained using a representative volume element (RVE) based on homogenization theory. The effectiveness of the proposed method is demonstrated through a series of 2D cases, achieving lightweight structural designs that satisfy stress constraints. Finally, full-scale mechanical analysis and 3D printing experimental validation further confirm the strength reinforcement of the optimized results.},
  archive      = {J_MATDES},
  author       = {Zixin Yang and Jikai Liu and Shuzhi Xu and Yifan Guo},
  doi          = {10.1016/j.matdes.2025.114792},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114792},
  shortjournal = {Mater. Des.},
  title        = {Stress-constrained topology optimization of heterogeneous lattice structures for additive manufacturing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metastability matters: Exploring hardness and conductivity in bell bronze alloys. <em>MATDES</em>, <em>259</em>, 114791. (<a href='https://doi.org/10.1016/j.matdes.2025.114791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cu-Sn alloy system exhibits diverse stable and metastable phases with complex phase transformations, making it attractive for applications requiring tailored mechanical and electrical performance. This study investigates the mechanical response of individual phases during ongoing phase transformations in a Cu-20 m.% Sn alloy. Heat treatments produced large-grained microstructures containing distinct phase combinations in equilibrium and non-equilibrium states. The evolving microstructure was characterized using light optical and scanning electron microscopy. Phase-specific hardness, Young’s modulus, and strain rate sensitivity were determined through room-temperature and high-temperature nanoindentation combined with electron back-scattered diffraction phase mapping, alongside compression testing. This method enables direct quantification of phase properties under phase transformation, separating the contributions of stable and metastable phases. Results reveal how transformation kinetics and solute interactions govern the phase-specific deformation bulk performance, offering new insights into structure–property relationships in Cu-Sn alloys. The methodology provides a framework for phase-specific property characterization in transforming systems, supporting the design of materials with transformation-informed properties optimization.},
  archive      = {J_MATDES},
  author       = {Lea A. Lumper-Wimler and Leon Ruess and Johann Kappacher and Wolfram Schillinger and Verena Maier-Kiener},
  doi          = {10.1016/j.matdes.2025.114791},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114791},
  shortjournal = {Mater. Des.},
  title        = {Metastability matters: Exploring hardness and conductivity in bell bronze alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical nanocomposite formation and strengthening mechanisms in a phase-separated CrFeCoNiCu high-entropy alloy. <em>MATDES</em>, <em>259</em>, 114790. (<a href='https://doi.org/10.1016/j.matdes.2025.114790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates a CrFeCoNiCu high-entropy alloy (HEA) exhibiting hierarchical phase separation into Cu-rich low-entropy (LE) and CrFeCoNi-rich high-entropy (HE) regions, driven by a miscibility gap and monotectic reaction. A CALPHAD-based pseudo-binary diagram guided the optimization of solidification and annealing conditions, promoting nanoscale coherent precipitate (NCP) formation within each phase. Multiscale analysis (SEM, EPMA, TEM, 3D APT) revealed a dual FCC-phase composite where each region contains NCPs of the other phase. During annealing, secondary NCPs grow more slowly than primary phase-separated regions, enabling effective control through heat treatment. Mechanical testing via nanoindentation and micropillar compression showed that coherent NCPs enhance strength via a shearing mechanism. In particular, LE NCPs in the HE matrix effectively distribute the applied strain and suppress dislocation motion and slip band formation, resulting in stable strain hardening without stress drops. Upon coarsening beyond the size applicable for shearing, transition to the Orowan bypass mechanism resulting in a decrease in nano-hardness. These findings highlight the importance of coherent phase-separated nanostructures in strengthening and deformation control, and present a thermodynamically guided microstructural design strategy for fabricating HEA-based hierarchical nanocomposites with tunable mechanical performance, offering a promising approach for developing next-generation high-strength, ductile structural materials.},
  archive      = {J_MATDES},
  author       = {Jinyeon Kim and Jinwoo Kim and Wan Kim and Jeong Won Yeh and Jae-Hyeok Shim and Hye Jung Chang and Eun Soo Park},
  doi          = {10.1016/j.matdes.2025.114790},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114790},
  shortjournal = {Mater. Des.},
  title        = {Hierarchical nanocomposite formation and strengthening mechanisms in a phase-separated CrFeCoNiCu high-entropy alloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dispersion strategies development for high-performance carbon nanomaterials-reinforced cementitious composites − critical review on properties and future challenges. <em>MATDES</em>, <em>259</em>, 114789. (<a href='https://doi.org/10.1016/j.matdes.2025.114789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon nanomaterials (CNMs) including carbon nanotubes (CNTs), graphene nanosheets (GNS), carbon nanofibers (CNFs), graphene oxide (GO), with their excellent physical and chemical properties, have drawn widespread attention in the cement industry. This review introduces the dispersion strategies of CNMs in cementitious composites fabrication procedures before providing a comprehensive summary of the corresponding principles, advantages, limitations, and critical considerations. We also reviewed the latest CNMs dispersion characterization techniques and the dispersion effectiveness evaluation methods. Furthermore, the properties of cementitious composites incorporating CNMs, including workability, mechanical strength, durability, electrical conductivity and thermal conductivity, are summarized. The impact of dispersion strategies on these properties is analyzed, and potential causes behind performance inconsistencies are discussed. This review found that the current research faces several challenges: the lack of standardized mix proportions and dispersion protocols hinders result comparison, and inconsistent characterization methods, insufficient cost/lifecycle analyses, combined with unclear links between CNMs’ properties and enhancement, collectively limit practicality. Therefore, future works should focus on establishing unified guidelines for production and characterization, conducting cost-sustainability assessments, and clarifying CNMs’ property-performance relations to advance engineering applications.},
  archive      = {J_MATDES},
  author       = {Yuan Gao and Fufu Zou and Hao Sui and Jiajing Xu and Siyao Wang and Shuaijie Lu and Jiajian Yu and Weiqiang Chen and Yanming Liu and Jing Chen and Lilin Zhao},
  doi          = {10.1016/j.matdes.2025.114789},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114789},
  shortjournal = {Mater. Des.},
  title        = {Dispersion strategies development for high-performance carbon nanomaterials-reinforced cementitious composites − critical review on properties and future challenges},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven prediction and inverse design of optical asymmetry in gold nanorod-helical assemblies. <em>MATDES</em>, <em>259</em>, 114788. (<a href='https://doi.org/10.1016/j.matdes.2025.114788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of optical asymmetry in gold nanorod- (Au NR-) helical assemblies is of paramount importance for the development of functional nanomaterials in optoelectronics, catalysis, and biomedicine. However, such assemblies frequently proceed without adequate theoretical guidance on structure–property relationships, hindering precise control and rational design of tailored optical activity. The present study explores automated, data-driven workflows to investigate geometry-dependent optical asymmetry, with the aim of predicting the asymmetry factor (g-factor) of Au NR-helical assemblies and retrieving their geometric features. A forward artificial neural network (ANN) has been developed to predict the g-factor from geometric inputs. Conversely, a combination of ANN with particle swarm optimisation (PSO) has been demonstrated to retrieve geometric parameters necessary to achieve a target g-factor. The findings demonstrate that the forward ANN attains a high level of prediction accuracy ( r = 0.9833), and the inverse ANN-PSO workflow effectively identifies geometries that yield g-factors with a high degree of proximity to the target values. This demonstrates the significant value of these automated workflows for the fundamental geometric design and optical asymmetry prediction of Au NR-helical assemblies.},
  archive      = {J_MATDES},
  author       = {Yang Liu and Yongguang Chen and Bo Yang and Lina Zhao},
  doi          = {10.1016/j.matdes.2025.114788},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114788},
  shortjournal = {Mater. Des.},
  title        = {Data-driven prediction and inverse design of optical asymmetry in gold nanorod-helical assemblies},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling the SLM process-structure-property relationship of a moderate mg content al-mg-si-sc-zr-mn alloy. <em>MATDES</em>, <em>259</em>, 114787. (<a href='https://doi.org/10.1016/j.matdes.2025.114787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selective Laser Melting (SLM) holds great promise for fabricating high-precision aluminum alloy components with complex geometries and lightweight structures. However, producing high-strength aluminum alloys with excellent mechanical properties remains hindered by poor printability and complex microstructural control. In this study, an Al-4.79 Mg-1.3Si-0.51Sc-0.27Zr-0.47Mn (wt.%) alloy was developed and processed via SLM. The SLM process-structure-property relationship of this alloy was investigated. Crack-free samples were achieved across a broad process window, indicating excellent crack resistance and adaptability. Good printability and high relative density over 99.5 % can be achieved at a laser power of 200-230 W and scanning speed of 1050 and 1150 mm/s, corresponding to a volumetric energy density (VED) of 60 J/mm 3 -73 J/mm 3 . The increase in the laser energy density promoted the formation of columnar grains and the widening of subgrain structures, and made the Mg 2 Si phase transformed from continuous to discontinuous morphology. The as-printed alloy exhibited 439 MPa tensile strength and 11.3 % elongation, attributed to grain refinement, reduced porosity, and the formation of the high dislocation density, 9R phase, and nanotwin. After aging, strength increased to 483 MPa and elongation decreased to 6.5 %. This study defines the process window and demonstrates a balance between high specific strength and cost efficiency.},
  archive      = {J_MATDES},
  author       = {Rui Liu and Junquan Yu and Wenyou Zhang and Xiebin Wang and Jun Lin and Guoqun Zhao},
  doi          = {10.1016/j.matdes.2025.114787},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114787},
  shortjournal = {Mater. Des.},
  title        = {Unveiling the SLM process-structure-property relationship of a moderate mg content al-mg-si-sc-zr-mn alloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-responsive injectable dECM hydrogel for sustained doxycycline delivery in osteoarthritis therapy. <em>MATDES</em>, <em>259</em>, 114785. (<a href='https://doi.org/10.1016/j.matdes.2025.114785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoarthritis (OA) is the most prevalent degenerative joint disease worldwide. Current therapeutic approaches are limited by rapid drug clearance from the joint cavity, necessitating frequent administrations and failing to provide sustained therapeutic effects. Injectable hydrogels that can persistently remain within the joint space represent a promising strategy for comprehensive OA treatment. Herein, an injectable hydrogel system based on dermal-derived decellularized extracellular matrix (dECM) engineered with N-isopropylacrylamide, tannic acid, and sodium tetraborate was developed to achieve superior lubrication and strong tissue adhesion. The hydrogel exhibits exceptional lubrication properties and robust tissue adhesion, enabling prolonged retention within the joint cavity while providing continuous cartilage protection. Its excellent shear-thinning behavior and rapid self-healing capability facilitate minimally invasive injection and ensure conformal coverage of defect sites. In vitro and in vivo evaluations demonstrated that the hydrogel promotes cell proliferation, modulates anti-inflammatory responses, and significantly preserves cartilage integrity with enhanced proteoglycan and type II collagen (COL-2) expression. The sustained therapeutic efficacy was attributed to the hydrogel’s ability to maintain prolonged residence time while continuously delivering bioactive components and providing mechanical lubrication. These findings demonstrate that this multifunctional dECM-based injectable hydrogel represents a promising therapeutic platform for OA treatment suitable for clinical translation.},
  archive      = {J_MATDES},
  author       = {Ximing Wang and Ting Zheng and Luyao Cai and Clara Chen and Junjie Xu and Jinzhong Zhao},
  doi          = {10.1016/j.matdes.2025.114785},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114785},
  shortjournal = {Mater. Des.},
  title        = {Multi-responsive injectable dECM hydrogel for sustained doxycycline delivery in osteoarthritis therapy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards understanding the design principle and rotation deformation mechanics of 3D chiral NPR structure with tunable mechanical responses. <em>MATDES</em>, <em>259</em>, 114784. (<a href='https://doi.org/10.1016/j.matdes.2025.114784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an innovative three-dimensional Negative Poisson’s ratio (NPR) chiral structure was designed based on a 2D staggered rib architecture. This design integrates horizontally oriented chiral alternating ribs and vertically oriented Z-shaped configurations. Two optimized architectures, namely the wave-optimized structure (W-NPR) and the node-enhanced structure (N-NPR), were proposed and compared with the original folded structure (F-NPR). Characterization analysis revealed that the N-NPR structure exhibited superior formability, making it suitable for Digital Light Processing (DLP) fabrication. A parametric study on the mechanical performance of the N-NPR structure demonstrated that an increased volume fraction enhances the mechanical properties at the expense of structural compliance. Uniaxial tensile testing along the XY-plane and Z-axis confirmed the anisotropic Young’s modulus. Experimental and finite element simulations further revealed anisotropic behavior and a unique two-stage rotation-torsion compressive deformation mechanism of N-NPR, which enables advanced mechanical designs by enhancing the degree of freedom for deformation mode conversion. This work proposes a novel method for designing 3D NPR structures and elucidates its mechanical deformation mechanism, enabling transformative advances in aerospace, personalized healthcare, and adaptive wearable technologies.},
  archive      = {J_MATDES},
  author       = {Ruiqi Pan and Ruiying Luo and Wei Xiong and Qiaoyu Chen and Jiafeng Wu and Chunze Yan and Liang Hao and Jie Yin and Zheng Li and Ronghong Zhang and Lei Yang and Yan Li},
  doi          = {10.1016/j.matdes.2025.114784},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114784},
  shortjournal = {Mater. Des.},
  title        = {Towards understanding the design principle and rotation deformation mechanics of 3D chiral NPR structure with tunable mechanical responses},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of irradiation temperature on the microstructure and hardness of W-0.3Cr alloy after irradiation with 6.4 MeV fe ions. <em>MATDES</em>, <em>259</em>, 114783. (<a href='https://doi.org/10.1016/j.matdes.2025.114783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The W-0.3 at.% Cr alloy samples were irradiated with 6.4 MeV Fe ions at 773, 1073 and 1273 K, and the damage peak was 0.26 dpa. The evolution of the microstructure, defects, and hardness was investigated using grazing-incidence X-ray diffraction (GIXRD), transmission electron microscopy (TEM) and nanoindentation tests. The GIXRD results showed that diffraction peaks shifted towards lower 2θ values, indicating that lattice swelling was caused by irradiation-induced defects after irradiation at elevated temperatures. According to the TEM observations, the size of the dislocation loops remained nearly constant, while their number density decreased with an increase in irradiation temperature. The precipitation of Cr was not observed in the W-0.3Cr alloy after irradiation at 773 K. In contrast, it was significant in the samples irradiated at temperatures of 1073 and 1273 K, showing increases in both the size and number density of the precipitates. Irradiation hardening was observed in all samples, primarily attributed to the presence of dislocation loops. The hardness change was estimated with the dispersion barrier hardening model by taking into account the contributions of dislocation loops and Cr precipitates. The values evaluated with the model were significantly larger than those obtained with the nanoindentation tests. This difference was ascribed to the depletion of solute Cr atoms from the W matrix by precipitation.},
  archive      = {J_MATDES},
  author       = {Jing Wang and Jingxian Sun and Yingying Jia and Yifan Zhang and Yuji Hatano and Diancheng Geng and Katsuya Suzuki and Chang Chen and Laima Luo and Kiyohiro Yabuuchi and Ryuta Kasada},
  doi          = {10.1016/j.matdes.2025.114783},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114783},
  shortjournal = {Mater. Des.},
  title        = {Effect of irradiation temperature on the microstructure and hardness of W-0.3Cr alloy after irradiation with 6.4 MeV fe ions},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel in-situ gas-phase alloying approach in wire arc additive manufacturing for controlling solidification mode and designing hybrid stainless steels. <em>MATDES</em>, <em>259</em>, 114781. (<a href='https://doi.org/10.1016/j.matdes.2025.114781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a thermodynamically guided in-situ gas-phase alloying approach in wire arc additive manufacturing (WAAM) to enhance duplex stainless steels by shifting the primary solidification mode from δ-ferrite to γ-austenite, producing a nitrogen-enriched alloy with a continuous austenitic matrix that combines duplex-grade strength with superior ductility. Thermodynamic calculations guided nitrogen adjustment in the shielding gas to control solidification and develop high-performance microstructures. Thermodynamic–kinetic modeling predicted nitrogen uptake from the arc plasma, enabling gas composition selection to promote a shift from δ-ferrite to γ-austenite as the primary solidification phase. Nitrogen content analysis and Scheil simulations confirmed a transition to austenite-first solidification at approximately 0.7 wt% nitrogen. Electron Backscatter Diffraction and optical microscopy revealed that nitrogen-enriched (HN) samples exhibited a continuous γ-austenitic matrix with finely dispersed δ-ferrite, whereas nitrogen-lean (LN) samples had a δ-ferritic matrix with isolated γ-austenite islands. HN samples showed greater grain orientation spread, indicating increased internal misorientation. Despite pronounced crystallographic texture, the HN samples demonstrated nearly isotropic tensile behavior along with enhanced yield strength, tensile strength, ∼11 % higher hardness, and improved elongation. These findings demonstrate that melt chemistry control via gas-phase alloying enables phase-engineered microstructures with superior mechanical performance without modifying the filler wire.},
  archive      = {J_MATDES},
  author       = {Elina Akbarzadeh Chiniforoush and Mohammad Reza Jandaghi and Johan Moverare and Tohid Saeid and Koray Yurtışık},
  doi          = {10.1016/j.matdes.2025.114781},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114781},
  shortjournal = {Mater. Des.},
  title        = {A novel in-situ gas-phase alloying approach in wire arc additive manufacturing for controlling solidification mode and designing hybrid stainless steels},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influencing the draping behaviour of solid epoxy prepregs by applying 3D-printed resin patterns. <em>MATDES</em>, <em>259</em>, 114780. (<a href='https://doi.org/10.1016/j.matdes.2025.114780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel strategy to overcome the limitations of solid resin prepregs (SRPs) − namely the inability to drape at room temperature and hindered gas evacuation during vacuum-bag-only (VBO) processing − by 3D-printing a regular, uncured solid epoxy resin (SR) pattern on a dry woven textile. The locally patterned resin distribution preserves dry textile regions, enabling room temperature drapeability and more robust VBO-processing due to improved gas evacuation. By adjusting pattern parameters such as element geometry and coverage, the draping behaviour can be controlled to adapt to a desired draping condition. In order to be able to design the right pattern for given draping conditions, the influence of these parameters on bending and shearing was studied. Manual draping showed that bending radii down to 4 mm were achievable, governed only by the element length in bending direction, while coverage had no significant effect. In contrast, picture-frame-tests showed that the shearing is mainly influenced by the coverage and that a maximal shearing angle of 30° can be achieved. These results show that the SRPs bending and shearing can be independently influenced through pattern design. The derived structure–drapeability relationships enable targeted design of SRPs for robust, autoclave-free composite manufacturing.},
  archive      = {J_MATDES},
  author       = {Jan Philipp Janzen and Hendrik Schäfer and Murat Çelik and Colin Robert and Conchúr M. Ó Brádaigh and David May and Thomas Neumeyer},
  doi          = {10.1016/j.matdes.2025.114780},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114780},
  shortjournal = {Mater. Des.},
  title        = {Influencing the draping behaviour of solid epoxy prepregs by applying 3D-printed resin patterns},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser powder bed fusion of pure silver sputtering target: Process, microstructure, and sputtering performance. <em>MATDES</em>, <em>259</em>, 114779. (<a href='https://doi.org/10.1016/j.matdes.2025.114779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silver (Ag) sputtering targets are crucial in electronic information materials, particularly with the rapid advancement of Artificial Intelligence (AI), which has further increased their demand. However, the extremely high reflectivity and poor laser absorption of pure Ag in the infrared range make it challenging to process using conventional laser-based Additive Manufacturing (AM) systems, limiting its wide application. In this study, a novel hatch spacing-to-scanning speed ratio ( h / v )-centered low-energy–density strategy was proposed to overcome this challenge and enable high-quality additive manufacturing of pure Ag. By optimizing the ( h / v ) value to 1.0E-04, we successfully fabricated dense, low-defect Ag sputtering targets without increasing energy input. The results demonstrated that this method significantly shortened the manufacturing cycle and produced high-performance Ag targets with refined grains (3–7 μm), high density (≥99.8 %), a smooth surface (Ra = 11.5 μm), and stable sputtering performance (sputtering rate = 31.8 nm/min). Furthermore, the hardness increased by 45.1 % compared to Ag targets prepared by traditional methods. This work offers a practical pathway for applying laser-based AM in the production of highly reflective metal sputtering targets, advancing their industrialization in thin-film electronics, while also contributing to the understanding of AM process–structure relationships in metallic materials.},
  archive      = {J_MATDES},
  author       = {Zheda Ning and Yipei He and Qi Tang and Yunxiu Chao and Yue Shen and Haozhang Zhong and Ming Wen and Jianfeng Gu},
  doi          = {10.1016/j.matdes.2025.114779},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114779},
  shortjournal = {Mater. Des.},
  title        = {Laser powder bed fusion of pure silver sputtering target: Process, microstructure, and sputtering performance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the performance of organic photodetectors by low-temperature electron beam annealing. <em>MATDES</em>, <em>259</em>, 114778. (<a href='https://doi.org/10.1016/j.matdes.2025.114778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organic photodetectors (OPDs) are promising candidates for next-generation optoelectronic devices due to their flexibility, low cost, and scalability. Enhancing OPD performance requires optimizing key layers such as the electron transport layer (ETL) using low-temperature processes to prevent thermal degradation. This study explores the use of low-temperature electron beam annealing (EBA) to improve the performance of Al-doped ZnO (AZO)-based ETLs. The impact of EBA irradiation time (1–8 min) on the structural, morphological, and electrical properties of AZO films was systematically analyzed. EBA effectively modulated oxygen vacancies and reduced surface roughness, lowering trap density and leakage current while enhancing charge transport. An OPD with an ETL treated by 8 min of EBA exhibited superior detectivity (2.22 × 10 13 Jones at 0 V) and significantly reduced leakage current compared to a device with conventionally annealed ETLs. Importantly, the low-temperature EBA process preserved the amorphous state of AZO, making it suitable for heat-sensitive and flexible substrates. These findings demonstrate that EBA is a powerful, scalable method for ETL optimization in OPDs and offers a pathway toward high-performance, energy-efficient, and flexible optoelectronic devices.},
  archive      = {J_MATDES},
  author       = {Jaebum Jeong and Gun woong Kim and Eun Jin Park and Seong Woo Jeong and Seok Hwan Jang and Jae Yeong Jeong and Soo Won Heo and Jun Young Kim},
  doi          = {10.1016/j.matdes.2025.114778},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114778},
  shortjournal = {Mater. Des.},
  title        = {Improving the performance of organic photodetectors by low-temperature electron beam annealing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable biopolymer design: Extraction of chitin and chitosan using natural deep eutectic solvents with improved antibacterial features. <em>MATDES</em>, <em>259</em>, 114775. (<a href='https://doi.org/10.1016/j.matdes.2025.114775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of biopolymers using natural deep eutectic solvents (NADES) offers a promising approach for developing sustainable and biocompatible materials for biomedical applications. In this study, a novel and environmentally friendly process has been developed for extracting chitin and chitosan from organic Agaricus bisporus ( A. bisporus ) mushrooms, which serves as a readily available and renewable resource. NADES not only enhances the extraction efficiency but also preserves the structural integrity of the biopolymers. The characteristics of these biopolymers were analyzed by X-ray diffraction (XRD), Fourier transform infrared spectroscopy (FT-IR), thermogravimetric (DTG/TGA) analysis, scanning electron microscopy (SEM), atomic force microscopy (AFM), and nuclear magnetic resonance ( 1 H NMR) techniques. By optimizing the NADES extraction conditions, high-purity chitin (98.58 %) and chitosan (98.69 %) were achieved, surpassing the purity levels achieved by traditional chemical methods. NADES-extracted chitosan exhibited a remarkable degree of deacetylation (DD) of up to 94.22 %, and a crystallinity index (CrI) of up to 61.77 %, highlighting its enhanced functionality for biomedical applications. Moreover, the NADES-derived biopolymers showed excellent biocompatibility with L929 fibroblast cells. They exhibited dose-dependent antibacterial activity against Staphylococcus aureus (S. aureus) and Escherichia coli (E. coli) and exhibited promising antioxidant and biodegradability properties.},
  archive      = {J_MATDES},
  author       = {Issam Thamer and Magdalena Mazurek-Budzyńska and Vignesh Kumaravel},
  doi          = {10.1016/j.matdes.2025.114775},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114775},
  shortjournal = {Mater. Des.},
  title        = {Sustainable biopolymer design: Extraction of chitin and chitosan using natural deep eutectic solvents with improved antibacterial features},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic effect of interfacial silane film and laser texturing on joining characteristics of pretreated Al/CFRTP friction stir welded joints. <em>MATDES</em>, <em>259</em>, 114774. (<a href='https://doi.org/10.1016/j.matdes.2025.114774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by lightweight requirements in the low-altitude economy, a synergistic laser ablation‒silane coupling process was developed to optimize friction stir welded joints between Al alloys and carbon fiber-reinforced thermoplastics (CFRTPs), with a focus on elucidating the sequence-dependent gradient interfacial joining mechanism. A sequence involving silane coupling prior to laser ablation was employed, enabling dual-mode enhancement of the interfacial geometric configuration and chemical bonding. Mechanical interlocking was ensured in laser-ablated zones, whereas the chemical bonding capacity in unablated regions was enhanced. The tensile–shear strength and cross-tension strength of the joints were measured at 32.6 MPa and 3.2 MPa, respectively. Detailed microstructural characterization revealed that mechanical interlocking occurred in the laser-ablated zones of the PA66 resin and that synergistic physicochemical reinforcement was achieved via covalent Al‒O‒Si bonds coupled with molecular chain entanglement/hydrogen bonding in unablated regions. Defect-free continuous interfacial transitions were confirmed through the penetration of nanolamellar structures by amorphous silane films. This synergistic strategy provides new insights for the high-performance joining of dissimilar metal and polymer materials.},
  archive      = {J_MATDES},
  author       = {Suyu Wang and Wenquan Wang and Yuhua Chen and Xinge Zhang and Shanlin Wang and Timing Zhang and Yuxin Xu},
  doi          = {10.1016/j.matdes.2025.114774},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114774},
  shortjournal = {Mater. Des.},
  title        = {Synergistic effect of interfacial silane film and laser texturing on joining characteristics of pretreated Al/CFRTP friction stir welded joints},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High voltage rotary freestanding triboelectric nanogenerator with novel electrode pair relative position: Theoretical and experimental studies. <em>MATDES</em>, <em>259</em>, 114773. (<a href='https://doi.org/10.1016/j.matdes.2025.114773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Triboelectric nanogenerators (TENGs) are widely used as ideal high-voltage sources in high-voltage equipment. However, there are still some high-voltage application demands that exceed the voltage range of traditional TENG. Here, we propose a high-voltage rotary freestanding TENG (HRF-TENG) with a simple structure. The HRF-TENG device is obtained by changing the relative positions of the electrode pairs (reducing the capacitance) in the traditional RF-TENG, which is inspired by the finite element (FEM) calculation of the traditional RF-TENG. The high-voltage mechanism is initially studied through FEM calculation and experiments, and the calculated output voltage can reach over 30 kV at 500 rpm. In addition, the current direction remains unchanged regardless of the rotation direction. The ultrahigh voltage from HRF-TENG is sufficient to break down the air gap to generate ozone, which achieves the ozone drinking water sterilization system. Drinking water containing 10 7 CFU/ml of E. coli and S. aureus can be completely sterilized within 24 min and 28 min, respectively. Meanwhile, the electrospinning system can be directly driven by HRF-TENG without any circuit. All of these demonstrations prove the feasibility of HRF-TENG in the field of high-voltage applications. In summary, this work provides useful guidance for designing TENGs for high-voltage applications.},
  archive      = {J_MATDES},
  author       = {Ming Li and Tianyi Jiang and Liangyu Cao and Haoxiu Sun and Shanguo Zhang and Jiachao Tang and Yu Li and Hongyuan Jiang},
  doi          = {10.1016/j.matdes.2025.114773},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114773},
  shortjournal = {Mater. Des.},
  title        = {High voltage rotary freestanding triboelectric nanogenerator with novel electrode pair relative position: Theoretical and experimental studies},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microcellular TLCP/SiO2 for high-frequency communication design. <em>MATDES</em>, <em>259</em>, 114772. (<a href='https://doi.org/10.1016/j.matdes.2025.114772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of high-frequency and high-speed communication technologies, especially in microwave/millimeter-wave applications, electronic devices face increased performance demands. Developing low dielectric materials with exceptional properties for these devices has become a significant challenge. Thermotropic liquid crystal polymers (TLCP) are promising due to their excellent high-frequency performance, while microcellular foaming technology is commonly used to enhance dielectric properties. In this study, TLCP was modified with ADR and nano-SiO 2 . The synergistic modification introduces long-chain branched structures and nucleation sites, improving matrix performance and optimizing foaming behavior. In addition, long-chain branched TLCP/SiO 2 foam has highly compressive properties, excellent dimensional stability, ultra-low dielectric stability at high frequencies, great flame retardant and wonderful high-temperature infrared thermal stealth performance. It is also found by simulation that the patch antenna with long-chain branched TLCP/SiO 2 foam substrate has excellent signal transmission performance. The transmission distance up to 4793 m, which is 5.8 times higher than pure TLCP before foaming, which presents a novel solution for high-frequency and high-speed communication. Furthermore, the long-chain branched TLCP/SiO 2 foams with significant performance is expected to be used in sophisticated technology fields such as wide-ranging applications in military, extreme conditions, aviation, microelectronic and other fields.},
  archive      = {J_MATDES},
  author       = {Jiayang Sun and Wenyu Zhong and Yichong Chen and Kuikui Fan and Dongdong Hu and Zhenhao Xi and Tao Gu and Ling Zhao},
  doi          = {10.1016/j.matdes.2025.114772},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114772},
  shortjournal = {Mater. Des.},
  title        = {Microcellular TLCP/SiO2 for high-frequency communication design},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent progress of manipulating microenvironment for spinal cord injury therapy using nanoparticles. <em>MATDES</em>, <em>259</em>, 114769. (<a href='https://doi.org/10.1016/j.matdes.2025.114769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spinal cord injury (SCI) is a severe traumatic condition that profoundly compromises patients’ health and quality of life. While various therapeutic strategies, including pharmacotherapy, have been developed and demonstrate some efficacy, however their clinical application is significantly limited by challenges, such as low drug bioavailability and undesirable side effects. Moreover, a critical limitation is their frequently neglect the SCI microenvironment, which serves as the essential foundation for nerve regeneration. In contrast, intelligent nanoparticles-based delivery systems, owing to their excellent biocompatibility and high drug-loading capacity, they can modulate the SCI microenvironment on demand, hold great promise for improving SCI therapy. However, how to design intelligent nanoparticles to achieve precise microenvironment regulation for SCI therapy is still lack of a systematic summary. Therefore, this review summarizes recent advances in advances in modulating the microenvironment for treating SCI using targeted nano drug delivery system, hope provide a theoretical basis for the further development of nano-drug to treatment of SCI.},
  archive      = {J_MATDES},
  author       = {Linfeng Xiao and Chunping Tian and Yinshan Hong and Jiajun Wu and Jiani Du and Yanling Yang and Xiaowei Chang},
  doi          = {10.1016/j.matdes.2025.114769},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114769},
  shortjournal = {Mater. Des.},
  title        = {Recent progress of manipulating microenvironment for spinal cord injury therapy using nanoparticles},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances and challenges of targeted protein degradation in ophthalmology: Future directions and therapeutic potential. <em>MATDES</em>, <em>259</em>, 114767. (<a href='https://doi.org/10.1016/j.matdes.2025.114767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of targeted protein degradation technologies, particularly proteolysis-targeting chimeras (PROTACs) and lysosome-targeting chimeras (LYTACs), is poised to revolutionize therapeutic strategies in ophthalmology. This review presents the first systematic analysis of these protein degradation platforms to address ’undruggable’ targets in ocular pathologies. Harnessing distinct cellular machinery through the engagement of the ubiquitin–proteasome system and the lysosomal pathway with PROTACs and LYTACs, respectively, these heterobifunctional molecules enable the targeted elimination of disease-driving proteins implicated in ocular surface diseases, such as dry eye, and fundus diseases, including age-related macular degeneration, diabetic retinopathy, and glaucoma. We review the mechanistic basis of these technologies, their translational potential in overcoming the limitations of conventional therapies, and ocular-specific challenges such as optimizing bioavailability and intraocular target selectivity. Central to this discussion is the role of advanced linker engineering in achieving spatio-temporal control of degradation activity. While barriers to ocular biodistribution and sustained delivery remain, targeted protein degradation represents a paradigm shift in ophthalmology, offering durable therapeutic effects that could significantly improve clinical outcomes and patient compliance through reduced dosing frequency.},
  archive      = {J_MATDES},
  author       = {Ke Feng and Mingyan Wei and Panqin Ma and Jiaoyue Hu and Caihong Huang and Yi Han and Zuguo Liu},
  doi          = {10.1016/j.matdes.2025.114767},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114767},
  shortjournal = {Mater. Des.},
  title        = {Advances and challenges of targeted protein degradation in ophthalmology: Future directions and therapeutic potential},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In situ observation of the dynamic precipitation of Mg2Sn in mg-sn binary alloy processed by controlled aging treatment. <em>MATDES</em>, <em>259</em>, 114766. (<a href='https://doi.org/10.1016/j.matdes.2025.114766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic precipitation and growth of Mg 2 Sn in a binary Mg-9.76wt.%Sn alloy aged in the temperature range of 180 °C-330 °C were observed in real time by applying in situ transmission electron microscopy techniques, showing the details where and how precipitates nucleate, grow, or dissolve. The dispersive nanoparticles were observed in the Mg matrix at 180 °C, then gradually grew to a lath-like shape on the basal plane at 240 °C-250 °C. The dynamic re-dissolution process of precipitates at the appropriate temperature of 300 °C-330 °C was observed, which was also found to mainly be related to temperature, aging time, surface tension, and vacancies. Meanwhile, a new orientation relationship between the stable precipitates and the Mg matrix was revealed. The results will give a significant insight into the microstructural factors regarding the formation of the orientation relationships, and provide a theoretical guidance for the optimization of alloy performance.},
  archive      = {J_MATDES},
  author       = {Shujing Wu and Chong Cao and Qingjun Zhang},
  doi          = {10.1016/j.matdes.2025.114766},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114766},
  shortjournal = {Mater. Des.},
  title        = {In situ observation of the dynamic precipitation of Mg2Sn in mg-sn binary alloy processed by controlled aging treatment},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bioadhesive sustained-release films for in situ therapy of oral ulcers. <em>MATDES</em>, <em>259</em>, 114765. (<a href='https://doi.org/10.1016/j.matdes.2025.114765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oral ulcers affect more than 25 % of the global population and are driven by complex pathological mechanisms, including bacterial infection, oxidative stress, and dysregulated inflammation, all of which impede healing. To address the limitations of therapies that target only a single aspect of ulcer pathology, this study developed a multifunctional electrospun film by combining 45S5 bioactive glass (BG) with hydroxypropyl methyl cellulose (HPMC). The BG/HPMC films, fabricated by electrospinning with 5 wt% BG incorporated into HPMC matrices, were thoroughly characterized for their structural and bioactive properties. In a rat oral ulcer model, the BG/HPMC films significantly accelerated re-epithelialization and reduced ulcer size compared to both control and chitosan-treated groups. The films also exhibited strong antibacterial activity against Staphylococcus aureus. In vitro, BG extracts promoted the viability and migration of human oral epithelial cells (HOECs) and human umbilical vein endothelial cells (HUVECs), mitigated hydrogen peroxide-induced oxidative stress, and suppressed the expression of pro-inflammatory cytokines—interleukin-1 alpha (IL-1α), tumor necrosis factor alpha (TNF-α), and interleukin-6 (IL-6)—in lipopolysaccharide-stimulated macrophages.},
  archive      = {J_MATDES},
  author       = {Hongping Ge and Jing Yu and Li Pan and Lifang Zhang and Xiaohang Yin and Jie Cai and Chenghu Wu and Chen Wang and Shisheng Chen},
  doi          = {10.1016/j.matdes.2025.114765},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114765},
  shortjournal = {Mater. Des.},
  title        = {A bioadhesive sustained-release films for in situ therapy of oral ulcers},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bioactive nerve conduit enhance peripheral nerve regeneration through dual functions of ion-regulated dedifferentiation and particle-anchored migration. <em>MATDES</em>, <em>259</em>, 114764. (<a href='https://doi.org/10.1016/j.matdes.2025.114764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The regeneration of long-segment peripheral nerve defects remains a critical and challenging clinical problem. The key step in nerve regeneration involves the dedifferentiation of Schwann cells into a repair phenotype, followed by their orderly migration to form Büngner bands that guide axonal elongation. However, due to the lack of bioactive factors for stimulation, the repair of current nerve conduits is generally slow. In this study, we designed a bioactive glass microspheres-embedded nerve conduit. The ions released from these microspheres activate c-Jun to induce Schwann cell dedifferentiation. Meanwhile, the microspheres coated onto the conduit surface provide physical anchoring sites, which accelerate integrin- β 1-mediated Schwann cell adhesion and orderly migration to facilitate Büngner bands assembly. This study confirms that dual-function bioactive glass microspheres promote nerve regeneration through ion-regulated dedifferentiation and particle-anchored migration, offering a novel approach for the design of nerve conduits.},
  archive      = {J_MATDES},
  author       = {Haohui Huang and Shijing Xu and Yulian Yang and Yonghao Qiu and Yujuan Liu and Xiaofeng Chen and Huichang Gao and Fujian Zhao},
  doi          = {10.1016/j.matdes.2025.114764},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114764},
  shortjournal = {Mater. Des.},
  title        = {Bioactive nerve conduit enhance peripheral nerve regeneration through dual functions of ion-regulated dedifferentiation and particle-anchored migration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of dielectric properties, radiation shielding, and electrical resistivity of alkali-activated blast furnace slag and portland cement binders. <em>MATDES</em>, <em>259</em>, 114763. (<a href='https://doi.org/10.1016/j.matdes.2025.114763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alkali-activated materials (AAMs) are increasingly explored for sustainable construction, yet their electromagnetic and radiation-related properties remain largely unknown. This study explored the radio wave propagation, gamma-ray shielding efficiency, and electrical resistivity of alkali-activated blast furnace slag (BFS-AAM) compared to hydrated Portland cement (PC). BFS-AAM demonstrated superior relative permittivity (ε r ≈ 7.6 at 2.4 GHz) and loss tangent (∼0.33) at lower radio frequencies (0.02–10 GHz), leading to enhanced signal attenuation compared to PC (ε r ≈ 5.6, loss tangent ≈ 0.07). BFS-AAM showed similar performance to PC at frequencies between 10–20 GHz, while its characteristics below 10 GHz make it suitable for secure signal environments. In terahertz spectrum (0.2–2 THz), relevant for 6G wireless communication, both materials displayed comparable permittivity (∼5.3 and ∼4.2) and loss tangent (∼0.09 and ∼0.04), indicating compatibility with residential and commercial applications. Simulations at 0.7, 2.4, and 6.0 GHz confirmed higher signal attenuation by BFS-AAM. Additionally, BFS-AAM exhibited higher resistivity (26–110 Ω·m), greater compressive strength (60 MPa), and lower porosity (∼11 %), contributing to its favorable dielectric properties. Although BFS-AAM demonstrated slightly lower gamma-ray shielding efficiency (at 0.661 MeV) than PC, its multifunctional properties position it as promising material for advanced electromagnetic and radiation shielding technologies.},
  archive      = {J_MATDES},
  author       = {Mehedi Rabbil and Mikko Kokkonen and Elijah Adesanya and Otto Mankinen and Mohammad Bhuyan and Sherif Hegazy and Sami Myllymäki and Juho Yliniemi and Tero Luukkonen},
  doi          = {10.1016/j.matdes.2025.114763},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114763},
  shortjournal = {Mater. Des.},
  title        = {Comparison of dielectric properties, radiation shielding, and electrical resistivity of alkali-activated blast furnace slag and portland cement binders},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anisotropic electrospun poly(ε-caprolactone)/polycarbonate urethane scaffolds with improved fatigue performance for tissue-engineered heart valves. <em>MATDES</em>, <em>259</em>, 114762. (<a href='https://doi.org/10.1016/j.matdes.2025.114762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, poly(ε-caprolactone) (PCL) and polycarbonate urethane (PCU) were used to fabricate electrospun scaffolds for tissue-engineered heart valves (TEHVs). The PCL/PCU scaffold containing 25 % PCU (named as 75%PCL-O) with oriented fibers exhibited pronounced anisotropy, with elastic moduli of 53.47 ± 0.93 MPa (X-axis) and 4.19 ± 0.70 MPa (Y-axis), and tensile strength of 14.21 ± 1.16 MPa (X-axis) and 1.59 ± 0.09 MPa (Y-axis), respectively, close to native heart valves. The 75%PCL-O scaffold showed good cell viability and guided cell alignment along the fibers, and no obvious hemolysis or thrombus formation. Hydrodynamic tests showed an effective orifice area ( EOA ) of 2.42 ± 0.12 cm 2 and a regurgitant fraction ( RF ) of 5.98 ± 2.31 % for a 25 mm surgical pulmonary valve, meeting the ISO 5840-2 standard. The accelerated fatigue testing demonstrated that the EOA and RF remained stable throughout 50 million cycles. Additionally, finite element analysis (FEA) revealed that mechanical stress concentrated at the free edge for the 75%PCL-O valve leaflet during the opening-closing cycles, correlating well with the observed fiber degradation in these regions during fatigue tests. In summary, the 75%PCL-O scaffold exhibits favorable mechanical performance, good biocompatibility and improved durability, showing great potential for TEHV applications.},
  archive      = {J_MATDES},
  author       = {Zeping Zhang and Rizheng Han and Caihao Huang and Yueen Liu and Guixue Wang and Yun Bai and Rui Yang and Tao Jin and Xing Zhang},
  doi          = {10.1016/j.matdes.2025.114762},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114762},
  shortjournal = {Mater. Des.},
  title        = {Anisotropic electrospun poly(ε-caprolactone)/polycarbonate urethane scaffolds with improved fatigue performance for tissue-engineered heart valves},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven design for additive manufacturing of energy absorption lattice structures with variable density. <em>MATDES</em>, <em>259</em>, 114761. (<a href='https://doi.org/10.1016/j.matdes.2025.114761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) lattice structures have garnered significant attention in aerospace, architecture, automotive, and medical applications due to their lightweight and superior energy absorption capabilities. Additive manufacturing (AM) enables the fabrication of complex lattice geometries with customized mechanical properties, making them ideal structures for energy absorption scenarios. However, optimizing these structures to achieve spatially varying density distributions for enhanced performance remains a significant challenge. In this study, a data-driven design framework has been proposed for the AM of energy absorption lattice structures with spatially graded densities. The approach enables the tailoring of geometric parameters, including cell arrangement and strut diameters, to realize variable-density architectures optimized for specific performance requirements. The proposed framework is validated through experimental testing of 3D-printed lattice specimens. Compared to the lattices with uniformly distributed cells, the variable-density structures evidence a 218 % increase in maximum load and a 246 % improvement in specific energy absorption. The finite element analysis and experimental comparisons are used to investigate the influence of relative density gradients on energy absorption performance, peak stress mitigation, and deformation. The results highlight the effectiveness of the data-driven design approach in enabling the fabrication of functionally graded lattice structures with enhanced mechanical performance.},
  archive      = {J_MATDES},
  author       = {Yuxin Zhang and Nanya Li},
  doi          = {10.1016/j.matdes.2025.114761},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114761},
  shortjournal = {Mater. Des.},
  title        = {Data-driven design for additive manufacturing of energy absorption lattice structures with variable density},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of γ′ phase on the microstructural evolution and compressive properties of ni-based single crystal superalloys. <em>MATDES</em>, <em>259</em>, 114760. (<a href='https://doi.org/10.1016/j.matdes.2025.114760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate the evaluation and prediction of hot-end component performance, scanning electron microscopy and quasi-static compression tests were carried out on Ni-based single crystal superalloys, and the influence of γ′ phase on microstructural evolution and compressive properties was systematically investigated. Results show that γ′ phases exhibit spherical, cubic, or lath-like morphologies, and their average size increases from ∼ 180  nm to ∼ 450  nm after thermal exposure; and superalloys with higher volume fraction of γ′ phase gradually precipitate topologically close-packed (TCP) phase. The compressive properties display pronounced anisotropy, governed by both microstructure and loading direction. For superalloys with lower volume fraction of γ′ phase, yield strength decreases from 670  MPa to 505 MPa and ultimate compressive strength from 4690  MPa to 4240 MPa as the γ′ phase coarsens. In contrast, for superalloys with higher volume fraction of γ′ phase, ultimate compressive strength initially decreases and then increases, accompanied by rise in failure strain from 22 % to 46 % after thermal exposure. With increasing loading angle, ultimate compressive strength initially decreases and then rises, whereas yield strength, failure strain and hardening modulus exhibit more complex trends. These variations are closely related to γ′ and TCP phase, and microstructure and loading direction collectively affect mechanical behavior.},
  archive      = {J_MATDES},
  author       = {Shunyong Zhang and Bin Zhang and Fengpeng Zhao and Jicheng Li and Dong Jia and Xicheng Huang},
  doi          = {10.1016/j.matdes.2025.114760},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114760},
  shortjournal = {Mater. Des.},
  title        = {Influence of γ′ phase on the microstructural evolution and compressive properties of ni-based single crystal superalloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-assembly of bortezomib nanofibers for solid tumor and bone metastasis therapy. <em>MATDES</em>, <em>259</em>, 114758. (<a href='https://doi.org/10.1016/j.matdes.2025.114758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome challenges including insufficient drug loading capacity, limited targeting accuracy, and the complex preparation of conventional nanomedicine, self-assembled nanomaterials have emerged as a viable solution. To explore the peptide self-assembly theory and overcome limitations, this study used bortezomib (BTZ) as the base material, and a novel peptide self-assembly strategy utilizing Zn(II) coordination was employed to prepare cancer cell-targeting nanofiber drugs (cRGD-BTZNDs). The therapeutic efficacy was evaluated in different types of tumors. The results demonstrated that cRGD-BTZNDs effectively entered cancer cells and exhibited enhanced cytotoxic effects against cancer cells compared to BTZ. Moreover, cRGD-BTZNDs exhibited excellent therapeutic efficacy against solid tumors, significantly inhibiting 4 T1 tumor growth while reducing biological toxicity. Additionally, in the treatment of bone metastases, cRGD-BTZNDs demonstrated excellent therapeutic potency, effectively alleviating bone damage in mice with high biocompatibility. This study not only self-assembled nanomaterials with great potential in cancer therapy, but also affirmed the correctness and universality of the Zn(II) coordination peptide self-assembly theory, providing a theoretical basis for the improvement of peptide-based nanomedicine.},
  archive      = {J_MATDES},
  author       = {Dongjie Fu and Yuerong Wang and Jiaqi Xuan and Dingchang Liu and Jiawei Zhao and Yang Lei and Tianwen Xi and Hui Yang and Leming Sun},
  doi          = {10.1016/j.matdes.2025.114758},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114758},
  shortjournal = {Mater. Des.},
  title        = {Self-assembly of bortezomib nanofibers for solid tumor and bone metastasis therapy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wire-arc directed energy deposition of metastable-β alloy ti-15 V-3Cr-3Sn-3Al using thick wire feedstock: Microstructure and mechanical response. <em>MATDES</em>, <em>259</em>, 114757. (<a href='https://doi.org/10.1016/j.matdes.2025.114757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ti-15V-3Cr-3Sn-3Al is a metastable-β alloy initially developed to improve cold formability and reduce downstream processing costs compared to hot-forming Ti-6Al-4V. It is primarily used in sheet and welded forms, with secondary applications in castings and forgings. However, high formulation costs and strict process windows reduce expected cost benefits. This study explores an alternative manufacturing route for large-scale components using the available thick wire format (Ø3.0 mm). Ti-15V-3Cr-3Sn-3Al was deposited via plasma-based wire-arc directed energy deposition. Samples were evaluated in two conditions: (1) solution-treated (2) solution-treated and aged. Mechanical testing included tensile and hardness measurements, while microstructural analysis used a broad range of techniques. Deformation behaviour and fracture surfaces were also examined. The β-phase microstructure in the as-built condition contained α GB at grain boundaries, which dissolved during solution treatment, leaving a fully β-phase matrix. Aging resulted in the precipitation of fine α-laths, providing expected strengthening. In this condition, the material achieved an ultimate tensile strength > 1150 MPa and failure strain > 6 %, with anisotropy observed only in ductility. In the solution-treated condition, continuous softening was observed during tensile testing. This study provides insight into properties of Ti-15V-3Cr-3Sn-3Al in additive manufacturing, laying the groundwork for alternative processing routes for titanium alloys.},
  archive      = {J_MATDES},
  author       = {José L. Neves and Tomasz Wojcik and David Obersteiner and Johann Grillitsch and David Holec and Daniel Kiener and Thomas Klein},
  doi          = {10.1016/j.matdes.2025.114757},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114757},
  shortjournal = {Mater. Des.},
  title        = {Wire-arc directed energy deposition of metastable-β alloy ti-15 V-3Cr-3Sn-3Al using thick wire feedstock: Microstructure and mechanical response},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming the challenges of fusion-based brass additive manufacturing through solid-state additive friction-stir deposition. <em>MATDES</em>, <em>259</em>, 114756. (<a href='https://doi.org/10.1016/j.matdes.2025.114756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing Cu-Zn alloys (brass) using fusion-based additive manufacturing (AM) techniques presents significant challenges due to volatile elements and the inherently high thermal conductivity of these alloys. Addressing these issues often demands increased energy input, modifications to laser systems, and compositional adjustments to mitigate zinc loss. However, such solutions are complex and remain in the early stages of development. In contrast, Additive friction stir deposition (AFSD), a solid-state AM technique, offers a promising alternative to overcome these limitations. This study represents a pioneering effort to deposit dual-phase brass (Cu-40Zn) using a closed-loop temperature-controlled AFSD. The influence of processing temperature (ranging from 0.38 to 0.61 T p /T m ) on microstructural evolution and mechanical performance was systematically investigated along the build and longitudinal direction. The resulting microstructure was predominantly governed by dynamic recrystallization and post-dynamic recrystallization (P-DRX) due to repeated thermal cycles. The as-deposited brass exhibited a balanced strength-ductility combination, with yield strength ranging from 215 to 437 MPa and elongation from 34 % to 67 %. Tensile properties in longitudinal and build directions revealed that grain boundary strengthening was the primary mechanism for improving the mechanical performance. The as-deposited properties were comparable to those of wrought counterparts, thus highlighting the potential of AFSD for fabricating high-performance brass components.},
  archive      = {J_MATDES},
  author       = {Meet Gor and Matthew Barnett and Pinaki Bhattacharjee and Daniel Fabijanic},
  doi          = {10.1016/j.matdes.2025.114756},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114756},
  shortjournal = {Mater. Des.},
  title        = {Overcoming the challenges of fusion-based brass additive manufacturing through solid-state additive friction-stir deposition},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-temperature viscoelastic mechanism for SiC fibers to elucidate creep and recovery behaviors. <em>MATDES</em>, <em>259</em>, 114755. (<a href='https://doi.org/10.1016/j.matdes.2025.114755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mastering the high-temperature creep behavior of SiC fibers plays pivotal role in designing reinforced ceramic matrix composites. Creep viscoelastic behavior is activated at higher temperatures due to complicated interactive coordination between grain interiors and grain boundaries. This study investigated the tensile creep behaviors at different generations of SiC fibers under conditions of various stress and temperatures. The creep recovery behaviors after unloading exhibits the viscoelastic nature, which comes from the possible motion of amorphous phase near massive grain boundaries. It is driven by the release of elastic energy of the grain boundary, evidenced by frequency shifts in Raman spectroscopy. Then classical diffusion creep theory is modified to a viscoelastic model incorporating physical parameters such as the elasticity, viscosity, and threshold stress for SiC fibers. The proposed equations have been well supported by creep test results. The viscosity and elasticity parameters decrease with increasing temperature, the latter being more sensitive. 3rd generation fiber exhibits higher viscosity and elasticity, explaining better creep resistance. The model can evaluate the elastic and plastic contributions and predict creep results at higher temperatures. This work helps to understand high-temperature SiC fiber creep, and to guide optimizing fiber-reinforced composites.},
  archive      = {J_MATDES},
  author       = {Wenguo Jiang and Yi Ru and Jundong Shi and Haozhang Hou and Zexu Sun and Weiwei Qu and Xiaotian Hu and Guoquan Ma and Lianyi Wang and Yanling Pei and Shusuo Li and Shengkai Gong},
  doi          = {10.1016/j.matdes.2025.114755},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114755},
  shortjournal = {Mater. Des.},
  title        = {High-temperature viscoelastic mechanism for SiC fibers to elucidate creep and recovery behaviors},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aqua-powered hybrid solar cell using amorphous conformal Ga2O3 thin-film. <em>MATDES</em>, <em>259</em>, 114754. (<a href='https://doi.org/10.1016/j.matdes.2025.114754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clean energy generation is a primary demand to neutralise carbon emissions. Photovoltaics are the best candidates for clean energy. Water is a reliable and sufficient resource for future clean energy generation, as it can be used to enhance photovoltaic performance in a hybrid system. This study designs and investigates a novel aqua-voltaic hybrid solar cell by integrating an ultra-thin gallium oxide layer (2.3 nm) with a polycrystalline silicon solar cell under water-based conditions. The amorphous Ga 2 O 3 layer grown by sputtering enhances optical absorption, reduces surface reflectance in the ultraviolet (UV) region, and serves as a protective barrier against environmental degradation. Photovoltaic characterisations reveal an efficiency enhancement from 19.04 % to 21.56 % in Si solar cell when Ga 2 O 3 and water are introduced. Under illumination, electrochemical impedance spectroscopy (EIS) exhibits capacitance and resistance, indicating strong interfacial charge dynamics. These phenomena are attributed to electronic double-layer capacitance, quantum capacitance modulation, and charge redistribution at the Ga 2 O 3 -water interface. The results illustrate the dual role of water in enhancing charge transport while influencing surface-state interactions, leading to improved solar cell performance. This work provides insights into the interaction of semiconductor-liquid interfaces and offers an efficient hybrid energy harvesting technologies.},
  archive      = {J_MATDES},
  author       = {Md Arifur Rahman Barno and Malkeshkumar Patel and Shubham Umeshkumar Gupta and Sourov Hossain and Sanh Vo Thi and Cho Seung Hee and Joondong Kim},
  doi          = {10.1016/j.matdes.2025.114754},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114754},
  shortjournal = {Mater. Des.},
  title        = {Aqua-powered hybrid solar cell using amorphous conformal Ga2O3 thin-film},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Direct joining of sapphire and invar alloy by nanosecond laser. <em>MATDES</em>, <em>259</em>, 114753. (<a href='https://doi.org/10.1016/j.matdes.2025.114753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The direct joining of single-crystal sapphire and Invar alloy using a nanosecond laser is demonstrated for the first time in this study. The macro- and microstructures of the sapphire/Invar alloy joints were analyzed, along with an investigation of their compositional characteristics. Based on this, the effects of nanosecond laser processing parameters on the joint’s macro- and microstructures and its mechanical performance were explored. The typical fracture morphologies of the sapphire/Invar alloy joints were examined, revealing the fracture mechanisms involved. The laser-irradiated area exhibited a conical molten zone, predominantly composed of sapphire with a small amount of Invar alloy particles. No new phases were detected in the joint region, and the primary joining mechanism was identified as mechanical interlocking and embedding. After optimizing the nanosecond laser welding parameters, the joint’s shear strength reached 123.2 MPa. Additionally, the sealed sapphire/Invar alloy samples welded by nanosecond laser passed a 336-hour water resistance test without any leakage. The mechanical interlocking effect generated by the conical weld seam structure in the laser-irradiated area played a key role in enhancing shear strength.},
  archive      = {J_MATDES},
  author       = {Rui Pan and Yinghao Feng and Pei Chen and Lizhong Wang and Shujun Chen},
  doi          = {10.1016/j.matdes.2025.114753},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114753},
  shortjournal = {Mater. Des.},
  title        = {Direct joining of sapphire and invar alloy by nanosecond laser},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructured Y3Al5O12 single-crystal fibers for high-sensitivity quasi-distributed ultrasonic thermometry based on acoustic anisotropy engineering. <em>MATDES</em>, <em>259</em>, 114751. (<a href='https://doi.org/10.1016/j.matdes.2025.114751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of aerospace, nuclear energy, and advanced manufacturing has created a growing demand for temperature sensing in extreme environments. Ultrasonic temperature sensors (UTS) are widely used in high-temperature sensing due to their extreme operating temperature close to the melting point of the waveguide materials. In this work, YAG single-crystal fibers (SCF) with spatially distributed acoustic reflection microstructures have been successfully fabricated via the laser-heated pedestal growth (LHPG) method and employed as acoustic waveguides. Herein, anisotropic acoustic waveguide behaviors were revealed in YAG SCF, where the [110]-oriented YAG SCF demonstrates enhanced unit sensitivity with the S-wave polarization direction of [ 1 1 ¯ 0 ], primarily attributed to the lower acoustic velocity and the more substantial velocity variations with temperature. Furthermore, quasi-distributed ultrasonic temperature sensing in the range of 30-1800℃ has been achieved based on the [110]-oriented YAG SCF with two discrete sensing units, reaching the maximum unit sensitivities of 47.18 ns·℃ -1 ·m - 1 and an optimal temperature resolution of 5.04℃ at 1800℃. Superior acoustic waveguide characteristics, a wide working temperature range, and the positive temperature-dependent sensor performance suggest that the [110]-oriented microstructured YAG SCF is an ideal candidate for distributed high-temperature sensing in harsh environments.},
  archive      = {J_MATDES},
  author       = {Kaihui Zhang and Tao Wang and Mingji Zhang and Xin Guan and Zhengmin Wang and Wenchang Zhuang and Liang Zhang and Jian Zhang and Zhitai Jia},
  doi          = {10.1016/j.matdes.2025.114751},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114751},
  shortjournal = {Mater. Des.},
  title        = {Microstructured Y3Al5O12 single-crystal fibers for high-sensitivity quasi-distributed ultrasonic thermometry based on acoustic anisotropy engineering},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Static recrystallization characteristics and kinetics of austenitic stainless steels under development for LH2 storage applications. <em>MATDES</em>, <em>259</em>, 114750. (<a href='https://doi.org/10.1016/j.matdes.2025.114750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing high-strength austenitic stainless steel (ASS) grades for lightweight cryogenic storage tanks, particularly for liquefied hydrogen (LH 2 ), demands precise microstructure control achievable via optimized thermomechanically controlled processing (TMCP). In recrystallization–controlled regime of TMCP, successive rolling passes facilitate microstructural refinement through dynamic and static restoration mechanisms. This work illustrates static recrystallization (SRX) characteristics and kinetics in three ASS alloys designed by varying N, Mn and Nb contents. Interrupted (double–hit) compression tests were conducted to characterize the flow behaviour and microstructural evolution across different deformation conditions. SRX kinetics were formulated using a fractional–softening framework, where the time to 50 % recrystallization was correlated with strain, strain rate, temperature, and initial grain size. While the exponents of strain (−3.1) and strain rate (−0.3) were consistent across all compositions, the apparent activation energies of SRX varied in the range 251.5–298 kJ·mol −1 , with 7 wt% Mn showing a more noticeable effect in comparison with 0.1 wt% Nb. Detailed metallographic analysis confirmed the accuracy of the derived models. Suitable semi-empirical relations were established enabling prediction of statically recrystallised grain size across various processing conditions. These results define the processing windows needed to design TMCP schedules for advanced ASSs for LH 2 and cryogenic environments.},
  archive      = {J_MATDES},
  author       = {Mahesh Somani and Sumit Ghosh and Juha Uusitalo and Frank Hoffmann and Marta Muratori and Ali Smith and Ahmed W. Abdelghany},
  doi          = {10.1016/j.matdes.2025.114750},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114750},
  shortjournal = {Mater. Des.},
  title        = {Static recrystallization characteristics and kinetics of austenitic stainless steels under development for LH2 storage applications},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bonding of vanadium- and iron-based alloys as interlayers for plasma-facing and structural materials in fusion systems. <em>MATDES</em>, <em>259</em>, 114749. (<a href='https://doi.org/10.1016/j.matdes.2025.114749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vanadium alloys and FeCrAl were investigated as interlayers between tungsten and reduced activation ferritic martensitic steel for fusion system components to avoid formation of intermetallic phase at operating temperatures between 550 and 1100 °C, while maintaining a body centered cubic phase throughout the interface. Physical and mechanical properties need to be graded between tungsten and steel, but recent results showed a significant hardness increase at the FeCrAl to vanadium alloy interface. Here, a sintered sample of these alloys was annealed for extended time, and the microstructure was investigated to provide a better understanding of the phenomena. A comparison with an additively manufactured interface of the same material is provided. An unexpected L2 1 intermetallic phase formation has been revealed using microscopy and synchrotron techniques and will inform future additive manufacturing approaches of the interface. A Cr layer interface as a preliminary solution was proposed between the Vanadium alloy and FeCrAl alloy interface.},
  archive      = {J_MATDES},
  author       = {Tim Gräning and Deniz Ebeperi and Ibrahim Karaman and Ishtiaque Robin and Mobashera Saima Haque and Akhil Kolanti and David Sprouster and Lance Snead and Yutai Katoh},
  doi          = {10.1016/j.matdes.2025.114749},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114749},
  shortjournal = {Mater. Des.},
  title        = {Bonding of vanadium- and iron-based alloys as interlayers for plasma-facing and structural materials in fusion systems},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic strength and conductivity enhancement via induced 〈0 0 1〉-textured ultrafine grains in Al2O3/Cu composites. <em>MATDES</em>, <em>259</em>, 114748. (<a href='https://doi.org/10.1016/j.matdes.2025.114748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overcoming the strength–conductivity trade-off in Al 2 O 3 /Cu composites remains a key challenge. Here, we propose a microstructural design strategy that combines 〈0 0 1〉 texture with elongated ultrafine grains. Room-temperature rotary swaging (RS), assisted by the pinning effect of Al 2 O 3 particles, promotes the selective formation of 〈0 0 1〉-oriented grains through compressive–shear deformation and enhances grain aspect ratios. The resulting structure provides texture-dominated conductive paths while reducing transverse grain boundary density. Consequently, the composite achieves a yield strength of 342 MPa and an electrical conductivity of 95.3 % IACS—representing a 56.8 % strength increase over the Cu matrix without sacrificing conductivity. This work demonstrates a scalable, room-temperature route to high-performance Cu-based composites with an exceptional strength–conductivity balance for advanced electrical applications.},
  archive      = {J_MATDES},
  author       = {Song Liu and Shaolin Li and Kexing Song and Xiaowen Peng and Xiuhua Guo and Zhenhan Zhou and Shuaibin Li and Fuxiao Chen},
  doi          = {10.1016/j.matdes.2025.114748},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114748},
  shortjournal = {Mater. Des.},
  title        = {Synergistic strength and conductivity enhancement via induced 〈0 0 1〉-textured ultrafine grains in Al2O3/Cu composites},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D-printed barriers with machine learning powered image analysis for enhanced wound healing assays. <em>MATDES</em>, <em>259</em>, 114746. (<a href='https://doi.org/10.1016/j.matdes.2025.114746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wound healing assay is a standard method enabling investigation of cell proliferation and migration through a cell-free gap in a cell monolayer. Despite very common, it shows several weaknesses: lack of reproducibility and manual and time-based image analysis. Based on novel approach founded on innovative materials and AI-assisted processing of biological images, a promising automated barrier-wound healing assay is realized, achieving consistent results while retaining cells integrity. To increase assay accuracy, biocompatible 3D-printed resin inserts have been developed, facilitating precise control over shape and size of the wound. In parallel, a new image-detection algorithm powered by Deep Learning models was developed to identify cell-free area during the healing process, exceeding limitations of manual analysis. 3D-resin inserts combined with automated image analysis allowed the elimination of subjective errors and provided reproducible quantification of cell-free areas across multiple experiments. Moreover, a dataset to train a Convolutional Neural Network for monitor healing over time was developed. As proof of concept, this algorithm was tested on a cancer cell line stimulated by TGF-β, a drug stimulating cell migration. Innovative design of biocompatible materials combined with Deep Learning for automatically processing high-throughput data enables standardized wound healing assay, increasing efficiency, reliability, and accuracy of results.},
  archive      = {J_MATDES},
  author       = {Alfredo De Cillis and Valeria Garzarelli and Alessia Foscarini and Giuseppe Gigli and Antonio Turco and Elisabetta Primiceri and Maria Serena Chiriacò and Francesco Ferrara},
  doi          = {10.1016/j.matdes.2025.114746},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114746},
  shortjournal = {Mater. Des.},
  title        = {3D-printed barriers with machine learning powered image analysis for enhanced wound healing assays},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced morphology and conductivity in aerosol jet printing via optimization of print speed range under various deposition rate. <em>MATDES</em>, <em>259</em>, 114745. (<a href='https://doi.org/10.1016/j.matdes.2025.114745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerosol Jet (AJ) printing is becoming increasingly attractive for printed conformal electronics due to its non-contact capability. However, the impact of deposition rate and print speed on the morphology and electrical properties of printed traces remains unclear. In this study, AJ printed traces with different print speed (0.3–20 mm/s) under commonly used deposition rate values (0.0002, 0.0004 and 0.0006 mm 3 /s) were examined. After evaluating the corresponding morphology and conductivity of the printed traces, the optimal print speed range of each deposition rate was determined as follows: deposition rate of 0.0002 mm 3 /s as 0.3–1.5 mm/s, 0.0004 mm 3 /s as 0.7–4 mm/s, and 0.0006 mm 3 /s as 1–6 mm/s, respectively. A three-dimensional computational fluid dynamics (CFD) model is proposed to elucidate the fundamental aerodynamic behaviors of AJ printed traces under different deposition rate, and its trends align with experimental observations. The mechanism by which print speed influences conductivity was analyzed, revealing that internal porosity is the primary factor reducing conductivity at low print speed. The analysis of morphology, conductivity, and printing efficiency across various print modes revealed that the morphology of printed traces under the respective deposition rate and print speed combination remained consistent in single-layer printing. Notably, printing efficiency is substantially enhanced at elevated deposition rate and high print speed. Compared to multi-layer printing at low deposition rate, high deposition rate single-layer printing emerges as the optimal method for achieving superior efficiency and conductivity. Ultimately, a correlation was established between resistance, print speed, and deposition rate, that enabling the successful printing of 15 resistors with specific resistance values (20 Ω) for different geometries, within an average error of 5.9 %, thereby broadening the applicability of AJ printing in printed electronics.},
  archive      = {J_MATDES},
  author       = {Xuanbo Jiang and Zijun Yan and Yingjie Niu and Xuan Zhang and Teng Ma and Hui Cheng and Kaifu Zhang and Chenglin Yi},
  doi          = {10.1016/j.matdes.2025.114745},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114745},
  shortjournal = {Mater. Des.},
  title        = {Enhanced morphology and conductivity in aerosol jet printing via optimization of print speed range under various deposition rate},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multichannel hollow carbon fiber reinforcement in an epoxy resin matrix for direct ink writing of high-performance composites. <em>MATDES</em>, <em>259</em>, 114744. (<a href='https://doi.org/10.1016/j.matdes.2025.114744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon-fiber reinforced polymers are widely used in additive manufacturing for high-performance composites. However, the aerospace and automotive sectors seek lighter materials compatible with practical processing methods. This study introduces hollow carbon fibers (HCFs) with a honeycomb cross-section as lightweight reinforcements in composites, fabricated via direct ink writing. The printability, mechanical performance, and microstructural features of HCF-based composites were systematically evaluated. Rheological testing showed that HCF-based inks exhibit similar pre-printing properties to conventional, densified carbon fiber (DCF) inks. However, mechanical tests revealed superior strength in traditional DCF composites due to differences in fiber morphology, density, and diameter. Microstructural analysis using small-angle X-ray scattering (SAXS) and optical microscopy indicated comparable fiber alignment, while scanning electron microscopy (SEM) showed complete epoxy infiltration in HCF channels, evidenced by the pullout of cured epoxy strands. While fiber–matrix interlocking was expected to enhance strength, weak bonding within HCF interiors contributed to reduced mechanical strength. Despite lower strength, HCFs offer advantages for applications prioritizing weight reduction, thermal insulation, or fluid permeability, such as lightweight aerospace and automotive components, thermal management systems, and filtration media. The hollow structure also enables integration with functional materials for smart materials and energy storage.},
  archive      = {J_MATDES},
  author       = {Olivia K. Meyer and Roneisha Haney and Tyler Bauder and Kishor Gupta and Hellen Stephanie and Jefferson Bordeau and Cliff Wood and Keenan Mintz and Satish Kumar and Hilmar Koerner and Harshita Kumari},
  doi          = {10.1016/j.matdes.2025.114744},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114744},
  shortjournal = {Mater. Des.},
  title        = {Multichannel hollow carbon fiber reinforcement in an epoxy resin matrix for direct ink writing of high-performance composites},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultralight pt-ALD-modified graphene aerogel achieving aluminum-class thermal resistance at 12% mass. <em>MATDES</em>, <em>259</em>, 114742. (<a href='https://doi.org/10.1016/j.matdes.2025.114742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphene aerogels (GAs), a class of three-dimensional porous structures, are limited by a fundamental challenge: low thermal conductivity stemming from high interfacial resistance between constituent layers and structural defects. This study systematically investigates a strategy to enhance thermal transport properties by engineering the interlayer bonding via platinum atomic layer deposition (Pt-ALD) and compares it with conventional high-temperature annealing (1873 K). The Pt-ALD-modified graphene aerogel (GA-ALD) exhibited a 199 % increase in thermal conductivity, significantly surpassing the 113 % enhancement from heat treatment. SEM, Raman, XRD, XPS, and FTIR data explicitly indicate that Pt-ALD forms covalent Pt O C bonds that bridge adjacent graphene layers while preserving the original porous morphology. Owing to the synergistic effect of enhanced solid-phase thermal conductivity and efficient convective heat transfer through the preserved porous structure, the GA-ALD sample achieved a total thermal resistance comparable to that of an equal-sized aluminum heat sink under identical forced-convection conditions, while weighing only ∼12 % of its aluminum counterpart. Moreover, cyclic compressive tests confirmed GA-ALD durability, retaining 99.5 % height and 94.7 % stress after 1000 cycles. These findings demonstrate that interfacial bond engineering via ALD is a powerful route to ultralight, high-performance carbon aerogels for weight-sensitive thermal-management applications.},
  archive      = {J_MATDES},
  author       = {Jiho Kang and Viet Phuong Nguyen and Seung-Mo Lee and Duckjong Kim},
  doi          = {10.1016/j.matdes.2025.114742},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114742},
  shortjournal = {Mater. Des.},
  title        = {Ultralight pt-ALD-modified graphene aerogel achieving aluminum-class thermal resistance at 12% mass},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser powder bed fusion of a novel CoNi-based high entropy superalloy. <em>MATDES</em>, <em>259</em>, 114741. (<a href='https://doi.org/10.1016/j.matdes.2025.114741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser powder bed fusion (L-PBF) is poised to revolutionize the manufacturing of high-value metallic materials, allowing for intricate, geometrically complex designs while minimizing material waste. The primary challenge lies in formulating alloys compatible with L-PBF that also maintain properties suitable for the demanding conditions encountered in energy, space, and nuclear applications. We introduce a category of high strength, defect-resistant octonary CoNi-based high entropy superalloy (CoNi-HESA), comprising roughly equal parts of Co and Ni, along with Cr, Al, V, Ti, Ta, and W. This alloy exhibits as-printed tensile strength exceeding 1 GPa and tensile ductility exceeding 30 % at room temperature. Furthermore, compression tests demonstrate that the as-printed parts maintain a yield strength of about 1 GPa at room temperature up to 700 °C, which decreases to 0.9 GPa and 0.7 GPa as the test temperature reaches 800 °C and 900 °C, respectively. With a careful combination of laser powder and scan speed, the developed HESA is well-suited for crack-resistant, high-density component production through L-PBF. Alloy design principles are elucidated through CALPHAD calculations based on the high entropy alloy (HEA) database, including the structure and properties of L-PBF processed CoNi-HESA.},
  archive      = {J_MATDES},
  author       = {Alessandro De Nardi and Ahad Mohammadzadeh and Amir Mostafaei and Jose Manuel Torralba},
  doi          = {10.1016/j.matdes.2025.114741},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114741},
  shortjournal = {Mater. Des.},
  title        = {Laser powder bed fusion of a novel CoNi-based high entropy superalloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Al alloying-driven spinodal decomposition enables ultra-strong cast refractory high-entropy alloys. <em>MATDES</em>, <em>259</em>, 114736. (<a href='https://doi.org/10.1016/j.matdes.2025.114736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strengthening in refractory high-entropy alloys (RHEAs) can be achieved through the formation of “compositional heterogeneity” at the atomic scale. Here, we chose Zr 45 Ti 15 Nb 20 Ta 20 alloy with a single-phase body-centered cubic (BCC) structure as a matrix and added a small amount of Al to promote a unique spinodal decomposition. The results show that the introduction of Al-X negative mixing enthalpy induces the RHEAs spinodal decomposition to form a nanocubic structure in the form of a basket-like fabric morphology with a characteristic periodicity of 12 nm. Nanocubic structures consist of (Nb, Ta)-rich cubes and Zr-rich channels as well as generate strong localized strain fields at the interfaces. Spinodal decomposition strengthening enables the as-cast RHEA to achieve a yield strength of 1405 MPa. Periodically distributed nanostructures make dislocations move slowly, causing plugging and cross-slip, facilitating dislocation interactions, multiplication, and accumulation. In summary, the chemical heterostructure produced by spinodal decomposition has been remarkably effective in improving the strength of RHEAs.},
  archive      = {J_MATDES},
  author       = {Yongkang Zhou and Ziyan Zhao and Yuanyuan Wang and Hong Li and Haifeng Zhang and Zhengwang Zhu},
  doi          = {10.1016/j.matdes.2025.114736},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114736},
  shortjournal = {Mater. Des.},
  title        = {Al alloying-driven spinodal decomposition enables ultra-strong cast refractory high-entropy alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving synergistic strength-ductility enhancement in a hierarchical hetero-lamellar AlCoCrFeNi2.1 eutectic high-entropy alloy via facile hot-rolling strategy. <em>MATDES</em>, <em>259</em>, 114734. (<a href='https://doi.org/10.1016/j.matdes.2025.114734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eutectic high-entropy alloys (EHEAs) have attracted considerable interest due to their superior multifunctional performance. However, the inherent tendency of stress concentration at irregular phase boundaries frequently leads to premature fracture. This study presents a facile hot-rolling strategy to achieve synergistic strength-ductility enhancement in AlCoCrFeNi 2.1 EHEA via constructing a hierarchical hetero-lamellar structure (HHLS). Through controlled per-pass rolling reduction (PPRD), we induce strain-partitioning-mediated microstructural refinement in the hot-rolled EHEA and activate synergistic deformation mechanisms including stacking faults, Lomer-Cottrell locks, and deformation twinning. The resultant HHLS (aligned FCC/B2 lamellae, partially recrystallized FCC regions, and intragranular B2 precipitates) triggers pronounced hetero-deformation-induced (HDI) strengthening. Consequently, the EHEA with HHLS exhibits exceptional properties: yield strength of 1202 MPa, ultimate tensile strength of 1489 MPa, and uniform elongation of 11.5 %, which are 112 %, 45 %, and 6 % higher than those of the as-cast alloy, respectively. The superior properties originate from HDI effect and FCC phase-mediated deformation mechanisms, which enable the EHEA to maintain exceptional work-hardening rate despite high dislocation density, effectively delaying plastic instability. These findings not only establish a readily implementable thermomechanical processing strategy for EHEAs, but also provide a novel paradigm for improving mechanical properties, paving the way for their application in high-performance structural materials.},
  archive      = {J_MATDES},
  author       = {Qidong Ren and Tianxin Li and Hengke Xie and Yuhao Jia and Mingpan Wan and Chaowen Huang and Chaoyi Chen and Junqi Li and Yiping Lu},
  doi          = {10.1016/j.matdes.2025.114734},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114734},
  shortjournal = {Mater. Des.},
  title        = {Achieving synergistic strength-ductility enhancement in a hierarchical hetero-lamellar AlCoCrFeNi2.1 eutectic high-entropy alloy via facile hot-rolling strategy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of electroplating current density and post-annealing on the warpage and reliability of redistribution layer for advanced semiconductor package. <em>MATDES</em>, <em>259</em>, 114732. (<a href='https://doi.org/10.1016/j.matdes.2025.114732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the warpage and thermal fatigue reliability of the redistribution layer (RDL) were improved by optimizing the electroplating current density and post-annealing process to control residual stress. The residual stress of the electroplated copper layer and the cure shrinkage of the photo-imageable dielectric (PID) were evaluated using bi-layer beam specimens designed based on Timoshenko beam theory. To analyze the mechanism of residual stress generation in the copper layer, the grain size was quantified using X-ray diffraction (XRD) and the coefficient of thermal expansion (CTE) was measured using a thermomechanical analyzer (TMA). Warpage and thermal fatigue reliability were evaluated under varying electroplating current densities and post-annealing conditions. These experimental results were validated by comparing them with stress analysis data obtained through finite element analysis (FEA). In the RDL structure, the optimized current density condition effectively reduced the residual tensile stress in the electroplated copper layer and improved both warpage and thermal fatigue life. In addition, the post-annealing relieved cure shrinkage-induced stress in the PID, enhancing the reliability of the RDL structure. The results of this study are expected to contribute to improved yield and thermomechanical reliability in advanced semiconductor packages.},
  archive      = {J_MATDES},
  author       = {Taek-Hyeon Kim and Jeong-Hyeon Baek and Sang-Il Kim and Tae-Hoon Kim and Ji-Hye Shim and Hak-Sung Kim},
  doi          = {10.1016/j.matdes.2025.114732},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114732},
  shortjournal = {Mater. Des.},
  title        = {Effect of electroplating current density and post-annealing on the warpage and reliability of redistribution layer for advanced semiconductor package},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In vitro antibacterial and in vivo osteogenesis of 3D-printed magnesium peroxide–doped calcium phosphate silicate scaffolds for revision total knee arthroplasty. <em>MATDES</em>, <em>259</em>, 114731. (<a href='https://doi.org/10.1016/j.matdes.2025.114731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revision total knee arthroplasty (RTKA) often encounters tibial bone defects and high infection risk, especially from methicillin-resistant Staphylococcus aureus (MRSA). Current strategies rely on bone grafts with antibiotics, but prolonged use promotes resistance. Here, we developed a 3D-printed magnesium peroxide (MgO 2 )–doped calcium phosphate silicate (CSP) scaffold to address both structural and antibacterial demands. The MgO 2 –CSP scaffold exhibited cancellous bone-like strength (∼7.95 MPa) and an interconnected macroporous structure conducive to cell migration and healing. In vitro , the 14 wt% MgO 2 scaffold (B14M) inhibited 80.4 % of Gram-negative bacteria and 74.6 % of MRSA via Mg 2+ and H 2 O 2 release, while both B0M (no MgO 2 ) and B14M promoted BMSC proliferation and osteogenic differentiation. In vivo , the B14M scaffold markedly enhanced bone regeneration in rat tibial defects, achieving a BV/TV of ∼73.09 % versus ∼29.84 % for B0M at 8 weeks. These findings highlight MgO 2 –CSP scaffolds as a promising strategy to promote osteogenesis while combating MRSA-associated infections in RTKA.},
  archive      = {J_MATDES},
  author       = {Lisha Meng and Hao Li and Xujia Hao and Tao Wu and Jingqiu Zhou and Yadong Chen and Qiang Zheng and Xiuhong Cao and Juan Wang and Xinwei Liu and Tongmeng Jiang and Tianxing Gong and Wei Yuan},
  doi          = {10.1016/j.matdes.2025.114731},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114731},
  shortjournal = {Mater. Des.},
  title        = {In vitro antibacterial and in vivo osteogenesis of 3D-printed magnesium peroxide–doped calcium phosphate silicate scaffolds for revision total knee arthroplasty},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of synthesis routes on oxygen content, crystallography, and thermal stability of Ti3AlC2 MAX phases and resulting MXenes. <em>MATDES</em>, <em>259</em>, 114729. (<a href='https://doi.org/10.1016/j.matdes.2025.114729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current MXene research focuses on synthesising high-quality MAX phases with minimal O substitution in the C sublattice. This study provides insights into how different ball milling techniques and elemental compositions used in Ti 3 AlC 2 MAX phase synthesis affect the O incorporation into the lattice structure, which directly impacts the MAX phases’ and the resulting MXenes’ thermal stability. The unit cell lattice parameters (LPs) of a MAX phase are well-established indicators in determining the degree of O substitution. The presence of O reduced the a and c LPs of the MAX phase unit cell. However, the corresponding MXenes exhibited similar a LP ( a = 3.05 Å) values regardless of the LP values of their MAX phases. The LP observations are validated by correlative thermogravimetric analysis (TGA) carried out in air atmosphere. With the decreasing O incorporation in the MAX phase, an increase in the oxidation temperature was observed from 450 °C to 780 °C. However, the corresponding MXenes showed an average oxidation onset around 460 °C. Thus, this study reveals an important structure–property relationship between the Ti 3 AlC 2 MAX phase and the resulting Ti 3 C 2 MXenes.},
  archive      = {J_MATDES},
  author       = {Chathushka D. Hettige Dharmasiri and Konstantin L. Firestein and Joseph F.S. Fernando and Xiaodong Wang and Zhenhuan Chen and Dasun P.W. Guruge and Courtney-Elyce Lewis and Dmitri V. Golberg},
  doi          = {10.1016/j.matdes.2025.114729},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114729},
  shortjournal = {Mater. Des.},
  title        = {Influence of synthesis routes on oxygen content, crystallography, and thermal stability of Ti3AlC2 MAX phases and resulting MXenes},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ex vivo porcine urethral model for investigating intermittent catheter-associated urethral microtrauma. <em>MATDES</em>, <em>259</em>, 114727. (<a href='https://doi.org/10.1016/j.matdes.2025.114727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catheter-associated urethral microtrauma is a significant complication of intermittent catheterisation, compromising patient quality of life (QOL) and increasing urinary tract infection risk. Current research is hindered by the lack of robust physiological models to evaluate the mechanical interactions between catheter materials and urethral tissue during intermittent catheterisation. This study introduces the first ex vivo porcine urethral model to investigate tribological performance and material-tissue interactions during intermittent catheter (IC) use, enabling more informed catheter design. We examined four commercial hydrophilic polyvinylpyrrolidone (PVP)-coated ICs and a coating-free integrated amphiphilic surfactant (IAS) IC. ICs were inserted into porcine urethras using a texture analyser, held for two minutes, and withdrawn while measuring force and work done. Post-catheterisation, urethras were examined for microtrauma. Three of four PVP-coated catheters required significantly greater withdrawal force compared to the IAS catheter, correlating with increased urethral transitional membrane damage post-catheterisation. Ex vivo findings suggest that IAS catheters may lower the risk of complications compared with PVP-coated catheters in intermittent catheterisation. This study provides a new platform for comprehensive evaluation of IC-tissue interactions. It underscores the importance of tribological design in medical devices, aiding future innovation in device design and ultimately improve the QOL of patients undergoing intermittent catheterisation.},
  archive      = {J_MATDES},
  author       = {Jane Burns and Robyn N. Irwin and James Quinn and Jessica V. Moore and David Pollard and Ased Ali and James Hands and Colin P. McCoy and Louise Carson and Matthew P. Wylie},
  doi          = {10.1016/j.matdes.2025.114727},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114727},
  shortjournal = {Mater. Des.},
  title        = {An ex vivo porcine urethral model for investigating intermittent catheter-associated urethral microtrauma},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNN-based shape optimization of gradient-index phononic crystals with sensitivity analysis for tunable focal position and robust energy harvesting. <em>MATDES</em>, <em>259</em>, 114723. (<a href='https://doi.org/10.1016/j.matdes.2025.114723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-index (GRIN) phononic crystals (PnCs) enable energy harvesting (EH) by focusing elastic waves into electrical energy. Efficient EH requires maximizing focused wave intensity, typically achieved by tuning the GRIN PnCs unit-cell shape. However, existing designs often exhibit energy concentration near the GRIN lens boundary and incorporate narrow gaps and sharp corners, making them susceptible to manufacturing errors and limiting their practical applicability. Understanding the potential performance changes caused by manufacturing errors is important because geometrical alterations can compromise wave-focusing performance. Therefore, this study aims to optimize the unit-cell shape toward maximum focused intensity at the desired locations for EH devices. To assess manufacturability, the effects of minor geometric variations on the focal position and focused intensity are evaluated via a sensitivity analysis. The optimal shape is derived using a deep neural network (DNN) surrogate model trained to predict focal position and focused intensity. This model accelerates a genetic algorithm (GA) used to perform the optimization. Our optimized designs exhibit 1.5 to 2.0 times higher focused intensity across the target focal positions compared with the conventional design. Thus, these optimal shapes, along with their sensitivity analysis results, provide practical guidelines for defining manufacturing tolerances and achieving consistent, efficient EH performance.},
  archive      = {J_MATDES},
  author       = {Mary Kim and Sangryun Lee},
  doi          = {10.1016/j.matdes.2025.114723},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114723},
  shortjournal = {Mater. Des.},
  title        = {DNN-based shape optimization of gradient-index phononic crystals with sensitivity analysis for tunable focal position and robust energy harvesting},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving high oxygen tolerance in Ti6Al4V: Copper-oxygen co-doping strategy for ultrahigh strength-ductility balance. <em>MATDES</em>, <em>259</em>, 114719. (<a href='https://doi.org/10.1016/j.matdes.2025.114719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional α + β Ti6Al4V alloys lack sufficient strengthening mechanisms, limiting strength. While oxygen (O) offers a cost-effective strengthening route, exceeding ∼ 0.33 wt% causes significant embrittlement. Here, we explored how to efficiently utilize interstitial oxygen to enhance the mechanical properties of Ti6Al4V. The copper oxide (CuO) was innovatively employed as a precursor to completely dissolve into Ti6Al4V matrix, interstitial O and substitutional Cu atoms were simultaneously utilized to strengthen the primary α-phase (α p ) while inducing the abundant secondary-α (α s ) nanoprecipitates. Surprisingly, the introduction of Cu element facilitated control of lattice distortion and redistributed oxygen between α p and β-transformed (β trans ) structure, resulting in the Ti6Al4V-2.5CuO (wt.%) alloy with high oxygen tolerance (0.62 wt%) and an ultra-high ultimate strength of ∼ 1635 MPa and a favorable ductility of ∼ 5.3 %. The dual effect of interstitial solid solution strengthening and α s precipitation strengthening were achieved under the Cu/O interaction. Additionally, the addition of Cu promoted the oxygen redistribution and activation of the basal < a > and pyramidal < c + a > slip systems, thereby ensuring improved ductility. This study presented a novel strategy for high-strength Ti alloys using interstitial oxygen, maximizing strengthening while mitigating embrittlement.},
  archive      = {J_MATDES},
  author       = {Hongqiang Duan and Hongmei Zhang and Xingwang Cheng and Xiaonan Mu and Qunbo Fan and Ying Zhang and Ni Xiong and Ke Feng and Yu Wang and Xuexia Li and Taotao Cai and Kefan Zheng},
  doi          = {10.1016/j.matdes.2025.114719},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114719},
  shortjournal = {Mater. Des.},
  title        = {Achieving high oxygen tolerance in Ti6Al4V: Copper-oxygen co-doping strategy for ultrahigh strength-ductility balance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crack deflection by design – Utilizing the material inhomogeneity effect on miniaturized additively manufactured structures. <em>MATDES</em>, <em>259</em>, 114718. (<a href='https://doi.org/10.1016/j.matdes.2025.114718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A natural crack exhibits a surrounding stress field, which may overlap considerably with a stress field caused by any material inhomogeneity, influencing the crack driving force and extension direction. To utilize this effect for potentially increasing the apparent toughness, a defined pore is introduced near a potential crack path, whereby upon interaction, the crack tip can be deflected or trapped, depending on the intermediate distance. Since fundamental mechanics is well-known, a miniaturized notched bending specimen geometry incorporating a pore was selected to investigate the application potential for parts manufactured via multi-photon lithography. The size regime is representative of the smallest available objects and requires in situ SEM testing, which was completed with finite element modeling based on crack path prediction through analyzing the local crack driving force. The high dimensional repeatability of the process allowed for testing reliably reproduced specimens with variation of crack to pore distance only. The prediction represented the actual crack paths well, underlining successfully facilitated crack path alteration. The toughness was mainly increased by crack trapping within the pore, where deflection had a quantitatively negligible effect.},
  archive      = {J_MATDES},
  author       = {Alexander Jelinek and Markus Alfreider and Dražen Breščaković and Otmar Kolednik and Daniel Kiener},
  doi          = {10.1016/j.matdes.2025.114718},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114718},
  shortjournal = {Mater. Des.},
  title        = {Crack deflection by design – Utilizing the material inhomogeneity effect on miniaturized additively manufactured structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Damping properties of single-material and bi-material lattice structures. <em>MATDES</em>, <em>259</em>, 114710. (<a href='https://doi.org/10.1016/j.matdes.2025.114710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice structure is widely used to achieve lightweight while damping is an indispensable property for evaluating the dynamic properties of lattice structures. This paper studies the damping performance of the lattice structures by experiments and analysis. A series of lattice specimens including single-material and bi-material lattices are prepared. The bi-material lattice is designed by filling the metal lattice with epoxy material. By this way, the stiffness of the bi-material lattice is guaranteed, and the effect of vibration absorption is realized at the same time. Different from the traditional proportional damping method of single-material structure, the non-proportional damping model is used for the bi-material lattice structure. The homogenization method is used to calculate the equivalent complex modulus of the lattice. An inverse method is proposed in this paper to obtain the loss factor of in-situ epoxy material filled in the metal lattice. Finally, lattice specimens with local damping are prepared and tested, and the experimental and simulation data are compared.},
  archive      = {J_MATDES},
  author       = {Haotian Wang and Bin Niu and Rui Yang},
  doi          = {10.1016/j.matdes.2025.114710},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114710},
  shortjournal = {Mater. Des.},
  title        = {Damping properties of single-material and bi-material lattice structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adenosine-loaded adhesive microfluidic hydrogel microspheres stimulate acupoint activation for pain management. <em>MATDES</em>, <em>259</em>, 114708. (<a href='https://doi.org/10.1016/j.matdes.2025.114708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pain represents a significant public health challenge with substantial clinical and economic burdens. While pharmacotherapy remains a mainstay of pain management, its utility is limited by adverse side effects and the potential for dependency. Acupuncture has shown great potential in pain management through its ability to induce analgesic effects via acupoint stimulation. However, its poor specificity and ill-defined stimulation parameters compromise therapeutic specificity and reproducibility. Herein, we developed a biomaterial-based acupoint activation strategy for pain management. Adhesive polydopamine-coated hydrogel microspheres were fabricated using microfluidic techniques for accurate attachment and activation of acupoints. Adhesive hydrogel microspheres loaded with adenosine can slowly release exogenous adenosine at the ST36 acupoint to simulate the analgesic effect of acupuncture. In vitro and in vivo studies demonstrated that single-dose administration of adhesive microspheres can effectively target acupoints, elevate mechanical pain thresholds, and provide systemic anti-inflammatory effects for up to 7 days. Overall, the proposed adhesive hydrogel microsphere system offers a new perspective on acupuncture practice and pain management.},
  archive      = {J_MATDES},
  author       = {Xiujuan Li and Zehao Chen and Songgen Chen and Han Wang and Lin Fu and Ban Feng and Hui Chen and Lize Xiong},
  doi          = {10.1016/j.matdes.2025.114708},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114708},
  shortjournal = {Mater. Des.},
  title        = {Adenosine-loaded adhesive microfluidic hydrogel microspheres stimulate acupoint activation for pain management},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Study and characterization of recycled ABS-GF in large format additive manufacturing to enhance mechanical properties of printed structures. <em>MATDES</em>, <em>259</em>, 114707. (<a href='https://doi.org/10.1016/j.matdes.2025.114707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large format additive manufacturing (LFAM) has proven its ability to produce high-performance components for competitive markets. By depositing material only where it's needed, it drastically reduces waste material and energy use, obtaining a sustainability advantage that is further enhanced on larger scale. However, a deeper understanding of material recycling is critical to achieving the next milestone in sustainability. In this work, a methodology was proposed that uses both molds and final parts, manufactured in acrylonitrile-butadiene-styrene reinforced with short glass fibers (ABS-GF), which had reached the end of their useful life to be used as feedstock. It is observed that recycling reduces fiber length by 47.3%, which directly impacts the mechanical properties in the longitudinal printing direction, resulting in around a 9% decrease in maximum tensile stress. However, this reduction falls to 5.1% in the transverse direction to the printing, and in some cases, the recycled material even surpasses the virgin material due to improved interlayer adhesion. An analysis on the adhesion reveals that the shorter monomer chains obtained during recycling allow better interlacing between layers. These results suggest that the reuse of the molds is viable and by adjusting the printing parameters we can obtain properties suitable for demanding applications.},
  archive      = {J_MATDES},
  author       = {Javier Bas-Bolufer and Pablo Castelló-Pedrero and Cesar García-Gascón and Juan Antonio García-Manrique},
  doi          = {10.1016/j.matdes.2025.114707},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114707},
  shortjournal = {Mater. Des.},
  title        = {Study and characterization of recycled ABS-GF in large format additive manufacturing to enhance mechanical properties of printed structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology optimization of 3D-printed material architectures: Testing toolpath consideration in design. <em>MATDES</em>, <em>259</em>, 114700. (<a href='https://doi.org/10.1016/j.matdes.2025.114700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology Optimization (TO) methods applied to the design of material architectures allow for a wider exploration of the possible design space when compared to common geometry parameter controlled design methods. These optimal designs are often realized using Direct Ink Writing methods which exhibit characteristic features of discrete bead sizes and weak bead bonding. The resultant lack of design fidelity and toolpath dependent anisotropy has been found to negatively impact structural performance if not accounted for in the design. This paper addresses both characteristics in the design process of cellular material architectures by expanding upon the Nozzle Constrained Topology Optimization algorithm and experimentally validating the results against a typical baseline. An experimental method of deriving bond region material properties is detailed. A direct toolpath generation method from topology optimized results is proposed. Comparisons are made with conventional topology optimization design methods and performance is measured both experimentally and numerically against theoretical bounds. At relative densities ≤ 70 % , designs with nozzle constraints were able to more closely align numerical and experimental results for both performance and design fidelity (measured by relative density). In contrast, conventional topology optimized designs had higher overall performance, but little alignment between intended design and resultant experimental result. Typical designs consistently overdeposited material and inconsistently predicted performance.},
  archive      = {J_MATDES},
  author       = {Hajin Kim-Tackowiak and Josephine V. Carstensen},
  doi          = {10.1016/j.matdes.2025.114700},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114700},
  shortjournal = {Mater. Des.},
  title        = {Topology optimization of 3D-printed material architectures: Testing toolpath consideration in design},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forming-induced thickness effects on structural response of arched thin-shell metal alloys. <em>MATDES</em>, <em>259</em>, 114692. (<a href='https://doi.org/10.1016/j.matdes.2025.114692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical influence of forming-induced thickness variations on arched thin-shell metal components' structural response and rupture behavior, a key challenge in safety-critical applications. An integrated predictive framework combines classical plate theory for initial deformation estimates, explicit dynamic finite element simulations for elastic-plastic analysis, and Kriging-based response surface modeling to map geometric, material, and process parameters to performance metrics. A large-scale simulation campaign across eight isotropic material models and 42,669 configurations identifies the arch rise-to-radius ratio as the dominant factor in post-forming thickness evolution, with non-uniform profiles causing up to deviations in rupture pressures and altering failure modes compared to uniform assumptions. Modal, buckling, and rupture analyses highlight significant impacts on natural frequencies, critical loads, and mechanisms. Experimental validation on 36 Monel Alloy 400 rupture discs achieves high accuracy, with thickness root-mean-square error of (maximum mean absolute percentage error ) and rupture pressure errors below , supported by uncertainty analysis (expanded uncertainties at confidence). The generalizable framework, extensible to non-metallic isotropic shells and non-arched geometries, enables enhanced prediction, optimization, and reliability by linking forming outcomes to structural integrity.},
  archive      = {J_MATDES},
  author       = {Shilin Chen and Qingxi Yang and Qingzhou Yu and Genmu Shi and Haotian Yin},
  doi          = {10.1016/j.matdes.2025.114692},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114692},
  shortjournal = {Mater. Des.},
  title        = {Forming-induced thickness effects on structural response of arched thin-shell metal alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond diameters: Decoding fabrication patterns of hierarchical micro-nano titanium implants via anodization and their geometries on region-specific soft-tissue integration. <em>MATDES</em>, <em>259</em>, 114691. (<a href='https://doi.org/10.1016/j.matdes.2025.114691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrochemical anodization creates titania nanopores (TNPs) on Ti implants with distinctive micro-nano geometries to enhance their surface bioactivity, showing the potential to improve soft-tissue integration at varied transmucosal regions. However, understanding how topography regulates TNP dimensions under voltage, and the clinical feasibility of diverse TNP geometries was limited. More crucially, existing research predominantly focused on nanopore diameter, neglecting other geometric characteristics (alignment, texture/roughness) on soft-tissue cells that impeded optimized TNPs design for ideal soft-tissue integration. This study showed nanopore dimensions were voltage-dependent on micro-patterned Ti but remain stable on smooth counterparts. Varied TNPs with similar diameters but different alignment/roughness were selected and identified with similar chemistry/hydrophilicity, but their protein adhesion and stability were length-dependent, showing their feasibility as implant devices. Finally, human gingival fibroblasts (HGFs) and HaCaT epithelial cells functions on varied selected TNPs reflected that nanopores inherently promoted cell responses, but hybrid microgroove-nanopores dramatically enhanced HGF’s collagen and fibronectin secretion, while irregular textured nanopores significantly improved HaCaT adhesion. By addressing the gaps in understanding topographical regulation and the influence of overlooked geometric features beyond diameter, this work advances spatially optimized implant designs for improved epithelial sealing and connective tissue integration at different transmucosal zones for improved implant health.},
  archive      = {J_MATDES},
  author       = {Tianqi Guo and Miaoxuan Dai and Xinxin Ding and Xiaomeng Zhang and Yingxin Gu and Hongchang Lai},
  doi          = {10.1016/j.matdes.2025.114691},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114691},
  shortjournal = {Mater. Des.},
  title        = {Beyond diameters: Decoding fabrication patterns of hierarchical micro-nano titanium implants via anodization and their geometries on region-specific soft-tissue integration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Micro-scale shale fracture wear under normal stress: 3D point cloud-coupled experiments/simulations study. <em>MATDES</em>, <em>259</em>, 114690. (<a href='https://doi.org/10.1016/j.matdes.2025.114690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive understanding of frictional interactions and wear mechanisms in rough fractures is critical for advancing research in earthquake dynamics and associated geological hazards. Systematic loading experiments were performed on unconfined shale fractures using a six-dimensional rock pressure detection and displacement monitoring system. High-resolution three-dimensional point cloud datasets of fracture surfaces were acquired via laser profilometry, while pressure-sensitive films were employed to quantitatively map contact behavior under varying normal stresses. Spatial integration of point cloud data with pressure-sensitive film measurements demonstrated that initial contact occurs preferentially at asperities with elevated heights. A wear distribution model was constructed by computationally aligning and subtracting pre- and post-loading topographic datasets. Mesh-based analytical methods identified a robust correspondence between extreme wear loci and regions of concentrated contact stress. The steady-state wear rate of shale fractures followed a power-law relationship with normal stress, consistent with micromechanical wear theories. Statistical evaluation of 3D surface topography parameters revealed that the root-mean-square height ( S q ) displayed significant correlations (Pearson’s r > 0.85, p < 0.01) with mechanical metrics. These findings advocate for S q as a robust 3D geomechanical index for characterizing contact wear evolution in fractured media.},
  archive      = {J_MATDES},
  author       = {Haichun Ma and Jian Wang and Jiazhong Qian and Yang Xu and Chenglong Xie and Lei Ma},
  doi          = {10.1016/j.matdes.2025.114690},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114690},
  shortjournal = {Mater. Des.},
  title        = {Micro-scale shale fracture wear under normal stress: 3D point cloud-coupled experiments/simulations study},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Water-responsive hydroplastic 4D printing with programmable shape morphing and locking. <em>MATDES</em>, <em>259</em>, 114688. (<a href='https://doi.org/10.1016/j.matdes.2025.114688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydroplastic materials undergo reversible mechanical changes upon water absorption, transitioning between soft and rigid states. Leveraging this characteristic promotes environmentally friendly shape-morphing technologies, recently attracting significant research interest. This study aims to develop a method for inducing non-uniform curing along the thickness of a hydroplastic photocurable resin by applying frontal photopolymerization (FPP) using a commercial projector, and for achieving shape-morphing behavior through water absorption. The 3D-printed structures deform according to a predefined design, soften upon water absorption, and harden upon drying while retaining a stable deformed shape. Materials that deform in response to water or humidity are typically ductile, making it difficult to maintain their deformed shape after stimulus removal. However, this study demonstrates that a single material can programmable self-assembly while retaining its deformed shape even after water removal. This hydroplastic shape-morphing structure can be used for fabricating microfluidic channels on glass surfaces, which are difficult to process.},
  archive      = {J_MATDES},
  author       = {Sun Hye Yoon and Seo Rim Park and Myung Seo Kim and Kwang Min Lee and Seong Hyeon Park and Seok Kim and Young Tae Cho},
  doi          = {10.1016/j.matdes.2025.114688},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114688},
  shortjournal = {Mater. Des.},
  title        = {Water-responsive hydroplastic 4D printing with programmable shape morphing and locking},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of particle size on powder velocity distribution at the nozzle outlet in directed energy deposition. <em>MATDES</em>, <em>259</em>, 114680. (<a href='https://doi.org/10.1016/j.matdes.2025.114680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal-based Directed Energy Deposition (DED) is considered one of the variations of additive manufacturing with the highest potential, particularly for space industry and in-orbital manufacturing. The technology however still faces various challenges, many of which can be traced back to poor control and understanding of the powder delivery. Velocity distribution of powder particles at the DED nozzle outlet has a key influence on the results of any predictive model of powder stream and yet remains largely disputed. Certain numerical studies highlighted a possible influence of powder particle size on the velocity condition at the nozzle exit, yet no experimental studies confirmed this effect. The experimental campaign described in this paper quantifies this relation between powder particle size and velocity distribution at the nozzle outlet and a strong decrease of particle speed with particle size is observed. Moreover, smaller particles are observed to travel at speeds higher than the mean carrier gas speed suggesting powder particle segregation within the nozzle as one of the mechanisms driving speed differences at the nozzle outlet.},
  archive      = {J_MATDES},
  author       = {Tijan Mede and Andrej Jeromen and Edvard Govekar and Michael Mallon and Matjaž Godec},
  doi          = {10.1016/j.matdes.2025.114680},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114680},
  shortjournal = {Mater. Des.},
  title        = {Influence of particle size on powder velocity distribution at the nozzle outlet in directed energy deposition},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse design of two-dimensional architected materials with desired uniaxial polynomial nonlinear constitutive responses aided by stiffness normalization. <em>MATDES</em>, <em>259</em>, 114677. (<a href='https://doi.org/10.1016/j.matdes.2025.114677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of specified nonlinear mechanical responses into a structure or material is a highly sought after capability, with significant potential impacts in areas such as wave tailoring in metamaterials, impact mitigation, soft robotics, and biomedicine. Here, we present a topology optimization approach to design two-dimensional structures for desired uniaxial polynomial nonlinear behavior, wherein we formulate the objective function to match nonlinear coefficient ratios, such that the linear stiffness is decoupled from the desired nonlinearity of the response. We suggest that such linear stiffness decoupling can help aid convergence for problems with fixed, but poorly matched, constituent materials and design volumes. This benefit can be understood by considering, if large absolute force values and stiffnesses are targeted, thicker structures with less open space generally result. Such high volume ratio structures reduce the kinematic freedom (available to, e.g. , long thin structures) which is needed for strong geometrically nonlinear responses. We show designs achieved using this approach that match a range of qualitatively different polynomial behaviors with high precision, which are of interest, in particular, within the domain of dynamical systems where nonlinear elasticity of relatively simple polynomial forms can confer greater analytical tractability.},
  archive      = {J_MATDES},
  author       = {Brianna MacNider and Ian Frankel and Kai Qian and Alan Pozos and Luz Estrella Aketzali Santos-Salazar and H. Alicia Kim and Nicholas Boechler},
  doi          = {10.1016/j.matdes.2025.114677},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114677},
  shortjournal = {Mater. Des.},
  title        = {Inverse design of two-dimensional architected materials with desired uniaxial polynomial nonlinear constitutive responses aided by stiffness normalization},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of orifice geometry in determining fibre production efficiency in pressurized gyration. <em>MATDES</em>, <em>259</em>, 114670. (<a href='https://doi.org/10.1016/j.matdes.2025.114670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pressurized gyration allows the scaled-up production of polymeric fibre under the simultaneous application of pressure and rotation. This study investigates the influence of orifice design on fibre formation and production rate in pressurized gyration, aiming to optimize the technique for industrial-scale applications. Transparent vessels with varying orifice heights (7.5 mm, 15 mm, and 22.5 mm), orifice numbers (24 and 48), and dual-level orifice distributions were fabricated and tested under pressures of 0.1, 0.2, and 0.3 MPa. Morphological analysis showed that fibre diameter decreased from 2.2 µm to 1.8 µm when pressure was raised from 0.1 to 0.3 MPa when increasing the number of orifices to 48. Two-level orifice designs yielded mixed diameter distributions, enabling tunable fibre architectures. High-speed imaging revealed that the 7.5 mm orifice height achieved fluid ejection 7.5 % faster than 22.5 mm at 0.1 MPa and increasing pressure from 0.1 to 0.2 MPa reduced ejection time by up to 33 %. Production rate increased with more orifices (48 compared to 24), by 9.8 % at 0.2 MPa, and declined at higher pressure for vessels with dual-level designs. Overall, the findings provide quantitative insights into how vessel geometry influences fibre morphology and throughput in pressurized gyration systems.},
  archive      = {J_MATDES},
  author       = {Ahmed Alneyadi and Alexander Smith and Anthony Harker and Mohan Edirisinghe},
  doi          = {10.1016/j.matdes.2025.114670},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114670},
  shortjournal = {Mater. Des.},
  title        = {The role of orifice geometry in determining fibre production efficiency in pressurized gyration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="mla">MLA - 8</h2>
<ul>
<li><details>
<summary>
(2025). Multi-source plume tracing via multi-agent reinforcement learning under common UAV-faults. <em>MLA</em>, <em>22</em>, 100737. (<a href='https://doi.org/10.1016/j.mlwa.2025.100737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazardous airborne gas releases from accidents, leaks, or wildfires require rapid localization of emission sources under uncertain and turbulent conditions. Traditional gradient-based or biologically inspired strategies struggle in multi-source environments where odor cues are intermittent, aliased, and partially observed. We address this challenge by formulating multi-source plume tracing in three-dimensional fields as a cooperative partially observable Markov game. To solve it, we introduce an Action-Specific Double Deep Recurrent Q-Network (ADDRQN) that conditions on action–observation pairs to improve latent-state inference, and integrates teammate information through a permutation-invariant set encoder. Training follows a randomized centralized-training and decentralized-execution regime with host randomization, team-size variation, and noise injection. This yields a policy that is robust to agent failures (hardware malfunction, battery depletion, etc.), resilient to intermittent communication blackouts, and tolerant of sensor noise. Empirical evaluation in simulated Gaussian plume environments shows that ADDRQN achieves higher success rates and shorter localization times than non-action baselines, maintains strong performance under mid-mission disruptions, and scales predictably with team size.},
  archive      = {J_MLA},
  author       = {Pedro Antonio Alarcon Granadeno and Theodore Chambers and Jane Cleland-Huang},
  doi          = {10.1016/j.mlwa.2025.100737},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100737},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Multi-source plume tracing via multi-agent reinforcement learning under common UAV-faults},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure-aware stable diffusion for traditional architectural decoration design. <em>MLA</em>, <em>22</em>, 100735. (<a href='https://doi.org/10.1016/j.mlwa.2025.100735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent generation of traditional architectural styles faces significant challenges in structural integrity and style consistency. While existing methods can generate numerous realistic images, they lack a deep understanding of structural elements in traditional architectural decorative design. This paper proposes a Structure-aware Stable Diffusion (SSD) model, which enhances the model's comprehension of architectural features through three key innovations. First, we design a structure-aware feature injection module that adaptively fuses extracted architectural structural information with original features during the U-net upsampling phase, enhancing the model's understanding of geometric structures. Second, we introduce a dual-path text enhancement strategy that combines structural descriptions with original descriptions to provide richer textual guidance signals for the generation process. Finally, we design a progressive injection strategy that dynamically controls the injection intensity of structural information through cosine scheduling, ultimately achieving effective internalization of structural knowledge. Experimental results show that compared to existing methods, our model effectively improves both the diversity of generated traditional architectural decorations and the rationality of their structures, thus providing an effective new technical approach for traditional architectural decorative design.},
  archive      = {J_MLA},
  author       = {Jianhong Yang and Guoyong Wang},
  doi          = {10.1016/j.mlwa.2025.100735},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100735},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Structure-aware stable diffusion for traditional architectural decoration design},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines. <em>MLA</em>, <em>22</em>, 100734. (<a href='https://doi.org/10.1016/j.mlwa.2025.100734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer experience is crucial in the airline industry, as understanding passenger satisfaction helps airlines improve service quality. This study evaluates hyperparameter optimization and feature interpretability in machine learning models for predicting airline passenger satisfaction. Support Vector Machine (SVM) and Multilayer Perceptron (MLP) models were tested for binary classification, labeling passengers as ‘Satisfied’ or ‘Neutral or Dissatisfied’ using a Kaggle dataset with ∼104,000 training and ∼26,000 test records. Hyperparameter tuning used grid search with 10-fold cross-validation. For SVM, the optimal setup included the RBF kernel, C = 10, and gamma = ‘auto’, achieving a mean score of 0.9606. For MLP, the best configuration used no regularization, "he" initialization, ReLU activation, 30 epochs, batch size of 32, two hidden layers with 32 neurons each, and a learning rate of 0.001, yielding a mean score of 0.9556. Performance metrics included accuracy, precision, recall, and F1-Score, with SVM achieving a test accuracy of 0.96, precision of 0.97, and F1-Score of 0.95, slightly outperforming MLP by <1 %, though MLP was faster at 0.3 s versus SVM’s 18 s. Both models surpassed baseline models and prior studies, benefiting from robust preprocessing and a large dataset. Permutation importance analysis identified Type of Travel, Inflight Wi-Fi Service, Customer Type, and Online Boarding as key predictors, emphasizing passenger needs for digital connectivity and personalized services. These insights guide airlines to prioritize reliable Wi-Fi and efficient online boarding to enhance satisfaction, loyalty, and competitive positioning.},
  archive      = {J_MLA},
  author       = {Hamid Mirzahossein and Soheil Rezashoar},
  doi          = {10.1016/j.mlwa.2025.100734},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100734},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation. <em>MLA</em>, <em>22</em>, 100733. (<a href='https://doi.org/10.1016/j.mlwa.2025.100733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validating performance is a key challenge facing the adoption of machine learning models in high risk applications. Current validation methods assess performance marginally over the entire testing dataset, which can fail to identify regions in the distribution with insufficient performance. In this paper, we propose Conformal Validation, a systems-based approach with a calibrated form of uncertainty quantification using a conformal prediction framework as a part of the validation process to reduce performance gaps. Specifically, the policy defers a subset of observations for which the predictive model is most uncertain and provides a human with informative prediction sets to make the ancillary decision. We evaluate this policy on an image classification task where images are distorted with varying levels of gaussian blur for a quantifiable measure of added difficulty. The model is compared to human performance on the most difficult observations, i.e., those where the model is most uncertain, to simulate the scenario when a human is the alternative decision-maker. We evaluate performance on three arms: the model independently, humans with access to a set of classes the model is most confident in, and humans independently. The deferral policy is simple to understand, applicable to any predictive model, and easy to implement while, in this case, keeping humans in the loop for improved trustworthiness. Conformal Validation incorporates a risk assessment that is conditioned on the prediction set length and can be tuned to the needs of the application.},
  archive      = {J_MLA},
  author       = {Paul Horton and Alexandru Florea and Brandon Stringfield},
  doi          = {10.1016/j.mlwa.2025.100733},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100733},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of machine learning technologies in construction maintenance: A strategic analysis. <em>MLA</em>, <em>22</em>, 100731. (<a href='https://doi.org/10.1016/j.mlwa.2025.100731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current predictive maintenance systems in construction rely on static machine learning approaches that fail to adapt to evolving operational environments, achieving only 3%–7% performance improvements over individual models and suffering 15%–25% performance degradation when transferred across domains. This research develops and validates an Adaptive Ensemble Framework that dynamically optimizes algorithm selection through real-time data assessment and performance feedback. The framework’s meta-learning architecture continuously adapts ensemble weights using data complexity measures, temporal pattern analysis, and uncertainty quantification metrics. Unlike static approaches, the system integrates scikit-learn and TensorFlow models through dynamic optimization algorithms that respond to changing conditions without manual reconfiguration. The framework provides uncertainty-aware predictions with confidence intervals essential for safety-critical construction decisions. Comprehensive evaluation across four industries using 50,000+ maintenance records from major construction firms demonstrates substantial improvements. The adaptive ensemble achieves F1-score of 0.934 in construction delay prediction, representing 15.3% improvement over individual models and 8.7% enhancement over static ensembles. Cross-industry validation reveals successful knowledge transfer with minimal performance degradation ( < 5%). This research contributes three scholarly advances: (i) the first real-time adaptive ensemble framework eliminating manual hyperparameter tuning, (ii) uncertainty quantification mechanisms for safety-critical applications, and (iii) robust cross-industry transferability through systematic domain adaptation. The framework extends beyond construction to manufacturing, energy, and transportation sectors, demonstrating computational efficiency with sub-100ms latency and linear scaling characteristics. These contributions establish new benchmarks for adaptive machine learning in industrial predictive maintenance.},
  archive      = {J_MLA},
  author       = {Assane Lo and Aysha Alshehhi},
  doi          = {10.1016/j.mlwa.2025.100731},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100731},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Implementation of machine learning technologies in construction maintenance: A strategic analysis},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning based li-ion cell state prediction using impedance spectroscopy. <em>MLA</em>, <em>22</em>, 100729. (<a href='https://doi.org/10.1016/j.mlwa.2025.100729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable monitoring of battery state parameters is crucial for ensuring optimal battery performance, safety, and lifetime. Existing methods have limitations, such as requiring modeling of each degradation mechanism involved or relying on direct measurement techniques that impose restrictions on field studies or end-user use. In this paper, we propose a machine learning-based approach that combines the strengths of electrochemical impedance spectroscopy (EIS) and machine learning algorithms to predict battery state parameters. We have developed an efficient prediction system that can learn from EIS data and accurately predict battery state parameters. Our approach is trained on an open dataset comprising of over 30,000 spectra, generated using an automated measurement technique that outperforms current machine learning-based models, particularly in terms of generalization across different cells and measurement setups.},
  archive      = {J_MLA},
  author       = {Carl Philipp Klemm and Till Frömling},
  doi          = {10.1016/j.mlwa.2025.100729},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100729},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine-learning based li-ion cell state prediction using impedance spectroscopy},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the cost of equity for insurance companies in the world: Evidence from machine learning approaches. <em>MLA</em>, <em>22</em>, 100726. (<a href='https://doi.org/10.1016/j.mlwa.2025.100726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the determinants of the WACC for insurance firms, integrating both financial and non-financial factors through advanced machine learning techniques. Analyzing data from 2012 to 2022 for a large sample of 190 insurance companies in the world, we compare nine ML models, revealing that XGBoost and LightGBM outperform traditional methods. Key drivers of WACC include beta, dividend yield, and earnings per share, with Emission score also showing significant influence. This study fills gaps in insurance finance literature by introducing ML-based WACC modeling, enhancing predictive accuracy, and providing policy recommendations for regulatory reporting and Emission score disclosures. From a policy perspective, the global insurance sector is at a crucial turning point, where ESG integration in granular form is found to be vital for financial stability. By mandating standardized ESG disclosures in alignment with the ISSB and TCFD frameworks, regulators can reduce insurers’ cost of equity, enabling a balance between financial sustainability and environmental responsibility, while promoting long-term value creation for both investors and society.},
  archive      = {J_MLA},
  author       = {Indranarain Ramlall and Dineshwar Ramdhony},
  doi          = {10.1016/j.mlwa.2025.100726},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100726},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Exploring the cost of equity for insurance companies in the world: Evidence from machine learning approaches},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets. <em>MLA</em>, <em>22</em>, 100712. (<a href='https://doi.org/10.1016/j.mlwa.2025.100712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistic regression is a simple yet widely used classification model in spectroscopic profiling analysis. Considering the model’s output represents a probability, this paper will investigate its latent distribution assumption, i.e., its inner linear regressor unit follows a standard logistic distribution. An empirical study on five spectroscopic profiling open datasets, i.e., wine, coffee, olive oil, cheese, and milk powder, was conducted to verify this latent distribution assertion. This paper measured the GoF (Goodness of Fit) of each dataset’s latent variable from three aspects, i.e., curve fitting, P–P and Q–Q plots, and K–S test. After hyper-parameter optimization and proper training, the latent variable, as a weighted sum of the original features, has demonstrated a high level of GoF on all the five datasets. This study verifies the suitability of logistic regression in spectroscopic profiling analysis and answers why the model output can be interpreted as a conditional probability.},
  archive      = {J_MLA},
  author       = {Yinsheng Zhang and Mingming He and Haiyan Wang},
  doi          = {10.1016/j.mlwa.2025.100712},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100712},
  shortjournal = {Mach. Learn. Appl.},
  title        = {On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="neucom">NEUCOM - 44</h2>
<ul>
<li><details>
<summary>
(2025). GDViT: Group-level decorrelation-based vision transformer for domain generalization. <em>NEUCOM</em>, <em>657</em>, 131624. (<a href='https://doi.org/10.1016/j.neucom.2025.131624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality-inspired domain generalization aims to improve model generalization by removing correlations between relevant and irrelevant features. However, a key challenge lies in effectively distinguishing the two. Existing methods, lacking explicit feature grouping, often eliminate all feature correlations indiscriminately, which disrupts the internal structure of relevant features and degrades generalization performance. In this work, we propose a group-level decorrelation-based vision Transformer that explicitly separates features (tokens) into relevant and irrelevant groups. This design preserves the internal correlations within relevant features while removing the correlations between the two groups. To achieve this, we introduce a feature grouping module that guides the separation process, followed by a grouping Transformer encoder that performs inter-group decorrelation, enabling the model to focus more on task-relevant information. Additionally, a supervised contrastive loss is employed to further enhance generalization. Extensive experiments demonstrate that our method significantly improves out-of-distribution performance. Visual analysis further shows that our model suppresses attention to irrelevant features, mitigating spurious correlations and resulting in more stable predictions. Our approach achieves strong performance in both multi-source and single-source domain generalization settings.},
  archive      = {J_NEUCOM},
  author       = {Wenqiang Tang and Zhouwang Yang and Yanzhi Song},
  doi          = {10.1016/j.neucom.2025.131624},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131624},
  shortjournal = {Neurocomputing},
  title        = {GDViT: Group-level decorrelation-based vision transformer for domain generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design. <em>NEUCOM</em>, <em>657</em>, 131623. (<a href='https://doi.org/10.1016/j.neucom.2025.131623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of distributed generalized Nash equilibrium (GNE) seeking in aggregative games, it is challenging yet interesting to design fast GNE seeking algorithms using energy-efficient communication strategy. However, most existing distributed GNE seeking algorithms can only achieve asymptotic convergence under continuous-time communication setting, resulting in a slower convergence rate and greater consumption of communication resources. In this paper, by exploiting two time-varying gain feedback functions, we present a new kind of distributed GNE seeking algorithm by integrating predefined-time control law with event-triggered communication strategy. It is theoretically shown that the proposed algorithm can solve the predefined-time GNE seeking problem for aggregative games with Zeno behavior being avoided during the seeking process. Compared with the existing algorithms, the present one exhibits several salient features: 1) the convergence time can be preset according to task requirements; 2) the communication resources can be significantly saved by the event-triggered mechanism; and 3) the proposed algorithms exhibit simplicity in their structures and possess the advantage of easy implementability.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Guo and Lingwei Zeng and Jinlei Cheng and Pengwen Xiong and Qian Li},
  doi          = {10.1016/j.neucom.2025.131623},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131623},
  shortjournal = {Neurocomputing},
  title        = {Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection. <em>NEUCOM</em>, <em>657</em>, 131620. (<a href='https://doi.org/10.1016/j.neucom.2025.131620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke lesion detection in brain MRI remains challenging as existing deep learning methods process single modalities and ignore anatomical boundaries, limiting clinical adoption. We develop a graph-based framework that integrates neuroanatomical priors and multi-modal imaging for automated stroke lesion detection. Our approach uses anatomically-constrained supervoxel generation and graph attention networks with probabilistic attention attribution for interpretable lesion detection. Evaluated on the SOOP dataset (1715 subjects including 1461 stroke patients), our method achieves a Dice coefficient, sensitivity, and ROC-AUC of 0.85 ± 0.03, 0.88, and 0.94, respectively, outperforming CNN baselines by 15 %. The framework provides clinically meaningful attention maps and accurate automated stroke analysis.},
  archive      = {J_NEUCOM},
  author       = {Luis R. Mercado-Diaz and Derek Aguiar and Hugo F. Posada-Quintero},
  doi          = {10.1016/j.neucom.2025.131620},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131620},
  shortjournal = {Neurocomputing},
  title        = {Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios. <em>NEUCOM</em>, <em>657</em>, 131619. (<a href='https://doi.org/10.1016/j.neucom.2025.131619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated significant potential in addressing decision-making problems in the field of autonomous driving due to their strong reasoning capabilities. However, deploying LLMs in real-world driving scenarios often encounters challenges such as high computational requirements, elevated costs, and increased latency. On the other hand, Deep Reinforcement Learning (DRL) exhibits strong adaptability to decision-making tasks in autonomous driving with a relatively smaller parameter scale. Nevertheless, DRL agents often suffer from low exploration efficiency and high sensitivity to parameter variations. To address the above issues, we propose an LLM-Enhanced Autonomous Driving (LEAD) training framework, which integrates a high-level agent based on LLMs into the training process of DRL models, effectively improving the policy learning efficiency and generalization capability of DRL models. During the early stage of training, a dynamic intervention mechanism is introduced to identify key decision points within the DRL model, and a predefined expert guidance algorithm is utilized to integrate high-level decision strategies from LLMs into these critical nodes. During the later stage of training, the DRL model transitions into an autonomous optimization phase, where the agent, enhanced with LLM priors, continuously interacts with the environment to further refine the policy network, ultimately surpassing the performance of the LLM-based agent. Experimental results demonstrate that the LEAD-PPO model, built upon the proposed framework, reduces collision rates by 49.49 % and 59.4 % in low-density and high-density scenarios, respectively, during training compared to the baseline model. In the testing phase, the DRL model optimized through LEAD achieves task completion rates that are 9.60 %, 35.94 %, and 65.63 % higher than those of the baseline model in simple, moderate, and difficult scenarios, respectively. Overall, the proposed LEAD framework significantly improves the robustness, sample efficiency, and generalization ability of DRL models.},
  archive      = {J_NEUCOM},
  author       = {Dongwei Xu and Enwen Qiao and Tongcheng Gu and Hongda Fu and Chengju Sun and Haifeng Guo and Yuqing Liu},
  doi          = {10.1016/j.neucom.2025.131619},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131619},
  shortjournal = {Neurocomputing},
  title        = {LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms. <em>NEUCOM</em>, <em>657</em>, 131618. (<a href='https://doi.org/10.1016/j.neucom.2025.131618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively handle the synchronization of reaction–diffusion fuzzy memristive neural networks (MNNs) and shorten their synchronization time has become a worthwhile and meaningful issue to study. This paper mainly studies fixed-time synchronization (FXTS) and preassigned-time synchronization (PATS) problems for delayed fuzzy memristive neural networks (DFMNNs) with reaction–diffusion terms. First, a DFMNNs model with reaction–diffusion terms is introduced, which can effectively describe the spatial distribution characteristics of the network. Second, through the Lyapunov stability theory, the FXTS criterion and the upper limit of the settling-time (ST) are obtained. Subsequently, a state feedback controller is proposed to ensure that the system achieves synchronization within a specified time, and the synchronization time is independent of initial conditions and control parameters, which gives the designed controller a wider range of applications. Finally, two examples are presented to illustrate the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Hanrui Chen and Dongbing Tong and Qiaoyu Chen},
  doi          = {10.1016/j.neucom.2025.131618},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131618},
  shortjournal = {Neurocomputing},
  title        = {Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond sparsity: An empirical study of structured collaboration in modular AI. <em>NEUCOM</em>, <em>657</em>, 131616. (<a href='https://doi.org/10.1016/j.neucom.2025.131616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mixture-of-Experts (MoE) architectures, the prevailing paradigm emphasizes sparse expert activation for computational efficiency. This paper explores an alternative architectural approach centered on structured collaboration, hypothesizing that the quality and nature of inter-module interactions are as significant as computational cost. We present a series of targeted proof-of-concept experiments to validate three distinct principles of structured interaction, inspired by cognitive science. First, we demonstrate that a hierarchical fusion mechanism, modeled on the brain's segregated visual pathways, enhances compositional reasoning on the VQA v2.0 benchmark. Second, by employing a redesigned reinforcement learning task in MiniGrid, we demonstrate that a system-wide differentiated credit assignment (SDCA) mechanism, with conflict detection learned end-to-end, facilitates more robust policy learning. Third, we ascertain that integrating reasoning "tools" as co-adaptive modules offers superior out-of-distribution robustness on the DROP dataset compared to a more powerful baseline agent utilizing external LLM-based tools. Our work provides concrete validation for these principles, highlighting a series of trade-offs between performance, robustness, and efficiency, and suggesting that prioritizing cognitive synergy over simple sparsity offers a promising direction for future research in modular AI.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Zhou and Soohong Kim and Yiru Wang and Kailin Zhang},
  doi          = {10.1016/j.neucom.2025.131616},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131616},
  shortjournal = {Neurocomputing},
  title        = {Beyond sparsity: An empirical study of structured collaboration in modular AI},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes. <em>NEUCOM</em>, <em>657</em>, 131614. (<a href='https://doi.org/10.1016/j.neucom.2025.131614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key nodes in complex networks play a crucial role in maintaining the stability, functionality, and robustness of networked systems. Accordingly, the accurate identification of such nodes is of fundamental importance. Their significance spans multiple domains, including communication systems, transportation infrastructures, life sciences, and social networks. Existing algorithms for key node identification typically rely on heuristic measures or standard deep reinforcement learning frameworks. However, these approaches often suffer from limited feature extraction capabilities, high computational complexity, and insufficient generalizability, and a lack of dynamic adaptability. To overcome these limitations, this study proposes a novel architecture, GTRP (Graph Transformer-Driven Reinforcement Learning Based on Popularity). GTRP extends Epidemic-aware Heterogeneous Graph Transformer (GT) by introducing distinct attention mechanisms for both nodes and edges, enabling the integration of local structural features and global propagation properties. In addition, GTRP incorporates Dual-dynamics Reward Optimization (DR) to identify key nodes based on a network disintegration strategy. The model is trained on randomly generated Barabási–Albert (BA) networks and evaluated on synthetic networks of varying scales as well as multiple real-world network scenarios. Comparative experiments with six representative algorithms demonstrate that GTRP achieves substantial performance improvements—outperforming existing methods by 6.30 % in unweighted networks and 15.90 % in weighted networks. These results underscore the potential of GTRP to advance key node detection in complex network analysis.},
  archive      = {J_NEUCOM},
  author       = {Kaili Wang and Muqing Wu and Min Zhao},
  doi          = {10.1016/j.neucom.2025.131614},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131614},
  shortjournal = {Neurocomputing},
  title        = {A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter. <em>NEUCOM</em>, <em>657</em>, 131611. (<a href='https://doi.org/10.1016/j.neucom.2025.131611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostics and Health Management (PHM) is critical for industrial equipment maintenance, whose core task is to predict the Remaining Useful Life (RUL) of a system or component accurately. However, traditional deep learning-based approaches often demand significant computational and memory resources, limiting their feasibility for edge deployment. As an effective model compression technique, Knowledge Distillation (KD) has emerged as a core strategy for enabling edge intelligence by transferring knowledge from a teacher model to a lightweight student model. However, traditional KD methods exhibit a high dependency on the teacher model's output. This dependency limits the student model's capacity for autonomous error correction, impairing its distillation performance. To solve these problems, this paper proposes a novel Classification and Error Correction Knowledge Distillation (CEKD) framework. The framework employs Gaussian kernel-based feature entropy to dynamically evaluate teacher models' predictive capabilities, facilitating comprehensive assessment and sample differentiation. Furthermore, the knowledge self-reflection learning strategy extends error correction to continuous dynamic adjustment, enabling deep optimization of complex data. Experimental results on the air turbine starter bearing datasets show that CEKD surpasses KD methods by improving MAE and RMSE by 79.8 % and 78.6 % on average, while reducing memory consumption and inference time by nearly 10 × and 8 × , respectively, enabling deployment on resource-constrained devices.},
  archive      = {J_NEUCOM},
  author       = {Runxia Guo and Jingxu Yi and Xianfeng Luo},
  doi          = {10.1016/j.neucom.2025.131611},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131611},
  shortjournal = {Neurocomputing},
  title        = {An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay. <em>NEUCOM</em>, <em>657</em>, 131609. (<a href='https://doi.org/10.1016/j.neucom.2025.131609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the finite-time lag consensus (FTLC) and finite-time H ∞ lag consensus (FTHLC) problems for first-order multi-agent systems (MASs) are studied. On the one hand, a new state feedback controller considering the communication delay between agents is proposed. Besides, based on several inequality scaling techniques and finite-time stability theory, a sufficient criterion is derived to guarantee the FTLC of MASs. On the other hand, an adaptive state feedback controller and the corresponding adaptive law are put forward, which can also help MASs realize lag consensus in finite time without any additional conditions. Moreover, to address inevitable external disturbances in practice, the proposed control strategies are further enhanced to achieve FTHLC, which further expands the application range of the research results. Finally, the effectiveness of these provided FTLC and FTHLC control schemes in different scenarios is manifested through some numerical simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Kun Ling and Shun-Yan Ren and Ming-Zhu Wei and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131609},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131609},
  shortjournal = {Neurocomputing},
  title        = {Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks. <em>NEUCOM</em>, <em>657</em>, 131608. (<a href='https://doi.org/10.1016/j.neucom.2025.131608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the computation of generalized Nash equilibrium in aggregative games with coupling constraints over time-varying networks. The player’s cost objective comprises a differentiable function dependent on the aggregate of all players’ decisions and a possibly non-smooth term with a linear mapping. In this context, designing solution methods for such game formulation is relatively scarce. We thus develop a fully distributed equilibrium-seeking algorithm that accommodates time-varying communication networks while circumventing the need for global decision information. The proposed algorithm synergistically embeds dynamic tracking of aggregate decisions through a consensus-based mechanism with projected pseudo-gradient updates, augmented by a proximal splitting scheme to handle non-smooth components. Theoretically, we establish convergence guarantees to the variational equilibrium through a new operator splitting framework. Finally, numerical experiments are conducted to substantiate the validity of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Liang Ran and Huaqing Li and Zheng Wang and Lifeng Zheng and Jun Li and Zhe Li},
  doi          = {10.1016/j.neucom.2025.131608},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131608},
  shortjournal = {Neurocomputing},
  title        = {Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling. <em>NEUCOM</em>, <em>657</em>, 131604. (<a href='https://doi.org/10.1016/j.neucom.2025.131604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the synchronization control for multi-weighted complex networks (MWCNs) with unknown disturbances and aperiodic intermittent coupling. Firstly, an adaptive neural network strategy is used to approximate the unknown components derived from nonlinear function, while a novel continuous function is proposed by utilizing the idea of time-varying boundary layer technique to deal with the influence of approximation errors. Secondly, different from the continuous coupling and periodic intermittent coupling mechanisms in existing works, an aperiodic intermittent coupling mechanism is taken into consideration in MWCNs. Thirdly, to synchronize MWCNs under aperiodic intermittent coupling, adaptive strategies are developed to adjust coupling strengths and coupling gains based on all edges and partial edges, respectively. Note that these two strategies are fully distributed, i.e., they do not require any global information. Finally, some numerical simulations are provided to verify the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhang and Dan Liu and Binrui Wang and Kaibo Shi},
  doi          = {10.1016/j.neucom.2025.131604},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131604},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective framework with hybrid augmentation for visual reinforcement learning generalization. <em>NEUCOM</em>, <em>657</em>, 131602. (<a href='https://doi.org/10.1016/j.neucom.2025.131602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current studies in Visual Reinforcement Learning focus on developing policies to acclimate to unknown environments through data augmentation. This paper aims to develop a new methodology to improve upon existing results. To this end, we first categorize existing methods into three groups based on the focus of augmentation: Task-Aware Augmentation, Image-Processing Augmentation, and Image-Scene Augmentation. Subsequently, we establish a unified framework that integrates these three augmentation categories. The core of our framework is hybrid data augmentation, which enhances data diversity. In this framework, we employ hyperspherical space and regularization techniques to address the side effects of such augmentation, specifically the discrepancy between augmented and original data, as well as the instability associated with hybrid augmentation. Finally, we evaluate the proposed framework across three benchmarks, demonstrating its significant advantages over current state-of-the-art methods. Notably, our framework outperforms existing approaches by an average of 4.59 % across 10 tasks in DMC-GB, 28.81 % across 6 tasks in Robosuite, and 20.50 % across 4 tasks in Adroit. The code for our framework will be released at https://github.com/csufangyu/MuHA .},
  archive      = {J_NEUCOM},
  author       = {Yu Fang and Xuehe Zhang and Haoshu Cheng and Xizhe Zang and Changle Li and Jie Zhao},
  doi          = {10.1016/j.neucom.2025.131602},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131602},
  shortjournal = {Neurocomputing},
  title        = {An effective framework with hybrid augmentation for visual reinforcement learning generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robust generalization through appropriate adversarial example attack intensity. <em>NEUCOM</em>, <em>657</em>, 131599. (<a href='https://doi.org/10.1016/j.neucom.2025.131599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are notoriously susceptible to adversarial examples. To mitigate the impact of well-designed adversarial attacks on network models, researchers have developed various defense mechanisms, among which adversarial training has emerged as one of the most effective strategies to date. Adversarial training aims to augment training data with adversarial examples, thus giving DNNs a certain degree of robustness to defend against adversarial attacks. However, while obtaining adversarial robustness, this method comes at the cost of reducing the generalization performance, manifested in the reduced classification effect of clean test datasets. Researchers have been actively seeking to counter the balance between adversarial robustness and model generalization. We believe that the key to balancing these two aspects lies in identifying appropriate adversarial examples. Overly potent examples can lead to a decline in clean accuracy, whereas weaker examples may offer limited robustness. Based on our analysis, a new adversarial example generation algorithm called Denoising Projection Gradient Descent (DPGD) was proposed. DPGD adds a purification module and a constraint in generating adversarial examples, the former is used to limit the influence of too strong adversarial examples on model training and the latter is used to ensure the necessary attack intensity. Combining DPGD with the framework of traditional adversarial training, we obtain the Diffusion Adversarial Training (DifAT) approach. To verify the effectiveness of our proposed method, we conducted extensive experiments on benchmark datasets, including CIFAR-10, CIFAR-100, and Tiny-Imagenet. Our results demonstrate the effectiveness of DifAT in improving the robustness of DNNs while maintaining or even improving their generalization performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaoguo Ding and Liangjian Zhang and Qiqi Bao and Yaguan Qian and Bin Wang and Zhaoquan Gu and Yanchun Zhang},
  doi          = {10.1016/j.neucom.2025.131599},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131599},
  shortjournal = {Neurocomputing},
  title        = {Enhancing robust generalization through appropriate adversarial example attack intensity},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User identification based on the topology consistency of cross-layer common neighbors in social network. <em>NEUCOM</em>, <em>657</em>, 131591. (<a href='https://doi.org/10.1016/j.neucom.2025.131591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it has become a common practice to create multiple accounts on various social networks for online recreation. When accounts in different networks share similar structural features, i . e . , they have topology consistency, they may belong to the same individual. However, having multiple accounts for the same person across different networks can be inconvenient and uncertain, leading to difficulties in accurate recommendations. Therefore, some researchers have focused on identifying users within single network layers, but without involving the information from various network platforms, resulting in identification confusion and reduced algorithm accuracy. This paper proposes a novel topology consistency-based link prediction algorithm (Topology Consistency: TC) for user identification, combining separate layers of a multilayer network into a single-layer network to include more layer information. TC applies topology information from the cross-layer common neighbors produced in layer combination to distinguish target node pairs and utilizes matrix computation to reduce complexity. Furthermore, to address controversial identification situations appearing after layer combination, the edges between the cross-layer common neighbors are innovatively considered. Finally, experimental results in real-world and artificial networks show that TC has superior performance to state-of-the-art algorithms and has applicability and practicality.},
  archive      = {J_NEUCOM},
  author       = {Yujie Yang and Shuai Cao and Long Wang and Dong Liu and Marcus Kaiser},
  doi          = {10.1016/j.neucom.2025.131591},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131591},
  shortjournal = {Neurocomputing},
  title        = {User identification based on the topology consistency of cross-layer common neighbors in social network},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states. <em>NEUCOM</em>, <em>657</em>, 131588. (<a href='https://doi.org/10.1016/j.neucom.2025.131588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear optics neural networks or optical neural networks offer potential advantages over traditional electronic neural networks in terms of speed, energy efficiency, scalability, and improved parallelism, particularly for high-bandwidth applications. The use of photonics allows for more compact and integrated neural network designs, potentially enabling the development of larger and more complex networks. A linear optics network is developed to implement a quantum classifier. Indeed, the designed network is a quantum circuit consisting of some Gaussian gates such as displacement, noiseless linear amplification (NLA), squeezer and Green machine. At first, the classical inputs are encoded with the help of position-displacement operator to prepare single-mode coherent states. Then, the amplitudes of the coherent states are amplified by passing through NLA elements followed by squeezer gates that may transform classical coherent states into nonclassical ones. Finally, the transformed coherent states are fed into the Green machine which provides entangled states as the outcome of the network. As a primary goal of this work, the network generates a multi-mode entangled state by applying the displacement operator on the vacuum state encoded classical data. Besides, it is shown that the output state of the circuit may possess squeezing characteristics as another nonclassical feature. In the continuation, as a practical application, the network is implemented to perform some pattern recognition tasks. At first, the Bayes theorem is employed to define discriminant functions to perform a general classification task, then the outcome distribution of the network is utilized to classify some corrupted LEDs that display English letters. Finally, we show that the outcome of the circuit may be manipulated to embed classical neural networks into a continuous-variable variational quantum circuit (VQC). The network is trained via the logistic regression algorithm with the MNIST database. The results show that the digits can be recognized with relatively high accuracy. Ongoing research is focused on developing new linear optical techniques for machine learning, improving the efficiency and scalability of optical networks, and exploring new applications of linear optics in machine learning and quantum computing. Hence, such a quantum circuit may also be used to design novel high-accuracy pattern recognition devices.},
  archive      = {J_NEUCOM},
  author       = {Ebrahim Ghasemian and Mohammad Kazem Tavassoly and Habib Rostami},
  doi          = {10.1016/j.neucom.2025.131588},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131588},
  shortjournal = {Neurocomputing},
  title        = {Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding. <em>NEUCOM</em>, <em>657</em>, 131586. (<a href='https://doi.org/10.1016/j.neucom.2025.131586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning has emerged as a crucial research direction in the field of computer vision, offering improved performance and efficiency across multiple tasks. Recent studies have incorporated prompt learning into multi-task learning to enhance the interaction between prompt vectors and image representations. However, these studies fail to consider the inter-task and intra-task relations of prompt vectors under multi-task scenarios. To address this issue, we propose learning Generic and Specific Prompts (GSPrompt) with contrastive constraints for multi-task visual scene understanding. Our approach assumes that each task possesses both commonality and individuality, leading us to design two distinct types of prompt vectors: task-generic prompts and task-specific prompts. By constraining the prompt vectors through pulling task-generic prompts and pushing task-specific prompts, we enable multi-task models to learn prompts capable of adapting to multiple tasks simultaneously. Extensive experiments on NYUD-v2, PASCAL-Context, and Cityscapes show that GSPrompt learns effective prompts and achieves state-of-the-art performance. The code is publicly available at https://github.com/teeyohan/GSPrompt-main .},
  archive      = {J_NEUCOM},
  author       = {Tianyu Han and Zhimin Xu and Wanying Li and Haohao Hu and Xinxin He and Song He and Peng Zan and Xiaochen Bo},
  doi          = {10.1016/j.neucom.2025.131586},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131586},
  shortjournal = {Neurocomputing},
  title        = {Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based passenger head detection for carriage crowd density estimation. <em>NEUCOM</em>, <em>657</em>, 131584. (<a href='https://doi.org/10.1016/j.neucom.2025.131584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carriage crowd density monitoring is a key component in developing intelligent transportation systems, such as maglev transportation system. Surveillance images captured by sensors, such as carriage monitoring cameras, serve as a new solution for estimating crowd density inside the carriage due to their wide coverage and real-time updates. In this study, a passenger head detection dataset (PHD) is developed using 3717 images acquired from carriage surveillance. Based on these images, over 67,215 head instances are precisely annotated manually. To address the issue of insufficient feature fusion in existing detection algorithms, an efficient cross-scale feature enhancement (CFE) module is proposed and introduced into the advanced YoloX model. The PHD dataset is, to the best of our knowledge, the first public dataset of surveillance images for carriage crowd density estimation. To prove the usability of the PHD dataset and the validity of the proposed method, 12 different versions of detectors are applied and compared. The results demonstrate the performance of these algorithms in the detection of passenger heads. Our research offers a new approach for carriage crowd density estimation. The dataset is publicly available at: https://github.com/Xujiajing111/PHD .},
  archive      = {J_NEUCOM},
  author       = {Jiajing Xu and Mingda Zhai and Yuan Tian and Jun Wu},
  doi          = {10.1016/j.neucom.2025.131584},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131584},
  shortjournal = {Neurocomputing},
  title        = {Vision-based passenger head detection for carriage crowd density estimation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-client GAN-based backdoor attacks for asynchronous federated learning. <em>NEUCOM</em>, <em>657</em>, 131580. (<a href='https://doi.org/10.1016/j.neucom.2025.131580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables distributed collaborative training while preserving data privacy; however, it demonstrates significant vulnerability to backdoor attacks. Existing attack methodologies predominantly require control of numerous malicious clients to achieve efficacy and largely neglect asynchronous FL scenarios. In response to these limitations, we propose a novel GAN-based backdoor attack framework capable of injecting effective and covert backdoors with minimal malicious client participation, functioning efficiently across both synchronous and asynchronous environments. Our framework operates effectively with a single malicious client, eliminating the need for coordination among multiple adversarial participants or prior knowledge of benign client data distributions. This reduction in resource requirements enhances the framework's practicality in real-world FL implementations. The malicious client employs a Generative Adversarial Network to synthesize adversarial samples containing predefined triggers, which are subsequently incorporated into local training datasets. The concurrent training on legitimate and triggered data enhances attack effectiveness, while gradient injection—manipulating differences between local and global gradients to introduce strategic noise—facilitates backdoor embedding with improved stealth characteristics. Empirical evaluations demonstrate that in a configuration of 200 clients with a single attacker, our framework achieves attack success rates of 98.66 % on MNIST and 86.29 % on CIFAR-10 datasets. Comprehensive experimentation across both datasets substantiates the framework's effectiveness, imperceptibility, and resilience in synchronous and asynchronous FL environments. This research contributes significant insights into backdoor attack strategies in FL, particularly within asynchronous contexts, and underscores the imperative for developing robust defensive countermeasures.},
  archive      = {J_NEUCOM},
  author       = {Siyu Guan and Chunguang Huang and Hai Cheng},
  doi          = {10.1016/j.neucom.2025.131580},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131580},
  shortjournal = {Neurocomputing},
  title        = {Single-client GAN-based backdoor attacks for asynchronous federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UA-PDFL: A personalized approach for decentralized federated learning. <em>NEUCOM</em>, <em>657</em>, 131579. (<a href='https://doi.org/10.1016/j.neucom.2025.131579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy preserving machine learning paradigm designed to collaboratively learn a global model without data leakage. Specifically, in a typical FL system, the central server solely functions as a coordinator to iteratively aggregate the collected local models trained by each client, potentially introducing single-point transmission bottleneck and security threats. To mitigate this issue, decentralized federated learning (DFL) has been proposed, where all participating clients engage in peer-to-peer communication without a central server. Nonetheless, DFL still suffers from training degradation as FL does due to the non-independent and identically distributed (non-IID) nature of client data. And incorporating personalization layers into DFL may be one of the most effective solutions to alleviate the side effects caused by non-IID data. Therefore, in this paper, we propose a novel unit representation aided personalized decentralized federated learning framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By adaptively adjusting the level of personalization layers through the guidance of the unit representation, UA-PDFL is able to address the varying degrees of data skew. Based on this scheme, client-wise dropout and layer-wise personalization are proposed to further enhance the learning performance of DFL. Extensive experiments empirically prove the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Zhu and Yuxiang Fan and Zhenping Xie},
  doi          = {10.1016/j.neucom.2025.131579},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131579},
  shortjournal = {Neurocomputing},
  title        = {UA-PDFL: A personalized approach for decentralized federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups. <em>NEUCOM</em>, <em>657</em>, 131574. (<a href='https://doi.org/10.1016/j.neucom.2025.131574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) has emerged as an important data pre-processing technology to solve the challenging task of data mining. However, most existing FS methods primarily focus on exploiting the independent contributions provided by individual features, while neglecting the critical contributions inherent in ubiquitous intrinsic feature groups. As a result, they may fail to fully capture the potentially valuable information embedded in data. This issue becomes more pronounced in modern large-scale data environments, such as JointCloud, where cross-organizational collaborative data analysis over non-shared datasets is often required. To address this issue, this paper proposes a N ovel T wo- S tage H ybrid FS approach (NTSHFS) that jointly considers the informative contributions of both individual features and collaborative feature groups, enabling a comprehensive evaluation of feature relevance, redundancy and discriminative capability. In the first stage, the correlation coefficient-based co-association matrix (CC-CAM) is developed to ensemble the results obtained by different univariate and structured regularization techniques. Then, a CC-CAM-based embedded FS is proposed to select and rank representative features, achieving strong relevance prioritization and redundancy elimination. In the second stage, a quasi fuzzy-rough set (QFRS) model is designed by integrating the similarity relations at both individual-feature level and multi-feature level through the intersection operation. Based on this model, a QFRS-based filter FS is presented to determine the final feature subset with stronger discriminative capability using internal rankings of feature groups. Experimental results on 24 datasets demonstrate that the proposed approach typically outperforms the compared methods (i.e., achieving an average classification accuracy improvement ranging from 1.77 % to 7.69 %), highlighting its effectiveness, robustness and generalization in data mining.},
  archive      = {J_NEUCOM},
  author       = {Lin Qiu and Xingwei Wang and Bo Yi and Yanpeng Qu and Min Huang and Kaimin Zhang},
  doi          = {10.1016/j.neucom.2025.131574},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131574},
  shortjournal = {Neurocomputing},
  title        = {A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view semi-supervised feature selection with multi-order similarity and tensor learning. <em>NEUCOM</em>, <em>657</em>, 131573. (<a href='https://doi.org/10.1016/j.neucom.2025.131573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data has attracted extensive attention because it can better characterize samples, and multi-view semi-supervised feature selection can not only effectively improve multi-view performance, but also maintain the original real structure of the data. To this end, many scholars have proposed various models to achieve this goal. However, most of the existing methods rely on the graph structure constructed from the original data and use the constructed graph as a guide for feature selection. This not only ignores multi-order domain knowledge, but also ignores the high-order relations between views. Therefore, this study effectively integrates multi-order domain information with graph learning, and performs tensor low-rank learning on the graph structure between multiple views. A multi-view semi-supervised feature selection method based on multi-order similarity and tensor learning is proposed, which not only integrates multi-order domain information, but also takes into account the relationship between views. Based on this, we propose an iterative method to solve the objective function and prove the superiority of our method on multiple basic datasets.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Chen and Xijiong Xie and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131573},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131573},
  shortjournal = {Neurocomputing},
  title        = {Multi-view semi-supervised feature selection with multi-order similarity and tensor learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection via risk-bound utility maximization. <em>NEUCOM</em>, <em>657</em>, 131572. (<a href='https://doi.org/10.1016/j.neucom.2025.131572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate goal of supervised feature selection is to identify a feature subset that minimizes classification risk. Contemporary methods, however, often rely on heuristic or model-dependent proxy criteria that lack a direct theoretical connection to this fundamental objective. To bridge this gap, we introduce a new feature selection framework that directly optimizes a model-agnostic utility function grounded in statistical learning theory. Our approach defines the utility of a feature subset based on the 1-Wasserstein distance between class-conditional distributions. This metric is theoretically powerful as it can be used to construct an upper bound on the Bayes classification error, allowing us to construct a utility function that is a direct surrogate for this risk bound. We instantiate this framework with a subset search strategy that effectively captures feature interactions by maximizing this risk-bound utility. Extensive experiments on real-world datasets demonstrate that our method not only achieves state-of-the-art classification performance but also demonstrates superior robustness and interpretability, providing a principled and powerful alternative to traditional feature selection methods, confirming our framework’s theoretical soundness.},
  archive      = {J_NEUCOM},
  author       = {Chunxu Cao and Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131572},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131572},
  shortjournal = {Neurocomputing},
  title        = {Feature selection via risk-bound utility maximization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training. <em>NEUCOM</em>, <em>657</em>, 131568. (<a href='https://doi.org/10.1016/j.neucom.2025.131568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning optimization faces a fundamental trade-off between convergence efficiency and generalization. First-order methods such as stochastic gradient descent (SGD) and adaptive moment estimation (Adam) tend to find flatter minima but converge slowly, while higher-order methods converge rapidly but are often drawn to sharp minima that generalize poorly. To address this, we introduce the projected variable three-term conjugate gradient (PVTTCG) algorithm. Motivated by the geometric instabilities in modern networks that use techniques such as batch normalization (BN), PVTTCG integrates an orthogonal projection into the higher-order optimization framework. This mechanism eliminates radial components from the search direction, inherently guiding the optimization toward flatter regions without requiring additional regularization terms or hyperparameters. The effectiveness of PVTTCG is validated across diverse tasks, including language modeling, large-scale image classification, and a real-world engineering application. In complex scenarios, PVTTCG consistently improves upon its higher-order baseline, achieving up to a 3.92 percentage point gain on CIFAR-100 while remaining competitive with leading first-order methods. A systematic analysis reveals that PVTTCG demonstrates superior robustness to batch size variations, particularly excelling at larger batch sizes. This robustness enables the algorithm to process batch sizes up to 2,048 in engineering applications, achieving a 35.9% test loss reduction compared to Adam. These findings establish PVTTCG as an effective solution for bridging the convergence-generalization trade-off.},
  archive      = {J_NEUCOM},
  author       = {Sanghyuk Kim and Hansu Kim and Namwoo Kang and Tae Hee Lee},
  doi          = {10.1016/j.neucom.2025.131568},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131568},
  shortjournal = {Neurocomputing},
  title        = {Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVC2: Deep video cascade clustering from video structures. <em>NEUCOM</em>, <em>657</em>, 131565. (<a href='https://doi.org/10.1016/j.neucom.2025.131565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video clustering is a critical unsupervised learning task, where category labels are unavailable, unlike in supervised video classification. The primary challenge is learning meaningful video representations without annotations to effectively group similar videos. Most existing methods extract frame-level features and apply standard clustering algorithms such as K-means, but they often fail to capture temporal relationships inherent in video data. In this paper, we introduce Deep Video Cascade Clustering ( DVC 2 ), a novel unsupervised video learning paradigm. Unlike image-based clustering methods, DVC 2 first learns an initial video representation through frame clustering, which serves as guidance, and then aligns video clustering results with both long-term and short-term structures as well as nearest neighbors. We evaluate DVC 2 on benchmark datasets, including UCF101 and Kinetics-400, achieving state-of-the-art results. Notably, even in annotation-free scenarios where self-supervised learning with K-means already yields reasonable clustering, DVC 2 demonstrates significantly superior performance.},
  archive      = {J_NEUCOM},
  author       = {Zihua Wang and Siya Mi and Yu Zhang},
  doi          = {10.1016/j.neucom.2025.131565},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131565},
  shortjournal = {Neurocomputing},
  title        = {DVC2: Deep video cascade clustering from video structures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting. <em>NEUCOM</em>, <em>657</em>, 131563. (<a href='https://doi.org/10.1016/j.neucom.2025.131563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion forecasting is a fundamental component of the autonomous driving system and plays an important role in ensuring safety. While supervised learning methods have achieved promising performance in many domains, their model capacity is typically limited by the availability of annotated data. Some previous works have tried to introduce this paradigm into motion forecasting. However, these early studies neglect the task-specific characteristics. To address this, we incorporate two key insights into motion forecasting tasks within the self-supervised paradigm and propose a novel self-supervised motion forecasting framework. First, we design a Frequency Information Harmonization pretext task that explicitly encourages the model to integrate frequency domain features with their time domain counterparts, making them work harmoniously. Second, we introduce an Implicit Scene Alignment task, which enables the model to learn scene-level semantics by aligning masked and unmasked views through shared prototypes. By jointly optimizing these objectives, the model is encouraged to leverage abundant unlabeled data and capture rich spatio-temporal representations. Extensive experiments conducted on the challenging Argoverse 2 and Argoverse 1 benchmarks demonstrate that our proposed model outperforms previous state-of-the-art baselines and can produce more accurate and reliable predictions.},
  archive      = {J_NEUCOM},
  author       = {Chunyu Liu and Zeyu Liu and Tiechui Yao and Shijie Li},
  doi          = {10.1016/j.neucom.2025.131563},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131563},
  shortjournal = {Neurocomputing},
  title        = {SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal. <em>NEUCOM</em>, <em>657</em>, 131559. (<a href='https://doi.org/10.1016/j.neucom.2025.131559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, mental stress is emerging as a common social problem triggering different health disorders, including nervousness, heart attacks, strokes, and depression. Specifically, the Electroencephalography (EEG) signal, capable of reflecting the variations in brain activity, is highly used for mental state detection. Despite their promising performance, the existing EEG-based detection methods fail to capture the inherent characteristics of highly intricate and nonstationary EEG signals. In order to address the drawbacks of existing methods, this research proposes the Deep Learning model namely, Rosmarus Migrative Search Optimized Efficient channel attention enabled Distributed Bi-directional Long Short-Term Memory (RosMS-ECDBTM) model for precise mental state detection. More specifically, the efficient channel attention facilitates the proposed model to dynamically highlight the important parts of the signal characteristics while suppressing the irrelevant regions. Besides, the distributed DL architecture improves the learning capability and scalability of the proposed model to process the large datasets, through the parallel processing of sequential data. Further, the proposed approach exploits the Rosmarus Migrative Search Optimization (RosMS) algorithm for optimizing the RosMS-ECDBTM architecture, resulting in improving the training process. Ultimately, the proposed model, combining efficient channel attention and distributed learning mechanism, captures the intricate patterns and reduces the computational complexity of mental state detection. In addition, the Hybrid Discrete Wavelet transform (DWT) approach decomposes the EEG signal into several frequency components for capturing the hidden patterns and anomalous states in the EEG signal, providing key insights for improving the mental state detection. Extensive experiments show that the RosMS-ECDBTM method provides superior performance, achieving a high accuracy of 96.78 %, precision of 98.99 %, recall of 95.91 %, and F1-score of 97.42 % for the Mental Stress Detection dataset compared to other state-of-the-art methods. Ultimately, these findings reveal the high learning efficiency of the proposed deep learning approach in enhancing the mental state detection accuracy, significantly contributing to advancing the field of mental health monitoring.},
  archive      = {J_NEUCOM},
  author       = {Mandar Nitin Kakade},
  doi          = {10.1016/j.neucom.2025.131559},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131559},
  shortjournal = {Neurocomputing},
  title        = {RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion. <em>NEUCOM</em>, <em>657</em>, 131555. (<a href='https://doi.org/10.1016/j.neucom.2025.131555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has shown promising applications in integrating information from different modalities. However, existing multimodal fusion approaches in remote sensing face two main challenges: First, multimodal fusion models relying on Convolutional Neural Networks (CNNs) or Visual Transformers (ViTs) have limitations in terms of remote modeling capabilities and computational complexity, while state-space model (SSM)-based fusion models are prone to feature redundancy due to the use of multiple scanning paths, and similarly suffer from high computational complexity. Second, existing methods do not fully address inter-modal heterogeneity, leading to poor multimodal data fusion. To address these issues, we propose an efficient multimodal fusion network, AFMamba, based on the state-space model (SSM) for semantic segmentation of remote sensing images. Specifically, we design the Efficient Dynamic Visual State Space (EDVSS) module, which enhances the efficiency of the standard Mamba model by dynamically improving local features and reducing channel redundancy. Furthermore, we introduce the Cross Attention Alignment Fusion (CAAFM) module, which combines cross-image attention fusion and channel interaction alignment to effectively improve the accuracy and efficiency of cross-modal feature fusion and mitigate feature inconsistency. Experimental results demonstrate that in multimodal hyperspectral image semantic segmentation, the proposed model reduces computational complexity, measured in GFLOPs, by at least 61 % while maintaining a low parameter count, achieving optimal overall accuracy (OA) of around 92 %, and effectively balancing performance and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Wenqian Chen and Wendie Yue and Kai Chang and Hongzhi Wang and Kaijun Tan and Xinyu Liu and Xiaoyi Cao},
  doi          = {10.1016/j.neucom.2025.131555},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131555},
  shortjournal = {Neurocomputing},
  title        = {Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-step minimax Q-learning algorithm for two-player zero-sum markov games. <em>NEUCOM</em>, <em>657</em>, 131552. (<a href='https://doi.org/10.1016/j.neucom.2025.131552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interesting iterative procedure is proposed to solve two-player zero-sum Markov games. Under suitable assumptions, the boundedness of the proposed iterates is obtained theoretically. Using results from stochastic approximation, the almost sure convergence of the proposed multi-step minimax Q-learning is obtained theoretically. More specifically, the proposed algorithm converges to the game theoretic optimal value with probability one, when the model information is not known. Numerical simulations authenticate that the proposed algorithm is effective and easy to implement.},
  archive      = {J_NEUCOM},
  author       = {Shreyas S.R. and Antony Vijesh},
  doi          = {10.1016/j.neucom.2025.131552},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131552},
  shortjournal = {Neurocomputing},
  title        = {A multi-step minimax Q-learning algorithm for two-player zero-sum markov games},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-agent evasion using deep reinforcement learning. <em>NEUCOM</em>, <em>657</em>, 131550. (<a href='https://doi.org/10.1016/j.neucom.2025.131550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective evasion strategies in pursuit–evasion scenarios is challenging, particularly when the pursuer’s model is unknown and inaccessible. This limitation hinders the application of conventional evasion policy design methods. To overcome this challenge, especially when evaders have constrained maneuverability against unrestricted pursuers, we propose a novel multi-agent evasion algorithm based on deep reinforcement learning. Our approach employs a staged learning framework, progressively guiding evaders from simpler to more complex tasks to refine their evasion strategies. Crucially, our algorithm enables evaders to infer pursuers’ intentions even without prior knowledge of pursuers’ objectives, allowing for optimal decision-making despite mobility constraints. Simulation results demonstrate that our method significantly enhances evasion success, validating the effectiveness of learning-based strategies. Additionally, the algorithm exhibits strong adaptability to environmental changes, ensuring reliable performance across diverse pursuit–evasion scenarios.},
  archive      = {J_NEUCOM},
  author       = {Bowei Yan and Runle Du and Xiaojun Ban and Di Zhou},
  doi          = {10.1016/j.neucom.2025.131550},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131550},
  shortjournal = {Neurocomputing},
  title        = {Constrained multi-agent evasion using deep reinforcement learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation. <em>NEUCOM</em>, <em>657</em>, 131539. (<a href='https://doi.org/10.1016/j.neucom.2025.131539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph convolutional networks utilize an alternating combination of one-dimensional ordinary convolution and graph convolution to extract spatio-temporal features. This alternation intertwines temporal and spatial features closely, leading to a tight coupling between them. The presence of spatio-temporal coupling complicates the analysis of spatio-temporal data, posing challenges for existing explainability algorithms to effectively separate and interpret these intertwined features. Therefore, we propose STD-Explain, an explainable algorithm based on spatio-temporal decoupled perturbation, which employs a two-stage perturbation approach considering subgraph and node-level explanations. Firstly, targeting the spatio-temporal coupling issue in spatio-temporal graph convolutional networks, the algorithm proposes a temporal perturbation algorithm based on Slice Graph and a spatial perturbation algorithm aimed at important subgraph node features. Secondly, to avoid introducing additional semantic information when extracting temporal subgraphs, we propose a method for generating temporal subgraphs in spatio-temporal decoupling, slicing human skeleton sequences with discrete masks to ensure each subsequence maintains spatial structure integrity without introducing additional edges. Furthermore, to ensure the maximum correlation between the interpreted subgraphs and model predictions, we propose a temporal important subgraph discrimination strategy to select the most relevant subgraphs to model predictions. Experimental results demonstrate that STD-Explain performs well in qualitative and quantitative analysis.},
  archive      = {J_NEUCOM},
  author       = {Yanshan Li and Ting Shi and Suixuan He and Zhiyuan Chen and Li Zhang and Rui Yu and Weixin Xie},
  doi          = {10.1016/j.neucom.2025.131539},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131539},
  shortjournal = {Neurocomputing},
  title        = {STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment. <em>NEUCOM</em>, <em>657</em>, 131534. (<a href='https://doi.org/10.1016/j.neucom.2025.131534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision–language pretraining (VLP) models have demonstrated exceptional performance across a wide range of image–text multimodal tasks. Despite their prominence, research confirms that these systems retain significant susceptibility to adversarial manipulation. Existing multimodal adversarial attack methods often fail to fully exploit sample-specific semantic structures, resulting in suboptimal cross-modal alignment and limited transferability of adversarial examples. To overcome this limitation, we propose MGSA—a Multi-Granularity Semantic Alignment Attack framework that enhances adversarial perturbation transferability by jointly disrupting cross-modal semantics at both global and fine-grained levels. MGSA captures coarse-grained alignment using overall representations and fine-grained correspondence by selectively aggregating key image regions and words based on importance. This dual-level joint optimization effectively perturbs both holistic consistency and detailed correspondences, thereby significantly enhancing attack effectiveness in white-box scenarios and transferability to black-box models. Extensive experiments conducted across diverse model architectures and multimodal tasks demonstrate that our method achieves strong performance in white-box settings while significantly improving black-box attack success rates. The results highlight the vulnerability of current VLP models and the effectiveness of our approach in generating transferable and semantically grounded adversarial examples.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Liu and Haohua Zhou and Zhidong Shen and Hui Sun},
  doi          = {10.1016/j.neucom.2025.131534},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131534},
  shortjournal = {Neurocomputing},
  title        = {MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation. <em>NEUCOM</em>, <em>657</em>, 131526. (<a href='https://doi.org/10.1016/j.neucom.2025.131526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D semantic maps generated from Light Detection and Ranging (LiDAR) point clouds enable scene understanding in diverse applications such as autonomous driving and urban planning. However, existing deep learning models struggle when tested on different domains, worsened by limited labeled data. Unsupervised Domain Adaptation (UDA) can bridge this gap, but existing UDA methods often face adaptation challenges due to domain shifts arising from variations in the physical environment, data sparsity, and sensor differences. To address these limitations, we propose UMDMix , a novel UDA architecture that operates on the mixing of multiple labeled source domains with unlabeled target domains to make the predictive model robust to cross-domain variations. UMDMix integrates a teacher–student learning scheme to produce a robust teacher model and an adaptable student model. The performance of the teacher model in the source domain is further strengthened by a position-aware loss that assigns greater significance to semantically rich neighborhoods. A combination of entropy regularization and KL-divergence loss in the target domain updates the knowledge of the teacher model to the student model during adaptation. Our extensive experiments across diverse environments show that UMDMix achieves an average improvement of 13 % on minor classes such as bicycle, traffic sign, and person in target domain datasets, outperforming previous State-Of-The-Art (SOTA) UDA methods.},
  archive      = {J_NEUCOM},
  author       = {Anurag Nihal and Pyare Lal and Vaibhav Kumar},
  doi          = {10.1016/j.neucom.2025.131526},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131526},
  shortjournal = {Neurocomputing},
  title        = {Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure. <em>NEUCOM</em>, <em>657</em>, 131521. (<a href='https://doi.org/10.1016/j.neucom.2025.131521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a prescribed performance control algorithm with asymmetric boundary for Unmanned Surface Vehicle (USV) formation to achieve cooperative navigation under marine disturbances. The proposed algorithm consists of a guidance switching mechanism and a robust adaptive control method. In the improved guidance principle, a velocity correction rule is provided to generate accurate reference signals for USVs during path following. Combined with the guidance term, the communication load between controller and actuator is significantly reduced by employing the Dynamic Event-Triggered Mechanism (DETM) with adaptive updating of threshold parameters. By integrating the initial errors into the performance boundary function, the controller can effectively adapt to different initial states. In addition, due to the smooth property of the shifting function, the error oscillation of the system before steady state is effectively suppressed. The Radial Basis Function Neural Networks (RBF-NNs) are utilized to design damping terms, enhancing the anti-interference capability in marine environments and mitigating the effects of nonlinearities in the model. Through the Lyapunov theorem, the Semi-Globally Uniformly Ultimately Bounded (SGUUB) stability of all state variables is guaranteed. Finally, quantitative validation of the algorithm is performed through numerical simulations and comparative analysis. The results demonstrate a control accuracy within 0.5 meters while showing that, compared to Static Event-Triggering Mechanisms (SETM), the DETM reduces control update frequency for surge force and yawing moment by 12.32 % and 18.78 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Guoqing Zhang and Junji Feng and Shilin Yin and Matthew Montebello},
  doi          = {10.1016/j.neucom.2025.131521},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131521},
  shortjournal = {Neurocomputing},
  title        = {Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines. <em>NEUCOM</em>, <em>657</em>, 131507. (<a href='https://doi.org/10.1016/j.neucom.2025.131507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient 3D object detection is essential for ensuring both safety and operational efficiency in open-pit mines. Due to complex scene structures, broad perception ranges, and significant object size variations, existing point-based 3D detection methods face challenges that limit their applicability in open-pit mines. To address these issues, Mine-SSD, a single-stage 3D object detection method, is developed with dual-threshold set abstraction (DT-SA) and a radius-adaptive grouping mechanism. Specifically, a dual-head self-correlation module is introduced to calculate comprehensive importance scores for each point, enhancing the model’s ability to prioritize key features. Using these importance scores, a dual-threshold self-correlative farthest point sampling (DTSC-FPS) method is applied to retain key non-local information points during downsampling in set abstraction (SA). Additionally, a radius-adaptive grouping mechanism is designed to dynamically adjust the candidate point aggregation radius, capturing critical features of unconventional objects and supporting multi-scale feature processing. Finally, a novel regression loss function is constructed to improve prediction accuracy and balanced performance across objects of different sizes, ensuring reliable performance of Mine-SSD in multi-scale detection. Extensive experiments on an open-pit mine dataset validate the effectiveness of Mine-SSD.},
  archive      = {J_NEUCOM},
  author       = {Zhongyu Xie and Yuqian Zhao and Fan Zhang and Biao Luo and Wenliu Hu and Tenghai Qiu},
  doi          = {10.1016/j.neucom.2025.131507},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131507},
  shortjournal = {Neurocomputing},
  title        = {Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131498. (<a href='https://doi.org/10.1016/j.neucom.2025.131498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although large-scale pre-trained vision–language models (VLMs) exhibit significant potential for cross-domain visual tasks, existing prompt-learning-based unsupervised domain adaptation (UDA) methods suffer from source domain overfitting and target domain performance degradation. This paper experimentally demonstrates that conventional prompt learning exhibits insufficient cross-domain generalization due to optimization being heavily biased toward the source distribution. To address this challenge, we propose a Self-regulating Distribution Alignment (SRDA) framework. Its core innovation is a dual-branch collaborative optimization mechanism that dynamically balances cross-domain semantic alignment with pre-trained knowledge preservation. Specifically, the self-regulating multimodal prompt branch incorporates three constraints: semantic consistency regularization, dual-domain collaborative contrastive regularization, and text semantic diversity enhancement. This design suppresses prompt overfitting to the source domain while preserving CLIP’s zero-shot generalization capability. The cross-domain alignment branch introduces dynamic dual-domain feature bank and Cross-domain Collaborative Dual Attention module, achieving fine-grained local semantic calibration through moving average prototypes and a dual-layer attention mechanism. Extensive experiments validate SRDA’s effectiveness on downstream UDA tasks. The code is available at https://github.com/QYw12/SRDA .},
  archive      = {J_NEUCOM},
  author       = {Yang Qu and Jinlong Shi and Yun Cui and Ao Zhang and Suqin Bai and Ye Lu},
  doi          = {10.1016/j.neucom.2025.131498},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131498},
  shortjournal = {Neurocomputing},
  title        = {SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures. <em>NEUCOM</em>, <em>657</em>, 131489. (<a href='https://doi.org/10.1016/j.neucom.2025.131489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the synchronization of drive-response memristive competitive neural networks (MCNNs) under multiple actuator failures is studied through implementing fault-tolerant control scheme. Unlike previous studies, the actuator failures considered in this paper include both bias and effectiveness failures. To address these challenges, a proper mathematical model is first established to capture the impact of actuator failures on control inputs. Subsequently, several sufficient conditions are deduced by designing an appropriate bilayer fault-tolerant controller and constructing a Lyapunov functional to achieve the global exponential synchronization, finite-time synchronization, fixed-time synchronization and predefined-time synchronization respectively. Additionally, the settling time upper bounds for the proposed synchronization methods are determined. In the end, numerical simulations with analysis and comparison are performed to confirm the validity of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Duan and Yanli Huang and Quang Dan Le and Tse Chiu Wong},
  doi          = {10.1016/j.neucom.2025.131489},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131489},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-boundary awareness of shared categories for source-free universal domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131473. (<a href='https://doi.org/10.1016/j.neucom.2025.131473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Universal Domain Adaptation (SF-UniDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data or prior knowledge of cross-domain category shifts. Existing methods focus on distinguishing target-private unknown samples and assigning pseudo-labels to known samples across the entire label space, including both shared and source-private categories as pseudo-labels, for self-training. However, this data-aware pseudo-labeling approach could mistakenly assign known samples to either source-private or target-private categories, making it sensitive to category shifts and potentially introducing errors or mislabeling. In this paper, we propose Double-boundary Awareness Domain Adaptation (DADA), a class-aware framework that partitions the target domain pseudo-label space into shared, potential source-private, and target-private categories. By labeling target-private samples as unknown and filtering out misassigned source-private samples, DADA enhances the quality of target samples and the reliability of pseudo-labels. To achieve this, we introduce Double-bounded Shared Categories Refinement (DSCR) module, which refines shared classes by identifying both source- and target-private categories based on prior class probabilities and the entropy distribution. Additionally, we incorporate Class-Aware Discriminative Learning (CADL) to enhance discrimination between shared and target-private samples across domains. Experiments on four benchmarks demonstrate the effectiveness of DADA, with overall H-score gains of 8.2 % in the OPDA scenario on Digit dataset and accuracy gains of 10.6 % in the PDA scenario on VisDA dataset. Code is available at: https://github.com/W2Wzj/DADA .},
  archive      = {J_NEUCOM},
  author       = {Zhijing Wang and Ji Guo and Xu Sun and Yi Luo and Aiguo Chen},
  doi          = {10.1016/j.neucom.2025.131473},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131473},
  shortjournal = {Neurocomputing},
  title        = {Double-boundary awareness of shared categories for source-free universal domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGN: Stochastic guidance network for sim-to-real generalization. <em>NEUCOM</em>, <em>657</em>, 131468. (<a href='https://doi.org/10.1016/j.neucom.2025.131468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant domain differences between synthetic data and real data are a challenging problem for current domain generalized segmentation networks. Therefore, this paper proposes a stochastic guidance network (SGN) for sim-to-real generalization that includes the category reweighting strategy, Multi-scale Feature Fusion Guidance (MSFFG) module and multiple style perturbation modules, which improves the issues caused by the imbalance of the source domain’s sample categories as well as large domain gap. Experimental results show that our SGN can effectively enhance the model’s generalization ability to unseen data. In terms of mean intersection over union (mIoU) metric, compared with SOTA, the SGN improves by 3.86 % and 2.05 % respectively on two real scene-enhanced datasets(Rain_Cityscapes, Foggy_Cityscapes), and an average improvement of 1.48 % on four conventional datasets (BDD100k, Cityscapes, Mapillary, Synthia). Our project can be found at https://githubcom/leo-lab-511/SGN.},
  archive      = {J_NEUCOM},
  author       = {Yao Li and Jinlong Shi and Yun Cui and Dan Xu and Wei Teng and Yan Jiang},
  doi          = {10.1016/j.neucom.2025.131468},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131468},
  shortjournal = {Neurocomputing},
  title        = {SGN: Stochastic guidance network for sim-to-real generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers. <em>NEUCOM</em>, <em>657</em>, 131449. (<a href='https://doi.org/10.1016/j.neucom.2025.131449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oblivious Transfer (OT) is crucial in various security protocols, as it serves as a privacy-preserving and secure communication protocol. However, traditional OT protocols often necessitate complex encryption algorithms and involve intricate steps. Given the rapid advancements in artificial intelligence, it is imperative to explore the potential of artificial neural networks in simplifying OT protocols while still meeting stringent security and privacy requirements. To this need, we introduce the Adv ersarial O blivious T ransfer (AdvOT) protocol, which integrates OT with the adversarial learning mechanism of Generative Adversarial Network (GAN). Our approach involves training a neural network model to learn encryption techniques through end-to-end adversarial training, thereby eliminating the reliance on specific algorithms. The AdvOT protocol comprises two phases. Firstly, a Random Oblivious Transfer (ROT) protocol is employed to generate and distribute keys based on the CKKS homomorphic encryption algorithm. Subsequently, neural networks are introduced to replace specific symmetric encryption algorithms and encrypt the messages to be transferred. These neural networks undergo training using the adversarial learning mechanism to develop a symmetric encryption algorithm. Furthermore, to enhance the model, attack networks with varying capabilities are created, resulting in a more secure encryption algorithm capable of withstanding multiple attackers. Experimental results demonstrate that the execution speed of the CKKS-based ROT algorithm is significantly faster compared to the BFV and Paillier algorithms. Moreover, in adversarial network models with multiple attackers, the decryption accuracy for the recipient approaches 100 %, while the accuracy or classification error rate for attackers is approximately 50 %. These findings indicate that the proposed method effectively safeguarded communication between parties from interception.},
  archive      = {J_NEUCOM},
  author       = {Yuke Wang and Zhentian Zhong and Ninghao Liu and Xiaohui Li and Junfeng Wang},
  doi          = {10.1016/j.neucom.2025.131449},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131449},
  shortjournal = {Neurocomputing},
  title        = {AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study. <em>NEUCOM</em>, <em>657</em>, 131440. (<a href='https://doi.org/10.1016/j.neucom.2025.131440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving partial differential equations (PDEs) with discontinuous solutions—such as shock waves in multiphase viscous flow in porous media—is critical for a wide range of scientific and engineering applications, as they represent sudden changes in physical quantities. Physics-Informed Neural Networks (PINNs), an approach proposed for solving PDEs, encounter significant challenges when applied to such systems. Accurately solving PDEs with discontinuities using PINNs requires specialized techniques to ensure effective solution accuracy and numerical stability. Various methods have been developed to address the challenges of modeling discontinuities within the PINNs framework. This work reviews and benchmarks these approaches across problems of varying complexity, categorizing them into three broad groups, influencing solution accuracy differently. (1) Physics-modification (PM) methods improve accuracy by modifying the system’s physics, such as adding artificial viscosity or enforcing entropy constraints. (2) Loss and training modification (LM) techniques focus on regularizing the loss landscape, often by refining the loss term in high-error regions. (3) Architecture-modification (AM) approaches, on the other hand, propose advanced network designs to handle discontinuities better. A benchmarking study was conducted on two multiphase flow problems in porous media: the classic Buckley-Leverett (BL) problem and a fully coupled system of equations involving shock waves but with varying levels of solution complexity. The findings show that PM and LM approaches can provide accurate solutions for the BL problem by effectively addressing the infinite gradients associated with shock occurrences. In contrast, AM methods failed to effectively resolve the shock waves. When applied to fully coupled PDEs (with more complex loss landscapes), the generalization error in the solutions quickly increased, highlighting the need for ongoing innovation. This study provides a comprehensive review of existing techniques for managing PDE discontinuities using PINNs, offering information on their strengths and limitations. The results underscore the necessity for further research to improve PINNs’ ability to handle complex discontinuities, particularly in more challenging problems with complex loss landscapes. This includes problems involving higher dimensions or multiphysics systems, where current methods often struggle to maintain accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jassem Abbasi and Ameya D. Jagtap and Ben Moseley and Aksel Hiorth and Pål Østebø Andersen},
  doi          = {10.1016/j.neucom.2025.131440},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131440},
  shortjournal = {Neurocomputing},
  title        = {Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting. <em>NEUCOM</em>, <em>657</em>, 131422. (<a href='https://doi.org/10.1016/j.neucom.2025.131422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose SparseSCIGaussian, a novel method for achieving high-quality novel view synthesis under sparse input conditions. Previous methods often rely heavily on depth or neural priors, which can lead to generalization challenges and significant quality degradation on complex datasets. These limitations arise primarily from the insufficient scene information available in sparse regular images. To overcome these issues, our approach utilizes images captured through Snapshot Compressive Imaging (SCI) as input. SCI-captured images inherently encode richer scene information compared to regular images, thereby substantially improving the quality of novel view synthesis under sparse input conditions. Moreover, SCI images can be conveniently captured using a software-implemented encoder, making them as accessible as traditional images. Experimental results demonstrate that our method improves 2.65 dB (13.04 %) in PSNR compared to previous methods, and further exhibits the inherent advantages of using SCI images for sparse input novel view synthesis.},
  archive      = {J_NEUCOM},
  author       = {Haoyuan He and Xuan Wang and Nanning Zheng and Caigui Jiang},
  doi          = {10.1016/j.neucom.2025.131422},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131422},
  shortjournal = {Neurocomputing},
  title        = {SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RehearMixup: Improving rehearsal-based continual learning. <em>NEUCOM</em>, <em>657</em>, 131404. (<a href='https://doi.org/10.1016/j.neucom.2025.131404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks often suffer from catastrophic forgetting when learning new tasks, leading to the loss of previously acquired knowledge. To address this issue, rehearsal-based methods have emerged, which involve storing a subset of data from previous tasks and accessing it during the learning of new tasks. Current rehearsal-based methods focus on selecting representative samples to store in memory. However, there is a considerable lack of exploration of how to exploit the data at hand and consider the correlation between tasks or between past and new knowledge to improve performance. Therefore, we propose a simple yet effective approach named RehearMixup that adapts the Mixup technique into rehearsal-based methods, which synthesizes new samples for learning by interpolating data from past or current tasks. Specifically, we introduce three strategies, namely Cross-Mixup , Intra-Memory-Mixup , and Intra-Current-Mixup , based on the inherent characteristics of rehearsal-based methods - involving the memory and new tasks. Through empirical evaluations under various benchmark scenarios, we compare our approach against different rehearsal-based baselines. The results demonstrate that ours, particularly Intra-Current-Mixup , improves accuracy, backward transfer, forward transfer, and enhances the model’s robustness.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Kaiyuan Qi and Dong Wu and Guoqiang Wu and Yilong Yin},
  doi          = {10.1016/j.neucom.2025.131404},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131404},
  shortjournal = {Neurocomputing},
  title        = {RehearMixup: Improving rehearsal-based continual learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A zero-shot high-performance fire detection framework based on large language models. <em>NEUCOM</em>, <em>657</em>, 131403. (<a href='https://doi.org/10.1016/j.neucom.2025.131403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire detection is crucial for minimizing economic damage and safeguarding human lives. Existing methods, including advanced AI and ML techniques, face challenges such as detecting small fires in complex environments and relying on extensive labeled data for training. This paper proposes a novel zero-shot fire detection framework leveraging large language models (LLMs) and contrastive learning-based image–text pre-training models. The framework introduces an enhanced self-attention mechanism for optimizing image embeddings, diverse prompt generation using GPT-3.5 for improved generalization, and a dynamic threshold calculation method based on statistical analysis to enhance detection accuracy and reliability. The proposed method is tested on the public FLAME dataset and a self-collected dataset. Experimental results demonstrate that the proposed method outperforms state-of-the-art models in detecting small fires within complex backgrounds, achieving better detection performance without the need for any training data. This study highlights the potential of zero-shot learning in fire detection and provides a promising solution for real-world fire detection applications.},
  archive      = {J_NEUCOM},
  author       = {Hongyang Zhao and Yi Liu and Yuhang Han and Xingdong Li and Yanan Guo and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131403},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131403},
  shortjournal = {Neurocomputing},
  title        = {A zero-shot high-performance fire detection framework based on large language models},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hetero-MoE by attention: Three-plus tasks learning solver. <em>NEUCOM</em>, <em>657</em>, 131333. (<a href='https://doi.org/10.1016/j.neucom.2025.131333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) stands as a promising sub-field of machine learning, aiming to simultaneously tackle multiple tasks. By leveraging shared representations and structures across diverse tasks, MTL models often exhibit higher data efficiency compared to single-task models across various domains, including recommender system applications, multi-label classification and other AI applications. However, the efficacy of MTL models is sometimes hindered by the multi-causal task conflict problem. To address this challenge, existing research predominantly focuses on enhancing structural designs and the underlying optimizers. Nevertheless, these approaches often fall short in comprehensively mitigating task conflicts, especially in scenarios involving three or more tasks, such as recommender systems. When shared experts contend with excessive task-related information simultaneously, the effective filtration of potentially harmful knowledge becomes challenging. To this end, we propose a novel Heterogeneous Multi-Expert model with an attention layer, termed HMEA. HMEA introduces Heterogeneous Experts as shared experts to decompose signal connections among three or more tasks. Additionally, it integrates an attention layer to further decouple conflicts among mini-tasks within shared experts. The experiments and ablation studies on various standard and synthetic datasets illustrate the effectiveness of HMEA in alleviating the task conflict problem inherent in three-plus task learning systems.},
  archive      = {J_NEUCOM},
  author       = {Dandan Zhang and Guanqi Zeng and Haotian Wu and Hongwen Zhang and Zheng Ye and Yao Yang},
  doi          = {10.1016/j.neucom.2025.131333},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131333},
  shortjournal = {Neurocomputing},
  title        = {Hetero-MoE by attention: Three-plus tasks learning solver},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="nn">NN - 43</h2>
<ul>
<li><details>
<summary>
(2026). AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression. <em>NN</em>, <em>194</em>, 108134. (<a href='https://doi.org/10.1016/j.neunet.2025.108134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have demonstrated remarkable performance in the field of novel view synthesis (NVS). However, their high computational cost limits practical applicability. The 3D Gaussian Splatting (3DGS) method offers a significant improvement in rendering efficiency, enabling real-time rendering through its explicit representations. Nevertheless, its substantial storage requirements pose challenges for complex scenes and resource-constrained devices. Existing methods aim to achieve storage compression through redundant point pruning, spherical harmonics adjustment, and vector quantization. However, point pruning methods often compromise geometric details in complex structures, while vector quantization approaches fail to capture feature relationships effectively, resulting in texture degradation and geometric boundary blurring. Although anchor point representations partially address storage concerns, their sparse representation limits compression efficiency. These limitations become particularly evident in scenes with intricate textures and complex lighting conditions. To ensure optimal compression ratios while maintaining high fidelity in Gaussian scenarios, this paper proposes an Attention-Aware Adaptive Codebook Gaussian Splatting (AAC-GS) method for efficient storage compression. The approach dynamically adjusts the size of the codebook to optimize storage efficiency and incorporates an attention mechanism to capture feature contextual relationships, thereby enhancing reconstruction quality. Additionally, a Generative Adversarial Network (GAN) is employed to mitigate quantization losses, achieving a balance between compression rate and visual fidelity. Experimental results demonstrate that AAC-GS achieves an average compression ratio of approximately 40× while maintaining high reconstruction quality, showcasing its potential for multi-scene applications.},
  archive      = {J_NN},
  author       = {Fang Wan and Jianhang Zhang and Tianyu Li and Guangbo Lei and Li Xu and Zhiwei Ye},
  doi          = {10.1016/j.neunet.2025.108134},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108134},
  shortjournal = {Neural Netw.},
  title        = {AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints. <em>NN</em>, <em>194</em>, 108130. (<a href='https://doi.org/10.1016/j.neunet.2025.108130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a fixed-time learning-based dynamic event-triggered control framework to address the optimal tracking control problem in robotic systems with the prescribed performance constraints. In many practical scenarios, the states of robotic systems are often subject to performance constraints imposed by structural characteristics and task requirements. To address this issue, prescribed performance control (PPC) theory is employed to ensure performance state constraints and construct an unconstrained tracking error system. Subsequently, a critic-only adaptive dynamic programming (ADP) control framework is designed to approximate the optimal control law for the transformed unconstrained system. Furthermore, in the design of critic neural network (NN), a novel fixed-time convergence (FTC) weight update law based on concurrent learning (CL) techniques is proposed, which guarantees the fixed-time convergence of weight estimation error under relaxed persistent excitation (PE) condition. Throughout the controller design, a dynamic event-triggered mechanism is adopted to reduce the number of sampling instances and computational resources. Meanwhile, the stability of the closed-loop system under this mechanism is rigorously proven. Finally, the effectiveness of the proposed method is demonstrated through simulation results and comparative analysis.},
  archive      = {J_NN},
  author       = {Zhinan Peng and Xingyu Zhang and Zhuo Xia and Lin Hao and Linpu He and Hong Cheng},
  doi          = {10.1016/j.neunet.2025.108130},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108130},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation. <em>NN</em>, <em>194</em>, 108128. (<a href='https://doi.org/10.1016/j.neunet.2025.108128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal analysis can provide complementary information and significantly aid in the early diagnosis and intervention of Alzheimer’s Disease (AD). However, the issue of missing modalities presents a major challenge, as most methods that rely on complete multi-modal data become infeasible. The most advanced approaches to addressing missing modalities typically use generative models, but these often neglect the importance of modality-specific features, leading to biased predictions and poor performance. Inspired by this limitation, we propose a Modality Disentanglement and Specific Features Distillation Network (MDSFD-Net) for AD diagnosis with missing modality, which consists of a disentanglement-based imputation module (DI module) and a specific features distillation module (SFD module). In the DI module, we introduce a novel spatial-channel modality disentanglement learning scheme that is first used to disentangle modality-specific features, along with a shared constrain objective to learn modality-shared features, which are used for imputing missing modality features. To address the specific features of the missing modality, the SFD module is designed to transfer the specific features from complete modality in the teacher network to the incomplete modality in the student network. A regularized knowledge distillation (R-KD) mechanism is incorporated to mitigate the impact of incorrect predictions from the teacher network. By leveraging modality-shared features imputation and modality-specific features distillation, our model can effectively learn sufficient information for classification even if some modalities are missing. Extensive experiments on ADNI dataset demonstrate the superiority of our proposed MDSFD-Net over state-of-the-art methods in missing modality situations.},
  archive      = {J_NN},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neunet.2025.108128},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108128},
  shortjournal = {Neural Netw.},
  title        = {MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spiking neural networks for EEG signal analysis: From theory to practice. <em>NN</em>, <em>194</em>, 108127. (<a href='https://doi.org/10.1016/j.neunet.2025.108127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate and efficient information processing of the human brain, driven by spiking neural interactions, has led to the development of spiking neural networks (SNNs) as a cutting-edge neural network paradigm. Unlike traditional artificial neural networks (ANNs) that use continuous values, SNNs emulate the brain’s spiking mechanisms, offering enhanced temporal information processing and computational efficiency. This review addresses the critical gap between theoretical advancements and practical applications of SNNs in EEG signal analysis. We provide a comprehensive examination of recent SNN methodologies and their application to EEG signals, highlighting their potential benefits over conventional deep learning approaches. The review encompasses foundational knowledge of SNNs, detailed implementation strategies for EEG analysis, and challenges inherent to SNN-based methods. Practical guidance is provided through step-by-step instructions and accessible code available on GitHub, aimed at facilitating researchers’ adoption of these techniques. Additionally, we explore emerging trends and future research directions, emphasizing the potential of SNNs to advance brain-computer interfaces and neurofeedback systems. This paper serves as a valuable resource for bridging the gap between theoretical developments in SNNs and their practical implementation in EEG signal analysis.},
  archive      = {J_NN},
  author       = {Siqi Cai and Zheyuan Lin and Xiaoli Liu and Wenjie Wei and Shuai Wang and Malu Zhang and Tanja Schultz and Haizhou Li},
  doi          = {10.1016/j.neunet.2025.108127},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108127},
  shortjournal = {Neural Netw.},
  title        = {Spiking neural networks for EEG signal analysis: From theory to practice},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck. <em>NN</em>, <em>194</em>, 108125. (<a href='https://doi.org/10.1016/j.neunet.2025.108125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are prominent for their effectiveness in processing graph-structured data for semi-supervised node classification tasks. Most existing GNNs perform message passing directly based on the observed graph structure. However, in real-world scenarios, the observed structure is often suboptimal due to multiple factors, significantly degrading the performance of GNNs. To address this challenge, we first conduct an empirical analysis showing that different graph structures significantly impact empirical risk and classification performance. Motivated by our observations, we propose a novel method named T rade-off G raph S tructure L earning (TGSL), guided by the multifaceted Graph Information Bottleneck (GIB) principle based on Mutual Information (MI). The key idea behind TGSL is to learn a minimal sufficient graph structure that minimizes empirical risk while maintaining performance. Specifically, we introduce global feature augmentation to capture the structural roles of nodes, and global structure augmentation to uncover global relationships between nodes. The augmented graphs are then processed by structure estimators with different parameters for refinement and redefinition, respectively. Additionally, we innovatively leverage multifaceted GIB as the optimization objective by maximizing the MI between the labels and the representation derived from the final structure, while constraining the MI between this representation and that based on the redefined structures. This trade-off helps avoid capturing irrelevant information from the redefined structures and enhances the final representation for node classification. We conduct extensive experiments across a range of datasets under clean and attacked conditions. The results demonstrate the outstanding performance and robustness of TGSL over state-of-the-art baselines.},
  archive      = {J_NN},
  author       = {Shuangjie Li and Baoming Zhang and Jianqing Song and Gaoli Ruan and Chongjun Wang and Junyuan Xie},
  doi          = {10.1016/j.neunet.2025.108125},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108125},
  shortjournal = {Neural Netw.},
  title        = {TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving few-shot relation classification with multi-scale hierarchical prototype learning. <em>NN</em>, <em>194</em>, 108124. (<a href='https://doi.org/10.1016/j.neunet.2025.108124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot relation classification aims to distinguish different relation classes from extremely limited annotated data. Most existing methods primarily use prototype networks to construct a prototypical representation, classifying the instance by comparing its similarity to each prototype. Despite achieving promising results, the prototypes derived solely from limited support instances are often inaccurate due to constraints in feature extraction capabilities. Moreover, they ignore the different hierarchical levels of relational information, which can provide more effective guidance for classification. In this paper, we propose a novel m ulti-sc a le hie r arch i cal pr o totype (Mario) learning method that captures relational interaction information at three levels: inter-set, inter-class and intra-class, enhancing the model’s understanding of global semantic information and helping it distinguish subtle differences between classes. Additionally, we incorporate relational descriptive information to reduce the impact of textual expression diversity, enabling the model to emulate the human cognitive process in understanding variation. Extensive experiments conduct on the FewRel dataset demonstrate the effectiveness of our proposed model. In particular, it achieves accuracy rates of 92.52 %/95.33 %/85.46 %/91.33 % under four common few-shot settings. Notably, in the critical 5-way and 10-way 1-shot settings, it outperforms the strongest baseline by 2.87 % and 4.29 %.},
  archive      = {J_NN},
  author       = {Haijia Bi and Lu Liu and Hai Cui and Shengyue Liu and Ridong Han and Jiayu Han and Tao Peng},
  doi          = {10.1016/j.neunet.2025.108124},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108124},
  shortjournal = {Neural Netw.},
  title        = {Improving few-shot relation classification with multi-scale hierarchical prototype learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Planning forward: Deep incremental hashing by gradually defrosting bits. <em>NN</em>, <em>194</em>, 108123. (<a href='https://doi.org/10.1016/j.neunet.2025.108123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep incremental hashing can generate hash codes incrementally for new classes, while keeping the existing ones unchanged. Existing methods typically allocate fixed code lengths to all classes, causing the entire Hamming space occupied by existing classes, thus failing to prepare models for future extensions. This significantly limits the ability to effectively accommodate new classes. Beyond that, it is inefficient in computation and storage to use all bits for encoding a few classes in the early sessions. This paper presents B it D efrosting Deep I ncremental H ashing (BDIH) to tackle these problems. Our key insight is to map the classes into a small subspace by freezing most hash bits during the first session, which reserves adequate space for future classes. This allows subsequent sessions to map new classes into progressively expanding subspaces by defrosting a portion of the frozen bits. Specifically, we propose a bit-defrosting code learning framework, which includes a bit-defrosting center generation part and a center-based bit-defrosting code learning part. The former part generates hash centers as learning objectives in expanding subspaces while the latter part learns globally discriminative hash codes with the guidance of hash centers and preserves the backward compatibility between the updated model and previously stored codes. As a result, our method achieves comparable performance on old classes using fewer bits while reserving more space for new ones. Extensive experiments demonstrate that BDIH outperforms existing methods regarding retrieval accuracy and storage efficiency in long-sequence incremental learning scenarios.},
  archive      = {J_NN},
  author       = {Qinghang Su and Dayan Wu and Chenming Wu and Bo Li and Weiping Wang},
  doi          = {10.1016/j.neunet.2025.108123},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108123},
  shortjournal = {Neural Netw.},
  title        = {Planning forward: Deep incremental hashing by gradually defrosting bits},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Offline-to-online reinforcement learning with efficient unconstrained fine-tuning. <em>NN</em>, <em>194</em>, 108120. (<a href='https://doi.org/10.1016/j.neunet.2025.108120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning provides the capability to learn a policy only from pre-collected datasets, but its performance is often limited by the quality of the offline dataset and the coverage of the state-action space. Offline-to-online reinforcement learning is promising to address these limitations and achieve high sample efficiency by integrating the advantages of both offline and online learning paradigms. However, existing methods typically struggle to adapt to online learning and improve the performance of pre-trained policies due to the distributional shift and conservative training. To address these issues, we propose an efficient unconstrained fine-tuning framework that removes conservative constraints on the policy during fine-tuning, allowing thorough exploration of state-action pairs not covered by the offline data. This framework leverages three key techniques: dynamics representation learning, layer normalization, and increasing the update frequency of the value network to improve sample efficiency and mitigate value function estimation bias caused by the distributional shift. Dynamics representation learning accelerates fine-tuning by capturing meaningful features, layer normalization bounds Q -value to suppress catastrophic value function divergence, and increasing the update frequency of the value network enhances the sample efficiency and reduces value function estimation bias. Extensive experiments on the D4RL benchmark demonstrate that our algorithm outperforms state-of-the-art offline-to-online reinforcement learning algorithms across various tasks with minimal online interactions.},
  archive      = {J_NN},
  author       = {Jun Zheng and Runda Jia and Shaoning Liu and Ranmeng Lin and Dakuo He and Fuli Wang},
  doi          = {10.1016/j.neunet.2025.108120},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108120},
  shortjournal = {Neural Netw.},
  title        = {Offline-to-online reinforcement learning with efficient unconstrained fine-tuning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AutoSGRL: Automated framework construction for self-supervised graph representation learning. <em>NN</em>, <em>194</em>, 108119. (<a href='https://doi.org/10.1016/j.neunet.2025.108119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated machine learning (AutoML) is a promising solution for building a machine learning framework without human assistance and has attracted significant attention throughout the computational intelligence research community. Although there has been an emerging interest in graph neural architecture search, current research focuses on the specific design of semi-supervised or supervised graph neural networks. Motivated by this, we propose a novel method that enables the automatic construction of flexible self-supervised graph representation learning frameworks for the first time as far as we know, referred to as AutoSGRL. Based on existing self-supervised graph contrastive learning methods, AutoSGRL establishes a framework search space for self-supervised graph representation learning, which encompasses data augmentation strategies and proxy tasks for constructing graph contrastive learning frameworks, and the hyperparameters required for model training. Then, we implement an automatic search engine based on genetic algorithms, which constructs multiple self-supervised graph representation learning frameworks as the initial population. By simulating the process of biological evolution including selection, crossover, and mutation, the search engine iteratively evolves the population to identify high-performed frameworks and optimal hyperparameters. Empirical studies demonstrate that our AutoSGRL achieves comparative or even better performance than state-of-the-art manual-designed self-supervised graph representation learning methods and semi-supervised graph neural architecture search methods.},
  archive      = {J_NN},
  author       = {Yu Xie and Yu Chang and Ming Li and A.K. Qin and Xialei Zhang},
  doi          = {10.1016/j.neunet.2025.108119},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108119},
  shortjournal = {Neural Netw.},
  title        = {AutoSGRL: Automated framework construction for self-supervised graph representation learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation. <em>NN</em>, <em>194</em>, 108118. (<a href='https://doi.org/10.1016/j.neunet.2025.108118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vascular morphology plays a crucial role in diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and stylistic augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to apply random photometric augmentations and introduce uncertainty perturbations, enriching the stylistic diversity of fundus images and further improving the model’s robustness and generalization across varying imaging conditions. Our framework, which employs a DeepLabv3+ model with a MobileNetV2 backbone as its segmentation network, has been rigorously evaluated on four challenging datasets—DRIVE, CHASEDB1, HRF, and STARE—achieving Dice Similarity Coefficient (DSC) of 78.45%, 78.62%, 72.66% and 82.17%, respectively, with an average DSC of 77.98%. These results demonstrate that our method surpasses existing approaches, validating its effectiveness and highlighting its potential for clinical application in automated retinal vessel analysis.},
  archive      = {J_NN},
  author       = {Bo Liu and Yudong Zhang and Shuihua Wang and Siyue Li and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108118},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108118},
  shortjournal = {Neural Netw.},
  title        = {DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution. <em>NN</em>, <em>194</em>, 108116. (<a href='https://doi.org/10.1016/j.neunet.2025.108116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data distribution discrepancy across datasets is one of the major obstacles hindering the improvement of the accuracy of cross-domain adaptive detection of medical images. To address this challenge, we propose a novel lightweight cross-modal adaptive detection module named LCA-Med (LCaM). The proposed module boasts a lightweight structure and a minimalistic parameter count, thereby facilitating its integration into the anterior segment of a diverse array of foundational and downstream networks. It is adept at serving as a feature preprocessor, proficiently extracting pertinent information regrading pathologies from a array of images (image modality) produced through varied medical imaging techniques, all guided by the input of prompts (text modality). We also propose a novel cross-modal medical image adaptive detection method, LCA-Med CNX (LCaM-CNX), and a novel cross-domain adaptive detection training paradigm that incorporates generated dataset groups, an attention module, and a meta-heuristic algorithm. Experimental results on six medical image datasets compared with ten state-of-the-art methods demonstrate that the LCaM-CNX trained following the proposed paradigm achieves the best performance on five datasets and competitive performance on the other dataset. Notably, our method outperforms the state-of-the-art methods more when the data distribution is more imbalanced.},
  archive      = {J_NN},
  author       = {Xiang Li and Long Lan and Husam Lahza and Shaowu Yang and Shuihua Wang and Yong Liang and Hudan Pan and Wenjing Yang and Hengzhu Liu and Yudong Zhang},
  doi          = {10.1016/j.neunet.2025.108116},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108116},
  shortjournal = {Neural Netw.},
  title        = {LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual causal inference for robust visual question answering. <em>NN</em>, <em>194</em>, 108115. (<a href='https://doi.org/10.1016/j.neunet.2025.108115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) systems have seen remarkable progress with the incorporation of multimodal data. However, their performance is still hampered by biases ingrained in language and vision modalities, frequently resulting in subpar generalization. In this study, we introduce a novel counterfactual causal framework (CC-VQA). This framework utilizes Counterfactual Sample Synthesis (CSS) and causal inference to tackle cross-modality biases. Our approach innovatively employs a strategy based on causal graphs, which effectively disentangles spurious correlations in multimodal data. This ensures a balanced and precise multimodal reasoning process, enabling the model to make more accurate and unbiased decisions. Moreover, we propose a contrastive loss mechanism. By contrasting the embeddings of positive and negative samples, this mechanism significantly enhances the robustness of VQA models. Additionally, we develop a robust training strategy that improves both the visual-explainable and question-sensitive capabilities of these models. Our experimental evaluations on benchmark datasets, such as VQA-CP v2 and VQA v2, demonstrate substantial improvements in bias mitigation and overall accuracy. The proposed CC-VQA framework outperforms state-of-the-art methods, highlighting its effectiveness in enhancing the performance of VQA systems.},
  archive      = {J_NN},
  author       = {Wei Li and Zhixin Li and Fuyun Deng and Kun Zeng and Canlong Zhang},
  doi          = {10.1016/j.neunet.2025.108115},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108115},
  shortjournal = {Neural Netw.},
  title        = {Counterfactual causal inference for robust visual question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inference of hidden common driver dynamics by anisotropic self-organizing neural networks. <em>NN</em>, <em>194</em>, 108113. (<a href='https://doi.org/10.1016/j.neunet.2025.108113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the Anisotropic Self-Organizing Map (ASOM), a novel neural network-based approach for inferring hidden common drivers in nonlinear dynamical systems from observed time series. Grounded in topological theorems, our method integrates time-delay embedding, intrinsic dimension estimation, and a new anisotropic training scheme for Kohonen’s self-organizing map, enabling the precise decomposition of attractor manifolds into autonomous and shared components of the dynamics. We validated ASOM through simulations involving chaotic maps, where two driven systems were influenced by a hidden nonlinear driver. The inferred time series showed a strong correlation with the actual hidden common driver, unlike the observed systems. We further compared our reconstruction performance against several established methods for identifying shared features in time series, including PCA, kernel PCA, ICA, dynamical component analysis, canonical correlation analysis, deep canonical correlation analysis, traditional self-organizing map, and recent recurrence-based approaches. Our results demonstrate ASOM’s superior accuracy and robustness in recovering latent dynamics, providing a powerful tool for unsupervised learning of hidden causal structures in complex systems.},
  archive      = {J_NN},
  author       = {Zsigmond Benkő and Marcell Stippinger and Attila Bencze and Fülöp Bazsó and András Telcs and Zoltán Somogyvári},
  doi          = {10.1016/j.neunet.2025.108113},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108113},
  shortjournal = {Neural Netw.},
  title        = {Inference of hidden common driver dynamics by anisotropic self-organizing neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the theoretical expressive power of graph transformers for solving graph problems. <em>NN</em>, <em>194</em>, 108112. (<a href='https://doi.org/10.1016/j.neunet.2025.108112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformers have become the dominant neural architecture in the fields of natural language processing and computer vision. The generalization of Transformers to graphs, so-called Graph Transformers, have recently emerged as a promising alternative to the successful message passing Graph Neural Networks (MPNNs). While the expressive power of MPNNs has been intensively studied in the past years, that of Graph Transformers is still underexplored. Existing results mostly rely on the employed structural/positional encodings and not on the pure architecture itself. However, gaining an understanding of the strengths and limitations of Graph Transformers would be very useful both for the scientific community and the practitioners. In this paper, we derive a connection between Graph Transformers and the Congested clique , a popular model in distributed computing. This connection allows us to translate theoretical results for different graph problems from the latter to the former. We show that under certain conditions, Graph Transformers with depth 2 are Turing universal. We also show that there exist Graph Transformers that can solve problems which cannot be solved by MPNNs. We empirically investigate whether Graph Transformers and MPNNs with depth 2 can solve graph problems on some molecular datasets. Our results demonstrate that Graph Transformers can generally address the underlying tasks, while MPNNs are incapable of learning any information about the graph.},
  archive      = {J_NN},
  author       = {Giannis Nikolentzos and Dimitrios Kelesis and Michalis Vazirgiannis},
  doi          = {10.1016/j.neunet.2025.108112},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108112},
  shortjournal = {Neural Netw.},
  title        = {On the theoretical expressive power of graph transformers for solving graph problems},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders. <em>NN</em>, <em>194</em>, 108110. (<a href='https://doi.org/10.1016/j.neunet.2025.108110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodevelopmental disorders exhibit highly similar behavioral characteristics in clinical assessments, heavily relying on subjective behavioral reports, leading to insufficient understanding of the neurobiological mechanisms behind inter-patient heterogeneity and symptom overlap between diseases. To address this issue, this study proposes a graph neural network framework that integrates neuroimaging data, focusing on three key problems: Firstly, enhance the nonlinear features in brain neural activity by introducing the Neurodynamics Rössler system. Transform raw static neural signals into simulated signals with nonlinear, temporal, and dynamic features, thereby more accurately reflecting the process of brain neural activity. Secondly, improve feature discrimination by integrating the spatial adjacency characteristics of local brain regions with the topological structure information of the global brain network to highlight key features. Thirdly, improve noise resistance and generalization ability. Introducing adaptive controllers and cross-site adversarial learning mechanisms, the interference of heterogeneous noise is effectively reduced. This study conducted experimental validation on data from neurodevelopmental disorders such as ADHD and ASD. The results indicate that this framework not only has advantages in classification accuracy but also possesses good interpretability, making it a promising tool for imaging biomarker research and auxiliary diagnosis.},
  archive      = {J_NN},
  author       = {Qiulei Han and Hongbiao Ye and Miaoshui Bai and Lili Wang and Yan Sun and Ze Song and Jian Zhao and Lijuan Shi and Zhejun Kuang},
  doi          = {10.1016/j.neunet.2025.108110},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108110},
  shortjournal = {Neural Netw.},
  title        = {MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State-flipped control design for the stabilization of probabilistic boolean control networks. <em>NN</em>, <em>194</em>, 108109. (<a href='https://doi.org/10.1016/j.neunet.2025.108109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilization is a fundamental issue in modern control theory. In the past decades, significant efforts have been invested in deriving necessary and sufficient conditions for verifying the global stabilization of probabilistic Boolean control networks (PBCNs). However, systematic methods and general criteria for exploring the local stabilization and determining the domain of attraction of PBCNs are still lacking in the existing literature. Motivated by this research gap, this paper investigates the local state feedback stabilization of PBCNs, including local finite-time state feedback stabilization with probability one (FTSFS) and local state feedback stabilization in distribution (SFSD). Firstly, a sequence of reachable sets with probability one is constructed, based on which, the largest domain of attraction is derived for the FTSFS of PBCNs by designing the state feedback controllers. Secondly, by constructing a sequence of reachable sets with positive probability, the largest domain of attraction is determined for the SFSD of PBCNs. Finally, when the largest domain of attraction is not the whole state space, the state-flipped control is designed to achieve the global FTSFS or SFSD of PBCNs via the largest domain of attraction.},
  archive      = {J_NN},
  author       = {Xinrong Yang and Haitao Li},
  doi          = {10.1016/j.neunet.2025.108109},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108109},
  shortjournal = {Neural Netw.},
  title        = {State-flipped control design for the stabilization of probabilistic boolean control networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability of large-scale probabilistic boolean networks via network aggregation. <em>NN</em>, <em>194</em>, 108108. (<a href='https://doi.org/10.1016/j.neunet.2025.108108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale probabilistic Boolean networks (LSPBNs) are a modeling tool used to simulate and analyze the dynamics of complex systems with uncertainty. However, due to its high computational complexity, previous research methods cannot be directly applied to study such systems. Inspired by network aggregation, this paper conducts network aggregation on LSPBNs to investigate its global stability with probability 1. It is worth mentioning that the stability conclusion proposed in this article holds for any form of network aggregation. First, the entire network is partitioned and the algebraic expressions for each subnetwork are given through the semi-tensor product of matrices. And then, a set of iterative formulas is constructed to describe and reflect the input-output coordination relationship among the subnetworks, and based on which, a sufficient condition for the global stability of LSPBNs is derived, greatly reducing computational complexity. The feasibilities of the proposed method and results are verified through examples.},
  archive      = {J_NN},
  author       = {Wen Liu and Shihua Fu and Jianjun Wang and Renato De Leone and Jianwei Xia},
  doi          = {10.1016/j.neunet.2025.108108},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108108},
  shortjournal = {Neural Netw.},
  title        = {Stability of large-scale probabilistic boolean networks via network aggregation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPC: Self-supervised point cloud completion. <em>NN</em>, <em>194</em>, 108107. (<a href='https://doi.org/10.1016/j.neunet.2025.108107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape incompleteness is a common issue in point clouds acquired by depth sensors. Point cloud completion aims to restore partial point clouds to their complete form. However, most existing point cloud completion methods rely on complete point clouds or multi-view information of the same object during training, which is not practical for real-world scenarios with high information acquisition costs. To overcome the above limitation, a self-supervised point cloud completion (SPC) method is proposed, which uses the training set consisting of only a single partial point cloud for each object. Specifically, an autoencoder-like network architecture that includes a two-step strategy is developed. First, a compression-reconstruction strategy is proposed to enable the network to learn the representation of complete point clouds from existing knowledge. Then, considering the potential problem of overfitting in self-supervised training, a global enhancement strategy is further designed to maintain the positional coherence of predicted points. Comprehensive experiments are conducted on the ScanNet, MatterPort3D, KITTI, and ShapeNet datasets. On real-world datasets, the unidirectional Chamfer distance (UCD) and the unidirectional Hausdorff distance (UHD) of the method are reduced by an average of 2.3 and 2.4, respectively, compared to the state-of-the-art method. In addition to its excellent completion capabilities, the proposed method has a positive impact on downstream tasks. In point cloud classification, applying the proposed method improves classification accuracy by an average of 14 %. Extensive experimental results demonstrate that the proposed SPC has a high practical value.},
  archive      = {J_NN},
  author       = {Jie Song and Xing Wu and Junfeng Yao and Qi Zhang and Chenhao Shang and Quan Qian and Jun Song},
  doi          = {10.1016/j.neunet.2025.108107},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108107},
  shortjournal = {Neural Netw.},
  title        = {SPC: Self-supervised point cloud completion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition. <em>NN</em>, <em>194</em>, 108106. (<a href='https://doi.org/10.1016/j.neunet.2025.108106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) integrates complementary information from both text and images to identify named entities within text. However, existing methods face three key issues: imbalanced handling of modality noise, the cascading effect of semantic mismatch, and information loss resulting from the lack of text dominance. To address these issues, this paper proposes a M ulti-stage I nteraction N etwork I nspired by G ene E diting for MNER (MINIGE-MNER). The core innovations of this method include: A gene knockout module based on the variational information bottleneck, which removes inferior genes (modality noise) from the text, raw image, and generated image features. This approach retains the superior genes, achieving balanced filtering of modality noise. A determination of gene recombination sites module that maximizes the mutual information between superior genes across modalities, reducing the spatial distance between them and ensuring precise, fine-grained semantic alignment. This helps to prevent the cascading effect of semantic mismatch. A text-guided gene recombination module that implements a “text-dominant, vision-supplementary” cross-modal fusion paradigm. This module dynamically filters out visual noise unrelated to the text while avoiding excessive reliance on visual information that could obscure the unique contextual information of the text, effectively mitigating information loss. Experimental results show that MINIGE-MNER achieves F1 scores of 76.45 % and 88.67 % on the Twitter-2015 and Twitter-2017 datasets, respectively, outperforming existing state-of-the-art methods by 0.83 % and 0.42 %. In addition, this paper presents comprehensive experiments that demonstrate the superiority of MINIGE-MNER and the effectiveness of its individual modules.},
  archive      = {J_NN},
  author       = {Bo Kong and Shengquan Liu and Liruizhi Jia and Yi Liang and Dongfang Han and Xu Zhang},
  doi          = {10.1016/j.neunet.2025.108106},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108106},
  shortjournal = {Neural Netw.},
  title        = {MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deceiving question-answering models: A hybrid word-level adversarial approach. <em>NN</em>, <em>194</em>, 108105. (<a href='https://doi.org/10.1016/j.neunet.2025.108105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning underpins most of the currently advanced natural language processing (NLP) tasks such as textual classification, neural machine translation (NMT), abstractive summarization and question-answering (QA). However, the robustness of the models, particularly QA models, against adversarial attacks is a critical concern that remains insufficiently explored. This paper introduces QA-Attack (Question Answering Attack), a novel word-level adversarial strategy that fools QA models. Our attention-based attack exploits the customized attention mechanism and deletion ranking strategy to identify and target specific words within contextual passages. It creates deceptive inputs by carefully choosing and substituting synonyms, preserving grammatical integrity while misleading the model to produce incorrect responses. Our approach demonstrates versatility across various question types, particularly when dealing with extensive long textual inputs. Extensive experiments on multiple benchmark datasets demonstrate that QA-Attack successfully deceives baseline QA models and surpasses existing adversarial techniques regarding success rate, semantics changes, BLEU score, fluency and grammar error rate.},
  archive      = {J_NN},
  author       = {Jiyao Li and Mingze Ni and Yongshun Gong and Wei Liu},
  doi          = {10.1016/j.neunet.2025.108105},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108105},
  shortjournal = {Neural Netw.},
  title        = {Deceiving question-answering models: A hybrid word-level adversarial approach},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified gradient regularization method for heterogeneous graph neural networks. <em>NN</em>, <em>194</em>, 108104. (<a href='https://doi.org/10.1016/j.neunet.2025.108104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks (HGNNs) are advanced deep learning methods widely applied for learning representations of heterogeneous graphs. However, they face challenges such as over-smoothing and non-robustness. Existing methods can mitigate these issues by applying gradient regularization to one of the three information dimensions: node, edge, or propagation message. However, these methods have problems such as unstable training, difficulty in parameter convergence, and inadequate utilization of heterogeneous information. We propose a novel gradient regularization method called Grug, which iteratively applies regularization to the gradients derived from both node type and message matrix during the message-passing process. A detailed theoretical analysis demonstrates its advantages in Stability and Diversity. Notably, Grug potentially exceeds the theoretical upper bounds set by DropMessage. In addition, Grug offers a unified gradient regularization framework that integrates the existing dropping and adversarial training methods, and provides theoretical guidance for their further optimization in different data and tasks. We validate Grug through extensive experiments on six public datasets, showing significant improvements in performance and effectiveness.},
  archive      = {J_NN},
  author       = {Xiao Yang and Xuejiao Zhao and Zhiqi Shen},
  doi          = {10.1016/j.neunet.2025.108104},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108104},
  shortjournal = {Neural Netw.},
  title        = {A unified gradient regularization method for heterogeneous graph neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-level graph contrastive learning for community value prediction. <em>NN</em>, <em>194</em>, 108103. (<a href='https://doi.org/10.1016/j.neunet.2025.108103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Value Prediction (CVP) is an important emerging task in the field of social commerce, which aims to predict the community values. However, due to the complex structure of communities and individuals, previous graph machine learning methods have struggled to adequately address this task. This study endeavors to bridge this gap by introducing a cross-level graph contrastive learning method called Cross-level Community Contrastive Learning (CCCL) to handle such subgraph-level tasks. Specifically, we generate two views that describe different levels of social connections, the augmented node-level graph and the community-level graph that is produced by graph coarsening. Subsequently, CCCL captures the mutual information between the two views through a cross-view contrastive loss. The learned embeddings utilize community and node information at various levels, making them capable of handling subgraph-level regression problems. To the best of our knowledge, CCCL is the first graph contrastive learning method that addresses the CVP problem. We theoretically show that CCCL maximizes a lower bound of the mutual information shared between node-view and community-view representations. Experimental results demonstrate that our proposed approach is highly effective for the CVP task, outperforming both end-to-end and self-supervised baselines. Furthermore, our model also exhibits robust resistance to edge perturbation attacks.},
  archive      = {J_NN},
  author       = {Wenjie Yang and Shengzhong Zhang and Zengfeng Huang},
  doi          = {10.1016/j.neunet.2025.108103},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108103},
  shortjournal = {Neural Netw.},
  title        = {Cross-level graph contrastive learning for community value prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training. <em>NN</em>, <em>194</em>, 108102. (<a href='https://doi.org/10.1016/j.neunet.2025.108102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation, which aims to provide accurate descriptions of both normal and abnormal regions, has been attracting growing research attention. Recently, despite considerable progress, data-driven deep-learning based models still face challenges in capturing and describing the abnormalities, due to the data bias problem. To address this problem, we propose to generate radiology reports via the Visual-Semantic Ambivalence-Aware Network (VSANet) and the Focal Self-Critical Sequence Training (FSCST). In detail, our VSANet follows the encoder-decoder framework. In the encoder part, we first deploy a multi-grained abnormality extractor and a visual extractor to capture both semantic and visual features from given images, and then introduce a Parameter Shared Dual-way Encoder (PSDwE) to delve into the inter- and intra-relationships among these features. In the decoder part, we propose the Visual-Semantic Ambivalence-Aware (VSA) module to generate the abnormality-aware visual features to mitigate the data bias problem. In implementation, our VSA introduces three sub-modules: Dual-way Attention (DwA), introduced to generate both the word-related visual and semantic features; Dual-way Attention on Attention (DwAoA), designed to mitigate redundant information; Score-based Feature Fusion (SFF), constructed to fuse the visual and semantic features in an ambivalence way. We further introduce the FSCST to enhance the overall performance of our VSANet by allocating more attention toward difficult samples. Experimental results demonstrate that our proposal achieves superior performance on various evaluation metrics. Source code have released at https://github.com/SKD-HPC/VSANet .},
  archive      = {J_NN},
  author       = {Xiulong Yi and You Fu and Enxu Bi and Jianguo Liang and Hao Zhang and Jianzhi Yu and Qianqian Li and Rong Hua and Rui Wang},
  doi          = {10.1016/j.neunet.2025.108102},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108102},
  shortjournal = {Neural Netw.},
  title        = {Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative representation learning via attention-enhanced contrastive learning for short text clustering. <em>NN</em>, <em>194</em>, 108101. (<a href='https://doi.org/10.1016/j.neunet.2025.108101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has gained significant attention in short text clustering, yet it has an inherent drawback of mistakenly identifying samples from the same category as negatives and separating them in the feature space (i.e., the false negative separation problem). To generate discriminative representations for short text clustering, we propose a novel clustering method, called Discriminative Representation learning via A ttention- E nhanced C ontrastive L earning for Short Text Clustering ( AECL ). The AECL consists of two modules which are the contrastive learning module and the pseudo-label assisting module. Both modules utilize a sample-level attention mechanism to extract similarities between samples, based on which cross-sample features are aggregated to form a consistent representation for each sample. The contrastive learning module explores the similarity relationships and the consistent representations to form positive samples, effectively addressing the false negative separation issue, and the pseudo-label assisting module utilizes the consistent representations to produce reliable supervision information to assist the clustering task. Experimental results demonstrate that AECL outperforms state-of-the-art methods. The code is available at https://github.com/YZH0905/AECL-STC .},
  archive      = {J_NN},
  author       = {Zhihao Yao and Bo Li and Yufei Liao},
  doi          = {10.1016/j.neunet.2025.108101},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108101},
  shortjournal = {Neural Netw.},
  title        = {Discriminative representation learning via attention-enhanced contrastive learning for short text clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects. <em>NN</em>, <em>194</em>, 108100. (<a href='https://doi.org/10.1016/j.neunet.2025.108100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fixed-time synchronization (FXTS) and prescribed-time synchronization (PSTS) problems of state-dependent switching neural networks (SDSNNs) with stochastic disturbances and impulsive effects. By leveraging the average impulsive interval, comparison principle, and interval matrix methodology, this study advances a novel analytical framework. Departing from conventional approaches, we reformulate stochastic disturbed and impulsive SDSNNs as interval-parameter systems through rigorous interval matrix transformation. Consequently, we derive some sufficient conditions in the form of linear matrix inequalities (LMIs) to ensure the realization of FXTS and PSTS. Since impulsive effects can potentially compromise synchronization stability, careful controller design becomes critical. To address this challenge, we develop a unified proportional integral (PI) control framework. Through proper adjustment of its control parameters, this framework enables the system to achieve both FXTS and PSTS. Moreover, by reasonably configuring the relationship between the impulsive intensity and the prescribed time, the synchronization performance can be balanced. Finally, we demonstrate the effectiveness of the theoretical results through two examples.},
  archive      = {J_NN},
  author       = {Guici Chen and Houxuan Zhang and Shiping Wen and Junhao Hu and Leimin Wang},
  doi          = {10.1016/j.neunet.2025.108100},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108100},
  shortjournal = {Neural Netw.},
  title        = {Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories. <em>NN</em>, <em>194</em>, 108099. (<a href='https://doi.org/10.1016/j.neunet.2025.108099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of long-tail visual recognition, the imbalance in data distribution leads to a significant performance gap between head and tail classes. Improving the tail-class performance and alleviating the decline in head class are two critical questions. Although many methods have proposed solutions for the former, most of them fall short in the latter. Introducing additional knowledge is a novel view to address the problem, however, how to attain useful knowledge and further transfer the knowledge to the target model is the core. This paper proposes a novel method called Expert Knowledge Distillation for Specific Categories (EKDSC). Firstly, we propose a kind of well-trained teacher model ensuring each expert concentrates on its specialized field while being less affected by other interference. Furthermore, the teacher model including three categories of experts: head, mid, and tail classes, is utilized to distill their specialized knowledge to the student model. Experimental results demonstrate that EKDSC effectively improves the accuracy of tail classes, and mitigates the common decreases of head classes’ performance. Our proposed method achieves a high accuracy, exceeding the current state-of-the-art (SOTA) by 1–5 % on benchmark datasets including the small-scale CIFAR-10 LT and CIFAR-100 LT. Furthermore, it demonstrates outstanding performance on large-scale datasets such as ImageNet-LT, iNaturalist 2018, and Places-LT.},
  archive      = {J_NN},
  author       = {Yaping Bai and Jinghua Li and Dehui Kong and Suqiao Yang and Baocai Yin},
  doi          = {10.1016/j.neunet.2025.108099},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108099},
  shortjournal = {Neural Netw.},
  title        = {EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations. <em>NN</em>, <em>194</em>, 108098. (<a href='https://doi.org/10.1016/j.neunet.2025.108098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal imitation learning enables the agent to learn demonstrations of multiple modes at the same time. However, as expert demonstrations in practice tend to have incomplete labels for behavior modes, most methods are inefficient. To address this issue, an approach capable of imitation learning from incompletely labeled expert demonstrations, referred to as Weakly Supervised Multi-modal Imitation Learning (WSMIL), is proposed. WSMIL incorporates weakly supervised learning into multi-modal imitation learning by adding a behavior mode classifier to the adversarial network, thus forming adversaries among three players (generator, classifier and discriminator). Both labeled and unlabeled data are fully utilized in this adversarial process where fake state-action-label pairs generated by the generator and the classifier try to deceive the discriminator that tries to identify them and limited labeled expert demonstrations. Additionally, in order to ensure the data distribution of classifier and generator individually to converge to the expert’s real distribution, three extra losses are employed, where simulated annealing behavioral cloning is also added to the generator network to improve the generalization of policy. Experiments show that WSMIL accurately distinguishes modes with incomplete modal labels in demonstrations, learns close to the expert standard for each mode, and is more stable than other multi-modal methods.},
  archive      = {J_NN},
  author       = {Sijia Gu and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108098},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108098},
  shortjournal = {Neural Netw.},
  title        = {Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection. <em>NN</em>, <em>194</em>, 108097. (<a href='https://doi.org/10.1016/j.neunet.2025.108097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight salient object detection (SOD) is widely used in various downstream applications due to its low resource requirements and fast inference speed. The use of hybrid encoders offers the potential to achieve a better balance between efficiency and accuracy for SOD task. However, the aggregation of features from convolutional neural networks (CNNs) and transformers remains challenging, and most existing lightweight SOD models rarely explore the efficient aggregation of cross-architecture features derived from hybrid encoders. In this paper, we propose a hybrid aggregation strategy network (HASNet) that balances accuracy and efficiency for lightweight SOD by grouping and aggregating features to leverage salient information across different architectures. Specifically, the features obtained after hybrid encoder processing are divided into convolutional and transformer features for shallow and deep aggregation respectively. Deep aggregation uses the global inverted residual block (GIRB) to facilitate the transfer of salient information encoded within transformer features across various levels. Meanwhile, shallow aggregation uses the lightweight inverted residual block (LIRB) to efficiently integrate the spatial information inherent in convolutional features. The GIRB incorporates an efficient global operation to extract channel semantic information from the high-dimensional transformer features. The LIRB fuses low-level features by efficiently exploiting the spatial information in features at extremely low computational cost. Comprehensive experiments conducted across five datasets demonstrate that our HASNet significantly outperform existing methods in a thorough evaluation encompassing parameter sizes, inference speed, and accuracy. The source code will be publicly available at https://github.com/LitterMa-820/HASNet .},
  archive      = {J_NN},
  author       = {Jianhua Ma and Mingfeng Jiang and Xian Fang and Jiatong Chen and Yaming Wang and Guang Yang},
  doi          = {10.1016/j.neunet.2025.108097},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108097},
  shortjournal = {Neural Netw.},
  title        = {Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing image restoration through learning context-rich and detail-accurate features. <em>NN</em>, <em>194</em>, 108096. (<a href='https://doi.org/10.1016/j.neunet.2025.108096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover high-quality images from their degraded counterparts, necessitating a delicate balance between preserving spatial details and capturing contextual information. Although some methods attempt to address this trade-off, they tend to focus primarily on spatial features while overlooking the importance of understanding frequency variations. Moreover, these approaches commonly utilize skip connections–implemented via addition or concatenation–to fuse encoder and decoder features for improved restoration. However, since encoder features may still carry degradation artifacts, such direct fusion strategies risk introducing implicit noise, ultimately hindering restoration performance. In this paper, we present a multi-scale design that optimally balances these competing objectives, seamlessly integrating spatial and frequency domain knowledge to selectively recover the most informative information. Specifically, we develop a hybrid scale frequency selection block (HSFSBlock), which not only captures multi-scale information from the spatial domain, but also selects the most informative components for image restoration in the frequency domain. Furthermore, to mitigate the inherent noise introduced by skip connections employing only addition or concatenation, we introduce a skip connection attention mechanism (SCAM) to selectively determines the information that should propagate through skip connections. The resulting tightly interlinked architecture, named as LCDNet. Extensive experiments conducted across diverse image restoration tasks showcase that our model attains performance levels that are either superior or comparable to those of state-of-the-art algorithms. The code and the pre-trained models are released at https://github.com/Tombs98/LCDNet .},
  archive      = {J_NN},
  author       = {Hu Gao and Xiaoning Lei and Depeng Dang},
  doi          = {10.1016/j.neunet.2025.108096},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108096},
  shortjournal = {Neural Netw.},
  title        = {Enhancing image restoration through learning context-rich and detail-accurate features},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation. <em>NN</em>, <em>194</em>, 108095. (<a href='https://doi.org/10.1016/j.neunet.2025.108095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) has emerged as a critical paradigm for adapting large pre-trained models to downstream tasks, offering a balance between computational efficiency and model performance. Among these methods, Low-Rank Adaptation (LoRA) has gained significant popularity due to its efficiency; it freezes the pre-trained weights and decomposes the incremental matrices into two trainable low-rank matrices. However, a critical limitation of LoRA lies in its uniform rank assignment across all layers, which fails to account for the heterogeneous importance of different layers in contributing to task performance, potentially resulting in suboptimal adaptation. To address this limitation, we propose Layer-wise Adaptive Low-Rank Adaptation (La-LoRA), a novel approach that dynamically allocates rank to each layer based on Dynamic Contribution-Driven Parameter Budget (DCDPB) and Truncated Norm Weighted Dynamic Rank Allocation (TNW-DRA) during training. By treating each layer as an independent unit and progressively adjusting its rank allocation, La-LoRA ensures optimal model performance while maintaining computational efficiency and adapting to the complexity of diverse tasks. We conducted extensive experiments across multiple tasks and models to evaluate the effectiveness of La-LoRA. The results demonstrate that La-LoRA consistently outperforms existing benchmarks, validating its effectiveness in diverse scenarios.},
  archive      = {J_NN},
  author       = {Jiancheng Gu and Jiabin Yuan and Jiyuan Cai and Xianfa Zhou and Lili Fan},
  doi          = {10.1016/j.neunet.2025.108095},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108095},
  shortjournal = {Neural Netw.},
  title        = {La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-level dynamic heterogeneous graph network for video question answering. <em>NN</em>, <em>194</em>, 108094. (<a href='https://doi.org/10.1016/j.neunet.2025.108094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Video Question Answering (VideoQA) has garnered considerable research interest as a pivotal task within the realm of vision-language understanding. However, existing Video Question Answering datasets often lack sufficient entity and event information. Thus, the Vision Language Models (VLMs) struggle to complete intricate grounding and reasoning among multi-modal entities or events and heavily rely on language short-cut or irrelevant visual context. To address these challenges, we make improvements from both data and model perspectives. In terms of VideoQA data, we focus on supplementing the missing specific entities and events with the proposed event and entity augmentation strategies. Based on the augmented data, we propose a Dual-Level Dynamic Heterogeneous Graph Network (DDHG) for Video Question Answering. DDHG incorporates transformer layers to capture the dynamic temporal-spatial changes of visual entities. Then, DDHG establishes multi-modal semantic grounding ability between vision and text with entity-level and event-level heterogeneous graphs. Finally, the Dual-level Cross-modal Interaction Module integrates the dual-level features to predict correct answers. Our method not only significantly outperforms existing VideoQA models on two complex event-based benchmark datasets (Causal-VidQA and NExT-QA) but also demonstrates superior event content prediction ability over several state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Zefan Zhang and Yanhui Li and Weiqi Zhang and Tian Bai},
  doi          = {10.1016/j.neunet.2025.108094},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108094},
  shortjournal = {Neural Netw.},
  title        = {Dual-level dynamic heterogeneous graph network for video question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction. <em>NN</em>, <em>194</em>, 108093. (<a href='https://doi.org/10.1016/j.neunet.2025.108093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction plays a crucial role in drug discovery and repurposing by efficiently and accurately identifying potential therapeutic targets. Existing methods face challenges in capturing high-order semantic relationships in heterogeneous graphs and effectively integrating multi-meta-path information while also suffering from low computational efficiency. To address these challenges, a pre-computation-style hierarchical meta-path learning framework named HMT-DTI is proposed. HMT-DTI can effectively capture rich semantic information about drugs and targets while ensuring high computational efficiency. Specifically, during the pre-collection stage, HMT-DTI employs a Transformer-based message passing mechanism to evaluate neighbors’ importance and adaptively collect meta-path information. The incorporation of even-relation propagation reduces redundant iterations and improves efficiency. During training, HMT-DTI adopts a hierarchical knowledge extraction strategy to evaluate the importance of multi-hop neighbors and different meta-path patterns, capturing fine-grained semantic representations of drugs and targets. HMT-DTI is evaluated on three heterogeneous biological datasets and compared with several state-of-the-art methods. The results demonstrate the superiority of HMT-DTI in DTI prediction.},
  archive      = {J_NN},
  author       = {Dianlei Gao and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108093},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108093},
  shortjournal = {Neural Netw.},
  title        = {HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis. <em>NN</em>, <em>194</em>, 108091. (<a href='https://doi.org/10.1016/j.neunet.2025.108091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal neuroimaging techniques are widely employed for the accurate diagnosis of Alzheimer’s Disease (AD). Existing fusion methods typically focus on capturing semantic correlations between modalities through feature-level interactions. However, they fail to suppress redundant cross-modal information, resulting in sub-optimal multi-modal representation. Moreover, these methods ignore subject-specific differences in modality contributions. To address these challenges, we propose a novel Multi-modal Orthogonal Fusion Network via cross-layer guidance (MOFNet) to effectively fuse multi-modal information for AD diagnosis. We first design a Cross-layer Guidance Interaction module (CGI), leveraging high-level features to guide the learning of low-level features, thereby enhancing the fine-grained representations on disease-relevant regions. Then, we introduce a Multi-modal Orthogonal Compensation module (MOC) to realize bidirectional interaction between modalities. MOC encourages each modality to compensate for its limitations by learning orthogonal components from other modalities. Finally, a Feature Enhancement Fusion module (FEF) is developed to adaptively fuse multi-modal features based on the contributions of different modalities. Extensive experiments on the ADNI dataset demonstrate that MOFNet achieves superior performance in AD classification tasks.},
  archive      = {J_NN},
  author       = {Yumiao Zhao and Bo Jiang and Yuan Chen and Ye Luo and Jin Tang},
  doi          = {10.1016/j.neunet.2025.108091},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108091},
  shortjournal = {Neural Netw.},
  title        = {Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ClickAttention: Click region similarity guided interactive segmentation. <em>NN</em>, <em>194</em>, 108090. (<a href='https://doi.org/10.1016/j.neunet.2025.108090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive segmentation algorithms based on click points have attracted significant attention from researchers in recent years. However, most existing methods rely on sparse click maps as model inputs to segment specific target objects. These clicks primarily affect local regions, limiting the model’s ability to focus on the entire target object and often resulting in a higher number of required clicks. Additionally, many current algorithms struggle to balance performance and efficiency effectively. To address these challenges, we propose a click attention algorithm that expands the influence of positive clicks by leveraging the similarity between positively-clicked regions and the entire input. We further introduce a discriminative affinity loss to reduce attention coupling between positive and negative click regions, minimizing accuracy degradation caused by mutual interference. On the DAVIS dataset, our method achieves a 2 % performance gain (NoC@90) over the state-of-the-art SimpleClick-ViT-L, while using only 15.6 % of its parameters. Extensive experiments demonstrate that our approach outperforms existing methods and achieves state-of-the-art performance with fewer parameters. Data and code are published.},
  archive      = {J_NN},
  author       = {Long Xu and Yongquan Chen and Shanghong Li and Junkang Chen and Ziyuan Tang},
  doi          = {10.1016/j.neunet.2025.108090},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108090},
  shortjournal = {Neural Netw.},
  title        = {ClickAttention: Click region similarity guided interactive segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language model for multitask classification of memes. <em>NN</em>, <em>194</em>, 108089. (<a href='https://doi.org/10.1016/j.neunet.2025.108089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of social media and online memes has led to an increasing demand for automated systems that can analyse and classify multimodal data, particularly in online forums. Memes blend text and graphics to express complicated ideas, sometimes containing emotions, satire, or inappropriate material. Memes often represent cultural prejudices such as objectification, sexism, and bigotry, making it difficult for artificial intelligence to classify these components. Our solution is the vision-language model ViT-BERT CAMT (cross-attention multitask), which is intended for multitask meme categorization. Our model uses a linear self-attentive fusion mechanism to combine vision transformer (ViT) features for image analysis and bidirectional encoder representations from transformers (BERT) for text interpretation. In this way, we can see how text and images relate to space and meaning. We tested the ViT-BERT CAMT on two difficult datasets: the SemEval 2020 Memotion dataset, which contains a multilabel classification of sentiment, sarcasm, and offensiveness in memes, and the MIMIC dataset, which focuses on detecting sexism, objectification, and prejudice. The findings show that the ViT-BERT CAMT achieves good accuracy on both datasets and outperforms many current baselines in multitask settings. These results highlight the importance of combined image-text modelling for correctly deciphering nuanced meanings in memes, particularly when spotting abusive and discriminatory content. By improving multimodal categorization algorithms, this study helps better monitor and comprehend online conversation.},
  archive      = {J_NN},
  author       = {Md. Mithun Hossain and Md. Shakil Hossain and M.F. Mridha and Nilanjan Dey},
  doi          = {10.1016/j.neunet.2025.108089},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108089},
  shortjournal = {Neural Netw.},
  title        = {A vision-language model for multitask classification of memes},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view learning meets state-space model: A dynamical system perspective. <em>NN</em>, <em>194</em>, 108088. (<a href='https://doi.org/10.1016/j.neunet.2025.108088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning exploits the complementary nature of multiple modalities to enhance performance across diverse tasks. While deep learning has significantly advanced these fields by enabling sophisticated modeling of intra-view and cross-view interactions, many existing approaches still rely on heuristic architectures and lack a principled framework to capture the dynamic evolution of feature representations. This limitation hampers interpretability and theoretical understanding. To address these challenges, this paper introduces the Multi-view State-Space Model (MvSSM), which formulates multi-view representation learning as a continuous-time dynamical system inspired by control theory. In this framework, view-specific features are treated as external inputs, and a shared latent representation evolves as the internal system state, driven by learnable dynamics. This formulation unifies feature integration and label prediction within a single interpretable model, enabling theoretical analysis of system stability and representational transitions. Two variants, MvSSM-Lap and MvSSM-iLap, are further developed using Laplace and inverse Laplace transformations to derive system dynamics representations. These solutions exhibit structural similarities to graph convolution operations in deep networks, supporting efficient feature propagation and theoretical interpretability. Experiments on benchmark datasets such as IAPR-TC12, and ESP demonstrate the effectiveness of the proposed method, achieving up to 4.31 % improvement in accuracy and 4.27 % in F1-score over existing state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Weibin Chen and Ying Zou and Zhiyong Xu and Li Xu and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108088},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108088},
  shortjournal = {Neural Netw.},
  title        = {Multi-view learning meets state-space model: A dynamical system perspective},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph convolutional network with adaptive grouping aggregation strategy. <em>NN</em>, <em>194</em>, 108086. (<a href='https://doi.org/10.1016/j.neunet.2025.108086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph convolutional networks (GCNs) with naive aggregation functions on nodes has reached the bottleneck, rendering a gap between practice and theoretical expressity. Some learning-based aggregation strategies have been proposed to improve the performance. However, few of them focus on how these strategies affect the expressity and evaluate their performance in an equal experimental setting. In this paper, we point out that the generated features lack discrimination because naive aggregation functions cannot retain sufficient node information, largely leading to the performance gap. Accordingly, a novel Adaptive Grouping Aggregation (AGA) strategy is proposed to remedy this drawback. Inspired by the label histogram in the Weisfeiler-Lehman (WL) Test, this strategy assigns each node to a unique group to retain more node information, which is proven to have a strictly more powerful expressity. In this work setting, the nodes are grouped according to a modified Student’s t-Distribution between node features and a set of learnable group labels, where the Gumbel Softmax is employed to implement this strategy in an end-to-end trainable pipeline. As a result, such a design can generate more discriminative features and offer a plug-in module in most architectures. Extensive experiments have been conducted on several benchmarks to compare our method with other aggregation strategies. The proposed method improves the performance in all control groups of all benchmarks and achieves the best result in most cases. Additional ablation studies and comparisons with state-of-the-art methods on the large-scale benchmark also indicate the superiority of our method.},
  archive      = {J_NN},
  author       = {Ruixiang Wang and Chunxia Zhang and Chunhong Pan},
  doi          = {10.1016/j.neunet.2025.108086},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108086},
  shortjournal = {Neural Netw.},
  title        = {Graph convolutional network with adaptive grouping aggregation strategy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive behavior with stable synapses. <em>NN</em>, <em>194</em>, 108082. (<a href='https://doi.org/10.1016/j.neunet.2025.108082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral changes in animals and humans, triggered by errors or verbal instructions, can occur extremely rapidly. While learning theories typically attribute improvements in performance to synaptic plasticity, recent findings suggest that such fast adaptations may instead result from dynamic reconfiguration of the networks involved without changes to synaptic weights. Recently, similar capabilities have been observed in transformers, foundational architecture in machine learning widely used in applications such as natural language and image processing. Transformers are capable of in-context learning, the ability to adapt and acquire new information dynamically within the context of the task or environment they are currently engaged in, without changing their parameters. We argue that this property may stem from gain modulation–a feature widely observed in biological networks, such as pyramidal neurons through input segregation and dendritic amplification. We propose a constructive approach to induce in-context learning in an architecture composed of recurrent networks with gain modulation, demonstrating abilities inaccessible to standard networks. In particular, we show that, such architecture can dynamically implement standard gradient-based by encoding weight changes in the activity of another network. We argue that, while these algorithms are traditionally associated with synaptic plasticity, their reliance on non-local terms suggests that they may be more naturally realized in the brain at the level of neural circuits. We demonstrate that we can extend our approach to temporal tasks and reinforcement learning. We further validate our approach in a MuJoCo ant navigation task, showcasing a neuromorphic control paradigm via real-time network reconfiguration.},
  archive      = {J_NN},
  author       = {Cristiano Capone and Luca Falorsi},
  doi          = {10.1016/j.neunet.2025.108082},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108082},
  shortjournal = {Neural Netw.},
  title        = {Adaptive behavior with stable synapses},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disentangled self-supervised video camouflaged object detection and salient object detection. <em>NN</em>, <em>194</em>, 108077. (<a href='https://doi.org/10.1016/j.neunet.2025.108077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video tasks play an important role in multimedia fields. In various video tasks, such as video camouflaged/salient object detection (VCOD/VSOD), motion and context information are two important aspects. Despite the fact that many existing works have already achieved promising results in VCOD and VSOD tasks, they still have limitations when it comes to leveraging motion and context information. In this paper, we propose a new disentangled perspective to treat motion and context information in VCOD and VSOD tasks. Our proposed model can respectively utilize context and motion information in ContextNet and MotionNet, without conflicting with each other as there can be biases between these two types of information in certain circumstances. Moreover, we further explore how to apply disentangled perspective in the self-supervised manner, which can reduce annotation costs. Specifically, we first design a self-supervised adaptive frame routing mechanism to determine whether each video frame belongs to ContextNet or MotionNet. Then we design a cross-supervision for ContextNet and MotionNet to train these two segmentation networks in self-supervised mechanism. In experiments, our proposed self-supervised disentangled model consistently outperforms state-of-the-art unsupervised methods on VCOD and VSOD datasets.},
  archive      = {J_NN},
  author       = {Haoke Xiao and Lv Tang and Bo Li and Zhiming Luo and Shaozi Li},
  doi          = {10.1016/j.neunet.2025.108077},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108077},
  shortjournal = {Neural Netw.},
  title        = {Disentangled self-supervised video camouflaged object detection and salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WPDA: Frequency-based backdoor attack with wavelet packet decomposition. <em>NN</em>, <em>194</em>, 108074. (<a href='https://doi.org/10.1016/j.neunet.2025.108074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores backdoor attack, which is an emerging security threat against deep neural networks (DNNs). The adversary aims to inject a backdoor into the model by manipulating a portion of training samples, such that the backdoor could be activated by a particular trigger to make a target prediction at inference. Currently, existing backdoor attacks often require moderate or high poisoning ratios to achieve the desired attack performance, but making them susceptible to some advanced backdoor defenses ( e . g . , poisoned sample detection). One possible solution to this dilemma is enhancing the attack performance at low poisoning ratios, which has been rarely studied due to its high challenge. To achieve this goal, we propose an innovative frequency-based backdoor attack via wavelet packet decomposition (WPD), which could finely decompose the original image into multiple sub-spectrograms with semantic information. It facilitates us to accurately identify the most critical frequency regions to effectively insert the trigger into the victim image, such that the trigger information could be sufficiently learned to form the backdoor. The proposed attack stands out for its exceptional effectiveness, stealthiness, and resistance at an extremely low poisoning ratio. Notably, it achieves the 98.12 % attack success rate on CIFAR-10 with an extremely low poisoning ratio of 0.004 % ( i.e. , only 2 poisoned samples among 50,000 training samples), and bypasses several advanced backdoor defenses. Besides, we provide more extensive experiments to demonstrate the efficacy of the proposed method, as well as in-depth analyses to explain its underlying mechanism.},
  archive      = {J_NN},
  author       = {Zhengyao Song and Yongqiang Li and Danni Yuan and Li Liu and Shaokui Wei and Baoyuan Wu},
  doi          = {10.1016/j.neunet.2025.108074},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108074},
  shortjournal = {Neural Netw.},
  title        = {WPDA: Frequency-based backdoor attack with wavelet packet decomposition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts. <em>NN</em>, <em>194</em>, 108064. (<a href='https://doi.org/10.1016/j.neunet.2025.108064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are gaining popularity for processing graph data. In real-world scenarios, graph data within the same dataset can vary significantly in scale. This variability leads to depth-sensitivity, where the optimal depth of GNN layers depends on the scale of the graph data. Empirically, fewer layers are sufficient for message passing in smaller graphs, while larger graphs typically require deeper networks to capture long-range dependencies and global features. However, existing methods generally use a fixed number of GNN layers to generate representations for all graphs, overlooking the depth-sensitivity issue in graph data. To address this challenge, we propose the depth adaptive mixture of expert (DA-MoE) method, which incorporates two main improvements to GNN backbone: 1) DA-MoE employs different GNN layers, each considered an expert with its own parameters. Such a design allows the model to flexibly aggregate information at different scales, effectively addressing the depth-sensitivity issue in graph data. 2) DA-MoE utilizes GNN to capture the structural information instead of the linear projections in the gating network. Thus, the gating network enables the model to capture complex patterns and dependencies within the data. By leveraging these improvements, each expert in DA-MoE specifically learns distinct graph patterns at different scales. Furthermore, comprehensive experiments on the TU dataset and open graph benchmark (OGB) have shown that DA-MoE consistently surpasses existing baselines on various tasks, including graph, node, and link-level analyses. The code are available at https://github.com/Celin-Yao/DA-MoE .},
  archive      = {J_NN},
  author       = {Zelin Yao and Mukun Chen and Chuang Liu and Xianke Meng and Yibing Zhan and Jia Wu and Shirui Pan and Huiting Xu and Wenbin Hu},
  doi          = {10.1016/j.neunet.2025.108064},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108064},
  shortjournal = {Neural Netw.},
  title        = {DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph representation learning with disentangled information bottleneck. <em>NN</em>, <em>194</em>, 108056. (<a href='https://doi.org/10.1016/j.neunet.2025.108056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning recently garnered enormous research attention. Despite the notable successes of existing methods, they usually characterize dynamic graphs as a perceptual whole and learn dynamic graph representations within an entangled feature space, which overlook different temporal dependencies inherent in the data. Specifically, the evolution of dynamic graphs is usually decided by a dichotomy in properties: time-invariant properties and time-varying properties. Existing holistic works fail to distinguish these temporal properties and may suffer suboptimal performance in downstream tasks. To tackle this problem, we propose to learn macro-disentangled dynamic graph representations based on the Information Bottleneck theory, leading to a novel dynamic graph representation learning method, Disentangled Dynamic Graph Information Bottleneck (DDGIB). Our DDGIB explicitly embeds the dynamic graphs into a time-invariant representation space and a time-varying representation space. The time-invariant representation space encapsulates stable properties across the temporal span of dynamic graphs, whereas the time-varying representation space encapsulates time-fluctuating properties. The macro disentanglement on the temporal dependencies facilitates the representations’ performance on downstream tasks. Furthermore, we theoretically prove the sufficiency and macro disentanglement of DDGIB. The sufficiency demonstrates that DDGIB can achieve sufficient representations for any possible downstream tasks, while the macro disentanglement certifies that DDGIB can embed the different temporal properties into their corresponding temporal representation space. Extensive experimental results on various datasets and downstream tasks demonstrate the superiority of our method.},
  archive      = {J_NN},
  author       = {Jihong Wang and Yuxin Bai and Chunqiang Zhu and Hao Qian and Ziqi Liu and Minnan Luo},
  doi          = {10.1016/j.neunet.2025.108056},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108056},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph representation learning with disentangled information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning. <em>NN</em>, <em>194</em>, 108023. (<a href='https://doi.org/10.1016/j.neunet.2025.108023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral diversity emerges as a crucial factor for achieving effective collaboration in Multi-Agent Reinforcement Learning (MARL). Current methods often use partial parameter sharing, such as sharing the same representation layer, to balance behavioral diversity and algorithmic scalability. However, this approach ignores that different agents need different decision knowledge, causing training conflicts and knowledge redundancy. To solve these, we propose Tailoring Knowledge for Empowered Cooperative Actions in Multi-Agent Reinforcement Learning (TKCA). Specially, we employ a set of Knowledge Encoders to encode different environment types of knowledge and utilize a Knowledge Selector network to assist each agent in decision-making by selecting the corresponding knowledge. We evaluated TKCA in challenging StarCraftII micromanagement games and Google Research Football games, and the results demonstrate the superior performance of TKCA.},
  archive      = {J_NN},
  author       = {Hu Fu and Yihua Tan and Hao Chen and Pengyi Li},
  doi          = {10.1016/j.neunet.2025.108023},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108023},
  shortjournal = {Neural Netw.},
  title        = {Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="orl">ORL - 1</h2>
<ul>
<li><details>
<summary>
(2026). Monotone convergence of spreading processes on networks. <em>ORL</em>, <em>64</em>, 107363. (<a href='https://doi.org/10.1016/j.orl.2025.107363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the Bass and SI models for the spreading of innovations and epidemics, respectively, on homogeneous complete networks, on one-dimensional networks, and on heterogeneous two-groups complete networks. We allow the network parameters to be time dependent, which is a prerequisite for the analysis of optimal promotional strategies on networks. Using a novel top-down analysis of the master equations, we present a simple proof for the monotone convergence of these models to their respective infinite-population limits. This leads to explicit expressions for the expected adoption or infection level in the Bass and SI models with time-dependent parameters on infinite homogeneous complete and circular networks, and on heterogeneous two-groups complete networks.},
  archive      = {J_ORL},
  author       = {Gadi Fibich and Amit Golan and Steven Schochet},
  doi          = {10.1016/j.orl.2025.107363},
  journal      = {Operations Research Letters},
  month        = {1},
  pages        = {107363},
  shortjournal = {Oper. Res. Lett.},
  title        = {Monotone convergence of spreading processes on networks},
  volume       = {64},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="parco">PARCO - 5</h2>
<ul>
<li><details>
<summary>
(2025). Software acceleration of multi-user MIMO uplink detection on GPU. <em>PARCO</em>, <em>125</em>, 103150. (<a href='https://doi.org/10.1016/j.parco.2025.103150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the exploration of GPU-accelerated block-wise decompositions for zero-forcing (ZF) based QR and Cholesky methods applied to massive multiple-input multiple-output (MIMO) uplink detection algorithms. Three algorithms are evaluated: ZF with block Cholesky decomposition, ZF with block QR decomposition (QRD), and minimum mean square error (MMSE) with block Cholesky decomposition. The latter was the only one previously explored, but it used standard Cholesky decomposition. Our approach achieves an 11% improvement over the previous GPU-accelerated MMSE study. Through performance analysis, we observe a trade-off between precision and execution time. Reducing precision from FP64 to FP32 improves execution time but increases bit error rate (BER), with ZF-based QRD reducing execution time from 2 . 04 μ s to 1 . 24 μ s for a 128 × 8 MIMO size. The study also highlights that larger MIMO sizes, particularly 2048 × 32, require GPUs to fully utilize their computational and memory capabilities, especially under FP64 precision. In contrast, smaller matrices are compute-bound. Our results recommend GPUs for larger MIMO sizes, as they offer the parallelism and memory resources necessary to efficiently handle the computational demands of next-generation networks. This work paves the way for scalable, GPU-based massive MIMO uplink detection systems.},
  archive      = {J_PARCO},
  author       = {Ali Nada and Hazem Ismail Ali and Liang Liu and Yousra Alkabani},
  doi          = {10.1016/j.parco.2025.103150},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103150},
  shortjournal = {Parallel Comput.},
  title        = {Software acceleration of multi-user MIMO uplink detection on GPU},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enable cross-iteration parallelism for PIM-based graph processing with vertex-level synchronization. <em>PARCO</em>, <em>125</em>, 103149. (<a href='https://doi.org/10.1016/j.parco.2025.103149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing-in-memory (PIM) architectures have emerged as a promising solution for accelerating graph processing by enabling computation in memory and minimizing data movement. However, most existing PIM-based graph processing systems rely on the Bulk Synchronous Parallel (BSP) model, which frequently enforces global barriers that limit cross-iteration computational parallelism and introduce significant synchronization and communication overheads. To address these limitations, we propose the Cross Iteration Parallel (CIP) model, a novel vertex-level synchronization approach that eliminates global barriers by independently tracking the synchronization states of vertices. The CIP model enables concurrent execution across iterations, enhancing computational parallelism, overlapping communication and computation, improving core utilization, and increasing resilience to workload imbalance. We implement the CIP model in a PIM-based graph processing system, GraphDF, which features a few specially designed function units to support vertex-level synchronization. Evaluated on a PyMTL3-based cycle-accurate simulator using four real-world graphs and four graph algorithms, CIP running on GraphDF achieves an average speedup of 1.8 × and a maximum of 2.3 × compared to Dalorex, the state-of-the-art PIM-based graph processing system.},
  archive      = {J_PARCO},
  author       = {Xiang Zhao and Haitao Du and Yi Kang},
  doi          = {10.1016/j.parco.2025.103149},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103149},
  shortjournal = {Parallel Comput.},
  title        = {Enable cross-iteration parallelism for PIM-based graph processing with vertex-level synchronization},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-workflow fault-tolerance scheduling strategy considering resources supply delay in WaaS platforms. <em>PARCO</em>, <em>125</em>, 103148. (<a href='https://doi.org/10.1016/j.parco.2025.103148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workflow as a Service (WaaS) platforms rent virtual machines (VMs) from IaaS providers to run scientific workflows for users. However, current researches on workflow scheduling in WaaS platforms did not consider the possibility of VMs downtime leading to task failures or the resources (such as VMs and containers) supply delay affecting scheduling efficiency. To address this issue, this paper proposes a multi-workflow fault-tolerance scheduling strategy for WaaS platforms. Firstly, since WaaS platforms do not manage hardware directly but schedule workflows at the level of VMs and containers, we establish a workflow scheduling model suitable for WaaS platforms, taking into account the impact of resources supply delay on workflow scheduling. Secondly, we propose a multi-workflow fault-tolerance scheduling strategy for WaaS platforms, which includes preprocessing, fault-tolerance selection, task assignment, and resource adjustment. It involves an improved deadline division algorithm to determine the scheduling order, a fault-tolerance selection algorithm combining two fault-tolerance strategies (replication and re-submission), task assignment algorithm considering task attributes and resource supply delay to schedule tasks, and a resource adjustment algorithm to pre-deploy resources for upcoming tasks. Finally, we compare the proposed scheduling strategy with three other algorithms, and the results also demonstrate its effectiveness.},
  archive      = {J_PARCO},
  author       = {Hui Zhao and Wentao Zhi and Xiaoqin Lu and Jing Wang and Nan Luo and Bo Wan and Quan Wang},
  doi          = {10.1016/j.parco.2025.103148},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103148},
  shortjournal = {Parallel Comput.},
  title        = {Multi-workflow fault-tolerance scheduling strategy considering resources supply delay in WaaS platforms},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALBBA: An efficient ALgebraic bypass BFS algorithm on long vector architectures. <em>PARCO</em>, <em>125</em>, 103147. (<a href='https://doi.org/10.1016/j.parco.2025.103147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breadth First Search (BFS) is a fundamental algorithm in scientific computing, databases, and network analysis applications. In the algebraic BFS paradigm, each BFS iteration is expressed as a sparse matrix–vector multiplication, allowing BFS to be accelerated and analyzed through well-established linear algebra primitives. Although much effort has been made to optimize algebraic BFS on parallel platforms such as CPUs, GPUs, and distributed memory systems, vector architectures that exploit Single Instruction Multiple Data (SIMD) parallelism, particularly with their high performance on sparse workloads, remain relatively underexplored for BFS. In this paper, we propose the ALgebraic Bypass BFS Algorithm (ALBBA), a novel and efficient algebraic BFS implementation optimized for long vector architectures. ALBBA utilizes a customized variant of the SELL- C - σ data structure to fully exploit the SIMD capabilities. By integrating a vectorization-friendly search method alongside a two-level bypass strategy, we enhance both sparse matrix-sparse vector multiplication (SpMSpV) and sparse matrix-dense vector multiplication (SpMV) algorithms, which are crucial for algebraic BFS operations. We further incorporate merge primitives and adopt an efficient selection method for each BFS iteration. Our experiments on an NEC VE20B processor demonstrate that ALBBA achieves average speedups of 3.91 × , 2.88 × , and 1.46 × over Enterprise, GraphBLAST, and Gunrock running on an NVIDIA H100 GPU, respectively.},
  archive      = {J_PARCO},
  author       = {Yuyao Niu and Marc Casas},
  doi          = {10.1016/j.parco.2025.103147},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103147},
  shortjournal = {Parallel Comput.},
  title        = {ALBBA: An efficient ALgebraic bypass BFS algorithm on long vector architectures},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using java to create and analyze models of parallel computing systems. <em>PARCO</em>, <em>125</em>, 103146. (<a href='https://doi.org/10.1016/j.parco.2025.103146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the study is to develop optimal solutions for models of parallel computing systems using the Java language. During the study, programs were written for the examined models of parallel computing systems. The result of the parallel sorting code is the output of a sorted array of random numbers. When processing data in parallel, the time spent on processing and the first elements of the list of squared numbers are displayed. When processing requests asynchronously, processing completion messages are displayed for each task with a slight delay. The main results include the development of optimization methods for algorithms and processes, such as the division of tasks into subtasks, the use of non-blocking algorithms, effective memory management, and load balancing, as well as the construction of diagrams and comparison of these methods by characteristics, including descriptions, implementation examples, and advantages. In addition, various specialized libraries were analyzed to improve the performance and scalability of the models. The results of the work performed showed a substantial improvement in response time, bandwidth, and resource efficiency in parallel computing systems. Scalability and load analysis assessments were conducted, demonstrating how the system responds to an increase in data volume or the number of threads. Profiling tools were used to analyze performance in detail and identify bottlenecks in models, which improved the architecture and implementation of parallel computing systems. The obtained results emphasize the importance of choosing the right methods and tools for optimizing parallel computing systems, which can substantially improve their performance and efficiency.},
  archive      = {J_PARCO},
  author       = {Harish Padmanaban and Nurkasym Arkabaev and Maher Ali Rusho and Vladyslav Kozub and Yurii Kozub},
  doi          = {10.1016/j.parco.2025.103146},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103146},
  shortjournal = {Parallel Comput.},
  title        = {Using java to create and analyze models of parallel computing systems},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="pr">PR - 123</h2>
<ul>
<li><details>
<summary>
(2026). Cooperative multi-task learning and reliability assessment for glioma segmentation and IDH genotyping. <em>PR</em>, <em>172</em>, 112467. (<a href='https://doi.org/10.1016/j.patcog.2025.112467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high heterogeneity of gliomas presents significant challenges in distinguishing isocitrate dehydrogenase (IDH) genotypes based on magnetic resonance imaging (MRI) features. To address this issue, we propose a joint optimization framework based on multi-task learning (MLNet), which enables the simultaneous optimization of glioma segmentation and IDH genotype prediction within a unified framework. First, we design a glioma segmentation network based on a CNN-Transformer hybrid architecture to extract glioma features. Second, feature fusion is employed to provide feature support for the IDH genotyping task. A reliability assessment mechanism is introduced to evaluate the IDH genotyping results, determining whether a secondary assessment is necessary. Finally, we construct a multi-task learning loss function and achieve end-to-end joint training through feature sharing across tasks. We evaluate the proposed method on the BraTs2020 dataset, and comparisons with state-of-the-art methods demonstrate that the multi-task learning method offers superior performance.},
  archive      = {J_PR},
  author       = {Meng Li and Du Jiang and Juntong Yun and Rong Liu and Ying Sun and Gongfa Li},
  doi          = {10.1016/j.patcog.2025.112467},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112467},
  shortjournal = {Pattern Recognition},
  title        = {Cooperative multi-task learning and reliability assessment for glioma segmentation and IDH genotyping},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “Efficient multi-view discrete co-clustering with learned graph” [Pattern recognition 168 (2025) 111811]. <em>PR</em>, <em>172</em>, 112453. (<a href='https://doi.org/10.1016/j.patcog.2025.112453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PR},
  author       = {Jiaqi Nie and Qianyao Qiang and Jason Chen Zhang and Fei Hao},
  doi          = {10.1016/j.patcog.2025.112453},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112453},
  shortjournal = {Pattern Recognition},
  title        = {Corrigendum to “Efficient multi-view discrete co-clustering with learned graph” [Pattern recognition 168 (2025) 111811]},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LayerCLIP: A fine-grained class activation map for weakly supervised semantic segmentation. <em>PR</em>, <em>172</em>, 112452. (<a href='https://doi.org/10.1016/j.patcog.2025.112452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation (WSSS) using image-level labels aims to create pseudo-labels leveraging Class Activation Maps (CAM) to train a separate segmentation model. Recent methods that utilize Contrastive Language-Image Pre-training (CLIP) models have achieved significant advancements. These approaches take advantage of CLIP’s capability to identify various categories without requiring additional training. However, due to the limited local information of the final embedding layer, the CAM generated by the CLIP model is still a rough region with an under-activated or over-activated issue. Furthermore, the abundant multi-layer information of CLIP, which plays a vital role in dense prediction, has been ignored. In this paper, we proposed a LayerCLIP model for a fine-grained CAM generation via hierarchical features, which consists of two consecutive components: a dynamic hierarchical CAMs module and an adaptive affinity module. Specifically, the dynamic hierarchical CAMs module utilizes the hierarchical features to produce two complementary CAMs, along with a dynamic strategy to fuse these CAMs. Subsequently, the affinity based on multi-head self-attention is adaptively reweighted to refine CAM by the CAM itself in the adaptive affinity module. LayerCLIP significantly enhances the quality of CAM. Our method achieves a new state-of-the-art performance on PASCAL VOC 2012 (75.1 % mIoU) and MS COCO 2014 (46.9 % mIoU) through extensive benchmark experiments.},
  archive      = {J_PR},
  author       = {Lingma Sun and Le Zou and Xianghu Lv and Zhize Wu and Xiaofeng Wang},
  doi          = {10.1016/j.patcog.2025.112452},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112452},
  shortjournal = {Pattern Recognition},
  title        = {LayerCLIP: A fine-grained class activation map for weakly supervised semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-frequency shared-feature-learning based diffusion model for removing surgical smoke. <em>PR</em>, <em>172</em>, 112447. (<a href='https://doi.org/10.1016/j.patcog.2025.112447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical smoke in laparoscopic surgery can deteriorate visibility for surgeons. This work aims to simultaneously remove the surgical smoke and restore true-to-life image colors with deep learning. However, deep learning-based smoke removal remains a challenge due to: 1) the non-homogeneous distribution of surgical smoke, 2) higher frequency modes being hindered from being learned due to spectral bias. In this work, we propose the multi-frequency shared-feature-learning based conditional diffusion model with adaptive smoke attention for removing surgical smoke. The proposed model learns to map both the smoky and smokeless images into a shared inherent feature by the forward learning and synthesize the smokeless image by the reverse learning, and the input noisy image used for the forward learning is wrapped by the smoke attention learning to ease sampling steps and facilitate shared feature optimization. The smoke attention learning employs smoke segmentation and convolutional block attention modules to capture the non-homogeneous features of smoke. The multi-frequency learning is introduced to incorporate with shared feature learning to enhance the mid-to-high frequency features. In addition, the multi-task learning incorporates shared feature loss, smoke perception loss, dark channel prior loss, and contrast enhancement loss to help the model optimization. The experimental results show that the proposed method outperforms other state-of-the-art methods on both synthetic/real laparoscopic surgical images, with the potential to be embedded in laparoscopic devices for de-smoking.},
  archive      = {J_PR},
  author       = {Hao Li and Xiangyu Zhai and Ziwei Liang and Jie Xue and Bin Jin and Haitao Niu and Guangyong Zhang and Huanxin Ding and Dengwang Li and Pu Huang},
  doi          = {10.1016/j.patcog.2025.112447},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112447},
  shortjournal = {Pattern Recognition},
  title        = {Multi-frequency shared-feature-learning based diffusion model for removing surgical smoke},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Decoding the brain via multi-view brain topology contrastive learning. <em>PR</em>, <em>172</em>, 112445. (<a href='https://doi.org/10.1016/j.patcog.2025.112445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Graph Neural Networks (GNNs) have been widely used in neural decoding due to strong topological feature mining and interpretability. GNNs are heavily based on manually defined brain topology; if there are false connections or noise, it will greatly affect the decoding performance. To address the aforementioned challenges, a series of GNN-based graph topology learning (GTL) methods have received widespread attention due to their ability to automatically optimize brain topology. However, existing GTL methods are usually implemented in a supervised manner and rely on a large amount of annotated data, making it difficult to directly transfer them to different decoding scenarios. Therefore, in this paper, a Brain Topology Inference framework based on Multi-View Contrastive Self-supervised Learning (BTI-MVCSL) is proposed for neural decoding. Specifically, BTI-MVCSL first designs a series of graph learners, which can infer brain topological connections as “learner”, generate topology learning objectives as “instructor” from the original fMRI data, and maximize consistency between “instructor” and “learner” to extract the rich information in hidden connections. Furthermore, in order to achieve fully automated topology learning guidance, BTI-MVCSL develops a new self-learning mechanism that can use the “learner”-view brain topology to update the “instructor”-view brain topology during model optimization and further achieves comparative constraints through the “instructor” topology. The proposed BTI-MVCSL has been extensively evaluated in two publicly available fMRI datasets, demonstrating superior performance and revealing potential changes in brain topology under different decoding tasks.},
  archive      = {J_PR},
  author       = {Ziyu Li and Zhiyuan Zhu and Qing Li and Xia Wu},
  doi          = {10.1016/j.patcog.2025.112445},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112445},
  shortjournal = {Pattern Recognition},
  title        = {Decoding the brain via multi-view brain topology contrastive learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Condense loss: Exploiting vector magnitude during person re-identification training process. <em>PR</em>, <em>172</em>, 112443. (<a href='https://doi.org/10.1016/j.patcog.2025.112443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The magnitudes of features and weights significantly affect the gradients during the training process. L2 normalized softmax losses (such as NormFace, CosFace, ArcFace, etc.) and Naive softmax losses both reduce the magnitudes of image features in the training process and achieve good results in face recognition and person re-identification tasks, respectively. In this paper, we fully utilize the feature vector magnitudes and propose Condense loss for Re-ID tasks, which replaces the inner production of Naive softmax loss with the negative Euclidean distance. Condense loss generates negative radial gradients when updating weight parameters to push all features compacter. Because the coefficients of tangential gradients (the tangential component of the gradients) are related to feature magnitudes, it ideally provides monotonically decreasing tangential gradients, resulting in gradually diminishing updates that enhance the stability of the training process. We also introduce a margin parameter into Condense loss to enlarge inter-class distances and thus help the model learn more discriminative features. Mathematical analysis is given in this paper, and we have conducted sufficient experiments focusing on Re-ID tasks to prove the corresponding conclusion. The experimental results demonstrate that the Condense loss achieves competitive results compared to the state-of-the-art methods in the person re-identification task. At the same time, it also has a good performance in face recognition tasks.},
  archive      = {J_PR},
  author       = {Xi Yang and Wenjiao Dong and Yingzhi Tang and Gu Zheng and Nannan Wang and Xinbo Gao},
  doi          = {10.1016/j.patcog.2025.112443},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112443},
  shortjournal = {Pattern Recognition},
  title        = {Condense loss: Exploiting vector magnitude during person re-identification training process},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Entropy-informed weighting channel normalizing flow for deep generative models. <em>PR</em>, <em>172</em>, 112442. (<a href='https://doi.org/10.1016/j.patcog.2025.112442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normalizing Flows (NFs) are widely used in deep generative models for their exact likelihood estimation and efficient sampling. However, they require substantial memory since the latent space matches the input dimension. Multi-scale architectures address this by progressively reducing latent dimensions while preserving reversibility. Existing multi-scale architectures use simple, static channel-wise splitting, limiting expressiveness. To improve this, we introduce a regularized, feature-dependent Shuffle operation and integrate it into vanilla multi-scale architecture. This operation adaptively generates channel-wise weights and shuffles latent variables before splitting them. We observe that such operation guides the variables to evolve in the direction of entropy increase, hence we refer to NFs with the Shuffle operation as Entropy-Informed Weighting Channel Normalizing Flow (EIW-Flow). Extensive experiments on CIFAR-10, CelebA, ImageNet, and LSUN demonstrate that EIW-Flow achieves state-of-the-art density estimation and competitive sample quality for deep generative modeling, with minimal computational overhead.},
  archive      = {J_PR},
  author       = {Wei Chen and Shian Du and Shigui Li and Delu Zeng and John Paisley},
  doi          = {10.1016/j.patcog.2025.112442},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112442},
  shortjournal = {Pattern Recognition},
  title        = {Entropy-informed weighting channel normalizing flow for deep generative models},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Buffer-free class-incremental learning with out-of-distribution detection. <em>PR</em>, <em>172</em>, 112441. (<a href='https://doi.org/10.1016/j.patcog.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-incremental learning (CIL) poses significant challenges in open-world scenarios, where models must learn new classes over time without forgetting previous ones and handle inputs from unknown classes that a closed-set model would misclassify. In this paper, we present an in-depth analysis of post-hoc OOD detection methods and investigate their potential to eliminate the need for a memory buffer. When post hoc OOD detection is applied at inference time, we discover that it can effectively replace buffer-based strategies. We examine the performance of these methods in terms of classification accuracy of seen samples and rejection rates of unseen samples. We show that our approach achieves competitive performance compared to recent multi-head and single-head methods that rely on memory buffers and other buffer-free approaches. The results show that the proposed approach outperforms them in a closed-world setting and detects unseen samples while being significantly resource-efficient. Experimental results on CIFAR-10, CIFAR-100, and Tiny ImageNet support our findings and offer new insights into the design of efficient and privacy-preserving CIL systems for open-world settings.},
  archive      = {J_PR},
  author       = {Srishti Gupta and Daniele Angioni and Maura Pintor and Ambra Demontis and Lea Schönherr and Fabio Roli and Battista Biggio},
  doi          = {10.1016/j.patcog.2025.112441},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112441},
  shortjournal = {Pattern Recognition},
  title        = {Buffer-free class-incremental learning with out-of-distribution detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction” [Pattern recognition 172 (2026) 112339]. <em>PR</em>, <em>172</em>, 112440. (<a href='https://doi.org/10.1016/j.patcog.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PR},
  author       = {Chengcheng Li and Luqi Gong and Leiheng Xu and Xin Wang},
  doi          = {10.1016/j.patcog.2025.112440},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112440},
  shortjournal = {Pattern Recognition},
  title        = {Corrigendum to “DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction” [Pattern recognition 172 (2026) 112339]},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A progressive attention network with transformer for multi-label image recognition. <em>PR</em>, <em>172</em>, 112439. (<a href='https://doi.org/10.1016/j.patcog.2025.112439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research typically improves the performance of multi-label image recognition by constructing higher-order pairwise label correlations. However, these methods lack the ability to effectively learn multi-scale features, which makes it difficult to distinguish small-scale objects. Moreover, most current attention-based methods to capture local salient features may ignore many useful non-salient features. To address the aforementioned issues, we propose a Transformer-based Progressive Attention Network (TPANet) for multi-label image recognition. Specifically, we first design a new adaptive multi-scale feature attention (AMSA) module to learn cross-scale features in multi-level features. Then, to excavate various useful object features, we introduce the transformer encoder to construct a semantic spatial attention (ESA) module and also propose a context-aware feature enhanced (CAFE) module. The former ESA module is used to discover complete object regions and capture discriminative features, and the latter CAFE module leverages object-local features to enhance pixel-level global features. The proposed TPANet model can generate more accurate object labels in three popular benchmark datasets (i.e., MS-COCO 2014, Pascal VOC 2007 and Visual Genome), and is competitive to state-of-the-art models (e.g., SST and FL-Tran, etc.).},
  archive      = {J_PR},
  author       = {Sulan Zhang and Zhenwen Liao and Jianeng Li and Lihua Hu and Jifu Zhang},
  doi          = {10.1016/j.patcog.2025.112439},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112439},
  shortjournal = {Pattern Recognition},
  title        = {A progressive attention network with transformer for multi-label image recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Layer-wise correlation and attention discrepancy distillation for semantic segmentation. <em>PR</em>, <em>172</em>, 112438. (<a href='https://doi.org/10.1016/j.patcog.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) has recently garnered increased attention in segmentation tasks due to its effective balance between accuracy and computational efficiency. Nonetheless, existing methods mainly rely on structured knowledge from a single layer, overlooking the valuable discrepant knowledge that captures the diversity and distinctiveness of features across various layers, which is essential for the KD process. We present Layer-wise Correlation and Attention Discrepancy Distillation (LCADD) to tackle this issue, training compact and accurate semantic segmentation networks by considering layer-wise discrepancy knowledge. Specifically, we employ two distillation schemes: (i) correlation discrepancy distillation, which constructs a pixel-wise correlation discrepancy matrix across various layers to seize more detailed spatial dependencies, and (ii) attention discrepancy self-distillation, which aims to guide the shallower layers of the student network to emulate the attention discrepancy maps of the deeper layers, facilitating self-learning of attention discrepancy knowledge within the student network. Each proposed method is designed to work collaboratively in learning discrepancy knowledge, allowing the student network to better imitate the teacher from the perspective of layer-wise discrepancy. Our method has demonstrated superior performance on various semantic segmentation datasets, including Cityscapes, Pascal VOC 2012, and CamVid, compared to the latest knowledge distillation techniques, thereby validating its effectiveness.},
  archive      = {J_PR},
  author       = {Jianping Gou and Kaijie Chen and Cheng Chen and Weihua Ou and Xin Luo and Zhang Yi},
  doi          = {10.1016/j.patcog.2025.112438},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112438},
  shortjournal = {Pattern Recognition},
  title        = {Layer-wise correlation and attention discrepancy distillation for semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gradient semi-masking for improving adversarial robustness. <em>PR</em>, <em>172</em>, 112433. (<a href='https://doi.org/10.1016/j.patcog.2025.112433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In gradient masking, certain complex signal processing and probabilistic optimization strategies exhibit favorable characteristics such as nonlinearity, irreversibility, and feature preservation, thereby providing new solutions for adversarial defense. Inspired by this, this paper proposes a plug-and-play gradient semi-masking module ( GSeM ) to improve the adversarial robustness of neural networks. GSeM primarily contains a feature straight-through pathway that allows for normal gradient propagation and a feature mapping pathway that interrupts gradient flow. The multi-pathway and semi-masking characteristics cause GSeM to exhibit opposing behaviors when processing data and gradients. Specifically, during data processing, GSeM compresses the state space of features while introducing white noise augmentation. However, during gradient processing, it leads to inefficient updates to certain parameters and ineffective generation of training examples. To address this shortcoming, we correct gradient propagation and introduce gradient-corrected adversarial training. Extensive experiments demonstrate that GSeM differs fundamentally from earlier gradient masking methods: it can genuinely enhance the adversarial defense performance of neural networks, surpassing previous state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Xinlei Liu and Tao Hu and Peng Yi and Baolin Li and Jichao Xie and Hailong Ma},
  doi          = {10.1016/j.patcog.2025.112433},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112433},
  shortjournal = {Pattern Recognition},
  title        = {Gradient semi-masking for improving adversarial robustness},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Structural-prior guided bi-generative network for image inpainting. <em>PR</em>, <em>172</em>, 112432. (<a href='https://doi.org/10.1016/j.patcog.2025.112432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting is a great challenge when reconstructed with realistic textures and required to enhance the consistency of semantic structures in large-scale missing regions. However, popular structural prior guidance methods primarily rely on the reconstruction of structural features. Due to the Markovian property inherent in purely feedforward architectures, noise undergoes persistent accumulation and propagation in early network layers. Without intermediate feedback mechanisms, minor artifacts in shallow layers would be nonlinearly amplified through successive convolution operations and cannot be timely corrected, thereby hindering the extraction of valid structural information. To this end, we presents a bi-generative network (Bi-GNet) guided by specific semantic structures, including an auxiliary network N s and an inpainting network N inp . Here N s provides the structural prior information to N inp for reconstructing the texture details of images. Additionally, we provide the spatial coordinate attention (SCA) and the adaptive feature filtering (AFF) module to ensure structural consistency and texture plausibility in the reconstructed content. Experiments demonstrate that Bi-GNet significantly outperforms other state-of-the-art approaches on three datasets and achieves good inpainting results on the Mogao Grottoes mural dataset.},
  archive      = {J_PR},
  author       = {Jiajun Zhang and Jizhao Liu and Huaikun Zhang and Jibao Zhang and Jing Lian},
  doi          = {10.1016/j.patcog.2025.112432},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112432},
  shortjournal = {Pattern Recognition},
  title        = {Structural-prior guided bi-generative network for image inpainting},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning from majority label: A novel problem in multi-class multiple-instance learning. <em>PR</em>, <em>172</em>, 112425. (<a href='https://doi.org/10.1016/j.patcog.2025.112425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a novel multi-class Multiple-Instance Learning (MIL) problem called Learning from Majority Label (LML). In LML, the majority class of instances in a bag is assigned as the bag-level label. The goal of LML is to train a classification model that estimates the class of each instance using the majority label. This problem is valuable in a variety of applications, including pathology image segmentation, political voting prediction, customer sentiment analysis, and environmental monitoring. To solve LML, we propose a Counting Network trained to produce bag-level majority labels, estimated by counting the number of instances in each class. Furthermore, analysis experiments on the characteristics of LML revealed that bags with a high proportion of the majority class facilitate learning. Based on this result, we developed a Majority Proportion Enhancement Module (MPEM) that increases the proportion of the majority class by removing minority class instances within the bags. Experiments demonstrate the superiority of the proposed method on four datasets compared to conventional MIL methods. Moreover, ablation studies confirmed the effectiveness of each module. The code is available at here .},
  archive      = {J_PR},
  author       = {Kaito Shiku and Shinnosuke Matsuo and Daiki Suehiro and Ryoma Bise},
  doi          = {10.1016/j.patcog.2025.112425},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112425},
  shortjournal = {Pattern Recognition},
  title        = {Learning from majority label: A novel problem in multi-class multiple-instance learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Feature subset weighting for distance-based supervised learning. <em>PR</em>, <em>172</em>, 112424. (<a href='https://doi.org/10.1016/j.patcog.2025.112424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces feature subset weighting using monotone measures for distance-based supervised learning. The Choquet integral is used to define a distance function that incorporates these weights. This integration enables the proposed distances to effectively capture non-linear relationships and account for interactions both between conditional and decision attributes and among conditional attributes themselves, resulting in a more flexible distance measure. In particular, we show how this approach ensures that the distances remain unaffected by the addition of duplicate and strongly correlated features. Another key point of this approach is that it makes feature subset weighting computationally feasible, since only m feature subset weights should be calculated each time instead of calculating all feature subset weights ( 2 m ), where m is the number of attributes. Next, we also examine how the use of the Choquet integral for measuring similarity leads to a non-equivalent definition of distance. The relationship between distance and similarity is further explored through dual measures. Additionally, symmetric Choquet distances and similarities are proposed, preserving the classical symmetry between similarity and distance. Finally, we introduce a concrete feature subset weighting distance, evaluate its performance in a k -nearest neighbours (KNN) classification setting, and compare it against Mahalanobis distances and weighted distance methods.},
  archive      = {J_PR},
  author       = {Adnan Theerens and Yvan Saeys and Chris Cornelis},
  doi          = {10.1016/j.patcog.2025.112424},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112424},
  shortjournal = {Pattern Recognition},
  title        = {Feature subset weighting for distance-based supervised learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 4DStyleGaussian: Generalizable 4D style transfer with gaussian splatting. <em>PR</em>, <em>172</em>, 112422. (<a href='https://doi.org/10.1016/j.patcog.2025.112422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D neural style transfer has gained significant attention for its potential to provide user-friendly stylization with 3D spatial consistency. However, existing 3D style transfer methods often struggle with inference efficiency, generalization, and maintaining temporal consistency when handling dynamic scenes. In this paper, we introduce 4DStyleGaussian, a novel 4D style transfer framework designed to achieve real-time stylization of arbitrary style references while maintaining reasonable content affinity, multi-view consistency, and temporal coherence. Our approach leverages an embedded 4D Gaussian Splatting technique, which is trained utilizing a reversible neural network for reducing content loss and artifacts in the feature distillation process. With the pre-trained 4D embedded Gaussians for efficient and view-consistent rendering, we predict a 4D style transformation matrix that facilitates spatially and temporally consistent style transfer. Experiments demonstrate that our method can achieve high-quality and generalizable stylization for 4D scenarios with enhanced efficiency and spatial-temporal consistency, with 7.1 % lower LPIPS and 2.5× faster inference compared to existing methods.},
  archive      = {J_PR},
  author       = {Wanlin Liang and Hongbin Xu and Weitao Chen and Feng Xiao and Wenxiong Kang},
  doi          = {10.1016/j.patcog.2025.112422},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112422},
  shortjournal = {Pattern Recognition},
  title        = {4DStyleGaussian: Generalizable 4D style transfer with gaussian splatting},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Retinex-guided generative diffusion prior for low-light image enhancement. <em>PR</em>, <em>172</em>, 112421. (<a href='https://doi.org/10.1016/j.patcog.2025.112421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Retinex-based training-free low-light image enhancement (LLIE) methods often rely on complex architectures or lack support for text-controlled personalization. In this paper, we propose RetinexGDP, a training-free and text-controllable LLIE framework that uniquely integrates Retinex-based image modeling with generative diffusion priors. First, we introduce a simplified Retinex decomposition by embedding weighted total variation optimization into a single Gaussian convolutional layer, enabling robust illumination estimation without the need for training. Next, we guide the diffusion denoising process using the estimated reflectance map, employing patch-wise inversion and reflectance-conditioned sampling to effectively suppress noise while preserving structural details. Finally, unlike previous diffusion-based LLIE methods that perform only monotonous global brightness enhancement, we incorporate text guidance into the sampling process, enabling controllable enhancement that aligns with user-specific stylistic preferences. RetinexGDP thus provides a modular, interpretable, and text-controllable solution for low-light image enhancement. Experimental results show that RetinexGDP achieves state-of-the-art performance in terms of NIQMC and CPCQI metrics across seven real-world datasets. Code will be available at: https://github.com/zhaozunjin/PLIE},
  archive      = {J_PR},
  author       = {Zunjin Zhao and Daming Shi},
  doi          = {10.1016/j.patcog.2025.112421},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112421},
  shortjournal = {Pattern Recognition},
  title        = {Retinex-guided generative diffusion prior for low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive integration of textual context and visual embeddings for underrepresented vision classification. <em>PR</em>, <em>172</em>, 112420. (<a href='https://doi.org/10.1016/j.patcog.2025.112420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of deep learning has significantly improved image classification performance; however, handling long-tail distributions remains challenging due to the limited data available for rare classes. Existing approaches predominantly focus on visual features, often neglecting the valuable contextual information provided by textual data, which can be especially beneficial for classes with sparse visual examples. In this work, we introduce a novel method addressing this limitation by integrating textual data generated by advanced language models with visual inputs through our newly proposed Adaptive Integration Block for Vision-Text Synergy (AIB-VTS). Specifically designed for Vision Transformer architectures, AIB-VTS adaptively balances visual and textual information during inference, effectively utilizing textual descriptions generated from large language models. Extensive experiments on benchmark datasets demonstrate substantial performance improvements across all class groups, particularly in underrepresented (tail) classes. These results confirm the effectiveness of our approach in leveraging textual context to mitigate data scarcity issues and enhance model robustness.},
  archive      = {J_PR},
  author       = {Seongyeop Kim and Hyung-Il Kim and Yong Man Ro},
  doi          = {10.1016/j.patcog.2025.112420},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112420},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive integration of textual context and visual embeddings for underrepresented vision classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PCFFusion: Progressive cross-modal feature fusion network for infrared and visible images. <em>PR</em>, <em>172</em>, 112419. (<a href='https://doi.org/10.1016/j.patcog.2025.112419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) aims to fuse thermal target information in infrared images and spatial texture information in visible images, improving the observability and comprehensibility of the fused images. Currently, most IVIF methods suffer from the loss of salient target information and texture details in fused images. To alleviate this problem, a progressive cross-modal feature fusion network (PCFFusion) for IVIF is proposed, which comprises two stages: feature extraction and feature fusion. In the feature extraction stage, to enhance the network’s feature representation capability, a feature decomposition module (FDM) is constructed to extract two modal features of different scales by defining a feature decomposition operation (FDO). In addition, by establishing correlations between the high- frequency and low-frequency components of two modal features, a cross-modal feature enhancement module (CMFEM) is built to realize correction and enhancement of the two features at each scale. The feature fusion stage achieves the fusion of two modal features at each scale and the supplementation of adjacent scale features by constructing three cross-domain fusion module (CDFMs). To constrain the fused results preserve more salient targets and richer texture details, a dual-feature fidelity loss function is defined by constructing a salient weight map to balance the two loss terms. Extensive experiments demonstrate that fusion results of the proposed method highlight prominent targets from infrared images while retaining rich background details from visible images, and the performance of PCFFusion is superior to some advanced methods. Specifically, compared to the optimal results obtained by other comparison methods, the proposed network achieves an average increase of 30.35 % and 10.9 % in metrics Mutual Information (MI) and Standard deviation (SD) on the TNO dataset, respectively.},
  archive      = {J_PR},
  author       = {Shuying Huang and Kai Zhang and Yong Yang and Weiguo Wan},
  doi          = {10.1016/j.patcog.2025.112419},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112419},
  shortjournal = {Pattern Recognition},
  title        = {PCFFusion: Progressive cross-modal feature fusion network for infrared and visible images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MonoA2: Adaptive depth with augmented head for monocular 3D object detection. <em>PR</em>, <em>172</em>, 112418. (<a href='https://doi.org/10.1016/j.patcog.2025.112418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3D object detection is a hot direction due to its low cost and configuration simplicity. Achieving accurate instance depth prediction from monocular images is a challenging problem in monocular 3D object detection. Many existing methods perform instance depth prediction based on fixed rules, which are not flexible for various objects. Furthermore, these methods ignore the design of more discriminative task heads. To address these issues, we propose the MonoA 2 , which consists of the Adaptive Depth Module (ADM) and the Augmented Head Module (AHM). The ADM is used to achieve more accurate depth prediction by learning adaptive offsets to decouple the depth prediction from object center constraints. The AHM is proposed to obtain more discriminative task heads through task-aware attention and task-interaction attention. The task-aware attention can generate different weights adapted to different tasks and the task-interaction attention can guide depth tasks to interact with other tasks. Experimental results on the KITTI and Waymo datasets demonstrate the effectiveness of the proposed method. Our method achieves superior performance on the KITTI and Waymo benchmarks.},
  archive      = {J_PR},
  author       = {Jinpeng Dong and Sanping Zhou and Yufeng Hu and Yuhao Huang and Jingjing Jiang and Weiliang Zuo and Shitao Chen and Nanning Zheng},
  doi          = {10.1016/j.patcog.2025.112418},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112418},
  shortjournal = {Pattern Recognition},
  title        = {MonoA2: Adaptive depth with augmented head for monocular 3D object detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time series adaptive mode decomposition (TAMD): Method for improving forecasting accuracy in the apparel industry. <em>PR</em>, <em>172</em>, 112417. (<a href='https://doi.org/10.1016/j.patcog.2025.112417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of apparel sales is critical for inventory management, supply chain optimization, and market strategy planning. However, existing forecasting models often struggle to effectively capture the complex characteristics of apparel sales data, such as distinct seasonality, cyclicality, and strongly nonlinear fluctuations, which significantly hinder prediction accuracy and generalization ability. To address these challenges, this study introduces a novel Time series Adaptive Mode Decomposition (TAMD)-based forecasting algorithm. The proposed method: (1) employs Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and sample entropy-guided Variational Mode Decomposition (VMD) to separate the input time series into noise components and multiple smooth Intrinsic Mode Functions (IMFs), to better capture intrinsic data dynamics; (2) refines the sub-series distribution features via an adaptive module guided by sample entropy, dividing each sub-series into subsequences with maximal distribution difference to improve adaptability to periodic changes and market volatility; (3) predicts each subsequence with adaptive distribution matching based on discontinuous random subsequence combinations, and then linearly superposes the prediction results as a final output, thereby boosting accuracy and generalizability. Comprehensive experiments on both public and self-constructed datasets (including four years of Taobao sales data for dresses, jeans, sweatshirts, and sweaters, totaling over 44.7 million records) demonstrate that TAMD outperforms existing methods significantly, highlighting its effectiveness in revealing the complexity of apparel market data and enhancing prediction performance.},
  archive      = {J_PR},
  author       = {Guangbao Zhou and Pengliang Liu and Quanle Lin and Miao Qian and Zhong Xiang and Zeyu Zheng and Lixian Liu},
  doi          = {10.1016/j.patcog.2025.112417},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112417},
  shortjournal = {Pattern Recognition},
  title        = {Time series adaptive mode decomposition (TAMD): Method for improving forecasting accuracy in the apparel industry},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A framework for bias-aware dataset evaluation in soft facial attribute recognition. <em>PR</em>, <em>172</em>, 112416. (<a href='https://doi.org/10.1016/j.patcog.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft Facial Attribute Recognition (FAR) remains largely unexplored in terms of demographic fairness. To the best of our knowledge, this study presents one of the first comprehensive analyses of demographic bias in FAR, proposing a systematic framework to detect, quantify, and promote awareness of both representational and stereotypical biases, supporting their mitigation. Leveraging established taxonomies, we evaluate state-of-the-art datasets using a rigorous set of interpretable bias metrics to uncover hidden demographic imbalances. To support reliable fairness assessment, we first enrich the datasets with standardized demographic annotations using the FairFace model. We then address label inconsistencies through the integration of predictions from advanced Vision-Language Models (VLMs). Our analysis reveals substantial imbalances across gender, age, and racial categories-specifically White, Black, and Asian- affecting dataset composition. Furthermore, we show that conventional fairness metrics often yield divergent assessments, highlighting the importance of multi-metric evaluation. This study provides a replicable methodology and actionable insights to support bias-aware facial analysis.},
  archive      = {J_PR},
  author       = {Lucia Cascone and Michele Nappi and Chiara Pero and Xinggang Wang},
  doi          = {10.1016/j.patcog.2025.112416},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112416},
  shortjournal = {Pattern Recognition},
  title        = {A framework for bias-aware dataset evaluation in soft facial attribute recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fast multi-view discrete clustering with two solvers. <em>PR</em>, <em>172</em>, 112415. (<a href='https://doi.org/10.1016/j.patcog.2025.112415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view graph clustering follows a three-phase process: constructing view-specific similarity graphs, fusing information from different views, and conducting eigenvalue decomposition followed by post-processing to obtain the clustering indicators. However, it encounters two key challenges: the high computational cost of graph construction and eigenvalue decomposition, and the inevitable information deviation introduced by the last process. To tackle these obstacles, we propose Fast Multi-view Discrete Clustering with two solvers (FMDC), to directly and efficiently solve the multi-view graph clustering problem. FMDC involves: (1) generating a compact set of representative anchors to construct anchor graphs, (2) automatically weighting them into a symmetric and doubly stochastic aggregated similarity matrix, (3) executing clustering on the aggregated form with the discrete indicator matrix directly computed through two efficient solvers that we devised. The linear computational complexity of FMDC w.r.t. data size is a notable improvement over traditional quadratic or cubic complexity. Extensive experiments confirm the superior performance of FMDC both in efficiency and in effectiveness.},
  archive      = {J_PR},
  author       = {Qianyao Qiang and Bin Zhang and Jason Chen Zhang and Feiping Nie},
  doi          = {10.1016/j.patcog.2025.112415},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112415},
  shortjournal = {Pattern Recognition},
  title        = {Fast multi-view discrete clustering with two solvers},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clinical knowledge enhanced medical image classification. <em>PR</em>, <em>172</em>, 112414. (<a href='https://doi.org/10.1016/j.patcog.2025.112414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the scarcity of data in medical field, deep learning-based medical image classification faces challenges in both accuracy and reliability. Foundation models (FMs) provide a promising enhancement strategy by extracting the text medical knowledge embeddings from FMs and use it to guide the specific classification model. However, the clinical knowledge is generally structurized, and the use of pure text as knowledge representation may not be significant enough for enhancing downstream model. Moreover, the lesion areas are generally subtle, combining FMs to downstream model in a coarse-grained manner still faces challenge in precisely attending the lesions. To tackle these challenges, we propose a novel medical image classification model that effectively embeds clinical knowledge through combining graphs and FMs. First, we represent the clinical rules as graphs, where the node describes the critical characteristics of disease. During training, we use FMs to extract the embeddings of node text description, and use graph transformer to extract global representation of graphs. By employing vision transformer to encode input images, we propose a global-local alignment module to transfer clinical knowledge where the embeddings of image branch and graph branch are aligned from image-to-graph level and patch-to-vertex level, respectively. Moreover, we propose a dynamic image patch selection method to reduce the attention of the model to irrelevant and noisy regions. Experimental results on bladder tumor classification dataset verifies that even with limited training data, the proposed method can not only achieve SOTA performance, but also accurately attend the lesion areas, thus improving the trustworthiness.},
  archive      = {J_PR},
  author       = {Zhikang Xu and Jiye Liang and Zhipeng Wei and Xiaodong Yue and Deyu Li},
  doi          = {10.1016/j.patcog.2025.112414},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112414},
  shortjournal = {Pattern Recognition},
  title        = {Clinical knowledge enhanced medical image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asymmetric simulation-enhanced flow reconstruction for incomplete multimodal learning. <em>PR</em>, <em>172</em>, 112413. (<a href='https://doi.org/10.1016/j.patcog.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multimodal learning addresses the common real-world challenge of missing modalities, which undermines the performance of standard multimodal methods. Existing solutions struggle with distribution mismatches between reconstructed and observed data, asymmetric cross-modal structures, and insufficient cross-modal knowledge sharing. To tackle these issues, we propose an asymmetric simulation-enhanced flow reconstruction (ASE-FR) framework, which contains following contributions: (1) Distribution-consistent flow reconstruction module that align available and missing modality distributions by normalizing flows; (2) Asymmetric simulation module that perturbs and randomly masks features to mimic real-world modality absence and improve robustness; (3) Modal-shared knowledge distillation that transfers shared representations from teacher encoders to a student encoder through contrastive learning. This framework is applicable to a range of real-world scenarios, such as multi-sensor networks in smart manufacturing, medical diagnostic systems combining imaging and electronic health records, and autonomous driving platforms that integrate camera and LiDAR data. The experimental results show that our ASE-FR method achieves 94.71 %, 41.85 % and 81.90 % accuracy on Audiovision-MNIST, MM-IMDb and IEMOCAP datasets, as well as 1.1376 error rate on CMU-MOSI dataset, which exhibits competitive performance.},
  archive      = {J_PR},
  author       = {Jiacheng Yao and Jing Zhang and Yixiao Wang and Li Zhuo},
  doi          = {10.1016/j.patcog.2025.112413},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112413},
  shortjournal = {Pattern Recognition},
  title        = {Asymmetric simulation-enhanced flow reconstruction for incomplete multimodal learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Benchmarking the spatial robustness of DNNs via natural and adversarial localized corruptions. <em>PR</em>, <em>172</em>, 112412. (<a href='https://doi.org/10.1016/j.patcog.2025.112412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robustness of deep neural networks is a crucial factor in safety-critical applications, particularly in complex and dynamic environments (e.g., medical or driving scenarios) where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remained underexplored. This paper fills this gap by introducing novel, region-aware metrics for benchmarking the spatial robustness of segmentation models, along with an evaluation framework to assess the impact of natural localized corruptions. Furthermore, it uncovers the inherent complexity of evaluating worst-case spatial robustness using only a single localized adversarial attack. To address this, the work proposes a region-aware multi-attack adversarial analysis to systematically assess model robustness across specific image regions. The proposed metrics and analysis were exploited to evaluate 14 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones, and vice versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.},
  archive      = {J_PR},
  author       = {Giulia Marchiori Pietrosanti and Giulio Rossolini and Alessandro Biondi and Giorgio Buttazzo},
  doi          = {10.1016/j.patcog.2025.112412},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112412},
  shortjournal = {Pattern Recognition},
  title        = {Benchmarking the spatial robustness of DNNs via natural and adversarial localized corruptions},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preserving privacy without compromising accuracy: Machine unlearning for handwritten text recognition. <em>PR</em>, <em>172</em>, 112411. (<a href='https://doi.org/10.1016/j.patcog.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten Text Recognition (HTR) is crucial for document digitization, but handwritten data can contain user-identifiable features, like unique writing styles, posing privacy risks. Regulations such as the “right to be forgotten” require models to remove these sensitive traces without full retraining. We introduce a practical encoder-only transformer baseline as a robust reference for future HTR research. Building on this, we propose a two-stage unlearning framework for multihead transformer HTR models. Our method combines neural pruning with machine unlearning applied to a writer classification head, ensuring sensitive information is removed while preserving the recognition head. We also present Writer-ID Confusion (WIC), a method that forces the forget set to follow a uniform distribution over writer identities, unlearning user-specific cues while maintaining text recognition performance. We compare WIC to Random Labeling, Fisher Forgetting, Amnesiac Unlearning, and DELETE within our prune-unlearn pipeline and consistently achieve better privacy and accuracy trade-offs. This is the first systematic study of machine unlearning for HTR. Using metrics such as Accuracy, Character Error Rate (CER), Word Error Rate (WER), and Membership Inference Attacks (MIA) on the IAM and CVL datasets, we demonstrate that our method achieves state-of-the-art or superior performance for effective unlearning. These experiments show that our approach effectively safeguards privacy without compromising accuracy, opening new directions for document analysis research. Our code is publicly available at https://github.com/leitro/WIC-WriterIDConfusion-MachineUnlearning .},
  archive      = {J_PR},
  author       = {Lei Kang and Xuanshuo Fu and Lluis Gomez and Alicia Fornés and Ernest Valveny and Dimosthenis Karatzas},
  doi          = {10.1016/j.patcog.2025.112411},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112411},
  shortjournal = {Pattern Recognition},
  title        = {Preserving privacy without compromising accuracy: Machine unlearning for handwritten text recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated automatic latent variable selection in multi-output gaussian processes. <em>PR</em>, <em>172</em>, 112410. (<a href='https://doi.org/10.1016/j.patcog.2025.112410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a federated learning approach that automatically selects the number of latent processes in multi-output Gaussian processes (MGPs). The MGP has seen great success as a transfer learning tool when data is generated from multiple sources/units/entities. A common approach in MGPs to transfer knowledge across units involves gathering all data from each unit to a central server and extracting common independent latent processes to express each unit as a linear combination of the shared latent patterns. However, this approach poses key challenges in (i) determining the adequate number of latent processes and (ii) relying on centralized learning which leads to potential privacy risks and significant computational burdens on the central server. To address these issues, we propose a hierarchical model that places spike-and-slab priors on the coefficients of each latent process. These priors help automatically select only needed latent processes by shrinking the coefficients of unnecessary ones to zero. To estimate the model while avoiding the drawbacks of centralized learning, we propose a variational inference-based approach, that formulates model inference as an optimization problem compatible with federated settings. We then design a federated learning algorithm that allows units to jointly select and infer the common latent processes without sharing their data. We also discuss an efficient learning approach for a new unit within our proposed federated framework. Simulation and case studies on Li-ion battery degradation and air temperature data demonstrate the advantageous features of our proposed approach.},
  archive      = {J_PR},
  author       = {Jingyi Gao and Seokhyun Chung},
  doi          = {10.1016/j.patcog.2025.112410},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112410},
  shortjournal = {Pattern Recognition},
  title        = {Federated automatic latent variable selection in multi-output gaussian processes},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-view consistency clustering via structure-enhanced contrastive learning. <em>PR</em>, <em>172</em>, 112409. (<a href='https://doi.org/10.1016/j.patcog.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current state-of-the-art deep multi-view clustering methods resort to contrastive learning to learn consensus representations with Cross-View Consistency ( CVC ). However, contrastive learning has inherent limitations when being applied to the multi-view clustering. On one hand, contrastive learning suffers from class collision issue, compromising the discriminability of consensus representation. On the other hand, contrastive alignment of two views of different quality could lead to representation degradation for the higher-quality view, weakening the robustness of the consensus representation. To alleviate these issues, this paper presents an Adaptive Multi-view consistency clustering method via structure-enhanced contrastive learning ( A da M ), which learns multi-faceted consensus representation that balances view-consistency, discriminability and robustness, forming an optimal consensus representation. Specifically, we first design a view fusion module and a structural learning module to learn view weights and structural relationships among samples, respectively, to derive the consensus representation. Second, beyond CVC , we propose a novel clustering framework called Adaptive Multi-View Consistency ( AMVC ), which adaptively aligns specific view representation with consensus representation based on the learned view weights. Furthermore, compared to CVC , we theoretically demonstrate the superiority of AMVC in learning robust consensus representation. Third, A da M leverages the structural relationships among samples to refine the conventional contrastive loss, further enhancing the discriminability of the consensus representation. Extensive experimental results on eight datasets demonstrate the superior performance of A da M over eight advanced multi-view clustering baselines.},
  archive      = {J_PR},
  author       = {Xuqian Xue and Qi Cai and Zhanwei Zhang and Yiming Lei and Hongming Shan and Junping Zhang},
  doi          = {10.1016/j.patcog.2025.112409},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112409},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive multi-view consistency clustering via structure-enhanced contrastive learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A text-only weakly supervised learning framework for text spotting via text-to-polygon generator. <em>PR</em>, <em>172</em>, 112408. (<a href='https://doi.org/10.1016/j.patcog.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced text spotting methods typically rely on large-scale, meticulously labeled datasets to achieve satisfactory performance. However, annotating fine-grained positional information of texts in real-world scene images is extremely costly and time-consuming. Although some weakly supervised methods have been developed to reduce annotation costs, they face two major challenges: 1) their performance significantly lags behind the fully supervised counterparts, and 2) They are tightly coupled with specific text spotting models, meaning that switching to a different model would require retraining and incur substantial computational costs. To address these limitations, we propose a novel text-only weakly supervised learning framework for text spotting via text-to-polygon generator. In the first stage, we pretrain a text-to-polygon generator on an auxiliary dataset, e.g., synthetic or public datasets, where full annotations are readily accessible. In the second stage, given real-world target datasets annotated with text-only labels, we employ the pretrained generator to produce pseudo polygon labels, thereby constructing a pseudo-labeled supervised dataset for training text spotting models. To ensure high-quality pseudo polygon labels, the text-to-polygon generator first identifies all candidate text regions, then filters those that are relevant to the target text, and finally predicts their precise spatial locations. Notably, this generator requires only a single pretraining session and can subsequently be applied to any text spotting model and target text-only dataset without incurring additional costs. Extensive experiments on public benchmarks demonstrate that our method can significantly reduce labeling costs while maintaining competitive performance.},
  archive      = {J_PR},
  author       = {Gege Zhang and Zhiyong Gan and Ling Deng and Shuaicheng Niu and Zhenghua Peng and Gang Dai and Shuangping Huang and Xiangmin Xu},
  doi          = {10.1016/j.patcog.2025.112408},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112408},
  shortjournal = {Pattern Recognition},
  title        = {A text-only weakly supervised learning framework for text spotting via text-to-polygon generator},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Leveraging synthetic data for zero–shot and few–shot circle detection in real–world domains. <em>PR</em>, <em>172</em>, 112407. (<a href='https://doi.org/10.1016/j.patcog.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circle detection plays a pivotal role in computer vision, underpinning applications from industrial inspection and bioinformatics to autonomous driving. Traditional methods, however, often struggle with real–world complexities, as they demand extensive parameter tuning and adaptation across different domains. In this paper, we present the Synthetic Circle Dataset (SynCircle), a large synthetic image dataset designed to train a YOLO v10 network for circle detection. The YOLO v10 network, pre–trained solely on synthetic data, demonstrates remarkable off–the–shelf performance that surpasses conventional methods in various practical scenarios. Furthermore, we show that incorporating just a few labeled real images for fine–tuning can significantly boost performance, reducing the need for large annotated datasets. To promote reproducibility and streamline adoption, we publicly release both the trained YOLO v10 weights and the full SynCircle dataset.},
  archive      = {J_PR},
  author       = {Paolo Andreini and Marco Tanfoni and Simone Bonechi and Monica Bianchini},
  doi          = {10.1016/j.patcog.2025.112407},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112407},
  shortjournal = {Pattern Recognition},
  title        = {Leveraging synthetic data for zero–shot and few–shot circle detection in real–world domains},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Aegis: A domain generalization framework for medical image segmentation by mitigating feature misalignment. <em>PR</em>, <em>172</em>, 112406. (<a href='https://doi.org/10.1016/j.patcog.2025.112406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain shift caused by variations in data acquisition significantly impedes the deployment of medical image segmentation models in clinical settings. Domain generalization aims to mitigate performance degradation induced by domain shift by training a model using source domain data and generalize well to unseen target domain. In this work, we have an interesting observation: domain shift results in significantly different activation patterns across domains even they have semantically identical input. This cross-domain “feature misalignment” phenomenon motivates us to develop a hypothesis: mitigating cross-domain feature misalignment may enhance domain generalization. To this end, we propose a framework called Aegis , which employs style augmentation to generate augmented image features that simulate domain shift. Subsequently, we introduce a dual attention-guided feature calibration (DAFC) module to facilitate feature interaction between source and augmented images, thereby establishing an implicit alignment constraint within the shared feature space. Furthermore, we propose an uncertainty-guided feature alignment (UFA) loss, which quantifies segmentation discrepancies caused by domain shift and incorporates an uncertainty-weighting mechanism to enhance the alignment of hard-to-classify pixel regions. These components work in synergy to effectively mitigate cross-domain feature misalignment, promote robust feature alignment, and ultimately improve cross-domain generalization. Extensive experiments conducted on three widely used benchmarks demonstrate that the proposed framework significantly outperforms existing methods in domain generalization. Code is available at https://github.com/Zerua-bit/Aegis .},
  archive      = {J_PR},
  author       = {Yuheng Xu and Taiping Zhang and Yuqi Fang},
  doi          = {10.1016/j.patcog.2025.112406},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112406},
  shortjournal = {Pattern Recognition},
  title        = {Aegis: A domain generalization framework for medical image segmentation by mitigating feature misalignment},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preference isolation forest for structure-based anomaly detection. <em>PR</em>, <em>172</em>, 112405. (<a href='https://doi.org/10.1016/j.patcog.2025.112405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of detecting anomalies as samples that do not conform to structured patterns represented by low-dimensional manifolds. To this end, we conceive a general anomaly detection framework called Preference Isolation Forest ( PIF ), that combines the benefits of adaptive isolation-based methods with the flexibility of preference embedding. The key intuition is to embed the data into a high-dimensional preference space by fitting low-dimensional manifolds, and to identify anomalies as isolated points. We propose three isolation approaches to identify anomalies: i ) Voronoi- iForest , the most general solution, ii ) RuzHash - iForest , that avoids explicit computation of distances via Local Sensitive Hashing, and iii ) Sliding- PIF , that leverages a locality prior to improve efficiency and effectiveness.},
  archive      = {J_PR},
  author       = {Filippo Leveni and Luca Magri and Cesare Alippi and Giacomo Boracchi},
  doi          = {10.1016/j.patcog.2025.112405},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112405},
  shortjournal = {Pattern Recognition},
  title        = {Preference isolation forest for structure-based anomaly detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DURN: Data uncertainty-driven robust network for mural sketch detection. <em>PR</em>, <em>172</em>, 112404. (<a href='https://doi.org/10.1016/j.patcog.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mural sketches reveal both the content and structure of the murals and are crucial for the preservation of murals. However, existing methods lack robustness, making it difficult to suppress noise while preserving sketches on damaged murals and fully capturing details on clear murals. To address this, we propose a Data Uncertainty-Driven Robust Network (DURN) for mural sketch detection. DURN uses uncertainty to quantify noise in the murals, converting prediction into a learnable normal distribution, where the mean represents the sketch and the variance denotes the uncertainty. This enables the model to learn both the sketch and the noise simultaneously, achieving noise suppression while preserving the sketches. To enhance sketches, we design an Adaptive Fusion Feature Enhancement Module (AFFE) to dynamically adjust the fusion strategy according to the contribution of features at different scales and reduce the information loss caused by feature dimensionality reduction to maximize the utility of each feature. We develop a novel Deep-Shallow Supervision (DSS) module to mitigate background noise using deep semantic information to guide shallow features without adding parameters. Additionally, we achieve model lightweighting through pruning techniques, ensuring competitive performance while reducing the number of parameters to only 4.5 % of the original. The experimental results show an improvement of 10. 4 % AP over existing methods, demonstrating the robustness of DURN for complex and damaged murals. The source code is available at https://github.com/TIVEN-Z/DURN .},
  archive      = {J_PR},
  author       = {Shenglin Peng and Xingguo Zhao and Jun Wang and Lin Wang and Shuyi Qu and Jingye Peng and Xianlin Peng},
  doi          = {10.1016/j.patcog.2025.112404},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112404},
  shortjournal = {Pattern Recognition},
  title        = {DURN: Data uncertainty-driven robust network for mural sketch detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learn depth space from light field via a distance-constraint query mechanism. <em>PR</em>, <em>172</em>, 112403. (<a href='https://doi.org/10.1016/j.patcog.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Light Field (LF) captures both spatial and angular information of scenes, enabling precise depth estimation. Recent advancements in deep learning have led to significant success in this field; however, existing methods primarily focus on modeling surface characteristics (e.g., depth maps) while overlooking the depth space, which contains additional valuable information. The depth space consists of numerous space points and provides substantially more geometric data than a single depth map. In this paper, we conceptualize depth prediction as a spatial modeling problem, aiming to learn the entire depth space rather than merely a single depth map. Specifically, we define space points as signed distances relative to the scene surface and propose a novel distance-constraint query mechanism for LF depth estimation. To model the depth space effectively, we first develop a mixed sampling strategy to approximate its data representation. Subsequently, we introduce an encoder-decoder network architecture to query the distances of each point, thereby implicitly embedding the depth space. Finally, to extract the target depth map from this space, we present a generation algorithm that iteratively invokes the decoder network. Through extensive experiments, our approach achieves the highest performance on LF depth estimation benchmarks, and also demonstrates superior performance on various synthetic and real-world scenes.},
  archive      = {J_PR},
  author       = {Hao Sheng and Rongshan Chen and Ruixuan Cong and Da Yang and Zhenglong Cui and Sizhe Wang},
  doi          = {10.1016/j.patcog.2025.112403},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112403},
  shortjournal = {Pattern Recognition},
  title        = {Learn depth space from light field via a distance-constraint query mechanism},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised instance segmentation with superpixels. <em>PR</em>, <em>172</em>, 112402. (<a href='https://doi.org/10.1016/j.patcog.2025.112402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation is essential for numerous computer vision applications, including robotics, human-computer interaction, and autonomous driving. Currently, popular models bring impressive performance in instance segmentation by training with a large number of human annotations, which are costly to collect. For this reason, we present a new framework that efficiently and effectively segments objects without the need for human annotations. Firstly, a MultiCut algorithm is applied to self-supervised features for coarse mask segmentation. Then, a mask filter is employed to obtain high-quality coarse masks. To train the segmentation network, we compute a novel superpixel-guided mask loss, comprising hard loss and soft loss, with high-quality coarse masks and superpixels segmented from low-level image features. Lastly, a self-training process with a new adaptive loss is proposed to improve the quality of predicted masks. We conduct experiments on public datasets in instance segmentation and object detection to demonstrate the effectiveness of the proposed framework. The results show that the proposed framework outperforms previous state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Cuong Manh Hoang},
  doi          = {10.1016/j.patcog.2025.112402},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112402},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised instance segmentation with superpixels},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MIGF-net: Multimodal interaction-guided fusion network for image aesthetics assessment. <em>PR</em>, <em>172</em>, 112401. (<a href='https://doi.org/10.1016/j.patcog.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of social media, people like to post images and comments to share their ideas, which provides rich visual and textural semantic information for image aesthetics assessment (IAA). However, most previous works either extracted the unimodal aesthetic features from image due to the difficulty of obtaining comments, or combined multimodal information together but ignoring the interactive relationship between image and comment, which limits the overall performance. To solve the above problem, we propose a Multimodal Interaction-Guided Fusion Network (MIGF-Net) for image aesthetics assessment based on both image and comment semantic information, which can not only solve the challenge of comment generating, but also provide the multimodal feature interactive information. Specifically, considering the coupling mechanism of the image theme, we construct a visual semantic fusion module to extract the visual semantic feature based on the visual attributes and the theme features. Then, a textural semantic feature extractor is designed to mine the semantic information hidden in comments, which not only addresses the issue of missing comments but also effectively complements the visual semantic features. Furthermore, we establish a Dual-Stream Interaction-Guided Fusion module to fuse the semantic features of images and comments, fully exploring the interactive relationship between images and comments in the human brain’s perception mechanism. Experimental results on two public image aesthetics evaluation datasets demonstrate that our model outperforms the current state-of-the-art methods. Our code will be released at https://github.com/wenzhipeng123/MIGF-Net .},
  archive      = {J_PR},
  author       = {Yun Liu and Zhipeng Wen and Leida Li and Peiguang Jing and Daoxin Fan},
  doi          = {10.1016/j.patcog.2025.112401},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112401},
  shortjournal = {Pattern Recognition},
  title        = {MIGF-net: Multimodal interaction-guided fusion network for image aesthetics assessment},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IRIS: An information path planning method based on reinforcement learning and information-directed sampling. <em>PR</em>, <em>172</em>, 112400. (<a href='https://doi.org/10.1016/j.patcog.2025.112400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information Path Planning (IPP) is a critical aspect of robotics, aimed at intelligently selecting information-rich paths to optimize robot trajectories and significantly enhance the efficiency and quality of data collection. However, in the process of maximizing information acquisition, IPP must also account for energy consumption, time constraints, and physical obstacles, which often lead to inefficiencies. To address these challenges, we propose an Information Path Planning method based on Reinforcement Learning and Information-Directed Sampling (IRIS). This model is the first to integrate Reinforcement Learning (RL) with Information-Directed Sampling (IDS), ensuring both immediate rewards and the potential for greater information gain through exploratory actions. IRIS employs an off-policy deep reinforcement learning framework, effectively overcoming the limitations observed in on-policy methods, thereby enhancing the model’s adaptability and efficiency. Simulation results demonstrate that the IRIS algorithm performs exceptionally well across various IPP scenarios. Once training stabilizes, IDS will dominate decision-making with a probability of approximately 1.3 % to yield better outcomes, highlighting its significant potential in this field. The relevant code is available at https://github.com/SUTLZY/IRIS .},
  archive      = {J_PR},
  author       = {Ziyuan Liu and Yan Zhuang and Peng Wu and Yuanchang Liu},
  doi          = {10.1016/j.patcog.2025.112400},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112400},
  shortjournal = {Pattern Recognition},
  title        = {IRIS: An information path planning method based on reinforcement learning and information-directed sampling},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge tailoring: Bridging the teacher-student gap in semantic segmentation. <em>PR</em>, <em>172</em>, 112399. (<a href='https://doi.org/10.1016/j.patcog.2025.112399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation transfers knowledge from a high-capacity teacher network to a compact student network, but a large capacity gap often limits the student’s ability to fully benefit from the teacher’s guidance. In semantic segmentation, another major challenge is the difficulty in predicting accurate object boundaries, as even strong teacher models can produce ambiguous or imprecise outputs. To address both challenges, we present Knowledge Tailoring, a novel distillation framework that adapts the teacher’s knowledge to better match the student’s representational capacity and learning dynamics. Much like a tailor adjusts an oversized suit to fit the wearer’s shape, our method reshapes the teacher’s abundant but misaligned knowledge into a form more suitable for the student. KT introduces feature tailoring, which restructures intermediate features based on channel-wise correlation to narrow the representation gap, and logit tailoring, which improves boundary prediction by refining class-specific logits. The tailoring strategy evolves throughout training, offering guidance that aligns with the student’s progress. Experiments on Cityscapes, Pascal VOC, and ADE20K confirm that KT consistently enhances performance across a variety of architectures including DeepLabV3, PSPNet, and SegFormer. Our code is available for https://github.com/seok-hwa/KT .},
  archive      = {J_PR},
  author       = {Seokhwa Cheung and Seungbeom Woo and Taehoon Kim and Wonjun Hwang},
  doi          = {10.1016/j.patcog.2025.112399},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112399},
  shortjournal = {Pattern Recognition},
  title        = {Knowledge tailoring: Bridging the teacher-student gap in semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Understanding and tackling the modality imbalance problem in multimodal survival prediction. <em>PR</em>, <em>172</em>, 112398. (<a href='https://doi.org/10.1016/j.patcog.2025.112398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the in-depth integration of multimodal data, survival prediction has emerged as a pivotal task in cancer prognosis by facilitating personalized treatment planning and medical resource allocation. In this study, we report an intriguing phenomenon of inter-modality capability gap (ICG) enlargement during joint survival modelling of genomics data and pathology images. This observation, supported by our dedicated theoretical analysis, uncovers a previously unrecognized modality imbalance problem, where pathology modality suffers from limited gradient propagation and insufficient learning while genomics modality dominates in reducing survival loss. To tackle this problem, we further propose a balanced multimodal learning approach for survival prediction named BMLSurv, which introduces two innovative auxiliary learning strategies: self-enhancement learning (SEL) and peer-assistance learning (PAL). The SEL strategy exploits a real-time imbalance measure to guide extra task-aware supervision, therefore dynamically strengthening pathology-specific gradient propagation in a self-enhanced manner. Meanwhile, the PAL strategy leverages the stronger genomics modality as a “helpful peer” to assist the sufficient learning of pathology modality via a new risk-ranking distillation technique. Extensive experiments on representative cancer datasets demonstrate that by successfully address the modality imbalance problem, BMLSurv remarkably narrows the ICG in joint survival modelling and consistently outperforms state-of-the-art methods by a large margin. These results underscore the potential of BMLSurv to advance multimodal survival prediction and enhance clinical decision-making in cancer prognosis.},
  archive      = {J_PR},
  author       = {Chicheng Zhou and Minghui Wang and Yi Shi and Anli Zhang and Ao Li},
  doi          = {10.1016/j.patcog.2025.112398},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112398},
  shortjournal = {Pattern Recognition},
  title        = {Understanding and tackling the modality imbalance problem in multimodal survival prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hyper-network curvature: A new representation method for high-order brain network analysis. <em>PR</em>, <em>172</em>, 112397. (<a href='https://doi.org/10.1016/j.patcog.2025.112397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human brain is a complex system and contains abundant high-order interactions among multiple brain regions, which can be described by brain hyper-network. In brain hyper-networks, nodes represent brain regions of interest (ROIs), while edges describe the interactions of multiple ROIs, providing important high-order information for brain disease analysis and diagnosis. However, most of the existing hyper-network studies focused on the hyper-connection (i.e. hyper-edge) analysis and ignored the local topological information on nodes. To address this problem, we propose a new representation method (i.e., hyper-network curvature) for brain hyper-network analysis. Compared with the existing hyper-network representation methods, the proposed hyper-network curvature can be used to analyze the local topologies of nodes in brain hyper-networks. Based on hyper-network curvature, we further propose a novel graph kernel called brain hyper-network curvature kernel to measure the similarity of a pair of brain hyper-networks. We have proved that the proposed hyper-network curvature is bounded and brain hyper-network curvature kernel is positive definite. To evaluate the effectiveness of our proposed method, we perform the classification experiments on functional magnetic resonance imaging data of brain diseases. The experimental results demonstrate that our proposed method can significantly improve classification accuracy compared to the state-of-the-art graph kernels and graph neural networks for classifying brain diseases.},
  archive      = {J_PR},
  author       = {Kai Ma and Tianyu Du and Qi Zhu and Xuyun Wen and Jiashuang Huang and Xibei Yang and Daoqiang Zhang},
  doi          = {10.1016/j.patcog.2025.112397},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112397},
  shortjournal = {Pattern Recognition},
  title        = {Hyper-network curvature: A new representation method for high-order brain network analysis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated cross-source learning for lung nodule segmentation with data characteristic-aware weight optimization. <em>PR</em>, <em>172</em>, 112396. (<a href='https://doi.org/10.1016/j.patcog.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning enables multiple medical institutions to undertake distributed training while protecting patient privacy. Nevertheless, the significant variance in data distributions across diverse sites results in imbalanced knowledge acquisition, thereby affecting the performance of the global model. To tackle this challenge, we propose a novel federated algorithm for lung nodule segmentation, incorporating a Cross-source Learning (CSL) method. This method generates pseudo nodules by synthesizing the nodule phase spectrum with the nodule amplitude spectrum from other clients. These pseudo nodules are subsequently embedded into pulmonary regions to augment the data. By incorporating knowledge from various clients, which alleviates the challenges posed by non-IID data. On the server side, a Data Characteristic-aware Weight Optimization (DCWO) method is proposed to incorporate client data quality assessment and the size of lung nodule volume as weights to optimize both model performance and fairness. On the client side, we design a Multi-scale Attention Dynamic Convolution (MADC) lightweight network, which dynamically adapts attention to different spatial regions and extracts features at multiple scales. The performance of our method is superior to the state-of-the-art methods on six public and in-house CT datasets of lung cancer.},
  archive      = {J_PR},
  author       = {Xinjun Bian and Huan Lin and Yumeng Wang and Lingqiao Li and Zhenbing Liu and Huadeng Wang and Zhenwei Shi and Yi Qian and Zaiyi Liu and Rushi Lan and Xipeng Pan},
  doi          = {10.1016/j.patcog.2025.112396},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112396},
  shortjournal = {Pattern Recognition},
  title        = {Federated cross-source learning for lung nodule segmentation with data characteristic-aware weight optimization},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint luminance-chrominance learning for quality assessment of low-light image enhancement. <em>PR</em>, <em>172</em>, 112395. (<a href='https://doi.org/10.1016/j.patcog.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods for low-light enhancement quality assessment (LEQA) often underperform across diverse scenarios. One reason is that most of them rely on shallow feature respresentations, while another is that deep-learning-based counterparts fail to make full use of the unique characteristics of low-light enhanced images (LEIs), such as luminance enhancement and color refinement. In this paper, we propose a novel Joint Luminance-Chrominance Learning Network (JLCLNet) for LEQA to comprehensively assess the effects of low-light image enhancement (LLIE) algorithms. Specifically, we construct a two-branch network architecture consisting of a luminance learning branch and a chrominance learning branch. In the luminance learning branch, the low- and high-frequency subbands of the luminance channel in the CIELAB color space, derived from the dual-tree complex wavelet transform (DTCWT), focus on measuring contrast enhancement and structure preservation. Meanwhile, the chrominance learning branch addresses potential color distortions by integrating perceptual information from the two parallel chrominance channels of the CIELAB color space. Finally, the complementary features from both branches are fused to predict quality scores. Experimental results on four public LEQA databases demonstrate the performance advantages of the proposed method compared to the state-of-the-art approaches. The source code of JLCLNet is available at https://github.com/li181119/JLCLNET .},
  archive      = {J_PR},
  author       = {Tuxin Guan and Qiuping Jiang and Xiongli Chai and Chaofeng Li},
  doi          = {10.1016/j.patcog.2025.112395},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112395},
  shortjournal = {Pattern Recognition},
  title        = {Joint luminance-chrominance learning for quality assessment of low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A graph contrastive learning network for change detection with heterogeneous remote sensing images. <em>PR</em>, <em>172</em>, 112394. (<a href='https://doi.org/10.1016/j.patcog.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land cover change detection (LCCD) with heterogeneous remote sensing images (Hete-RSIs) is an attractive topic in the community of remote sensing applications. Intuitively, Hete-RSIs are acquired with different remote sensors, and they cannot be compared directly for LCCD because of the different imaging modalities. In this paper, a graph contrastive learning network (GCLN) is proposed for LCCD with bitemporal Hete-RSIs. First, with the motivation of smoothing the noise and utilizing contextual information, the k-nearest neighbor algorithm is used to improve the spectral homogeneity of the pixels within a superpixel. Then, a pairwise graph is constructed on the basis of each superpixel from spectral similarity and dissimilarity perspectives, and a graph feature learning network is designed to learn the near-far dependencies of graph features for change detection. Finally, the similarity and dissimilarity loss functions are coupled as a contrastive loss function to expand the difference between similar and dissimilar features. Comparisons with seven advanced methods on five pairs of Hete-RSIs demonstrate the feasibility and superiority of the proposed GCLN for LCCD with Hete-RSIs. For example, the improvements on the five datasets are 3.63 % , 8.47 % , 4.17 % , 8.23 % , and 4.98 % in terms of overall accuracy. The code of the proposed approach can be available at: https://github.com/ImgSciGroup/2024-GCLN .},
  archive      = {J_PR},
  author       = {Zhiyong Lv and Sizhe Cheng and Linfu Xie and Junhuai Li and Minghua Zhao},
  doi          = {10.1016/j.patcog.2025.112394},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112394},
  shortjournal = {Pattern Recognition},
  title        = {A graph contrastive learning network for change detection with heterogeneous remote sensing images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AM40: Enhancing action recognition through matting-driven interaction analysis. <em>PR</em>, <em>172</em>, 112393. (<a href='https://doi.org/10.1016/j.patcog.2025.112393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition models frequently face challenges from complex video backgrounds, where actors may blend into their surroundings and complicate motion analysis. Human interactions with action-related elements vary across scenarios, with backgrounds serving as both contextual cues and sources of interference. To address these issues, we introduce video matting techniques to separate foreground subjects from the background. This enables the model to focus on the subject of interest while suppressing irrelevant regions, thereby enhancing the extraction of interactions between the subject and associated objects. To support this methodology, we present ActionMatting40 ( AM40 ) dataset, which comprises 40 action categories annotated with alpha mattes to distinguish human actions and related objects from the background. Furthermore, we propose Matting-Driven Interaction Recognition (MIR), integrating an Action Background Decoupling (ABD) module to mitigate background interference and a Semantic-aware Feature Communication (SFC) module to selectively extract informative features for improved action recognition. Our code and dataset are publicly available at https://github.com/lwxfight/actionmatting .},
  archive      = {J_PR},
  author       = {Siqi Liang and Wenxuan Liu and Zhe Li and Kui Jiang and Siyuan Yang and Chia-Wen Lin and Xian Zhong},
  doi          = {10.1016/j.patcog.2025.112393},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112393},
  shortjournal = {Pattern Recognition},
  title        = {AM40: Enhancing action recognition through matting-driven interaction analysis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Edge craft odyssey: Navigating guided super-resolution with a fast, precise, and lightweight network. <em>PR</em>, <em>172</em>, 112392. (<a href='https://doi.org/10.1016/j.patcog.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal imaging technology is exceptionally valuable in environments where visibility is limited or nonexistent. However, the high cost and technological limitations of high-resolution thermal imaging sensors restrict their widespread use. Many thermal cameras are now paired with high-resolution visible cameras, which can help improve low-resolution thermal images. However, aligning thermal and visible images is challenging due to differences in their spectral ranges, making pixel-wise alignment difficult. Therefore, we present the Edge Craft Odyssey Network (ECONet), a lightweight transformer-based network designed for Guided Thermal Super-Resolution (GTSR) to address these challenges. Our approach introduces a Progressive Edge Prediction module that extracts edge features from visible images using an adaptive threshold within our innovative Edge-Weighted Gradient Blending technique. This technique provides precise control over the blending intensity between low-resolution thermal and visible images. Additionally, we introduce a lightweight Cascade Deep Feature Extractor that focuses on efficient feature extraction and edge weight highlighting, enhancing the representation of high-frequency details. Experimental results show that ECONet outperforms state-of-the-art methods across various datasets while maintaining a relatively low computational and memory requirements. ECONet improves performance by up to 0.20 to 1.3 dB over existing methods and generates super-resolved images in a fraction of a second, approximately 91 % faster than the other methods. The code is available at https://github.com/Rm1n90/ECONet .},
  archive      = {J_PR},
  author       = {Armin Mehri and Parichehr Behjati and Dario Carpio and Angel D. Sappa},
  doi          = {10.1016/j.patcog.2025.112392},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112392},
  shortjournal = {Pattern Recognition},
  title        = {Edge craft odyssey: Navigating guided super-resolution with a fast, precise, and lightweight network},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models. <em>PR</em>, <em>172</em>, 112391. (<a href='https://doi.org/10.1016/j.patcog.2025.112391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent vulnerabilities of large Vision-Language Models (VLMs), security governance has emerged as a critical concern, particularly given the risks posed by noisy and biased training data as well as adversarial attacks, including data poisoning and prompt injection. These perturbations can significantly degrade model performance and introduce multifaceted societal risks. To verify the safe robustness of VLMs and further inspire the design of defensive AI frameworks, we propose Virtual Scenario Hypnosis (VSH), a multimodal prompt injection jailbreak method that embeds malicious queries into prompts through a deceptive narrative framework. This approach strategically distracts the model while compromising its resistance to jailbreak attempts. Our methodology features two key innovations: 1) Targeted adversarial image prompts that transform textual content into visual layouts through optimized typographic designs, circumventing safety alignment mechanisms to elicit harmful responses; and 2) An information veil encrypted In-Context Learning (ICL) method for text prompts that systematically evades safety detection protocols. To streamline evaluation, we employ Large Language Models (LLMs) to facilitate an efficient assessment of jailbreak success rates, supported by a meticulously designed prompt template incorporating multi-dimensional scoring rules and evaluation metrics. Extensive experiments demonstrate the efficacy of VSH, achieving an overall success rate exceeding 82% on 500 harmful queries spanning multiple domains when tested against LLaVA-v1.5-13B and GPT-4o mini.},
  archive      = {J_PR},
  author       = {Xiayang Shi and Shangfeng Chen and Gang Zhang and Wei Wei and Yinlin Li and Zhaoxin Fan and Jingjing Liu},
  doi          = {10.1016/j.patcog.2025.112391},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112391},
  shortjournal = {Pattern Recognition},
  title        = {Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A locality-sensitive hashing based instance selection method with its application to acceleration of feature selection. <em>PR</em>, <em>172</em>, 112390. (<a href='https://doi.org/10.1016/j.patcog.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of important data preprocessing techniques, feature selection aims to remove redundant and irrelevant features and has been extensively applied to many fields. At present, however, the evaluation of existing feature selection algorithms focuses mainly on the scale of the selected features and the performance of models formulated by the selected features, while the running time of feature selection algorithms is usually neglected. It is noted that the computation complexity of the majority of feature selection algorithms is the square order of the number of instances, resulting in an exponential increase of the running time for large-scale data. In this paper, we propose an algorithm of core instance selection based on the locality-sensitive hashing (CISLSH) to improve the computation efficiency of feature selection algorithms by alleviating the instances used for feature selection. Specifically, all the instances are firstly considered to map them into the one-dimensional integer space using a locality-sensitive hashing (LSH) function. Given a set of hash functions families, a bucket index matrix is constructed to integrate all the mapping results of the set of hash functions families. Then, a voting mechanism is designed according to the bucket index matrix, which motivates to present a novel data partitioning method dividing similar instances into the same bucket (partition) as many as possible. Furthermore, the CISLSH algorithm is developed by selecting a core instance from each non-empty bucket. Finally, numerical experiments are conducted to assess the performance of CISLSH. The experimental results show that the execution of feature selection using the representative instances selected by CISLSH can not only significantly reduce the running time of feature selection but also guarantee the effectiveness of the selected features.},
  archive      = {J_PR},
  author       = {Fan Song and Xiao Zhang and Jinhai Li and Changlin Mei},
  doi          = {10.1016/j.patcog.2025.112390},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112390},
  shortjournal = {Pattern Recognition},
  title        = {A locality-sensitive hashing based instance selection method with its application to acceleration of feature selection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive latent disease state learning for multimodal alzheimer’s disease biomarker detection with missing modalities. <em>PR</em>, <em>172</em>, 112389. (<a href='https://doi.org/10.1016/j.patcog.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal neuroimaging genetics is a crucial approach for identifying biomarkers of Alzheimer’s disease (AD) by leveraging the inherent relationships between genetic and neuroimaging data. However, existing methods are limited by susceptibility to input noises, underutilization of complementary information across neuroimaging modalities, and ineffective handling of samples with incomplete modalities. To address these challenges, we propose an Adaptive Latent Disease State Learning (ALDSL) method, which integrates noise reduction, latent space learning, adaptive regularization, and feature selection into a unified framework for detecting AD biomarkers from incomplete multimodal data. ALDSL introduces a noise reduction strategy based on inter-variable correlations and tailored distance metrics to eliminate noises in the input data, thereby obtaining high-quality representations for each modality. Additionally, latent disease state learning with adaptive regularization is proposed to capture inter-modality correlations by projecting the high-quality representations from multiple modalities into a common latent space. To utilize samples with incomplete modalities, we design a modality-specific weight matrix that accounts for the missing information in the latent disease state learning. Furthermore, an adaptive weighting determination strategy is developed to ensure that the modalities with different data types and varying sample sizes contribute on the same scale. We develop an efficient alternating optimization algorithm to solve the objective function of ALDSL. Experimental results on synthetic datasets and the ADNI GO/2 dataset demonstrate the effectiveness of ALDSL in detecting AD biomarkers.},
  archive      = {J_PR},
  author       = {Zhi Chen and Fengli Zhang and Yun Zhang and Jiajing Zhu and Qiaoqin Li and Yongguo Liu},
  doi          = {10.1016/j.patcog.2025.112389},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112389},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive latent disease state learning for multimodal alzheimer’s disease biomarker detection with missing modalities},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MMP: Enhancing unsupervised graph anomaly detection with multi-view message passing. <em>PR</em>, <em>172</em>, 112388. (<a href='https://doi.org/10.1016/j.patcog.2025.112388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complementary and conflicting relationships between views are two fundamental issues when applying Graph Neural Networks (GNNs) to multi-view attributed graph anomaly detection. Most existing approaches do not address the inherent multi-view properties in the attribute space or leverage complementary information through simple representation fusion, which overlooks the conflicting information among different views. In this paper, we argue that effectively applying GNNs to multi-view anomaly detection necessitates reinforcing complementary information between views and, more importantly, managing conflicting information. Building on this perspective, this paper introduces Multi-View Message Passing (MMP), a novel and effective message passing paradigm specifically designed for multi-view anomaly detection. In the multi-view aggregation phase of MMP, views containing different types of information are integrated using view-specific aggregation functions. This approach enables the model to dynamically adjust the amount of information aggregated from complementary and conflicting views, thereby mitigating issues arising from insufficient complementary information and excessive conflicting information, which can lead to suboptimal representation learning. Furthermore, we propose an innovative aggregation loss mechanism that enhances model performance by optimizing the reconstruction differences between aggregated representations and the original views, thereby improving both detection accuracy and model interpretability. Extensive experiments on synthetic and real-world datasets validate the effectiveness and robustness of our method. The source code is available at https://github.com/weihus/MMP .},
  archive      = {J_PR},
  author       = {Weihu Song and Lei Li and Mengxiao Zhu and Yue Pei and Haogang Zhu},
  doi          = {10.1016/j.patcog.2025.112388},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112388},
  shortjournal = {Pattern Recognition},
  title        = {MMP: Enhancing unsupervised graph anomaly detection with multi-view message passing},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HopGAT: A multi-hop graph attention network with heterophily and degree awareness. <em>PR</em>, <em>172</em>, 112387. (<a href='https://doi.org/10.1016/j.patcog.2025.112387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In highly heterophilic graphs, where nodes frequently connect across categories, the attention learning mechanism by dynamically adjusting neighboring node weights, may struggle to capture intricate node relationships. Furthermore, first-hop neighbor information is usually insufficient to encompass the global structure, but multi-hop increases complexity. To address these challenges, we propose HopGAT, a multi-hop graph attention network with heterophily and degree awareness. Firstly, we design heterophily-based neighbor sampling to sequentially filter high-hop neighbors by degree. Next, to obtain comprehensive global information, we construct a multi-hop recursive learning method with head and tail attention vectors to learn multi-hop neighbor features. Finally, we combine the average node degree of the graph with hop decay modeling to learn importance coefficients at different hops and adaptively aggregate the learned multi-hop features. Experimental results demonstrate that HopGAT significantly improves performance across 9 benchmark datasets with various heterophily and different average degrees.},
  archive      = {J_PR},
  author       = {Han Zhang and Huan Wang and Mingjing Han},
  doi          = {10.1016/j.patcog.2025.112387},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112387},
  shortjournal = {Pattern Recognition},
  title        = {HopGAT: A multi-hop graph attention network with heterophily and degree awareness},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A boundary-enhanced and target-driven deformable convolutional network for abdominal multi-organ segmentation. <em>PR</em>, <em>172</em>, 112386. (<a href='https://doi.org/10.1016/j.patcog.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to accurately segment organs from abdominal CT images for clinical diagnosis, treatment planning, and surgical guidance, which remains an extremely challenging task due to low contrast between organs and surrounding tissues and the difference of organ size and shape. Previous works mainly focused on complex network architectures or task-specific modules but frequently failed to learn irregular boundaries and did not consider that different slices from the same case might contain targets of different numbers of categories. To tackle these issues, this paper proposes UAMSNet for abdominal multi-organ segmentation. In UAMSNet, a hybrid receptive field extraction (HRFE) module is introduced to adaptively learn the features of irregular targets, which has an adaptive dilation factor containing distance information to facilitate spatial and channel attention. The HRFE module can simultaneously learn multiple scales and deformations of different organs. Furthermore, a multi-organ boundary-enhanced attention (MBA) module in the encoder and decoder is designed to provide effective boundary information for feature extraction based on the large peak of the organ edge. Finally, the difference in the number of organ categories between different slices is first considered using a loss function, which can adjust the loss computation based on organ categories in the image. The loss function mitigates the effect of false positives during training to ensure the model can adapt to small organ segmentation. Experimental results on WORD and Synapse datasets demonstrate that our UAMSNet outperforms the existing state-of-the-art methods. Ablation experiments confirm the effectiveness of our designed modules and loss function. Our code is publicly available on https://github.com/HeyJGJu/UAMSNet .},
  archive      = {J_PR},
  author       = {Jianguo Ju and Menghao Liu and Wenhuan Song and Tongtong Zhang and Jindong Liu and Pengfei Xu and Ziyu Guan},
  doi          = {10.1016/j.patcog.2025.112386},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112386},
  shortjournal = {Pattern Recognition},
  title        = {A boundary-enhanced and target-driven deformable convolutional network for abdominal multi-organ segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distantly supervised reinforcement localization for real-world object distribution estimation. <em>PR</em>, <em>172</em>, 112385. (<a href='https://doi.org/10.1016/j.patcog.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the distribution of objects in the real world from monocular images is a challenging task due to the disparity between object distributions in perspective images and reality. Many researchers focus on predicting object distributions by converting perspective images into Bird’s-Eye View (BEV) images. In scenarios where camera parameter information is unavailable, the prediction of vanishing lines becomes critical for performing inverse perspective transformations. However, accurately predicting vanishing lines necessitates accounting for variations in object size, which cannot be effectively captured through simple regression models. Therefore, this paper proposes a size variation-aware method, utilizing expert knowledge from object detection to build a reinforcement learning framework for predicting vanishing lines in traffic scenes. Specifically, this method leverages size information from trained detectors to convert perspective images into BEV images without the need for additional camera intrinsic parameters. First, we design a novel reward mechanism that utilizes prior knowledge of scale differences between similar objects in perspective images, allowing the network to automatically update and learn specific vanishing line positions. Second, we propose a fast inverse perspective transformation method, which accelerates the training speed of the proposed approach. To evaluate the effectiveness of the method, experiments are conducted on two traffic flow datasets. The experimental results demonstrate that the proposed algorithm accurately predicts vanishing line positions and successfully transforms perspective images into BEV images. Furthermore, the proposed algorithm performs competitively with directly supervised methods. The code is available at: https://github.com/HotChieh/DDRL.},
  archive      = {J_PR},
  author       = {Haojie Guo and Junyu Gao and Yuan Yuan},
  doi          = {10.1016/j.patcog.2025.112385},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112385},
  shortjournal = {Pattern Recognition},
  title        = {Distantly supervised reinforcement localization for real-world object distribution estimation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A variable gaussian kernel scale active contour model based on jeffreys divergence for ICT image segmentation. <em>PR</em>, <em>172</em>, 112384. (<a href='https://doi.org/10.1016/j.patcog.2025.112384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial computed tomography (ICT), factors like beam scattering, insufficient beam intensity, and detector dark current often lead to weak edges, scattering artifacts, and severe Gaussian noise in ICT images. These issues pose significant difficulties for accurate segmentation of high-density complex structures using existing active contour models (ACMs). To address these limitations, this paper presents a variable Gaussian kernel scale active contour model based on Jeffreys divergence (VGJD). Firstly, the Jeffreys divergence (JD) is incorporated into the energy function to replace the conventional Euclidean distance, enhancing the contour’s ability to quantify pixel value disparity during evolution. Additionally, a filter weight is introduced to minimize the impact of noise. Moreover, a variable Gaussian kernel scale strategy is adopted to effectively integrate both global and local image information, thereby enhancing the robustness of the initial contour and improving the precision of detail segmentation. Finally, optimized length and regularity terms are employed to enforce constraints on the level set function. Extensive experimental results demonstrate that the VGJD model can effectively segment various complex ICT images, achieving superior precision in comparison to other ACM models. The code is available at https://github.com/LiuZX599/ACM-VGJD.git},
  archive      = {J_PR},
  author       = {Zexin Liu and Qi Li and Junyao Wang and Tingyuan Deng and Rifeng Zhou and Yufang Cai and Fenglin Liu},
  doi          = {10.1016/j.patcog.2025.112384},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112384},
  shortjournal = {Pattern Recognition},
  title        = {A variable gaussian kernel scale active contour model based on jeffreys divergence for ICT image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust spatio-temporal graph neural networks with sparse structure learning. <em>PR</em>, <em>172</em>, 112383. (<a href='https://doi.org/10.1016/j.patcog.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of spatio-temporal graph classification by introducing sparse structure learning to enhance its robustness and explainability. Spatio-temporal graph neural networks (STGNN) integrate spatial structure and temporal sequential features into GNN learning, resulting in promising performance in many applications. However, current STGNN models often fail to capture the discriminative sparse substructure and the smooth distribution of these samples. To this end, this paper introduces RostGNN, robust spatio-temporal graph neural networks, for achieving more discriminative graph representations. Concretely, RostGNN extracts the spatial and temporal features by performing gated recurrent units on the given time series data and calculating adjacent matrixes for graphs. Then, we impose the iterative hard-thresholding approach on the final association matrix to obtain a sparse graph. Meanwhile, we calculate a similarity matrix from the side information of samples to smooth the achieved data representations and use fully connected networks for graph classification. We finally applied RostGNN to brain graph classification in experiments on real-world datasets. The results demonstrate that RostGNN delivers robust and discriminative graph representations and performs better than compared methods, benefiting from the sparsity and manifold regularizers. Furthermore, RostGNN can potentially yield useful findings for data understanding.},
  archive      = {J_PR},
  author       = {Yupei Zhang and Yuxin Li and Shuhui Liu and Xuequn Shang},
  doi          = {10.1016/j.patcog.2025.112383},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112383},
  shortjournal = {Pattern Recognition},
  title        = {Robust spatio-temporal graph neural networks with sparse structure learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiscDC: Unsupervised discriminative deep image clustering via confidence-driven self-labeling. <em>PR</em>, <em>172</em>, 112382. (<a href='https://doi.org/10.1016/j.patcog.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering, as an important research topic in machine learning and data mining, has been widely applied in many real-world scenarios. However, existing deep clustering methods primarily rely on implicit optimization objectives such as contrastive learning or reconstruction, which do not explicitly enforce cluster-level discrimination. This limitation restricts their ability to achieve compact intra-cluster structures and distinct inter-cluster separations. To overcome this limitation, we propose a novel unsupervised discriminative deep clustering (discDC) method, which explicitly integrates cluster-level discrimination into the learning process. The proposed discDC framework projects data into a nonlinear latent space with compact and well-separated cluster representations. It explicitly optimizes clustering objectives by minimizing intra-cluster discrepancy and maximizing inter-cluster discrepancy. Additionally, to tackle the lack of label information in unsupervised scenarios, we introduce a confidence-driven self-labeling mechanism, which iteratively derives reliable pseudo-labels to enhance discriminative analysis. Extensive experiments on five benchmark datasets demonstrate the superiority of discDC over state-of-the-art deep clustering approaches.},
  archive      = {J_PR},
  author       = {Jinyu Cai and Wenzhong Guo and Yunhe Zhang and Jicong Fan},
  doi          = {10.1016/j.patcog.2025.112382},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112382},
  shortjournal = {Pattern Recognition},
  title        = {DiscDC: Unsupervised discriminative deep image clustering via confidence-driven self-labeling},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MCoCa: Towards fine-grained multimodal control in image captioning. <em>PR</em>, <em>172</em>, 112381. (<a href='https://doi.org/10.1016/j.patcog.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controllable image captioning (CIC) models have traditionally focused on generating controlled descriptions using specific text styles. However, these approaches are limited as they rely solely on text control signals, which often fail to align with complex human intentions, such as selecting specific areas in images. To enhance multimodal interactivity, we propose to augment current CIC systems with diverse and joint visual-text controls. To achieve this, we first create a comprehensive Multimodal Controllable Image Captioning Corpus (MCoCa) dataset by leveraging language rewriting ability of GPT-3.5, containing 0.97M image-captions pairs along with 21 visual-text control signals. By training the visual and textual adapters equipped on the multimodal large language model with newly proposed instructional prompts on MCoCa, we observe emergent combinatory multimodal controllability and significant improvement in text controllability. We present exhaustive quantitative and qualitative results, benchmarking our trained model’s state-of-the-art zero-shot captioning performance on SentiCap and FlickrStyle10K in terms of both fidelity and controllability. For regional understanding ability of visual-controlled captioning, our method achieves obvious improvement compared with the baseline models.},
  archive      = {J_PR},
  author       = {Shanshan Zhao and Teng Wang and Jinrui Zhang and Xiangchen Wang and Feng Zheng},
  doi          = {10.1016/j.patcog.2025.112381},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112381},
  shortjournal = {Pattern Recognition},
  title        = {MCoCa: Towards fine-grained multimodal control in image captioning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning interpretable binary codes via semantic alignment for customized image retrieval. <em>PR</em>, <em>172</em>, 112380. (<a href='https://doi.org/10.1016/j.patcog.2025.112380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single modality hashing (SMH) has achieved impressive performance on image retrieval task in recent years. The only fly in the ointment is that most of the methods mainly measure the image similarity based on the high-level class labels. The retrieval needs in the real world are diverse in form of different subsets of the semantics (not only the category labels) presented in the query image. However, existing SMH methods fail to account for such customized image retrieval task that allows users to select visual semantics or their combinations present in the query and retrieve similar images based on such selected semantic descriptions. To address such practical issues, we propose a deep hashing to learn Interpretable Binary Codes (IBC), endowing the hashing bits with semantic interpretability rather than purely entangling the class information in the whole codes, i.e., aligning the criteria of binary space partition of each bit with a particular visual semantic concept. Specifically, binary encoding is a highly non-linear operation of dimension reduction, the semantic and spatial information of which has respectively been abstract and lost heavily. In light of the rich semantic interpretability and binary concept detection ability of convolutional filters, we innovatively transfer the semantic knowledge from filters to hashing bits by align the distributions of the binary codes and filter activations that capture the presence/absence of visual patterns in images. To further improve the semantics of filters/bits, the shared and learnable classification rules are introduced and optimized to disentangle the sparse composition between the category label and encoded semantics in filters/bits. With high interpretability, we can selectively combine bits corresponding to the target semantics during retrieval, thereby enabling flexible and customized similarity searches. Extensive experiments on several large-scale datasets covering general objects and scenes, single and multiple label scenarios, demonstrate the interpretability and functionalities of learned binary codes for the customized image retrieval tasks.},
  archive      = {J_PR},
  author       = {Shishi Qiao and Ruiping Wang and Xilin Chen},
  doi          = {10.1016/j.patcog.2025.112380},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112380},
  shortjournal = {Pattern Recognition},
  title        = {Learning interpretable binary codes via semantic alignment for customized image retrieval},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AFFusion: Atmospheric scattering enhancement and frequency integrated spatial-channel attention for infrared and visible image fusion. <em>PR</em>, <em>172</em>, 112379. (<a href='https://doi.org/10.1016/j.patcog.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) seeks to generate fused images that combine rich texture details with distinct thermal radiation features by integrating and leveraging complementary information from multiple sources. However, existing fusion methods frequently neglect the challenges posed by illumination degradation and inaccurate color contrast, which arise due to light energy loss and light scattering during atmospheric transmission. To address these limitations, this study introduces an innovative IVIF framework, termed AFFusion, which integrates an atmospheric scattering physical model with a frequency-domain feature component. By accurately predicting and estimating two key physical parameters-the transmission map and atmospheric light-within the scattering model, AFFusion harnesses atmospheric scattering principles to produce enhanced visible images, thereby mitigating the adverse effects of energy attenuation and scattering. Furthermore, to resolve artifacts and texture loss caused by traditional atmospheric scattering models, AFFusion incorporates Fourier transform in conjunction with spatial and channel attention mechanisms to selectively amplify amplitude and phase features in the frequency domain, thereby enhancing texture fidelity and detail representation within the fused images. Comprehensive experimental evaluations demonstrate that AFFusion surpasses state-of-the-art methods in both qualitative and quantitative performance metrics, while also providing robust support for high-level visual tasks. The implementation code is publicly accessible at https://github.com/cici0206/AFFusion .},
  archive      = {J_PR},
  author       = {Jiwei Hu and Chengcheng Song and Qiwen Jin and Kin-Man Lam},
  doi          = {10.1016/j.patcog.2025.112379},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112379},
  shortjournal = {Pattern Recognition},
  title        = {AFFusion: Atmospheric scattering enhancement and frequency integrated spatial-channel attention for infrared and visible image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Vision-by-prompt: Context-aware dual prompts for composed video retrieval. <em>PR</em>, <em>172</em>, 112378. (<a href='https://doi.org/10.1016/j.patcog.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composed video retrieval (CoVR) is a challenging task of retrieving relevant videos in a corpus by using a query that integrates both a relative change text and a reference video. Most existing CoVR models simply rely on the late-fusion strategy to combine visual and change text. Furthermore, various methods have been proposed to generate pseudo-word tokens from the reference video, which are then integrated into the relative change text for CoVR. However, these pseudo-word-based techniques exhibit limitations when the target video involves complex changes from the reference video, e.g. , object removal. In this work, we propose a novel CoVR framework that learns context information via context-aware dual prompts for relative change text to achieve effective composed video retrieval. The dual prompts cater to two aspects: 1) Global descriptive prompts generated from the pretrained V-L models, e.g. , BLIP-2, to get concise textual representations of the reference video. 2) Local target prompts to learn the target representations that the change text pays attention to. By connecting these prompts with relative change text, one can easily use existing text-to-video retrieval models to enhance CoVR performance. Our proposed framework can be flexibly used for both composed video retrieval (CoVR) and composed image retrieval (CoIR) tasks. Moreover, we take a pioneering approach by adopting the CoVR model to achieve zero-shot CoIR for remote sensing. Experiments on four datasets show that our approach achieves state-of-the-art performance in both CoVR and zero-shot CoIR tasks, with improvements of as high as around 3.5 % in terms of recall@K=1 score.},
  archive      = {J_PR},
  author       = {Hao Wang and Fang Liu and Licheng Jiao and Jiahao Wang and Shuo Li and Lingling Li and Puhua Chen and Xu Liu},
  doi          = {10.1016/j.patcog.2025.112378},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112378},
  shortjournal = {Pattern Recognition},
  title        = {Vision-by-prompt: Context-aware dual prompts for composed video retrieval},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient and compact tensor wheel decomposition for tensor completion. <em>PR</em>, <em>172</em>, 112377. (<a href='https://doi.org/10.1016/j.patcog.2025.112377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor wheel (TW) decomposition has recently emerged as a powerful technique for achieving state-of-the-art recovery performance in tensor completion tasks. However, its widespread application has been hindered by issues related to rank sensitivity and high computational cost. To address these limitations, we introduce an efficient and compact TW decomposition method for low-rank tensor completion. Specifically, we demonstrate that the model complexity of TW decomposition is controlled simultaneously by two elements, namely, the explicit TW rank and implicit sparsity in the core tensor. Therefore, low-rank and sparsity regularization are introduced to ring factors and core factor, respectively, to achieve a compact TW decomposition. Furthermore, to alleviate the computational bottleneck of TW decomposition, we propose a novel generalized inverse operation, which reduces the computational complexity of vanilla TW decomposition from O ( I N R 2 N ) to O ( I N R N ) . Subsequently, we develop an efficient alternating direction method of multipliers (ADMM) algorithm with theoretical convergence guarantees. Numerical tensor completion experiments on color images, multispectral images, and color videos demonstrate that the proposed method achieves superior performance while significantly reducing runtime compared to state-of-the-art methods. The code is available at: https://github.com/justicbro/TWLRS .},
  archive      = {J_PR},
  author       = {Peilin Yang and Yuning Qiu and Zhenhao Huang and Guoxu Zhou and Qibin Zhao},
  doi          = {10.1016/j.patcog.2025.112377},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112377},
  shortjournal = {Pattern Recognition},
  title        = {Efficient and compact tensor wheel decomposition for tensor completion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning to complement with multiple humans. <em>PR</em>, <em>172</em>, 112376. (<a href='https://doi.org/10.1016/j.patcog.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solution for addressing real-world image classification challenges. Human-AI collaborative classification (HAI-CC) aims to synergise the efficiency of machine learning classifiers and the reliability of human experts to support decision making. Learning to defer (L2D) has been one of the promising HAI-CC approaches, where the system assesses a sample and decides to defer to one of human experts when it is not confident. Despite recent progress, existing L2D methods rely on the strong assumption of ground truth label availability for training, while in practice, most datasets often contain multiple noisy annotations per data sample without well-curated ground truth labels. In addition, current L2D methods either consider the setting of a single human expert or defer the decision to one human expert, even though there may be multiple experts available, resulting in a suboptimal utilisation of available resources. Furthermore, current HAI-CC evaluation frameworks often overlook processing costs, making it difficult to assess the trade-off between computational efficiency and performance when benchmarking different methods. To address these gaps, this paper introduces LECOMH – a new HAI-CC method that learns from noisy labels without depending on clean labels for training, simultaneously maximising collaborative accuracy with either one or multiple human experts, while minimising the cost of human collaboration. The paper also introduces benchmarks featuring multiple noisy labels per data sample for both training and testing to evaluate HAI-CC methods. Through quantitative comparisons on these benchmarks, LECOMH consistently outperforms HAI-CC methods and baselines, including human experts alone, multi-rater learning and noisy-label learning methods across both synthetic and real-world datasets.},
  archive      = {J_PR},
  author       = {Zheng Zhang and Cuong Nguyen and Kevin Wells and Thanh-Toan Do and Gustavo Carneiro},
  doi          = {10.1016/j.patcog.2025.112376},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112376},
  shortjournal = {Pattern Recognition},
  title        = {Learning to complement with multiple humans},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-aware state-space method for underwater object detection. <em>PR</em>, <em>172</em>, 112375. (<a href='https://doi.org/10.1016/j.patcog.2025.112375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater Object Detection (UOD) faces significant challenges due to complex degradation factors, such as color shifts caused by light absorption and scattering, spatially varying noise induced by plankton and sea snow, and motion blur resulting from dynamic water currents. Among existing methods, Convolutional Neural Networks (CNNs) are limited by fixed receptive fields, making it difficult to model long-range noise patterns; while Transformers excel at modeling global dependencies, they suffer from high computational complexity and weak capability in restoring fine-grained local features. Neither can effectively address the demands of detecting underwater-specific noise and small objects. To tackle these issues, we propose UOD-Mamba, a state space model (SSM)-based framework for underwater object detection. At its core is the Noise-Aware Dual-path Mamba (NADM) module, which integrates a global-local dual-path fusion strategy to enable both long-range noise modeling and local feature enhancement. The global path balances noise in input features through the Noise-Balanced Preprocessing Module (NBPM) and leverages Mamba’s long-range modeling capability to extract global noise patterns; the local path fuses the Underwater Enhanced Multi-scale Attention Module (UEMA) with CSP convolution to model edge and detail features at a fine-grained level, thereby compensating for the loss of local information. By explicitly learning the distribution characteristics of underwater noise and capturing the differences between noise and target features, the framework enhances detection robustness in noisy environments. Experimental validation on the DUO and RUOD datasets demonstrates that UOD-Mamba sets a new state-of-the-art in detection performance. It also exhibits advantages in explicit modeling of diverse noises, preservation of local details, and computational efficiency across multi-noise scenarios, enabling effective handling of complex underwater interference environments.},
  archive      = {J_PR},
  author       = {Jingchun Zhou and Xudong Wang and Mingjie Li and Zongxin He and Wentian Xin and Xiuguo Zhang},
  doi          = {10.1016/j.patcog.2025.112375},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112375},
  shortjournal = {Pattern Recognition},
  title        = {Noise-aware state-space method for underwater object detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-domain-aware deep unfolding transformer for hyperspectral image super-resolution. <em>PR</em>, <em>172</em>, 112374. (<a href='https://doi.org/10.1016/j.patcog.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusing low-spatial-resolution hyperspectral images with high-spatial-resolution (HSR) multispectral images is pivotal for generating HSR hyperspectral images (HSR-HSIs). While current deep unrolling-based multi-stage frameworks have shown notable advancements due to their robustness and interpretability, they still exhibit limitations in adequately harnessing the HSI prior knowledge. This deficiency is principally attributed to three factors: (1) prior knowledge learned from training samples often overlooks target-specific characteristics; (2) insufficient feature representation within and across stages; and (3) insufficient modeling of spatial–spectral dependencies. To address these issues, we propose a novel Cross-domain-aware Transformer (CaFormer). Specifically, a cross-domain aware attention mechanism is investigated to capture intrinsic joint spatial–spectral dependencies through unified cross-domain feature representation. The attention mechanism models HSI eigenfeatures to derive spatial and spectral representations while preserving their mutual correlations. Furthermore, we introduce a Fourier Domain Perception Block to enhance structural and semantic representations by exploiting amplitude and phase components in the frequency domain, thereby strengthening feature aggregation across stages. To further improve adaptability while preserving the interpretability of deep unrolling networks, CaFormer employs a dual-stage prior learning strategy, transferring prior knowledge learned from general training data to the specific observed scene. Our experimental evaluations on four public datasets and Worldview-2 satellite images confirm that our proposed method outperformed eleven state-of-the-art methods. The code is available at https://github.com/Caoxuheng/HIFtool .},
  archive      = {J_PR},
  author       = {Xuheng Cao and Xuquan Wang and Xiong Dun and Yusheng Lian and Xinbin Cheng and Xiaopeng Hao},
  doi          = {10.1016/j.patcog.2025.112374},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112374},
  shortjournal = {Pattern Recognition},
  title        = {Cross-domain-aware deep unfolding transformer for hyperspectral image super-resolution},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-teacher self-distillation registration for multi-modality medical image fusion. <em>PR</em>, <em>172</em>, 112373. (<a href='https://doi.org/10.1016/j.patcog.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misaligned multimodal medical images pose challenges to the fusion task, resulting in structural distortions and edge artifacts in the fusion results. Existing registration networks primarily consider single-scale deformation fields at each stage, thereby neglecting long-range connections between non-adjacent stages. Moreover, in the fusion task, due to the quadratic computational complexity faced by Transformers during feature extraction, they are unable to effectively capture long-range correlated features. To address these problems, we propose an image registration and fusion method called DTMFusion. DTMFusion comprises two main networks: a Dual-Teacher Self-Distillation Registration (DTSDR) network and a Mamba-Conv-based Fusion (MCF) network. The registration network employs a pyramid progressive architecture to generate independent deformation fields at each layer. We introduce a dual-teacher self-distillation scheme that leverages past learning history and the current network structure as teacher guidance to constrain the generated deformation fields. For the fusion network, we introduced Mamba to address the quadratic complexity problem of Transformers. Specifically, the fusion network involves two key components: the Shallow Fusion Module (SFM) and the Cross-Modality Fusion Module (CFM). The SFM achieves lightweight cross-modality interaction through channel exchange, while the CFM leverages inherent cross-modality relationships to enhance the representation capability of fusion results. Through the collaborative effort of these components, the network can effectively integrate cross-modality complementary information and maintain appropriate apparent strength from a global perspective. Extensive experimental analysis demonstrates the superiority of this method in fusing misaligned medical images.},
  archive      = {J_PR},
  author       = {Aimei Dong and Jingyuan Xu and Long Wang},
  doi          = {10.1016/j.patcog.2025.112373},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112373},
  shortjournal = {Pattern Recognition},
  title        = {Dual-teacher self-distillation registration for multi-modality medical image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FSF-net: Enhance 4D occupancy forecasting with coarse BEV scene flow for autonomous driving. <em>PR</em>, <em>172</em>, 112372. (<a href='https://doi.org/10.1016/j.patcog.2025.112372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {4D occupancy forecasting is one of the important techniques for autonomous driving, which can avoid potential risk in the complex traffic scenes. Scene flow is a crucial element to describe 4D occupancy map tendency. However, an accurate scene flow is difficult to predict in the real scene. In this paper, we find that BEV scene flow can approximately represent 3D scene flow in most traffic scenes. And coarse BEV scene flow is easy to generate. Under this thought, we propose 4D occupancy forecasting method FSF-Net based on coarse BEV scene flow. At first, we develop a general occupancy forecasting architecture based on coarse BEV scene flow. Then, to further enhance 4D occupancy feature representation ability, we propose a vector quantized based Mamba (VQ-Mamba) network to mine spatial-temporal structural scene feature. After that, to effectively fuse coarse occupancy maps forecasted from BEV scene flow and latent features, we design a U-Net based quality fusion (UQF) network to generate the fine-grained forecasting result. Extensive experiments are conducted on public Occ3D dataset. FSF-Net has achieved IoU and mIoU 9.56 % and 10.87 % higher than state-of-the-art method. Hence, we believe that proposed FSF-Net benefits to the safety of autonomous driving.},
  archive      = {J_PR},
  author       = {Erxin Guo and Pei An and You Yang and Qiong Liu and An-An Liu},
  doi          = {10.1016/j.patcog.2025.112372},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112372},
  shortjournal = {Pattern Recognition},
  title        = {FSF-net: Enhance 4D occupancy forecasting with coarse BEV scene flow for autonomous driving},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel image enhancement method based on image decomposition and deep neural networks. <em>PR</em>, <em>172</em>, 112371. (<a href='https://doi.org/10.1016/j.patcog.2025.112371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image decomposition and deep learning are active research areas in computer vision tasks, such as cartoon texture decomposition, low-light image enhancement, rain streak removal, image recovery, etc. This paper proposes a novel low-light image enhancement method by joining image decomposition and deep neural network techniques. We introduce a new image decomposition-based optimization model by incorporating the Tikhonov regularization and multi-scale convolutional sparse coding (MSCSC) to enhance image visual effects. To enhance robustness performance, we introduce a noise-free image decomposition error term to effectively suppress noise in low-light images. To effectively implement the proposed method, we incorporate a deep-unfolding neural network and an adaptive denoiser into the alternating direction method of multipliers (ADMM) framework. Since the deep unfolding network can effectively simulate the optimization algorithm process, the interpretability of the network model is increased. Moreover, through end-to-end training, we can automatically estimate the two priors and parameter settings from training samples. Finally, qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art image enhancement methods in terms of visual quality and robustness. The source code is available at https://github.com/cassiopeia-yxx/LLIE .},
  archive      = {J_PR},
  author       = {Yao Xiao and Youshen Xia},
  doi          = {10.1016/j.patcog.2025.112371},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112371},
  shortjournal = {Pattern Recognition},
  title        = {A novel image enhancement method based on image decomposition and deep neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonuniform low-light image enhancement via noise-aware decomposition and adaptive correction. <em>PR</em>, <em>172</em>, 112370. (<a href='https://doi.org/10.1016/j.patcog.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-illumination conditions often exhibit low brightness with nonuniform distribution, low contrast, and noise, negatively affecting the human visual experience and the accuracy of image-based computer vision tasks. Enhancing nonuniform low-light images is challenging considering the requirement of simultaneously reducing noise, enhancing low-light regions, and suppressing high-light regions. To address these challenges, we innovatively propose a noise-aware decomposition and adaptive correction method (NDAC) to enhance the nonuniform low-light images without the need for paired high-quality training data. Specifically, a noise-aware image decomposition network (NIDNet) is first presented to decompose the input images into illumination, reflection, and noise components, while suppressing the noise in the reflection component through a variable gradient operator and estimating the noise component. Besides, we devise a novel nonlinear adaptive brightness mapping function (NABM), whose parameters are optimized via a designed automatic light enhancement network (ALENet) to brighten the illumination component. The enhancements are obtained by fusing the noiseless reflection component with the brightened illumination component. Extensive experiments on both public and industrial datasets demonstrate that the proposed NDAC method outperforms state-of-the-art approaches in both qualitative and quantitative evaluations.},
  archive      = {J_PR},
  author       = {Jiancai Huang and Zhaohui Jiang and Xingjian Liu and Yap-Peng Tan and Weihua Gui},
  doi          = {10.1016/j.patcog.2025.112370},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112370},
  shortjournal = {Pattern Recognition},
  title        = {Nonuniform low-light image enhancement via noise-aware decomposition and adaptive correction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fourier-enhanced semi-supervised proxy learning for ultra-fine-grained novel class discovery. <em>PR</em>, <em>172</em>, 112369. (<a href='https://doi.org/10.1016/j.patcog.2025.112369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating in open-world environments requires recognizing known categories and discovering new ones, especially in ultra-fine-grained task, where distinguishing similar categories is challenging. The task of Ultra-Fine-Grained Novel Class Discovery (UFG-NCD) intensifies this challenge by requiring systems to identify previously unseen classes within unlabeled data. However, existing UFG-NCD methods fall short in extracting critical visual cues and efficiently transferring knowledge from known to novel categories. To overcome these limitations, this paper proposes Fourier-Enhanced Semi-supervised Proxy Learning (FESPL), a novel framework for UFG-NCD. FESPL incorporates a Fourier amplitude guided block that leverages frequency domain analysis to capture high-frequency details often missed by traditional approaches, enhancing ultra-fine-grained discrimination. Additionally, the semi-supervised proxy learning strategy maximizes information extraction from limited labeled data and promotes robust generalization across known and unseen categories. Our approach achieves substantial improvements in both novel category discovery and known category classification on seven popular UFG-NCD datasets, with average performance gains of 10.41 % in the accuracy of the old class and 4.27 % in the accuracy of the new class in task-agnostic evaluation, while with average performance gains of 4.40 % in clustering accuracy on the unlabeled training data in task-aware evaluation.},
  archive      = {J_PR},
  author       = {Qiupu Chen and Hongkui Jiang and Lin Jiao and Zhou Li and Taosheng Xu and Xue Wang and Rujing Wang},
  doi          = {10.1016/j.patcog.2025.112369},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112369},
  shortjournal = {Pattern Recognition},
  title        = {Fourier-enhanced semi-supervised proxy learning for ultra-fine-grained novel class discovery},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive weighted active contour based HRNet for underwater image segmentation. <em>PR</em>, <em>172</em>, 112368. (<a href='https://doi.org/10.1016/j.patcog.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acquiring optimal results in underwater environments remains challenging due to light absorption, scattering, and suspended particles. Furthermore, the low-resolution outputs from traditional semantic segmentation often result in spatial information loss and blurred segmentation boundaries. To address these issues, we first propose a low-level image enhancement preprocessing module as an independent preliminary stage to improve underwater image quality, thereby enhancing subsequent high-level semantic segmentation performance. Second, leveraging the region-based active contour model-which is independent of image gradients and adept at handling complex contour topology changes-we design a novel level set function to serve as the level set in the geometric active contour model. While this new level set exhibits formal similarity to classical level sets in representing binary segmentation contours, its formulation is derived from network prediction outputs. Third, we construct an adaptive weighted active contour energy function as a loss function within HRNet for multi-class segmentation. This loss function preserves geometric information while penalizing deviations between network-predicted probabilities and ground truth, effectively mitigating spatial information loss and optimizing boundary. Comparative experiments demonstrate that our model outperforms classical methods on objective metrics including mIoU and mPA.},
  archive      = {J_PR},
  author       = {Bo Chen and Jing Ji and Junwei Li and Xiaoli Sun and Feng Gong},
  doi          = {10.1016/j.patcog.2025.112368},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112368},
  shortjournal = {Pattern Recognition},
  title        = {An adaptive weighted active contour based HRNet for underwater image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BORT2: Bi-level optimization for robust target training in multi-source domain adaptation. <em>PR</em>, <em>172</em>, 112367. (<a href='https://doi.org/10.1016/j.patcog.2025.112367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both conventional and source-free multi-source domain adaptation (MSDA) tasks often face bias toward source domains, because more numerous labeled data in these domains, compared with a single unlabeled target domain, can dominate the training process. To alleviate the bias, target adaptation techniques train a target model on the pseudo-labeled target domain data only, with the source-domain-biased models used as the labeling function for pseudo-label generation. However, the pseudo labels may contain noise and harm performance when directly used for supervision. To tackle label noise, we introduce a novel Bi-level Optimization for Robust Target Training (BORT 2 ) scheme. BORT 2 trains a noise-robust target model on pseudo-labeled target data only and meanwhile updates the labeling function (i.e., the source-domain-biased models) to improve pseudo-label quality. Specifically, the target model is a stochastic network designed to be robust to label noise. Such a stochastic network exploits a Gaussian distribution to model the feature of each target instance and deploys an entropy maximization regularizer to the Gaussian to quantify the uncertainty of each pseudo-label, where the uncertainty is utilized to mitigate the negative effects of label noise. In addition, BORT 2 leverages the entropy to update the labeling function for better pseudo-label quality. Updating both the labeling function and the stochastic network involves a nested bi-level optimization problem, addressed using implicit differentiation. Extensive experiments demonstrate that BORT 2 achieves state-of-the-art performance for both conventional and source-free MSDA, as verified on Office-Home, Office-Caltech, PACS, Digit-Five, and the large-scale DomainNet datasets.},
  archive      = {J_PR},
  author       = {Zhongying Deng and Da Li and Xiaojiang Peng and Yi-Zhe Song and Tao Xiang},
  doi          = {10.1016/j.patcog.2025.112367},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112367},
  shortjournal = {Pattern Recognition},
  title        = {BORT2: Bi-level optimization for robust target training in multi-source domain adaptation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ultra-efficient 3D shape reconstruction: Line-coded absolute phase unwrapping algorithm. <em>PR</em>, <em>172</em>, 112366. (<a href='https://doi.org/10.1016/j.patcog.2025.112366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Absolute phase unwrapping-based fringe projection profilometry (APU-FPP) has the advantages of pixel-wise calculation, high precision, and full-field sensing of 3D shape information. To the best of our knowledge, existing APU-FPP methods have a general contradiction between accuracy and efficiency because of projecting extra auxiliary coded fringes (ACFs). In this paper, a line-coded absolute phase unwrapping (LCAPU) algorithm is presented for absolute 3D shape reconstruction of the scene with non-uniform reflectivity and complex surfaces. Firstly, a sequence of single-pixel lines is successively embedded into two sets of 3-step phase-shifting patterns to mark fringe periods, which can thoroughly avoid extra ACFs to disrupt the coherence of adjacent morphological information. Secondly, two line-coded phase-shifting patterns with the same phase shift are used to recognize the corresponding coded lines containing the fringe order cue, which can be simultaneously used to guide fringe mutual compensation, thereby extracting a high-quality phase. Finally, according to the pixel positions and the fringe indices of the decoded lines, a multi-layer decoding (MLD) algorithm is developed to iteratively generate a fringe order map, which can adapt to the randomness of morphological changes. Compared to other methods, the proposed LCAPU can not only perform a one-shot 3D shape reconstruction with a single image acquisition, but also automatically correct phase errors, balancing ultra-efficiency and high accuracy. Experimental results demonstrate the superior performance and the practical application potential in dynamic complex scenes.},
  archive      = {J_PR},
  author       = {Haihua An and Yiping Cao and Hechen Zhang},
  doi          = {10.1016/j.patcog.2025.112366},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112366},
  shortjournal = {Pattern Recognition},
  title        = {Ultra-efficient 3D shape reconstruction: Line-coded absolute phase unwrapping algorithm},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning label-specific features for multi-dimensional classification. <em>PR</em>, <em>172</em>, 112365. (<a href='https://doi.org/10.1016/j.patcog.2025.112365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-dimensional classification (MDC), instances are associated with multiple class variables that are assumed in the output space, and each class variable corresponds to one heterogeneous class space and characterizes the objects’ semantics from one dimension. Learning from MDC examples poses challenges due to the heterogeneity of class spaces, since the outputs from different class spaces are not directly comparable. Moreover, existing approaches often use identical data representation for all labels in a class, which may lead to suboptimal results as each label might be determined by its own specific characteristics. Critically, the inherent incomparability of raw heterogeneous labels prevents existing methods from effectively capturing label correlations, which are essential for guiding feature learning. In this paper, we propose a novel algorithm named LEAD, i.e., learning Label-spEcific feAtures for multi-Dimensional classification. LEAD first resolves label heterogeneity by transforming the original output space into a unified encoded label space through one-hot label encoding. This critical alignment enables explicit extraction of label correlations from the encoded space. To enhance the reliability of the estimation of label correlations, LEAD then leverages feature-space manifold structures via locally linear embedding, propagating labeling information across similar instances to counteract sparsity. Finally, LEAD jointly learns label-specific feature representations and constructs the classifier through sparse learning while incorporating label correlations. Experimental comparisons on fifteen datasets demonstrate that our proposed method outperforms state-of-the-art multi-dimensional classification methods. The code is available at https://github.com/ZhangZan-source/LEAD .},
  archive      = {J_PR},
  author       = {Zan Zhang and Jialin Zhou and Jialu Yao and Lin Liu and Jiuyong Li and Lei Li and Xindong Wu},
  doi          = {10.1016/j.patcog.2025.112365},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112365},
  shortjournal = {Pattern Recognition},
  title        = {Learning label-specific features for multi-dimensional classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TSAR: A two-stage approach to motion artifact reduction in OCTA images. <em>PR</em>, <em>172</em>, 112364. (<a href='https://doi.org/10.1016/j.patcog.2025.112364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical Coherence Tomography Angiography (OCTA) is an innovative and non-invasive imaging technique that leverages motion contrast imaging to generate angiographic images from high-resolution volumetric blood flow data rapidly. However, OCTA imaging is vulnerable to various artifacts induced by eye movements, including displacement artifacts, duplicated scanning artifacts, and white line artifacts. Previous methods that attempted to mitigate eye motion artifacts necessitated costly hardware upgrades. However, despite the availability of advanced eye-tracking hardware and software correction in commercial machines, motion artifacts persist in real-world usage. Recently developed cost-effective learning-based methods only focus on the removal of white line artifacts while neglecting the displacement artifacts and duplicated scanning artifacts. To address this challenge, we propose a comprehensive framework, TSAR, to remove three types of eye motion artifacts in OCTA images. In the first stage, we leverage the intrinsic axial and directional attributes of these artifacts in the first phase to develop an innovative hierarchical transformer network. This network is designed to capture global-wise, local-wise, and vertical-wise features effectively while also removing displacement and duplicate scanning artifacts. Afterward, we leverage the contextual information and develop a residual conditional diffusion model (RCDM) to remove the white line artifacts. By applying our TSAR to the degraded OCTA images, we aim to eliminate all three types of motion artifacts. We evaluate the superior performance of our proposed methodology in artifact removal and image quality enhancement compared to other methods by conducting experiments on both synthetic and real-world OCTA images. The code is available at https://github.com/btma48/TSAR},
  archive      = {J_PR},
  author       = {Benteng Ma and Xiaomeng Li and Xu Lin and Xiaoyu Bai and Dongping Shao and Chubin Ou and Lin An and Jia Qin and Kwang-Ting Cheng},
  doi          = {10.1016/j.patcog.2025.112364},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112364},
  shortjournal = {Pattern Recognition},
  title        = {TSAR: A two-stage approach to motion artifact reduction in OCTA images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quaternionic reweighted amplitude flow for phase retrieval in image reconstruction. <em>PR</em>, <em>172</em>, 112363. (<a href='https://doi.org/10.1016/j.patcog.2025.112363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternionic signal processing provides powerful tools for efficiently managing color signals by preserving the intrinsic correlations among signal dimensions through quaternion algebra. In this paper, we address the quaternionic phase retrieval problem by systematically developing novel algorithms based on an amplitude-based model. Specifically, we propose the Quaternionic Reweighted Amplitude Flow (QRAF) algorithm, which is further enhanced by three of its variants: incremental, accelerated, and adapted QRAF algorithms. In addition, we introduce the Quaternionic Perturbed Amplitude Flow (QPAF) algorithm, which has linear convergence. Extensive numerical experiments on both synthetic data and real images demonstrate that our proposed methods significantly improve recovery performance and computational efficiency compared to state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Ren Hu and Pan Lian},
  doi          = {10.1016/j.patcog.2025.112363},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112363},
  shortjournal = {Pattern Recognition},
  title        = {Quaternionic reweighted amplitude flow for phase retrieval in image reconstruction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust scene text understanding with OCR token and word alignment for text-VQA and text-caption. <em>PR</em>, <em>172</em>, 112362. (<a href='https://doi.org/10.1016/j.patcog.2025.112362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve vision-language tasks incorporating scene text, such as Text-VQA and Text-Caption, recognizing and understanding scene text within image is the first priority. However, the scene text recognized by Optical Character Recognition (OCR) systems often includes spelling errors, such as “pepsi” being recognized as “peosi”. These OCR errors are one of the major challenges for Text-VQA and Text-Caption systems. To address this, we propose a novel multi-modal OCR Token and Word Alignment (TWA) method to alleviate OCR errors in these tasks. First, we artificially create the misspelled OCR tokens and render them onto the RGB images, which can effectively simulates OCR errors. Second, we propose an OCR token-word contrastive learning task to pre-train OCR token representation, making the system more robust to OCR errors. Finally, we introduce a vocabulary predictor with character-level semantic matching, which enables the model to recover the correct word from the vocabulary even with misspelled OCR tokens. A variety of experimental evaluations demonstrate that our method outperforms the state-of-the-art methods on both Text-VQA and Text-Caption datasets.},
  archive      = {J_PR},
  author       = {Zan-Xia Jin and Pinle Qin and Suzhen Lin and Jia Qin and Shuangjiao Zhai and Jianchao Zeng and Xu-Cheng Yin},
  doi          = {10.1016/j.patcog.2025.112362},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112362},
  shortjournal = {Pattern Recognition},
  title        = {Robust scene text understanding with OCR token and word alignment for text-VQA and text-caption},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prior tokenization-based interactive segmentation with vision transformers. <em>PR</em>, <em>172</em>, 112361. (<a href='https://doi.org/10.1016/j.patcog.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively leveraging the provided priors is crucial for interactive segmentation. Existing approaches typically encode clicks via distance-based maps, which are then concatenated or added to the original image as network input. However, these methods do not fully exploit the semantic information embedded in the provided priors, leading to confusion in the feature distribution of different targets and reducing the segmentation quality. To address this issue, we propose a prior tokenization-based interactive segmentation method that uses simple Vision Transformers. By extending the original image tokens with prior tokens, each token represents the semantic features of the foreground and background related to the priors. These tokens participate in the self-attention operation alongside regular image tokens, gradually extracting semantic features from the image tokens to the prior tokens. In addition, we introduce a discriminative loss function to enforce inter-class separation and intra-class compactness of the prior tokens. Subsequently, we employ a cross-attention mechanism to couple the prior tokens with the regular image block token features, ensuring that the features extracted by the network are aligned with the user’s intent. Finally, we use the register method to suppress artifacts and enhance the segmentation performance further. Extensive experiments demonstrate that our method achieves superior interaction efficiency, robustness, and generalization ability across various medical image segmentation benchmarks. The source codes are available at https://github.com/dzyha2011/PT-SimpleClick},
  archive      = {J_PR},
  author       = {Zongyuan Ding and Boyu Wang and Hongyuan Wang and Tao Wang},
  doi          = {10.1016/j.patcog.2025.112361},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112361},
  shortjournal = {Pattern Recognition},
  title        = {Prior tokenization-based interactive segmentation with vision transformers},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CTNet: Color transformation network for low-light image enhancement. <em>PR</em>, <em>172</em>, 112360. (<a href='https://doi.org/10.1016/j.patcog.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light images are often plagued by low visibility, poor contrast, and high noise levels, which significantly impair both subjective visual quality and the performance of downstream tasks. Existing enhancement methods typically struggle with color-related degradations such as color casting, artifacts, and distortion. To address these challenges, we propose an end-to-end Color Transformation Network for low-light image enhancement, with a specific focus on improving color restoration. By leveraging the complementary strengths of the HSV and RGB color spaces in capturing color attributes, our approach enables effective interaction between these color spaces at the feature level. The HSV branch simultaneously enhances the V component while extracting features from the H and S components, thereby providing a more comprehensive set of cues for color recovery. To facilitate interaction, we design a learnable Color Transformation Block that bridges the HSV and RGB feature domains, effectively simulating the HSV-to-RGB conversion. Furthermore, a Cross-Integration Block, employing an attention-based cross-guidance mechanism, enables bi-directional information flow between the two color spaces. Extensive experiments on both real and synthetic datasets demonstrate that our method achieves superior performance, surpassing existing approaches both qualitatively and quantitatively. The project is available at https://github.com/1013990424/CTNet .},
  archive      = {J_PR},
  author       = {Lidong Xie and Runmin Cong and Ju Dai and Wenhan Yang and Junjun Pan and Hao Wu},
  doi          = {10.1016/j.patcog.2025.112360},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112360},
  shortjournal = {Pattern Recognition},
  title        = {CTNet: Color transformation network for low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint adversarial attack: An effective approach to evaluate robustness of 3D object tracking. <em>PR</em>, <em>172</em>, 112359. (<a href='https://doi.org/10.1016/j.patcog.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have widely been used in 3D object tracking, thanks to its superior capabilities to learn from geometric training samples and locate tracking targets. Although the DNN based trackers show vulnerability to adversarial examples, their robustness in real-world scenarios with potentially complex data defects has rarely been studied. To this end, a joint adversarial attack method against 3D object tracking is proposed, which simulates defects of the point cloud data in the form of point filtration and perturbation simultaneously. Specifically, a voxel-based point filtration module is designed to filter points of the tracking template, which is described by the voxel-wise binary distribution regarding the density of the point cloud. Furthermore, a voxel-based point perturbation module adds voxel-wise perturbations to the filtered template, whose direction is constrained by local geometrical information of the template. Experiments conducted on popular 3D trackers demonstrate that the proposed joint attack have decreased the success and precision of existing 3D trackers by 30.2% and 35.4% respectively in average, which made an improvement of 30.5% over existing attack methods.},
  archive      = {J_PR},
  author       = {Riran Cheng and Xupeng Wang and Ferdous Sohel and Hang Lei},
  doi          = {10.1016/j.patcog.2025.112359},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112359},
  shortjournal = {Pattern Recognition},
  title        = {Joint adversarial attack: An effective approach to evaluate robustness of 3D object tracking},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-channel blur invariants of color and multispectral images. <em>PR</em>, <em>172</em>, 112358. (<a href='https://doi.org/10.1016/j.patcog.2025.112358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with the recognition of blurred color/multispectral images directly without any deblurring. We present a general theory of invariants of multispectral images with respect to blur. The paper is a significant non-trivial extension of the recent theory of blur invariants of graylevel images. The main original contribution of the paper lies in introducing cross-channel blur invariants in Fourier domain. We also developed an algorithm for their stable and fast calculation in the moment domain. Moreover, the cross-channel invariants can be found for blurs for which single-channel invariants do not exist. The experiments on simulated and real data demonstrate that incorporating the new cross-channel invariants significantly improves the recognition power and surpasses other existing approaches. The outlook for a possible implementation of the blur invariants into neural networks is briefly sketched in the conclusion.},
  archive      = {J_PR},
  author       = {Václav Košík and Jan Flusser and Filip Šroubek},
  doi          = {10.1016/j.patcog.2025.112358},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112358},
  shortjournal = {Pattern Recognition},
  title        = {Cross-channel blur invariants of color and multispectral images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniForCE: The unimodality forest method for clustering and estimation of the number of clusters. <em>PR</em>, <em>172</em>, 112357. (<a href='https://doi.org/10.1016/j.patcog.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the number of clusters k while clustering the data is a challenging task. An incorrect cluster assumption indicates that the number of clusters k gets wrongly estimated. Consequently, the model fitting becomes less important. In this work, we focus on the concept of unimodality and propose a flexible cluster definition called locally unimodal cluster . A locally unimodal cluster extends for as long as unimodality is locally preserved across pairs of subclusters of the data. Then, we propose the UniForCE method for locally unimodal clustering. The method starts with an initial overclustering of the data and relies on the unimodality graph that connects subclusters forming unimodal pairs. Such pairs are identified using an appropriate statistical test. UniForCE identifies maximal locally unimodal clusters that are statistically significant by computing a spanning forest in the unimodality graph. Experimental results on both real and synthetic datasets illustrate that the proposed methodology is particularly flexible and robust in discovering regular and highly complex cluster shapes. Most importantly, it automatically provides an adequate estimation of the number of clusters.},
  archive      = {J_PR},
  author       = {Georgios Vardakas and Argyris Kalogeratos and Aristidis Likas},
  doi          = {10.1016/j.patcog.2025.112357},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112357},
  shortjournal = {Pattern Recognition},
  title        = {UniForCE: The unimodality forest method for clustering and estimation of the number of clusters},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SequencePAR: Understanding pedestrian attributes via a sequence generation paradigm. <em>PR</em>, <em>172</em>, 112356. (<a href='https://doi.org/10.1016/j.patcog.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current pedestrian attribute recognition (PAR) algorithms use multi-label or multi-task learning frameworks with specific classification heads. These models often struggle with imbalanced data and noisy samples. Inspired by the success of generative models, we propose Sequence Pedestrian Attribute Recognition (SequencePAR), a novel sequence generation paradigm for PAR. SequencePAR extracts pedestrian features using a language-image pre-trained model and embeds the attribute set into query tokens guided by text prompts. A Transformer decoder generates human attributes by integrating visual features and attribute query tokens. The masked multi-head attention layer in the decoder prevents the model from predicting the next attribute during training. The extensive experiments on multiple PAR datasets validate the effectiveness of SequencePAR. Specifically, we achieve 84.92 %, 90.44 %, 90.73 %, and 90.46 % in accuracy, precision, recall, and F1-score on the PETA dataset.},
  archive      = {J_PR},
  author       = {Jiandong Jin and Xiao Wang and Yin Lin and Chenglong Li and Lili Huang and Aihua Zheng and Jin Tang},
  doi          = {10.1016/j.patcog.2025.112356},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112356},
  shortjournal = {Pattern Recognition},
  title        = {SequencePAR: Understanding pedestrian attributes via a sequence generation paradigm},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SATE: Efficient knowledge distillation with implicit student-aware teacher ensembles. <em>PR</em>, <em>172</em>, 112355. (<a href='https://doi.org/10.1016/j.patcog.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent findings suggest that with the same teacher architecture, a fully converged or “stronger” checkpoint surprisingly leads to a worse student. This can be explained by the Information Bottleneck (IB) principle, as the features of a weaker teacher transfer more “dark” knowledge because they maintain higher mutual information with the inputs. Meanwhile, various works have shown that severe teacher-student structural disparity or capability mismatch often leads to worse student performance. To deal with these issues, we propose a generalizable and efficient Knowledge Distillation (KD) framework with implicit Student-Aware Teacher Ensembles (SATE). The SATE framework simultaneously trains a student network and a student-aware intermediate teacher as a learning companion. With the proposed co-training strategy, the intermediate teacher is trained gradually and forms implicit ensembles of weaker teachers along the learning process. Such a design enables the student model to retain more dark knowledge for better generalization ability. The proposed framework improves the training scheme in a plug-and-play way so that it can be applied to improve various classic and state-of-the-art KD methods on both intra-domain (up to 2.184 % ) and cross-domain (up to 7.358 % ) settings, under a diversified configurations on teacher-student architectures, and achieves a major efficient advantage over other generic frameworks. The code is available at https://github.com/diqichen91/SATE.git .},
  archive      = {J_PR},
  author       = {Diqi Chen and Yang Li and Jiajun Liu and Jun Zhou and Yongsheng Gao},
  doi          = {10.1016/j.patcog.2025.112355},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112355},
  shortjournal = {Pattern Recognition},
  title        = {SATE: Efficient knowledge distillation with implicit student-aware teacher ensembles},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative attention based weighted sparse representation of visual objects in complex scenarios. <em>PR</em>, <em>172</em>, 112354. (<a href='https://doi.org/10.1016/j.patcog.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse subspace representation (SSR) is an attractive technique for subspace segmentation of high-dimensional data through a self-representation manner to reveal its algebraic structure. Numerous generalizations of SSR have been developed to meet different applications. However, a fatal limitation in those extensions is their neglect of feature weights in visual samples, which play crucial roles in segmenting or recognizing specific objects. This paper introduces a discriminative attention based weighted SSR model to tackle visual objects. In the proposed model, the prior information is empirically constructed for intra-cluster features and inter-cluster ones, aided by the sparse representation of samples. An attention mechanism is introduced to learn weights of features of samples. The attention based weights of objects in samples and sparse representation of samples are collaboratively learned from the prior information. A hard version and a soft one of attention based sparse subspace representation, abbreviated as HDAWSSR and SDAWSSR, are specified by assigning attention of features by a Boolean matrix and a fuzzy matrix. Algorithms for solving both models are meticulously developed, respectively. Applications of both algorithms in clustering and moving object detection within high-dimensional image data are investigated. Experimental results show that both models outperform the state-of-the-art subspace based segmentation methods.},
  archive      = {J_PR},
  author       = {Ge Yang and Tingquan Deng and Ming Yang and Changzhong Wang},
  doi          = {10.1016/j.patcog.2025.112354},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112354},
  shortjournal = {Pattern Recognition},
  title        = {Discriminative attention based weighted sparse representation of visual objects in complex scenarios},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale feature sharing and collaborative sampling for unsupervised vehicle re-identification. <em>PR</em>, <em>172</em>, 112353. (<a href='https://doi.org/10.1016/j.patcog.2025.112353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle Re-identification (Re-ID) retrieves target vehicle images from non-overlapping cameras. To address label noise in pseudo-labels, we propose the Multi-scale Feature Sharing and Collaborative Sampling (MFSCS) method. Specifically, the designed multi-scale feature sharing module moves beyond reliance on global features, efficiently promoting the exchange of characteristics between global and local aspects. This shared feature approach collectively mitigates the label noise arising from clustering. Recognizing that clustering methods are highly sensitive to outliers, we introduce a collaborative sampling module that cooperatively combines samples in the clustering process before training the model. This cooperative sampling module is better equipped to handle outliers in the samples and update label information more efficiently. As a result, it asymptotically improves the accuracy and stability of the model. The effectiveness of the proposed method in terms of performance is demonstrated through extensive experiments conducted on both the latest challenging truck Re-ID dataset, Truck-ID and VeRi-776.},
  archive      = {J_PR},
  author       = {Jia-Jia Li and Si-Bao Chen and Chris Ding and Bin Luo},
  doi          = {10.1016/j.patcog.2025.112353},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112353},
  shortjournal = {Pattern Recognition},
  title        = {Multi-scale feature sharing and collaborative sampling for unsupervised vehicle re-identification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). You look from old classes: Towards accurate few shot class-incremental learning. <em>PR</em>, <em>172</em>, 112352. (<a href='https://doi.org/10.1016/j.patcog.2025.112352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) is a common but difficult task that faces two challenges: catastrophic forgetting of old classes and insufficient learning of new classes with limited samples. Recent wisdom focuses on preventing catastrophic forgetting yet overlooks the limited samples issue, resulting in poor new class performance. In this paper, we argue that old class samples contain rich knowledge, which can be exploited to supplement the learning of new classes. To this end, we propose to Look from Old Classes (YLOC) for FSCIL, enhancing both the base and incremental sessions. In the base session, we develop a prototype centered loss (PCL) to obtain a compact distribution of old classes. During incremental sessions, we devise a prototype augmentation learning (PAL) method to aid the learning of new classes by exploiting old classes. Extensive experiments on three FSCIL benchmark datasets demonstrate the superiority of our method.},
  archive      = {J_PR},
  author       = {Yijie Hu and Kaizhu Huang and Wei Wang and Xiaowei Huang and Qiufeng Wang},
  doi          = {10.1016/j.patcog.2025.112352},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112352},
  shortjournal = {Pattern Recognition},
  title        = {You look from old classes: Towards accurate few shot class-incremental learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-decoder collaborative learning with multi-hybrid view augmentation for self-supervised 3D action recognition. <em>PR</em>, <em>172</em>, 112351. (<a href='https://doi.org/10.1016/j.patcog.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised methods, including contrastive learning and masked skeleton modeling, have demonstrated considerable potential in the field of skeleton-based action recognition. While contrastive learning captures fine-grained details at the instance level, masked skeleton modeling emphasizes joint-level features. Recent studies have begun to combine these two approaches. However, existing combination methods primarily focus on integrating the tasks within the skeleton space. Moreover, existing contrastive learning methods often fail to exploit the comprehensive interaction information in skeletal structures, resulting in suboptimal performance when recognizing actions involving multiple individuals. To overcome these limitations, we introduce the Dual-Decoder Collaborative Learning (DDC) with Multi-Hybrid View Augmentation (MHGNA) method, which connects these two tasks across multiple spaces. Specifically, the masked skeleton modeling task provides diverse views for the contrastive learning task in the skeleton space, while the contrastive method aligns the features generated by both tasks within the feature space. We further present an innovative view augmentation method that enhances the model’s capacity to understand human interaction relationships by shuffling and replacing data across temporal, spatial, and personal dimensions. Extensive experiments on four downstream tasks across three large-scale datasets demonstrate that DDC exhibits stronger representational capabilities compared to state-of-the-art methods. Our code is available at https://github.com/Yingfei-Wu/DDC .},
  archive      = {J_PR},
  author       = {Wenming Cao and Yingfei Wu and Xinpeng Yin},
  doi          = {10.1016/j.patcog.2025.112351},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112351},
  shortjournal = {Pattern Recognition},
  title        = {Dual-decoder collaborative learning with multi-hybrid view augmentation for self-supervised 3D action recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). D3PD: Dual distillation and dynamic fusion for camera-radar 3D perception. <em>PR</em>, <em>172</em>, 112350. (<a href='https://doi.org/10.1016/j.patcog.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving perception is driving rapid advancements in Bird’s-Eye-View (BEV) technology. The synergy of surround-view imagery and radar is seen as a cost-friendly approach that enhances the understanding of driving scenarios. However, current methods for fusing radar and camera features lack effective environmental perception guidance and dynamic adjustment capabilities, which restricts their performance in real-world scenarios. In this paper, we introduce the D3PD framework, which combines fusion techniques with knowledge distillation to tackle the dynamic guidance deficit in existing radar-camera fusion methods. Our method includes two key modules: Radar-Camera Feature Enhancement (RCFE) and Dual Distillation Knowledge Transfer. The RCFE module enhances the areas of interest in BEV, addressing the poor object perception performance of single-modal features. The Dual Distillation Knowledge Transfer includes four distinct modules: Camera Radar Sparse Distillation (CRSD) for sparse feature knowledge transfer and teacher-student network feature alignment. Position-guided Sampling Distillation(SamD) for refining the knowledge transfer of fused features through dynamic sampling. Detection Constraint Result Distillation (DcRD) for strengthening the positional correlation between teacher and student network outputs in forward propagation, achieving more precise detection perception. and Self-learning Mask Focused Distillation (SMFD) for focusing perception detection results on knowledge transfer through self-learning, concentrating on the reinforcement of local key areas. The D3PD framework outperforms existing methods on the nuScenes benchmark, achieving 49.6 % mAP and 59.2 % NDS performance. Moreover, in the occupancy prediction task, D3PD-Occ has achieved an advanced performance of 37.94 % mIoU. This provides insights for the design and model training of camera and radar-based 3D object detection and occupancy network prediction methods. The code will be available at https://github.com/no-Name128/D3PD .},
  archive      = {J_PR},
  author       = {Junyin Wang and Chenghu Du and Tongao Ge and Bingyi Liu and Shengwu Xiong},
  doi          = {10.1016/j.patcog.2025.112350},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112350},
  shortjournal = {Pattern Recognition},
  title        = {D3PD: Dual distillation and dynamic fusion for camera-radar 3D perception},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TBiGAN-based parallel networks for remaining useful life prediction of multi-stage degraded bearings. <em>PR</em>, <em>172</em>, 112349. (<a href='https://doi.org/10.1016/j.patcog.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of the remaining useful life (RUL) of rolling bearings is crucial for ensuring the safe and reliable operation of rotating machinery. However, existing methods generally overlook the correlation between different degradation stages and RUL, thereby limiting the accuracy of RUL prediction for rolling bearings. To address this challenge, a novel adaptive RUL prediction method for multi-stage degrading rolling bearings is proposed. Specifically, a new Transformer-based network is designed to classify the degradation stages of bearings. Additionally, a parallel RUL prediction model incorporating attention mechanisms is introduced, which integrates Temporal Convolutional Networks (TCN) and Bidirectional Gated Recurrent Units (BiGRU) to capture degradation features from multiple dimensions automatically and enhance the model’s ability to capture long-term dependencies in sequence tasks. Finally, the RUL prediction results from different stages are adaptively integrated using a smoothing technique to generate the final RUL. The accuracy and superiority of the proposed method are validated on the PHM2012 bearing dataset.},
  archive      = {J_PR},
  author       = {Zheng Jianfei and Chen Dongnan and Hu Changhua and Han Qihui and Pei Hong},
  doi          = {10.1016/j.patcog.2025.112349},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112349},
  shortjournal = {Pattern Recognition},
  title        = {TBiGAN-based parallel networks for remaining useful life prediction of multi-stage degraded bearings},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MChartQA and mChartQABench: A multimodal-only solution for complex chart question-answering. <em>PR</em>, <em>172</em>, 112348. (<a href='https://doi.org/10.1016/j.patcog.2025.112348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal chart question-answering (QA) is essential for applications such as financial report analysis, decision support, and invoice parsing. Current methods typically convert charts to text for processing by large language models (LLMs) or use direct multimodal processing. This raises an important question: under what conditions is a multimodal approach essential for chart question-answering? We observe that these traditional approaches often struggle with complex color patterns, structural intricacies, and implicit numerical data. Yet, limited research addresses these challenges. To bridge this gap, we introduce a new multimodal chart dataset, mChartQABench, constructed by consolidating data from existing open-source datasets to address challenges with color, structure, and textless chart data. To handle these complex multimodal scenarios effectively, we propose mChartQA, a framework integrating the advanced language processing of LLMs with a state-of-the-art table-to-text engine. This framework excels in aligning visual and textual data, enhancing deep reasoning and contextual understanding within charts. Experimental results show that mChartQA achieves superior performance across four datasets, with over 20 % overall accuracy improvement on mChartQABench.},
  archive      = {J_PR},
  author       = {Jingxuan Wei and Nan Xu and Guiyong Chang and Yin Luo and Bihui Yu and Ruifeng Guo},
  doi          = {10.1016/j.patcog.2025.112348},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112348},
  shortjournal = {Pattern Recognition},
  title        = {MChartQA and mChartQABench: A multimodal-only solution for complex chart question-answering},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Copula-based conformal prediction for prioritized heterogeneous multi-task learning. <em>PR</em>, <em>172</em>, 112347. (<a href='https://doi.org/10.1016/j.patcog.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction (CP) has emerged as a standard for finite-sample and distribution-free uncertainty quantification (UQ). Although CP is widely used as a post-processing step (on the outputs of machine learning models) to produce reliable set-valued predictions, it is still challenging to post-process heterogeneous (i.e., categorical & numerical) predictions since the traditional CP procedures are either exclusively designed for classification or only tailored to regression. This article proposes the use of a simple yet novel copula-based CP method that jointly produces (discrete) set-valued predictions and (continuous) interval-valued predictions. This approach offers flexibility by allowing the prioritization of specific outputs’ reliability and applies to general heterogeneous multi-task problems. We demonstrate its effectiveness in the context of autonomous driving, on two popular multi-class object detection benchmarks, where it effectively infers set values for object classes and bounding boxes with the specified confidence levels. Experimental results validate our method’s ability in handling heterogeneous multi-task conformal predictions: we achieve high confidence levels without losing the informativeness of the prediction regions.},
  archive      = {J_PR},
  author       = {Bruce Cyusa Mukama and Soundouss Messoudi and Sébastien Destercke and Sylvain Rousseau},
  doi          = {10.1016/j.patcog.2025.112347},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112347},
  shortjournal = {Pattern Recognition},
  title        = {Copula-based conformal prediction for prioritized heterogeneous multi-task learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep spatio-temporal architecture for dynamic ECN analysis with granger causality based causal discovery. <em>PR</em>, <em>172</em>, 112346. (<a href='https://doi.org/10.1016/j.patcog.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurobrain science provides the motivation for research on causal modeling. The existing causal discovery methods have shown promising results in effective connectivity network analysis, however, they often overlook the dynamics of causality, in addition to the incorporation of spatio-temporal information in data. Dynamic effective connectivity networks (dECNs) reveal the changing directed brain activity and the dynamic causal influences among brain regions, which facilitate the identification of individual differences and enhance the understanding of human brain. To learn dynamic causality, we propose a deep spatio-temporal fusion architecture, which employs a dynamic causal deep encoder to incorporate spatio-temporal information into dynamic causality modeling, and a dynamic causal deep decoder to verify the discovered causality. The effectiveness of the proposed method is first illustrated with simulated data. Then, experimental results from Philadelphia Neurodevelopmental Cohort (PNC) demonstrate the superiority of the proposed method in inferring dECNs, which reveal the dynamic evolution of directed flow between brain regions. The analysis shows the difference of dECNs between young adults and children. Specifically, the directed brain functional networks transit from fluctuating undifferentiated systems to more stable specialized networks as one grows. This observation provides further evidence on the modularization and adaptation of brain networks during development, leading to higher cognitive abilities observed in young adults.},
  archive      = {J_PR},
  author       = {Faming Xu and Yiding Wang and Gang Qu and Vince D. Calhoun and Julia M. Stephen and Tony W. Wilson and Yu-Ping Wang and Chen Qiao},
  doi          = {10.1016/j.patcog.2025.112346},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112346},
  shortjournal = {Pattern Recognition},
  title        = {A deep spatio-temporal architecture for dynamic ECN analysis with granger causality based causal discovery},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised domain adaptation via style-aware self-intermediate domain. <em>PR</em>, <em>172</em>, 112344. (<a href='https://doi.org/10.1016/j.patcog.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) has garnered significant attention for its ability to transfer knowledge from a label-rich source domain to a related but unlabeled target domain, with minimizing inter-domain discrepancies being crucial, especially when a substantial gap exists between the domains. To address this, we introduce the novel Style-aware Self-Intermediate Domain (SSID), which effectively bridges large domain gaps by facilitating knowledge transfer while preserving class-discriminative information. Inspired by human transitive inference and learning capabilities, SSID connects seemingly unrelated concepts through a sequence of intermediate, auxiliary synthesized concepts. Meanwhile, an external memory bank is designed to store and update designated labeled features, ensuring the stability of class-specific and class-wise style features. Additionally, we also proposed a novel intra- and inter-domain loss functions that enhance class recognition and feature compatibility, with their convergence rigorously validated through a novel analytical approach. Comprehensive experiments demonstrate that SSID achieves accuracies of 85.4 % and 85.3 % on two widely recognized UDA benchmarks, outperforming the second-best methods by 0.94 % and 1.17 %, respectively. As a plug-and-play solution, SSID integrates seamlessly with various backbone networks, showcasing its effectiveness and versatility in domain adaptation scenarios.},
  archive      = {J_PR},
  author       = {Lianyu Wang and Meng Wang and Daoqiang Zhang and Huazhu Fu},
  doi          = {10.1016/j.patcog.2025.112344},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112344},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised domain adaptation via style-aware self-intermediate domain},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing visual representation of untrimmed videos by counteracting visuality threatening content. <em>PR</em>, <em>172</em>, 112343. (<a href='https://doi.org/10.1016/j.patcog.2025.112343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the remarkable growth of the video platform industry and the surge in video uploads, Content-Based Video Retrieval (CBVR), which finds videos on desired topics from a collection of untrimmed videos using solely the visual modality, is gaining increased attention. However, the challenge of accurate retrieval persists due to the varied and complex content in untrimmed videos, and there has been a lack of discussion on which types of content compromise visual representations. In this paper, we found that text and blur texture are of this nature, grounded in empirical observations. Indeed, in models focusing on the visual modality, both the visual structure of text (without semantics) and the smoothness of blur texture (with few edges and corners) interfere with decision-making. To address them, we propose two strategies: text-masking learning, which excludes the effect of text in the descriptor for inputs that may contain text content, and blur texture filtering, a re-scaling strategy that mitigates the impact of blur textures by exploiting the neural network’s insensitivity to the smoothed pixel-wise gradients. Furthermore, through empirical observations, we demonstrate that our proposed method effectively handles visuality-threatening content. Additionally, we show that our method can lead to state-of-the-art performance across multiple benchmarks of untrimmed videos.},
  archive      = {J_PR},
  author       = {Gwangjin Lee and Won Jo and Hyunwoo Kim and Yukyung Choi},
  doi          = {10.1016/j.patcog.2025.112343},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112343},
  shortjournal = {Pattern Recognition},
  title        = {Enhancing visual representation of untrimmed videos by counteracting visuality threatening content},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Texture-aware transformer with pose-patch mapping for occluded person re-identification. <em>PR</em>, <em>172</em>, 112341. (<a href='https://doi.org/10.1016/j.patcog.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification (re-ID) aims to retrieve the target person from occluded images captured by different cameras, where the challenges lie in identity loss caused by different types of occlusion. To alleviate the occlusion interference, some methods rely on external clues or generate more occlusion samples. However, these methods fail to address the issues of pose misalignment under extreme occlusion and identity confusion caused by non-target pedestrian occlusion. To solve these problems, we design a novel T exture-Aware T ransformer with P ose-Patch M apping (TTPM), which does not require generating any occlusion samples. Specifically, a Multi-patch Feature Encoder is proposed to encode discriminative features from inter patches and intra patches. Afterwards, the Pose-Patch Mapping is designed to construct a positional mapping between poses and patches, which highlights human patches and weakens the impact of occluded patches. Finally, to mitigate the non-target pedestrian occlusion, a Texture-Aware Decoder is introduced to perceive texture features and leverage their distinctiveness to enhance the representation of important regions. Extensive experiments show that our method achieves state-of-the-art results on Occluded-Duke and Occluded-REID datasets.},
  archive      = {J_PR},
  author       = {Dengwen Wang and Guanyu Xing and Yanli Liu},
  doi          = {10.1016/j.patcog.2025.112341},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112341},
  shortjournal = {Pattern Recognition},
  title        = {Texture-aware transformer with pose-patch mapping for occluded person re-identification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient community-aware pre-training method for graph neural networks. <em>PR</em>, <em>172</em>, 112340. (<a href='https://doi.org/10.1016/j.patcog.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While graph neural networks (GNNs) have demonstrated widespread success in various domains, their pre-training techniques lag behind those in computer vision and natural language processing, typically exhibiting limited performance gains and high computational costs. This paper introduces Community-Aware Pre-training (CAP), a novel approach that leverages the inherent community structures prevalent in real-world networks to enhance GNN pre-training efficiency and effectiveness. CAP employs a self-supervised contrastive learning framework to learn node representations that are highly discriminative of their respective communities. To further optimize the pre-training process, we introduce a Monte Carlo Tree Search-based community sampler that efficiently extracts representative subgraphs, mitigating noise and enhancing sample quality. CAP is versatile and can be applied to a broad range of node classification tasks due to the commonly existing community structures within networks. Extensive evaluations on diverse node classification benchmarks demonstrate that CAP consistently outperforms state-of-the-art methods, achieving accuracy improvements of up to 4.34 % while significantly reducing pre-training time by up to 14.87 times compared to existing techniques. Furthermore, CAP enhances the predictive confidence and visualization distinctiveness of node representations, paving a new path for effective and efficient GNN pre-training.},
  archive      = {J_PR},
  author       = {Zhenhua Huang and Wenhao Zhou and Yihang Jiang and Zhaohong Jia and Linyuan Lü and Yunjie Ma},
  doi          = {10.1016/j.patcog.2025.112340},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112340},
  shortjournal = {Pattern Recognition},
  title        = {An efficient community-aware pre-training method for graph neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction. <em>PR</em>, <em>172</em>, 112339. (<a href='https://doi.org/10.1016/j.patcog.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have made significant progress in trajectory prediction tasks but still face several critical challenges. The ordinary differential equation (ODE) solving methods used in standard diffusion models often suffer from error accumulation during multi-step iterations. Additionally, the denoising process is highly time-consuming due to the large number of computational steps, which significantly hinders inference efficiency and makes real-time applications challenging. To address these issues, we propose a diffusion-based method, DiffTrajectory, which integrates the Runge-Kutta (RK4) method, a Leap Initializer Module (LIM), and an Adaptive Dynamic Step-size Strategy (ADSS) to enhance generation accuracy and greatly optimize inference efficiency. Specifically, to tackle the problem of error accumulation, DiffTrajectory formalizes the denoising process as an ODE-solving problem and adopts the RK4 as a numerical solution. By computing multiple intermediate points at each iteration, this approach significantly reduces error accumulation. To improve the efficiency of the denoising process, DiffTrajectory introduces LIM, which leverages a pre-trained initial model to quickly generate a high-quality starting point for denoising, thereby reducing the computational burden during the initial denoising stages. Furthermore, we design the ADSS that adjusts the step size dynamically based on the results of each denoising stage, ensuring the quality of the generated results while substantially shortening inference time. Extensive experiments on the ETH/UCY and NBA datasets demonstrate that DiffTrajectory achieves substantial improvements in both accuracy and efficiency.},
  archive      = {J_PR},
  author       = {Chengcheng Li and Luqi Gong and Leiheng Xu and Xin Wang},
  doi          = {10.1016/j.patcog.2025.112339},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112339},
  shortjournal = {Pattern Recognition},
  title        = {DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A mondrian conformal predictive system with improved decision trees for uncertainty quantification under heteroscedasticity. <em>PR</em>, <em>172</em>, 112338. (<a href='https://doi.org/10.1016/j.patcog.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing application of machine learning in industrial production, model uncertainty quantification has become a critical tool to evaluate the prediction reliability and guide decision-making. The Conformal Predictive System (CPS), which generates Cumulative Distribution Functions (CDFs), provides valuable support for uncertainty quantification. However, CPS faces limitations when addressing heteroskedasticity. This paper proposes a Mondrian Conformal Predictive System (LWT-MCPS) based on an enhanced Decision Tree. The proposed approach constructs decision trees using splitting criteria derived from Levene’s test and Welch’s t -test, ensuring that the variance and mean within each partition remain as homogeneous as possible. Furthermore, it incorporates predicted values and prediction variances estimated using the k -Nearest Neighbors (KNN) as splitting features, effectively mitigating the impact of high-dimensional data on tree partitioning and enhancing the model’s ability to identify heterogeneous regions. Experiments conducted on simulated data, public datasets, and blast furnace ironmaking data demonstrate that LWT-MCPS generates CDFs with lower Continuous Ranked Probability Scores (CRPS) than traditional CPS. These results validate its significant advantages in addressing heteroskedasticity challenges.},
  archive      = {J_PR},
  author       = {Ruiyao Zhang and Ping Zhou},
  doi          = {10.1016/j.patcog.2025.112338},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112338},
  shortjournal = {Pattern Recognition},
  title        = {A mondrian conformal predictive system with improved decision trees for uncertainty quantification under heteroscedasticity},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial multi-semantic features guided spectral-friendly transformer network for hyperspectral image classification. <em>PR</em>, <em>172</em>, 112337. (<a href='https://doi.org/10.1016/j.patcog.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification (HSIC) is a foundational topic in remote sensing. However, the high correlations between bands and the spectral correlations often result in redundant data. Moreover, traditional convolutional neural networks (CNNs) compress spatial dimensions through pooling layers or strides during spatial information extraction, resulting in the loss of spatial information. To overcome these challenges, we propose a spatial multi-semantic features guided spectral-friendly Transformer network (SFTN), which effectively extracts the spectral and spatial features of HSIs. Specifically, a multi-semantic spatial attention (MsSA) module applies unidirectional spatial compression along the height and width dimensions. Thus, this module maintains spatial structure in one direction while aggregating global spatial information, thereby minimizing information loss during compression. It then employs multi-scale depth-shared 1D convolutions to capture multi-semantic spatial information. Furthermore, the spectral-friendly Transformer replaces the traditional multi-head self-attention (MHSA) with spectral correlation self-attention (ECSa), which effectively captures spectral differences and thus reduces the redundancy of spectral information. Extensive experiments on several HSI datasets show that the proposed SFTN method outperforms other state-of-the-art methods in HSIC applications. The source code for this work will be released later.},
  archive      = {J_PR},
  author       = {Xiaoyan Yu and Mingzhu Tai and Yuyang Wang and Zhenqiu Shu and Liehuang Zhu},
  doi          = {10.1016/j.patcog.2025.112337},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112337},
  shortjournal = {Pattern Recognition},
  title        = {Spatial multi-semantic features guided spectral-friendly transformer network for hyperspectral image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation. <em>PR</em>, <em>172</em>, 112336. (<a href='https://doi.org/10.1016/j.patcog.2025.112336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have become indispensable across various fields; however, their susceptibility to backdoor attacks poses significant security risks. In this paper, we propose a backdoor defense scheme based on adversarial prediction proximity and contrastive knowledge distillation. This scheme not only detects poisoned models and labels but also effectively unlearns backdoors while preserving the model’s benign functionality. Based on the observation that untargeted adversarial examples and poisoned samples exhibit proximity in feature space within poisoned models (i.e., adversarial prediction proximity), we first detect backdoors by analyzing changes in the prediction behavior of untargeted adversarial examples for models before and after fine-tuning. Next, we purify the poisoned model using a triplet loss that incorporates clean samples and untargeted adversarial examples. This process is guided by contrastive knowledge distillation, where a fine-tuned model acts as a “benign teacher”, and a backdoor-retained model serves as a “malicious teacher”, encouraging the poisoned model to align its feature representations with clean behavior. Comprehensive experimental results demonstrate that our scheme achieves high accuracy in detecting poisoned models and labels, even with limited access to clean samples. Furthermore, our scheme provides effective backdoor purification, while preserving the integrity and performance of models.},
  archive      = {J_PR},
  author       = {Lin Huang and Leo Yu Zhang and Ching-Chun Chang and Wei Wang and Chuan Qin},
  doi          = {10.1016/j.patcog.2025.112336},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112336},
  shortjournal = {Pattern Recognition},
  title        = {Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hyperspectral space transformations for texture classification. <em>PR</em>, <em>172</em>, 112335. (<a href='https://doi.org/10.1016/j.patcog.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D color space transformations are widely used in color imaging to enhance the results of various tasks, including image segmentation, object recognition, and texture classification. However, such useful transformations are much more limited in hyperspectral imaging, where images contain hundreds to thousands of spectral bands. To improve the performance of hyperspectral image analysis, we introduce four new hyperspectral space transformations in this paper: the Hyper-Chrominance-Luminance (H-CL), the Hyper-Hue-Chroma-Luminance (H-HCL), the Hyper-Hue-Saturation-Intensity (H-HSI), and the Hyper-Hue-Saturation-Value (H-HSV). These transformations extend the corresponding CL, HCL, HSI, and HSV 3D color spaces to multiple dimensions. To investigate their suitability in the context of texture classification, several well-known texture descriptors, including both theory-driven (handcrafted) and data-driven (deep learning) methods, are used in the experiments. Ten hyperspectral datasets are considered: HyTexila, SpecTex, HyperPlastic, and seven datasets extracted from the Timbers database. Among these datasets, six new ones are introduced in this paper. The proposed H-CL, H-HCL, H-HSI, and H-HSV transformations are also compared with state-of-the-art transformation strategies. The experiments conducted in this paper demonstrate the efficacy of the proposed space transformations with an accuracy improvement that can reach +43.47 %.},
  archive      = {J_PR},
  author       = {Alice Porebski and Souraya Ouaidar Hadir and Thierry Gensane and Nicolas Vandenbroucke},
  doi          = {10.1016/j.patcog.2025.112335},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112335},
  shortjournal = {Pattern Recognition},
  title        = {Hyperspectral space transformations for texture classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-target federated backdoor attack based on feature aggregation. <em>PR</em>, <em>172</em>, 112333. (<a href='https://doi.org/10.1016/j.patcog.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current federated backdoor attacks focus on collaboratively training backdoor triggers, where multiple compromised clients train their local trigger patches and then merge them into a global trigger during the inference phase. However, these methods require careful design of the shape and position of trigger patches and lack the feature interactions between trigger patches during training, resulting in poor backdoor attack success rates. Moreover, the pixels of the patches remain untruncated, thereby making abrupt areas in backdoor examples easily detectable by the detection algorithm. To this end, we propose a novel benchmark for the federated backdoor attack based on feature aggregation. Specifically, we align the dimensions of triggers with images, constrain the trigger’s pixel boundaries so that it is within a small range to avoid being detected, and aggregate trigger features from multiple compromised clients to enhance the global trigger’s ability to capture distributed data patterns. Furthermore, leveraging the intra-class attack strategy to train specific triggers for each class of samples, we propose the simultaneous generation of backdoor triggers for all target classes, significantly reducing the overall production time for triggers across all target classes and increasing the risk of the federated model being attacked. Experiments demonstrate that our method can not only bypass the detection of defense methods while patch-based methods fail, but also achieve a zero-shot backdoor attack with a success rate of 77.39 %. To the best of our knowledge, our work is the first to implement such a zero-shot attack in federated learning. Finally, we evaluate attack performance by varying the trigger’s training factors, including poison location, ratio, pixel bound, and trigger training duration (local epochs and communication rounds).},
  archive      = {J_PR},
  author       = {Lingguag Hao and Kuangrong Hao and Bing Wei and Xue-Song Tang},
  doi          = {10.1016/j.patcog.2025.112333},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112333},
  shortjournal = {Pattern Recognition},
  title        = {Multi-target federated backdoor attack based on feature aggregation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LayerMix: Enhanced data augmentation for robust deep learning. <em>PR</em>, <em>172</em>, 112332. (<a href='https://doi.org/10.1016/j.patcog.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) models have demonstrated remarkable performance across various computer vision tasks, yet their vulnerability to distribution shifts remains a critical challenge. Despite sophisticated neural network architectures, existing models often struggle to maintain consistent performance when confronted with Out-of-Distribution (OOD) samples, including natural corruptions, adversarial perturbations, and anomalous patterns. We introduce LayerMix, an innovative Data Augmentation (DA) approach that systematically enhances model robustness through structured fractal-based image synthesis. By meticulously integrating structural complexity into training datasets, our method generates semantically consistent synthetic samples that significantly improve neural network generalization capabilities. Unlike traditional augmentation techniques that rely on random transformations, LayerMix employs a structured mixing pipeline that preserves original image semantics while introducing controlled variability. Extensive experiments across multiple benchmark datasets, including CIFAR-10, CIFAR-100, ImageNet-200, and ImageNet-1K demonstrate LayerMix’s superior performance in classification accuracy and substantially enhances critical Machine Learning (ML) safety metrics, including resilience to natural image corruptions, robustness against adversarial attacks, improved model calibration and enhanced prediction consistency. LayerMix represents a significant advancement toward developing more reliable and adaptable artificial intelligence systems by addressing the fundamental challenges of DL generalization. The code is available at https://github.com/ahmadmughees/layermix .},
  archive      = {J_PR},
  author       = {Hafiz Mughees Ahmad and Dario Morle and Afshin Rahimi},
  doi          = {10.1016/j.patcog.2025.112332},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112332},
  shortjournal = {Pattern Recognition},
  title        = {LayerMix: Enhanced data augmentation for robust deep learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A query-driven twin network framework with optimization-based meta-learning for few-shot hyperspectral image classification. <em>PR</em>, <em>172</em>, 112331. (<a href='https://doi.org/10.1016/j.patcog.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved remarkable results in hyperspectral image (HSI) classification due to its powerful deep feature extraction and nonlinear relationship processing capabilities. However, the success of deep learning methods is largely dependent on extensive labeled samples, which is both time-consuming and labor-intensive. To address this issue, a novel query-driven meta-learning twin network (QMTN) framework is proposed for HSI few-shot learning. QMTN uses two meta-learning channels, allowing for the comprehensive learning of meta-knowledge across diverse meta-tasks and enhancing learning efficiency. Within the QMTN framework, a lightweight spectral-spatial attention residual network is proposed for extraction of HSI features. The network incorporates a residual mechanism in both spectral and spatial feature extraction processes and includes an attention block to improve network performance by focusing on key locations in the spatial features. To maximize the use of the limited samples for constructing diverse meta-tasks, two meta-task generation approaches are employed, with and without simulated noise. Experiments on three public HSI datasets demonstrate that the QMTN framework effectively reduces the dependence on labeled samples in a single scene and significantly improves the classification performance and convergence of the internal network. The meta-task generation method with simulated noise can improve the classification performance of the QMTN.},
  archive      = {J_PR},
  author       = {Jian Zhu and Pengxin Wang and Jian Hui and Xin Ye},
  doi          = {10.1016/j.patcog.2025.112331},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112331},
  shortjournal = {Pattern Recognition},
  title        = {A query-driven twin network framework with optimization-based meta-learning for few-shot hyperspectral image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reliable classification through rank-based conformal prediction sets. <em>PR</em>, <em>172</em>, 112330. (<a href='https://doi.org/10.1016/j.patcog.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning classification tasks often benefit from predicting a set of possible labels with confidence scores to capture uncertainty. However, existing methods struggle with the high-dimensional nature of the data and the lack of well-calibrated probabilities from modern classification models. We propose a novel conformal prediction method that utilizes a rank-based score function suitable for classification models that predict the order of labels correctly, even if not well-calibrated. Our approach constructs prediction sets that achieve the desired coverage rate while managing their size. We provide a theoretical analysis of the expected size of the conformal prediction sets based on the rank distribution of the underlying classifier. Through extensive experiments, we demonstrate that our method outperforms existing techniques on various datasets, providing reliable uncertainty quantification. Our contributions include a novel conformal prediction method, theoretical analysis, and empirical evaluation. This work advances the practical deployment of machine learning systems by enabling reliable uncertainty quantification.},
  archive      = {J_PR},
  author       = {Rui Luo and Zhixin Zhou},
  doi          = {10.1016/j.patcog.2025.112330},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112330},
  shortjournal = {Pattern Recognition},
  title        = {Reliable classification through rank-based conformal prediction sets},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised domain adaptation for cardiac MRI segmentation via adversarial learning in latent space. <em>PR</em>, <em>172</em>, 112328. (<a href='https://doi.org/10.1016/j.patcog.2025.112328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) imaging is crucial for visualizing myocardial infarction (MI), with accurate segmentation of the ventricles and myocardium being essential for effective MI treatment. However, due to the complex myocardial structure and the limited availability of pixel-level annotations in LGE CMR images, accurate segmentation using supervised deep learning methods remains challenging. To address this, we propose an unsupervised domain adaptation framework for LGE CMR segmentation, utilizing CMR images from other modalities. First, we transform balanced Steady-State Free Precession (bSSFP) CMR images, which have abundant annotations, into LGE-like images using an enhanced CycleGAN. This CycleGAN incorporates an adversarial sample mining technique in the latent space to improve the quality of synthetic images. Next, we modify the nnU-Net architecture by introducing non-local blocks to train on these synthetic images, enabling precise segmentation of the myocardium and ventricular regions. We evaluate our method on the MS-CMRSeg 2019 dataset and MyoPS 2020 dataset, achieving an average Dice score of 88.0 % and 82.6 % respectively. Our experimental results demonstrate superior performance compared to state-of-the-art methods. The code for our approach is available at https://github.com/Lucarqi/Adv-CycleGAN .},
  archive      = {J_PR},
  author       = {Fan Zheng and Hengfei Cui and Yanning Zhang and Yong Xia},
  doi          = {10.1016/j.patcog.2025.112328},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112328},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised domain adaptation for cardiac MRI segmentation via adversarial learning in latent space},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficacy of varying sensing features for enhanced performance of deep-learning-informed multidimensional force platform. <em>PR</em>, <em>172</em>, 112327. (<a href='https://doi.org/10.1016/j.patcog.2025.112327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL)-informed vision-based 3D force platforms have demonstrated significant potential for simultaneous assessment of pressure and shear stresses. However, the enhancement of force decoupling capacity is widely recognized as a difficult challenge in the field. For vision-based designs, the marker-embedded sensing layer serves as the pivotal element of the force platform, unveiling diverse sensing characteristics throughout the learning process. However, none of the previous studies have thoroughly investigated the differences among these sensing features and leveraged them to optimize DL models for enhanced performance in multidimensional force detection. This study addresses this gap by systematically evaluating five distinct features (including optical flow, original images, and their derivatives) using four classic CNN architectures. Our comparative analysis reveals a clear feature-force specialization: gray images are most effective for pressure decoupling, while arrow images are superior in decoupling shear stress. Based on this finding, we proposed and validated a dual-branch DL model that fuses these two specialized features. The model achieves a strong, comprehensive performance on both tasks simultaneously, demonstrating the efficacy of our evidence-based feature-fusion strategy. This study provides new insights into sensing feature selection and evidence-based neural network design for vision-based multidimensional force platforms. These advancements have the potential to expedite the deployment of high-performance multidimensional force platforms in real-life applications.},
  archive      = {J_PR},
  author       = {Hu Luo and Yuxin Ma and Zesheng Wang and Jiewen Li and Xin Ma and Wen-Ming Chen},
  doi          = {10.1016/j.patcog.2025.112327},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112327},
  shortjournal = {Pattern Recognition},
  title        = {Efficacy of varying sensing features for enhanced performance of deep-learning-informed multidimensional force platform},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TP-LReID: Lifelong person re-identification using text prompts. <em>PR</em>, <em>172</em>, 112326. (<a href='https://doi.org/10.1016/j.patcog.2025.112326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong person re-identification (LReID) aims to develop a single model that is capable of continuously learning from new domain (present) while retaining knowledge from previously encountered ones (past) and generalizing to unseen domains (future). However, distribution shifts across these domains pose a significant challenge in maintaining performance across past, present, and future domains, that is, causing the catastrophic forgetting on previously seen domains and limited generalization to unseen ones. To address the above issues, we propose to guide consistent feature extraction to bridge distribution shifts using text prompts designed to remain invariant across domains. First, identity-consistent text prompts capturing high-level image semantics are extracted and aligned with image features throughout the lifelong learning pipeline. Moreover, to enhance generalization to unseen domains, we introduce an adversarial training that text features are contrastively aligned with both original and future-style image features, the latter generated by applying gradient-based perturbations in the feature space. Compared with 21 representative models on 11 benchmark datasets, our proposed model, trained without access to historical data, achieves performance comparable to the model trained using a joint training approach, and it performs well on all of the past, present, and future domains. We further explored the forgetting of the first historical domain and the generalization to all unseen domains under all 24 orders, and the results confirmed the superiority of our model. Codes will be released if this paper is accepted.},
  archive      = {J_PR},
  author       = {Zhaoshuo Liu and Zhiwei Guo and Chaolu Feng and Wei Li and Kun Yu and Jun Hu and Jinzhu Yang},
  doi          = {10.1016/j.patcog.2025.112326},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112326},
  shortjournal = {Pattern Recognition},
  title        = {TP-LReID: Lifelong person re-identification using text prompts},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Zoom-shot: Fast, efficient and unsupervised zero-shot knowledge transfer from CLIP to vision encoders. <em>PR</em>, <em>172</em>, 112323. (<a href='https://doi.org/10.1016/j.patcog.2025.112323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models like CLIP demonstrate exceptional capabilities over a broad domain of knowledge, such as with zero-shot classification; however, they also require significant computational resources, narrowing their real-world utility. Recent studies have shown that mapping features from pre-trained vision encoders into CLIP’s latent space can transfer some of CLIP’s abilities to smaller vision encoders, offering a promising alternative. Yet, the performance of these vision encoders still falls short of CLIP’s native capabilities, particularly in low-data regimes. In this work, we argue that enhancing training data coverage/diversity significantly improves mapping efficacy. We achieve this using tailored loss functions rather than relying on data augmentation or increasing training samples. For instance, we exploit the inherent multimodal nature of CLIP’s latent space, by incorporating cycle-consistency loss as one of our loss functions. Moreover, the mapping is learned using entirely unlabelled and unpaired data, eliminating the need for manual labelling or data pairing in novel domains. From these findings, our resulting method (Zoom-shot) offers a viable path to flexible zero-shot models for resource-limited, data-scarce settings. We test Zoom-shot’s zero-shot performance across various pre-trained vision encoders on coarse- and fine-grained datasets and achieve superior performance compared to recent works. In our ablations, we find Zoom-shot allows for a trade-off between data and compute during training; allowing for a significant reduction in required training data. All code and models are available on GitHub.},
  archive      = {J_PR},
  author       = {Jordan Shipard and Arnold Wiliem and Kien Nguyen Thanh and Wei Xiang and Clinton Fookes},
  doi          = {10.1016/j.patcog.2025.112323},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112323},
  shortjournal = {Pattern Recognition},
  title        = {Zoom-shot: Fast, efficient and unsupervised zero-shot knowledge transfer from CLIP to vision encoders},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging. <em>PR</em>, <em>172</em>, 112322. (<a href='https://doi.org/10.1016/j.patcog.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-pixel imaging provides significant advantages for non-visible wavelength detection and ultra-compressed sensing. However, accurate reconstruction from severely under-sampled measurements remains challenging. To tackle this, we propose a novel wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging (WGDNet), which hierarchically reconstructs images through wavelet component-aware reinforcement. Specifically, we design a sampling-guided model to capture essential textures and produce an initial image decomposed into high- and low-frequency components. The low-frequency part is enhanced with adaptive diffusion to preserve structure, while the high-frequency part is directionally incorporated through a multi-frequency adaptive fusion attention (MAFA) mechanism to refine details. Building on this, we develop a residual spatial adaptive fusion (RSAF) module to effectively combine low-frequency structures and high-frequency details. Extensive experiments on five public datasets demonstrate that our method achieves superior performance in both structural preservation and detail recovery. Successful implementation in the imaging system validates the applicability in real scenarios.},
  archive      = {J_PR},
  author       = {Dawei Song and Qiurong Yan and Hui Wang and Jian Yang and Xiaolong Luo},
  doi          = {10.1016/j.patcog.2025.112322},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112322},
  shortjournal = {Pattern Recognition},
  title        = {Wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical community-based graph generation model for improving structural diversity. <em>PR</em>, <em>172</em>, 112320. (<a href='https://doi.org/10.1016/j.patcog.2025.112320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generation remains a challenging task due to the high dimensionality of graphs and the complex dependencies among their edges. Existing models often struggle to produce structurally diverse graphs. To address this limitation, we propose a novel generative framework specifically designed to capture structural diversity in graph generation. Our approach follows a sequential process: initially, a community detection algorithm partitions the input graph into distinct communities. Each community is then generated independently using deep generative models, while a dedicated module concurrently learns the interconnections between communities. To scale to graphs with a larger number of communities, we extend our approach into a hierarchical generative model. The proposed framework not only improves generation accuracy but also significantly reduces generation time for large-scale graphs. Moreover, it enables the application of prior methods that were previously incapable of handling such graphs. To highlight the shortcomings of existing approaches, we conduct experiments on a synthetic dataset comprising diverse graph structures. The results demonstrate substantial improvements in standard evaluation metrics as well as in the quality of the generated graphs.},
  archive      = {J_PR},
  author       = {Masoomeh Sadat Razavi and Abdolreza Mirzaei and Mehran Safayani},
  doi          = {10.1016/j.patcog.2025.112320},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112320},
  shortjournal = {Pattern Recognition},
  title        = {Hierarchical community-based graph generation model for improving structural diversity},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GLGF-CR: A gated local-global fusion approach for cloud removal in real-world remote sensing. <em>PR</em>, <em>172</em>, 112319. (<a href='https://doi.org/10.1016/j.patcog.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical satellite imagery is a critical data source for Earth observation in remote sensing. However, cloud cover often degrades image quality, hindering its application and analysis. Therefore, effective cloud removal from optical satellite images has become a prominent research direction. In real-world scenarios, thick clouds act as pure noise, completely obscuring underlying information, while thin clouds provide partially beneficial information that can be leveraged for reconstruction. Traditional cloud removal methods often fail to distinguish between these two types of noise, leading to suboptimal performance. To address this limitation, we propose a novel cloud removal model, GLGF-CR, which incorporates a Gated Local-Global Fusion module. This module is designed to effectively separate and process the distinct characteristics of thick and thin clouds. For thick clouds, which contain no recoverable information, the model focuses on robust reconstruction using complementary data sources. For thin clouds, the model extracts and utilizes the beneficial information embedded in the partially obscured regions, enabling more accurate and detailed reconstruction. Additionally, a Dual Cross-Attention mechanism is introduced to establish robust mappings between SAR and optical modalities, further improving fusion accuracy. To handle domain shifts between source and target domains, we incorporate a domain adaptation module, which enhances the model’s ability to generalize across diverse real-world scenarios. The proposed algorithm not only outperforms existing methods on the large-scale real-world dataset SEN12MS-CR but also demonstrates strong cross-domain transferability on the Henan flood dataset. By explicitly addressing the dual nature of cloud noise–pure noise in thick clouds and partially beneficial information in thin clouds–this work advances the field of beneficial noise learning, demonstrating how noise can be systematically analyzed and utilized to improve model performance in complex scenarios.},
  archive      = {J_PR},
  author       = {Ganchao Liu and Jiawei Qiu and Jincheng Huang and Yuan Yuan},
  doi          = {10.1016/j.patcog.2025.112319},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112319},
  shortjournal = {Pattern Recognition},
  title        = {GLGF-CR: A gated local-global fusion approach for cloud removal in real-world remote sensing},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised feature selection with concept factorization and robust label learning. <em>PR</em>, <em>172</em>, 112317. (<a href='https://doi.org/10.1016/j.patcog.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is essential for improving model performance in high-dimensional data by identifying the most relevant features. Concept Factorization (CF), building on Non-negative Matrix Factorization (NMF), is valued for revealing meaningful data structure and producing interpretable concept vectors. However, existing CF-based FS methods are typically unsupervised and do not leverage label information, leading to a bias toward high-variance features. This bias can result in the omission of low-variance features that may be highly discriminative, ultimately reducing the effectiveness of FS and compromising model performance, especially in tasks where subtle or rare patterns are important. To address these limitations, this paper proposes SCFLR, a novel semi-supervised FS method that combines CF with robust label learning. SCFLR establishes the CF framework based on the feature space by expressing each concept vector as a conic combination of the feature vectors, thereby leveraging both the underlying data structure and available label information to select a more informative and balanced set of features. To this end, SCFLR defines a linear regression-based loss function derived from the generated concept vectors to leverage information from labeled data. This loss function is further enhanced through a label learning framework based on the L 2 , 1 -norm to ensure a robust label approximation. SCFLR also utilizes the dual-graph regularization to maintain the local geometric structures in both feature and data spaces. In order to tackle the optimization problem of SCFLR, an efficient algorithm, with proof of its convergence, is introduced. Finally, the experimental validation of the SCFLR method on multiple datasets highlights its effectiveness and superior performance compared to other FS methods.},
  archive      = {J_PR},
  author       = {Razieh Sheikhpour and Farid Saberi-Movahed and Mahdi Jalili and Kamal Berahmand},
  doi          = {10.1016/j.patcog.2025.112317},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112317},
  shortjournal = {Pattern Recognition},
  title        = {Semi-supervised feature selection with concept factorization and robust label learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning for DBT classification with saliency-guided 2D synthesis. <em>PR</em>, <em>172</em>, 112316. (<a href='https://doi.org/10.1016/j.patcog.2025.112316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Breast Tomosynthesis (DBT) is a key imaging modality for breast cancer detection, improving lesion visibility by reducing tissue overlap inherent in conventional mammography. In this work, we propose a novel deep learning framework that classifies DBT volumes as malignant or non-malignant, while simultaneously generating a synthetic 2D image to assist diagnostic interpretation. This image is derived from a 3D saliency map computed by the internal attention mechanisms of the model, which highlights and preserves the most diagnostically relevant regions from the original volume. A surface is defined in this saliency space, enabling sampling and projection into a 2D diagnostic representation. This projection offers a compact summary of the volumetric scan, assisting clinicians in diagnostic interpretation and potentially alleviating the cognitive workload. A standard convolutional neural network trained on these synthetic 2D images achieves classification performance comparable to models operating directly on full 3D volumes. We train and evaluate our method on the OPTIMAM dataset and assess generalization through external validation on the independent BCS-DBT dataset without retraining. Results show that the model performs robustly across different clinical sources and provides an interpretable, computationally efficient tool for DBT-based breast cancer diagnosis.},
  archive      = {J_PR},
  author       = {Marco Cantone and Ciro Russo and Federico~V.~L. Dell’Ascenza and Claudio Marrocco and Alessandro Bria},
  doi          = {10.1016/j.patcog.2025.112316},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112316},
  shortjournal = {Pattern Recognition},
  title        = {Deep learning for DBT classification with saliency-guided 2D synthesis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-tolerant scheme and explicit regularizer for deep active learning with noisy oracles. <em>PR</em>, <em>172</em>, 112313. (<a href='https://doi.org/10.1016/j.patcog.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring the query strategies based on deep learning shows promising results in terms of designing the criteria for active learning. However, the labels provided by the oracles might be noisy (inaccurate) due to similarities across several classes causing ambiguity, leading to unreliable results. To address this issue, we propose a noise-tolerant deep active learning method. Specifically, we design a consistency regularization for deep attention network as explicit regularizer, which is used to measure the uncertainty of examples. Besides, we develop the robust model for dealing with the noisy oracles , which first take the associations that make from embeddings of labeled data to those of unlabeled data and back, then we employ the association probability as a weighting fusion schema into angular margin based loss. Moreover, we design the submodular maximization function for reducing the redundancy of selected batch examples. Finally, the formulation is encapsulated into the multi-task framework that helps to adaptive learning towards more generalizable performance. Experimentally, we conduct extensive experiments on classification and segmentation tasks, and the results clearly demonstrate the superiority of the proposed method to the existing state-of-the-art deep active learning approaches.},
  archive      = {J_PR},
  author       = {Yanchao Li and Ziteng Xie and Hongwu Zhong and Guangwei Gao},
  doi          = {10.1016/j.patcog.2025.112313},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112313},
  shortjournal = {Pattern Recognition},
  title        = {Noise-tolerant scheme and explicit regularizer for deep active learning with noisy oracles},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Linguistic query-guided mask generation for referring image segmentation. <em>PR</em>, <em>172</em>, 112306. (<a href='https://doi.org/10.1016/j.patcog.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation aims to segment the image region of interest according to the given language expression, which is a typical multi-modal task. Existing methods either adopt the pixel classification-based or the learnable query-based framework for mask generation, both of which are insufficient to deal with various text-image pairs with a fix number of parametric prototypes. The motivation of this work is to propose an end-to-end framework built on transformer to perform Linguistic query-Guided mask generation, dubbed LGFormer. It views the linguistic features as query to generate a specialized prototype for arbitrary input image-text pair, thus generating more consistent segmentation results. Moreover, we design several cross-modal interaction modules (e.g. vision-language bidirectional attention module, VLBA) in both encoder and decoder to achieve better cross-modal alignment. Extensive experiments demonstrate that our LGFormer achieves a new state-of-the-art performance on ReferIt, RefCOCO+, and RefCOCOg by large margins. Code is available at https://github.com/mqchen1993/LGFormer .},
  archive      = {J_PR},
  author       = {Zhichao Wei and Xiaohao Chen and Mingqiang Chen and Hao Li and Zilong Dong and Siyu Zhu},
  doi          = {10.1016/j.patcog.2025.112306},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112306},
  shortjournal = {Pattern Recognition},
  title        = {Linguistic query-guided mask generation for referring image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TransSTC: Transformer tracker meets efficient spatial-temporal cues. <em>PR</em>, <em>172</em>, 112303. (<a href='https://doi.org/10.1016/j.patcog.2025.112303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, researchers have started developing trackers using the powerful global modeling capabilities of transformer networks. However, existing transformer trackers usually model all template spatial cues indiscriminately and ignore temporal cues of target state changes. This distracts the tracker’s attention and gradually fails to understand the target’s latest state. Therefore, we propose a new tracker called TransSTC, which explores the effective spatial cues in the template and temporal cues during tracking to improve the tracker’s performance. Specifically, we design the target-aware focused coding network to emphasize the efficient spatial cues in the templates, alleviating the impact of spatial cues with low associations of targets in templates on the tracker’s localization accuracy. Additionally, we employ the multi-temporal template update structure that accurately captures variations in the target’s appearance. Within this structure, the collected samples are assessed for target appearance similarity and environmental interference, followed by a three-level sample selection process to ensure the accurate template update. Finally, we introduce the motion constraint framework to dynamically adjust the classification results based on the target’s historical motion trajectory. Extensive experimental results on seven tracking benchmarks demonstrate that TransSTC achieves competitive tracking performance.},
  archive      = {J_PR},
  author       = {Hong Zhang and Wanli Xing and Yifan Yang and Hanyang Liu and Ding Yuan},
  doi          = {10.1016/j.patcog.2025.112303},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112303},
  shortjournal = {Pattern Recognition},
  title        = {TransSTC: Transformer tracker meets efficient spatial-temporal cues},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MGFNet: Multi-granularity medical pattern fusion network for patient risk prediction. <em>PR</em>, <em>172</em>, 112302. (<a href='https://doi.org/10.1016/j.patcog.2025.112302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of patient risk prediction tasks is to predict a patient’s future disease or mortality risk based on his/her historical electronic health record (EHR). Most prior works focus on learning patient evolution patterns from longitudinal EHR data, while ignoring the differences in temporal granularity in medical data, resulting in insufficient information exploitation. To address these limitations, we propose the M ulti- G ranularity Medical Pattern F usion Net work (MGFNet) for patient risk prediction based on temporal data. It learns the evolutionary patterns of medical data at different temporal granularities (both at the vital sign-level and visit-level), and introduces a gated filtering function and a contrastive learning strategy for multi-granularity fusion, which captures fused information from different temporal granularities and supervises each other to obtain a more effective information representation. In addition, for patients with variable visit lengths, we introduce a soft curriculum learning method to learn these patterns by assigning different weights to medical samples to improve prediction accuracy. The final experimental results demonstrate that MGFNet effectively improves the performance of risk prediction compared with state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Lin Cheng and Yuliang Shi and Xiaojing Yu and Xinyu Li and Xinjun Wang and Zhongmin Yan and Zhiyong Chen},
  doi          = {10.1016/j.patcog.2025.112302},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112302},
  shortjournal = {Pattern Recognition},
  title        = {MGFNet: Multi-granularity medical pattern fusion network for patient risk prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning multi-scale spatial-frequency features for image denoising. <em>PR</em>, <em>172</em>, 112300. (<a href='https://doi.org/10.1016/j.patcog.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.},
  archive      = {J_PR},
  author       = {Xu Zhao and Chen Zhao and Xiantao Hu and Hongliang Zhang and Ying Tai and Jian Yang},
  doi          = {10.1016/j.patcog.2025.112300},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112300},
  shortjournal = {Pattern Recognition},
  title        = {Learning multi-scale spatial-frequency features for image denoising},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep intrinsic image decomposition via physics-aware neural networks. <em>PR</em>, <em>172</em>, 112299. (<a href='https://doi.org/10.1016/j.patcog.2025.112299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrinsic image decomposition (IID) aims to separate an observed image into its underlying reflectance and shading components. This task is challenging due to the complex interplay of lighting, surface geometry, and material reflectance in real-world scenes. To address these challenges, this paper proposes a physics-aware deep neural network with a single-encoder, double-decoder architecture. The encoder incorporates an explicit alternating process inspired by a physics-guided model, enabling iterative decoupling of image features into reflectance and shading. Two asymmetric decoders are designed to reconstruct reflectance and shading maps based on their distinct properties. In addition, we introduce a shading loss function leverages spatial distributions of texture and structure. Unlike standard total variation (TV) losses, it employs a texture-likelihood-weighted TV norm, where weights are derived via a patch-matching scheme to distinguish isotropic textures from anisotropic image edges. This design enhances the model’s ability to suppress texture while preserving structure. Experimental results on three datasets (MIT, MPI-Sintel, and IIW) show the effectiveness of our method: on MIT and MPI-Sintel, it reduces the mean-squared-errors of both reflectance and shading by over 40 % compared to existing works, and on IIW, it achieves a superior WHDR score of 13.2, outperforming all existing methods.},
  archive      = {J_PR},
  author       = {Yan Huang and Kangjie Liu and Tengyue Chen and Yong Xu and Hui Ji},
  doi          = {10.1016/j.patcog.2025.112299},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112299},
  shortjournal = {Pattern Recognition},
  title        = {Deep intrinsic image decomposition via physics-aware neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Domain adapter for visual object tracking based on hyperspectral video. <em>PR</em>, <em>172</em>, 112296. (<a href='https://doi.org/10.1016/j.patcog.2025.112296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking based on hyperspectral video attracts increasing attention due to the rich material and motion information in the hyperspectral videos. The prevailing hyperspectral methods adapt pretrained RGB-based object tracking networks for hyperspectral tasks by converting the hyperspectral images into false-color images and fine-tuning the whole network on hyperspectral datasets, which achieves impressive results in challenging scenarios. However, the performance of hyperspectral trackers is limited by the spectral information loss during the transformation, and fine-tuning the entire pretrained network is inefficient for practical applications. To address the issues, a new hyperspectral object tracking method based on domain adaption, hyperspectral adapter for tracking (HyA-T), is proposed in this work. The hyperspectral adapter for the self-attention (HAS) and the hyperspectral adapter for the multilayer perceptron (HAM) are proposed to generate the adaption information and to transfer the multi-head self-attention (MSA) module and the multilayer perceptron (MLP) in pretrained network for the hyperspectral object tracking task by augmenting the spectral information in the original hyperspectral images into the calculation of the MSA and MLP. Additionally, the hyperspectral enhancement of input (HEI) is proposed to augment the original spectral information into the input of the tracking network. The proposed methods extract spectral information directly from the hyperspectral images, which reduce the negative impact of the spectral information loss caused by the transformation. Moreover, only the parameters in the proposed methods are fine-tuned, which is more efficient than the existing methods. Extensive experiments were conducted on four datasets with various spectral bands, verifying the effectiveness of the proposed methods. The HyA-T achieves state-of-the-art performance on all the datasets.},
  archive      = {J_PR},
  author       = {Long Gao and Yunhe Zhang and Langkun Chen and Yan Jiang and Gang He and Weiying Xie and Yunsong Li},
  doi          = {10.1016/j.patcog.2025.112296},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112296},
  shortjournal = {Pattern Recognition},
  title        = {Domain adapter for visual object tracking based on hyperspectral video},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Few-shot image generation via information transfer from the built geodesic surface. <em>PR</em>, <em>172</em>, 112293. (<a href='https://doi.org/10.1016/j.patcog.2025.112293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models trained with limited data often struggle with poor fidelity and diversity. While adapting large pre-trained models is a common solution, such an approach requires significant resources and suitable source domains, which are often unavailable. To address these limitations, we propose Information Transfer from the Built Geodesic Surface (ITBGS), a framework that generates high-quality images from scratch. The core of ITBGS is our Feature Augmentation on Geodesic Surface (FAGS) module, which constructs a Geodesic surface to create a diverse pseudo-source domain from the initial samples. By transferring structural information from the augmented domain to guide the generator’s training, our method completely removes the need for pre-trained models. To refine the output, a supporting Interpolation and Regularization (I&R) module is also introduced to enhance the smoothness and perceptual quality of generated images. Extensive experiments demonstrate that ITBGS achieves state-of-the-art or comparable performance on various few-shot datasets, successfully balancing image fidelity and diversity.},
  archive      = {J_PR},
  author       = {Yuexing Han and Liheng Ruan and Bing Wang},
  doi          = {10.1016/j.patcog.2025.112293},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112293},
  shortjournal = {Pattern Recognition},
  title        = {Few-shot image generation via information transfer from the built geodesic surface},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FADMB: Fully attention-based dual memory bank network for weakly supervised video anomaly detection. <em>PR</em>, <em>172</em>, 112288. (<a href='https://doi.org/10.1016/j.patcog.2025.112288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection is crucial for analyzing surveillance videos and plays a significant role in maintaining public safety. Recent advances in weakly supervised methods, utilizing video-level labels, have improved performance based on techniques like multi-instance learning and temporal modeling. Furthermore, memory banks demonstrate great potential in unsupervised anomaly detection, prompting their integration into weakly supervised setups. However, these methods depend on the Top- k selection mechanism to update the prototypes within memory banks, which has limitations such as overlooking valuable prototypes, leading to a biased updating process, and requiring hyperparameters. To tackle these challenges, we introduce a novel video anomaly detection model, FADMB ( F ully A ttention-based D ual M emory B ank network), which replaces the Top- k selection mechanism with an innovative attention-based prototype updating paradigm to obtain a more comprehensive and robust memory bank. Additionally, we design a Hybrid Encoder that encodes local and global temporal information to produce superior video representations. Extensive experiments demonstrate the superiority of FADMB, achieving 85.79 % AUC on UCF-Crime dataset and 83.29 % AP on XD-Violence dataset.},
  archive      = {J_PR},
  author       = {Zhiming Luo and Shuheng Huang and Kun Yang and Jianzhe Gao and Shaozi Li},
  doi          = {10.1016/j.patcog.2025.112288},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112288},
  shortjournal = {Pattern Recognition},
  title        = {FADMB: Fully attention-based dual memory bank network for weakly supervised video anomaly detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="ras">RAS - 7</h2>
<ul>
<li><details>
<summary>
(2026). Behavior-based navigation of a two-wheeled self-balancing robot using a modified hybrid automaton. <em>RAS</em>, <em>195</em>, 105195. (<a href='https://doi.org/10.1016/j.robot.2025.105195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to advances in robotics science, mobile robots are being used in more and more applications worldwide, and the autonomous navigation of these robots is an important topic in their discussion. This paper focuses on the autonomous navigation of a two-wheeled self-balancing robot (TWSBR) in an unknown environment using behavior-based control in the form of a hybrid automaton. This hybrid automaton includes the behaviors “Go To Goal” and “Avoid Obstacle,” and to avoid the Zeno phenomenon between these two behaviors, another behavior is considered in between, called “Follow Wall,” which the robot uses to move around the obstacle. However, two bugs are identified in the conventional hybrid automaton. The first bug causes the robot to not follow the optimal path. Another bug is that the Zeno phenomenon occurs between the two behaviors “Follow Wall” and “Go To Goal,” causing odometry errors in the experimental environment. The results show that the modified hybrid automaton successfully corrects the bugs and works as intended. The navigation algorithm is designed for the point mass model, so it is transformed to the unicycle model using a transformation, which can be used as input to the TWSBR controller. After linearizing the dynamic equations of the robot around its equilibrium point, the pole placement method is used to create the TWSBR controller. By adding the Luenberger observer to estimate the state variables, the non-full-state feedback system is also controlled. The results of the simulations demonstrate that the whole system is functioning properly so that the robot follows the path determined by the navigation algorithm while maintaining its equilibrium.},
  archive      = {J_RAS},
  author       = {Mohsen Heydari Khalili and Majid Sadedel},
  doi          = {10.1016/j.robot.2025.105195},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105195},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Behavior-based navigation of a two-wheeled self-balancing robot using a modified hybrid automaton},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CPP-DIP: Multi-objective coverage path planning for MAVs in dispersed and irregular plantations. <em>RAS</em>, <em>195</em>, 105193. (<a href='https://doi.org/10.1016/j.robot.2025.105193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coverage Path Planning (CPP) is vital in precision agriculture to improve efficiency and resource utilization. In irregular and dispersed plantations, traditional grid-based CPP often causes redundant coverage over non-vegetated areas, leading to waste and pollution. To overcome these limitations, we propose CPP-DIP, a multi-objective CPP framework designed for Micro Air Vehicles (MAVs). The framework transforms the CPP task into a Traveling Salesman Problem (TSP) and optimizes flight paths by minimizing travel distance, turning angles, and intersection counts. Unlike conventional approaches, our method does not rely on GPS-based environmental modeling. Instead, it uses aerial imagery and a Histogram of Oriented Gradients (HOG)-based approach to detect trees and extract image coordinates. A density-aware waypoint strategy is applied: Kernel Density Estimation (KDE) is used to reduce redundant waypoints in dense regions, while a greedy algorithm ensures complete coverage in sparse areas. To verify the generality and scalability of the framework, TSP instances of varying sizes are solved using three methods: Greedy Heuristic Insertion (GHI), Ant Colony Optimization (ACO), and Monte Carlo Reinforcement Learning (MCRL). An object-based optimization is subsequently applied to further refine the paths. Additionally, CPP-DIP integrates ForaNav, our insect-inspired navigation method, for accurate tree localization and tracking. Experimental results show that MCRL provides a balanced solution, reducing travel distance by 16.9 % compared to ACO while maintaining comparable performance to GHI. It also improves path smoothness by reducing turning angles by 28.3 % and 59.9 % relative to ACO and GHI, respectively, and eliminates intersections. Computational resource comparisons further highlight that GHI scales efficiently with increasing waypoints, whereas ACO and MCRL incur higher computational costs. These results confirm the robustness, efficiency, and scalability of the proposed CPP-DIP.},
  archive      = {J_RAS},
  author       = {Weijie Kuang and Hann Woei Ho and Ye Zhou},
  doi          = {10.1016/j.robot.2025.105193},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105193},
  shortjournal = {Robot. Auton. Syst.},
  title        = {CPP-DIP: Multi-objective coverage path planning for MAVs in dispersed and irregular plantations},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EM-LSD: A lightweight and efficient model for multi-scale line segment detection. <em>RAS</em>, <em>195</em>, 105192. (<a href='https://doi.org/10.1016/j.robot.2025.105192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of detecting line segments in dynamic and geometrically complex environments, EM-LSD, a lightweight and efficient line segment detection model, is introduced. Accurate and efficient detection of line segments is critical for tasks such as environmental modeling and localization in SLAM, where the failure to extract robust line features can result in unreliable mapping and trajectory estimation. The design of EM-LSD is guided by the limitations of existing methods: traditional approaches often fail to capture multi-scale and global features in noisy scenes, while deep learning models with multi-stage architectures impose high computational costs, making them unsuitable for real-time applications. Inspired by the observation that multi-scale feature extraction is essential for handling diverse geometric structures, EM-LSD incorporates a Dense Atrous Convolution (DAC) module to effectively capture multi-scale information with minimal computational overhead. Additionally, the need for robustness against structural complexities and noise led to the integration of dual decoders with a Channel-Spatial Multi-scale Attention (CSMA) module and a Multi-scale Atrous Deformable Block (MADB), enabling adaptive feature representation. Experimental results on the Wireframe and YorkUrban datasets validate EM-LSD’s superior accuracy, robustness, and real-time performance, emphasizing its capability to support resource-constrained SLAM applications. This model not only addresses the limitations of existing methods but also enhances the reliability of environment modeling and localization, offering inspiration for the development of lightweight and efficient detection frameworks.},
  archive      = {J_RAS},
  author       = {Shuo Hu and Liye Zhao and Qing Wang},
  doi          = {10.1016/j.robot.2025.105192},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105192},
  shortjournal = {Robot. Auton. Syst.},
  title        = {EM-LSD: A lightweight and efficient model for multi-scale line segment detection},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Neuromorphic visuotactile slip perception for robotic manipulation. <em>RAS</em>, <em>195</em>, 105191. (<a href='https://doi.org/10.1016/j.robot.2025.105191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visuotactile sensing technology has received extensive attention in the tactile sensing community due to its stable high-resolution deformation sensing capabilities. However, the existing visuotactile sensing methods are far from humanoid neural information processing mechanism. To address this gap, we propose a neuromorphic visuotactile slip detection method named VT-SNN using Tactile Address-Event Representation (TAER) encoding combined with brain-inspired Spiking Neural Network (SNN) modeling in this paper. Our extensive experimental results demonstrate that the VT-SNN achieves slip detection accuracy of 99.59% and F1 score of 99.28%, which is comparable to Artificial Neural Networks (ANNs) while exhibiting significant advantages in power dissipation and inference time. Furthermore, we deployed the VT-SNN on Intel neuromorphic computing chip–Loihi and performed closed-loop slip-feedback robotic manipulation tasks such as bottle-cap tightening and loosening. Our closed-loop neuromorphic visuotactile sensing system shows significant promise for high accuracy, low latency, and low power dissipation for robotic dexterous manipulation.},
  archive      = {J_RAS},
  author       = {Yiming Qiao and Chaofan Zhang and Shaowei Cui and Lu Cao and Zhigang Wang and Peng Wang and Shuo Wang},
  doi          = {10.1016/j.robot.2025.105191},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105191},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Neuromorphic visuotactile slip perception for robotic manipulation},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm. <em>RAS</em>, <em>195</em>, 105190. (<a href='https://doi.org/10.1016/j.robot.2025.105190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstacle-aware configuration control represents a critical challenge in the deployment of continuum robots for advanced applications such as robotic-assisted laparoscopic surgery and intelligent industrial grasping systems. At present, in order to realize the obstacle avoidance function of flexible robots, inverse kinematic calculations are usually unavoidable. The problems of large amount of computation, long solution time, and non-convergence of results make the configuration control for flexible robots still challenging. Most of the current studies use the inverse kinematics calculation of end tracking, and for flexible robots with multiple degrees of freedom, the success rate of obstacle avoidance is low and the computational cost is large. In this paper, a three-segment continuum configuration planning method based on Rapidly-exploring Random Tree (RRT) algorithm is proposed, in which the rough obstacle avoidance path is obtained by RRT algorithm, then the three-segment fitting is carried out by using the second-order Bézier curve, and the length error is evaluated to meet the planning requirements. Experiments such as obstacle avoidance tests, the arrival of target endpoints at different positions and different obstacle environments show that the proposed method can effectively map the feasible solution to the actual configuration. Compared with the inverse kinematics method, the proposed approach improves the success rate of obtaining feasible solutions by at least 14.8% and reduces the solution time by at least 55%. In addition, no prior curvature information and traditional inverse kinematics calculation are needed for the configuration control.},
  archive      = {J_RAS},
  author       = {Qiqi Pan and Hongbo Wang and Yongfei Feng and Shijie Guo and Jingjing Luo},
  doi          = {10.1016/j.robot.2025.105190},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105190},
  shortjournal = {Robot. Auton. Syst.},
  title        = {RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions. <em>RAS</em>, <em>195</em>, 105185. (<a href='https://doi.org/10.1016/j.robot.2025.105185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the following problem: A robot operating in a 2D environment with a limited vision range finds a path to a goal in an unknown environment containing obstacles. In this paper, we propose a novel algorithm to solve the problem. In some special cases, our algorithm is convergent with respect to ‖ . ‖ . The problem involves discovering the environmental map and blind alley regions, that are bounded by obstacles, and it provides no possible passage for robots except in and out of their path entry occur, the robot has to return back to some positions outside to escape from such regions such that the returned path is not longer than the path entry (Blind Alley Region problem, (BAR) problem, in short). To solve the (BAR) problem, sequences of bundles of line segments during the robot’s traveling are constructed in our algorithm. Some advantages of our algorithm are that (a) It reduces search space in blind alley regions because it only works on the sequences of bundles of the line segments built by the robot’s limited vision range. (b) Our algorithm ensures that the returned path to escape from the regions is not longer than the previous path of the robot. (c) Due to the construction of the sequences of bundles of line segments, our paths are not always “close” obstacles and the number of turns of such paths is smaller ones determined by other shortest path algorithms (e.g., A*, RRT*). Our algorithm is implemented in Python and we experience the algorithm on some autonomous robots with different vision ranges in real environment. We also compare our result with RRTX, a state-of-art local path-planning algorithm, and A ∗ , a basic one. The experimental results show that our algorithm provides better solutions than RRTX and A* results in some specific circumstances.},
  archive      = {J_RAS},
  author       = {Phan Thanh An and Pham Hoang Anh and Tran Thanh Binh and Tran Van Hoai},
  doi          = {10.1016/j.robot.2025.105185},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105185},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances. <em>RAS</em>, <em>195</em>, 105184. (<a href='https://doi.org/10.1016/j.robot.2025.105184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust and enhanced control strategy for a multi-quadrotor suspended payload system, which is characterized by complex nonlinear dynamics and unknown external disturbances. A precise dynamic model of the system is formulated using the Udwadia–Kalaba method. A distributed cooperative planning framework, based on graph theory, is employed to enable effective information exchange and cooperative control among multiple quadrotors. To mitigate the impact of unknown disturbances, such as wind fields and variations in payload mass, a disturbance observer is developed to estimate and compensate for these disturbances, thereby enhancing system robustness. Furthermore, an improved prescribed performance control method is proposed to address the issue of exceeding performance boundaries. The steady-state error of the system is effectively reduced by adaptively adjusting the prescribed performance boundary and combining it with integral backstepping, and real-time constraints on tracking errors and closed-loop stability are achieved. Simulation results validate that the proposed control strategy significantly enhances the control performance and disturbance rejection capability of the multi-quadrotor suspended payload system, demonstrating superior robustness.},
  archive      = {J_RAS},
  author       = {Xinyu Chen and Yunsheng Fan and Guofeng Wang and Dongdong Mu},
  doi          = {10.1016/j.robot.2025.105184},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105184},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="spa">SPA - 6</h2>
<ul>
<li><details>
<summary>
(2026). Reflected BSDE driven by a marked point process with a convex/concave generator. <em>SPA</em>, <em>191</em>, 104777. (<a href='https://doi.org/10.1016/j.spa.2025.104777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a class of reflected backward stochastic differential equations (RBSDE) driven by a marked point process (MPP) with a convex/concave generator. Based on fixed point argument, θ -method and truncation technique, the well-posedness of this kind of RBSDE with unbounded terminal condition and obstacle is investigated. Besides, we present an application on the pricing of American options via utility maximization, which is solved by constructing an RBSDE with a convex generator.},
  archive      = {J_SPA},
  author       = {Zihao Gu and Yiqing Lin and Kun Xu},
  doi          = {10.1016/j.spa.2025.104777},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104777},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Reflected BSDE driven by a marked point process with a convex/concave generator},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mixing time and cutoff for the k-SPEP. <em>SPA</em>, <em>191</em>, 104776. (<a href='https://doi.org/10.1016/j.spa.2025.104776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the mixing time of the capacity k symmetric partial exclusion process of Schütz and Sandow with m particles on a segment of length N , and we show that this process exhibits cutoff at time 1 2 k π 2 N 2 log m . We also introduce a related complete multi-species process that we call the S k , N shuffle and show that this process exhibits cutoff at time 1 2 k π 2 N 2 log ( N ) . This extends the celebrated result of Lacoin, which proved cutoff for the symmetric simple exclusion process on a segment of length N and the adjacent transposition shuffle.},
  archive      = {J_SPA},
  author       = {Eyob Tsegaye},
  doi          = {10.1016/j.spa.2025.104776},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104776},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Mixing time and cutoff for the k-SPEP},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Convergence of adapted smoothed empirical measures. <em>SPA</em>, <em>191</em>, 104775. (<a href='https://doi.org/10.1016/j.spa.2025.104775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adapted Wasserstein distance ( AW -distance) controls the calibration errors of optimal values in various stochastic optimization problems, pricing and hedging problems, optimal stopping problems, etc. However, statistical aspects of the AW -distance are bottlenecked by the failure of empirical measures ( Emp ) to converge under this distance. Kernel smoothing and adapted projection have been introduced to construct converging substitutes of empirical measures, known respectively as smoothed empirical measures ( S - Emp ) and adapted empirical measures ( A - Emp ). However, both approaches have limitations. Specifically, S - Emp lack comprehensive convergence results, whereas A - Emp in practical applications lead to fewer distinct samples compared to standard empirical measures. In this work, we address both of the aforementioned issues. First, we develop comprehensive convergence results of S - Emp . We then introduce a smoothed version for A - Emp , which provide as many distinct samples as desired. We refer them as AS - Emp and establish their convergence in mean, deviation and almost sure convergence. The convergence estimation incorporates two results: the empirical analysis of the smoothed adapted Wasserstein distance ( AW ( σ ) -distance) and its bandwidth effects. Both results are novel and their proof techniques could be of independent interest.},
  archive      = {J_SPA},
  author       = {Songyan Hou},
  doi          = {10.1016/j.spa.2025.104775},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104775},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Convergence of adapted smoothed empirical measures},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal control of the nonlinear stochastic Fokker–Planck equation. <em>SPA</em>, <em>191</em>, 104774. (<a href='https://doi.org/10.1016/j.spa.2025.104774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a control problem for the nonlinear stochastic Fokker–Planck equation. This equation describes the evolution of the distribution of nonlocally interacting particles affected by a common source of noise. The system is directed by a controller that acts on the drift term with the goal of minimising a cost functional. We establish the well-posedness of the state equation, prove the existence of optimal controls, and formulate a stochastic maximum principle (SMP) that provides necessary and sufficient optimality conditions for the control problem. The adjoint process arising in the SMP is characterised by a nonlocal (semi)linear backward SPDE for which we study existence and uniqueness. We also rigorously connect the control problem for the nonlinear stochastic Fokker–Planck equation to the control of the corresponding McKean–Vlasov SDE that describes the motion of a representative particle. Our work extends existing results for the control of the Fokker–Planck equation to nonlinear and stochastic dynamics. In particular, the sufficient SMP, which we obtain by exploiting the special structure of the Fokker–Planck equation, seems to be novel even in the linear deterministic setting. We illustrate our results with an application to a model of government interventions in financial systems, supplemented by numerical illustrations.},
  archive      = {J_SPA},
  author       = {Ben Hambly and Philipp Jettkant},
  doi          = {10.1016/j.spa.2025.104774},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104774},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Optimal control of the nonlinear stochastic Fokker–Planck equation},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A tamed euler scheme for SDEs with non-locally integrable drift coefficient. <em>SPA</em>, <em>191</em>, 104772. (<a href='https://doi.org/10.1016/j.spa.2025.104772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we show that for SDEs with a drift coefficient that is non-locally integrable, one may define a tamed Euler scheme that converges in L p at rate 1 / 2 to the true solution. The taming is required in this case since one cannot expect the regular Euler scheme to have finite moments in L p . Our proof strategy involves controlling the inverse moments of the distance of scheme and the true solution to the singularity set. We additionally show that our setting applies to the case of two scalar valued particles with singular interaction kernel. To the best of the authors’ knowledge, this is the first work to prove strong convergence of an Euler-type scheme in the case of non-locally integrable drift.},
  archive      = {J_SPA},
  author       = {Tim Johnston and Sotirios Sabanis},
  doi          = {10.1016/j.spa.2025.104772},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104772},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A tamed euler scheme for SDEs with non-locally integrable drift coefficient},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scaling limit and large deviation for 3D globally modified stochastic Navier–Stokes equations with transport noise. <em>SPA</em>, <em>191</em>, 104770. (<a href='https://doi.org/10.1016/j.spa.2025.104770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the globally modified stochastic (hyperviscous) Navier–Stokes equations with transport noise on 3D torus. We first establish the existence and pathwise uniqueness of the weak solutions, and then show their convergence to the solutions of the deterministic 3D globally modified (hyperviscous) Navier–Stokes equations in an appropriate scaling limit. Furthermore, we prove a large deviation principle for the stochastic globally modified hyperviscous system.},
  archive      = {J_SPA},
  author       = {Chang Liu and Dejun Luo},
  doi          = {10.1016/j.spa.2025.104770},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104770},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Scaling limit and large deviation for 3D globally modified stochastic Navier–Stokes equations with transport noise},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="swevo">SWEVO - 28</h2>
<ul>
<li><details>
<summary>
(2025). Collaborative multi-CP model and meta-feedback learning-assisted matheuristic for solving the flexible job shop scheduling problem with sequence-dependent setup times. <em>SWEVO</em>, <em>99</em>, 102173. (<a href='https://doi.org/10.1016/j.swevo.2025.102173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible job shop scheduling problem with sequence-dependent setup times (FJSP-SDST) is a crucial challenge in modern manufacturing, where varying setup times significantly impact scheduling performance. This challenge has motivated significant research interest in solving FJSP-SDST through both exact and approximate methods. Although existing exact methods, such as mixed-integer linear programming and constraint programming (CP) have been explored, they remain inefficient in solving large-scale instances. To address this limitation, this paper proposes a collaborative multi-CP model, inspired by the collaborative optimization paradigm, which integrates global and local optimization stages to effectively solve large instances. Due to the NP-hard nature of FJSP-SDST, an approximate method, the meta-feedback learning-assisted matheuristic (MFLA-MH) algorithm, is proposed. The algorithm adopts collaborative variable neighborhood search as its main framework and incorporates meta-feedback learning to adaptively guide search operator selection. Additionally, two mathematical neighborhood structures and a mathematical evolution operator, as matheuristic techniques, are designed to optimize the subproblem solutions and overcome the limitations of traditional encoding-decoding methods. Experimental results on 20 real-world cases demonstrate that the collaborative multi-CP model and MFLA-MH efficiently generate high-quality solutions, and outperform state-of-the-art methods.},
  archive      = {J_SWEVO},
  author       = {Weiyao Cheng and Chaoyong Zhang and Leilei Meng and Yaping Ren and Saif Ullah},
  doi          = {10.1016/j.swevo.2025.102173},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102173},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Collaborative multi-CP model and meta-feedback learning-assisted matheuristic for solving the flexible job shop scheduling problem with sequence-dependent setup times},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metaheuristics for analog circuit design optimization: A survey. <em>SWEVO</em>, <em>99</em>, 102170. (<a href='https://doi.org/10.1016/j.swevo.2025.102170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As CMOS technology continues to scale down, the design complexity of very large-scale integrated circuits (VLSI) is rapidly increasing. Analog circuit design, in particular, remains time-consuming due to the critical impact of component dimensions on performance. Although the application of metaheuristics in analog circuit automation dates back to the 1980s, the growing complexity of analog design tasks and the need to reduce design cycles has sparked renewed interest in using metaheuristic approaches to address these challenges. In this paper, we provide a comprehensive and up-to-date review of existing studies on the application of metaheuristics in analog circuit design automation, including circuit synthesis, sizing, and layout synthesis, while assessing their effectiveness in meeting design objectives. The paper provides an in-depth discussion from the metaheuristics perspective and highlights key research directions for future exploration.},
  archive      = {J_SWEVO},
  author       = {Abdelaziz Lberni and Malika Alami Marktani and Abdelaziz Ahaitouf and Ali Ahaitouf},
  doi          = {10.1016/j.swevo.2025.102170},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102170},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Metaheuristics for analog circuit design optimization: A survey},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A preference modified inverted generational distance indicator guided algorithm for evolutionary multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102169. (<a href='https://doi.org/10.1016/j.swevo.2025.102169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference-based evolutionary multi-objective optimization algorithms have attracted much attention in the area of evolutionary computation. However, there are only a few researchers incorporating performance indicators for designing preference-based evolutionary algorithm. In this paper, we propose a preference modified inverted generational distance indicator guided algorithm, named PIGA, for evolutionary multi-objective optimization. The main purpose is that decision-makers provide their preferences, ultimately identifying the portion of Pareto optimal solutions where are located in region of interest. A new preference construction strategy based on coordinate transformation is first proposed. The reference points in the whole objective space can be projected into the preference space, obtaining the preferred reference points. The non-preferred reference points remain in the original objective space, outside the specified preference region. In addition, we define the distance between the candidate solution and preferred reference points as the preference distance and the distance to non-preferred reference points as the penalty distance. Finally, a preference-based modified inverted generational distance indicator is formulated to obtain the preferred optimal solutions according to the preferences and penalty distances. The comparative results are comprehensively analyzed by comparing it with some related preference-based evolutionary algorithms on some test instances. Experimental results have validated the effectiveness and feasibility of the proposed algorithm under different scenarios with the given preference range.},
  archive      = {J_SWEVO},
  author       = {Fei Li and Hao Tian and Hao Shen and Xingyi Zhang and Jianchang Liu and Zaiwu Gong},
  doi          = {10.1016/j.swevo.2025.102169},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102169},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A preference modified inverted generational distance indicator guided algorithm for evolutionary multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Material delivery optimization for make-to-order reconfigurable job shops using an improved chaotic multi-verse algorithm. <em>SWEVO</em>, <em>99</em>, 102167. (<a href='https://doi.org/10.1016/j.swevo.2025.102167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for product customization has highlighted the importance of make-to-order (MTO) material delivery. Although manufacturers have deployed intelligent reconfigurable job shops equipped with flexible workstations and automated guided vehicles (AGVs), challenges remain due to inefficient material scheduling, delayed deliveries, and the complexity arising from diverse material types. This study proposes an active delivery strategy based on a workshop material supermarket, in which both AGV path planning and workstation layout are jointly optimized in response to dynamically changing orders. A multi-objective delivery path model is formulated to support demand splitting while minimizing material delivery costs and maximizing timeliness satisfaction. The model incorporates constraints related to AGV capacity, path feasibility, and demand alignment. To address the nonlinearity and complexity of the problem, an improved chaotic multi-verse optimizer (ICMVO) is proposed. The algorithm employs chaotic encoding to enhance population diversity and mitigate premature convergence. It further integrates gravitational and collision operators to improve global and local search capabilities and adopts adaptive orbital dynamics control to balance exploration and exploitation. A dual-population iterative strategy is employed to enable joint decision-making on workstation coordinates, path direction, and vehicle assignment. Through comprehensive comparisons with state-of-the-art meta-heuristics, the superiority of the ICMVO algorithm and the effectiveness of its components are demonstrated. Moreover, the proposed material delivery optimization method is implemented in a cloud–edge–terminal system and validated in practical MTO reconfigurable job shops through improvements in productivity and cost efficiency.},
  archive      = {J_SWEVO},
  author       = {Qinge Xiao and Kai Wang and Chi Ma and Ye Chen},
  doi          = {10.1016/j.swevo.2025.102167},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102167},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Material delivery optimization for make-to-order reconfigurable job shops using an improved chaotic multi-verse algorithm},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trend analysis-based prediction strategies for dynamic multi-objective evolutionary optimization. <em>SWEVO</em>, <em>99</em>, 102166. (<a href='https://doi.org/10.1016/j.swevo.2025.102166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) change over time, which require Evolutionary algorithms (EA) to track Pareto-optimal solutions (PS) and/or Pareto-optimal front (PF) in a dynamic environment. Most prediction-based algorithms solely use a single model to learn the changing pattern for solution prediction. In the face of complex DMOPs, they may achieve an unsatisfactory performance. To address this issue, a novel trend analysis-based prediction strategy (TAP) is proposed in this paper. Based on previous population information, a simple trend analysis is designed to extract the changing pattern of each solution, and classify them into different types: irregular, translational, and stationary. For irregular changing solutions, a neural network nonlinear model is presented to predict the new location. For translational changing solutions, a simple linear model is built to estimate their new positions. For stationary solutions, they are preserved. As a result, TAP is more responsive to different dynamic environments. TAP is incorporated into the dynamic multiobjective evolutionary algorithm (DMOEA) based on decomposition (MOEA/D) to construct a novel algorithm denoted as MOEA/D-TAP. To verify the performance of the proposed method, comparison experiments are carried out on 26 test instances of four different benchmarks compared with six state-of-the-art methods. The test results indicate that TAP is highly competitive.},
  archive      = {J_SWEVO},
  author       = {Anran Cao and Xiaoli Li and Kang Wang},
  doi          = {10.1016/j.swevo.2025.102166},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102166},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Trend analysis-based prediction strategies for dynamic multi-objective evolutionary optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternating curvature-driven evolutionary genetic algorithm for cable insulation thickness measurement. <em>SWEVO</em>, <em>99</em>, 102164. (<a href='https://doi.org/10.1016/j.swevo.2025.102164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate insulation thickness measurement in industrial cables presents a critical yet challenging optimization problem, characterized by an extremely large solution space and stringent requirements for sub-millimeter precision under real-time constraints. Traditional computer vision approaches struggle with computational complexity when processing irregular cross-sections, while conventional evolutionary algorithms exhibit poor convergence characteristics due to the non-convex search landscape. To address these dual challenges, we propose an Alternating Curvature-Driven Genetic Algorithm (ACD-GA) that innovatively integrates geometric prior knowledge with evolutionary computing. Our key advancement lies in establishing a multi-scale curvature gene information database that synergizes differential geometry with adaptive genetic operators. This hybrid architecture features three core innovations: (1) Adaptive generation of initial populations based on multi-scale curvature characteristics to ensure gene quality and diversity; (2) Alternating crossover-mutation operations guided by curvature information to accelerate solution convergence; (3) A population renewal mechanism combining crossover-mutation with original populations and post-selection updates to preserve high-quality genes. Experiments on both regular and irregular IEC standard specimens demonstrate the superiority of ACD-GA in terms of accuracy, repeatability, and convergence efficiency. Compared with traditional manual inspection and fitted ray methods, ACD-GA reduces the average detection time by over 95.8%, decreases the minimum insulation thickness deviation by more than 89.3%, and significantly improves measurement repeatability. When compared with classical evolutionary algorithms (GA, PSO, ACO, SA, DE) and the latest intelligent methods (PSOCO, HPDE, TDE), ACD-GA achieves reductions of 21.1%–86.7% in minimum thickness deviation and up to 88.5% in repeatability, while maintaining comparable detection efficiency.},
  archive      = {J_SWEVO},
  author       = {Yujie LiuFu and Mingyu Hu and Haoran Xu and Junru Song},
  doi          = {10.1016/j.swevo.2025.102164},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102164},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Alternating curvature-driven evolutionary genetic algorithm for cable insulation thickness measurement},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid metaheuristic algorithms for image watermarking: An experimental study. <em>SWEVO</em>, <em>99</em>, 102163. (<a href='https://doi.org/10.1016/j.swevo.2025.102163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invisible image watermarking is a promising method for protecting the copyright of digital images such as photographs, illustrations, and scans. An effective watermarking algorithm embeds a special mark into an image that does not change the image content but can be extracted from it even after some common post-processing operations such as cropping or compression. Many authors use metaheuristic optimization algorithms to achieve a trade-off between imperceptibility and robustness of embedding. In recent years, researchers have been interested in hybrid metaheuristics, which combine operations of individual metaheuristics in some way. However, designs and compositions of hybrid metaheuristic optimization schemes for image watermarking have not been sufficiently studied to date. In this paper, we present an experimental study of various hybrid metaheuristics including sequential, interleaved, and parallel schemes for popular bioinspired optimization algorithms including genetic algorithm, differential evolution algorithm, particle swarm optimization algorithm, firefly algorithm, and artificial bee colony algorithm. We evaluate the effectiveness of hybrid metaheuristics for image watermarking using an algorithm based on changing the ratio between absolute values ​​of sums of discrete cosine transform coefficient groups as an example and perform an experimental comparison of different schemes. The results of the study show that a approach to metaheuristic hybridization and a composition of hybrid scheme significantly affect the imperceptibility and robustness of the image watermarking algorithm. In particular, the interleaved hybridization type provides the best results for the algorithm under consideration.},
  archive      = {J_SWEVO},
  author       = {Anna Melman and Oleg Evsutin},
  doi          = {10.1016/j.swevo.2025.102163},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102163},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Hybrid metaheuristic algorithms for image watermarking: An experimental study},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal financial portfolio selection using a metaheuristic approach with multiple strategies. <em>SWEVO</em>, <em>99</em>, 102162. (<a href='https://doi.org/10.1016/j.swevo.2025.102162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimisation with cardinality constraints has been extensively studied in the realm of financial investment, recognised as an NP-hard quadratic programming problem. As an innovative metaheuristic approach, the dung beetle optimiser leverages its unique optimisation search mechanism to effectively tackle unconstrained optimisation problems. However, the realities of portfolio optimisation involve various constraints; thus, the original dung beetle optimiser may not suffice. Consequently, this study develops an improved dung beetle optimiser to address cardinality constrained portfolio optimisation, incorporating a new decision variable update strategy, a constraint handling strategy, and a local search strategy. These techniques facilitate the efficient selection of assets from among multiple candidate assets. To validate the capabilities of the indicated methodologies, five datasets from OR-Library and six datasets from NGINX are employed for testing. The results from these datasets consistently indicate that the proposed strategies outperform existing alternatives. Furthermore, the comparison results with various methods presented in other works demonstrate that the proposed technology is competitive in the realm of cardinality constrained portfolio optimisation.},
  archive      = {J_SWEVO},
  author       = {Limin Wang and Guosen Lin and Qijun Zhang and Muhammet Deveci and Seifedine Kadry and Mingyang Li},
  doi          = {10.1016/j.swevo.2025.102162},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102162},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Optimal financial portfolio selection using a metaheuristic approach with multiple strategies},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A population-oriented hybrid search surrogate-assisted evolutionary algorithm for expensive constrained optimization multi-objective problems with small feasible regions. <em>SWEVO</em>, <em>99</em>, 102161. (<a href='https://doi.org/10.1016/j.swevo.2025.102161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization problems with expensive objectives and constraints frequently arise in real industries, such problems are called expensive constrained multi-objective optimization problems(ECMOPs). Due to the expensive cost of actual fitness calculations, constructing suitable surrogates for objectives and constraints is crucial for finding potentially feasible solutions. To enhance the search efficiency of surrogate-assisted multi-objective optimization algorithms in complex, small feasible regions with many decision variables, a population-oriented hybrid search surrogate-assisted evolutionary algorithm is proposed, called PHSEA. In PHSEA, the state of the current population is determined by relevance of the objective optimization and constraint violation reduction, as well as the ideal point change rate. Three search strategies are used: unconstrained, weakly constrained and strongly constrained surrogate-assisted search strategy, to search for feasible solutions. Furthermore, according to different search requirements, three archives with separate update criteria were used to construct the surrogate model for constraint functions. On this basis, we propose a population-oriented hybrid search framework that enhances the algorithm’s ability to search for potential solutions in small feasible regions. The proposed method was compared against two surrogate-assisted algorithms and three surrogate-free algorithms on 33 benchmark problems and 6 real-world engineering problems. Experimental results demonstrate that PHSEA exhibits strong competitiveness in solving ECMOPs characterized by small feasible regions and a large number of decision variables.},
  archive      = {J_SWEVO},
  author       = {Cong Zhu and Yongkuan Yang and Xiangsong Kong and Wenji Li},
  doi          = {10.1016/j.swevo.2025.102161},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102161},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A population-oriented hybrid search surrogate-assisted evolutionary algorithm for expensive constrained optimization multi-objective problems with small feasible regions},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolutionary method with shift pattern learning for real-world multi-skilled personnel scheduling with flexible shifts. <em>SWEVO</em>, <em>99</em>, 102160. (<a href='https://doi.org/10.1016/j.swevo.2025.102160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel scheduling remains a significant organizational challenge with substantial potential for cost and time savings. Despite extensive research in this domain, few studies have been successfully implemented in practice, and even fewer have gained widespread acceptance among end-users. This gap between research and application often arises from oversimplified real-world models, which may result from subjective solution evaluations or a lack of collaboration between modelers and end-users. To bridge this gap, this paper proposes a machine learning-enhanced memetic algorithm (MLMA) that mimics schedules created by experts to solve a highly complex personnel scheduling problem involving multi-skilled workers and flexible shift types (irregular workforce)—a real-world challenge commonly faced in the hospitality sector. By leveraging historical scheduling preferences, the MLMA generates solutions that align with past practices, enhancing their practicality and appeal to end-users. Experiments conducted on real-life instances demonstrate the effectiveness of the proposed approach in addressing real-world problems, where the workforce is predominantly part-time, possesses mixed skills, and requires flexible shifts. Furthermore, the results highlight the MLMA’s ability to identify shift patterns that closely resemble historical schedules, underscoring its potential for practical implementation and its role in bridging the gap between research and real-world application.},
  archive      = {J_SWEVO},
  author       = {Ning Xue and Ruibin Bai and Huan Jin and Tianxiang Cui},
  doi          = {10.1016/j.swevo.2025.102160},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102160},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An evolutionary method with shift pattern learning for real-world multi-skilled personnel scheduling with flexible shifts},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm for integrated design-production-distribution scheduling problems in mass personalized customization. <em>SWEVO</em>, <em>99</em>, 102158. (<a href='https://doi.org/10.1016/j.swevo.2025.102158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, new requirements are proposed for the manufacturing industry transitioning to distributed production models due to emergence of mass personalized customization. Integrated scheduling of design, production and distribution, mixed management of batch and flexible manufacturing are becoming the imminent challenges faced by enterprises. This article proposes an integrated design-production-distribution scheduling problem in distributed mixed shops. It considers distributed flow shops for batch manufacturing and distributed flexible job shops for flexible manufacturing. First, a mixed integer linear programming model is formulized to minimize the maximum completion time, total costs, and total tardiness. Second, a learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm is developed to settle the model. Genetic operators are adopted to improve the global and local search abilities. Three subpopulations with adaptive crossover and mutation probabilities are constructed to enhance the convergence and diversity of population. A Q-learning-assisted cooperative approach is adopted to realize the information communication among subpopulations in the genetic operations. The Q-learning method is used to intelligently choose parent individuals from three subpopulations by utilizing its self-learning strategies. A variable neighborhood search approach considering problem-knowledge neighborhood structures is devised to refine the excellent individuals in population. Finally, the presented algorithm is compared against three well-known intelligent optimization methods on a collection of instances. Comparison outcomes verify the superiority of the developed algorithm in handling the considered problem.},
  archive      = {J_SWEVO},
  author       = {Yanhe Jia and Wei Wang and Jian Zhang},
  doi          = {10.1016/j.swevo.2025.102158},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102158},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm for integrated design-production-distribution scheduling problems in mass personalized customization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster and reinforcement learning-based multi-objective evolutionary algorithm for joint scheduling of virtual machines and prioritize tasks in cloud computing. <em>SWEVO</em>, <em>99</em>, 102156. (<a href='https://doi.org/10.1016/j.swevo.2025.102156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, cloud computing is considered an essential on-demand service that is facing an ongoing problem in Virtual Machine (VM) placement and task scheduling optimization that simultaneously improves server efficiency and user experience. Considering these challenges, this paper aims to reduce the makespan, cost, and total tardiness in Joint Scheduling of Virtual Machines and Prioritize Tasks (JSVPT) by a multi-objective optimization framework. We designed a novel Cluster-Based Multi-Objective Evolutionary Algorithm (MOEA-CD/RLPD) framework, which includes a three-tier encoding scheme with Reinforcement Learning (RL)-guided local search, preselection, and dynamic resource allocation strategy to solve the problem. To guide the search process, we employ K-means clustering to decompose the population into diverse subgroups, promoting balanced exploration. The pre-selection mechanism uses a classifier to identify promising solutions in the decision space, which allows resources to be used effectively. Reinforcement learning adaptively selects intensification operators based on reward feedback, improving exploitation by intensifying promising regions of the search space. An Improved Strength Pareto Evolutionary Algorithm 2 (ISPEA2) is incorporated to maintain a diverse and high-quality Pareto archive. The performance of the proposed algorithm is assessed on multiple test instances covering different scales and benchmarked against five state-of-the-art Multi-Objective Evolutionary Algorithms (MOEAs). Experimental studies demonstrate that the proposed algorithm outperforms most existing algorithms in the literature.},
  archive      = {J_SWEVO},
  author       = {Aanchal Agrawal and Arun Kumar Pal},
  doi          = {10.1016/j.swevo.2025.102156},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102156},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Cluster and reinforcement learning-based multi-objective evolutionary algorithm for joint scheduling of virtual machines and prioritize tasks in cloud computing},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAFSP with limited assembly buffers: A deadlock-free coding-decoding paradigm and hybrid cooperative co-evolutionary approach. <em>SWEVO</em>, <em>99</em>, 102155. (<a href='https://doi.org/10.1016/j.swevo.2025.102155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most prior studies on the Distributed Assembly Flowshop Scheduling Problem (DAFSP) presume infinite buffer capacity for assembly machines. However, in practical DAFSP, assembly buffers are often limited, potentially leading to a deadlock where buffers are full of jobs yet none of them can be assembled into a product. Since the deadlock in DAFSP is caused by incorrect jobs’ sequences in assembly buffers, we formulate a Petri net to model this entry process for the first time. Based on this Petri net model and improved Banker algorithm (IBA), we develop a polynomial-complexity algorithm IDAM to ensure the deadlock-free decoding of a DAFSP solution, which is coded by job and factory permutations. The makespan of such a solution is calculated backward to maintain its deadlock-free property. Furthermore, according to the proposed coding-decoding paradigm for deadlock-free solutions, we propose a hybrid cooperative co-evolution (HCCE) algorithm for DAFSP to minimize the makespan. Notably, our HCCE algorithm incorporates an elite archive (EAR) and two subpopulations. It employs problem-specific operators for heuristic initialization and global-search procedures, and four local-search operators are successively applied to every individual in the EAR. Finally, comprehensive experiments demonstrate the effectiveness and superiority of the proposed HCCE algorithm.},
  archive      = {J_SWEVO},
  author       = {Siyi Wang and Yanxiang Feng and Xiaoling Li and Guanghui Zhang},
  doi          = {10.1016/j.swevo.2025.102155},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102155},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DAFSP with limited assembly buffers: A deadlock-free coding-decoding paradigm and hybrid cooperative co-evolutionary approach},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective combination of mechanisms for particle swarm optimization-based ensemble strategy. <em>SWEVO</em>, <em>99</em>, 102154. (<a href='https://doi.org/10.1016/j.swevo.2025.102154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-quality ensemble strategy can effectively integrate several coefficients, mechanisms, and algorithms into a single framework. The adaptability, timing of intervention, and complementarity are the key factors to consider for the selected coefficients, mechanisms, and algorithms. In this study, two complementary variants based on Particle Swarm Optimization (PSO), namely Modified PSO (MPSO) and Social Learning PSO (SLPSO), were selected, forming IMPSO and ISLPSO after improvements. IMPSO excels at exploration, while ISLPSO excels at exploitation. The Improved Novel Ratio Adaptation Scheme (INRAS) is employed as a selection strategy and provides the ability to abandon less-optimal particles. The Modified Nonlinear Population Size Reduction (MNLPSR) enables the extension of generations, allowing for more sufficient evolution in later stages. Due to the use of MNLPSR, an improved inertia weight and adaptive acceleration coefficients are introduced to ensure compatibility with the proposed algorithm. Additionally, an improved dynamic differential mutation strategy is designed not only to be compatible with the proposed algorithm but also to enhance particle diversity. Both the Improved Sine Cosine Algorithm (ISCA) and Sequential Quadratic Programming (SQP), which focus on searching near the global best particles, are incorporated into the proposed ensemble strategy. This PSO-based variant is named the Effective Combination of Mechanisms for a PSO-based Ensemble Strategy (ECM-PSOES). Ablation experiments demonstrated the effectiveness of the individual coefficients and mechanisms. The novel PSO-based variant was evaluated on the CEC2017 benchmarks and compared with 14 state-of-the-art PSO-based variants and 11 non-PSO algorithms. Additionally, to evaluate the flexible and robust capability of the proposed algorithm, three real-world applications for long-term Transmission Network Expansion Planning (TNEP), Planetary Gear Train Design (PGTD), and Robot Gripper Design (RGD) were tested. The experimental results illustrate that the proposed algorithm displays superior performance compared to recently proposed PSO-based variants and most non-PSO algorithms. However, the proposed algorithm falls short of outperforming Differential Evolution (DE)-based algorithms and still requires time to match the performance of top-tier metaheuristics. The source code of ECM-PSOES is provided at https://github.com/microhard1999/CODES .},
  archive      = {J_SWEVO},
  author       = {Libin Hong and Zhantao Gu and Ruibin Bai and John Woodward and Ender Özcan},
  doi          = {10.1016/j.swevo.2025.102154},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102154},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An effective combination of mechanisms for particle swarm optimization-based ensemble strategy},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive weight optimization algorithm based on decision variable grouping for large-scale multi-objective optimization problems. <em>SWEVO</em>, <em>99</em>, 102149. (<a href='https://doi.org/10.1016/j.swevo.2025.102149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving large-scale multi-objective optimization problems (LSMOPs), the optimization effect of traditional multi-objective optimization algorithms deteriorates as the number of decision variables increases. The weight optimization method based on problem transformation can effectively address LSMOPs, demonstrating superior convergence compared to most evolutionary algorithms. However, existing problem transformation methods often fail to balance convergence and diversity, leading to get trapped in local optima. In order to effectively solve this problem, we propose an adaptive weight optimization algorithm based on variable grouping (GWOEA). The algorithm optimizes weights within groups to accelerate population convergence, while the adaptive control strategy boosts diversity, avoiding local optima and ensuring a balance between convergence and diversity during the optimization process. To reduce the size of solving LSMOPs, weight optimization is performed by grouping decision variables. The weights of variables within each group are first computed, and then these weights are directly optimized instead of the decision variables. The adaptive control strategy is designed to detect whether population evolution has stagnated and to handle stagnant populations, ensuring that the population retains its ability to explore. To evaluate the effectiveness of GWOEA, comprehensive comparative experiments are conducted on benchmark test problems, including variable sizes ranging from 500 to 5000. The results show that the proposed algorithm has relatively better optimization performance.},
  archive      = {J_SWEVO},
  author       = {Hao Wang and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.102149},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102149},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An adaptive weight optimization algorithm based on decision variable grouping for large-scale multi-objective optimization problems},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GTG-ACO: Graph transformer guided ant colony optimization for learning heuristics and pheromone dynamics for combinatorial optimization. <em>SWEVO</em>, <em>99</em>, 102147. (<a href='https://doi.org/10.1016/j.swevo.2025.102147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization (CO) problems are fundamental to numerous real-world applications, ranging from logistics and scheduling to resource allocation. For solving CO problems, Ant Colony Optimization (ACO) is a widely used metaheuristic that simulates cooperative foraging behavior to iteratively construct high-quality solutions. However, traditional ACO suffers from handcrafted heuristic functions that fail to generalize across different instances and uniform pheromone initialization, which results in inefficient exploration and slow convergence. To address these limitations, we introduce G raph T ransformer G uided A nt C olony O ptimization- GTG-ACO , a novel approach that jointly learns both heuristic and initial pheromone matrices, enabling the model to generalize across diverse problem instances without manual tuning. Additionally, GTG-ACO employs Graph Transformer augmented with Squeeze-and-Excitation (SE) network as the backbone for heuristic and pheromone learner. The Graph Transformers enable adaptive representation learning by leveraging attention mechanisms to dynamically capture structural relationships in graph representation of combinatorial optimization problems. Additionally, SE networks enhance the model by recalibrating feature importance, ensuring that critical information is amplified while suppressing less relevant features. Extensive evaluations on four combinatorial optimization problems—Traveling Salesman Problem (TSP), Capacitated Vehicle Routing Problem (CVRP), Single Machine Total Weighted Tardiness Problem (SMTWTP) and Bin Packing Problem (BPP)—demonstrate that GTG-ACO consistently outperforms state-of-the-art baselines achieving improvements ranging from 1% to 56%. Furthermore, we validate its real-world applicability by evaluating it on benchmark datasets TSPLIB and CVRPLIB. Thus, GTG-ACO establishes itself as a powerful and generalizable framework by jointly learning heuristic and pheromone matrices, enabling more informed exploration, which leads to superior solution quality in combinatorial optimization problems. Our code is publicly available at https://github.com/abrarrahmanabir/GTG-ACO .},
  archive      = {J_SWEVO},
  author       = {Abrar Rahman Abir and Muhammad Ali Nayeem and M. Sohel Rahman and Md Adnan Arefeen},
  doi          = {10.1016/j.swevo.2025.102147},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102147},
  shortjournal = {Swarm Evol. Comput.},
  title        = {GTG-ACO: Graph transformer guided ant colony optimization for learning heuristics and pheromone dynamics for combinatorial optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective multi-UAV path planning via evolutionary multitasking optimization with adaptive operator selection and knowledge fusion. <em>SWEVO</em>, <em>99</em>, 102145. (<a href='https://doi.org/10.1016/j.swevo.2025.102145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is crucial for UAV task execution, underpinning effective aerial reconnaissance and precision strikes. An ideal flight path must both minimize travel distance and reduce the risk of enemy detection or destruction. Due to the inherent trade-off between these objectives, multi-UAV path planning is conventionally formulated as a multiobjective optimization problem. However, as the number of obstacles, threats, and UAVs increases, the computational complexity escalates, hindering the generation of optimal path planning solutions via conventional multiobjective optimization approaches. To address this challenge, we model a multiobjective multi-UAV path planning (MOMUPP) problem that simultaneously optimizes flight distance and threat cost, with the latter quantified using line-of-sight theory and terrain occlusion effects. We further construct an auxiliary task that approximates the MOMUPP problem and develop an evolutionary multitasking framework to facilitate effective knowledge transfer between tasks. Building on this framework, we propose the evolutionary multitasking multiobjective path planning (EMMOP) algorithm. EMMOP incorporates a double deep Q-networks-based adaptive operator selection (DAOS) mechanism that dynamically selects the optimal search operators for each task based on the current evolutionary state, thereby generating high-quality offspring. Additionally, a knowledge transfer strategy based on directional information extraction and knowledge fusion (KTDF) enables efficient exchange of critical information between the main and auxiliary tasks. Experiments on 15 benchmark instances across five map scenarios indicate that EMMOP outperforms five state-of-the-art methods, enhancing hypervolume by 2.46% and pure diversity by 28.27%, while generating shorter, safer, and collision-free UAV paths with diverse trade-off solutions for decision-makers. The source code is available at https://github.com/Leopard125/EMMOP .},
  archive      = {J_SWEVO},
  author       = {Kai Meng and Binghong Wu and Bin Xin and Fang Deng and Chen Chen},
  doi          = {10.1016/j.swevo.2025.102145},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102145},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multiobjective multi-UAV path planning via evolutionary multitasking optimization with adaptive operator selection and knowledge fusion},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic performance evaluation of evolutionary multi-objective optimization algorithms for gait cycle optimization of a 25-DOFs NAO humanoid robot. <em>SWEVO</em>, <em>99</em>, 102144. (<a href='https://doi.org/10.1016/j.swevo.2025.102144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are increasingly using optimization methods to achieve optimal dynamic performance of humanoid robots, often involving multiple conflicting objectives. Multi-objective optimization algorithms (MOAs) aim to find a Pareto front of optimal solutions, but selecting the best algorithm based on solution quality and computational efficiency remains challenging. This study comprehensively evaluates MOAs from different paradigms: swarm intelligence (CMOPSO), genetic algorithms (NSGA-II, DCNSGA-III), and decomposition-based approaches (CMOEA/D) for optimizing the gait cycle of a 25 DOF NAO humanoid robot during single support phase (SSP) and double support phase (DSP) scenarios. The algorithms’ convergence, diversity, and constraint-handling capabilities are systematically analyzed in solving the gait generation problem. The bi-objective optimization simultaneously minimizes power consumption and maximizes dynamic stability subject to eight functional constraints with 12-13 decision parameters. Through performance evaluation using running inverted generational distance (IGD) and hypervolume (HV) metrics across eleven independent runs of each algorithm, NSGA-II emerges as the most suitable algorithm, demonstrating superior convergence and solution quality, while CMOPSO shows competitive performance with faster initial convergence. DCNSGA-III exhibits moderate performance with constraint-handling difficulties, and CMOEA/D demonstrates poor convergence characteristics requiring significantly more computational resources. Two distinct knee regions emerge during both SSP and DSP, representing optimal trade-off solutions, with a systematic framework provided for practitioners to select appropriate gait parameters based on operational priorities. The running IGD metric combined with HV validation demonstrates effectiveness in providing robust algorithmic insights, enabling practitioners to select suitable algorithms for similar complex real-world optimization problems.},
  archive      = {J_SWEVO},
  author       = {Pushpendra Gupta and Dilip Kumar Pratihar and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.102144},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102144},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Dynamic performance evaluation of evolutionary multi-objective optimization algorithms for gait cycle optimization of a 25-DOFs NAO humanoid robot},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive landscape-aware repelling restart covariance matrix adaptation-evolution strategy for multimodal and global optimization. <em>SWEVO</em>, <em>99</em>, 102143. (<a href='https://doi.org/10.1016/j.swevo.2025.102143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal optimization using Covariance Matrix Adaptation-Evolution Strategy (CMA-ES), redundant restarts are caused by repeated convergence to previously explored local basins, which leads to significant computational resource waste. To address this problem, previous research proposed the concept of Repelling Restart and developed RR-CMA-ES, but issues remain regarding rigid repulsion and gradient information of local basin structures. Building on this foundation, we propose an Adaptive Landscape-aware Repelling Restart CMA-ES (ALR-CMA-ES) that enhances the original RR-CMA-ES through three key improvements: 1) A fitness sensitive dynamic exclusion mechanism that adaptively adjusts tabu region radius based on local optimality and convergence frequency, prioritizing avoidance of high-quality basins; 2) A covariance matrix mechanism preserving convergence history to geometrically align hyper-ellipsoidal exclusion regions with explored local basin landscapes; 3) A Boltzmann-like probabilistic acceptance scheme incorporating exclusion regions, permit- ting controlled exploration near tabu boundaries. Experiments on the BBOB benchmark demonstrate that ALR-CMA-ES outperforms RR-CMA-ES in 90% of tested problems spanning 2D to 50D. This method provides a practical solution for expensive black-box optimization by systematically integrating landscape topology awareness into tabu mechanisms, while proposing a new solution for multimodal optimization problems.},
  archive      = {J_SWEVO},
  author       = {Xikang Wang and Tongxi Wang and Hua Xiang},
  doi          = {10.1016/j.swevo.2025.102143},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102143},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Adaptive landscape-aware repelling restart covariance matrix adaptation-evolution strategy for multimodal and global optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-learning classification-based multi-objective evolutionary algorithm for machine multi-state energy-efficient flexible job shop scheduling under time-of-use pricing. <em>SWEVO</em>, <em>99</em>, 102142. (<a href='https://doi.org/10.1016/j.swevo.2025.102142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the “dual carbon” strategic goals, the coordinated optimization of energy consumption and production efficiency has become a core issue for manufacturing industries. As an important means to promote energy structure transformation, electric substitution has made significant progress in industrial manufacturing, transportation, household electrification, and other fields. Among them, industrial production accounts for over 60% of the total electric energy substitution, becoming the largest electricity consumer. Note that the electricity price is based on time-of-use pricing (TOU), meanwhile, electric consumption is related to the machine multi-state (MM). Regarding these matters, this study focuses on determining sensible machine states and formulating reasonable production scheduling plan, to minimize both production time and power consumption. First, a novel energy-efficient flexible job shop scheduling problem is developed, which considers both the TOU strategy and the MM conditions (EFJSP-MM-TOU). Second, a self-learning classification-based multi-objective evolutionary algorithm (SCMOEA) is proposed to solve the EFJSP-MM-TOU. In specific, the SCMOEA enhances population diversity through a hybrid initialization strategy, adopts a dynamic selection of cross individuals based on the self-learning classification mechanism to improve the search efficiency, and designs four local search operators to increase the potential for approaching better positions. Third, by employing the MK standard dataset in EFJSP-MM-TOU, the proposed SCMOEA is compared with its three variants and five state-of-the-art algorithms to verify its optimization performance. The experimental results suggest that SCMOEA has advantages in terms of Pareto optimal solutions’ diversity and convergence. Finally, by testing in an actual enterprise case, the results further support the effectiveness of the EFJSP-MM-TOU and the significance of SCMOEA.},
  archive      = {J_SWEVO},
  author       = {Da Wang and Lina Qian and Kai Zhang and Dengwang Li and Shicun Zhao and Junqing Li},
  doi          = {10.1016/j.swevo.2025.102142},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102142},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A self-learning classification-based multi-objective evolutionary algorithm for machine multi-state energy-efficient flexible job shop scheduling under time-of-use pricing},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using genetic programming to improve data collection for offline reinforcement learning. <em>SWEVO</em>, <em>99</em>, 102140. (<a href='https://doi.org/10.1016/j.swevo.2025.102140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (RL) learns policies solely from fixed pre-collected datasets, making it applicable to use-cases where data collection is expensive or risky. Consequently, the performance of these offline learners is highly dependent on the dataset used. Still the questions of how this data is collected and what dataset characteristics are needed are not thoroughly investigated. Simultaneously, evolutionary methods have reemerged as a promising alternative to classic RL, leading to the field of evolutionary RL (EvoRL), combining the two learning paradigms to exploit their supplementary attributes. This study aims to join these research directions and examine the effects of Genetic Programming (GP) on dataset characteristics in RL and its potential to enhance the performance of offline RL algorithms. A comparative approach was employed, comparing Deep Q-Networks (DQN) and GP for data collection across multiple environments and collection modes. The exploration and exploitation capabilities of these methods were quantified and a comparative analysis was conducted to determine whether data collected through GP led to superior performance in multiple offline learners. The findings indicate that GP demonstrates strong and stable performance in generating high-quality experiences with competitive exploration. GP exhibited lower uncertainty in experience generation compared to DQN and produced high trajectory quality datasets across all environments. More offline algorithms showed statistically significant performance gains with GP-collected data than trained on DQN-collected trajectories. Furthermore, their performance was less dependent on the environment, as the GP consistently generated high-quality datasets. This study showcases the effective combination of GP's properties with offline learners, suggesting a promising avenue for future research in optimizing data collection for RL.},
  archive      = {J_SWEVO},
  author       = {David Halder and Georgios Douzas and Fernando Bacao},
  doi          = {10.1016/j.swevo.2025.102140},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102140},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Using genetic programming to improve data collection for offline reinforcement learning},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple direction search algorithm for continuous optimization. <em>SWEVO</em>, <em>99</em>, 102138. (<a href='https://doi.org/10.1016/j.swevo.2025.102138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The particle swarm optimization algorithm has been successfully applied to various optimization problems. One of its key features is the combination of particle velocity and search direction towards the optimal position in the history and swarm. Recognizing the limitations of the particle swarm optimization algorithm, this paper proposes a new evolutionary algorithm called the multiple direction search algorithm. The algorithm integrates five different search directions, including a multi-point direction constructed using principal component analysis. The integrated direction is generated by the weighted sum of the search directions. Theoretical analysis shows that under mild conditions, the rate of convergence along the weighted direction is no worse than the rate of convergence along the best of single search directions by a positive constant, or even faster in certain cases. The performance of the proposed algorithm was evaluated on three benchmark test suites by computer simulation. Experimental results demonstrate that the proposed method outperforms seven state-of-the-art particle swarm optimization algorithms.},
  archive      = {J_SWEVO},
  author       = {Wei Huang and Jun He and Liehuang Zhu},
  doi          = {10.1016/j.swevo.2025.102138},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102138},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A multiple direction search algorithm for continuous optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-tightening based adaptive two-stage evolutionary algorithm for constrained multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102137. (<a href='https://doi.org/10.1016/j.swevo.2025.102137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) are prevalent in practical applications, yet existing methods often struggle to handle their diverse characteristics, such as disconnected feasible regions and infeasible solutions near the true constraints Pareto front (CPF). To address these challenges, this paper proposes a constraint-tightening based adaptive two-stage evolutionary algorithm (CT-TSEA) for CMOPs, incorporating a constraint boundary tightening strategy and parameter dynamic adjustment strategy. In the first stage, a constraint boundary tightening strategy based on evaluation counts guides the population toward feasible regions. Initially, constraint boundaries are relaxed to explore the solution space thoroughly, identifying promising solutions. As evaluations increase, the search boundaries shrink, enhancing the feasibility of solutions. Additionally, a step-size adaptive adjustment method improves infeasible solutions using their information, boosting search efficiency and solution diversity. The second stage introduces a dynamic adjustment method for crossover probability and scaling factor, balancing exploration and exploitation. It better balances the exploration and exploitation capabilities of the population. The proposed method is validated via comparing with seven state-of-the-art peer competitors across 59 test instances from four benchmark suites and 21 real-world problems. The corresponding results demonstrate that CT-TSEA has the higher competitiveness in addressing complex CMOPs.},
  archive      = {J_SWEVO},
  author       = {Cunyan Liu and Qingda Chen and Junhua Liu and Wei Zhang and Meng Wang and Can Liu},
  doi          = {10.1016/j.swevo.2025.102137},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102137},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Constraint-tightening based adaptive two-stage evolutionary algorithm for constrained multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploratory landscape analysis on black-box optimization problems via graph neural network. <em>SWEVO</em>, <em>99</em>, 102136. (<a href='https://doi.org/10.1016/j.swevo.2025.102136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most real-world optimization problems are poorly understood, some of which are black-box optimization problems (BBOPs). Exploratory landscape analysis (ELA) paves the way for algorithm design to deal with BBOPs. Existing ELA methods have limitations on unseen problems and lack analysis on the problem itself. To this end, this study introduces a novel ELA framework leveraging Graph Neural Network (GNN) upon BBOP’s surrogate model. Specifically, a neural network surrogate model is constructed whose architecture is utilized to represent BBOP in the form of graph. Then, GNN is responsible for capturing the relationships between the graph-represented BBOP and high-level features. As one of the most notable features in optimization, multimodality of multi-objective problems is to be identified for illustration. More than 99% accuracy on independent test set demonstrates the effectiveness of the proposed framework with simultaneously avoiding the effect of problem dimensions.},
  archive      = {J_SWEVO},
  author       = {Xu Yang and Rui Wang and Kaiwen Li and Wenhua Li and Tao Zhang},
  doi          = {10.1016/j.swevo.2025.102136},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102136},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Exploratory landscape analysis on black-box optimization problems via graph neural network},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention-based joint value estimation strategy for multi-agent coordination optimization. <em>SWEVO</em>, <em>99</em>, 102132. (<a href='https://doi.org/10.1016/j.swevo.2025.102132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordination optimization plays a vital role in complex multi-agent systems, and Multi-Agent Reinforcement Learning (MARL) has emerged as a widely adopted solution. However, MARL still faces significant challenges in this domain, including low coordination efficiency and inaccurate value estimation. To address these issues, we propose MVAPO, a novel Multi-Head Joint Value Attention-based Policy Optimization algorithm that improves policy learning through enhanced value approximation and selective attention to agent contributions. The key innovation of MVAPO lies in the introduction of a joint value network augmented with a multi-head attention mechanism. In this mechanism, context-aware team rewards serve as query inputs, directing attention to the most relevant agents in different situations. This allows the model to dynamically focus on the agents that are most critical at any given time, thus improving coordination efficiency and the accuracy of value estimates. Furthermore, MVAPO incorporates feedforward and residual layers, eliminating linear and monotonic constraints, which significantly enhances its representational capacity. Extensive experiments on a multi-UAV benchmark across a variety of scenarios demonstrate that MVAPO consistently outperforms state-of-the-art methods in both reward acquisition and win rates, highlighting its superior performance and robustness.},
  archive      = {J_SWEVO},
  author       = {Ze Wang and Ni Li and Guanghong Gong and Haitao Yuan},
  doi          = {10.1016/j.swevo.2025.102132},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102132},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An attention-based joint value estimation strategy for multi-agent coordination optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA2MODE: Dynamic archive with adaptive multi-operator differential evolution for numerical optimization. <em>SWEVO</em>, <em>99</em>, 102130. (<a href='https://doi.org/10.1016/j.swevo.2025.102130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Dynamic Archive with Adaptive Multi-Operator Differential Evolution (DA2MODE), a new algorithm that aims to boost the performance of meta-heuristic and evolutionary methods in numerical optimization. DA2MODE introduces a Progressive Adaptive Selector with Exponential Smoothing (PASES), which dynamically updates the selection probabilities of both mutation and crossover operators. Unlike prior approaches that emphasize only mutation operators or rely on short-term success within the current generation, PASES adapts based on cumulative operator performance over time, thus favoring the best-performing operators more reliably. DA2MODE employs an Adaptive Non-Elite Archive Update (ANEAU) mechanism that injects a controlled fraction of non-elite solutions into the archive. ANEAU promotes early exploration, which is gradually reduced to strengthen exploitation. Additionally, the control parameters (crossover probability and mutation factor) are automatically tuned in DA2MODE, allowing full adaptivity of both operator selection and parameter control. Extensive experiments on the CEC2017/2018, CEC2020-2022, and 1000-dimensional CEC2013 benchmarks, along with four real-world engineering design problems, confirm that DA2MODE consistently outperforms 33 competitive algorithms, including CEC winners and recent advanced DE variants. It achieves top performance across all statistical tests, demonstrating superior convergence speed and final accuracy. These results establish DA2MODE as a robust, scalable, and reliable algorithm for solving complex numerical optimization problems. The source code of the DA2MODE algorithm is publicly available at: URL https://github.com/MohamedRedaMu/DA2MODE-Algorithm and URL https://uk.mathworks.com/matlabcentral/fileexchange/182019-da2mode-algorithm .},
  archive      = {J_SWEVO},
  author       = {Mohamed Reda and Ahmed Onsy and Amira Y. Haikal and Ali Ghanbari},
  doi          = {10.1016/j.swevo.2025.102130},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102130},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DA2MODE: Dynamic archive with adaptive multi-operator differential evolution for numerical optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale multi-objective optimization framework based on a dual-space attention mechanism. <em>SWEVO</em>, <em>99</em>, 102089. (<a href='https://doi.org/10.1016/j.swevo.2025.102089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing attention-based methods for large-scale multi-objective optimization (LMOAM) focus only on decision variables, using their variance to guide search behavior. However, single-space strategies ignore critical information in the objective space and the diversity and search efficiency are often degraded for solving multimodal multi-objective optimization problems (MOPs). To address this problem, a novel large-scale optimization framework that integrates a dual-space attention mechanism is proposed in this paper. Different from building attention only with information in decision space, a dual-space Key matrix that quantifies variable importance by combining decision-variable and objective-space distributions is first designed in the framework to refine the precision of the attention. Subsequently, a cross-space clustering method is adopted to select the representative solutions by analyzing the characteristics of individuals in both spaces to construct the Query matrix. The accuracy of attention allocation is improved. Finally, A linear inverse mapping strategy is used to enhance the diversity of the population by translating promising objective-space solutions back to the decision space. Unlike existing approaches, the characteristics of decision and objective space are linked with a new attention mechanism, and the exploration and exploitation of the population are well balanced. Three types of experiments are designed on two benchmark test sets with 500-dimensional and 1000-dimensional decision variables and the voltage transformer optimization problem to demonstrate the efficacy of the AIDF framework, experimental results indicate that AIDF surpasses comparative algorithms in terms of the average performance of IGD and HV.},
  archive      = {J_SWEVO},
  author       = {Xu Li and Debao Chen and Feng Zou and Fangzhen Ge and Zhenghua Xin},
  doi          = {10.1016/j.swevo.2025.102089},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102089},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A large-scale multi-objective optimization framework based on a dual-space attention mechanism},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PheroCom: Decentralised and asynchronous robot swarm coordination framework based on virtual pheromone and vibroacoustic communication. <em>SWEVO</em>, <em>99</em>, 102083. (<a href='https://doi.org/10.1016/j.swevo.2025.102083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing and controlling the dynamics of stigmergic substances used by bio-inspired approaches pose significant challenges when applied to robotics. In order to overcome this challenge, this work proposes a framework based on the virtualisation and control of these substances at a local scope, with the primary goal of coordinating robot swarms. This framework introduces a novel pheromone representation that enables decentralisation and decision asynchronicity, while its lightweight design ensures accessibility to resource-constrained platforms. Each robot maintains an independent virtual pheromone map in its memory, which is continuously updated through its own pheromone deposits and evaporation. Additionally, each robot’s pheromone map is also updated by aggregating information from other robots that are exploring nearby areas. Consequently, individual and independent maps eliminate the need for a centralised agent to manage and distribute pheromone information. This propagation mechanism is inspired by ants’ vibroacoustic communication, which is characterised as a form of indirect communication. The framework was evaluated using an agent-based mass simulation tool and a real-world simulation platform. Experiments were conducted to validate the framework in diverse environments, with variations in shapes, sizes, and the number of robots. Results demonstrated that this proposal can effectively perform the coordination of robot swarms, and the robots have exhibited satisfactory performance while executing the surveillance task.},
  archive      = {J_SWEVO},
  author       = {Claudiney R. Tinoco and Luiz Gustavo A. Martins and Gina M.B. Oliveira},
  doi          = {10.1016/j.swevo.2025.102083},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102083},
  shortjournal = {Swarm Evol. Comput.},
  title        = {PheroCom: Decentralised and asynchronous robot swarm coordination framework based on virtual pheromone and vibroacoustic communication},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tcs">TCS - 9</h2>
<ul>
<li><details>
<summary>
(2025). Optimal gathering of robots in anonymous butterfly networks via leader election. <em>TCS</em>, <em>1057</em>, 115553. (<a href='https://doi.org/10.1016/j.tcs.2025.115553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots with very weak capabilities placed on the vertices of a graph are required to move toward a common vertex from where they do not move anymore. The task is known as the Gathering problem and it has been extensively studied in the last decade with respect to both general graphs and specific topologies. Most of the challenges faced are due to possible isometries observable from the placement of the robots with respect to the underlying topology. Rings, Grids, and Complete graphs are just a few examples of very regular topologies where the placement of the robots and suitable movements are crucial for succeeding in Gathering. Here we are interested in understanding what can be done in Butterfly graphs where really many isometries are present and most importantly unavoidable by any movement. We propose a Gathering algorithm for the so-called leader configurations, i.e., those where the initial placement of the robots admits the detection (and election) of one robot as the leader. We introduce a non-trivial technique to elect the leader which is of its own interest. We also prove that the proposed Gathering algorithm is asymptotically optimal in terms of synchronous rounds required.},
  archive      = {J_TCS},
  author       = {Serafino Cicerone and Alessia Di Fonso and Gabriele Di Stefano and Alfredo Navarra},
  doi          = {10.1016/j.tcs.2025.115553},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115553},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Optimal gathering of robots in anonymous butterfly networks via leader election},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient shape formation by 3D hybrid programmable matter: An algorithm for low diameter intermediate structures. <em>TCS</em>, <em>1057</em>, 115552. (<a href='https://doi.org/10.1016/j.tcs.2025.115552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the shape formation problem within the 3D hybrid model, where a single agent with a strictly limited viewing range and the computational capacity of a deterministic finite automaton manipulates passive tiles through pickup, movement, and placement actions. The goal is to reconfigure a set of tiles into a specific shape termed an icicle . The icicle, identified as a dense, hole-free structure, is strategically chosen to function as an intermediate shape for more intricate shape formation tasks. It is designed for easy exploration by a finite-state agent, enabling the identification of tiles that can be lifted without breaking connectivity. Compared to the line shape, the icicle presents distinct advantages, including a reduced diameter and the presence of multiple removable tiles. We propose an algorithm that transforms an arbitrary initially connected tile structure into an icicle in O ( n 3 ) steps, matching the runtime of the line formation algorithm from prior work. Our theoretical contribution is accompanied by an extensive experimental analysis, indicating that our algorithm decreases the diameter of tile structures on average.},
  archive      = {J_TCS},
  author       = {Kristian Hinnenthal and David Liedtke and Christian Scheideler},
  doi          = {10.1016/j.tcs.2025.115552},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115552},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient shape formation by 3D hybrid programmable matter: An algorithm for low diameter intermediate structures},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The grothendieck computability model. <em>TCS</em>, <em>1057</em>, 115550. (<a href='https://doi.org/10.1016/j.tcs.2025.115550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Translating notions and results from category theory to the theory of computability models of Longley and Normann, we introduce the Grothendieck computability model. We define the first-projection-simulation and prove its basic properties. With the Grothendieck computability model, the category of computability models is shown to be a type-category, in the sense of Pitts, a result that bridges the categorical interpretation of dependent types with the theory of computability models. We also show that the category of computability models is a category with 2-family arrows and a corresponding structure of Sigma-objects. Finally, we introduce the notion of a fibration and opfibration-simulation, and we prove that the first-projection-simulation is a split opfibration-simulation.},
  archive      = {J_TCS},
  author       = {Luis Gambarte and Iosif Petrakis},
  doi          = {10.1016/j.tcs.2025.115550},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115550},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The grothendieck computability model},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hop domination on subclasses of perfect graphs. <em>TCS</em>, <em>1057</em>, 115547. (<a href='https://doi.org/10.1016/j.tcs.2025.115547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set S ⊆ V ( G ) is said to be a hop dominating set if every vertex u ∈ V ( G ) ∖ S , there exists a vertex v ∈ S such that d ( u , v ) = 2 where d ( u , v ) represents the distance between u and v in G . Given a graph G , Hop Domination asks to find the minimum size of a hop dominating set of G , also called the hop domination number . Henning et al. (Graphs Combin. 2017) showed that Hop Domination is NP -hard for bipartite graphs and chordal graphs. Since the class of chordal graphs is contained in the class of perfect graphs, the problem is NP -hard on perfect graphs. We would like to study the complexity of the problem on subclasses of perfect graphs and understand where the complexity of the problem shifts from tractable to intractable. The following are the results of this paper. We present polynomial algorithms for Hop Domination on permutation graphs, interval graphs and biconvex bipartite graphs. This generalizes the polynomial time algorithm for Hop Domination on bipartite permutation graphs. We also initiate a study on this problem from the parameterized complexity perspective. We show that the decision version of Hop Domination is W [ 2 ] -hard when parameterized by solution size.},
  archive      = {J_TCS},
  author       = {D. Karthika and R. Muthucumaraswamy and Sriram Bhyravarapu and Pritesh Kumar},
  doi          = {10.1016/j.tcs.2025.115547},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115547},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hop domination on subclasses of perfect graphs},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tight length theorems for multiset extensions of higman’s lemma. <em>TCS</em>, <em>1057</em>, 115546. (<a href='https://doi.org/10.1016/j.tcs.2025.115546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-quasi-ordered (wqo) set generalizes the notion of well-foundedness and is a powerful tool for analyzing the complexity of computational problems through upper bounds on the length of controlled bad sequences, known as length theorems. The finitary multiset extension of a wqo-set induces an ordering on finite multisets over elements of that set, where one multiset precedes another if there exists an injective mapping between their elements that preserves the original ordering. In this work, we refine existing length theorems for the finitary multiset extension of Higman’s ordering over finite alphabets, and we establish a matching lower bound. As a corollary, we obtain tighter length bounds for the majoring extension of Higman’s ordering over finite alphabets. We demonstrate the application of our results in the complexity analysis of noncommutative hypersequent logics.},
  archive      = {J_TCS},
  author       = {Vitor Greati and Revantha Ramanayake},
  doi          = {10.1016/j.tcs.2025.115546},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115546},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tight length theorems for multiset extensions of higman’s lemma},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A note on busy beaver bounds. <em>TCS</em>, <em>1057</em>, 115541. (<a href='https://doi.org/10.1016/j.tcs.2025.115541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the relationship between several variations of the Busy Beaver game proposed by Radó (1962), such as the s p a c e ( n ) or the n u m ( n ) functions, establishing new bounds on these functions in terms of each other, as well as some properties about their growth. We also introduce and investigate a new function, b o u n c e s ( n ) , to this family of noncomputable functions. We give some specific values for b o u n c e s ( n ) , as well as several results concerning its growth and its relationship to the previously studied Busy Beaver functions. We also investigate growth properties and relationships of these functions when considering Turing Machines with non-binary alphabets with a single blank symbol.},
  archive      = {J_TCS},
  author       = {Tomás Schitter and Sergio Abriola and Nicolás González},
  doi          = {10.1016/j.tcs.2025.115541},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115541},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A note on busy beaver bounds},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On shuffling and splitting automata. <em>TCS</em>, <em>1057</em>, 115539. (<a href='https://doi.org/10.1016/j.tcs.2025.115539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of finite state three-tape transducers which models the operation of shuffling and splitting words. We present them as automata over the so-called Shuffling Monoid. These automata can be seen as either shufflers or splitters interchangeably. We prove that functionality is decidable for splitters, and we also show that the equivalence between functional splitters is decidable. Moreover, in the deterministic case, the algorithm for equivalence is polynomial on the number of states of the splitter.},
  archive      = {J_TCS},
  author       = {Ignacio Mollo Cunningham},
  doi          = {10.1016/j.tcs.2025.115539},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115539},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On shuffling and splitting automata},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-criteria sublinear time algorithms for clustering with outliers in high dimensions. <em>TCS</em>, <em>1057</em>, 115538. (<a href='https://doi.org/10.1016/j.tcs.2025.115538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world datasets often contain outliers, and the presence of outliers can make clustering problems be much more challenging. Existing algorithms for clustering with outliers often have high computational complexities. In this paper, we propose a simple yet effective sublinear framework for solving the representative center-based clustering with outliers problems: k -median/means clustering with outliers. Our analysis is fundamentally different from the previous (uniform and non-uniform) sampling based ideas. In particular, our sample complexity is independent of the input size and dimensionality, and thus it is suitable for dealing with large-scale and high-dimensional datasets. We also conduct a set of experiments to evaluate the effectiveness of our proposed method on both synthetic and real datasets.},
  archive      = {J_TCS},
  author       = {Jiawei Huang and Wenjie Liu and Hu Ding},
  doi          = {10.1016/j.tcs.2025.115538},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115538},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bi-criteria sublinear time algorithms for clustering with outliers in high dimensions},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategy templates for almost-sure and positive winning of stochastic parity games towards permissive and resilient control. <em>TCS</em>, <em>1057</em>, 115535. (<a href='https://doi.org/10.1016/j.tcs.2025.115535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic games are fundamental in various applications, including the control of cyber-physical systems (CPS), where both controller and environment are modeled as players. Traditional algorithms typically aim to determine a single winning strategy to develop a controller. However, in CPS control and other domains, permissive controllers are essential, as they enable the system to adapt when additional constraints arise and remain resilient to runtime changes. This work generalizes the concept of (permissive winning) strategy templates , originally introduced by Anand et al. at TACAS and CAV 2023 for deterministic games, to incorporate stochastic games. These templates capture an infinite number of winning strategies, allowing for efficient strategy adaptation to system changes. We focus on two winning criteria (almost-sure and positive winning) and five winning objectives (safety, reachability, Büchi, co-Büchi, and parity). Our contributions include algorithms for constructing templates for each winning criterion and objective and a novel approach for extracting a winning strategy from a given template. Discussions on comparisons between templates and between strategy extraction methods are provided.},
  archive      = {J_TCS},
  author       = {Kittiphon Phalakarn and Sasinee Pruekprasert and Ichiro Hasuo},
  doi          = {10.1016/j.tcs.2025.115535},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115535},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Strategy templates for almost-sure and positive winning of stochastic parity games towards permissive and resilient control},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
