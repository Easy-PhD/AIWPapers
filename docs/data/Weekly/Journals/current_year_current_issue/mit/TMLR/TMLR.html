<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMLR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmlr">TMLR - 88</h2>
<ul>
<li><details>
<summary>
(2025). MoReact: Generating reactive motion from textual descriptions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4zuT73heqm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and generating human reactions poses a significant challenge with broad applications for computer vision and human-computer interaction. Existing methods either treat multiple individuals as a single entity, directly generating interactions, or rely solely on one person's motion to generate the other's reaction, failing to integrate the rich semantic information that underpins human interactions. Yet, these methods often fall short in adaptive responsiveness, \ie, the ability to accurately respond to diverse and dynamic interaction scenarios. Recognizing this gap, our work introduces an approach tailored to address the limitations of existing models by focusing on text-driven human reaction generation. Our model specifically generates realistic motion sequences for individuals that responding to the other's actions based on a descriptive text of the interaction scenario. The goal is to produce motion sequences that not only complement the opponent's movements but also semantically fit the described interactions. To achieve this, we present MoReact, a diffusion-based method designed to disentangle the generation of global trajectories and local motions sequentially. This approach stems from the observation that generating global trajectories first is crucial for guiding local motion, ensuring better alignment with given action and text. Furthermore, we introduce a novel interaction loss to enhance the realism of generated close interactions. Our experiments, utilizing data adapted from a two-person motion dataset, demonstrate the efficacy of our approach for this novel task, which is capable of producing realistic, diverse, and controllable reactions that not only closely match the movements of the counterpart but also adhere to the textual guidance. Please find our webpage at https://xiyan-xu.github.io/MoReactWebPage.},
  archive      = {J_TMLR},
  author       = {Xiyan Xu and Sirui Xu and Yu-Xiong Wang and Liangyan Gui},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MoReact: Generating reactive motion from textual descriptions},
  url          = {https://openreview.net/forum?id=4zuT73heqm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning equivalence classes of bayesian network structures with GFlowNet. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FAcc7oAdaa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the causal graph underlying a system is essential for enabling causal inference, particularly in fields such as medicine and genetics. Identifying a causal Directed Acyclic Graph (DAG) from observational data alone is challenging because multiple DAGs can encode the same set of conditional independencies. These equivalent DAGs form a Markov Equivalence Class (MEC), which is represented by a Completed Partially Directed Acyclic Graph (CPDAG). Effectively approximating the CPDAG is crucial because it facilitates narrowing down the set of possible causal graphs underlying the data. We introduce CPDAG-GFN, a novel approach that uses a Generative Flow Network (GFlowNet) to learn a posterior distribution over CPDAGs. From this distribution, we sample high-reward CPDAG candidates that approximate the ground truth, with rewards determined by a score function that quantifies how well each graph fits the data. Additionally, CPDAG-GFN incorporates a sparsity-preferring filter to enhance the set of CPDAG candidates and improve their alignment with the ground truth. Experimental results on both simulated and real-world datasets demonstrate that CPDAG-GFN performs competitively with established methods for learning CPDAG candidates from observational data.},
  archive      = {J_TMLR},
  author       = {Michelle Liu and Zhaocheng Zhu and Olexa Bilaniuk and Emmanuel Bengio},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning equivalence classes of bayesian network structures with GFlowNet},
  url          = {https://openreview.net/forum?id=FAcc7oAdaa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SELU: Self-learning embodied multimodal large language models in unknown environments. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=G5gROx8AVi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multimodal large language models (MLLMs) have demonstrated strong visual understanding and decision-making capabilities, enabling the exploration of autonomously improving MLLMs in unknown environments. However, external feedback like human or environmental feedback is not always available. To address this challenge, existing methods primarily focus on enhancing the decision-making capabilities of MLLMs through voting and scoring mechanisms, while little effort has been paid to improving the environmental comprehension of MLLMs in unknown environments. To fully unleash the self-learning potential of MLLMs, we propose a novel actor-critic self-learning paradigm, dubbed SELU, inspired by the actor-critic paradigm in reinforcement learning. The critic employs self-asking and hindsight relabeling to extract knowledge from interaction trajectories collected by the actor, thereby augmenting its environmental comprehension. Simultaneously, the actor is improved by the self-feedback provided by the critic, enhancing its decision-making. We evaluate our method in the AI2-THOR and VirtualHome environments, and SELU achieves critic improvements of approximately 28% and 30%, and actor improvements of about 20% and 24% via self-learning.},
  archive      = {J_TMLR},
  author       = {Boyu Li and Haobin Jiang and Ziluo Ding and Xinrun Xu and Haoran Li and Dongbin Zhao and Zongqing Lu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SELU: Self-learning embodied multimodal large language models in unknown environments},
  url          = {https://openreview.net/forum?id=G5gROx8AVi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behaviour discovery and attribution for explainable reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JbHtpOIH9l'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building trust in reinforcement learning (RL) agents requires understanding why they make certain decisions, especially in high-stakes applications like robotics, healthcare, and finance. Existing explainability methods often focus on single states or entire trajectories, either providing only local, step-wise insights or attributing decisions to coarse, episodelevel summaries. Both approaches miss the recurring strategies and temporally extended patterns that actually drive agent behavior across multiple decisions. We address this gap by proposing a fully offline, reward-free framework for behavior discovery and segmentation, enabling the attribution of actions to meaningful and interpretable behavior segments that capture recurring patterns appearing across multiple trajectories. Our method identifies coherent behavior clusters from state-action sequences and attributes individual actions to these clusters for fine-grained, behavior-centric explanations. Evaluations on four diverse offline RL environments show that our approach discovers meaningful behaviors and outperforms trajectory-level baselines in fidelity, human preference, and cluster coherence. Our code is publicly available.},
  archive      = {J_TMLR},
  author       = {Rishav Rishav and Somjit Nath and Vincent Michalski and Samira Ebrahimi Kahou},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Behaviour discovery and attribution for explainable reinforcement learning},
  url          = {https://openreview.net/forum?id=JbHtpOIH9l},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlowBench: Benchmarking optical flow estimation methods for reliability and generalization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Kh4bj6YDNm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical flow estimation is a crucial computer vision task often applied to safety-critical real-world scenarios like autonomous driving and medical imaging. While optical flow estimation accuracy has greatly benefited from the emergence of deep learning, learning-based methods are also known for their lack of generalization and reliability. However, reliability is paramount when optical flow methods are employed in the real world, where safety is essential. Furthermore, a deeper understanding of the robustness and reliability of learning-based optical flow estimation methods is still lacking, hindering the research community from building methods safe for real-world deployment. Thus, we propose FlowBench, a robustness benchmark and evaluation tool for learning-based optical flow methods. FlowBench facilitates streamlined research into the reliability of optical flow methods by benchmarking their robustness to adversarial attacks and out-of-distribution samples. With FlowBench, we benchmark 57 checkpoints across 3 datasets under 9 diverse adversarial attacks and 23 established common corruptions, making it the most comprehensive robustness analysis of optical flow methods to date. Across this wide range of methods, we consistently find that methods with state-of-the-art performance on established standard benchmarks lack reliability and generalization ability. Moreover, we find interesting correlations between the performance, reliability, and generalization ability of optical flow estimation methods, under various lenses such as design choices used, number of parameters, etc. The open-source code and weights for FlowBench are available in this GitHub repository: https://github.com/shashankskagnihotri/FlowBench.},
  archive      = {J_TMLR},
  author       = {Shashank Agnihotri and Julian Yuya Caspary and Luca Schwarz and Xinyan Gao and Jenny Schmalfuss and Andres Bruhn and Margret Keuper},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FlowBench: Benchmarking optical flow estimation methods for reliability and generalization},
  url          = {https://openreview.net/forum?id=Kh4bj6YDNm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication cost reduction for subgraph counting under local differential privacy via hash functions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=N1J236mepp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We suggest the use of hash functions to cut down the communication costs when counting subgraphs under edge local differential privacy. While various algorithms exist for computing graph statistics --- including the count of subgraphs --- under the edge local differential privacy, many suffer with high communication costs, making them less efficient for large graphs. Though data compression is a typical approach in differential privacy, its application in local differential privacy requires a form of compression that every node can reproduce. In our study, we introduce linear congruence hashing. Leveraging amplification by sub-sampling, with a sampling size of $s$, our method can cut communication costs by a factor of $s^2$, albeit at the cost of increasing variance in the published graph statistic by a factor of $s$. The experimental results indicate that, when matched for communication costs, our method achieves a reduction in the $\ell_2$-error by up to 1000 times for triangle counts and by up to $10^3$ times for 4-cycles counts compared to the performance of leading algorithms.},
  archive      = {J_TMLR},
  author       = {Quentin Hillebrand and Vorapong Suppakitpaisarn and Tetsuo Shibuya},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Communication cost reduction for subgraph counting under local differential privacy via hash functions},
  url          = {https://openreview.net/forum?id=N1J236mepp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging fully-observable solutions for improved partially-observable offline reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=e9p4TDPy6A'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) is a popular learning framework for control problems where online interactions with the environment are expensive, risky, or otherwise impractical. Existing offline RL methods commonly assume full observability of the state, and therefore there is a lack of offline RL methods that are specialized for the more general case of partially-observable control. To address this gap, we propose Cross-Observability Conservative Q-Learning (CO-CQL), an offline RL algorithm for partially-observable control that leverages fully-observable expert policies in an asymmetric learning setting. To motivate the use of fully-observable experts for partially-observable control, we formalize Cross-Observability Optimality Ratio (COOR), a theoretical measure of cross-observability that quantifies the benefit of learning asymmetrically from a fully-observable expert, and Cross-Observability Approximation Ratio (COAR), an estimation of COOR computable from trained policies. Our empirical evaluation on a wide variety of partially-observable challenges demonstrates that CO-CQL is able to exploit the guidance of fully-observable experts to outperform other state-of-the-art offline algorithms.},
  archive      = {J_TMLR},
  author       = {Chulabhaya Wijesundara and Andrea Baisero and Gregory David Castanon and Alan S Carlin and Robert Platt and Christopher Amato},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Leveraging fully-observable solutions for improved partially-observable offline reinforcement learning},
  url          = {https://openreview.net/forum?id=e9p4TDPy6A},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unbiased loss functions for multilabel classification with missing labels. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hMq1hUhLqp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers binary and multilabel classification problems in a setting where labels are missing independently and with a known rate. Missing labels are a ubiquitous phenomenon in extreme multi-label classification (XMC) tasks, such as matching Wikipedia articles to a small subset out of the hundreds of thousands of possible tags, where no human annotator can possibly check the validity of all the negative samples. For this reason, propensity-scored precision---an unbiased estimate for precision-at-k under a known noise model---has become one of the standard metrics in XMC. Few methods take this problem into account already during the training phase, and all of these are limited to loss functions that can be decomposed into a sum of contributions from each individual label. A typical approach to training is to reduce the multilabel problem into a series of binary or multiclass problems, and it has been shown that if the surrogate task should be consistent for optimizing recall, the resulting loss function is not decomposable over labels. Therefore, this paper develops unbiased estimators for generic, potentially non-decomposable loss functions. These estimators suffer from increased variance and may lead to ill-posed optimization problems, which we address by switching to convex upper-bounds. The theoretical considerations are further supplemented by an experimental study showing that the switch to unbiased estimators significantly alters the bias-variance trade-off and thus requires stronger regularization.},
  archive      = {J_TMLR},
  author       = {Erik Schultheis and Rohit Babbar},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unbiased loss functions for multilabel classification with missing labels},
  url          = {https://openreview.net/forum?id=hMq1hUhLqp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical test for saliency maps of graph neural networks via selective inference. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5NkXTCVa7F'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have gained prominence for their ability to process graph-structured data across various domains. However, interpreting GNN decisions remains a significant challenge, leading to the adoption of saliency maps for identifying salient subgraphs composed of influential nodes and edges. Despite their utility, the reliability of GNN saliency maps has been questioned, particularly in terms of their robustness to input noise. In this study, we propose a statistical testing framework to rigorously evaluate the significance of saliency maps. Our main contribution lies in addressing the inflation of the Type I error rate caused by double-dipping of data, leveraging the framework of Selective Inference. Our method provides statistically valid $p$-values while controlling the Type I error rate, ensuring that identified salient subgraphs contain meaningful information rather than random artifacts. The method is applicable to a variety of saliency methods with piecewise linearity (e.g., Class Activation Mapping). We validate our method on synthetic and real-world datasets, demonstrating its capability in assessing the reliability of GNN interpretations.},
  archive      = {J_TMLR},
  author       = {Shuichi Nishino and Tomohiro Shiraishi and Teruyuki Katsuoka and Ichiro Takeuchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Statistical test for saliency maps of graph neural networks via selective inference},
  url          = {https://openreview.net/forum?id=5NkXTCVa7F},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Certified robustness to data poisoning in gradient-based training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9WHifn9ZVX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning pipelines leverage large amounts of public data, making it infeasible to guarantee data quality and leaving models open to poisoning and backdoor attacks. Provably bounding the behavior of learning algorithms under such attacks remains an open problem. In this work, we address this challenge by developing the first framework providing provable guarantees on the behavior of models trained with potentially manipulated data without modifying the model or learning algorithm. In particular, our framework certifies robustness against untargeted and targeted poisoning, as well as backdoor attacks, for bounded and unbounded manipulations of the training inputs and labels. Our method leverages convex relaxations to over-approximate the set of all possible parameter updates for a given poisoning threat model, allowing us to bound the set of all reachable parameters for any gradient-based learning algorithm. Given this set of parameters, we provide bounds on worst-case behavior, including model performance and backdoor success rate. We demonstrate our approach on multiple real-world datasets from applications including energy consumption, medical imaging, and autonomous driving.},
  archive      = {J_TMLR},
  author       = {Philip Sosnin and Mark Niklas Mueller and Maximilian Baader and Calvin Tsay and Matthew Robert Wicker},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Certified robustness to data poisoning in gradient-based training},
  url          = {https://openreview.net/forum?id=9WHifn9ZVX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HalluEntity: Benchmarking and understanding entity-level hallucination detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=494k7e9R5D'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate the impact of hallucination nature of LLMs, many studies propose detecting hallucinated generation through uncertainty estimation. However, these approaches predominantly operate at the sentence or paragraph level, failing to pinpoint specific spans or entities responsible for hallucinated content. This lack of granularity is especially problematic for long-form outputs that mix accurate and fabricated information. To address this limitation, we explore entity-level hallucination detection. We propose a new data set, HalluEntity, which annotates hallucination at the entity level. Based on the dataset, we comprehensively evaluate uncertainty-based hallucination detection approaches across 17 modern LLMs. Our experimental results show that uncertainty estimation approaches focusing on individual token probabilities tend to over-predict hallucinations, while context-aware methods show better but still suboptimal performance. Through an in-depth qualitative study, we identify relationships between hallucination tendencies and linguistic properties and highlight important directions for future research. HalluEntity: https://huggingface.co/datasets/samuelyeh/HalluEntity},
  archive      = {J_TMLR},
  author       = {Min-Hsuan Yeh and Max Kamachee and Seongheon Park and Yixuan Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HalluEntity: Benchmarking and understanding entity-level hallucination detection},
  url          = {https://openreview.net/forum?id=494k7e9R5D},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System-2 mathematical reasoning via enriched instruction tuning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Cl9Uox031k'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving complex mathematical problems via system-2 reasoning is a natural human skill, yet it remains a significant challenge for current large language models (LLMs). We identify the scarcity of deliberate multi-step reasoning data as a primary limiting factor. To this end, we introduce Enriched Instruction Tuning (EIT), a method that enriches existing human-annotated mathematical datasets by augmenting human-annotated data with AI-generated feedback to create fine-grained reasoning trajectories. These datasets are then used to fine-tune open-source LLMs, enhancing their mathematical reasoning abilities without reliance on any symbolic verification program. Concretely, EIT is composed of two critical steps: Enriching with Reasoning Plan (ERP) and Enriching with Reasoning Step (ERS). The former generates a high-level plan that breaks down complex instructions into a sequence of simpler objectives, while ERS fills in reasoning contexts often overlooked by human annotators, creating a smoother reasoning trajectory for LLM fine-tuning. Unlike existing CoT prompting methods that generate reasoning chains only depending on LLM's internal knowledge, our method leverages human-annotated initial answers as ``meta-knowledge'' to help LLMs generate more detailed and precise reasoning processes, leading to a more trustworthy LLM expert for complex mathematical problems. In experiments, EIT achieves an accuracy of 84.1% on GSM8K and 32.5% on MATH, surpassing state-of-the-art fine-tuning and prompting methods, and even matching the performance of tool-augmented methods.},
  archive      = {J_TMLR},
  author       = {Huanqia Cai and Yijun Yang and Zhifeng Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {System-2 mathematical reasoning via enriched instruction tuning},
  url          = {https://openreview.net/forum?id=Cl9Uox031k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning from human feedback with active queries. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EScatQaRxz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ instance-dependent regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to fine-tuning LLMs. Our experiments show that ADPO, while only making about half of queries for human preference, matches the performance of DPO, establishing it as a data-efficient alternative to DPO. The codes are available at https://github.com/jkx19/ActiveQuery.},
  archive      = {J_TMLR},
  author       = {Kaixuan Ji and Jiafan He and Quanquan Gu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reinforcement learning from human feedback with active queries},
  url          = {https://openreview.net/forum?id=EScatQaRxz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tree search for language model agents. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QF0N3x2XVm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agents powered by language models (LMs) have demonstrated promise in their ability to perform decision-making tasks such as web automation. However, a key limitation remains: LMs, primarily optimized for natural language understanding and generation, struggle with multi-step reasoning, planning, and using environmental feedback when attempting to solve realistic computer tasks. Towards addressing this, we propose an inference-time search algorithm for LM agents to explicitly perform exploration and multi-step planning in interactive web environments. Our approach is a form of best-first tree search that operates within the actual environment space, and is complementary with most existing state-of-the-art agents. It is the first tree search algorithm for LM agents that shows effectiveness on realistic web tasks. On the challenging VisualWebArena benchmark, applying our search algorithm on top of a GPT-4o agent yields a 39.7% relative increase in success rate compared to the same baseline without search, setting a state-of-the-art success rate of 26.4%. On WebArena, search also yields a 28.0% relative improvement over a baseline agent, setting a competitive success rate of 19.2%. Our experiments showcase the effectiveness of search for web agents, and we demonstrate that performance scales with increased test-time compute.},
  archive      = {J_TMLR},
  author       = {Jing Yu Koh and Stephen Marcus McAleer and Daniel Fried and Ruslan Salakhutdinov},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tree search for language model agents},
  url          = {https://openreview.net/forum?id=QF0N3x2XVm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of random learning rate: Theoretical analysis of SGD dynamics in non-convex optimization via stationary distribution. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RPtKkNx9ZK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a variant of the stochastic gradient descent (SGD) with a random learning rate and reveal its convergence properties. SGD is a widely used stochastic optimization algorithm in machine learning, especially deep learning. Numerous studies reveal the convergence properties of SGD and its theoretically favorable variants. Among these, the analysis of convergence using a stationary distribution of updated parameters provides generalizable results. However, to obtain a stationary distribution, the update direction of the parameters must not degenerate, which limits the applicable variants of SGD. In this study, we consider a novel SGD variant, Poisson SGD, which has degenerated parameter update directions and instead utilizes a random learning rate. Consequently, we demonstrate that a distribution of a parameter updated by Poisson SGD converges to a stationary distribution under weak assumptions on a loss function. Based on this, we further show that Poisson SGD finds global minima in non-convex optimization problems and also evaluate the generalization error using this method. As a proof technique, we approximate the distribution by Poisson SGD with that of the bouncy particle sampler (BPS) and derive its stationary distribution, using the theoretical advance of the piece-wise deterministic Markov process (PDMP).},
  archive      = {J_TMLR},
  author       = {Naoki Yoshida and Shogo Nakakita and Masaaki Imaizumi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Effect of random learning rate: Theoretical analysis of SGD dynamics in non-convex optimization via stationary distribution},
  url          = {https://openreview.net/forum?id=RPtKkNx9ZK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning the language of protein structure. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SRRPQIOS4w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning and \emph{de novo} generation of proteins are pivotal computational biology tasks. Whilst natural language processing (NLP) techniques have proven highly effective for protein sequence modelling, structure modelling presents a complex challenge, primarily due to its continuous and three-dimensional nature. Motivated by this discrepancy, we introduce an approach using a vector-quantized autoencoder that effectively tokenizes protein structures into discrete representations. This method transforms the continuous, complex space of protein structures into a manageable, discrete format with a codebook ranging from 4096 to 64000 tokens, achieving high-fidelity reconstructions with backbone root mean square deviations (RMSD) of approximately 1-4 \AA. To demonstrate the efficacy of our learned representations, we show that a simple GPT model trained on our codebooks can generate novel, diverse, and designable protein structures. Our approach not only provides representations of protein structure, but also mitigates the challenges of disparate modal representations and sets a foundation for seamless, multi-modal integration, enhancing the capabilities of computational methods in protein design.},
  archive      = {J_TMLR},
  author       = {Jérémie DONA and Benoit Gaujac and Timothy Atkinson and Liviu Copoiu and Thomas Pierrot and Thomas D Barrett},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning the language of protein structure},
  url          = {https://openreview.net/forum?id=SRRPQIOS4w},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond ordinary lipschitz constraints: Differentially private optimization with TNC. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SZCygcrGng'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study Stochastic Convex Optimization in Differential Privacy model (DP-SCO). Unlike previous studies, here we assume the population risk function satisfies the Tsybakov Noise Condition (TNC) with some parameter $\theta>1$, where the Lipschitz constant of the loss could be extremely large or even unbounded, but the $\ell_2$-norm gradient of the loss has bounded $k$-th moment with $k\geq 2$. For the Lipschitz case with $\theta\geq 2$, we first propose an $(\epsilon, \delta)$-DP algorithms whose utility bound is $\tilde{O}\left(\left(\tilde{r}_{2k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\epsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$ in high probability, where $n$ is the sample size, $d$ is the model dimension, and $\tilde{r}_{2k}$ is a term that only depends on the $2k$-th moment of the gradient. It is notable that such an upper bound is independent of the Lipschitz constant. We then extend to the case where $\theta\geq \bar{\theta}> 1$ for some known constant $\bar{\theta}$. Moreover, when the privacy budget $\epsilon$ is small enough, we show an upper bound of $\tilde{O}\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\epsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$ even if the loss function is not Lipschitz. For the lower bound, we show that for any $\theta\geq 2$, the private minimax rate for $\rho$-zero Concentrated Differential Privacy is lower bounded by $\Omega\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\sqrt{\rho}}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$.},
  archive      = {J_TMLR},
  author       = {Difei Xu and Meng Ding and Zihang Xiang and Jinhui Xu and Di Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond ordinary lipschitz constraints: Differentially private optimization with TNC},
  url          = {https://openreview.net/forum?id=SZCygcrGng},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complementarity: Toward better metrics and optimizing data efficiency in LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=feAbrMXGMh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalist Large Language Models (LLMs) are trained with an immense amount of data from across different domains. However, not all data contribute to model performance equally, and prioritizing data quality can improve domain-specific performance. We suggest that quality is not merely an independent feature of datasets, but rather the manner in which data samples interfere with or complement one another. Furthermore, existing performance metrics for language models are computationally expensive, while also frequently suffering from being mathematically ill-defined and poorly suited to generative AI. Toward improving general performance while reducing the amount of training data, and quantifying how data contributes to downstream tasks vis-a-vis their relation with other data, we introduce a new metric, Complementarity. We first establish a strong correlation between Complementarity and domain-specific task performance. Without reliance on heavy instruction-tuning and text scraping, Complementarity is significantly less expensive to compute and is applicable to a wide variety of potential target domains. Most interestingly, we demonstrate that the Complementarity taken over a training validation set provides a better predictor of generalization to future test sets than directly measuring performance on a test validation set. With this, we introduce an algorithm that carefully selects the data to fine-tune upon, leading to a high-performing fine-tuned generalist model while using only a fraction of the data, and without requiring data from the test domain. Overall, Complementarity may serve as a key metric in future analysis of data utility and design of datasets, and help facilitate the goal of a truly generalist model.},
  archive      = {J_TMLR},
  author       = {Roy Siegelmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Complementarity: Toward better metrics and optimizing data efficiency in LLMs},
  url          = {https://openreview.net/forum?id=feAbrMXGMh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the limitations of layer synchronization in spiking neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mfmAVwtMIk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural-network processing in machine learning applications relies on layer synchronization. This is practiced even in artificial Spiking Neural Networks (SNNs), which are touted as consistent with neurobiology, in spite of processing in the brain being in fact asynchronous. A truly asynchronous system however would allow all neurons to evaluate concurrently their threshold and emit spikes upon receiving any presynaptic current. Omitting layer synchronization is potentially beneficial, for latency and energy efficiency, but asynchronous execution of models previously trained with layer synchronization may entail a mismatch in network dynamics and performance. We present and quantify this problem, and show that models trained with layer synchronization either perform poorly in absence of the synchronization, or fail to benefit from any energy and latency reduction, when such a mechanism is in place. We then explore a potential solution direction, based on a generalization of backpropagation-based training that integrates knowledge about an asynchronous execution scheduling strategy, for learning models suitable for asynchronous processing. We experiment with 2 asynchronous neuron execution scheduling strategies in datasets that encode spatial and temporal information, and we show the potential of asynchronous processing to use less spikes (up to 50\%), complete inference faster (up to 2x), and achieve competitive or even better accuracy (up to $\sim$10\% higher). Our exploration affirms that asynchronous event-based AI processing can be indeed more efficient, but we need to rethink how we train our SNN models to benefit from it. (Source code available at: \url{https://github.com/RoelMK/asynctorch})},
  archive      = {J_TMLR},
  author       = {Roel Koopman and Amirreza Yousefzadeh and Mahyar Shahsavari and Guangzhi Tang and Manolis Sifalakis},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring the limitations of layer synchronization in spiking neural networks},
  url          = {https://openreview.net/forum?id=mfmAVwtMIk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple noises in diffusion model for semi-supervised multi-domain translation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vYdT26kDYM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address the challenge of multi-domain translation, where the objective is to learn mappings between arbitrary configurations of domains within a defined set (such as $(D_1, D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$, etc. for three domains) without the need for separate models for each specific translation configuration, enabling more efficient and flexible domain translation. We introduce Multi-Domain Diffusion (MDD), a method with dual purposes: i) reconstructing any missing views for new data objects, and ii) enabling learning in semi-supervised contexts with arbitrary supervision configurations. MDD achieves these objectives by exploiting the noise formulation of diffusion models, specifically modeling one noise level per domain. Similar to existing domain translation approaches, MDD learns the translation between any combination of domains. However, unlike prior work, our formulation inherently handles semi-supervised learning without modification by representing missing views as noise in the diffusion process. We evaluate our approach through domain translation experiments on BL3NDT, a multi-domain synthetic dataset designed for challenging semantic domain inversion, the BraTS2020 dataset, and the CelebAMask-HQ dataset.},
  archive      = {J_TMLR},
  author       = {Tsiry Mayet and Simon Bernard and Romain HÉRAULT and Clement Chatelain},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multiple noises in diffusion model for semi-supervised multi-domain translation},
  url          = {https://openreview.net/forum?id=vYdT26kDYM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuous language model interpolation yields dynamic and controllable text generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xD9Nu2Wah4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As large language models (LLMs) have gained popularity for a variety of use cases, making them adaptable and controllable has become increasingly important, especially for user-facing applications. In particular, linear interpolation between model parameters forms the backbone for many recent approaches to adapting models to user preferences. While the existing literature on LLM adaptation primarily focuses on finding methods that optimize for some set of performance criteria or user preferences, here we instead seek to better understand and characterize the behavior of dense, continuous interpolation between models. Specifically, we use low-rank updates to fine-tune a base model to various different domains, yielding a set of anchor models with distinct generation profiles. Then, we use the weight updates of these anchor models to parametrize the entire (infinite) class of models contained within their convex hull. We empirically show that varying the interpolation weights yields predictable and consistent change in the model outputs with respect to all of the controlled attributes simultaneously. We find that there is little entanglement between most attributes and identify and discuss the pairs of attributes for which this is not the case. Our results suggest that parameter merging facilitates flexible model adaptation due to its predictable behavior within the full interpolation region.},
  archive      = {J_TMLR},
  author       = {Sara Kangaslahti and David Alvarez-Melis},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Continuous language model interpolation yields dynamic and controllable text generation},
  url          = {https://openreview.net/forum?id=xD9Nu2Wah4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auto-regressive vs flow-matching: A comparative study of modeling paradigms for text-to-music generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xXc5DeaBYw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in text-to-music generation has enabled models to synthesize high-quality musical segments, full compositions, and even respond to fine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA) systems differ significantly in many dimensions, such as training datasets, modeling paradigms, and architectural choices. This diversity complicates efforts to evaluate models fairly and identify which design choices influence performance the most. While factors like data and architecture are important, in this study we focus exclusively on the modeling paradigm. We conduct a systematic empirical analysis to isolate its effects, offering insights into associated trade-offs and emergent behaviors that can guide future text-to-music generation systems. Specifically, we compare the two arguably most common modeling paradigms: auto-regressive decoding and conditional flow-matching. We conduct a controlled comparison by training all models from scratch using identical datasets, training configurations, and similar backbone architectures. Performance is evaluated across multiple axes, including generation quality, robustness to inference configurations, scalability, adherence to both textual and temporally aligned conditioning, and editing capabilities in the form of audio inpainting. This comparative study sheds light on distinct strengths and limitations of each paradigm, providing actionable insights that can inform future architectural and training decisions in the evolving landscape of text-to-music generation. Audio sampled examples are available at: https://huggingface.co/spaces/ortal1602/ARvsFM},
  archive      = {J_TMLR},
  author       = {Or Tal and Felix Kreuk and Yossi Adi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Auto-regressive vs flow-matching: A comparative study of modeling paradigms for text-to-music generation},
  url          = {https://openreview.net/forum?id=xXc5DeaBYw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean-field RL for large-scale unit-capacity pickup-and-delivery problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=E8JRswdyDR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving large-scale vehicle routing problems (VRPs) is NP-hard and poses a computational challenge in numerous applications such as logistics. Meanwhile, mean-field control (MFC) provides a tractable and rigorous approach to controlling many agents. We provide a solution to pickup-and-delivery VRPs via scalable MFC. In combination with reinforcement learning (RL) and clustering, our MFC approach efficiently scales to large-scale VRPs. We perform a theoretical analysis of our MFC-based approximation, giving convergence results for large VRP instances and error bounds for clustering-based approximations. We verify our algorithms on different datasets and compare them against solutions such as OR-Tools, PyVRP and heuristics, showing scalability in terms of speed for mean-field methods, for the first time in discrete optimization. Overall, our work establishes a novel synthesis of MFC-based RL techniques, vehicle routing problems and clustering approximations, to solve a hard discrete optimization problem of practical use in a scalable way.},
  archive      = {J_TMLR},
  author       = {Kai Cui and Sharif Azem and Christian Fabian and Kirill Kuroptev and Ramin Khalili and Osama Abboud and Florian Steinke and Heinz Koeppl},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mean-field RL for large-scale unit-capacity pickup-and-delivery problems},
  url          = {https://openreview.net/forum?id=E8JRswdyDR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Doubly robust uncertainty quantification for quantile treatment effects in sequential decision making. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=F0BwbieVws'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multi-stage sequential decision making, where the treatment at any stage may depend on the subject’s entire treatment and covariate history. We introduce a general framework for doubly robust uncertainty quantification for the quantiles of cumulative outcomes under a sequential treatment rule. While previous studies focused on mean effects, quantile effects offer unique insights into the distributional properties and are more robust for heavy-tailed outcomes. It is known that, doubly robust inference is significantly more challenging and largely unexplored for quantile treatment effects. More importantly, for mean effects, doubly robust estimation does not ensure doubly robust inference. Our approach first provides a doubly robust estimator for any quantile of interest based on pre-collected data, achieving semi-parametric efficiency. We then propose a novel doubly robust estimator for the asymptotic variance, enabling the construction of a doubly robust confidence interval. To overcome the challenges in parameter-dependent nuisance functions, we leverage deep conditional generative learning techniques. We demonstrate advantages of our approach via both simulation and real data from a short video platform. Additionally, we observe that our proposed approach leads to another mean effect estimator that outperforms existing estimators with heavy-tailed outcomes.},
  archive      = {J_TMLR},
  author       = {Yang Xu and Chengchun Shi and Shikai Luo and Lan Wang and Rui Song},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Doubly robust uncertainty quantification for quantile treatment effects in sequential decision making},
  url          = {https://openreview.net/forum?id=F0BwbieVws},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The overcooked generalisation challenge: Evaluating cooperation with novel partners in unknown environments using unsupervised environment design. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=K2KtcMlW6j'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the Overcooked Generalisation Challenge (OGC) – a new benchmark for evaluating reinforcement learning (RL) agents on their ability to cooperate with unknown partners in unfamiliar environments. Existing work typically evaluated cooperative RL only in their training environment or with their training partners, thus seriously limiting our ability to understand agents’ generalisation capacity – an essential requirement for future collaboration with humans. The OGC extends Overcooked-AI to support dual curriculum design (DCD). It is fully GPU-accelerated, open-source, and integrated into the minimax DCD benchmark suite. Compared to prior DCD benchmarks, where designers manipulate only minimal elements of the environment, OGC introduces a significantly richer design space: full kitchen layouts with multiple objects that require the designer to account for interaction dynamics between agents. We evaluate state-of-the-art DCD algorithms alongside scalable neural architectures and find that current methods fail to produce agents that generalise effectively to novel layouts and unfamiliar partners. Our results indicate that both agents and curriculum designers struggle with the joint challenge of partner and environment generalisation. These findings establish OGC as a demanding testbed for cooperative generalisation and highlight key directions for future research. We open-source our code.},
  archive      = {J_TMLR},
  author       = {Constantin Ruhdorfer and Matteo Bortoletto and Anna Penzkofer and Andreas Bulling},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The overcooked generalisation challenge: Evaluating cooperation with novel partners in unknown environments using unsupervised environment design},
  url          = {https://openreview.net/forum?id=K2KtcMlW6j},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving inverse problems using diffusion with iterative colored renoising. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RZv8FcQDPW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging inverse problems can be solved in an unsupervised manner using pre-trained diffusion models, but doing so requires approximating the gradient of the measurement-conditional score function in the diffusion reverse process. We show that the approximations produced by existing methods are relatively poor, especially early in the reverse process, and so we propose a new approach that iteratively reestimates and ``renoises'' the estimate several times per diffusion step. This iterative approach, which we call Fast Iterative REnoising (FIRE), injects colored noise that is shaped to ensure that the pre-trained diffusion model always sees white noise, in accordance with how it was trained. We then embed FIRE into the DDIM reverse process and show that the resulting ``DDfire'' offers state-of-the-art accuracy and runtime on several linear inverse problems, as well as phase retrieval.},
  archive      = {J_TMLR},
  author       = {Matthew C Bendel and Saurav K Shastri and Rizwan Ahmad and Philip Schniter},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Solving inverse problems using diffusion with iterative colored renoising},
  url          = {https://openreview.net/forum?id=RZv8FcQDPW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COMMA: A communicative multimodal multi-agent benchmark. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=TIGQIem1na'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advances of multimodal agents built on large foundation models have largely overlooked their potential for language-based communication between agents in collaborative tasks. This oversight presents a critical gap in understanding their effectiveness in real-world deployments, particularly when communicating with humans. Existing agentic benchmarks fail to address key aspects of inter-agent communication and collaboration, particularly in scenarios where agents have unequal access to information and must work together to achieve tasks beyond the scope of individual capabilities. To fill this gap, we introduce COMMA: a novel puzzle benchmark designed to evaluate the collaborative performance of multimodal multi-agent systems through language communication. Our benchmark features a variety of multimodal puzzles, providing a comprehensive evaluation across four key categories of agentic capability in a communicative collaboration setting. Our findings reveal surprising weaknesses in state-of-the-art models, including strong proprietary models like GPT-4o and reasoning models like o4-mini. Many chain of thought reasoning models such as R1-Onevision and LLaVA-CoT struggle to outperform even a random baseline in agent-agent collaboration, indicating a potential growth area in their communication abilities.},
  archive      = {J_TMLR},
  author       = {Timothy Ossowski and Danyal Maqbool and Jixuan Chen and Zefan Cai and Tyler J. Bradshaw and Junjie Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {COMMA: A communicative multimodal multi-agent benchmark},
  url          = {https://openreview.net/forum?id=TIGQIem1na},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-positive multi-label learning with label cardinality. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XEPPXH2nKu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study learning a multi-label classifier from partially labeled data, where each instance has only a single positive label. We explain how auxiliary information available on the label cardinality, the number of positive labels per instance, can be used for improving such methods. We consider auxiliary information of varying granularity, ranging from knowing just the maximum number of labels over all instances to knowledge on the distribution of label cardinalities and even the exact cardinality of each instance. We introduce methods leveraging the different types of auxiliary information, study how close to the fully labeled accuracy we can get under different scenarios, and show that an easy-to-implement method only assuming the knowledge of the maximum cardinality is comparable to the state-of-the-art single-positive multi-label learning methods when using the same base model. Our implementation is publicly available at https://github.com/shayangharib/SPMLL_with_Label_Cardinality.},
  archive      = {J_TMLR},
  author       = {Shayan Gharib and Pierre-Alexandre Murena and Arto Klami},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Single-positive multi-label learning with label cardinality},
  url          = {https://openreview.net/forum?id=XEPPXH2nKu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text to stealthy adversarial face masks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XYqCx026AI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have demonstrated that modern facial recognition systems, which are based on deep neural networks, are vulnerable to adversarial attacks, including the use of accessories, makeup patterns, or precision lighting. However, developing attacks that are both robust (resilient to changes in viewing angles and environmental conditions) and stealthy (do not attract suspicion by, for example, incorporating obvious facial features) remains a significant challenge. In this context, we introduce a novel diffusion-based method (DAFR) capable of generating robust and stealthy face masks for dodging recognition systems (where the system fails to identify the attacker). Specifically our approach is capable of producing high-fidelity printable textures using the guidance of textual prompts to determine the style. This method can also be adapted for impersonation purposes, where the system misidentifies the attacker as a specific other individual. Finally, we address a gap in the existing literature by presenting a comprehensive benchmark (FAAB) for evaluating adversarial accessories in three dimensions, assessing their robustness and stealthiness.},
  archive      = {J_TMLR},
  author       = {Ben Lewis and Thomas Moyse and James Parkinson and Elizabeth Telford and Callum Whitfield and Ranko Lazic},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Text to stealthy adversarial face masks},
  url          = {https://openreview.net/forum?id=XYqCx026AI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAPP: Large language model feedback for preference-driven reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cq76wx7T9F'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Large Language Model-Assisted Preference Prediction (LAPP), a novel framework for robot learning that enables efficient, customizable, and expressive behavior acquisition with minimum human effort. Unlike prior approaches that rely heavily on reward engineering, human demonstrations, motion capture, or expensive pairwise preference labels, LAPP leverages large language models (LLMs) to automatically generate preference labels from raw state-action trajectories collected during reinforcement learning (RL). These labels are used to train an online preference predictor, which in turn guides the policy optimization process toward satisfying high-level behavioral specifications provided by humans. Our key technical contribution is the integration of LLMs into the RL feedback loop through trajectory-level preference prediction, enabling robots to acquire complex skills including subtle control over gait patterns and rhythmic timing. We evaluate LAPP on a diverse set of quadruped locomotion and dexterous manipulation tasks and show that it achieves efficient learning, higher final performance, faster adaptation, and precise control of high-level behaviors. Notably, LAPP enables robots to master highly dynamic and expressive tasks such as quadruped backflips, which remain out of reach for standard LLM-generated or handcrafted rewards. Our results highlight LAPP as a promising direction for scalable preference-driven robot learning.},
  archive      = {J_TMLR},
  author       = {Pingcheng Jian and Xiao Wei and Yanbaihui Liu and Samuel A. Moore and Michael M. Zavlanos and Boyuan Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LAPP: Large language model feedback for preference-driven reinforcement learning},
  url          = {https://openreview.net/forum?id=cq76wx7T9F},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Studying memorization of large language models using answers to stack overflow questions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ddocn44Kaq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are capable of answering many software related questions and supporting developers by generating code snippets. These capabilities originate from training on massive amounts of data from the Internet, including information from Stack Overflow. This raises the question whether answers to software related questions are simply memorized from the training data, which might raise problems as this often requires attribution (e.g., CC-BY license), sharing with a similar license (e.g., GPL licenses) or may even be prohibited (proprietary license). To study this, we compare responses to questions from Stack Overflow for questions that were known during LLM pre-training and questions that were not included in the pre-training data. We then calculate the overlap both with answers marked as accepted on Stack Overflow as well as other texts we can find on the internet. We further explore the impact of the popularity of programming languages, the complexity of the prompts used, and the randomization of the text generation process on the memorization of answers to Stack Overflow. We find that many generated answers are to some degree collages of memorized content and that this does not dependent on whether the questions were seen during training or not. However, many of the memorized snippets are common phrases or code and, therefore, not copyrightable. Still, we also have clear evidence that copyright violation happens and is likely when LLMs are used at large scales.},
  archive      = {J_TMLR},
  author       = {Laura Caspari and Alexander Trautsch and Michael Granitzer and Steffen Herbold},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Studying memorization of large language models using answers to stack overflow questions},
  url          = {https://openreview.net/forum?id=ddocn44Kaq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HandsOnVLM: Vision-language models for hand-object interaction prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ehhMFjKnWm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can we predict future interaction trajectories of human hands in a scene given high-level colloquial task specifications in the form of natural language? In this paper, we extend the classic hand trajectory prediction task to several tasks involving explicit and implicit language queries. Our proposed tasks require extensive understanding of human daily activities and reasoning abilities about what is happening next given cues from the current scene. We also develop new benchmarks to evaluate the proposed two tasks, Vanilla Hand Prediction (VHP) and Reasoning-Based Hand Prediction (RBHP). We enable solving these tasks by integrating high-level world knowledge and reasoning capabilities of Vision-Language Models (VLMs) with the auto-regressive nature of low-level ego-centric hand trajectories. Our model, HandsOnVLM is a novel VLM that can generate textual responses and produce future hand trajectories through natural-language conversations. Our experiments show that HandsOnVLM outperforms existing task-specific methods and other VLM baselines on proposed tasks, and demonstrates its ability to effectively utilize world knowledge for reasoning about low-level human hand trajectories based on the provided context. More details can be found at https://www.chenbao.tech/handsonvlm/.},
  archive      = {J_TMLR},
  author       = {Chen Bao and Jiarui Xu and Xiaolong Wang and Abhinav Gupta and Homanga Bharadhwaj},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HandsOnVLM: Vision-language models for hand-object interaction prediction},
  url          = {https://openreview.net/forum?id=ehhMFjKnWm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete audio tokens: More than a survey!. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=eqNchtvc6v'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete audio tokens are compact representations that aim to preserve perceptual quality, phonetic content, and speaker characteristics while enabling efficient storage and inference, as well as competitive performance across diverse downstream tasks. They provide a practical alternative to continuous features, enabling the integration of speech and audio into modern large language models (LLMs). As interest in token-based audio processing grows, various tokenization methods have emerged, and several surveys have reviewed the latest progress in the field. However, existing studies often focus on specific domains or tasks and lack a unified comparison across various benchmarks. This paper presents a systematic review and benchmark of discrete audio tokenizers, covering three domains: speech, music, and general audio. We propose a taxonomy of tokenization approaches based on encoder-decoder, quantization techniques, training paradigm, streamability, and application domains. We evaluate tokenizers on multiple benchmarks for reconstruction, downstream performance, and acoustic language modeling, and analyze trade-offs through controlled ablation studies. Our findings highlight key limitations, practical considerations, and open challenges, providing insight and guidance for future research in this rapidly evolving area. For more information, including our main results and tokenizer database, please refer to our website: https://poonehmousavi.github.io/dates-website/.},
  archive      = {J_TMLR},
  author       = {Pooneh Mousavi and Gallil Maimon and Adel Moumen and Darius Petermann and Jiatong Shi and Haibin Wu and Haici Yang and Anastasia Kuznetsova and Artem Ploujnikov and Ricard Marxer and Bhuvana Ramabhadran and Benjamin Elizalde and Loren Lugosch and Jinyu Li and Cem Subakan and Phil Woodland and Minje Kim and Hung-yi Lee and Shinji Watanabe and Yossi Adi and Mirco Ravanelli},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Discrete audio tokens: More than a survey!},
  url          = {https://openreview.net/forum?id=eqNchtvc6v},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the learned look-ahead behavior of chess neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=np4Bg2zIxL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the look-ahead capabilities of chess-playing neural networks, specifically focusing on the Leela Chess Zero policy network. We build on the work of Jenner et al. (2024) by analyzing the model's ability to consider future moves and alternative sequences beyond the immediate next move. Our findings reveal that the network's look-ahead behavior is highly context-dependent, varying significantly based on the specific chess position. We demonstrate that the model can process information about board states up to seven moves ahead, utilizing similar internal mechanisms across different future time steps. Additionally, we provide evidence that the network considers multiple possible move sequences rather than focusing on a single line of play. These results offer new insights into the emergence of sophisticated look-ahead capabilities in neural networks trained on strategic tasks, contributing to our understanding of AI reasoning in complex domains. Our work also showcases the effectiveness of interpretability techniques in uncovering cognitive-like processes in artificial intelligence systems.},
  archive      = {J_TMLR},
  author       = {Diogo Cruz},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding the learned look-ahead behavior of chess neural networks},
  url          = {https://openreview.net/forum?id=np4Bg2zIxL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlowKac: An efficient neural fokker-planck solver using temporal normalizing flows and the feynman-kac formula. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=paeyQFa5or'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the Fokker-Planck equation for high-dimensional complex dynamical systems remains a pivotal yet challenging task due to the intractability of analytical solutions and the limitations of traditional numerical methods. In this work, we present FlowKac, a novel approach that reformulates the Fokker-Planck equation using the Feynman-Kac formula, allowing to query the solution at a given point via the expected values of stochastic paths. A key innovation of FlowKac lies in its adaptive stochastic sampling scheme which significantly reduces the computational complexity while maintaining high accuracy. This sampling technique, coupled with a time-indexed normalizing flow, designed for capturing time-evolving probability densities, enables robust sampling of collocation points, resulting in a flexible and mesh-free solver. This formulation mitigates the curse of dimensionality and enhances computational efficiency and accuracy, which is particularly crucial for applications that inherently require dimensions beyond the conventional three. We validate the robustness and scalability of our method through various experiments on a range of stochastic differential equations, demonstrating significant improvements over existing techniques.},
  archive      = {J_TMLR},
  author       = {Naoufal EL BEKRI and Lucas Drumetz and Franck Vermet},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FlowKac: An efficient neural fokker-planck solver using temporal normalizing flows and the feynman-kac formula},
  url          = {https://openreview.net/forum?id=paeyQFa5or},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient object-centric representation learning using masked generative modeling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=t9KvOYPeL3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning object-centric representations from visual inputs in an unsupervised manner has drawn focus to solve more complex tasks, such as reasoning and reinforcement learning. However, current state-of-the-art methods, relying on autoregressive transformers or diffusion models to generate scenes from object-centric representations, suffer from computational inefficiency due to their sequential or iterative nature. This computational bottleneck limits their practical application and hinders scaling to more complex downstream tasks. To overcome this, we propose MOGENT, an efficient object-centric learning framework based on masked generative modeling. MOGENT conditions a masked bidirectional transformer on learned object slots and employs a parallel iterative decoding scheme to generate scenes, enabling efficient compositional generation. Experiments show that MOGENT significantly improves computational efficiency, accelerating the generation process by up to 67x and 17x compared to autoregressive models and diffusion-based models, respectively. Importantly, the efficiency is attained while maintaining strong or competitive performance on object segmentation and compositional generation tasks.},
  archive      = {J_TMLR},
  author       = {Akihiro Nakano and Masahiro Suzuki and Yutaka Matsuo},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient object-centric representation learning using masked generative modeling},
  url          = {https://openreview.net/forum?id=t9KvOYPeL3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedComLoc: Communication-efficient distributed training of sparse and quantized models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vYQPLytQsj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has garnered increasing attention due to its unique characteristic of allowing heterogeneous clients to process their private data locally and interact with a central server, while being respectful of privacy. A critical bottleneck in FL is the communication cost. A pivotal strategy to mitigate this burden is Local Training, which involves running multiple local stochastic gradient descent iterations between communication phases. Our work is inspired by the innovative Scaffnew algorithm, which has considerably advanced the reduction of communication complexity in FL. We introduce FedComLoc (Federated Compressed and Local Training), integrating practical and effective compression into Scaffnew to further enhance communication efficiency. Extensive experiments, using the popular Top-K compressor and quantization, demonstrate its prowess in substantially reducing communication overheads in heterogeneous settings.},
  archive      = {J_TMLR},
  author       = {Kai Yi and Georg Meinhardt and Laurent Condat and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FedComLoc: Communication-efficient distributed training of sparse and quantized models},
  url          = {https://openreview.net/forum?id=vYQPLytQsj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label embedding via low-coherence matrices. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vrcWXcr4On'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label embedding is a framework for multiclass classification problems where each label is represented by a distinct vector of some fixed dimension, and training involves matching model output to the vector representing the correct label. While label embedding has been successfully applied in extreme classification and zero-shot learning, and offers both computational and statistical advantages, its theoretical foundations remain poorly understood. This work presents an analysis of label embedding in the context of extreme multiclass classification, where the number of classes $C$ is very large. We present an excess risk bound that reveals a trade-off between computational and statistical efficiency, quantified via the coherence of the embedding matrix. We further show that under the Massart noise condition, the statistical penalty for label embedding vanishes with sufficiently low coherence. Our analysis supports an algorithm that is simple, scalable, and easily parallelizable, and experimental results demonstrate its effectiveness in large-scale applications.},
  archive      = {J_TMLR},
  author       = {Jianxin Zhang and Clayton Scott},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Label embedding via low-coherence matrices},
  url          = {https://openreview.net/forum?id=vrcWXcr4On},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNR-pruning: Sparsity-aware pruning via dying neuron reactivation in convolutional neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ymUjGCNPYa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we challenge the conventional view of dead neurons—neurons that cease to activate—during deep neural network training. Traditionally regarded as problematic due to their association with optimization challenges and reduced model adaptability over training epochs, dead neurons are often seen as a hindrance. However, we present a novel perspective, demonstrating that they can be effectively leveraged to enhance network sparsity. Specifically, we propose DNR-Pruning, dying neuron reactivation based sparsity-aware pruning approach for convolutional neural networks (CNNs) that exploits the behavior of individual neurons during training. Through a systematic exploration of hyperparameter configurations, we show that dying neurons can be harnessed to improve pruning algorithms. Our method dynamically monitors the occurrence of dying neurons, enabling adaptive sparsification throughout CNN training. Extensive experiments on diverse datasets demonstrate that DNR-Pruning outperforms existing sparsity-aware pruning techniques while achieving competitive results compared to state-of-the-art methods. These findings suggest that dying neurons can serve as an efficient mechanism for network compression and resource optimization in CNNs, opening new avenues for more efficient and high-performance deep learning models.},
  archive      = {J_TMLR},
  author       = {Boyuan Wang and Richard Jiang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DNR-pruning: Sparsity-aware pruning via dying neuron reactivation in convolutional neural networks},
  url          = {https://openreview.net/forum?id=ymUjGCNPYa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information-theoretic lower bound on the generalization error of autoencoders. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0esF0M467w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying the limitations of classical neural network architectures is a critically underexplored area of machine learning research. Deriving lower bounds on the optimal performance of these architectures can facilitate improved neural architecture search and overfitting detection. We present an information-theoretic lower bound on the generalization mean squared error of autoencoders with sigmoid activation functions. Through the Estimation Error and Differential Entropy (EEDE) inequality for continuous random vectors, we derive this lower bound, which provides a new perspective on the inherent limitations and capabilities of autoencoders. Our analysis extends to the examination of how this lower bound is influenced by various architectural features and data distribution characteristics. This study enriches our theoretical understanding of autoencoders and has substantial practical implications for their design, optimization, and application in the field of deep learning.},
  archive      = {J_TMLR},
  author       = {Shyam Venkatasubramanian and Sean Moushegian and Ahmed Aloui and Vahid Tarokh},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An information-theoretic lower bound on the generalization error of autoencoders},
  url          = {https://openreview.net/forum?id=0esF0M467w},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Min-max optimisation for nonconvex-nonconcave functions using a random zeroth-order extragradient algorithm. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1bxY1uAXyr'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the performance of the random Gaussian smoothing Zeroth-Order ExtraGradient (ZO-EG) scheme considering deterministic min-max optimisation problems with possibly NonConvex-NonConcave (NC-NC) objective functions. We consider both unconstrained and constrained, differentiable and non-differentiable settings. We discuss the min-max problem from the point of view of variational inequalities. For the unconstrained problem, we establish the convergence of the ZO-EG algorithm to the neighbourhood of an $\epsilon$-stationary point of the NC-NC objective function, whose radius can be controlled under a variance reduction scheme, along with its complexity. For the constrained problem, we introduce the new notion of proximal variational inequalities and give examples of functions satisfying this property. Moreover, we prove analogous results to the unconstrained case for the constrained problem. For the non-differentiable case, we prove the convergence of the ZO-EG algorithm to a neighbourhood of an $\epsilon$-stationary point of the smoothed version of the objective function, where the radius of the neighbourhood can be controlled, which can be related to the ($\delta,\epsilon$)-Goldstein stationary point of the original objective function.},
  archive      = {J_TMLR},
  author       = {Amir Ali Farzin and Yuen-Man Pun and Philipp Braun and Antoine Lesage-Landry and Youssef Diouane and Iman Shames},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Min-max optimisation for nonconvex-nonconcave functions using a random zeroth-order extragradient algorithm},
  url          = {https://openreview.net/forum?id=1bxY1uAXyr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Survey of video diffusion models: Foundations, implementations, and applications. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2ODDBObKjH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in diffusion models have revolutionized video generation, offering superior temporal consistency and visual quality compared to traditional generative adversarial networks-based approaches. While this emerging field shows tremendous promise in applications, it faces significant challenges in motion consistency, computational efficiency, and ethical considerations. This survey provides a comprehensive review of diffusion-based video generation, examining its evolution, technical foundations, and practical applications. We present a systematic taxonomy of current methodologies, analyze architectural innovations and optimization strategies, and investigate applications across low-level vision tasks such as denoising and super-resolution. Additionally, we explore the synergies between diffusion-based video generation and related domains, including video representation learning, question answering, and retrieval. Compared to the existing surveys (Lei et al., 2024a;b; Melniket al., 2024; Cao et al., 2023; Xing et al., 2024c) which focus on specific aspects of video generation, such as human video synthesis (Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), our work provides a broader, more updated, and more fine-grained perspective on diffusion-based approaches with a special section for evaluation metrics, industry solutions, and training engineering techniques in video generation. This survey serves as a foundational resource for researchers and practitioners working at the intersection of diffusion models and video generation, providing insights into both the theoretical frameworks and practical implementations that drive this rapidly evolving field.},
  archive      = {J_TMLR},
  author       = {Yimu Wang and Xuye Liu and Wei Pang and Li Ma and Shuai Yuan and Paul Debevec and Ning Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Survey of video diffusion models: Foundations, implementations, and applications},
  url          = {https://openreview.net/forum?id=2ODDBObKjH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GROOD: GRadient-aware out-of-distribution detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2V7itvvMVJ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution (OOD) detection is crucial for ensuring the reliability of deep learning models in real-world applications. Existing methods typically focus on feature representations or output-space analysis, often assuming a distribution over these spaces or leveraging gradient norms with respect to model parameters. However, these approaches struggle to distinguish near-OOD samples and often require extensive hyper-parameter tuning, limiting their practicality. In this work, we propose GRadient-aware Out-Of-Distribution detection (GROOD), a method that derives an OOD prototype from synthetic samples and computes class prototypes directly from In-distribution (ID) training data. By analyzing the gradients of a nearest-class-prototype loss function concerning an artificial OOD prototype, our approach achieves a clear separation between in-distribution and OOD samples. Experimental evaluations demonstrate that gradients computed from the OOD prototype enhance the distinction between ID and OOD data, surpassing established baselines in robustness, particularly on ImageNet-1k. These findings highlight the potential of gradient-based methods and prototype-driven approaches in advancing OOD detection within deep neural networks.},
  archive      = {J_TMLR},
  author       = {Mostafa ElAraby and Sabyasachi Sahoo and Yann Pequignot and Paul Novello and Liam Paull},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GROOD: GRadient-aware out-of-distribution detection},
  url          = {https://openreview.net/forum?id=2V7itvvMVJ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning robust representations for visual reinforcement learning via task-relevant mask sampling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2rxNDxHwtn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans excel at isolating relevant information from noisy data to predict the behavior of dynamic systems, effectively disregarding non-informative, temporally-correlated noise. In contrast, existing visual reinforcement learning algorithms face challenges in generating noise-free predictions within high-dimensional, noise-saturated environments, especially when trained on world models featuring realistic background noise extracted from natural video streams. We propose Task Relevant Mask Sampling (TRMS), a novel approach for identifying task-specific and reward-relevant masks. TRMS utilizes existing segmentation models as a masking prior, which is subsequently followed by a mask selector that dynamically identifies subset of masks at each timestep, selecting those most probable to contribute to task-specific rewards. To mitigate the high computational cost associated with these masking priors, a lightweight student network is trained in parallel. This network learns to perform masking independently and replaces the Segment Anything Model~(SAM)-based teacher network after a brief initial phase (<10-25% of total training). TRMS enhances the generalization capabilities of Soft Actor-Critic agents under distractions, achieves better performance on the RL-Vigen benchmark, which includes challenging variants of the DeepMind Control Suite, Dexterous Manipulation and Quadruped Locomotion tasks.},
  archive      = {J_TMLR},
  author       = {Vedant Dave and Ozan Özdenizci and Elmar Rueckert},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning robust representations for visual reinforcement learning via task-relevant mask sampling},
  url          = {https://openreview.net/forum?id=2rxNDxHwtn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LIT-LVM: Structured regularization for interaction terms in linear predictors using latent variable models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3uW5nxESu1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some of the simplest, yet most frequently used predictors in statistics and machine learning use weighted linear combinations of features. Such linear predictors can model non-linear relationships between features by adding interaction terms corresponding to the products of all pairs of features. We consider the problem of accurately estimating coefficients for interaction terms in linear predictors. We hypothesize that the coefficients for different interaction terms have an approximate low-dimensional structure and represent each feature by a latent vector in a low-dimensional space. This low-dimensional representation can be viewed as a structured regularization approach that further mitigates overfitting in high-dimensional settings beyond standard regularizers such as the lasso and elastic net. We demonstrate that our approach, called LIT-LVM, achieves superior prediction accuracy compared to the elastic net, hierarchical lasso, and factorization machines on a wide variety of simulated and real data, particularly when the number of interaction terms is high compared to the number of samples. LIT-LVM also provides low-dimensional latent representations for features that are useful for visualizing and analyzing their relationships.},
  archive      = {J_TMLR},
  author       = {Mohammadreza Nemati and Zhipeng Huang and Kevin S. Xu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LIT-LVM: Structured regularization for interaction terms in linear predictors using latent variable models},
  url          = {https://openreview.net/forum?id=3uW5nxESu1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double machine learning based structure identification from temporal data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4iHAoFVM2K'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the causes of time-series data is a fundamental task in many applications, spanning from finance to earth sciences or bio-medical applications. Common approaches for this task are based on vector auto-regression, and they do not take into account unknown confounding between potential causes. However, in settings with many potential causes and noisy data, these approaches may be substantially biased. Furthermore, potential causes may be correlated in practical applications or even contain cycles. To address these challenges, we propose a new double machine learning based method for structure identification from temporal data (DR-SIT). We provide theoretical guarantees, showing that our method asymptotically recovers the true underlying causal structure. Our analysis extends to cases where the potential causes have cycles, and they may even be confounded. We further perform extensive experiments to showcase the superior performance of our method. Code: https://github.com/sdi1100041/TMLR_submission_DR_SIT},
  archive      = {J_TMLR},
  author       = {Emmanouil Angelis and Francesco Quinzan and Ashkan Soleymani and Patrick Jaillet and Stefan Bauer},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Double machine learning based structure identification from temporal data},
  url          = {https://openreview.net/forum?id=4iHAoFVM2K},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Byzantine-robust and hessian-free federated bilevel optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5trmyvtkeo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, Byzantine robust algorithms to solve a minimization problem in the Federated setup have received significant attention. Most of the existing works consider the problem of byzantine-robustness for single-level optimization or consider the federated bilevel optimization without Byzantine nodes. However, problem formulation such as federated bilevel optimization in the presence of byzantine nodes is unexplored. Recognizing the gap, for the first time, we propose a computationally efficient and robust algorithm for solving Federated Bilevel Optimization with Byzantine (FedBOB) nodes that: \One Work under the assumption that the data across nodes are heterogeneous (non-iid), \2 Consider the lower-level objective is non-convex and satisfies the Polyak-\L ojasiewicz (PL)-inequality, and \3 Is fully first-order and does not rely on second order information. We achieve this by reformulating the federated bilevel problem into a single penalty problem. We provide the theoretical performance of the proposed algorithm and experimentally corroborate our theoretical findings.},
  archive      = {J_TMLR},
  author       = {Shruti P Maralappanavar and Bharath B N},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Byzantine-robust and hessian-free federated bilevel optimization},
  url          = {https://openreview.net/forum?id=5trmyvtkeo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate bayesian neural operators: Uncertainty quantification for parametric PDEs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6WvIkYsMA8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators are a type of deep architecture that learns to solve (i.e. learns the nonlinear solution operator of) partial differential equations (PDEs). The current state of the art for these models does not provide explicit uncertainty quantification. This is arguably even more of a problem for this kind of tasks than elsewhere in machine learning, because the dynamical systems typically described by PDEs often exhibit subtle, multiscale structure that makes errors hard to spot by humans. In this work, we first provide a mathematically detailed Bayesian formulation of the ``shallow'' (linear) version of neural operators in the formalism of Gaussian processes. We then extend this analytic treatment to general deep neural operators—specifically, graph neural operators—using approximate methods from Bayesian deep learning, enabling them to incorporate uncertainty quantification. As a result, our approach is able to identify cases, and provide structured uncertainty estimates, where the neural operator fails to predict well.},
  archive      = {J_TMLR},
  author       = {Emilia Magnani and Nicholas Krämer and Runa Eschenhagen and Lorenzo Rosasco and Philipp Hennig},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Approximate bayesian neural operators: Uncertainty quantification for parametric PDEs},
  url          = {https://openreview.net/forum?id=6WvIkYsMA8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding emergent in-context learning from a kernel regression perspective. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6rD50Q6yYz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have initiated a paradigm shift in transfer learning. In contrast to the classic pretraining-then-finetuning procedure, in order to use LLMs for downstream prediction tasks, one only needs to provide a few demonstrations, known as in-context examples, without adding more or updating existing model parameters. This in-context learning (ICL) capability of LLMs is intriguing, and it is not yet fully understood how pretrained LLMs acquire such capabilities. In this paper, we investigate the reason why a transformer-based language model can accomplish in-context learning after pre-training on a general language corpus by proposing a kernel-regression perspective of understanding LLMs' ICL behaviors when faced with in-context examples. More concretely, we first prove that Bayesian inference on in-context prompts can be asymptotically understood as kernel regression $\hat y = \sum_i y_i K(x, x_i)/\sum_i K(x, x_i)$ as the number of in-context demonstrations grows. Then, we empirically investigate the in-context behaviors of language models. We find that during ICL, the attention and hidden features in LLMs match the behaviors of a kernel regression. Finally, our theory provides insights into multiple phenomena observed in the ICL field: why retrieving demonstrative samples similar to test samples can help, why ICL performance is sensitive to the output formats, and why ICL accuracy benefits from selecting in-distribution and representative samples.},
  archive      = {J_TMLR},
  author       = {Chi Han and Ziqi Wang and Han Zhao and Heng Ji},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding emergent in-context learning from a kernel regression perspective},
  url          = {https://openreview.net/forum?id=6rD50Q6yYz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-asynchronous local SGD: Robust and efficient data-parallel training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8VTrvS5vN7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following AI scaling trends, frontier models continue to grow in size and continue to be trained on larger datasets. Training these models requires huge investments in exascale computational resources, which has in turn driven developtment of distributed deep learning methods. Data parallelism is an essential approach to speed up training, but it requires frequent global communication between workers, which can bottleneck training at the largest scales. In this work, we propose a method called Pseudo-Asynchronous Local SGD (PALSGD) to improve the efficiency of data-parallel training. PALSGD is an extension of Local SGD (Stich, 2018) and DiLoCo (Douillard et al., 2023), designed to further reduce communication frequency by introducing a pseudo-synchronization mechanism. PALSGD allows the use of longer synchronization intervals compared to standard Local SGD. Despite the reduced communication frequency, the pseudo-synchronization approach ensures that model consistency is maintained, leading to performance results comparable to those achieved with more frequent synchronization. Furthermore, we provide a theoretical analysis of PALSGD, establishing its convergence and deriving its convergence rate. This analysis offers insights into the algorithm's behavior and performance guarantees. We evaluated PALSGD on image classification and language modeling tasks. Our results show that PALSGD achieves better performance in less time compared to existing methods like Distributed Data Parallel (DDP), and DiLoCo. Notably, PALSGD trains 18.4% faster than DDP on ImageNet-1K with ResNet-50, 24.4% faster than DDP on TinyStories with GPT-Neo-125M, and 21.1% faster than DDP on TinyStories with GPT-Neo-8M.},
  archive      = {J_TMLR},
  author       = {Hiroki Naganuma and Xinzhi Zhang and Man-Chung Yue and Ioannis Mitliagkas and Russell J. Hewett and Philipp Andre Witte and Yin Tat Lee},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pseudo-asynchronous local SGD: Robust and efficient data-parallel training},
  url          = {https://openreview.net/forum?id=8VTrvS5vN7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural causal circuits: Probabilistic circuits climbing all rungs of pearl's ladder of causation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=25XyUTICdZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity and vastness of our world can require large models with numerous variables. Unfortunately, coming up with a model that is both accurate and able to provide predictions in a reasonable amount of time can prove difficult. One possibility to help overcome such problems is sum-product networks (SPNs), probabilistic models with the ability to tractably perform inference in linear time. In this paper, we extend SPNs' capabilities to the field of causality and introduce the family of structural causal circuits (SCCs), a type of SPNs capable of answering causal questions. Starting from conventional SPNs, we ``climb the ladder of causation'' and show how SCCs can represent not only observational but also interventional and counterfactual problems. We demonstrate successful application in different settings, ranging from simple binary variables to physics-based simulations.},
  archive      = {J_TMLR},
  author       = {Florian Peter Busch and Moritz Willig and Matej Zečević and Kristian Kersting and Devendra Singh Dhami},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Structural causal circuits: Probabilistic circuits climbing all rungs of pearl's ladder of causation},
  url          = {https://openreview.net/forum?id=25XyUTICdZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open problems in mechanistic interpretability. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=91H76m9Z94'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities in order to accomplish concrete scientific and engineering goals. Progress in this field thus promises to provide greater assurance over AI system behavior and shed light on exciting scientific questions about the nature of intelligence. Despite recent progress toward these goals, there are many open problems in the field that require solutions before many scientific and practical benefits can be realized: Our methods require both conceptual and practical improvements to reveal deeper insights; we must figure out how best to apply our methods in pursuit of specific goals; and the field must grapple with socio-technical challenges that influence and are influenced by our work. This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems that the field may benefit from prioritizing.},
  archive      = {J_TMLR},
  author       = {Lee Sharkey and Bilal Chughtai and Joshua Batson and Jack Lindsey and Jeffrey Wu and Lucius Bushnaq and Nicholas Goldowsky-Dill and Stefan Heimersheim and Alejandro Ortega and Joseph Isaac Bloom and Stella Biderman and Adrià Garriga-Alonso and Arthur Conmy and Neel Nanda and Jessica Mary Rumbelow and Martin Wattenberg and Nandi Schoots and Joseph Miller and William Saunders and Eric J Michaud and Stephen Casper and Max Tegmark and David Bau and Eric Todd and Atticus Geiger and Mor Geva and Jesse Hoogland and Daniel Murfet and Thomas McGrath},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Open problems in mechanistic interpretability},
  url          = {https://openreview.net/forum?id=91H76m9Z94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model guidance via robust feature attribution. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AVAHxDSqUu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the patterns a model learns is essential to preventing reliance on irrelevant or misleading features. Such reliance on irrelevant features, often called shortcut features, has been observed across domains, including medical imaging and natural language processing, where it may lead to real-world harms. A common mitigation strategy leverages annotations (provided by humans or machines) indicating which features are relevant or irrelevant. These annotations are compared to model explanations, typically in the form of feature salience, and used to guide the loss function during training. Unfortunately, recent works have demonstrated that feature salience methods are unreliable and therefore offer a poor signal to optimize. In this work, we propose a simplified objective that simultaneously optimizes for explanation robustness and mitigation of shortcut learning. Unlike prior objectives with similar aims, we demonstrate theoretically why our approach ought to be more effective. Across a comprehensive series of experiments, we show that our approach consistently reduces test-time misclassifications by 20\% compared to state-of-the-art methods. We also extend prior experimental settings to include natural language processing tasks. Additionally, we conduct novel ablations that yield practical insights, including the relative importance of annotation quality over quantity. Code for our method and experiments is available at: https://github.com/Mihneaghitu/ModelGuidanceViaRobustFeatureAttribution.},
  archive      = {J_TMLR},
  author       = {Mihnea Ghitu and Vihari Piratla and Matthew Robert Wicker},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Model guidance via robust feature attribution},
  url          = {https://openreview.net/forum?id=AVAHxDSqUu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two is better than one: Aligned representation pairs for anomaly detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Bt0zdsnWYc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection focuses on identifying samples that deviate from the norm. Discovering informative representations of normal samples is crucial to detecting anomalies effectively. Recent self-supervised methods have successfully learned such representations by employing prior knowledge about anomalies to create synthetic outliers during training. However, we often do not know what to expect from unseen data in specialized real-world applications. In this work, we address this limitation with our new approach, Con2, which leverages prior knowledge about symmetries in normal samples to observe the data in different contexts. Con2 consists of two parts: Context Contrasting clusters representations according to their context, while Content Alignment encourages the model to capture semantic information by aligning the positions of normal samples across clusters. The resulting representation space allows us to detect anomalies as outliers of the learned context clusters. We demonstrate the benefit of this approach in extensive experiments on specialized medical datasets, outperforming competitive baselines based on self-supervised learning and pretrained models and presenting competitive performance on natural imaging benchmarks.},
  archive      = {J_TMLR},
  author       = {Alain Ryser and Thomas M. Sutter and Alexander Marx and Julia E Vogt},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Two is better than one: Aligned representation pairs for anomaly detection},
  url          = {https://openreview.net/forum?id=Bt0zdsnWYc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling multiple descents in unsupervised autoencoders. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FqfHDs6unx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of double descent has challenged the traditional bias-variance trade-off in supervised learning but remains unexplored in unsupervised learning, with some studies arguing for its absence. In this study, we first demonstrate analytically that double descent does not occur in linear unsupervised autoencoders (AEs). In contrast, we show for the first time that both double and triple descent can be observed with nonlinear AEs across various data models and architectural designs. We examine the effects of partial sample and feature noise and highlight the critical role of bottleneck size in shaping the double descent curve. Through extensive experiments on both synthetic and real datasets, we uncover model-wise, epoch-wise, and sample-wise double descent across several data types and architectures. Our findings indicate that over-parameterized models not only improve reconstruction but also enhance performance in downstream tasks such as anomaly detection and domain adaptation, highlighting their practical value in complex real-world scenarios.},
  archive      = {J_TMLR},
  author       = {Kobi Rahimi and Yehonathan Refael and Tom Tirer and Ofir Lindenbaum},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unveiling multiple descents in unsupervised autoencoders},
  url          = {https://openreview.net/forum?id=FqfHDs6unx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifi3D: A study on 3D representations for generation and reconstruction in a common framework. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GQpTWpXILA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following rapid advancements in text and image generation, research has increasingly shifted towards 3D generation. Unlike the well-established pixel-based representation in images, 3D representations remain diverse and fragmented, encompassing a wide variety of approaches such as voxel grids, neural radiance fields, signed distance functions, point clouds, or octrees, each offering distinct advantages and limitations. In this work, we present a unified evaluation framework designed to assess the performance of 3D representations in reconstruction and generation. We compare these representations based on multiple criteria: quality, computational efficiency, and generalization performance. Beyond standard model benchmarking, our experiments aim to derive best practices over all steps involved in the 3D generation pipeline, including preprocessing, mesh reconstruction, compression with autoencoders, and generation. Our findings highlight that reconstruction errors significantly impact overall performance, underscoring the need to evaluate generation and reconstruction jointly. We provide insights that can inform the selection of suitable 3D models for various applications, facilitating the development of more robust and application-specific solutions in 3D generation. The code for our framework is available at https://github.com/isl-org/unifi3d.},
  archive      = {J_TMLR},
  author       = {Nina Wiedemann and Sainan Liu and Quentin Leboutet and Katelyn Gao and Benjamin Ummenhofer and Michael Paulitsch and Kai Yuan},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unifi3D: A study on 3D representations for generation and reconstruction in a common framework},
  url          = {https://openreview.net/forum?id=GQpTWpXILA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-1-to-G: Taming pretrained 2D diffusion model for direct 3D generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GVizav9Zf8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in 2D image generation have achieved remarkable quality, largely driven by the capacity of diffusion models and the availability of large-scale datasets. However, direct 3D generation is still constrained by the scarcity and lower fidelity of 3D datasets. In this paper, we introduce Zero-1-to-G, a novel approach that addresses this problem by enabling direct single-view generation on Gaussian splats using pretrained 2D diffusion models. Our key insight is that Gaussian splats, a 3D representation, can be decomposed into multi-view images encoding different attributes. This reframes the challenging task of direct 3D generation within a 2D diffusion framework, allowing us to leverage the rich priors of pretrained 2D diffusion models. To incorporate 3D awareness, we introduce cross-view and cross-attribute attention layers, which capture complex correlations and enforce 3D consistency across generated splats. This makes Zero-1-to-G the first direct image-to-3D generative model to effectively utilize pretrained 2D diffusion priors, enabling efficient training and improved generalization to unseen objects. Extensive experiments on both synthetic and in-the-wild datasets demonstrate superior performance in 3D object generation, offering a new approach to high-quality 3D generation.},
  archive      = {J_TMLR},
  author       = {Xuyi Meng and Chen Wang and Jiahui Lei and Kostas Daniilidis and Jiatao Gu and Lingjie Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Zero-1-to-G: Taming pretrained 2D diffusion model for direct 3D generation},
  url          = {https://openreview.net/forum?id=GVizav9Zf8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low compute unlearning via sparse representations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GyKXzmk43s'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning, which involves erasing knowledge about a \emph{forget set} from a trained model, can prove to be costly and infeasible using existing techniques. We propose a low-compute unlearning technique based on a discrete representational bottleneck. We show that the proposed technique efficiently unlearns the forget set and incurs negligible damage to the model's performance on the rest of the dataset. We evaluate the proposed technique on the problem of class unlearning using four datasets: CIFAR-10, CIFAR-100, LACUNA-100 and ImageNet-1k. We compare the proposed technique to SCRUB, a state-of-the-art approach which uses knowledge distillation for unlearning. Across all four datasets, the proposed technique performs as well as, if not better than SCRUB while incurring almost no computational cost.},
  archive      = {J_TMLR},
  author       = {Vedant Shah and Frederik Träuble and Ashish Malik and Hugo Larochelle and Michael Curtis Mozer and Sanjeev Arora and Yoshua Bengio and Anirudh Goyal},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Low compute unlearning via sparse representations},
  url          = {https://openreview.net/forum?id=GyKXzmk43s},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRDT3: Diffusion-refined decision test-time training model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=I6zjLhIzgh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision Transformer (DT), a trajectory modelling method, has shown competitive performance compared to traditional offline reinforcement learning (RL) approaches on various classic control tasks. However, it struggles to learn optimal policies from suboptimal, reward-labelled trajectories. In this study, we explore the use of conditional generative modelling to facilitate trajectory stitching given its high-quality data generation ability. Additionally, recent advancements in Recurrent Neural Networks (RNNs) have shown their linear complexity and competitive sequence modelling performance over Transformers. We leverage the Test-Time Training (TTT) layer, an RNN that updates hidden states during testing, to model trajectories in the form of DT. We introduce a unified framework, called Diffusion-Refined Decision TTT (DRDT3), to achieve performance beyond DT models. Specifically, we propose the Decision TTT (DT3) module, which harnesses the sequence modelling strengths of both self-attention and the TTT layer to capture recent contextual information and make coarse action predictions. DRDT3 iteratively refines the coarse action predictions through the generative diffusion model, progressively moving closer to the optimal actions. We further integrate DT3 with the diffusion model using a unified optimization objective. With experiments on multiple tasks in the D4RL benchmark, our DT3 model without diffusion refinement demonstrates improved performance over standard DT, while DRDT3 further achieves superior results compared to state-of-the-art DT-based and offline RL methods.},
  archive      = {J_TMLR},
  author       = {Xingshuai Huang and Di Wu and Benoit Boulet},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DRDT3: Diffusion-refined decision test-time training model},
  url          = {https://openreview.net/forum?id=I6zjLhIzgh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification in retrieval augmented question answering. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JLkgI0h7wy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieval augmented Question Answering (QA) helps QA models overcome knowledge gaps by incorporating retrieved evidence, typically a set of passages, alongside the question at test time. Previous studies show that this approach improves QA performance and reduces hallucinations, without, however, assessing whether the retrieved passages are indeed useful at answering correctly. In this work, we propose to quantify the uncertainty of a QA model via estimating the utility of the passages it is provided with. We train a lightweight neural model to predict passage utility for a target QA model and show that while simple information theoretic metrics can predict answer correctness up to a certain extent, our approach efficiently approximates or outperforms more expensive sampling-based methods.},
  archive      = {J_TMLR},
  author       = {Laura Perez-Beltrachini and Mirella Lapata},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncertainty quantification in retrieval augmented question answering},
  url          = {https://openreview.net/forum?id=JLkgI0h7wy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Amdahl’s law for LLMs: A throughput-centric analysis of extreme LLM quantization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JtrQJJQYpP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of 1-bit large language models (LLMs) has sparked significant interest, promising substantial efficiency gains through extreme quantization. However, these benefits are inherently limited by the portion of the model that can be quantized. Specifically, 1-bit quantization typically targets only the projection layers, while the attention mechanisms remain in higher precision, potentially creating significant throughput bottlenecks. To address this, we present an adaptation of Amdahl's Law specifically tailored to the LLMs, offering a quantitative framework for understanding the throughput limits of extreme quantization. Our analysis reveals how improvements in quantization can deliver substantial throughput gains, but only to the extent that they address critical throughput-constrained sections of the model. Through extensive experiments across diverse model architectures and hardware platforms, we highlight key trade-offs and performance ceilings, providing a roadmap for future research aimed at maximizing LLM throughput through more holistic quantization strategies.},
  archive      = {J_TMLR},
  author       = {Jinendra Malekar and Ramtin Zand},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Amdahl’s law for LLMs: A throughput-centric analysis of extreme LLM quantization},
  url          = {https://openreview.net/forum?id=JtrQJJQYpP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous imagination: Closed-loop decomposition of visual-to-textual conversion in visual reasoning for multimodal large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MI4yIBLprs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under pure textual modality, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning tasks by decomposing them into simpler sub-problems. However, Multimodal Large Language Models (MLLMs) still struggle with some seemingly straightforward visual tasks, such as counting and solving jigsaw puzzles. We argue that these tasks challenge the ability of {\it visual-to-textual conversion}, where MLLMs convert visual information perceived from the input scene, to textual information for further reasoning and generating the answer. If the complexity of the visual input is beyond the perceptual capability of the MLLMs, without decomposing this conversion process, simply scaling inference-time reasoning cannot solve the task because it repeatedly encounters the same perceptual bottleneck. We propose an approach, {\it autonomous imagination}, to enable MLLMs to iteratively modify visual inputs (e.g. isolating objects, rearranging puzzle pieces) into intermediate visual states, decomposing visual-to-textual conversion into closed-loop visual modification steps. We show that, without any retraining, MLLMs can now solve tasks initially beyond their perceptual capability, highlighting that closed-loop visual modification can be an effective way of decomposing the visual reasoning task into solvable substeps. Our code and data are released at https://future-item.github.io/autoimagine-site/.},
  archive      = {J_TMLR},
  author       = {Jingming Liu and Yumeng Li and Boyuan Xiao and Yichang Jian and Ziang Qin and Tianjia Shao and Yao-Xiang Ding and Kun Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Autonomous imagination: Closed-loop decomposition of visual-to-textual conversion in visual reasoning for multimodal large language models},
  url          = {https://openreview.net/forum?id=MI4yIBLprs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A noise-corrected langevin algorithm and sampling by half-denoising. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QGtXn5GtfK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Langevin algorithm is a classic method for sampling from a given pdf in a real space. In its basic version, it only requires knowledge of the gradient of the log-density, also called the score function. However, in deep learning, it is often easier to learn the so-called "noisy-data score function", i.e. the gradient of the log-density of noisy data, more precisely when Gaussian noise is added to the data. Such an estimate is biased and complicates the use of the Langevin method. Here, we propose a noise-corrected version of the Langevin algorithm, where the bias due to noisy data is removed, at least regarding first-order terms. Unlike diffusion models, our algorithm only needs to know the noisy-data score function for one single noise level. We further propose a simple special case which has an interesting intuitive interpretation of iteratively adding noise the data and then attempting to remove half of that noise.},
  archive      = {J_TMLR},
  author       = {Aapo Hyvarinen},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A noise-corrected langevin algorithm and sampling by half-denoising},
  url          = {https://openreview.net/forum?id=QGtXn5GtfK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RouteFinder: Towards foundation models for vehicle routing problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QzGLoaOPiY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces RouteFinder, a comprehensive foundation model framework to tackle different Vehicle Routing Problem (VRP) variants. Our core idea is that a foundation model for VRPs should be able to represent variants by treating each as a subset of a generalized problem equipped with different attributes. We propose a unified VRP environment capable of efficiently handling any combination of these attributes. The RouteFinder model leverages a modern transformer-based encoder and global attribute embeddings to improve task representation. Additionally, we introduce two reinforcement learning techniques to enhance multi-task performance: mixed batch training, which enables training on different variants at once, and multi-variant reward normalization to balance different reward scales. Finally, we propose efficient adapter layers that enable fine-tuning for new variants with unseen attributes. Extensive experiments on 48 VRP variants show RouteFinder outperforms recent state-of-the-art learning methods. Our code is publicly available at https://github.com/ai4co/routefinder.},
  archive      = {J_TMLR},
  author       = {Federico Berto and Chuanbo Hua and Nayeli Gast Zepeda and André Hottung and Niels Wouda and Leon Lan and Junyoung Park and Kevin Tierney and Jinkyoo Park},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RouteFinder: Towards foundation models for vehicle routing problems},
  url          = {https://openreview.net/forum?id=QzGLoaOPiY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M4GN: Mesh-based multi-segment hierarchical graph network for dynamic simulations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=R3vDbqWa1v'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mesh-based graph neural networks (GNNs) have become effective surrogates for PDE simulations, yet their deep message passing incurs high cost and over‑smoothing on large, long‑range meshes; hierarchical GNNs shorten propagation paths but still face two key obstacles: (i) building coarse graphs that respect mesh topology, geometry, and physical discontinuities, and (ii) maintaining fine-scale accuracy without sacrificing the speed gained from coarsening. We tackle these challenges with M4GN—a three‑tier, segment‑centric hierarchical network. M4GN begins with a hybrid segmentation strategy that pairs a fast graph partitioner with a superpixel‑style refinement guided by modal‑decomposition features, producing contiguous segments of dynamically consistent nodes. These segments are encoded by a permutation‑invariant aggregator, avoiding the order sensitivity and quadratic cost of aggregation approaches used in prior works. The resulting information bridges a micro‑level GNN—which captures local dynamics—and a macro‑level transformer that reasons efficiently across segments, achieving a principled balance between accuracy and efficiency. Evaluated on multiple representative benchmark datasets, M4GN improves prediction accuracy by up to 56\% while achieving up to 22\% faster inference than state‑of‑the‑art baselines.},
  archive      = {J_TMLR},
  author       = {Bo Lei and Victor M Castillo and Yeping Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {M4GN: Mesh-based multi-segment hierarchical graph network for dynamic simulations},
  url          = {https://openreview.net/forum?id=R3vDbqWa1v},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoNNect: Connectivity-based regularization for structural pruning of neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RIZCe7BuEp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning encompasses a range of techniques aimed at increasing the sparsity of neural networks (NNs). These techniques can generally be framed as minimizing a loss function subject to an $L_0$ norm constraint. This paper introduces CoNNect, a novel differentiable regularizer for sparse NN training that ensures connectivity between input and output layers. We prove that CoNNect approximates $L_0$ regularization, while preserving essential network structure and preventing the emergence of fragmented or poorly connected subnetworks. Moreover, CoNNect is easily integrated within established structural pruning strategies. Numerical experiments demonstrate that CoNNect can improve classical pruning strategies and enhance state-of-the-art one-shot pruners, such as DepGraph and LLM-pruner.},
  archive      = {J_TMLR},
  author       = {Christian P.C. Franssen and Jinyang Jiang and Yijie Peng and Bernd Heidergott},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CoNNect: Connectivity-based regularization for structural pruning of neural networks},
  url          = {https://openreview.net/forum?id=RIZCe7BuEp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to rank with top-$K$ fairness. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SSPCc39XvO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness in ranking models is crucial, as disparities in exposure can disproportionately affect protected groups. Most fairness-aware ranking systems focus on ensuring comparable average exposure for groups across the entire ranked list, which may not fully address real-world concerns. For example, when a ranking model is used for allocating resources among candidates or disaster hotspots, decision-makers often prioritize only the top-$K$ ranked items, while the ranking beyond top-$K$ becomes less relevant. In this paper, we propose a list-wise learning-to-rank framework that addresses the issues of inequalities in top-$K$ rankings at training time. Specifically, we propose a top-$K$ exposure disparity measure that extends the classic exposure disparity metric in a ranked list. We then learn a ranker to balance relevance and fairness in top-$K$ rankings. Since direct top-$K$ selection is computationally expensive for a large number of items, we transform the non-differentiable selection process into a differentiable objective function and develop efficient stochastic optimization algorithms to achieve both high accuracy and sufficient fairness. Extensive experiments demonstrate that our method outperforms existing methods.},
  archive      = {J_TMLR},
  author       = {Boyang Zhang and Quanqi Hu and Mingxuan Sun and Qihang Lin and Tianbao Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning to rank with top-$K$ fairness},
  url          = {https://openreview.net/forum?id=SSPCc39XvO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solution augmentation for ARC problems using GFlowNet: A probabilistic exploration approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ULCOhBgGzy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the core challenges in building general reasoning systems lies in generating diverse, human-aligned solution trajectories—different yet valid paths by which a problem can be solved. Prior approaches often rely on handcrafted templates, rule-based augmentations, or human demonstrations, which are limited in scalability and stylistic diversity. To address this, we explore the use of Generative Flow Networks (GFlowNets) for automated solution augmentation in reasoning tasks. We propose a framework that learns to generate diverse reasoning trajectories with probabilities proportional to their quality, guided by a human-inspired reward function and a novel geometric forward policy. This enables the generation of multiple plausible solution paths without relying on manual supervision. Moreover, our method supports efficient test-time augmentation from input-output examples alone, without access to ground-truth programs or external demonstrations—making it suitable for zero-shot settings. We evaluate our framework on the Abstraction and Reasoning Corpus (ARC-AGI), a benchmark designed to test compositional and abstract reasoning. Our results show that GFlowNets can effectively explore the space of valid reasoning processes, producing a variety of plausible reasoning trajectories, similar to how different individuals might solve the same problem using different intermediate steps. These trajectories are generated at scale-over 100k per task in under an hour, and follow a logarithmic yield trend, enabling practical tradeoffs between augmentation volume and novelty. Furthermore, fine-tuning a large language model (LLaMA 3.1 Instruct 8B) on these synthetic trajectories leads to a 28.6% improvement in reasoning accuracy on ARC tasks, demonstrating the downstream utility of our method. These findings suggest that GFlowNets offer a promising foundation for modeling structured reasoning in automated trajectory generation. Our code is here: https://github.com/GIST-DSLab/GFN_to_ARC},
  archive      = {J_TMLR},
  author       = {Sanha Hwang and Seungpil Lee and Sejin Kim and Sundong Kim},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Solution augmentation for ARC problems using GFlowNet: A probabilistic exploration approach},
  url          = {https://openreview.net/forum?id=ULCOhBgGzy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wolf: Dense video captioning with a world summarization framework. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Z1dH7hao7p'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Wolf, a WOrLd summarization Framework for accurate video captioning. Wolf is an automated captioning framework that adopts a mixture-of-experts approach, leveraging complementary strengths of Vision Language Models (VLMs). By utilizing both image and video models, our framework captures different levels of information and summarizes them efficiently. Our approach can be applied to enhance video understanding, auto-labeling, and captioning. To evaluate caption quality, we introduce CapScore, an LLM-based metric to assess the similarity and quality of generated captions compared to the ground truth captions. We further build four human-annotated datasets in three domains: autonomous driving, general scenes, and robotics, to facilitate comprehensive comparisons. We show that Wolf achieves superior captioning performance compared to state-of-the-art approaches from the research community (VILA1.5, CogAgent) and commercial solutions (Gemini-Pro-1.5, GPT-4V). For instance, in comparison with GPT-4V, Wolf improves CapScore (caption quality) by 55.6% and CapScore (caption similarity) by 77.4% on challenging driving videos. Finally, we establish a benchmark for video captioning and introduce a leaderboard, aiming to accelerate advancements in video understanding, captioning, and data alignment.},
  archive      = {J_TMLR},
  author       = {Boyi Li and Ligeng Zhu and Ran Tian and Shuhan Tan and Yuxiao Chen and Yao Lu and Yin Cui and Sushant Veer and Max Ehrlich and Jonah Philion and Xinshuo Weng and Fuzhao Xue and Linxi Fan and Yuke Zhu and Jan Kautz and Andrew Tao and Ming-Yu Liu and Sanja Fidler and Boris Ivanovic and Trevor Darrell and Jitendra Malik and Song Han and Marco Pavone},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wolf: Dense video captioning with a world summarization framework},
  url          = {https://openreview.net/forum?id=Z1dH7hao7p},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeedleBench: Evaluating LLM retrieval and reasoning across varying information densities. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cEvmIKsRw0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of large language models to handle long-context information plays a crucial role across various real-world applications. Existing methods for evaluating long-context abilities often rely either on real-world long texts, making it difficult to exclude the influence of models' inherent knowledge, or introduce large amounts of irrelevant filler content to artificially reach target lengths, reducing the relevance and effectiveness of assessments. To address these limitations, we introduce NeedleBench, a comprehensive synthetic framework designed to assess retrieval and reasoning performance in bilingual long-context tasks with adaptive context lengths (e.g., 32k, 128k, and beyond). NeedleBench systematically embeds key data points at varying depths to rigorously test models' capabilities in diverse settings. Tasks within NeedleBench are categorized into two distinct scenarios: information-sparse, characterized by minimal relevant details embedded within extensive irrelevant text to simulate simpler real-world retrieval tasks; and information-dense, implemented as the Ancestral Trace Challenge, where relevant information is continuously distributed throughout the context to simulate more complex real-world reasoning tasks. Our experiments show that, while recent reasoning models such as Deepseek-R1 and OpenAI's o3 have demonstrated strong performance on mathematical reasoning benchmarks, they still struggle to generalize their reasoning abilities and perform poorly on our information-dense tasks, frequently encountering difficulties with continuous retrieval and reasoning even at relatively shorter context lengths.Furthermore, we identify and characterize a phenomenon termed `under-thinking', wherein models prematurely conclude their reasoning processes despite the availability of relevant information. NeedleBench thus provides critical insights and targeted evaluation tools essential for understanding and improving the long-context capabilities of LLMs. All codes and resources are publicly available at https://github.com/open-compass/opencompass.},
  archive      = {J_TMLR},
  author       = {Mo Li and Songyang Zhang and Taolin Zhang and Haodong Duan and Yunxin Liu and Kai Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {NeedleBench: Evaluating LLM retrieval and reasoning across varying information densities},
  url          = {https://openreview.net/forum?id=cEvmIKsRw0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaGFN: Exploring distant modes with adapted metadynamics for continuous GFlowNets. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dtyNeemB7A'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Flow Networks (GFlowNets) are a class of generative models that sample objects in proportion to a specified reward function through a learned policy. They can be trained either on-policy or off-policy, needing a balance between exploration and exploitation for fast convergence to a target distribution. While exploration strategies for discrete GFlowNets have been studied, exploration in the continuous case remains to be investigated, despite the potential for novel exploration algorithms due to the local connectedness of continuous domains. Here, we introduce Adapted Metadynamics, a variant of metadynamics that can be applied to arbitrary black-box reward functions on continuous domains. We use Adapted Metadynamics as an exploration strategy for continuous GFlowNets. We show several continuous domains where the resulting algorithm, MetaGFN, accelerates convergence to the target distribution and discovers more distant reward modes than previous off-policy exploration strategies used for training GFlowNets.},
  archive      = {J_TMLR},
  author       = {Dominic Phillips and Flaviu Cipcigan},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MetaGFN: Exploring distant modes with adapted metadynamics for continuous GFlowNets},
  url          = {https://openreview.net/forum?id=dtyNeemB7A},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simplifying knowledge transfer in pretrained models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=eQ9AVtDaP3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained models are ubiquitous in the current deep learning landscape, offering strong results on a broad range of tasks. Recent works have shown that models differing in various design choices exhibit categorically diverse generalization behavior, resulting in one model grasping distinct data-specific insights unavailable to the other. In this paper, we propose to leverage large publicly available model repositories as an auxiliary source of model improvements. We introduce a data partitioning strategy where pretrained models autonomously adopt either the role of a student, seeking knowledge, or that of a teacher, imparting knowledge. Experiments across various tasks demonstrate the effectiveness of our proposed approach. In image classification, we improved the performance of ViT-B by approximately 1.4\% through bidirectional knowledge transfer with ViT-T. For semantic segmentation, our method boosted all evaluation metrics by enabling knowledge transfer both within and across backbone architectures. In video saliency prediction, our approach achieved a new state-of-the-art. We further extend our approach to knowledge transfer between multiple models, leading to considerable performance improvements for all model participants.},
  archive      = {J_TMLR},
  author       = {Siddharth Jain and Shyamgopal Karthik and Vineet Gandhi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simplifying knowledge transfer in pretrained models},
  url          = {https://openreview.net/forum?id=eQ9AVtDaP3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hallucination detection on a budget: Efficient bayesian estimation of semantic entropy. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=j2N2RuNdbC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting whether an LLM hallucinates is an important research challenge. One promising way of doing so is to estimate the semantic entropy (Farquhar et al., 2024) of the distribution of generated sequences. We propose a new algorithm for doing that, with two main advantages. First, due to us taking the Bayesian approach, we achieve a much better quality of semantic entropy estimates for a given budget of samples from the LLM. Second, we are able to tune the number of samples adaptively so that `harder' contexts receive more samples. We demonstrate empirically that our approach systematically beats the baselines, requiring only 53% of samples used by Farquhar et al. (2024) to achieve the same quality of hallucination detection as measured by AUROC. Moreover, quite counterintuitively, our estimator is useful even with just one sample from the LLM.},
  archive      = {J_TMLR},
  author       = {Kamil Ciosek and Nicolò Felicioni and Sina Ghiassian},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hallucination detection on a budget: Efficient bayesian estimation of semantic entropy},
  url          = {https://openreview.net/forum?id=j2N2RuNdbC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing vision backbones for dense prediction with dense attentive probing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=neMAx4uBlh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paradigm of pretraining a backbone on a large set of (often unlabeled) images has gained popularity. The quality of the resulting features is commonly measured by freezing the backbone and training different task heads on top of it. However, current evaluations cover only classifications of whole images or require complex dense task heads which introduce a large number of parameters and add their own inductive biases. In this work, we propose dense attentive probing, a parameter-efficient readout method for dense prediction on arbitrary backbones – independent of the size and resolution of their feature volume. To this end, we extend cross-attention with distance-based masks of learnable sizes. We employ this method to evaluate 18 common backbones on dense predictions tasks in three dimensions: instance awareness, local semantics and spatial understanding. We find that DINOv2 outperforms all other backbones tested – including those supervised with masks and language – across all three task categories. Furthermore, our analysis suggests that self-supervised pretraining tends to yield features that separate object instances better than vision-language models. Code is available at http://eckerlab.org/code/deap.},
  archive      = {J_TMLR},
  author       = {Timo Lüddecke and Alexander S. Ecker},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Characterizing vision backbones for dense prediction with dense attentive probing},
  url          = {https://openreview.net/forum?id=neMAx4uBlh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global optimization algorithm through high-resolution sampling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=r3VEA1AWY5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an optimization algorithm that can identify a global minimum of a potentially nonconvex smooth function with high probability, assuming the Gibbs measure of the potential satisfies a logarithmic Sobolev inequality. Our contribution is twofold: on the one hand we propose said global optimization method, which is built on an oracle sampling algorithm producing arbitrarily accurate samples from a given Gibbs measure. On the other hand, we propose a new sampling algorithm, drawing inspiration from both overdamped and underdamped Langevin dynamics, as well as from the high-resolution differential equation known for its acceleration in deterministic settings. While the focus of the paper is primarily theoretical, we demonstrate the effectiveness of our algorithms on the Rastrigin function, where it outperforms recent approaches.},
  archive      = {J_TMLR},
  author       = {Daniel Cortild and Claire Delplancke and Nadia Oudjane and Juan Peypouquet},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Global optimization algorithm through high-resolution sampling},
  url          = {https://openreview.net/forum?id=r3VEA1AWY5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mutual information perspective on multiple latent variable generative models for positive view generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uaj8ZL2PtK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image generation, Multiple Latent Variable Generative Models (MLVGMs) employ multiple latent variables to gradually shape the final images, from global characteristics to finer and local details (e.g., StyleGAN, NVAE), emerging as powerful tools for diverse applications. Yet their generative dynamics remain only empirically observed, without a systematic understanding of each latent variable's impact. In this work, we propose a novel framework that quantifies the contribution of each latent variable using Mutual Information (MI) as a metric. Our analysis reveals that current MLVGMs often underutilize some latent variables, and provides actionable insights for their use in downstream applications. With this foundation, we introduce a method for generating synthetic data for Self-Supervised Contrastive Representation Learning (SSCRL). By leveraging the hierarchical and disentangled variables of MLVGMs, our approach produces diverse and semantically meaningful views without the need for real image data. Additionally, we introduce a Continuous Sampling (CS) strategy, where the generator dynamically creates new samples during SSCRL training, greatly increasing data variability. Our comprehensive experiments demonstrate the effectiveness of these contributions, showing that MLVGMs' generated views compete on par with or even surpass views generated from real data. This work establishes a principled approach to understanding and exploiting MLVGMs, advancing both generative modeling and self-supervised learning. Code and pre-trained models at: https://github.com/SerezD/mi_ml_gen},
  archive      = {J_TMLR},
  author       = {Dario Serez and Marco Cristani and Alessio Del Bue and Vittorio Murino and Pietro Morerio},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A mutual information perspective on multiple latent variable generative models for positive view generation},
  url          = {https://openreview.net/forum?id=uaj8ZL2PtK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond instance consistency: Investigating view diversity in self-supervised learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=urWCU3YMA0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) conventionally relies on the instance consistency paradigm, assuming that different views of the same image can be treated as positive pairs. However, this assumption breaks down for non-iconic data, where different views may contain distinct objects or semantic information. In this paper, we investigate the effectiveness of SSL when instance consistency is not guaranteed. Through extensive ablation studies, we demonstrate that SSL can still learn meaningful representations even when positive pairs lack strict instance consistency. Furthermore, our analysis further reveals that increasing view diversity, by enforcing zero overlapping or using smaller crop scales, can enhance downstream performance on classification and dense prediction tasks. However, excessive diversity is found to reduce effectiveness, suggesting an optimal range for view diversity. To quantify this, we adopt the Earth Mover’s Distance (EMD) as an estimator to measure mutual information between views, finding that moderate EMD values correlate with improved SSL learning, providing insights for future SSL framework design. We validate our findings across a range of settings, highlighting their robustness and applicability on diverse data sources.},
  archive      = {J_TMLR},
  author       = {Huaiyuan Qin and Muli Yang and Siyuan Hu and Peng Hu and Yu Zhang and Chen Gong and Hongyuan Zhu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond instance consistency: Investigating view diversity in self-supervised learning},
  url          = {https://openreview.net/forum?id=urWCU3YMA0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wasserstein convergence of score-based generative models under semiconvexity and discontinuous gradients. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vS9iVRB7XF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score-based Generative Models (SGMs) approximate a data distribution by perturbing it with Gaussian noise and subsequently denoising it via a learned reverse diffusion process. These models excel at modeling complex data distributions and generating diverse samples, achieving state-of-the-art performance across domains such as computer vision, audio generation, reinforcement learning, and computational biology. Despite their empirical success, existing Wasserstein-2 convergence analysis typically assume strong regularity conditions--such as smoothness or strict log-concavity of the data distribution--that are rarely satisfied in practice. In this work, we establish the first non-asymptotic Wasserstein-2 convergence guarantees for SGMs targeting semiconvex distributions with potentially discontinuous gradients. Our upper bounds are explicit and sharp in key parameters, achieving optimal dependence of $O(\sqrt{d})$ on the data dimension $d$ and convergence rate of order one. The framework accommodates a wide class of practically relevant distributions, including symmetric modified half-normal distributions, Gaussian mixtures, double-well potentials, and elastic net potentials. By leveraging semiconvexity without requiring smoothness assumptions on the potential such as differentiability, our results substantially broaden the theoretical foundations of SGMs, bridging the gap between empirical success and rigorous guarantees in non-smooth, complex data regimes.},
  archive      = {J_TMLR},
  author       = {Stefano Bruno and Sotirios Sabanis},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wasserstein convergence of score-based generative models under semiconvexity and discontinuous gradients},
  url          = {https://openreview.net/forum?id=vS9iVRB7XF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Taxonomy, opportunities, and challenges of representation engineering for large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2U1KIfmaU9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation Engineering (RepE) is a novel paradigm for controlling the behavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune the model, RepE directly manipulates the model's internal representations. As a result, it may offer more effective, interpretable, data-efficient, and flexible control over models' behavior. We present the first comprehensive survey of RepE for LLMs, reviewing the rapidly growing literature to address key questions: What RepE methods exist and how do they differ? For what concepts and problems has RepE been applied? What are the strengths and weaknesses of RepE compared to other methods? To answer these, we propose a unified framework describing RepE as a pipeline comprising representation identification, operationalization, and control. We posit that while RepE methods offer significant potential, challenges remain, including managing multiple concepts, ensuring reliability, and preserving models' performance. Towards improving RepE, we identify opportunities for experimental and methodological improvements and construct a guide for best practices.},
  archive      = {J_TMLR},
  author       = {Jan Wehner and Sahar Abdelnabi and Daniel Chee Hian Tan and David Krueger and Mario Fritz},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Taxonomy, opportunities, and challenges of representation engineering for large language models},
  url          = {https://openreview.net/forum?id=2U1KIfmaU9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local distribution-based adaptive oversampling for imbalanced regression. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6qYTR9iJdm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced regression occurs when continuous target variables have skewed distributions, creating sparse regions that are difficult for machine learning models to predict accurately. This issue particularly affects neural networks, which often struggle with imbalanced data. While class imbalance in classification has been extensively studied, imbalanced regression remains relatively unexplored, with few effective solutions. Existing approaches often rely on arbitrary thresholds to categorize samples as rare or frequent, ignoring the continuous nature of target distributions. These methods can produce synthetic samples that fail to improve model performance and may discard valuable information through undersampling. To address these limitations, we propose LDAO (Local Distribution-based Adaptive Oversampling), a novel data-level approach that avoids categorizing individual samples as rare or frequent. Instead, LDAO learns the global distribution structure by decomposing the dataset into a mixture of local distributions, each preserving its statistical characteristics. LDAO then models and samples from each local distribution independently before merging them into a balanced training set. LDAO achieves a balanced representation across the entire target range while preserving the inherent statistical structure within each local distribution. In extensive evaluations on 45 imbalanced datasets, LDAO outperforms state-of-the-art oversampling methods on both frequent and rare target values, demonstrating its effectiveness for addressing the challenge of imbalanced regression.},
  archive      = {J_TMLR},
  author       = {Shayan Alahyari and Mike Domaratzki},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Local distribution-based adaptive oversampling for imbalanced regression},
  url          = {https://openreview.net/forum?id=6qYTR9iJdm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized orders of magnitude for scalable, parallel, high-dynamic-range computation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SUuzb0SOGu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many domains, from deep learning to finance, require compounding real numbers over long sequences, often leading to catastrophic numerical underflow or overflow. We introduce generalized orders of magnitude (GOOMs), a principled extension of traditional orders of magnitude that incorporates floating-point numbers as a special case, and which in practice enables stable computation over significantly larger dynamic ranges of real numbers than previously possible. We implement GOOMs, along with an efficient custom parallel prefix scan, to support native execution on parallel hardware such as GPUs. We demonstrate that our implementation of GOOMs outperforms traditional approaches with three representative experiments, all of which were previously considered impractical or impossible, and now become possible and practical: (1) compounding real matrix products {\em far} beyond standard floating-point limits; (2) estimating spectra of Lyapunov exponents in parallel, {\em orders of magnitude faster} than with previous methods, applying a novel selective-resetting method to prevent state colinearity; and (3) capturing long-range dependencies in deep recurrent neural networks with {\em non-diagonal recurrent states, computed in parallel via a prefix scan, without requiring any form of stabilization}. Our results show that our implementation of GOOMs, combined with efficient parallel scanning, offers a scalable and numerically robust alternative to conventional floating-point numbers for high-dynamic-range applications.},
  archive      = {J_TMLR},
  author       = {Franz A. Heinsen and Leo Kozachkov},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalized orders of magnitude for scalable, parallel, high-dynamic-range computation},
  url          = {https://openreview.net/forum?id=SUuzb0SOGu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLMs can learn self-restraint through iterative self-reflection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SvKPfchVKX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to be deployed safely, Large Language Models (LLMs) must be capable of dynamically adapting their behavior based on their level of knowledge and uncertainty associated with specific topics. This adaptive behavior, which we refer to as self-restraint, is non-trivial to teach since it depends on the internal knowledge of an LLM. By default, LLMs are trained to maximize the next token likelihood, which does not teach the model to modulate its answer based on its level of uncertainty. In order to learn self-restraint, we devise a utility function that can encourage the model to produce responses only when its level of confidence is above a user-specified target accuracy $\rho^*$. This utility function can be used to score generation of different length and abstention. To optimize this function, we introduce ReSearch, a process of ``self-reflection'' consisting of iterative self-prompting and self-evaluation. We use the ReSearch algorithm to generate synthetic data on which we finetune our models. ReSearch elegantly incorporates the ability to abstain by augmenting the samples generated by the model during the search procedure with an answer expressing abstention. Compared to their original versions, our resulting models generate fewer hallucinations overall at no additional inference cost, for both known and unknown topics, as the model learns to selectively restrain itself. In addition, we show that our iterative search is more efficient as a function of tokens than naive search. Finally, we show that by modifying the target accuracy $\rho^*$, our trained models exhibit different behaviors.},
  archive      = {J_TMLR},
  author       = {Alexandre Piché and Aristides Milios and Dzmitry Bahdanau and Christopher Pal},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LLMs can learn self-restraint through iterative self-reflection},
  url          = {https://openreview.net/forum?id=SvKPfchVKX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmenting text and learning their rewards for improved RLHF in language model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YhLlqD0UNi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning from human feedback (RLHF) has been widely adopted to align language models (LMs) with human preference. Previous RLHF works typically take a bandit formulation, which, though intuitive, ignores the sequential nature of LM generation and can suffer from the sparse reward issue. While recent works propose dense token-level RLHF, treating each token as an action may be oversubtle to proper reward assignment. In this paper, we seek to get the best of both by training and utilizing a segment-level reward model, which assigns a reward to each semantically complete text segment that spans over a short sequence of tokens. For reward learning, our method allows dynamic text segmentation and compatibility with standard sequence-preference datasets. For effective RL-based LM training against segment reward, we generalize the classical scalar bandit reward normalizers into location-aware normalizer functions and interpolate the segment reward for further densification. Our method performs competitively on three popular RLHF benchmarks for LM policy: AlpacaEval 2.0, Arena-Hard, and MT-Bench. Ablation studies are conducted to further demonstrate our method.},
  archive      = {J_TMLR},
  author       = {Yueqin Yin and Shentao Yang and Yujia Xie and Ziyi Yang and Yuting Sun and Hany Hassan Awadalla and Weizhu Chen and Mingyuan Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Segmenting text and learning their rewards for improved RLHF in language model},
  url          = {https://openreview.net/forum?id=YhLlqD0UNi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VColRL: Learn to solve the vertex coloring problem using reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=a9AQRieTne'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Vertex Coloring Problem (VCP) is a fundamental NP-hard problem with applications in wireless networks, compiler design, scheduling, etc. We present VColRL, a deep reinforcement learning (DRL) framework that learns to color graphs quickly by leveraging a reduction-based approach that progressively reduces the graph at each step. The core novelty of VColRL is a new Markov Decision Process (MDP) formulation tailored for VCP that assigns colors to multiple vertices at each step, incorporates a rollback mechanism to revert all conflicting vertices to the undecided state, and employs a reward function designed to minimize the highest-indexed color used. Experiments on synthetic and benchmark graphs show that VColRL improves color usage over optimization solvers and prior learning-based methods, remains competitive with search-based heuristics and metaheuristics, and achieves fast runtime, while generalizing well to diverse graph families despite being trained only on synthetic graphs from a single family.},
  archive      = {J_TMLR},
  author       = {Abhinav Anand and Subrahmanya Swamy Peruru and Amitangshu Pal},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {VColRL: Learn to solve the vertex coloring problem using reinforcement learning},
  url          = {https://openreview.net/forum?id=a9AQRieTne},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curvature diversity-driven deformation and domain alignment for point cloud. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ePXWnH7rGk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation is crucial for point cloud learning due to geometric variations across different generation methods and sensors. To tackle this challenge, we propose Curvature Diversity-Driven Nuclear-Norm Wasserstein Domain Alignment (CDND). We first introduce a Curvature Diversity-driven Deformation Reconstruction (CurvRec) task, enabling the model to extract salient features from semantically rich regions of a given point cloud. We then propose a theoretical framework for Deformation-based Nuclear-norm Wasserstein Discrepancy (D-NWD), extending the Nuclear-norm Wasserstein Discrepancy to original and deformed samples. Our theoretical analysis demonstrates that D-NWD is effective for any deformation method. Empirical experiment results show that our CDND achieves state-of-the-art performance by a noticeable margin over existing approaches.},
  archive      = {J_TMLR},
  author       = {Mengxi Wu and Hao Huang and Yi Fang and Mohammad Rostami},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Curvature diversity-driven deformation and domain alignment for point cloud},
  url          = {https://openreview.net/forum?id=ePXWnH7rGk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simple and nearly-optimal sampling for rank-1 tensor completion via gauss-jordan. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ggAphfUt1J'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the sample and computational complexity of the rank-1 tensor completion problem in $\otimes_{i=1}^{N} \mathbb{R}^{d}$, given a uniformly sampled subset of entries. We present a characterization of the problem which reduces to solving a pair of random linear systems. For example, when $N$ is a constant, we prove it requires no more than $m = O(d^2 \log d)$ samples and runtime $O(md^2)$. Moreover, we show that a broad class of algorithms require $\Omega(d\log d)$ samples, even under higher rank scenarios. In contrast, existing upper bounds on the sample complexity are at least as large as $d^{1.5} \mu^{\Omega(1)} \log^{\Omega(1)} d$, where $\mu$ can be $\Theta(d)$ in the worst case. Prior work obtained these looser guarantees in higher rank versions of our problem, and tend to involve more complicated algorithms.},
  archive      = {J_TMLR},
  author       = {Alejandro Gomez-Leos and Oscar Lopez},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simple and nearly-optimal sampling for rank-1 tensor completion via gauss-jordan},
  url          = {https://openreview.net/forum?id=ggAphfUt1J},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain graph anomaly detection via test-time training with homophily-guided self-supervision. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sB3LqdOlNb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Anomaly Detection (GAD) has demonstrated great effectiveness in identifying unusual patterns within graph-structured data. However, while labeled anomalies are often scarce in emerging applications, existing supervised GAD approaches are either ineffective or not applicable when moved across graph domains due to distribution shifts and heterogeneous feature spaces. To address these challenges, we present GADT3, a novel test-time training framework for cross-domain GAD. GADT3 combines supervised and self-supervised learning during training while adapting to a new domain during test time using only self-supervised learning by leveraging a homophily-based affinity score that captures domain-invariant properties of anomalies. Our framework introduces four key innovations to cross-domain GAD: an effective self-supervision scheme, an attention-based mechanism that dynamically learns edge importance weights during message passing, domain-specific encoders for handling heterogeneous features, and class-aware regularization to address imbalance. Experiments across multiple cross-domain settings demonstrate that GADT3 significantly outperforms existing approaches, achieving average improvements of over 8.2\% in AUROC and AUPRC compared to the best competing model.},
  archive      = {J_TMLR},
  author       = {Delaram Pirhayatifard and Arlei Silva},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cross-domain graph anomaly detection via test-time training with homophily-guided self-supervision},
  url          = {https://openreview.net/forum?id=sB3LqdOlNb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The accuracy cost of weakness: A theoretical analysis of fixed-segment weak labeling for events in time. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tTw8wXBQ18'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate labels are critical for deriving robust machine learning models. Labels are used to train supervised learning models and to evaluate most machine learning paradigms. In this paper, we model the accuracy and cost of a common weak labeling process where annotators assign presence or absence labels to fixed-length data segments for a given event class. The annotator labels a segment as "present" if it sufficiently covers an event from that class, e.g., a birdsong sound event in audio data. We analyze how the segment length affects the label accuracy and the required number of annotations, and compare this fixed-length labeling approach with an oracle method that uses the true event activations to construct the segments. Furthermore, we quantify the gap between these methods and verify that in most realistic scenarios the oracle method is better than the fixed-length labeling method in both accuracy and cost. Our findings provide a theoretical justification for adaptive weak labeling strategies that mimic the oracle process, and a foundation for optimizing weak labeling processes in sequence labeling tasks.},
  archive      = {J_TMLR},
  author       = {John Martinsson and Olof Mogren and Tuomas Virtanen and Maria Sandsten},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The accuracy cost of weakness: A theoretical analysis of fixed-segment weak labeling for events in time},
  url          = {https://openreview.net/forum?id=tTw8wXBQ18},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
