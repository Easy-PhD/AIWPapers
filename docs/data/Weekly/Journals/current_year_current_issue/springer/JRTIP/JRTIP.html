<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JRTIP</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jrtip">JRTIP - 4</h2>
<ul>
<li><details>
<summary>
(2025). YOLO-GSD: A real-time pedestrian detection algorithm based on YOLOv8 in dense environments. <em>JRTIP</em>, <em>22</em>(6), 1-15. (<a href='https://doi.org/10.1007/s11554-025-01771-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With recent advancements in vision intelligence, pedestrian detection in autonomous driving has become a critical research focus within computer vision. Dense pedestrian scenarios present significant challenges from multi-scale variations and occlusions. Traditional detection methods can be used for pedestrian detection in ordinary scenarios, but they face challenges, such as high computational complexity and overly sophisticated models, that prevent effective deployment on mobile devices like in-vehicle cameras, along with unsatisfactory detection accuracy under multi-scale pedestrian scenarios and heavy occlusion conditions. To address these challenges, this paper proposes YOLO-GSD, an improved lightweight real-time pedestrian detection algorithm based on YOLOv8. The algorithm first introduces a dedicated detection layer specifically designed for small-scale targets. It then incorporates lightweight Ghost convolution and designs a DG-C2f module by integrating Ghost convolution and Dynamic Convolution, aiming to reduce computational complexity while enhancing the algorithm’s multi-scale feature fusion capability. Additionally, it employs the ultra-lightweight DySample upsampler for efficient feature reconstruction and integrates the SEAM attention mechanism to improve occlusion-aware detection. Finally, WIoUv3 is used to replace the CIoU loss function, which improves the generalization ability and overall performance of the algorithm. Experimental results demonstrate mAP@0.5 scores of 90.7% on the WiderPerson dataset (1.4% higher than the baseline) and 86.5% on the CrowdHuman dataset (2.2% improvement). The algorithm’s parameter count is reduced to 6.24 M, its FLOPs are lowered to 22.7 G, and its FPS is increased to 106.6. In addition, a homogeneous training comparison was conducted on the small-object dataset RSOD, demonstrating the advantages of YOLO-GSD in small-object detection. Therefore, the YOLO-GSD algorithm proposed in this paper is suitable for real-time pedestrian detection in multi-scale and occlusion scenarios on mobile platforms with limited computational resources.},
  archive      = {J_JRTIP},
  author       = {Zhang, Zuhao and Li, Weiwei and Luo, Lin},
  doi          = {10.1007/s11554-025-01771-2},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {YOLO-GSD: A real-time pedestrian detection algorithm based on YOLOv8 in dense environments},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TOE-YOLO: Accurate and efficient detection of tiny objects in UAV imagery. <em>JRTIP</em>, <em>22</em>(6), 1-19. (<a href='https://doi.org/10.1007/s11554-025-01770-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing models achieve high accuracy in small object detection but often overlook the rotational and dense characteristics of targets. To address this, we propose an improved YOLO11-based model specifically designed for detecting dense and rotated small objects in UAV scenarios. To better extract features from rotated targets, we design a C3k2–ARC module that enhances the model’s rotational detection capability. In addition, we introduce the CL-Concat feature fusion module, which combines traditional concatenation with channel and spatial attention, significantly improving the quality of multi-scale feature fusion. The experimental results demonstrate that the proposed method achieves notable performance improvements across multiple public benchmark data sets. Compared with the advanced YOLO11n model, our approach achieves gains of 1.6% on VISDRONE, 1.4% on UAVDT, 0.2% on CARPK, and 0.1% on UAVROD, further validating its effectiveness across diverse UAV detection scenarios.},
  archive      = {J_JRTIP},
  author       = {Yan, Haimin and Kong, Xiangbo and Shimada, Tomoyasu and Tomiyama, Hiroyuki},
  doi          = {10.1007/s11554-025-01770-3},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1-19},
  shortjournal = {J. Real-Time Image Process.},
  title        = {TOE-YOLO: Accurate and efficient detection of tiny objects in UAV imagery},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast and effective helmet detection in construction sites based on PEG-YOLOv10m. <em>JRTIP</em>, <em>22</em>(6), 1-12. (<a href='https://doi.org/10.1007/s11554-025-01774-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Helmet detection is essential in engineering measurements, ensuring compliance with safety standards and providing real-time data for project management on construction sites. This paper introduces PEG-YOLOv10m, a fast and efficient detection method designed to enhance speed while preserving accuracy. The PEG module replaces the PSA attention mechanism in the backbone network, refining region-of-interest focus, optimizing feature selection, and boosting detection precision. In the neck network, redundant feature layers are removed, simplifying the model and further accelerating detection. To boost the model's effectiveness on hard samples and achieve better training outcomes, a slide loss function is used instead of binary cross-entropy loss for classification. Experimental results show that PEG-YOLOv10m achieves a mAP50 of 93.7% with 313 FPS on the SHWD dataset. Compared to YOLOv10m, PEG-YOLOv10m reduces parameters by 12%, raises mAP50 by 0.5%, and increases detection speed by 8%.},
  archive      = {J_JRTIP},
  author       = {Liu, Peilin and Fang, Yinfeng and Zhang, Xuguang},
  doi          = {10.1007/s11554-025-01774-z},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Fast and effective helmet detection in construction sites based on PEG-YOLOv10m},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Yolo-based power-efficient object detection on edge devices for USVs. <em>JRTIP</em>, <em>22</em>(6), 1. (<a href='https://doi.org/10.1007/s11554-025-01776-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRTIP},
  author       = {Mela, Jose Luis and Sánchez, Carlos García},
  doi          = {10.1007/s11554-025-01776-x},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Correction: Yolo-based power-efficient object detection on edge devices for USVs},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
