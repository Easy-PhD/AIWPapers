<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJDAR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijdar">IJDAR - 11</h2>
<ul>
<li><details>
<summary>
(2025). Neurosymbolic information extraction from transactional documents. <em>IJDAR</em>, <em>28</em>(3), 475-485. (<a href='https://doi.org/10.1007/s10032-025-00530-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a neurosymbolic framework for information extraction from documents, evaluated on transactional documents. We introduce a schema-based approach that integrates symbolic validation methods to enable more effective zero-shot output and knowledge distillation. The methodology uses language models to generate candidate extractions, which are then filtered through syntactic-, task-, and domain-level validation to ensure adherence to domain-specific arithmetic constraints. Our contributions include a comprehensive schema for transactional documents, relabeled datasets, and an approach for generating high-quality labels for knowledge distillation. Experimental results demonstrate significant improvements in $$F_1$$ -scores and accuracy, highlighting the effectiveness of neurosymbolic validation in transactional document processing.},
  archive      = {J_IJDAR},
  author       = {Hemmer, Arthur and Coustaty, Mickaël and Bartolo, Nicola and Ogier, Jean-Marc},
  doi          = {10.1007/s10032-025-00530-0},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {475-485},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Neurosymbolic information extraction from transactional documents},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SlimDoc: Lightweight distillation of document transformer models. <em>IJDAR</em>, <em>28</em>(3), 457-473. (<a href='https://doi.org/10.1007/s10032-025-00542-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying state-of-the-art document understanding models remains resource-intensive and impractical in many real-world scenarios, particularly where labeled data is scarce and computational budgets are constrained. To address these challenges, this work proposes a novel approach towards parameter-efficient document understanding models capable of adapting to specific tasks and document types without the need for labeled data. Specifically, we propose an approach coined SlimDoc to distill multimodal document transformer encoder models into smaller student models, using internal signals at different training stages, followed by external signals. Our approach is inspired by TinyBERT and adapted to the domain of document understanding transformers. We demonstrate SlimDoc to outperform both a single-stage distillation and a direct fine-tuning of the student. Experimental results across six document understanding datasets demonstrate our approach’s effectiveness: Our distilled student models achieve on average $$93.0\%$$ of the teacher’s performance, while the fine-tuned students achieve $$87.0\%$$ of the teacher’s performance. Without requiring any labeled data, we create a compact student which achieves $$96.0\%$$ of the performance of its supervised-distilled counterpart and $$86.2\%$$ of the performance of a supervised-fine-tuned teacher model. We demonstrate our distillation approach to pick up on document geometry and to be effective on the two popular document understanding models LiLT and LayoutLMv3. Our implementation and training data is available at https://github.com/marcel-lamott/SlimDoc .},
  archive      = {J_IJDAR},
  author       = {Lamott, Marcel and Shakir, Muhammad Armaghan and Ulges, Adrian and Weweler, Yves-Noel and Shafait, Faisal},
  doi          = {10.1007/s10032-025-00542-w},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {457-473},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {SlimDoc: Lightweight distillation of document transformer models},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing music score analysis with monte carlo dropout: A probabilistic approach to staff-region detection. <em>IJDAR</em>, <em>28</em>(3), 441-456. (<a href='https://doi.org/10.1007/s10032-025-00541-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Layout Analysis (LA) is a critical process for detecting and isolating different components within a scanned document, allowing for more straightforward and precise processing of each part independently. In Optical Music Recognition (OMR), LA is essential for identifying and extracting music staves, which enables effective music notation recognition and processing. While the literature includes several studies exploring methods for staff retrieval, there remains room for improvement in terms of robustness and accuracy. In this work, we introduce a methodology that integrates Monte Carlo Dropout (MCD) into a neural network model in order to improve reliability in staff retrieval from scanned sheet music. Our approach leverages multiple non-deterministic predictions using standard dropout layers during inference and aggregates them through pixel-level combination policies. We extend the MCD technique, originally designed for classification and regression tasks using averaged predictions, to the LA task and introduce new combination strategies: maximum and voting criteria. Experiments on three diverse music score corpora, including printed and handwritten documents, demonstrated the effectiveness of our approach. The averaging and voting (with 25% and 50% of votes) criteria reduced the relative error by 63.6% compared to the baseline and achieved a 32.1% improvement over state-of-the-art methods. Our methodology notably enhanced detection accuracy without requiring modifications to the neural architecture, especially at the edges of staves, where conventional models tend to show higher error rates.},
  archive      = {J_IJDAR},
  author       = {Oliva-Bulpitt, Samuel B. and Martinez-Esteso, Juan P. and Galan-Cuenca, Alejandro and Castellanos, Francisco J. and Gallego, Antonio Javier},
  doi          = {10.1007/s10032-025-00541-x},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {441-456},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Enhancing music score analysis with monte carlo dropout: A probabilistic approach to staff-region detection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level style control for chinese handwriting generation. <em>IJDAR</em>, <em>28</em>(3), 429-440. (<a href='https://doi.org/10.1007/s10032-025-00533-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of artificial intelligence-generated content (AIGC) has made significant progress in handwriting generation, including complex scripts such as Chinese. Previous offline Chinese handwriting generation methods focus on isolated character image generation, without addressing the task of offline Chinese handwritten text line generation. This paper proposed a novel multi-level style control method for generating Chinese handwritten text lines, which consists of two key steps: style-controlled character image generation and text-line layout generation. For style-controlled character image generation, we implement a pre-training method utilizing multi-modal radical-level contrastive loss to align image features with radical embeddings in encoders. Additionally, a multi-level style representation control is achieved through multi-modal feature aggregation. We also propose a style-consistent text-line layout generation scheme by using prompt engineering with a large language model. Experimental results demonstrate that our method achieves comparable or even better performance in character image generation compared to diffusion model-based methods, while also delivering faster generation speeds. By incorporating text-line layout generation, the generated text-line samples can be effectively used for training handwriting recognition models.},
  archive      = {J_IJDAR},
  author       = {Yao, Gang and Peng, Liangrui and Li, Zhiyu and zhao, Tianqi and Zhao, Kemeng and Ding, Ning and Tao, Yao},
  doi          = {10.1007/s10032-025-00533-x},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {429-440},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Multi-level style control for chinese handwriting generation},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight cross-attention-based HookNet for historical handwritten document layout analysis. <em>IJDAR</em>, <em>28</em>(3), 409-427. (<a href='https://doi.org/10.1007/s10032-025-00519-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten document layout analysis is a fundamental step in digitizing scanned ancient documents for further processing (e.g., optical character recognition). So far, single branch-based fully convolutional networks (FCN) dominate this field. However, we contend that this task faces significant challenges, particularly in layouts with only semantic differences rather than differences in character appearance. For example, in the U-DIADS-Bib dataset, distinguishing between the main text and chapter headings can confuse existing FCNs due to the presence of similar distractors. It is, thus, critical to integrate layout structural information into the network learning processes. Moreover, the single branch-based networks have an upper limit of constructing document contextual relationships. Therefore, we propose a novel two-branch framework, called lightweight cross-attention-based HookNet (Light-HookNet), for handwritten document layout segmentation. The layout contextual information is connected and interacted with the cross-attention mechanism between a global context branch and a local target branch. This allows to achieve information enhancement inside the target branch and information exchange across both branches. Additionally, the reduced network parameters and computational costs make the proposed method both lightweight and efficient. Extensive experimental results and performance comparisons with state-of-the-art approaches on the newly proposed U-DIADS-Bib dataset and the popular DIVA-HisDB dataset demonstrate the superiority and effectiveness of the proposed method.},
  archive      = {J_IJDAR},
  author       = {Wu, Fei and Seuret, Mathias and Mayr, Martin and Kordon, Florian and Zöllner, Jochen and Wind, Sebastian and Maier, Andreas and Christlein, Vincent},
  doi          = {10.1007/s10032-025-00519-9},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {409-427},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Lightweight cross-attention-based HookNet for historical handwritten document layout analysis},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A low-intervention dual-loop iterative process for efficient dataset expansion and classification in palm leaf manuscript analysis. <em>IJDAR</em>, <em>28</em>(3), 391-408. (<a href='https://doi.org/10.1007/s10032-025-00532-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palm leaf manuscripts, celebrated for their historical and cultural significance, pose considerable challenges for digital analysis due to their intricate script structures and age-related degradation. Existing studies frequently highlight the difficulties in assembling realistic datasets and generating accurate ground truth labels, as interpreting ancient scripts requires extensive human expertise and substantial computational resources. To address these challenges, this paper proposes a low-intervention, dual-loop iterative framework designed to efficiently expand datasets and enhance glyph classification in palm leaf manuscript analysis. The framework comprises two primary stages: preprocessing and classification. In the preprocessing stage, state-of-the-art methods are employed for text-line detection, glyph extraction, and synthetic data generation, significantly reducing reliance on manual annotation. The classification stage introduces tailored enhancements to vision transformers (ViTs), incorporating CNN-based feature extraction, Dynamic Stride Shift Patch Tokenization (DS-SPT), and Multi-Scale Locality Self-Attention (MS-LSA). These methods enhance the model’s flexibility and adaptability to the unique characteristics of palm leaf datasets. Moreover, the classification phase facilitates the generation of labels for newly extracted and generated datasets, employing an iterative process to progressively refine model performance. In our experiments, we evaluate the framework using both the ICFHR 2018 palm leaf collection and newly extracted datasets. The experimental results demonstrate improvements in classifying complex glyphs, providing a scalable and efficient solution for low-resource historical document analysis. This framework establishes a foundation for advanced research in the preservation and study of ancient scripts, enabling long-term accessibility and conservation of these cultural heritage documents with minimal human intervention.},
  archive      = {J_IJDAR},
  author       = {Thuon, Nimol and Du, Jun and Theang, Panhapin and Thuon, Ratana},
  doi          = {10.1007/s10032-025-00532-y},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {391-408},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {A low-intervention dual-loop iterative process for efficient dataset expansion and classification in palm leaf manuscript analysis},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The PARES database: Information extraction over historical parish records. <em>IJDAR</em>, <em>28</em>(3), 377-389. (<a href='https://doi.org/10.1007/s10032-025-00531-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Historical census records convey information that is key to perform genealogical research and demographic studies. Given the large number of documents of this type that exist, it is crucial to research methods that allow the automatic extraction of information from this type of document. In this work, we present a new corpus of this kind, comprising 535 historical census tables from French archives. Alongside this dataset, we have assessed three different baseline methods for information extraction. The first two methods employ a traditional sequential approach, where table rows are detected before extracting information. The third baseline uses an end-to-end model that directly extracts information from the table images without prior row detection. Our results demonstrate the effectiveness of all three baselines in tackling the information extraction task.},
  archive      = {J_IJDAR},
  author       = {Andrés, José and Wall, Casey and Tarride, Solène and Coustaty, Mickaël and Toselli, Alejandro H. and Vidal, Enrique},
  doi          = {10.1007/s10032-025-00531-z},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {377-389},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {The PARES database: Information extraction over historical parish records},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tabular context-aware optical character recognition and tabular data reconstruction for historical records. <em>IJDAR</em>, <em>28</em>(3), 357-376. (<a href='https://doi.org/10.1007/s10032-025-00543-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digitizing historical tabular records is essential for preserving and analyzing valuable data across various fields, but it presents challenges due to complex layouts, mixed text types, and degraded document quality. This paper introduces a comprehensive framework to address these issues through three key contributions. First, it presents UoS_Data_Rescue, a novel dataset of 1,113 historical logbooks with over 594,000 annotated text cells, designed to handle the complexities of handwritten entries, aging artifacts, and intricate layouts. Second, it proposes a novel context-aware text extraction approach (TrOCR-ctx) to reduce cascading errors during table digitization. Third, it proposes an enhanced end-to-end OCR pipeline that integrates TrOCR-ctx with ByT5, combining OCR and post-OCR correction in a unified training framework. This framework enables the system to produce both the raw OCR output and a corrected version in a single pass, improving recognition accuracy, particularly for multilingual and degraded text, within complex table digitization tasks. The model achieves superior performance with a 0.049 word error rate and a 0.035 character error rate, outperforming existing methods by up to 41% in OCR tasks and 10.74% in table reconstruction tasks. This framework offers a robust solution for large-scale digitization of tabular documents, extending its applications beyond climate records to other domains requiring structured document preservation. The dataset and implementation are available as open-source resources.},
  archive      = {J_IJDAR},
  author       = {Singh, Loitongbam Gyanendro and Middleton, Stuart E.},
  doi          = {10.1007/s10032-025-00543-9},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {357-376},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Tabular context-aware optical character recognition and tabular data reconstruction for historical records},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Character recognition for greek squeezes. <em>IJDAR</em>, <em>28</em>(3), 345-356. (<a href='https://doi.org/10.1007/s10032-025-00540-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Squeezes are three-dimensional paper impressions made of stone inscriptions, a form of historical document where digital processing methods have received relatively little study to date. This paper reports on experiments in text recognition, working with a collection of approximately 30,000 squeezes originally collected from museums and archaeological sites in classical Greece. It explores a number of complementary strategies for character recognition in this medium, with the aim of establishing a strong benchmark in performance. Based on these experiments, we identify a recognition pipeline based on scene text recognition algorithms combined with line-based recognition that achieves a character error rate around 13%.},
  archive      = {J_IJDAR},
  author       = {Howe, Nicholas R. and Chang, Feiran and Falbo, Isabella and Brown, Tajhini and Hershkowitz, Aaron},
  doi          = {10.1007/s10032-025-00540-y},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {345-356},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Character recognition for greek squeezes},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On self-supervision in historical handwritten document segmentation. <em>IJDAR</em>, <em>28</em>(3), 329-344. (<a href='https://doi.org/10.1007/s10032-025-00538-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Historical document analysis plays a crucial role in understanding and preserving our past. However, this task is often hindered by challenges such as limited annotated training data and the diverse nature of historical handwritten documents. In this paper, we explore the potential of self-supervised learning (SSL) in historical document analysis, with a particular focus on historical handwritten document segmentation, to overcome the need for extensive annotated data while enhancing efficiency and robustness. We present an overview of SSL methods suitable for historical document analysis and discuss their potential applications and benefits. Furthermore, we present an approach for SSL in the document domain, considering various setups, augmentations, and resolutions. We also provide experimental results that demonstrate its feasibility and effectiveness. Our findings indicate that most document segmentation tasks can be effectively addressed using SSL features, highlighting the potential of SSL to advance historical document analysis and pave the way for more efficient and robust document processing workflows.},
  archive      = {J_IJDAR},
  author       = {Baloun, Josef and Prantl, Martin and Lenc, Ladislav and Martínek, Jiří and Král, Pavel},
  doi          = {10.1007/s10032-025-00538-6},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {329-344},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {On self-supervision in historical handwritten document segmentation},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Special issue on advanced topics in document analysis (2025 ICDAR-IJDAR journal track). <em>IJDAR</em>, <em>28</em>(3), 327-328. (<a href='https://doi.org/10.1007/s10032-025-00551-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJDAR},
  author       = {Lopresti, Daniel and Karatzas, Dimosthenis and Yin, Xu-Cheng},
  doi          = {10.1007/s10032-025-00551-9},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {9},
  number       = {3},
  pages        = {327-328},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Special issue on advanced topics in document analysis (2025 ICDAR-IJDAR journal track)},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
