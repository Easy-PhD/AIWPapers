<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ail">AIL - 9</h2>
<ul>
<li><details>
<summary>
(2025). Legal sentence boundary detection using hybrid deep learning and statistical models. <em>AIL</em>, <em>33</em>(2), 519-549. (<a href='https://doi.org/10.1007/s10506-024-09394-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentence boundary detection (SBD) represents an important first step in natural language processing since accurately identifying sentence boundaries significantly impacts downstream applications. Nevertheless, detecting sentence boundaries within legal texts poses a unique and challenging problem due to their distinct structural and linguistic features. Our approach utilizes deep learning models to leverage delimiter and surrounding context information as input, enabling precise detection of sentence boundaries in English legal texts. We evaluate various deep learning models, including domain-specific transformer models like LegalBERT and CaseLawBERT. To assess the efficacy of our deep learning models, we compare them with a state-of-the-art domain-specific statistical conditional random field (CRF) model. After considering model size, F1-score, and inference time, we identify the Convolutional Neural Network Model (CNN) as the top-performing deep learning model. To further enhance performance, we integrate the features of the CNN model into the subsequent CRF model, creating a hybrid architecture that combines the strengths of both models. Our experiments demonstrate that the hybrid model outperforms the baseline model, achieving a 4% improvement in the F1-score. Additional experiments showcase the superiority of the hybrid model over SBD open-source libraries when confronted with an out-of-domain test set. These findings underscore the importance of efficient SBD in legal texts and emphasize the advantages of employing deep learning models and hybrid architectures to achieve optimal performance.},
  archive      = {J_AIL},
  author       = {Sheik, Reshma and Ganta, Sneha Rao and Nirmala, S. Jaya},
  doi          = {10.1007/s10506-024-09394-x},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {519-549},
  shortjournal = {Artif. Intell. Law},
  title        = {Legal sentence boundary detection using hybrid deep learning and statistical models},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative user study of human predictions in algorithm-supported recidivism risk assessment. <em>AIL</em>, <em>33</em>(2), 471-517. (<a href='https://doi.org/10.1007/s10506-024-09393-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the effects of using an algorithm-based risk assessment instrument (RAI) to support the prediction of risk of violent recidivism upon release. The instrument we used is a machine learning version of RiskCanvi used by the Justice Department of Catalonia, Spain. It was hypothesized that people can improve their performance on defining the risk of recidivism when assisted with a RAI. Also, that professionals can perform better than non-experts on the domain. Participants had to predict whether a person who has been released from prison will commit a new crime leading to re-incarceration, within the next two years. This user study is done with (1) general participants from diverse backgrounds recruited through a crowdsourcing platform, (2) targeted participants who are students and practitioners of data science, criminology, or social work and professionals who work with RisCanvi. We also run focus groups with participants of the targeted study, including people who use RisCanvi in a professional capacity, to interpret the quantitative results. Among other findings, we observe that algorithmic support systematically leads to more accurate predictions from all participants, but that statistically significant gains are only seen in the performance of targeted participants with respect to that of crowdsourced participants. Among other comments, professional participants indicate that they would not foresee using a fully-automated system in criminal risk assessment, but do consider it valuable for training, standardization, and to fine-tune or double-check their predictions on particularly difficult cases. We found that the revised prediction by using a RAI increases the performance of all groups, while professionals show a better performance in general. And, a RAI can be considered for extending professional capacities and skills along their careers.},
  archive      = {J_AIL},
  author       = {Portela, Manuel and Castillo, Carlos and Tolan, Songül and Karimi-Haghighi, Marzieh and Pueyo, Antonio Andres},
  doi          = {10.1007/s10506-024-09393-y},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {471-517},
  shortjournal = {Artif. Intell. Law},
  title        = {A comparative user study of human predictions in algorithm-supported recidivism risk assessment},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Agents preserving privacy on intelligent transportation systems according to EU law. <em>AIL</em>, <em>33</em>(2), 437-470. (<a href='https://doi.org/10.1007/s10506-024-09391-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Transportation Systems are expected to automate how parking slots are booked by trucks. The intrinsic dynamic nature of this problem, the need of explanations and the inclusion of private data justify an agent-based solution. Agents solving this problem act with a Believe Desire Intentions reasoning, and are implemented with JASON. Privacy of trucks becomes protected sharing a list of parkings ordered by preference. Furthermore, the process of assigning parking slots takes into account legal requirements on breaks and driving time limits. Finally, the agent simulations use the distances, the number of trucks and parkings corresponding to the proportions of the current European Union data. The performance of the proposed solution is tested in these simulations with three different distances against an alternative with complete knowledge. The difference in efficiency, the number of illegal breaks and the traveled distances are measured in them. Comparing the results, we can conclude that the nonprivate alternative is slightly better in performance while both alternatives do not produce illegal breaks. In this way the simulations show that the proposed privacy protection does not impose a relevant handicap in efficiency.},
  archive      = {J_AIL},
  author       = {Carbo, Javier and Pedraza, Juanita and Molina, Jose M.},
  doi          = {10.1007/s10506-024-09391-0},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {437-470},
  shortjournal = {Artif. Intell. Law},
  title        = {Agents preserving privacy on intelligent transportation systems according to EU law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The challenge of open-texture in law. <em>AIL</em>, <em>33</em>(2), 405-435. (<a href='https://doi.org/10.1007/s10506-024-09390-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important challenge when creating automatically processable laws concerns open-textured terms. The ability to measure open-texture can assist in determining the feasibility of encoding regulation and where additional legal information is required to properly assess a legal issue or dispute. In this article, we propose a novel conceptualisation of open-texture with the aim of determining the extent of open-textured terms in legal documents. We conceptualise open-texture as a lever whose state is impacted by three types of forces: internal forces (the words within the text themselves), external forces (the resources brought to challenge the definition of words), and lateral forces (the merit of such challenges). We tested part of this conceptualisation with 26 participants by investigating agreement in paired annotators. Five key findings emerged. First, agreement on which words are open-texture within a legal text is possible and statistically significant. Second, agreement is even high at an average inter-rater reliability of 0.7 (Cohen’s kappa). Third, when there is agreement on the words, agreement on the Open-Texture Value is high. Fourth, there is a dependence between the Open-Texture Value and reasons invoked behind open-texture. Fifth, involving only four annotators can yield similar results compared to involving twenty more when it comes to only flagging clauses containing open-texture. We conclude the article by discussing limitations of our experiment and which remaining questions in real life cases are still outstanding.},
  archive      = {J_AIL},
  author       = {Guitton, Clement and Tamò-Larrieux, Aurelia and Mayer, Simon and van Dijck, Gijs},
  doi          = {10.1007/s10506-024-09390-1},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {405-435},
  shortjournal = {Artif. Intell. Law},
  title        = {The challenge of open-texture in law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Code is law: How COMPAS affects the way the judiciary handles the risk of recidivism. <em>AIL</em>, <em>33</em>(2), 383-404. (<a href='https://doi.org/10.1007/s10506-024-09389-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Judges in multiple US states, such as New York, Pennsylvania, Wisconsin, California, and Florida, receive a prediction of defendants’ recidivism risk, generated by the COMPAS algorithm. If judges act on these predictions, they implicitly delegate normative decisions to proprietary software, even beyond the previously documented race and age biases. Using the ProPublica dataset, we demonstrate that COMPAS predictions favor jailing over release. COMPAS is biased against defendants. We show that this bias can largely be removed. Our proposed correction increases overall accuracy, and attenuates anti-black and anti-young bias. However, it also slightly increases the risk that defendants are released who commit a new crime before tried. We argue that this normative decision should not be buried in the code. The tradeoff between the interests of innocent defendants and of future victims should not only be made transparent. The algorithm should be changed such that the legislator and the courts do make this choice.},
  archive      = {J_AIL},
  author       = {Engel, Christoph and Linhardt, Lorenz and Schubert, Marcel},
  doi          = {10.1007/s10506-024-09389-8},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {383-404},
  shortjournal = {Artif. Intell. Law},
  title        = {Code is law: How COMPAS affects the way the judiciary handles the risk of recidivism},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining prompt-based language models and weak supervision for labeling named entity recognition on legal documents. <em>AIL</em>, <em>33</em>(2), 361-381. (<a href='https://doi.org/10.1007/s10506-023-09388-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is a very relevant task for text information retrieval in natural language processing (NLP) problems. Most recent state-of-the-art NER methods require humans to annotate and provide useful data for model training. However, using human power to identify, circumscribe and label entities manually can be very expensive in terms of time, money, and effort. This paper investigates the use of prompt-based language models (OpenAI’s GPT-3) and weak supervision in the legal domain. We apply both strategies as alternative approaches to the traditional human-based annotation method, relying on computer power instead human effort for labeling, and subsequently compare model performance between computer and human-generated data. We also introduce combinations of all three mentioned methods (prompt-based, weak supervision, and human annotation), aiming to find ways to maintain high model efficiency and low annotation costs. We showed that, despite human labeling still maintaining better overall performance results, the alternative strategies and their combinations presented themselves as valid options, displaying positive results and similar model scores at lower costs. Final results demonstrate preservation of human-trained models scores averaging 74.0% for GPT-3, 95.6% for weak supervision, 90.7% for GPT + weak supervision combination, and 83.9% for GPT + 30% human-labeling combination.},
  archive      = {J_AIL},
  author       = {Oliveira, Vitor and Nogueira, Gabriel and Faleiros, Thiago and Marcacini, Ricardo},
  doi          = {10.1007/s10506-023-09388-1},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {361-381},
  shortjournal = {Artif. Intell. Law},
  title        = {Combining prompt-based language models and weak supervision for labeling named entity recognition on legal documents},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiscoLQA: Zero-shot discourse-based legal question answering on european legislation. <em>AIL</em>, <em>33</em>(2), 323-359. (<a href='https://doi.org/10.1007/s10506-023-09387-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structures of discourse used by legal and ordinary languages share differences that foster technical issues when applying or fine-tuning general-purpose language models for open-domain question answering on legal resources. For example, longer sentences may be preferred in European laws (i.e., Brussels I bis Regulation EU 1215/2012) to reduce potential ambiguities and improve comprehensibility, distracting a language model trained on ordinary English. In this article, we investigate some mechanisms to isolate and capture the discursive patterns of legalese in order to perform zero-shot question answering, i.e., without training on legal documents. Specifically, we use pre-trained open-domain answer retrieval systems and study what happens when changing the type of information to consider for retrieval. Indeed, by selecting only the important parts of discourse (e.g., elementary units of discourse, EDU for short, or abstract representations of meaning, AMR for short), we should be able to help the answer retriever identify the elements of interest. Hence, with this paper, we publish Q4EU, a new evaluation dataset that includes more than 70 questions and 200 answers on 6 different European norms, and study what happens to a baseline system when only EDUs or AMRs are used during information retrieval. Our results show that the versions using EDUs are overall the best, leading to state-of-the-art F1, precision, NDCG and MRR scores.},
  archive      = {J_AIL},
  author       = {Sovrano, Francesco and Palmirani, Monica and Sapienza, Salvatore and Pistone, Vittoria},
  doi          = {10.1007/s10506-023-09387-2},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {323-359},
  shortjournal = {Artif. Intell. Law},
  title        = {DiscoLQA: Zero-shot discourse-based legal question answering on european legislation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). To test or not to test? a question of rational decision making in forensic biology. <em>AIL</em>, <em>33</em>(2), 293-322. (<a href='https://doi.org/10.1007/s10506-023-09386-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can the forensic scientist rationally justify performing a sequence of tests and analyses in a particular case? When is it worth performing a test or analysis on an item? Currently, there is a large void in logical frameworks for making rational decisions in forensic science. The aim of this paper is to fill this void by presenting a step-by-step guide on how to apply Bayesian decision theory to routine decision problems encountered by forensic scientists on performing or not performing a particular laboratory test or analysis. A decision-theoretic framework, composed of actions, states of nature, and utilities, models this problem, and an influence diagram translates its notions into a probabilistic graphical network. Within this framework, the expected value of information (EVOI) for the submission of an item to a particular test or analysis addresses the above questions. The development of a classical case example on whether to perform presumptive tests for blood before submitting the item for a DNA analysis illustrates the use of this model for source level questions in forensic biology (i.e., questions that ask whether a crime stain consisting of a particular body fluid comes from a particular person). We show how to construct an influence diagram for this example, and how sensitivity analyses lead to an optimal analytical sequence. The key idea is to show that such a Bayesian decisional approach provides a coherent framework for justifying the optimal analytical sequence for a particular case in forensic science.},
  archive      = {J_AIL},
  author       = {Gittelson, Simone and Taroni, Franco},
  doi          = {10.1007/s10506-023-09386-3},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {293-322},
  shortjournal = {Artif. Intell. Law},
  title        = {To test or not to test? a question of rational decision making in forensic biology},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing legal judgment summarization with integrated semantic and structural information. <em>AIL</em>, <em>33</em>(2), 271-292. (<a href='https://doi.org/10.1007/s10506-023-09381-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legal Judgment Summarization (LJS) can highly summarize legal judgment documents, improving judicial work efficiency in case retrieval and other occasions. Legal judgment documents are usually lengthy; however, most existing LJS methods are directly based on general text summarization models, which cannot handle long texts effectively. Additionally, due to the complex structural characteristics of legal judgment documents, some information may be lost by applying only one single kind of summarization model. To address these issues, we propose an integrated summarization method which leverages both semantic and structural information to improve the quality of LJS. Specifically, legal judgment documents are firstly segmented into three relatively short parts according to their specific structure. We propose an extractive summarization model named BSLT and an abstractive summarization model named LPGN by adopting Lawformer as the encoder. Lawformer is a new pre-trained language model for long legal documents, which specializes in capturing long-distance dependency and modeling legal semantic features. Then, we adopt different models to summarize the corresponding part regarding its structural characteristics. Finally, the obtained summaries are integrated to generate a high-quality summary involving semantic and structural information. We conduct comparative experiments to evaluate the performance of our model. The results show that our model outperforms the baseline model LEAD-3 by 14.78% on the mean ROUGE score, which demonstrates our method is effective in LJS and is prospected to be applied to assist other tasks in legal artificial intelligence.},
  archive      = {J_AIL},
  author       = {Dan, Jingpei and Hu, Weixuan and Wang, Yuming},
  doi          = {10.1007/s10506-023-09381-8},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {271-292},
  shortjournal = {Artif. Intell. Law},
  title        = {Enhancing legal judgment summarization with integrated semantic and structural information},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
