<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJCIS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijcis">IJCIS - 261</h2>
<ul>
<li><details>
<summary>
(2025). Image registration using the arithmetic optimization algorithm for robotic visual servoing. <em>IJCIS</em>, <em>18</em>(1), 1-12. (<a href='https://doi.org/10.1007/s44196-024-00612-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual servoing using image registration is a method employed in robotics to control the movement of a system using visual information. In this context, we propose a new intensity-based image registration algorithm (IBIR) that uses information derived from images acquired at different times or from different views to determine the parameters of the geometric transformations needed to align these images. The Arithmetic Optimization Algorithm (AOA) is used to optimize these parameters, minimizing the difference between the images to be aligned. The proposed algorithm, Intensity-Based Image Registration via Arithmetic Optimisation Algorithm (IBIRAOA), is robust to image data fluctuations and perturbations and can avoid local optima. Simulation results prove the importance and efficiency of the proposed algorithm in terms of computation time and similarity of aligned images compared to other methods based on various metaheuristics. In addition, our results confirm a significant improvement in the trajectory of the wheeled mobile robot, thus reinforcing the overall effectiveness of our method in practical navigation and robotic control applications.},
  archive      = {J_IJCIS},
  author       = {Kmich, Mohamed and Harrade, Inssaf and Karmouni, Hicham and Sayyouri, Mhamed and Askar, S. S. and Abouhawwash, Mohamed},
  doi          = {10.1007/s44196-024-00612-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Image registration using the arithmetic optimization algorithm for robotic visual servoing},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MORKO: A multi-objective Runge–Kutta optimizer for multi-domain optimization problems. <em>IJCIS</em>, <em>18</em>(1), 1-34. (<a href='https://doi.org/10.1007/s44196-024-00714-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current landscape, there is a rapid increase in the creation of new algorithms designed for specialized problem scenarios. The performance of these algorithms in unfamiliar or practical settings often remains untested. This paper presents a new development, the multi-objective Runge–Kutta optimizer (MORKO), which is built upon the principles of elitist non-dominated sorting and crowding distance. The goal is to achieve superior efficiency, diversity, and robustness in solutions. MORKO effectiveness is further enhanced by incorporating various strategies that maintain a balance between diversity and execution efficiency. This approach not only directs the search toward optimal regions but also ensures that the process does not become stagnant. The efficiency of MORKO is compared against renowned algorithms like the multi-objective marine predicator algorithm (MOMPA), multi-objective gradient-based optimizer (MOGBO), multi-objective evolutionary algorithm based on decomposition (MOEA/D), and non-dominated sorting genetic algorithm (NSGA-II) on several test benchmarks such as ZDT, DTLZ, constraint (CONSTR, TNK, SRN, BNH, OSY and KITA) and real-world engineering design (brushless DC wheel motor, safety isolating transformer, helical spring, two-bar truss, welded beam, disk brake, tool spindle and cantilever beam) problems. We used unique, non-overlapping performance metrics for this comparison and suggested a fresh correlation analysis technique for exploration. The MORKO algorithm outcomes were rigorously tested and confirmed using the non-parametric statistical evaluations. The MORKO algorithm proves to excel in deriving comprehensive and varied solutions for many tests and practical challenges, owing to its multifaceted features. Looking ahead, MORKO has potential applications in complex engineering and management tasks.},
  archive      = {J_IJCIS},
  author       = {Kalita, Kanak and Jangir, Pradeep and Pandya, Sundaram B. and Alzahrani, Ahmed Ibrahim and Alblehai, Fahad and Abualigah, Laith and Ezugwu, Absalom E.},
  doi          = {10.1007/s44196-024-00714-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MORKO: A multi-objective Runge–Kutta optimizer for multi-domain optimization problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective particle swarm optimization with integrated fireworks algorithm and size double archiving. <em>IJCIS</em>, <em>18</em>(1), 1-37. (<a href='https://doi.org/10.1007/s44196-024-00722-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-objective particle swarm optimization (MOPSO) is an optimization technique that mimics the foraging behavior of birds to solve difficult optimization problems. MOPSO is well known for its strong global search capability, which efficiently locates solutions that are close to the global optimum across a wide search domain. However, similar to many other optimization algorithms, the fast convergence property of MOPSO can occasionally lead to the population entering the local optimum too soon, obstructing researchers from investigating more efficient solutions. To address this challenge, the study proposes a novel framework that integrates the fireworks algorithm (FA) into MOPSO and establishes a size-double archiving mechanism to maintain population diversity. By preventing population homogenization, this mechanism promotes the retention of better solutions. Additionally, by fusing evolutionary data analysis with particle information, the study offers new individual optimal choices and adaptive parameter tuning to improve the algorithm’s robustness and adaptability and better manage the complexity of multi-objective optimization problems (MOPs). The suggested algorithm is compared with several existing MOPSOs and multi-objective evolutionary algorithms (MOEAs) in simulation experiments. Standard test problems like ZDT, UF, and DTLZ are used in the experiments. The new algorithm performs exceptionally well in terms of improving convergence and population diversity, as well as demonstrating significant competitiveness for solving MOPs.},
  archive      = {J_IJCIS},
  author       = {Zhang, Yansong and Liu, Yanmin and Zhang, Xiaoyan and Song, Qian and Ouyang, Aijia and Yang, Jie},
  doi          = {10.1007/s44196-024-00722-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multi-objective particle swarm optimization with integrated fireworks algorithm and size double archiving},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock market prediction based multi-attribute decision making model using picture fuzzy $${\hat{Z}}$$ -information. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-024-00664-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As demonstrated in the section above, the stock market place is a dynamic factor, which makes it possible for traders and investors to make good decisions based on the information acquired through accurate prediction. This research aims at improving the prediction of stock market by applying a new method to Multi-attribute Group Decision making (MAGDM). MAGDM goes through a cycle of evaluating and ranking several criteria hence enhancing the decision-making aspects further. To overcome the shortcomings of prior models, some EU and FU is incorporated by combining Zadeh’s $${\hat{Z}}$$ -numbers with Picture Fuzzy Sets (PFSs). This integration is to enhance the ability of the model to address completely unclear decisions utilizing the peculiarities of $${\hat{Z}}$$ -numbers. To compare decisions between decision-makers, we proposed picture fuzzy $${\hat{Z}}$$ -numbers (PF $${\hat{Z}}$$ N) and for their aggregation, introduced picture fuzzy weighted averaging, picture fuzzy ordered weighted averaging, picture fuzzy hybrid averaging, picture fuzzy weighted geometric, picture fuzzy ordered weighted geometric and picture fuzzy hybrid geometric operators based algebraic $${\mathfrak {T}}$$ -norm ( $${\mathfrak {T}}-N$$ ) and $${\mathfrak {T}}$$ -conorm ( $${\mathfrak {T}}-CNs$$ ) To verify the efficiency of our suggested technique, we compare these operators with the Combined Compromised Solution (CoCoSo) model focusing on the stock market analysis. Our results, therefore, show how these operators are important in improving decision making accuracy and precision in conditions of risk. This research laid down the basis for enhancing decision-making and dealing with uncertainty in different fields especially in the application of stock market prediction. The proposed methodology can be attributed to providing a systematic and a more efficient way of dealing with uncertainty which in one way or the other has an outcome of enhancing the credibility of the decision making process in the financial sector.},
  archive      = {J_IJCIS},
  author       = {Ashraf, Shahzaib and Khalid, Amna and Batool, Bushra and Tlija, Mehdi and Jana, Chiranjibe and Pamucar, Dragan},
  doi          = {10.1007/s44196-024-00664-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Stock market prediction based multi-attribute decision making model using picture fuzzy $${\hat{Z}}$$ -information},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid dynamic harris hawks optimized gated recurrent unit approach for breast cancer prediction. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-024-00712-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The breast cancer (BC) prediction is improved through the machine learning (ML) techniques. In this study, we develop an innovative forecasting framework called the Dynamic Harris Hawks Optimized Gated Recurrent Unit (DHH-GRU) for the prediction of BC. It combines the Gated Recurrent Unit (GRU) and Harris Hawks Optimization (HHO) methods. We gathered data and a training set that included the Wisconsin diagnostic BC (WDBC) dataset, which contains 569 patients with malignant and beginning cases. The collected data were pre-processed using min–max normalization, and important features were extracted by Fast Fourier transform (FFT) and the process of reducing the dimensionality with principal component analysis (PCA). Decimal scaling is employed to equalize the various feature effects. The proposed DHH-GRU technique incorporated the GRU for capturing sequential connections on temporal medical information, and the optimization process, DHH optimization, is utilized. The proposed method's effectiveness is compared and estimated with various existing techniques in terms of log-loss (0.06%), accuracy (98.05%), precision (98.09%), F1-score (98.28%), and recall (98.15%). The proposed DHH-GRU method has a more predictive ability with the sequential dependency in capturing GRU and DHH optimization’s combined behaviour of hunting. This method significantly improved the accuracy of BC prediction.},
  archive      = {J_IJCIS},
  author       = {Natarajan, Rajesh and Krishna, Sujatha and Gururaj, H. L. and Flammini, Francesco and Alfurhood, Badria Sulaiman and Kumar, C. M. Naveen},
  doi          = {10.1007/s44196-024-00712-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel hybrid dynamic harris hawks optimized gated recurrent unit approach for breast cancer prediction},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive ensemble learning model-based binary white shark optimizer for software defect classification. <em>IJCIS</em>, <em>18</em>(1), 1-51. (<a href='https://doi.org/10.1007/s44196-024-00716-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software dominates modern enterprises, affecting numerous functions. Software firms constantly experiment with new methodologies to define and assess software quality to stay competitive and ensure excellence. Software engineering uses fundamentals and cutting-edge technology to develop great software. In recent decades, Data-mining techniques and machine learning for classifying problematic software projects have emerged to improve software quality. ML approaches, especially ensemble learning models, are becoming fundamental to software engineers’ daily jobs. This work created a binary white shark optimizer (WSO) to optimize standard ensemble learning models. The objective is to identify the most suitable ensemble number for weak learners to maximize accuracy on benchmark datasets. The EM model uses 14 weak learners. Twenty-one experimental runs are performed on 15 software-defective module datasets. The optimized ensemble model outperforms the standard Ensemble learning model in AUC-ROC, Accuracy, Precision, Recall, F1-Score, and Specificity. The enhanced model has an average accuracy of 86%, compared to 76% for the standard ensemble model across all datasets. The optimized model outperformed the conventional ensemble for the same datasets, with an average AUC of 72% compared to 61% for the standard ensemble. The optimized model was more stable than the standard model, with an STD of 5.53E−03 vs 7.24E−02 for the ensemble model. The WSO optimization process strengthens and generalizes optimizeels. The study suggests that evolutionary metaheuristic approaches can enhance EM models’ accuracy, trustworthiness, and adaptability.},
  archive      = {J_IJCIS},
  author       = {Saraireh, Jameel and Agoyi, Mary and Kassaymeh, Sofian},
  doi          = {10.1007/s44196-024-00716-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-51},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Adaptive ensemble learning model-based binary white shark optimizer for software defect classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Properties and applications of neutrosophic burr XII distribution. <em>IJCIS</em>, <em>18</em>(1), 1-11. (<a href='https://doi.org/10.1007/s44196-024-00721-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Primarily, when the hazards function has intricate structures, the BrXII distribution is an established framework for lifetime data analysis. However, classical probability models are limited in the sense that they cannot measure or record the data in exactness fueling the notion of indeterminacy in data collection process. This study addresses this issue by proposing the idea of neutrosophic BrXII (NeS-BrXII) distribution. The primary objective is to study the statistical properties of the proposed model by providing explicit expressions of reliability properties, the expression of moments and generating function, expression of order statistics, mean residual life, mean inactivity time, stochastic ordering, income inequality measures, and entropy in neutrosophic realm. In addition, the neutrosophic model parameters are estimated using the principle of maximum-likelihood estimation. Further, the precision of these model estimates is verified via a simulation study of the proposed model. Applying the model on two real-world material sciences data sets reinforces its efficacy with the NeS-BrXII distribution proving to be more suitable for managing anomalies in neutrosophic surface analysis among other models.},
  archive      = {J_IJCIS},
  author       = {Al-Essa, Laila A. and Jamal, Farrukh and Shafiq, Shakaiba and Khan, Sadaf and Abbas, Qamer and Khan Sherwani, Rehan Ahmad and Aslam, Muhammad},
  doi          = {10.1007/s44196-024-00721-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Properties and applications of neutrosophic burr XII distribution},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-way crossed effects fuzzy panel linear regression model. <em>IJCIS</em>, <em>18</em>(1), 1-10. (<a href='https://doi.org/10.1007/s44196-024-00723-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last two decades, the panel data model has become a focus of applied research. While there are numerous proposals for soft regression models in the literature, only a few linear regression models have been proposed based on fuzzy panel data. However, these models have serious limitations. This study is an attempt to propose a kind of two-way fuzzy panel regression model with crossed effects, fuzzy responses and crisp predictors to overcome the shortcomings of these models in real applications. The corresponding parameter estimation is provided based on a three-step procedure. For this purpose, the conventional least absolute error technique is employed. Two real data sets are analyzed to investigate the fitting and predictive capabilities of the proposed fuzzy panel regression model. These real data applications demonstrate that our proposed model has good fitting accuracy and predictive performance.},
  archive      = {J_IJCIS},
  author       = {Hesamian, Gholamreza and Johannssen, Arne},
  doi          = {10.1007/s44196-024-00723-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A two-way crossed effects fuzzy panel linear regression model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: A model for estimating resiliency of AI-based classifiers defending against cyber attacks. <em>IJCIS</em>, <em>18</em>(1), 1. (<a href='https://doi.org/10.1007/s44196-024-00725-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Barik, Kousik and Misra, Sanjay and Fernandez-Sanz, Luis},
  doi          = {10.1007/s44196-024-00725-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: A model for estimating resiliency of AI-based classifiers defending against cyber attacks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel conflict deduction algorithm based on contradiction separation inference rule. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-024-00726-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated reasoning, a significant field within artificial intelligence, has attracted increased attention in recent years due to the rising demand for trustworthy AI. Binary resolution, among other inference rules, is crucial in automated reasoning of first-order logic, including the new conflict resolution method. Conflict resolution processes only two clauses in each deduction step and eliminates a complementary pairs of literals from input clauses. This paper proposes a contradiction separation conflict deduction (CSCD) method based on the contradiction separation rule to address these limitations. This novel resolution methodology, together with its automated reasoning theory and method, handles several clauses in each deduction step to seek for conflicts and generates learnt clauses through synergized deduction. Thus, the approach improves deduction by detecting conflicts more effectively, especially with lengthier input clauses. CSCD and conflict resolution are analyzed in detail, then how to create a practical CSCD algorithm and its implementation is summarized. We tested the CSCD algorithm to solve the CASC-26 problems and also applied it to the current leading ATP system (Eprover). Experimental results show that the CSCD deduction approach improves reasoning capability of conflict deduction method. Additionally, the Eprover with the proposed CSCD algorithm improves its performance and has solved various problems with a rating of 1 from the benchmark database TPTP.},
  archive      = {J_IJCIS},
  author       = {Guo, Hailin and Cao, Feng and Yi, Jianbing and Wu, Guanfeng and Li, Weicai},
  doi          = {10.1007/s44196-024-00726-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel conflict deduction algorithm based on contradiction separation inference rule},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing FACTS device placement using the fata morgana algorithm: A cost and power loss minimization approach in uncertain load scenario-based systems. <em>IJCIS</em>, <em>18</em>(1), 1-38. (<a href='https://doi.org/10.1007/s44196-024-00727-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, reliable power delivery and increasing demand are important issues in modern power systems. Flexible Alternating Current Transmission Systems (FACTS) devices are used to control transmission line parameters to increase power transfer and stability. Nevertheless, the problem of determining the optimal placement and sizing of these devices is still challenging, as the placement and sizing of the devices affects generation costs, power losses, voltage stability, and system reliability. This study proposes the Fata Morgana Algorithm (FATA), an optimization algorithm inspired by the natural process of mirage formation to optimize placement and sizing of FACTS devices in an IEEE 30 bus system with wind turbine integration. The FATA algorithm is evaluated against recently developed and improved optimization techniques, such as rime-ice formation phenomenon based Improved RIME (IRIME) Algorithm, Newton–Raphson-Based Optimization (NRBO), Resistance Capacitance Algorithm (RCA), Krill Optimization Algorithm (KOA), and Grey Wolf Optimizer (GWO), across multiple optimization objectives: reduction in generation cost, reduction in power loss and combined generation cost plus power loss, termed as Gross cost function. Results obtained show that FATA consistently outperforms the other algorithms in terms of convergence and solution quality, offering a robust approach to solving single objective optimization problems. FATA theoretically provides a good balance between exploration and exploitation, and produces better global solutions. It practically increases power system efficiency by lowering operational costs and losses and improving stability. Results indicate that the FATA algorithm produced minimum generation cost of 807.0405 $/h, which is 0.088–0.426% less than the competing algorithms. It also reduced power losses to 5.5917 MW, which is 1.095–6.781% less than other methods. For gross cost minimization, the FATA algorithm achieved a minimum gross cost of 1366.3727 $/h, which is 0.4799% better than the next best algorithm and 3.2261% better than the worst. The results also show that FATA is robust in solving complex optimization problems in power systems, and it provides significant improvements in run time and convergence efficiency. The main advantage for readers is that FATA provides a reliable and efficient way to optimize power systems. Future work could also investigate the application of FATA in real time, as well as in larger power networks with more renewable energy sources.},
  archive      = {J_IJCIS},
  author       = {Aljaidi, Mohammad and Jangir, Pradeep and Agrawal, Sunilkumar P. and Pandya, Sundaram B. and Parmar, Anil and Alkoradees, Ali Fayez and Arpita and Smerat, Aseel},
  doi          = {10.1007/s44196-024-00727-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimizing FACTS device placement using the fata morgana algorithm: A cost and power loss minimization approach in uncertain load scenario-based systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time facial expression recognition based on image processing in virtual reality. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-024-00729-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More virtual reality (VR) scenarios have become more prevalent in recent years. More and more people are getting into VR, meaning that objective physiological measures to assess a user's emotional state automatically are becoming more critical. Individuals’ emotional states impact their behaviour, opinions, emotions, and decisions. They may be used to analyze VR experiences and make systems react to and engage with the user’s emotions. VR environments require users to wear head-mounted displays (HMDs), blocking off their upper faces. That makes traditional Facial Expression Recognition (FER) approaches very limited in their usefulness. Thus, a Deep Learning (DL) solution combined with image processing is utilized to classify universal emotions: sadness, happiness, disgust, anger, fear and surprise. Hence, this paper suggests the Deep Automatic Facial Expression Recognition Model (DAFERM) for interactive virtual reality (VR) applications such as intelligent education, social networks, and virtual training. Two main parts comprise the system: one that uses deep neural networks (DNNs) for facial emotion identification and another that automatically tracks and segments faces. The system begins by following a marker on the front of the head-mounted display (HMD). With the help of the spatial data that has been retrieved, the positions and rotations of the face are estimated to segment the mouth. Finally, the system interacts with DNN using the pixels processed by the lips. It obtains the facial expression results in real time using an adaptive method for histogram-based mouth segmentation.},
  archive      = {J_IJCIS},
  author       = {Gong, Qingzhen and Liu, Xuefang and Ma, Yongqiang},
  doi          = {10.1007/s44196-024-00729-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Real-time facial expression recognition based on image processing in virtual reality},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized novel text embedding approach for fake news detection on twitter x: Integrating social context, temporal dynamics, and enhanced interpretability. <em>IJCIS</em>, <em>18</em>(1), 1-36. (<a href='https://doi.org/10.1007/s44196-024-00730-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of widespread misinformation, detecting fake news has become a crucial challenge, particularly on social media platforms. This paper introduces an optimized approach for Fake News Detection, combining BERT and GloVe embeddings with Principal Component Analysis (PCA) and attention mechanisms, enriched by social and temporal features for more effective text representation. Leveraging the CIC Truth Seeker Dataset 2023, we applied SHAP for feature selection and interpretability, ensuring transparency in the model’s predictions. Our methodology achieved a remarkable accuracy of 99.9% using a Random Forest classifier, showcasing the efficacy of this optimized hybrid approach. The integration of interpretability techniques such as LIME and SHAP provides deeper insights into the model’s decisions, making it a reliable tool for combating misinformation. This novel approach offers a robust and transparent solution to the growing threat of fake news, contributing significantly to the integrity of online information and public discourse on platforms like Twitter X.},
  archive      = {J_IJCIS},
  author       = {AlJamal, Mahmoud and Alquran, Rabee and Alsarhan, Ayoub and Aljaidi, Mohammad and Al-Jamal, Wafa’ Q. and Alkoradees, Ali Fayez},
  doi          = {10.1007/s44196-024-00730-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimized novel text embedding approach for fake news detection on twitter x: Integrating social context, temporal dynamics, and enhanced interpretability},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-driven optimized chaotic encryption scheme for medical image transmission in IoT-edge environment. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-024-00731-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is adopted in a wide spectrum of applications in which a vast amount of data are produced and distributed to centralized cloud platforms to deliver various services. It involves smart devices that collect thousands of terabytes of heterogeneous data and deployed this to make instant decision that aids for the better performance and most comfort life. Traditional IoT architecture is heavily centralized, where it stores the most sensitive information that creates the multiple threats and security breaches as the attackers target towards these centralized cloud systems. To improve the security chain in IoT environment, edge computing (EC) was introduced to distribute the applications of IoT at the edge of the communication networks. However, these edge-based IoT are also vulnerable to many threats due to their decentralized and in secured management. Block chain (BC) technology offers a most trusted solution to resolve the security issues in the IoT-Edge computing environment. This research study presents the block chain driven medical image encryption technique using modified honey badger optimization with the ensemble chaotic systems. The proposed block chain framework uses the divergent methods that integrates differential scroll, Hénon chaotic maps and modified honey badger optimization to generate the optimum keys and high secured image data. These high secured data are stored in the block chain, ensuring the image security to be stored in edge nodes. The complete framework was experimented using Ethereum using Ganache API and Python3.19 are utilized as the major programs for designing the varied interfaces of the recommended model. The comprehensive experimentation is undertaken to assess the security strength of the recommended encryption scheme. The evaluation metrics like as NACI, UACI, Entropy and standard verification methods such as NIST standard tests are deployed and analyzed. To prove it security strength, proposed secured BC framework is compared with the wide-variety of secured frameworks. The experimental findings reveal that the suggested framework establishes a more robust and secure environment for image exchange, surpassing the performance of other blockchain-based systems in terms of integrity, robustness and security. Finally, the paper spreads the bright light of advantages in deploying the proposed framework to formulate the most secured environment in the IoT-Edge environment for medical image transmission.},
  archive      = {J_IJCIS},
  author       = {Archana, Goli and Goyal, Rajeev and Kumar, K. M. V. Madan},
  doi          = {10.1007/s44196-024-00731-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Blockchain-driven optimized chaotic encryption scheme for medical image transmission in IoT-edge environment},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing stock portfolio selection with trapezoidal bipolar fuzzy VIKOR technique with boruta-GA hybrid optimization model: A multicriteria decision-making approach. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00733-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The investors’ main objective is to minimize the risks and to get the maximum returns in the random stock market requires them to choose the correct mix of the stocks. The traditional portfolio selection methods often struggle with market volatility, leading to less-than-the targeted profits. This research attempts to apply trapezoidal bipolar fuzzy Vise Kriterijumska Optimizacija I Kompromisno Resenje (VIKOR) method to help in decision-making. It also combines the fuzzy set theory with the VIKOR method, the trapezoidal bipolar fuzzy with VIKOR (TrBFV) approach offers a comprehensive and flexible system for evaluating investment options. The proposed approach has been validated through real-world illustrations. The analysis has been made with the VIKOR method and its integration with trapezoidal bipolar fuzzy sets. Financial decision-making can be very hard for investors who have access to big data due to the overwhelming amount of information they are required to interpret. The Boruta-GA approach combines the advantages of the Genetic Algorithm (GA) and Boruta Optimization Algorithm (BOA) methods, implementing the comprehensive feature selection capability of Boruta to detect all relevant features and harnessing the strength of GA to bring about improvement within a wide range of datasets. The result shows that this novel approach is effective and can help to investors to take decisions in the unpredictable financial market. This study is an attempt to provides investors with an appropriate approach to navigate the challenges of stock market investment. Abbreviations serve as a nomenclature table, detailing all acronyms.},
  archive      = {J_IJCIS},
  author       = {Sharma, Sunil Kumar},
  doi          = {10.1007/s44196-025-00733-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing stock portfolio selection with trapezoidal bipolar fuzzy VIKOR technique with boruta-GA hybrid optimization model: A multicriteria decision-making approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Publisher correction: Image registration using the arithmetic optimization algorithm for robotic visual servoing. <em>IJCIS</em>, <em>18</em>(1), 1-2. (<a href='https://doi.org/10.1007/s44196-025-00735-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Kmich, Mohamed and Harrade, Inssaf and Karmouni, Hicham and Sayyouri, Mhamed and Askar, S. S. and Abouhawwash, Mohamed},
  doi          = {10.1007/s44196-025-00735-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Publisher correction: Image registration using the arithmetic optimization algorithm for robotic visual servoing},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal sizing and techno-economic analysis of combined solar wind power system, fuel cell and tidal turbines using meta-heuristic algorithms: A case study of lavan island. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00737-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combined renewable energy sources (RESs) are emerging as a competitive alternative to conventional energy production facilities due to their sustainability and zero-emission characteristics. However, determining the optimal system size is complicated by two major challenges: the cost of energy (COE) and the intermittent nature of RESs. This study introduces a novel mathematical approach to optimize the sizing of photovoltaic (PV), wind, hydrogen, battery, and fuel cell systems with electrolyzers, specifically tailored for the remote area of Lavan Island. The proposed method aims to deliver electricity without reliance on the traditional electricity distribution grid, while offering a scalable solution applicable to other geographical regions. The primary objective is to achieve cost-effective electricity generation while ensuring a reliable energy supply through the evaluation of system reliability indices. A fuzzy logic system is employed to minimize the costs of a hybrid system incorporating hydroelectric, wind, solar, and battery technologies, while simultaneously calculating two key reliability metrics: the Loss of Power Supply Probability (LPSP) and the Dump Energy Probability (DEP). To optimize the objective function, this study applies three advanced algorithms: the Shuffled Frog Leaping Algorithm (SFLA), the Grasshopper Optimization Algorithm (GOA), and the Honey Badger Algorithm (HBA). These algorithms are used to determine the global optimum, with comparative analyses conducted to highlight the performance of the proposed approach. The results are evaluated based on statistical metrics, including consistency, execution time, convergence speed, and the minimization of the objective function. The findings demonstrate the superiority and the reliability of the proposed method over alternative approaches, paving the way for cost-efficient and sustainable energy solutions in isolated regions.},
  archive      = {J_IJCIS},
  author       = {Talebi, Hessameddin and Nikoukar, Javad and Gandomkar, Majid},
  doi          = {10.1007/s44196-025-00737-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimal sizing and techno-economic analysis of combined solar wind power system, fuel cell and tidal turbines using meta-heuristic algorithms: A case study of lavan island},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic graph convolutional network relation extraction model combining dependency syntax and contrastive learning. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00738-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current relation extraction tasks, when the input sentence structure is complex, the performance of in-context learning methods based on large language model is still lower than that of traditional pre-train fine-tune models. For complex sentence structures, dependency syntax information can provide effective prior text structure information for relation extraction. However, most studies are affected by the noise in the syntactic information automatically extracted by natural language processing toolkits. Additionally, traditional pre-training encoders have issues such as an overly centralized representation of word embedding for high-frequency words, which adversely affects the model to learn contextual semantic information. To address proposed problem, the paper proposes a Hyperbolic Graph Convolutional Network Relation Extraction Model Combine Dependency Syntax and Contrastive Learning. Based on the hyperbolic graph neural network, dependent syntactic information and information optimization strategies are introduced to solve the problem of word embedding concentration. Simultaneously, to mitigate the impact of noise in dependency syntax information on the relation extraction task, a contrastive learning approach is employed. After the model learns context semantics separately in the original dependency syntax information and dependency syntax information with added random noise, it maximizes the mutual information between entity words to assist the model in distinguishing noise in dependency syntax. The experiments indicate that the proposed model in this paper can effectively enhance the performance of relation extraction on public datasets, especially achieving significantly higher precision on datasets with complex sentence structures compared to in-context learning.},
  archive      = {J_IJCIS},
  author       = {Li, Jinzhe},
  doi          = {10.1007/s44196-025-00738-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hyperbolic graph convolutional network relation extraction model combining dependency syntax and contrastive learning},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced LSTM approach for detecting IoT-based DDoS attacks using honeypot data. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00741-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the widening perils in network security is the Distributed Denial of Service (DDoS) attacks on the Internet of Things (IoT) ecosystem. This paper presents an enhanced Intrusion Detection System (IDS) through the proposal of an enhanced version of the long short-term memory (LSTM) model to detect DDoS attacks using honeypot-generated data. The proposed model aggregates the Conv1D, Bidirectional Long Short-Term Memory (Bi-LSTM), Bidirectional Gated Recurrent Unit (Bi-GRU), and dropout layers to extract temporal and spatial features from IoT traffic effectively. We tested the efficacy of the proposed system on a real-world IoT-DH dataset, which showed a remarkable accuracy of 99.41%, with an AUC score of 0.9999. A comparative analysis with other baseline models, such as LSTM, Bidirectional LSTM (Bi-LSTM), Gated Recurrent Unit (GRU), Recurrent Neural Network (RNN), Feedforward Neural Network (FNN), and Temporal Convolutional Network (TCN), proved that enhanced LSTM outperformed the other models. This indicates the robustness of the proposed model in correctly detecting DDoS attacks with high generalization capability for unseen traffic data. The contribution of this paper will be an addition to the deep learning techniques applied for the solution of intrusion detection systems (IDS), which will also allow the building and implementation of more efficient security mechanisms in IoT environments.},
  archive      = {J_IJCIS},
  author       = {Arnob, Arjun Kumar Bose and Mridha, M. F. and Safran, Mejdl and Amiruzzaman, Md and Islam, Md. Rajibul},
  doi          = {10.1007/s44196-025-00741-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An enhanced LSTM approach for detecting IoT-based DDoS attacks using honeypot data},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ExAIRFC-GSDC: An advanced machine learning-based interpretable framework for accurate gas leakage detection and classification. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-025-00742-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas leakage detection is imperative in various sectors, including chemical industries, coal mines, and household applications. The escalating number of accidents in coal mines, chemical industries, and homes underscores the urgency of swift and accurate gas detection methods. This research focuses on developing advanced systems that promptly identify gas types to prevent harm to human lives and the environment. This paper addresses the challenges of gas leakage detection and classification in diverse environments, such as industrial, residential, and mining scenarios. The proposed ExAIRFC-GSDC model integrates machine learning algorithms, particularly a Random Forest Classifier, with explainable artificial intelligence (XAI) techniques to enhance interpretability. This study employs a dataset comprising gas sensor measurements that encompassing gasses, such as Liquid Petroleum Gas (LPG), Compressed Natural Gas (CNG), Methane, Propane, and others. Various machine learning classifiers, including K-Nearest Neighbors, Decision Tree, Support Vector Machines, XGBoost, and others, are compared with ExAIRFC-GSDC for gas detection. The model demonstrates superior performance, achieving an accuracy rate of 98.67%. Incorporating SHAP and LIME explanations enhances the model's interpretability, providing insights into the contributions of individual sensors. Statistical analysis confirms the significant differences in sensor readings across different gas types. ExAIRFC-GSDC is a robust and explainable solution for accurate gas detection and classification in complex environments.},
  archive      = {J_IJCIS},
  author       = {Lalithadevi, B. and Krishnaveni, S.},
  doi          = {10.1007/s44196-025-00742-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {ExAIRFC-GSDC: An advanced machine learning-based interpretable framework for accurate gas leakage detection and classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BERT-BiGRU-senti-GCN: An advanced NLP framework for analyzing customer sentiments in E-commerce. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00747-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis plays an important role in understanding employee feedback and improving workplace culture. By leveraging NLP techniques to analyze this feedback accurately, organizations can pinpoint specific areas that need improvement, address employee concerns, and foster a positive work environment. These NLP-driven deep learning models offer valuable tools for E-Commerce HR and sales departments, enabling monitoring employee and users’ sentiment trends over time and assisting in implementing targeted interventions. Focusing on the e-commerce industry, this work utilizes NLP-driven deep learning methodologies to analyze employee and user feedback, aiming to identify sentiments. The proposed NLP-driven, deep learning-based framework is designed to classify user feedback into positive, negative, or neutral sentiments. The key steps in this framework include data collection, NLP-enhanced feature extraction using BERT-BiGRU, and final classification using a Graph Neural Network-based finite-state automata. The effectiveness of this NLP-centric approach was tested on diverse datasets of customer feedback from the e-commerce industry. The results demonstrate the framework’s efficacy, achieving an impressive 93.35% accuracy rate, surpassing existing benchmark methods. The research significantly benefits e-commerce by refining product portfolios and enhancing workplace culture.},
  archive      = {J_IJCIS},
  author       = {Rana, Muhammad Rizwan Rashid and Nawaz, Asif and Rehman, Saif Ur and Abid, Muhammad Ali and Garayevi, Mubariz and Kajanová, Jana},
  doi          = {10.1007/s44196-025-00747-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {BERT-BiGRU-senti-GCN: An advanced NLP framework for analyzing customer sentiments in E-commerce},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of hybrid intrusion detection system leveraging ensemble stacked feature selectors and learning classifiers to mitigate the DoS attacks. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00750-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denial of service (DoS) attacks occur more frequently with the progressive development of the Internet of things (IoT) and other Internet-based communication technologies. Since these technologies are deeply rooted in the individual’s comfort life, protecting the user’s privacy and security against the growing DoS attack has become a major challenge among researchers. In recent times, intrusion detection systems (IDS) have developed a vital part in ensuring security against these growing attacks. IDS is still unable to attain the optimum categorization performance due to a few bottlenecks. The speed and performance of the existing IDS are challenged by the intricacy of high-dimensional data and the efficacy of the conventional base classifiers. To tackle this aforementioned problem, this research article presents the hybrid IDS based on the combination of stacked feature selection methods such as Random Boruta Selector (RFS), Relief, Pearson coefficient (PCE) and Stacked learning classifiers (SLF). To reduce the dimension of the data features and to select the optimal feature sets, novel integration of RFS, Relief, PCE are deployed. As the final step, stacked classifiers are used for the classification of DoS attacks. All the trials in this framework were accompanied utilizing CICDDoS-2019 datasets and contrasted with the other similar models. The validation boundaries such as accuracy, precision, recall, specificity, and F1-score are used to evaluate the proposed framework. With an F1-score of 96%, accuracy of 96.5%, precision of 96.0%, and recall of 95.8%, the suggested model obtained a CICDDoS-2019 score of 96%. Compared with the other traditional classifiers, the suggested framework has produced the best classification performance in detecting the DoS attacks.},
  archive      = {J_IJCIS},
  author       = {Mamatha, P. and Balaji, S. and Anuraghav, S. Sai},
  doi          = {10.1007/s44196-025-00750-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Development of hybrid intrusion detection system leveraging ensemble stacked feature selectors and learning classifiers to mitigate the DoS attacks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessments of student’s adaptability using convoluted geyser bidirectional long short-term memory in online education. <em>IJCIS</em>, <em>18</em>(1), 1-17. (<a href='https://doi.org/10.1007/s44196-024-00724-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid transition from traditional in-person education to online classrooms has highlighted the need to effectively assess student engagement in virtual learning environments supported by learning management systems. Despite this shift, there remains a significant gap in predictive models that generalize across diverse blended courses, disciplines, and student demographics. Addressing this gap is essential for improving the accuracy and efficiency of predicting student adaptability in online education. To address these issues, this research introduces a novel student adaptability learning model named Convoluted Geyser Bidirectional Long Short-Term Memory (CGBiLSTM) model, designed to predict student adaptability in online entrepreneurship education. This technique has its ability to capture complicated patterns and dependencies in sequential data, which is critical for accurately assessing student adaptability. Furthermore, incorporating the Geyser Optimization Algorithm (GOA) into CGBiLSTM improves the performance by optimizing the learning process and training capabilities, resulting in more accurate and dependable predictions. The CGBiLSTM technique achieves an accuracy of 98.94%, a precision of 99.03%, a recall of 98.71%, and an F1-score of 98.15% proving its efficacy in assessing student adaptability. The CGBiLSTM model, enhanced by the GOA, provides a highly accurate and reliable solution for predicting student adaptability in online education, making it a vital tool for educators in the evolving virtual learning landscape.},
  archive      = {J_IJCIS},
  author       = {Baskar, B. S. Vijaya and Kesavan, Ramesh},
  doi          = {10.1007/s44196-024-00724-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Assessments of student’s adaptability using convoluted geyser bidirectional long short-term memory in online education},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coverage-based variable precision (I, PSO)-fuzzy rough sets with applications to emergency decision-making. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-024-00728-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the characteristics of imprecise, incomplete and fuzzy data in emergency environment, a novel emergency decision-making method based on coverage-based variable precision (I, PSO)-fuzzy rough set model is proposed. First, an improved (I, PSO)-fuzzy rough set model is proposed, which combines the covering-based fuzzy rough set (CFRS) and the variable precision fuzzy rough set (VPFRS). Second, inspired by the idea of attribute reduction, a novel method for determining attribute weights is introduced to optimize weight assignment in emergency decision-making. Last but not least, to illustrate the feasibility and effectiveness of the proposed method, an example of post-flood rescue force allocation in urban areas is demonstrated. Finally, the stability and superiority of the method are verified through sensitivity analysis and comparative evaluation.},
  archive      = {J_IJCIS},
  author       = {Yin, Ran and Chen, Minge and Wu, Jian and Liu, Yu},
  doi          = {10.1007/s44196-024-00728-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Coverage-based variable precision (I, PSO)-fuzzy rough sets with applications to emergency decision-making},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time athlete fatigue monitoring using fuzzy decision support systems. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00732-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports scientists worry about fatigue, because it affects performance, increases injury risk, and harms health. Traditional fatigue measurements may miss this complicated and ever-changing state, placing athletes at risk of injury while training. This study tests the premise that cutting-edge, real-time monitoring devices improve athlete health and performance. This research aims to reduce tiredness by developing a Fuzzy Decision Support System for Real-Time Athlete Weariness Monitoring. Fuzzy logic can handle unclear performance data, making it a more flexible and advanced alternative to standard methods. Sports athlete fatigue is complicated and dynamic, requiring improved, more precise, and real-time monitoring approaches. The FDSS-RAFM model uses fuzzy logic to account for human performance and physiology. The FDSS-RAFM model assesses athlete fatigue in a comprehensive and context-aware manner. This study’s findings can help coaches, players, and sports scientists improve training programs, reduce injury risk, and improve performance in ever-changing athletic contexts. Fuzzy decision-support systems and other cutting-edge technology can improve athletes’ health and performance, adding to sports science literature. Experimental results show that the proposed FDSS-RAFM model outperforms competing models in sensitivity (97%), specificity (89%), accuracy (96%), and dynamic adaptation error analysis (2.41%).},
  archive      = {J_IJCIS},
  author       = {Li, Aiqin},
  doi          = {10.1007/s44196-025-00732-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Real-time athlete fatigue monitoring using fuzzy decision support systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced heart disease prediction through spatial and temporal feature learning with SCN-deep BiLSTM. <em>IJCIS</em>, <em>18</em>(1), 1-34. (<a href='https://doi.org/10.1007/s44196-025-00734-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease prediction using machine learning methods faces various challenges, such as low data quality, missing irrelevant values, and underfit and overfit problems, which increase the time complexity and degrade the model's prediction performance. Moreover, the hybrid models for heart disease prediction showed poor accuracy due to the irrelevancy in the dataset. Therefore, a search optimizer with a deep convolutional neural network coupled with a Deep Bidirectional long short-term memory classifier (SCN-Deep BiLSTM) is proposed to handle the abovementioned issue. The importance of SCN-Deep BiLSTM relies upon establishing the spatial information and temporal features from the ECG signals that support learning while minimizing the computational complexity associated with learning from raw signals.The SCN-Deep BiLSTM model achieves the accuracy, F-score, precision, recall, and critical success index of 0.97, 0.97, 0.98, 0.99, and 0.97, respectively for 80% of model training, whereas the SCN-Deep BiLSTM model attained 0.97, 0.98, 0.96, 0.94, and 0.96 for accuracy, F-score, precision, recall and critical success index, respectively when K-Fold is 10. The performance outcome emphasizes the model’s efficacy and accurate prediction and classification of heart disease.},
  archive      = {J_IJCIS},
  author       = {Pandey, Vivek and Lilhore, Umesh Kumar and Walia, Ranjan},
  doi          = {10.1007/s44196-025-00734-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Advanced heart disease prediction through spatial and temporal feature learning with SCN-deep BiLSTM},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of physical education teaching quality based on hierarchical fuzzy set theory. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00736-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of physical education often faces challenges due to inadequate evaluation methods that fail to provide accurate, real-time teaching evaluation. These challenges influence student performance and overall teaching quality. This article introduces a quality assessment method using fuzzy set theory (QAM-FST) to evaluate physical education teaching. The proposed method extracts and classifies all the available teaching data to compute the students' performance over sessions through fuzzy rough set differentiations over partial and complete derivatives. The complete derivatives identify the factors contributing the maximum to the teaching quality, while the partial derivatives acquire the minimal influence factors. These derivatives are clubbed together through the hierarchical process to identify the precise quality impacting factors and least impacting factors to replace or recommend alternate suggestions. The QAM-FST framework offers a comprehensive, data-driven assessment ensuring the enhancement of PE teaching quality. The QAM-FST outperforms three current models in terms of suggestion accuracy (96.8%), assessment time reduction (22.66%), and total performance evaluation efficiency (16.78%). This data-driven platform guarantees improved physical education instruction quality through actionable insights obtained from real-time feedback.},
  archive      = {J_IJCIS},
  author       = {Tang, Chunlong},
  doi          = {10.1007/s44196-025-00736-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Analysis of physical education teaching quality based on hierarchical fuzzy set theory},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An algorithm for extracting features of basketball players' foul actions based on an attention mechanism. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-025-00743-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basketball foul action usually involves multiple features, and it is difficult to extract effective features from complex and diverse features. Therefore, a feature extraction algorithm for basketball players' foul action based on attention mechanism is proposed. On the basis of ResNet50 network model, the attention mechanism is integrated to build a basketball player foul action feature extraction model. The machine vision system is used to obtain basketball player action video as the input of the model. The space attention module and time attention module are, respectively, introduced into the video slow frame rate branch and video fast frame rate branch of ResNet50 network. By making the network give greater weight to the key areas of a single frame of video, and improving the network's attention to important video frames, the best spatio-temporal characteristics of foul actions are obtained. After fusion, the feature fusion results are input into the classifier with the cross-entropy loss function as the loss function, and the probability value of each possible foul action and the tag target probability are output, complete basketball player foul action feature extraction. The experimental results show that the algorithm can effectively identify the identification of basketball players, the cumulative matching feature value of foul action recognition can reach more than 95%, and the average accuracy is more than 70%; the F1 value and stability are high, which can reduce the error caused by data fluctuation and noise; the error rate of real-time detection is less than 4.5%, the omission rate is less than 4.7%, the detection time is lower than 14 ms, and the application effect is good.},
  archive      = {J_IJCIS},
  author       = {Wang, Peng},
  doi          = {10.1007/s44196-025-00743-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An algorithm for extracting features of basketball players' foul actions based on an attention mechanism},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-commerce live-streaming platform and decision support system based on fuzzy association rule mining. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00744-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Live streaming of e-commerce platforms attracts consumers for their products/purchases and hence the familiarity is retained high amid different competitors. Fuzzy decision systems are incorporated to filter the streaming content of the platforms to improve consumer augmentations at different promotions. Therefore to support such augmentation and consumer building process, this article proposes a filtered sale streaming model to improve the circulation of new launches and to project the existing products through sustainable promotions. In this process, the comprehensive transition rule for product promotions and sale improvements is defined using fuzzy mining. The fuzzy process introduces the different performance members based on consumer access rate and sale count. The rule modifications are defined using the above factors’ decrease over filtered promotions to boost the augmentation. Using the highest possible member weights over a product, sale, and consumers, the linear improvements between the three factors are estimated over the closure observed at each sale interval. Thus, the streaming modifications and the product exposures are modeled using different mining rules adaptable for e-commerce platforms.},
  archive      = {J_IJCIS},
  author       = {Liao, Hua},
  doi          = {10.1007/s44196-025-00744-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {E-commerce live-streaming platform and decision support system based on fuzzy association rule mining},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal AC power flow with energy storage and renewable energy: An efficient RL algorithm capable of handling equality constraints. <em>IJCIS</em>, <em>18</em>(1), 1-38. (<a href='https://doi.org/10.1007/s44196-025-00745-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using energy storage to solve the multiperiod OPF problem for renewable energy fluctuation is an effective way to increase operation safety and reduce the cost of power systems. However, in solving this OPF problem, model-based methods cannot accurately model uncertain scenarios, while traditional RL methods cannot satisfy the constraints well, and both methods have limitations. Therefore, we propose an RL method, ERL-HC, that does not require scene modelling and can handle general forms of physical constraints. First, a constraint policy network (CPN) is proposed that corrects the output of a neural network on the basis of the inequality generalized reduced gradient (GRG) method; the outputs of this network satisfy all constraints, and it can be trained in an end-to-end manner. Second, the critic network is improved based on the IM method to increase the sample learning efficiency by improving the agent's understanding of state interdependencies. Finally, the adaptive-tuning Lagrange multiplier method is applied in the AC framework to reduce the number of iterations of the inequality GRG in the CPN and efficiently train ERL-HC. ERL-HC was tested on two systems of different sizes. The results show that ERL-HC has a better learning ability than general safe RL algorithms, overcomes the limitations of mainstream safe RL methods in handling equality constraints, and addresses the poor generalization issues of RL methods that can handle equality constraints.},
  archive      = {J_IJCIS},
  author       = {Liu, Mingde and Zhu, Jianquan and Liu, Mingbo},
  doi          = {10.1007/s44196-025-00745-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimal AC power flow with energy storage and renewable energy: An efficient RL algorithm capable of handling equality constraints},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropy-weighted TOPSIS-based bird strike risk assessment for an airport. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00746-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To identify the factors with higher bird strike risk at a certain airport, and to provide a theoretical basis for the airport to develop targeted and dynamic bird strike prevention strategies, this study has established a bird strike risk assessment index system for the airport based on the “3M1E” theory and relevant content of the “Management Measures for the Prevention and Control of Bird Strikes and Animal Intrusions at Transport Airports”. Then, under the premise of reasonably selecting the parameters of generalized intuitionistic fuzzy entropy, the entropy method is used to simultaneously determine the expert weights and indicator weights. Finally, a weighted TOPSIS model was utilized to assess and rank the high-risk factors contributing to bird strike incidents. Then, taking the bird strike event occurrence at a certain airport as an example for analysis, the second-level indicators are ranked. The results show that the top three indicators are Bird Prevention Funding ( $$D_3$$ ), Habitat Distribution ( $$C_1$$ ), and Dispersal Activities ( $$D_5$$ ). The assessment results provide the necessary basic data for the bird strike prevention work of the airport.},
  archive      = {J_IJCIS},
  author       = {Yu, Changyang and Zhao, Fan and Yin, Yu and Wu, Yi},
  doi          = {10.1007/s44196-025-00746-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Entropy-weighted TOPSIS-based bird strike risk assessment for an airport},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and implementation evaluation of personalized and differentiated teaching strategies for preschool children based on fuzzy decision support systems. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00748-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {School operations have changed due to information technology. Personalized teaching for preschool children requires innovative and adaptable strategies for providing the best-afford experience and learning environment. Conventional teaching approaches may not always accommodate students’ learning styles. This can lower performance and involvement. The expanding variety of pre-schoolers necessitates creative evaluation and optimization methods that promote inclusion and success for all children. The article introduces a preschool teaching evaluation model to improve the students’ learning experience. In particular, the evaluation model is designed for various assessment strategies irrespective of personalization. The proposed model inputs the students’ learning feasibility and the teaching mode to evaluate the personalization adaptability. The fuzzy decision support system improves the evaluation based on the above factors. It evaluates student-specific indicators, including attentiveness, body language, and engagement, to determine instructional flexibility. The model uses real-time classroom observations and student assessments to find realistic approaches with low-to-high fuzzy derivatives. The proposed system is designed to compute the adaptability from both factors under low-to-high fuzzy derivatives. By defining the maximum feasibility range, the teaching strategy is optimized to meet the adaptability. Thus, the low-level strategies are discarded using adaptability measures to reduce personalization failures. The proposed model is verified using adaptability, feasibility, and mode improvements. Research shows that the fuzzy decision support system makes courses more adaptive and feasible in many contexts, particularly those that involve games, audiovisual approaches, and crafts. Preschoolers, parents, and teachers indicated increased enjoyment, fewer customization failures, and greater involvement. Fuzzy-based evaluation increased feasibility ratings and approach versatility. The research provides a valuable foundation for solving classroom customization difficulties in preschool settings, emphasizing data-driven, adaptive teaching techniques. This method enables scalable applications in early childhood education through fuzzy decision-making and real-time evaluations.},
  archive      = {J_IJCIS},
  author       = {Hou, Yali},
  doi          = {10.1007/s44196-025-00748-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Design and implementation evaluation of personalized and differentiated teaching strategies for preschool children based on fuzzy decision support systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-source fusion positioning system based on MDAW-PF algorithm and PDR. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00749-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to multiple occlusions and strong interference in an indoor environment, the traditional single signal source location method is difficult to meet the requirements of high precision and high robustness. Therefore, this paper proposes a multi-source fusion location system based on an adaptive vector particle filter, which combines fingerprint location, pedestrian dead reckoning and map information. The received signal intensity is optimized by offline fingerprint calibration and Kalman filter. The adaptive vector particle filter adopts multi-direction sampling and weight adjustment, which effectively improves the diversity of particles and reduces errors. Compared with the single-source method and other multi-source systems, the positioning accuracy and trajectory fitting degree of the proposed system were significantly improved. The positioning error probability was 97%, the average error was 0.67 m, and the positioning accuracy reached 90.1%. In summary, the proposed multi-source fusion system provides an effective solution for indoor high-precision and reliable positioning.},
  archive      = {J_IJCIS},
  author       = {Wu, Wennan and Xu, Yigang and Li, Zhimin and Lai, Jizhou},
  doi          = {10.1007/s44196-025-00749-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A multi-source fusion positioning system based on MDAW-PF algorithm and PDR},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter adaptive manta ray foraging optimization for global continuous optimization problems and parameter estimation of solar photovoltaic models. <em>IJCIS</em>, <em>18</em>(1), 1-36. (<a href='https://doi.org/10.1007/s44196-025-00753-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manta ray foraging optimization (MRFO) algorithm suffers from a fixed parameter $$ S $$ , limiting its adaptability in balancing search capability and convergence speed during different optimization stages. To address this limitation, a success-history-based parameter adaptation strategy is proposed to dynamically adjust $$ S $$ . Furthermore, to enhance population diversity and avoid premature convergence, a randomly selected individual from the top $$ G $$ high-quality solutions replaces the current best individual in the somersault foraging behavior. Based on these improvements, a parameter adaptive manta ray foraging optimization (PAMRFO) algorithm is developed. The experimental results demonstrate the effectiveness of PAMRFO. On the IEEE CEC2017 benchmark function set, PAMRFO achieved an average win rate of 82.39% across 29 functions compared to seven state-of-the-art algorithms. On 22 IEEE CEC2011 real-world optimization problems, PAMRFO achieved an average win rate of 55.91% compared to ten advanced algorithms. Sensitivity analysis identified optimal parameter settings, and further stability analysis revealed that PAMRFO exhibits higher success rates and computational efficiency among the four MRFO variants. Population diversity and exploration-exploitation analysis demonstrated the effectiveness of the proposed update mechanism in maintaining diversity and balancing exploration and exploitation. In solving parameter estimation problems for six multimodal solar photovoltaic models, PAMRFO outperformed other competing methods with a 100% success rate, highlighting its superior performance in the photovoltaic field. These findings validate the robustness, efficiency, and wide applicability of PAMRFO, providing advanced solutions for optimization problems in the new energy domain.},
  archive      = {J_IJCIS},
  author       = {Tang, Zhentao and Wang, Kaiyu and Yao, Yongxuan and Zhu, Mingxin and Zhuang, Lan and Chen, Huiqin and Li, Jing and Yan, Li and Gao, Shangce},
  doi          = {10.1007/s44196-025-00753-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Parameter adaptive manta ray foraging optimization for global continuous optimization problems and parameter estimation of solar photovoltaic models},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure authentication and key exchange protocol for vehicles to infrastructure network. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-025-00754-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles technology has been widely applied in various communication scenarios, including vehicles to vehicles, vehicles to roadside facilities, vehicles to pedestrians, and vehicles to cloud. Owing to transmitting data through public channels, various security issues like identity leakage, man in the middle attack, key leakage and etc., are also introduced simultaneously and still challenging to be solved. Researches and practices have shown that authentication and key exchange protocols are effective methods to solve such security issues. However, most existing security protocols for Internet of Vehicles are established on the premise that the registration process is with a secure channel, which is usually not satisfied and deviates from practical applications. Accordingly, an authentication and key exchange protocol with an insecure channel has been proposed, in which the operations of symmetric encryption and XOR encryption are adopted for all interactive processes to improve protocol security. The theoretical analysis and formal verification demonstrate that the proposed protocol satisfies security properties including authentication and confidentiality, and reduces the costs of computation and communication compared with the method with public key encryption.},
  archive      = {J_IJCIS},
  author       = {Xu, Peng and Wang, Xiuzhen and Chen, Meirong},
  doi          = {10.1007/s44196-025-00754-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A secure authentication and key exchange protocol for vehicles to infrastructure network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Publisher correction: A two-way crossed effects fuzzy panel linear regression model. <em>IJCIS</em>, <em>18</em>(1), 1. (<a href='https://doi.org/10.1007/s44196-025-00756-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Hesamian, Gholamreza and Johannssen, Arne},
  doi          = {10.1007/s44196-025-00756-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Publisher correction: A two-way crossed effects fuzzy panel linear regression model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: ExAIRFC-GSDC: An advanced machine learning-based interpretable framework for accurate gas leakage detection and classification. <em>IJCIS</em>, <em>18</em>(1), 1-2. (<a href='https://doi.org/10.1007/s44196-025-00758-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Lalithadevi, B. and Krishnaveni, S.},
  doi          = {10.1007/s44196-025-00758-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: ExAIRFC-GSDC: An advanced machine learning-based interpretable framework for accurate gas leakage detection and classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing solid oxide fuel cell efficiency through advanced model identification using differential evolutionary mutation fennec fox algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-31. (<a href='https://doi.org/10.1007/s44196-025-00759-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuel cells (FCs) are increasingly attracting attention for their efficient conversion of chemical energy into electricity without the need for combustion. Their high efficiency and versatility make them a promising technology across various applications. Researchers are actively exploring ways to optimize FC systems to meet specific energy needs. Among the different types of fuel cells, solid oxide fuel cells (SOFCs) stand out as a promising clean energy technology that generates electricity through electrochemical reactions. However, accurately modeling SOFCs, which is essential for reducing design costs, presents a challenge due to their complex and nonlinear characteristics. An ideal model should be adaptable to varying operating pressures and temperatures. This research introduces a novel approach for optimal SOFC model identification using a differential evolutionary mutation Fennec fox algorithm (DEMFFA). A real-world case study demonstrates the superior effectiveness of DEMFFA compared to existing methods. Additionally, a sensitivity analysis evaluates the influence of temperature and pressure on the model, with results indicating that the proposed method achieves higher efficiency than other approaches. The sum of the square error of the proposed algorithm is 1.18E-11 followed by the parent algorithm, Fennec fox algorithm (FFA) (1.24E-09), and some of the compared algorithms. The computational time of the proposed algorithm is 1.001 s, followed by the parent algorithm FFA (1.199 s) and some of the compared algorithms. DEMFFA offers significant potential, enhancing renewable energy, minimizing SOFC's environmental impact, and improving real-world applications like distributed power generation and hydrogen integration.},
  archive      = {J_IJCIS},
  author       = {Singla, Manish Kumar and Gupta, Jyoti and Kumar, Ramesh and Jangir, Pradeep and Louzazni, Mohamed and Giri, Nimay Chandra and Al-Gburi, Ahmed Jamal Abdullah and EI-Kenawy, E. I.-Sayed M. and Alharbi, Amal H.},
  doi          = {10.1007/s44196-025-00759-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing solid oxide fuel cell efficiency through advanced model identification using differential evolutionary mutation fennec fox algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid LECNN architecture: A computer-assisted early diagnosis system for lung cancer using CT images. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00761-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is one of the most common causes of cancer-related death. Therefore, early diagnosis of this cancer is crucial for planning patient treatment. This paper proposes a hybrid Lung Ensemble Convolutional Neural Network (LECNN) architecture for the computer-aided early diagnosis of lung cancer via CT images. The proposed hybrid approach integrates a transfer learning (TL) mechanism with ensemble learning (EL) on the basis of majority voting. Initially, CNN architectures (GoogLeNet, EfficientNet, DarkNet19, and ResNet18) are trained via TL, and the resulting CNN models are used as inputs in EL. The outputs from all the CNN architectures are evaluated via majority voting to identify the top-performing triple CNN combination, which is then utilized in the hybrid approach. The performance of the proposed method was assessed via the widely used IQ-OTH/NCCD dataset. Additionally, the impact of the elastic transformation method, a data augmentation technique, on performance improvement was investigated in the proposed method. The triple combination of the GoogLeNet, EfficientNet, and DarkNet19 CNN architectures, as part of the EL method in the hybrid approach, achieved superior performance on both the raw and augmented datasets according to the obtained performance results. The performance evaluations revealed that the proposed approach achieved more than a 5% improvement with the augmented dataset compared with the raw IQ-OTH/NCCD dataset, resulting in the highest performance. The proposed hybrid approach achieved 99% accuracy, 98.82% sensitivity, 99.48% specificity, 99.06% precision, and 98.94% F1 score on the augmented IQ-OTH/NCCD dataset. When compared with findings from previous studies using the same dataset, the proposed hybrid approach outperformed state-of-the-art methods. In conclusion, it demonstrates significant potential as a robust tool for computer-aided early lung cancer diagnosis systems and may also contribute to the development of future hybrid approaches in this field.},
  archive      = {J_IJCIS},
  author       = {Güraksın, Gür Emre and Kayadibi, Ismail},
  doi          = {10.1007/s44196-025-00761-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A hybrid LECNN architecture: A computer-assisted early diagnosis system for lung cancer using CT images},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval-valued intuitionistic fuzzy multi-attribute decision-making based on entropy and bidirectional projection. <em>IJCIS</em>, <em>18</em>(1), 1-13. (<a href='https://doi.org/10.1007/s44196-025-00763-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel arctangent-based interval-valued intuitionistic fuzzy entropy function designed to address multi-attribute group decision-making problems, particularly in situations where attribute weights are either completely unknown or only partially known. The proposed entropy function computes the objective weights of the attributes and, by integrating these with subjective weights, derives a comprehensive weight. This methodology effectively addresses uncertainties and the incomplete nature of weight information in decision-making processes. Furthermore, the paper extends the bidirectional projection method to the interval intuitionistic fuzzy context, developing a multi-attribute decision-making model that integrates the arctangent-based interval-valued intuitionistic fuzzy entropy and the bidirectional projection method. Finally, a series of comparative experiments are conducted to validate the effectiveness and robustness of the proposed entropy function and bidirectional projection method in multi-attribute decision-making.},
  archive      = {J_IJCIS},
  author       = {Zheng, Jian and Dong, Minggao},
  doi          = {10.1007/s44196-025-00763-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Interval-valued intuitionistic fuzzy multi-attribute decision-making based on entropy and bidirectional projection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of communication transmission frequency linear algebraic model under aerial computing architecture. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00764-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of the demand for wireless communication systems, when the existing algebraic model processes real-time data, the frequency adjustment is inflexible, it is difficult to quickly optimize the transmission parameters to cope with network load changes, and the long-term operation fails to effectively control the CPU frequency, resulting in increased energy consumption. To better promote the development of wireless communication systems, this article aimed to use aerial computing architecture to optimize the linear algebraic model of communication transmission frequency, to better meet the needs of today's wireless communication systems. The article first designed a communication frequency stabilization device structure to ensure high stability of the output spectrum. Then it introduced a dynamic frequency adjustment module to achieve real-time adjustment of communication transmission frequency. It then improved the data transmission rate through the design of the aerial computing perception module. This article used a frequency optimization algorithm based on linear algebra to adjust its linear relationship, optimize transmission energy consumption, and improve transmission efficiency. Finally, to verify the application effect of aerial computing architecture in optimizing the linear algebraic model of communication transmission frequency, this paper compared it with traditional dynamic adjustment models and parallel computational models. The research results showed that for packet 13, the round-trip time required to transmit the model in this article was 1.21 ms; the response time was 0.009 ms, and the total energy consumption was 89.6-W hours. The traditional dynamic adjustment model required a round-trip time of 4.92 ms, a response time of 0.093 ms, and a total energy consumption of 119.1-W hours for packet 13 transmissions. The parallel computational model required a round-trip time of 6.33 ms, a response time of 0.063 ms, and a total energy consumption of 131.4-W hours for packet 13 transmissions. The results showed that the optimized communication transmission frequency linear algebraic model using aerial computing architecture had shorter communication delay and response time, lower energy consumption, and better frequency control performance. This article highlighted the important impact of aerial computing architecture on the stability, real-time performance, and transmission rate of linear algebraic models of communication transmission frequencies, providing more ideas for the design and planning of wireless communication systems.},
  archive      = {J_IJCIS},
  author       = {Gao, Yufeng},
  doi          = {10.1007/s44196-025-00764-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimization of communication transmission frequency linear algebraic model under aerial computing architecture},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DenseNet-ABiLSTM: Revolutionizing multiclass arrhythmia detection and classification using hybrid deep learning approach leveraging PPG signals. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00765-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arrhythmias (AM) are heart conditions that can lead to fatal cardiac arrest. Automated identification of arrhythmias is crucial for detecting cardiac diseases. Previous studies have used photoplethysmography (PPG) signals to identify arrhythmias, but there is limited research on their application for multiclass arrhythmia classification. This study introduces a Hybrid Deep Learning (HDL) model called DenseNet-ABiLSTM, which uses densely connected convolutional networks and Attention-based Bidirectional Long Short-Term Memory (ABiLSTM) to categorize various types of arrhythmias. The model uses 1D convolutional kernels to acquire multiscale conceptual features, followed by BiLSTM to understand temporal relationships among features. The Attention Mechanism layer is presented to improve detection performance. The model categorizes arrhythmia rhythms into six types: Sinus Rhythm (SR), Early Ventricular Contraction (EVC), Early Atrial Contraction (EAC), Ventricular Tachycardia (VT), Supraventricular Tachycardia (ST), and AF. Various metrics were assessed and compared with Electrocardiogram (ECG) results to determine AM rhythms. The mean performance measures showed strong overall performance, with a mean F1 score and accuracy of 87.74% and 89.14%, respectively.},
  archive      = {J_IJCIS},
  author       = {Saranya, K. and Karthikeyan, U. and Kumar, A. Saran and Salau, Ayodeji Olalekan and Tin Tin, Ting},
  doi          = {10.1007/s44196-025-00765-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {DenseNet-ABiLSTM: Revolutionizing multiclass arrhythmia detection and classification using hybrid deep learning approach leveraging PPG signals},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intrusion detection system for network security using novel adaptive recurrent neural network-based fox optimizer concept. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00767-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of daily networks and communications rely heavily on network security. Researchers in cybersecurity emphasize the necessity of developing effective intrusion detection systems (IDS) to safeguard networks. The importance of efficient IDS escalates as attackers devise new types of attacks and network volumes expand. Furthermore, IDS aims to ensure the integrity, confidentiality, and availability of data transmitted across networked systems by preventing unauthorized access. Following numerous studies utilizing machine learning (ML) to develop effective IDS, the focus has shifted towards deep learning (DL) techniques as artificial neural networks (ANNs) and DL systems have become prevalent. ANNs are capable of generating features autonomously, eliminating the need for manual intervention. This paper introduces an innovative adaptive recurrent neural network-based fox optimizer (ARNN-FOX) method. The primary objective of the ARNN-FOX system is to efficiently detect and classify network intrusions, thereby enhancing network security. Data normalization is conducted to scale the incoming data into a usable format. The gray level co-occurrence matrix (GLCM) method is proposed for selecting the optimal subset of features for the ARNN-FOX method. In the proposed approach, the fox algorithm (FOX) is utilized for the adjustment of hyperparameters in the ARNN model. The efficacy of the ARNN-FOX approach is assessed using benchmark datasets. Based on comparative results, the ARNN-FOX method demonstrates superior performance in parameters such as accuracy, specificity, sensitivity, F1 Score, recall value, and precision values over existing models. The proposed ARNN-FOX-based IDS model for the network security in terms of accuracy is 15.12%, 8.79%, 6.45%, and 4.21% better than RNN, CNN-LSTM, DASO-RNN, and ChCSO-LSTM, respectively. Similarly, with respect to specificity, the suggested ARNN-FOX-based IDS model for network security outperforms RNN, CNN-LSTM, DASO-RNN, and ChCSO-LSTM by 32.43%, 8.89%, 3.16%, and 2.08%, respectively.},
  archive      = {J_IJCIS},
  author       = {Manivannan, R. and Senthilkumar, S.},
  doi          = {10.1007/s44196-025-00767-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Intrusion detection system for network security using novel adaptive recurrent neural network-based fox optimizer concept},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-perspective learning based on transformer for stock price trend. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00768-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock constitutes a crucial element of the financial market, and accurately forecasting stock trends remains a significant and unresolved issue. Nonetheless, the stock’s considerable complexity renders accurate prediction of stock trends more challenging. This paper proposes a novel multi-perspective approach that converts the time series prediction challenge into an image classification problem, referred to as the Multi-perspective Denoise Transformer (MPDTransformer). We initially multi-factor features into two-dimensional images employing a multi-perspective approach to more comprehensively explain the actual market conditions and enhance the model’s practicality and adaptability; secondly, we utilize a Convolutional Autoencoder (CAE) to extract features, which effectively eliminates noise and enhances data purity; finally, to comprehensively capture the temporal relationships within the data and gain a deeper understanding of the overall time series, we employ a Transformer for prediction. Experimental results demonstrate that our method outperforms other prevalent stock trend prediction techniques.},
  archive      = {J_IJCIS},
  author       = {Li, Xiliang and Chen, Shuoru and Qiao, Xiaoyan and Zhang, Mingli and Zhang, Caiming and Zhao, Feng},
  doi          = {10.1007/s44196-025-00768-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multi-perspective learning based on transformer for stock price trend},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid-CID: Securing IoT with mongoose optimization. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00751-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) technology has evolved beyond personal devices to power global deployments across a wide range of networks which has a significant impact on global commerce. However, security challenges arise due to the wide range of protocols and computational capabilities in IoT devices. To combat these issues, a novel hybrid optimization-enabled neural network for classification of intrusion data against IoT system (Hybrid-CID) is proposed particularly to identify intrusions in resource-constrained IoT devices. Initially, the incoming data are standardized by removing the irrelevant information through preprocessing to ensure the performance of detection models. After preprocessing, the Hybrid-CID framework develops a hybrid optimization algorithm to identify the intrusions from the traffic data which ensures data privacy by maintaining the reliability and integrity of IoT deployments. Finally, the combined deep learning (DL) network classifies the identified intrusions to contribute proactive threat mitigation by ensuring the confidentiality of IoT system data. The Hybrid-CID system is validated through the benchmark CSE-CIC-IDS 2018 and CICIDS 2017 datasets using accuracy, specificity, precision, F1-score, recall, execution time, communication cost, detection rate, detection time, and computational cost. The Hybrid-CID framework achieves an overall accuracy of 97.82%, whereas the WDLSTM, TLBO-IDS, and DIS-IoT techniques achieve 87.42%, 89.58%, and 94.72%, respectively, for efficiently detecting intrusions in IoT networks.},
  archive      = {J_IJCIS},
  author       = {Sheeba, S. Merlin and Shaji, R. S.},
  doi          = {10.1007/s44196-025-00751-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hybrid-CID: Securing IoT with mongoose optimization},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lattice-based decision models for green urban development: Insights from $$L_{q}*$$ q-rung orthopair multi-fuzzy soft set. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00755-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location selection is a critical process in decision-making for projects that involve multiple criteria, such as urban planning, industrial site development, or green building projects. Multiple criteria decision making (MCDM) is a systematic approach that evaluates and ranks potential alternatives based on a set of often conflicting criteria. This study focuses on selecting the optimal urban location for a green building project by employing the $$L_{q}*$$ q-rung orthopair multi-fuzzy soft-MCDM( $$L_{q}*$$ q-ROMFS) techniques. The $$L_{q}*$$ q-ROMFS set combines elements from two distinct theories with lattice ordering parameters: q-rung orthopair fuzzy set and multi-fuzzy soft set. It provides a mathematical framework with multiple parameters that effectively represents problems involving multi-dimensional data within a dataset. We expand this concept by establishing the algebraic structures of $$L_{q}*$$ q-ROMFS sets, including properties like modularity and distributivity, while also analyzing their homomorphism under lattice mappings. Finally, leveraging the $$L_{q}*$$ q-ROMFS matrix, we propose both a choice matrix and a weighted choice matrix to effectively address the selection of the optimal urban location for a green building project.},
  archive      = {J_IJCIS},
  author       = {Jayakumar, Vimala and Pethaperumal, Mahalakshmi and Kausar, Nasreen and Pamucar, Dragan and Simic, Vladimir and Salman, Mohammed Abdullah},
  doi          = {10.1007/s44196-025-00755-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Lattice-based decision models for green urban development: Insights from $$L_{q}*$$ q-rung orthopair multi-fuzzy soft set},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced model for gestational diabetes mellitus prediction using a fusion technique of multiple algorithms with explainability. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-025-00760-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High glucose levels during pregnancy cause Gestational Diabetes Mellitus (GDM). The risks include cesarean deliveries, long-term type 2 diabetes, fetal macrosomia, and infant respiratory distress syndrome. These risks highlight the need for accurate GDM prediction. This research proposes a novel fusion model for early GDM prediction. It uses conventional Machine Learning (ML) and advanced Deep Learning (DL) algorithms. Subsequently, it combines the strengths of both ML and DL algorithms using various ensemble techniques. It incorporates a meta-classifier that further reinforces its robust prediction performance. The dataset is split into training and testing sets in a 70/30 ratio. The initial steps involve exploratory analysis and data preprocessing techniques such as iterative imputation and feature engineering. Subsequently, oversampling is applied to the training set to address class imbalance which ensures the model learns effectively. The testing set remains imbalanced to maintain the credibility of the model’s performance evaluation. The fusion model achieves an accuracy of 98.21%, precision of 97.72%, specificity of 98.64%, recall of 97.47%, F1 score of 97.59%, and an Accuracy Under the Curve (AUC) of 99.91%. The model exhibits efficiency with an average processing time of 0.06 s to predict GDM. These results outperform the previous studies using the same GDM prediction dataset and demonstrate the model's superior performance. Additionally, Explainable Artificial Intelligence (XAI) techniques are utilized to interpret the model’s decisions. They highlight the most influential features in GDM prediction and ensures transparency. The proposed fusion model can facilitate proactive GDM prediction to elevate GDM management and maternal–fetal health outcomes.},
  archive      = {J_IJCIS},
  author       = {Hassan, Ahmad and Ahmad, Saima Gulzar and Iqbal, Tassawar and Munir, Ehsan Ullah and Ayyub, Kashif and Ramzan, Naeem},
  doi          = {10.1007/s44196-025-00760-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced model for gestational diabetes mellitus prediction using a fusion technique of multiple algorithms with explainability},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of distributionally robust optimization markov decision-making under uncertainty in scheduling of multi-category emergency medical materials. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00762-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the preliminary stages of public health emergencies, many regional public health systems do not have enough medical resources to address the needs that arise from the emergencies. Additionally, due to the rapid development of emergency situations, it is difficult to accurately understand all medical material demands. Thus, we develop a multi-category emergency medical materials robust scheduling method for multi-period, which continuously schedules the availability of multi-category emergency medical materials during times of uncertain demand. First, we developed a single-period Distributionally Robust Optimization (DRO) model to provide a powerful strategy for scheduling multi-category emergency medical materials with little information on material demand. In the DRO model, we prioritize medical material requirements into different categories, assuming only that the means and variances of information on the demand are available to seek an optimal implementation strategy in a single period. We then combine the DRO scheduling model with the Markov Decision Process (MDP) and extend it to the multi-period Distributionally Robust Optimization Markov Decision Process scheduling model (DRO-MDP). Our DRO-MDP model provides encouraging guidelines to solve the multi-period scheduling problem of multi-category emergency medical materials in uncertain situations. A simulated experiment is used to demonstrate the effectiveness of the proposed model. The simulation uses COVID-19 data from New Delhi, India in the spring of 2021. It is important to note that the model we propose can be easily generalized as a framework for any multi-category resource allocation problem with uncertain needs.},
  archive      = {J_IJCIS},
  author       = {Liang, Zhizhen and Wang, Xiaojia and Xu, Sheng and Chen, Wei},
  doi          = {10.1007/s44196-025-00762-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Application of distributionally robust optimization markov decision-making under uncertainty in scheduling of multi-category emergency medical materials},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SED-NET: Real-time suspicious event detection via deep learning-based di-stream neural network. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00766-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suspicious event detection (SED) identifies anomalous activities in surveillance data using computer vision and machine learning techniques. However, existing approaches have high false positive rates difficulty distinguishing suspicious from normal behaviors, and limited adaptability to dynamic environments. This research introduces a novel deep learning-based SED-NET model for detecting suspicious events in public places. Initially, input images are collected from two data for detecting Suspicious events. Surveillance camera videos are converted into frames and the suspicious images are pre-processed using a Gaussian adaptive bilateral filter (GABF) to reduce noise while preserving edges. A Sobel edge detector is used to detect the fine edges in the pre-processed frames for enhancing the structural details. Di-Stream Neural Network (DSNN) is introduced with the dual-branch EfficientNet-based feature extractor that retrieves both motion and pose features. The weighted Average Fusion method is used to combine pose and motion features to classify suspicious activities using the Simplified Spiking Neural Network (SSNN). The effectiveness of the proposed SED-NET method was evaluated using specificity, accuracy, sensitivity, and F1 score. The proposed SED-NET model attains an accuracy of 98.97% for UCSD Pedestrian and 98.84% for CUHK Avenue datasets. Moreover, the proposed SED-NET improved the overall accuracy by 7.44%, 4.18%, and 2.73% better than DenseNet121, SegAD, and 3DCNN, respectively.},
  archive      = {J_IJCIS},
  author       = {Siva Senthil, D. and Sivarani, T. S.},
  doi          = {10.1007/s44196-025-00766-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {SED-NET: Real-time suspicious event detection via deep learning-based di-stream neural network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hesitant fuzzy $$\beta $$ -covering $$({\mathcal {I}},$$ $${\mathcal {O}})$$ rough set models and applications to multi-attribute decision-making. <em>IJCIS</em>, <em>18</em>(1), 1-29. (<a href='https://doi.org/10.1007/s44196-025-00769-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hesitant fuzzy $$\beta $$ -covering rough set offers stronger representational capabilities than earlier hesitant fuzzy rough sets. Its flexibility makes it more suitable for hesitant fuzzy multi-attribute decision-making (MADM). As a result, it has become a popular research focus in decision analysis and has drawn significant attention from scholars. However, the existing hesitant fuzzy $$\beta $$ -covering rough set based on t-norms cannot handle the overlap and correlation between hesitant information well. Addressing this problem, we propose the hesitant fuzzy overlap function and hesitant fuzzy $$\beta $$ -covering $$({\mathcal {I}},$$ $${\mathcal {O}})$$ rough set (HF $$\beta $$ CIORS) models based on the hesitant fuzzy overlap function. First, we establish the definition of the hesitant overlap function and representable hesitant fuzzy overlap function on a partial order relation. Based on proposed definitions, we provide examples of representable and unrepresentable hesitant fuzzy overlap functions and offer a detailed proof to explain the unrepresentable function. Second, we construct four types of HF $$\beta $$ CIORS models and prove some of its important properties. Thirdly, we integrate the HF $$\beta $$ CIORS models with the TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) method and apply them to solve MADM problems. The validity of the proposed method is demonstrated through a practical application, and its stability and effectiveness are confirmed via sensitivity and comparative analyses. Based on these validations, our method proves effective in addressing MADM problems, offering reliable decision-making support.},
  archive      = {J_IJCIS},
  author       = {Wang, Jingyi and Shao, Songtao and Mao, Xiaoyan and Zhang, Xiaohong},
  doi          = {10.1007/s44196-025-00769-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hesitant fuzzy $$\beta $$ -covering $$({\mathcal {I}},$$ $${\mathcal {O}})$$ rough set models and applications to multi-attribute decision-making},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced hybrid machine learning model for accurate detection of cardiovascular disease. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00771-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular disease (CVD) is one of the foremost reasons behind the death of people worldwide. Prevention and early diagnosis are the only ways to control its progression and onset. Thus, there is an urgent need for a detection model comprising intelligent technologies, including Machine Learning (ML) and deep learning, to predict the future state of an individual suffering from cardiovascular disease by effectively analyzing patient data. This study aims to propose a hybrid model that provides a deep insight into the data under consideration to enhance model accuracy for effectively detecting cardiovascular disease. This current research proposes a hybrid model comprising four stages. In the first stage of the proposed hybrid model, the data imbalance problem is solved using a hybrid sampling technique named Synthetic Minority Oversampling Technique-Edited Nearest Neighbors Rule. In the second stage, the Chi-square is applied as a feature selection method to select the highly relevant features from the records of 1190 with 11 clinical features, curated by combining the 5 most popular datasets, including Long Beach VA, Hungarian, Switzerland, and Statlog (Heart). In the third stage, the preprocessed dataset is passed to a stacking ensemble model comprising three base learners: Random Forest Tree (RFT), K-Nearest Neighbor (K-NN), and AdaBoost classifier and one meta-learner: Logistic Regression (LR), optimized with Grid Search Cross-Validation (GSCV) optimization approach, whose performance is evaluated against individual classifier. In the fourth stage, the performance is evaluated in terms of accuracy, sensitivity, specificity, F1 score, and ROC_AUC score.. The comparative results prove that the proposed hybrid model scored the highest accuracy of 97.8%, 96.15% sensitivity, and 96.75% specificity and 98.6% ROC_AUC score when compared with the existing techniques and models after applying the SMOTE–ENN (for data balancing) and Chi-square (for feature selection) methods for the efficient detection of cardiovascular disease. The implementation results demonstrate that the suggested hybrid model may accurately identify cardiovascular disease among patients. It facilitates the application of robust clinical treatment strategies.},
  archive      = {J_IJCIS},
  author       = {Navita and Mittal, Pooja and Sharma, Yogesh Kumar and Lilhore, Umesh Kumar and Simaiya, Sarita and Saleem, Kashif and Ghith, Ehab Seif},
  doi          = {10.1007/s44196-025-00771-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Advanced hybrid machine learning model for accurate detection of cardiovascular disease},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted hybrid random forest model for significant feature prediction in alzheimer’s disease stages. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00780-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent studies, several machine learning and deep learning prediction models have been proposed for the early detection and classification of various stages of Alzheimer’s Disease (AD). Many years before the actual onset of AD, there occur several structural changes in the brain. These structural brain features can be utilized in learning the disease progression from an early stage of the disease. The various stages of pathology cause mild cognitive impairment (MCI) from normal cognition and AD from normal cognition. This work intends to develop a weighted and hybrid random forest learning model that utilizes a relevant subset of predictors to diagnose the progression of the disease. The conversion from normal cognition to MCI is identified at an early stage of the onset of structural brain changes. The importance of proposed research works lies in more early identification of significant feature that increase disease progression and appropriate interventions greatly improve subjects’ recovery. The Alzheimer’s Disease Neuro Imaging Initiative (ADNI) cross-sectional MRI data were analyzed in this study that utilized brain curvature, grey matter density, white matter density, the volume of cortical and sub-cortical structures, shape of hippocampus, hippocampal subfield volume, Mini-mental state exam (MMSE), Clinical Dementia Rating (CDR), Estimated Total Intracranial Volume, Normalize Whole Brain Volume, and Atlas Scaling Factor for constructing randomized trees and thus predicting the features that cause the progression of disease stages from MCI to Alzheimer’s disease that causes dementia. Based on previous studies, there is a significant shortfall in understanding Alzheimer’s disease progression from pre-MCI stages and the classification of progressive and stable MCI groups. As a consequence of this challenge discussed, whether all the mild cognitively impaired people change to AD cohorts or remain in normal cognition and identification of the structural and functional features remains underexplored. Thus, the proposed Weighted Hybrid Random Forest algorithm (WHBM) utilized the 63 features that comprise the whole brain volume. The most significant and weighted features are derived which segregate 39% of subjects with cognitively progressive MCI and 51% of subjects with normal age-related cognitive decline. This implementation model proved to give robust AD conversion probability and identify significant features with 93% accuracy and 88% sensitivity that are sufficient for future clinical inferences. The optimized model thus resulted in the prediction of disease conversion probability from Mild Cognitive Impairment to AD because of significant structural features that are key-requisite for affected geriatric cohorts.},
  archive      = {J_IJCIS},
  author       = {Rohini, M. and Surendran, D.},
  doi          = {10.1007/s44196-025-00780-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Weighted hybrid random forest model for significant feature prediction in alzheimer’s disease stages},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid android malware detection and classification using deep neural networks. <em>IJCIS</em>, <em>18</em>(1), 1-26. (<a href='https://doi.org/10.1007/s44196-025-00783-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a deep learning-based framework for Android malware detection that addresses critical limitations in existing methods, particularly in handling obfuscation and scalability under rapid mobile app development cycles. Unlike prior approaches, the proposed system integrates a multi-dimensional analysis of Android permissions, intents, and API calls, enabling robust feature extraction even under reverse engineering constraints. Experimental results demonstrate state-of-the-art performance, achieving 98.2% accuracy (a 7.5% improvement over DeepAMD) on a cross-dataset evaluation spanning 15 malware families and 45,000 apps. The framework’s novel architecture enhances explainability by mapping detection outcomes to specific behavioral patterns while rigorous benchmarking across five public datasets (including Drebin, AndroZoo, and VirusShare) mitigates dataset bias and validates generalization. By outperforming existing techniques in accuracy, adaptability, and interpretability, this work advances the practicality of deep learning for real-world Android malware defense in evolving threat landscapes.},
  archive      = {J_IJCIS},
  author       = {Rashid, Muhammad Umar and Qureshi, Shahnawaz and Abid, Abdullah and Alqahtany, Saad Said and Alqazzaz, Ali and ul Hassan, Mahmood and Al Reshan, Mana Saleh and Shaikh, Asadullah},
  doi          = {10.1007/s44196-025-00783-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hybrid android malware detection and classification using deep neural networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Book review: Multicriteria decision-making under conditions of uncertainty: A fuzzy set perspective. john wiley & sons. ISBN: 978–1-119–53,492-1.. <em>IJCIS</em>, <em>18</em>(1), 1-5. (<a href='https://doi.org/10.1007/s44196-025-00784-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This overview is focused on the book reflecting research results on the fundamentals of the theory of multicriteria (multiobjective and multiattribute) decision-making under conditions of uncertainty. The facet of uncertainty is formalized based on a possibilistic (not probabilistic) approach. These results are based on the fuzzy set theory and its fusion with other branches of mathematics of uncertainty. The overview identifies the crucial arguments behind the ultimate need for this theory, reflects the book’s primary objectives, identifies the key possibilities delivered by the presented book's results, and elaborates on real-world problems solved by applying the findings reported in the book. The thorough critical analysis summarizes the advantages and limitations of the main results covered by the book.},
  archive      = {J_IJCIS},
  author       = {Ekel, Petr Iakovlevitch and Libório, Matheus Pereira and Pedrycz, Witold},
  doi          = {10.1007/s44196-025-00784-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Book review: Multicriteria decision-making under conditions of uncertainty: A fuzzy set perspective. john wiley & sons. ISBN: 978–1-119–53,492-1.},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MicrobeNet: An automated approach for microbe organisms prediction using feature fusion and weighted CNN model. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00777-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microbial organisms are everywhere, millions residing within the human body and also cover 60% of the living earth. These microbes can pose significant health risks, causing diseases such as malaria and toxoplasmosis. Toxoplasmosis is notably prevalent, with seroprevalence rates ranging from 3.6 to 84% in an African region, underscoring the necessity for automated microorganism detection techniques. This research work aims to predict the presence of microorganisms in the human body. We propose a novel approach that combines and integrates principal-component analysis, Chi-square, and analysis-of-variance features using a weighted convolutional-neural-network model called MicrobeNet. The results highlight the efficacy of the proposed method, achieving a remarkable 99.97% in accuracy, recall, precision, and F1-score. The experiments use multiple deep and machine learning models to detect ten distinct microbial forms. The results of the proposed model are compared with those of previously published research. Additionally, k-fold cross validation confirms the robustness of these findings. This research significantly advances the field of microbiology by providing a highly accurate method for microorganism identification, facilitating early disease detection and prevention.},
  archive      = {J_IJCIS},
  author       = {Alnowaiser, Khaled},
  doi          = {10.1007/s44196-025-00777-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MicrobeNet: An automated approach for microbe organisms prediction using feature fusion and weighted CNN model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging multi-source data for local government financing vehicles debt risk assessment via random forests. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00778-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local government financing vehicles (LGFVs), in China, are pivotal indirect financing channels for urban development projects. However, the significant debt accumulated by these vehicles presents considerable long-term risks, including challenges to fiscal sustainability, threats to financial system stability, and disruptions to regional economic development. Timely monitoring of LGFV debt risks is essential for enabling effective interventions. This study develops a robust risk evaluation system for LGFVs by leveraging multi-source data and employing the Random Forest (RF) machine learning algorithm. We collected and analyzed a sample of 1584 Chinese LGFVs from a major state-owned bank. Through an examination of the mechanisms underlying LGFV debt risk and a review of relevant literature, we identified seven primary categories and 20 key risk indicators to construct our risk indicator system. After comparing several machine learning algorithms, we selected the RF algorithm to build the LGFV debt risk prediction model due to its superior performance. Our findings emphasize the External Guarantee Ratio, GDP growth rate, and proportion of the tertiary industry as critical risk indicators. The model evaluation demonstrates high accuracy, underscoring its significant potential for practical application. This study contributes to the management of local government debt risks and introduces a novel methodology with potential applicability in other areas of risk management.},
  archive      = {J_IJCIS},
  author       = {Li, Kejia and Chen, Zhen-Song},
  doi          = {10.1007/s44196-025-00778-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Leveraging multi-source data for local government financing vehicles debt risk assessment via random forests},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy decision support system for medical service quality management in hospitals. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00773-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical service quality in hospitals and clinical centres is expected to satisfy the patient’s satisfaction and the high precision diagnosis. Periodic assessment of the medical services increases the quality and the staff efficiency. Such quality assessments are analyzed using sophisticated computing techniques such as fuzzy, genetic algorithms, etc. Therefore, this article introduces a Quality Improvement Method using Fuzzy Decision Support (QIM-FDS) for periodic service enhancements in hospitals. This method acquires the diagnosis, care-taking, and environmental factors validated using the two levels of FDS. The first FDS handles the quality improvement and the second deals with recommendations. From the previous patient suggestions/complaints, the quality improvements are performed such that the varying inputs result in high service recommendations. The first FDS and the overall recommendations (from patients) towards the above considerations are accounted for in the second fuzzification process. This consideration assimilates the service demands and is the highest patient response for retaining the same level. Therefore, the fuzzification performs the different condition verification in the second decision-making. The joint FDS processes focus on delivering high-level improvements towards the considered factors.},
  archive      = {J_IJCIS},
  author       = {Cui, Hongrui and Tan, Qingli},
  doi          = {10.1007/s44196-025-00773-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A fuzzy decision support system for medical service quality management in hospitals},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction and optimization of student grades based on genetic algorithm and graph convolutional neural networks. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00775-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to limited support in registered courses, students frequently struggle to complete their courses in higher education institutions. To combat this, educational systems are incorporating intelligent prediction tools to help students improve their academic performance by predicting their grades. Students' demographic information, past performance in the subject, and course characteristics are some of the factors used by the grade prediction system to foretell how they will do in future. Complexity and non-linearity in the analysis of inter-variable connections pose problems for traditional prediction models. Our solution to these problems is a GGCNN, or Genetic Algorithm with Graph Convolutional Neural Networks. In order to improve the accuracy of predictions, GGCNN examines educational data and finds intricate linkages. Using a graph structure, the graph convolution model emphasizes the interdependencies among academic metrics, course features, and student performance. Relationships and correlations can be better predicted with the use of this dependency metric. Use of the genetic algorithm improves the grade prediction system by optimizing the network and making better use of features. Administrators and teachers alike can find ways to boost their kids' grades through the optimization process. To test how well the system performs on different measures, we utilize the Student Performance Kaggle dataset. This continues until the convergence requirements are satisfied. With Python as its implementation, the system was able to get an accuracy of 0.98% after 100 epochs and 0.97% after 1000 epochs.},
  archive      = {J_IJCIS},
  author       = {Li, Ting},
  doi          = {10.1007/s44196-025-00775-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Prediction and optimization of student grades based on genetic algorithm and graph convolutional neural networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning model leveraging time-series system call data to detect malware attacks in virtual machines. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00781-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Tenant Virtual Machine (TVM) user in the cloud may misuse its computing power to launch malware attack against other tenant VMs, Host OS, Hypervisor, or any other computing devices/resources inside the cloud environment of a Cloud Service Provider. The security solutions deployed within the TVM may not be reliable, as malware can disable them or remain undetected due to its hidden nature. Therefore, security solutions deployed outside the virtual machine are necessary. This research proposes deploying an Intrusion Detection System (IDS) at the Hypervisor layer, utilizing time series system call data and employing a Convolutional Neural Network (CNN) model to accurately detect the presence of malicious (malware) computer programs within virtual machines. The raw VMM system call traces are transformed into novel Time Series System Call patterns and utilized by a deep learning algorithm for training and building the classifier model. A deep learning model, CNN, is used to build the classifier model for detecting intrusions with high accuracy. It is capable of detecting both known and unknown malware. The CNN model is compared with machine learning algorithms for the results and discussions, and it outperforms ML algorithms in terms of intrusion detection accuracy when utilizing novel time series system call data..},
  archive      = {J_IJCIS},
  author       = {Melvin, A. Alfred Raja and Kathrine, Jaspher W. and Jeyabose, Andrew and Cenitta, D.},
  doi          = {10.1007/s44196-025-00781-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A deep learning model leveraging time-series system call data to detect malware attacks in virtual machines},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning for cancer diagnosis in medical images: A compendious study. <em>IJCIS</em>, <em>18</em>(1), 1-46. (<a href='https://doi.org/10.1007/s44196-025-00772-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, cancer stands out as one of the most perilous diseases, caused by the uncontrolled proliferation of cells within the human body. Early detection is paramount to ensuring that patients receive the necessary medical intervention in a timely manner. Recently, deep learning techniques, particularly convolutional neural networks, have proven to be incredibly effective in developing computer-aided diagnosis systems due to their remarkable accuracy in analyzing medical images. However, the process of training these neural networks from scratch is often complex and requires significant computational resources. Transfer learning has emerged as a powerful solution to overcome this challenge. This study examines the fundamental concepts of machine learning and deep learning-based computer-aided diagnostic systems. It underscores the significant role of transfer learning in enhancing diagnostic accuracy. It also illustrates the various transfer learning models employed to diagnose various cancer forms, including skin cancer, brain tumors, breast cancer, lung cancer, leukemia, prostate cancer, bladder cancer, and cervical cancer. This paper summarizes 151 studies conducted in recent years. In the end, the article offers a thorough discussion of the research findings, overall conclusions, and directions for future work.},
  archive      = {J_IJCIS},
  author       = {Kaur, Navreet and Hans, Rahul},
  doi          = {10.1007/s44196-025-00772-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-46},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Transfer learning for cancer diagnosis in medical images: A compendious study},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid method using grey wolf algorithm and genetic algorithm for IoT botnet DDoS attacks detection. <em>IJCIS</em>, <em>18</em>(1), 1-61. (<a href='https://doi.org/10.1007/s44196-025-00774-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a vast network of interconnected physical objects that has improved the conditions for a computer-based physical world and improved efficiency. With the increase in communication in an IoT system, Internet security has decreased, and the most dangerous and sophisticated attacks in the IoT have emerged, i.e., DDoS and Botnet attacks. DDoS attacks are a serious threat to the availability of Internet services, especially since botnets can now be launched by almost anyone. In this situation, the use of an intrusion detection system (IDS) is essential to detect intruders and maintain the security of IoT networks. In this paper, a new IDS is proposed to detect IoT-Botnet DDoS attacks. This IDS is a new three-phase system, the first phase is related to preprocessing on the dataset and the second phase includes a new hybrid method for feature selection using filter and wrapper methods based on the Grey Wolf (GW) algorithm and genetics called GW-GA. In this method, the initial population is randomly selected and then at each stage, feature selection is done by both algorithms simultaneously and the final answer is compared and the best solutions are given as a new population to both algorithms and the third phase includes the use of machine learning and metaheuristic algorithms as classifiers. In the proposed method and to verify the performance, it is evaluated using the large BOT-IoT dataset. The results show that the proposed method significantly reduces the feature and also increases the classification accuracy compared to other methods, and the RF and Bagging algorithms have achieved a maximum recognition accuracy of 0.999. The dimensions of BOT-IoT have been reduced from 46 features to 12.},
  archive      = {J_IJCIS},
  author       = {Maazalahi, Mahdieh and Hosseini, Soodeh},
  doi          = {10.1007/s44196-025-00774-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-61},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel hybrid method using grey wolf algorithm and genetic algorithm for IoT botnet DDoS attacks detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral patterns in micro-lending: Enhancing credit risk assessment with collaborative filtering and federated learning. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00776-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk assessment uses finance-based behavioural patterns for micro-lending purposes and organizations. The repayment behaviour and credit stability patterns are analyzed across varying repayment tenures and financed amounts. Due to limited borrower data and fluctuating financial patterns, micro-lending platforms have substantial hurdles when it comes to effectively evaluating credit risk. This article introduces a Collaborative Filtering Method using Lending Pattern Analysis (CFM-LPA). The proposed method is enhanced through collaborative federated learning, enabling the analysis of these patterns. This approach evaluates the return rate, credit limit, and consumer response behaviours. Federated learning processes one or more of these factors to assess diverse lending patterns. Based on these evaluations, the behavioural factor is updated for each return period, influencing the credit risk for subsequent return periods and supporting the financial stability of micro-lending operations. The model is trained individually on the identified factors, allowing the behavioural factor to be filtered. New credit risks are identified using this filtered factor from the previous return period. These insights help define new behavioural patterns for the specified credit limit. The proposed method enhances risk detection accuracy by 14.03% and improves return rate analysis by 13.28% across financed amounts. The above abstract is also graphically presented.},
  archive      = {J_IJCIS},
  author       = {Aldrees, Asma and Shahab, Sana and Dutta, Ashit Kumar and Ahmad, Waseem and Anjum, Mohd},
  doi          = {10.1007/s44196-025-00776-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Behavioral patterns in micro-lending: Enhancing credit risk assessment with collaborative filtering and federated learning},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSegNet: A multi-view coupled cross-modal attention model for enhanced MRI brain tumor segmentation. <em>IJCIS</em>, <em>18</em>(1), 1-32. (<a href='https://doi.org/10.1007/s44196-025-00787-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor incidence and mortality rates are increasing due to unique location and treatment challenges. Early detection, robust diagnosis, and prompt treatment are crucial for better clinical evaluations. However, traditional neural network-based diagnostic methods often overlook issues such as variation in multimodality information, loss of spatial information, and under-utilization of boundary information. This study presents the Multi-View Coupled Cross-Modal Attention Network (MSegNet), a novel Transformer-based segmentation framework that integrates cross-modal attention mechanisms and a multi-view architecture. MSegNet is designed to exploit multimodal MRI data’s spatial and depth dimensions, effectively capturing nuanced intermodal relationships and modeling long-range dependencies. The proposed framework also employs three data augmentation methods, which help prevent overfitting and improve the performance of segmentation network training, enhancing the model’s robustness and generalizability. The proposed model is validated using BraTS2019, BraTS2020 and Figshate brain datasets and is compared against three state-of-the-art 3D segmentation networks. Extensive experiments, including ablation studies and hyperparameter sensitivity analyses, highlight MSegNet’s robust performance. The dice scores for the whole tumor (WT), tumor core (TC) and enhancing tumor (ET) regions improved by 13. 96%, 12. 39%, and 11. 83%, respectively, while the Hausdorff distances were reduced by 3.64 mm, 2.98 mm, and 14.72 mm. These results demonstrate the model’s efficacy in enhancing segmentation precision, making it a valuable tool for clinical diagnosis and treatment planning.},
  archive      = {J_IJCIS},
  author       = {Wang, Yu and Xu, Juan and Guan, Yucheng and Ahmad, Faizan and Mahmood, Tariq and Rehman, Amjad},
  doi          = {10.1007/s44196-025-00787-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MSegNet: A multi-view coupled cross-modal attention model for enhanced MRI brain tumor segmentation},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual feature-based intrusion detection system for IoT network security. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00790-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has enabled widespread connectivity of smart devices but remains susceptible to cyber intrusions. In this research, a novel dual feature optimization using deep learning network for intrusion Detection (FOUND) technique has been proposed for enhancing security in IoT environments. The proposed method utilizes the bald eagle search (BES) algorithm and butterfly optimization algorithm (BOA) to capture both flow and packet level features to enhance the accuracy of the intrusion detection process. Moreover, a multi-head attention-based bidirectional gated recurrent unit (MHA-BiGRU) is utilized to classify Attack and Non-Attack classes with high precision. The efficacy of the suggested approach is measured utilizing metrics including recall (RC), accuracy, precision (PR), and f1score (F1S). Experimental outcomes utilizing BoT-IoT and UNSW-NB15 datasets demonstrate greater accuracy over existing models. In BoT-IoT, the accuracy of the FOUND approach is 1.5%, 1.1%, and 2.5% increase compared to existing GRU, RNN, and GCN methods, respectively.},
  archive      = {J_IJCIS},
  author       = {Biju, A. and Franklin, S. Wilfred},
  doi          = {10.1007/s44196-025-00790-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Dual feature-based intrusion detection system for IoT network security},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved transformer-based model for urban pedestrian detection. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-025-00791-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection is a crucial task in computer vision, applicable in object tracking, video surveillance, and autonomous driving. Recent years have witnessed substantial advancements in pedestrian detection due to the fast evolution of deep learning in object detection. Nonetheless, obstacles such as inadequate detection accuracy persist, mostly because of varied pedestrian postures and intricate environments. This study proposes the RT-DETR-improved model to overcome these issues based on the real-time detection transformer (RT-DETR). First, we incorporate the high-low frequency (HiLo) attention into the encoder, therefore enhancing the model’s detection performance. Furthermore, we present a nonlinear feature fusion module that fuses information from various feature scales and contexts more successfully. We also introduce a novel loss function, InnerMPDIoU, to enhance detection efficacy in congested environments. To evaluate our model’s performance, extensive experiments are conducted on the CityPersons dataset. Compared to the baseline model, the RT-DETR-improved model attains a 4.2% enhancement in mAP50, a 2.0% improvement in mAP, a 2.2% rise in accuracy, and a 3.1% gain in recall. The results demonstrate that the proposed method exhibits superior detection accuracy and robustness.},
  archive      = {J_IJCIS},
  author       = {Wu, Tianyong and Li, Xiang and Dong, Qiuxuan},
  doi          = {10.1007/s44196-025-00791-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An improved transformer-based model for urban pedestrian detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TraitBertGCN: Personality trait prediction using BertGCN with data fusion technique. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00792-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personality prediction via different techniques is an established and trending topic in psychology. The advancement of machine learning algorithms in multiple fields also attracted the attention of Automatic Personality Prediction (APP). This research proposes a novel TraitBertGCN method with a data fusion technique for predicting personality traits. Initially, this work integrates a pre-trained language model, Bidirectional Encoder Representations from Transformers (BERT), with a three-layer Graph Convolutional Network (GCN) to leverage large-scale language understanding and graph-based learning for personality prediction. This study fuses the two datasets (essays and myPersonality) to overcome the bias and generalize the model across different domains. We fine-tuned our TraitBertGCN model on the fused dataset and then evaluated it on both datasets individually to assess its adaptability and accuracy in varied contexts. We compared the proposed model’s results with previous studies; our model achieved better performance in personality trait prediction across multiple datasets, with an average accuracy of 77.42% on the essays dataset and 87.59% on the myPersonality dataset.},
  archive      = {J_IJCIS},
  author       = {Waqas, Muhammad and Zhang, Fengli and Laghari, Asif Ali and Almadhor, Ahmad and Petrinec, Filip and Iqbal, Asif and Khalil, Mian Muhammad Yasir},
  doi          = {10.1007/s44196-025-00792-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {TraitBertGCN: Personality trait prediction using BertGCN with data fusion technique},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid differential evolutionary algorithm for solving multi-objective distributed permutation flow-shop scheduling problem. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00793-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Distributed Permutation Flow-Shop Scheduling Problem (DPFSP) is a classic issue in distributed scheduling that involves job allocation and processing order within a factory, and it is known to be NP-hard. Numerous researchers have proposed various intelligent optimization algorithms to address the DPFSP; however, there are fewer studies related to the multi-objective DPFSP problem, and the algorithms for solving this problem also suffer from poor solution quality and tend to fall into local optimization and so on. To tackle the multi-objective DPFSP, this paper proposes a novel hybrid differential evolutionary algorithm aimed at minimizing both the maximum completion time and total delay time. In this algorithm, Bernoulli chaotic mapping is applied during the population initialization process to enhance the diversity of the initial population. Additionally, an adaptive mutation factor and crossover rate are designed to balance the global and local search capabilities of the algorithm. Furthermore, a novel selection strategy is constructed based on the NEH algorithm, specular reflection learning, and Pareto dominance relation to improve the quality of the solution set when solving instances of varying sizes. This strategy enhances the algorithm's optimization ability and helps it escape local optima. The effectiveness and superiority of the proposed algorithm are verified through 24 instances of different sizes. The results demonstrate that the proposed algorithm outperforms other improved algorithms in terms of convergence, and the uniformity and diversity of the solution set, making it an effective solution for the multi-objective distributed permutation flow-shop scheduling problem.},
  archive      = {J_IJCIS},
  author       = {Du, Xinzhe and Zhou, Yanping},
  doi          = {10.1007/s44196-025-00793-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel hybrid differential evolutionary algorithm for solving multi-objective distributed permutation flow-shop scheduling problem},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on cascade propagation of collaborative innovation risks in industrial clusters considering entities heterogeneity. <em>IJCIS</em>, <em>18</em>(1), 1-17. (<a href='https://doi.org/10.1007/s44196-025-00795-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study is to effectively mitigate the cascading propagation of collaborative innovation risks within industrial clusters and bolster the stability of their innovation networks. Drawing upon the cascade failure theory in complex networks, we employ the BA scale-free network model to construct an industrial cluster innovation network. We develop a cascade propagation model for collaborative innovation risk, addressing three dimensions: risk load, risk capacity, and load redistribution following node failures. To enhance the model, we propose a risk load distribution strategy that considers the heterogeneity among innovation entities, focusing on the similarity degree, importance degree, and cooperation degree of neighboring innovative entities. Through simulation experiments, we demonstrate that the integrated allocation strategy significantly improves the resistance to destruction of industrial cluster innovation networks. However, under intentional attacks, the resilience of these networks remains relatively weak. Further investigation reveals that the risk load capacity enhanced by the integrated allocation strategy can somewhat fortify the resistance of industrial cluster innovation networks to such attacks. The findings offer valuable insights for risk management and stability enhancement in industrial cluster innovation networks.},
  archive      = {J_IJCIS},
  author       = {Shi, Xiaowei and Wang, Jifa and Wang, Yang},
  doi          = {10.1007/s44196-025-00795-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Research on cascade propagation of collaborative innovation risks in industrial clusters considering entities heterogeneity},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Better pseudo-labeling for semi-supervised domain generalization in medical magnetic resonance image segmentation. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00786-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance image (MRI) is the primary diagnostic test used clinically for the diagnosis and assessment of a wide range of diseases. In recent years, many studies have employed artificial intelligence techniques for MRI segmentation. Deep learning methods have demonstrated potential to enhance segmentation performance. However, they still face two challenges: annotation scarcity and domain shift. The annotation of MRI is both challenging and costly, and well-annotated datasets are scarce and valuable. Moreover, due to variations in MRI machines, ensuring the independence and identical distribution between model training data and real-world data is difficult, which may lead to noisy model predictions and weak generalization ability. We aim to address the challenges through a multi-pronged approach. First, we propose a method that integrates confidence and uncertainty for generating reliable pseudo-labels. Second, we introduce a consistency learning method that employs self-perturbation at both the image and feature levels to encourage the learning of more generalized feature representations. Finally, we optimize pseudo-labels end-to-end with the teacher–student framework. To evaluate the effectiveness of our method, we conduct experiments on six different MRI segmentation datasets. The results showed that our method was superior to the existing methods in DSC, ASD and HD95 metrics. In addition, we evaluated the quality and quantity of the generated pseudo-labels, and the results showed that our method generated better pseudo-labels than other methods. Overall, our proposed method shows promising potential in assisting clinicians in practical applications.},
  archive      = {J_IJCIS},
  author       = {Hu, Liangqing and Meng, Zuqiang and Tan, Chaohong and Zhou, Yumin},
  doi          = {10.1007/s44196-025-00786-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Better pseudo-labeling for semi-supervised domain generalization in medical magnetic resonance image segmentation},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A greedy constructive heuristic for solving the team orienteering problem with variable time windows. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00797-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orienteering problems are a subclass of routing problems, in which a selection of the set of nodes should be made for visiting, due to route length restrictions. These nodes can also impose time-window constraints, which can be variable if they are defined by a spread process, which behavior can be modified. The problem including all these features is the Team Orienteering Problem with Variable Time Windows (TOPVTW). In this paper, deterministic and randomized greedy constructive heuristic schemes are developed for solving the problem, along with the definition of some metrics that guide the constructive processes. One of the heuristics is combined with an existing exact mixed integer programming model to improve the outputs. All the solving strategies proposed are tested with instances representing the spread of a wildfire in a landscape, demonstrating improvements in performance when compared with existing exact solving methodologies.},
  archive      = {J_IJCIS},
  author       = {Granda, Bibiana and Vitoriano, Begoña},
  doi          = {10.1007/s44196-025-00797-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A greedy constructive heuristic for solving the team orienteering problem with variable time windows},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instance assignment coverage feature for operation control of SAT solver. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00798-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Conflict-Driven Clause Learning (CDCL) framework integrates multiple heuristic components to solve Boolean satisfiability (SAT) problems through synergistic cooperation. Understanding the characteristics of these components in the underlying architecture provides crucial insights for designing corresponding methods to enhance the performance of CDCL solvers. Although numerous studies from diverse perspectives have been conducted, there remains a need to develop efficient methods and algorithms to meet the requirements for enhancing the performance efficiency of SAT solving. In this paper, we introduced two fundamental innovations: deep restart, a strategic reset mechanism that clears variable activity states while preserving learned clauses and making phase randomization, and assignment coverage time (CoverT), a novel metric quantifying the minimum—conflict count required to assign all variables at least once during search exploration. The CoverT metric provided unique insight into the characteristics of the instance structure, allowing dynamic adaptation of branching heuristics in our proposed Deep Restart-Enhanced Conflict-Driven Clause Learning algorithm framework (DR-CDCL). Experimental validation in 2021–2023 SAT Competition benchmarks demonstrated statistically significant improvements: Notably, the performance trade-off analysis revealed that while deep restart enhances solution diversity for satisfiable instances, it introduced a 2.1% overhead on unsatisfiable proofs due to clause learning pattern disruption, a phenomenon requiring further investigation. This work advances solver architecture design by establishing formal connections between exploratory search patterns and instance structural complexity. The implemented solution prototype and benchmark data are publicly available to facilitate reproducibility.},
  archive      = {J_IJCIS},
  author       = {Li, Zhihui and Chen, Shuwei and Wu, Guanfeng and Xu, Yang},
  doi          = {10.1007/s44196-025-00798-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Instance assignment coverage feature for operation control of SAT solver},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of machine learning algorithms for real-time gallbladder stone identification from ultrasound images in clinical decision support systems. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00740-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global epidemiology of gallstones in the twenty-first century affects millions of individuals, and ultrasound diagnostics effectively assess gallbladder size and function and detect abnormalities. This study collected datasets from local hospitals and reliable online sources for analysis using advanced CV/IP tools and WEKA. Image preprocessing techniques, including cropping, resizing, and grayscale conversion, were applied to 90 ultrasound images, extracting 600 ROIs with 21 features spanning binary, histogram, and texture attributes. The dataset was divided into balanced training and validation subsets, and supervised learning algorithms were optimized via cross-validation and grid search. Circular patterns were processed iteratively, with specific dimensions (512 × 512 for width/height, 32 × 32 for radius/blur, 128 × 128 for columns/rows). The performance of various machine learning classifiers was evaluated using accuracy, precision, recall, F1 score, AUC-ROC, MCC, Kappa GDR, and Dice Index, ensuring strong classification of normal and abnormal samples. The random forest (RF) classifier achieved the highest performance with an accuracy of 96.33%, followed by the MLP and Logit Boost classifiers with 95.67% and 95.40% accuracy rates, respectively. The RF model also exhibited the highest precision (0.9542), recall (0.9732), F1 score (0.9636), and a Dice Index (0.9649) with an MCC of 0.925, ROC area of 0.988, Kappa (0.921), and specificity of 95.34%-indicating its strong ability to balance true positives and negatives while minimizing misclassifications. The MLP classifier also performed well with a precision of 0.9477, a recall of 0.9665, and an F1 score of 0.957, while Logit Boost had similar results with a precision of 0.9411 and a recall of 0.9665. Other classifiers, such as the Bayes Net and J48 classifiers, showed slightly lower performance with accuracy rates of 94.67% but still exhibited good precision and recall, making them viable alternatives. This study highlights that the RF classifier achieved the highest superiority among other models in detecting gallbladder stones.},
  archive      = {J_IJCIS},
  author       = {Hong, Chen and Zafar, Imran and Ayaz, Muhammad Mazhar and Kanwal, Rimsha and Kanwal, Faheem and Dauelbait, Musaab and Bourhia, Mohammed and Jardan, Yousef A. Bin},
  doi          = {10.1007/s44196-025-00740-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Analysis of machine learning algorithms for real-time gallbladder stone identification from ultrasound images in clinical decision support systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: A two-way crossed effects fuzzy panel linear regression model. <em>IJCIS</em>, <em>18</em>(1), 1-2. (<a href='https://doi.org/10.1007/s44196-025-00808-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Hesamian, Gholamreza and Johannssen, Arne},
  doi          = {10.1007/s44196-025-00808-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: A two-way crossed effects fuzzy panel linear regression model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced YOLOv8 for efficient parcel identification in disordered logistics environments. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-025-00794-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate parcel identification in disordered logistics environments poses significant challenges due to varying package sizes, materials, and orientations. This study presents an improved YOLOv8-Efficiency algorithm tailored for such complex scenarios. The proposed algorithm introduces the C2f-OR module to reduce parameters and computation, the Conv-Ghost module for efficient feature extraction, and the HIoU loss function to enhance identification accuracy. By constructing a dataset of 4689 photos, experiments demonstrate the algorithm's effectiveness, achieving a 93.2% mAP, a 1.6% recall rate improvement, and a significant reduction in computational complexity (9.9% decrease in FLOPs). This work provides a robust solution for real-time parcel identification in disordered logistics, facilitating automation and efficiency in logistics operations.},
  archive      = {J_IJCIS},
  author       = {Yu, Han and Fengshou, Zhang and Gaoshuai, Zhuang and Yuanhao, Qu and Aohui, He and Qingyang, Duan},
  doi          = {10.1007/s44196-025-00794-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced YOLOv8 for efficient parcel identification in disordered logistics environments},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-scale spatial refinement graph convolutional network for skeleton-based action recognition. <em>IJCIS</em>, <em>18</em>(1), 1-17. (<a href='https://doi.org/10.1007/s44196-025-00802-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In skeleton-based action recognition, abstracting the human body to skeletal representations often results in the loss of crucial information, which may result in misclassification of similar actions. To address this issue, we propose a Cross-scale Spatial Refinement Graph Convolutional Network (CSR-GCN), which aims to improve action recognition accuracy by effectively capturing fine-grained features of skeleton sequences. In detail, we introduce an Attention-based Graph Pooling (AGP) module and a Cross-scale Feature Aggregation (CFA) module. The AGP module uses graph pooling to construct multi-scale skeletal sub-graphs, capturing implicit joint relationships and preserving crucial motion details. It retains global motion information while emphasizing local joint interactions, which enables a better understanding of dynamic changes in complex actions. Furthermore, the CFA module selectively integrates features from different spatial scales, enhancing feature distinctiveness while balancing global motion and local details. This multi-scale refinement of skeletal sequence representations, thereby capturing subtle dynamic changes in actions more precisely and enhancing the ability of the model to recognize and classify complex movement patterns. Finally, we validate the effectiveness of our method on three large-scale datasets, achieving superior accuracy compared to other state-of-the-art methods.},
  archive      = {J_IJCIS},
  author       = {Ke, Chengyuan and Liu, Sheng and Ke, Zhenghao and Feng, Yuan and Chen, Shengyong},
  doi          = {10.1007/s44196-025-00802-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Cross-scale spatial refinement graph convolutional network for skeleton-based action recognition},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GINSER: Geographic information system based optimal route recommendation via optimized faster R-CNN. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00805-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion and accident-prone zones present significant challenges to urban transportation by causing delays, pollution, and safety hazards. However, the existing techniques do not provide real-time recommendations for minimizing congestion leaving travelers and planners with suboptimal solutions. These systems often fail to integrate accident-prone zone detection with traffic congestion management and cannot provide a real time congestion-free route. This research aims to address these challenges by developing a geographic information system (GIS)-based optimal route recommendation model GINSER using advanced deep learning techniques. The primary objectives are to detect accident-prone zones, classify traffic congestion levels, and recommend efficient routes using GIS. The proposed GINSER model utilized CCTV camera as an input image are preprocessed using an adaptive Gaussian bilateral filter (AGBF) to remove noise and enhance image quality. Faster R-CNN is used for identifying and localizing objects in accident-prone areas. Particle swarm optimization (PSO) is used to hyperparameter tuning for improving an accuracy. A CNN-BiGRU model is utilized to classify traffic congestion levels into low, moderate, high, and congestion-free categories. GIS analyzes spatial data and traffic patterns to recommend the most efficient and congestion-free routes. The effectiveness of the proposed GINSER approach was assessed utilizing F1 score, accuracy, precision, recall, and specificity. The noise-free images using AGBF effectively enhances image quality by reducing noise leading to improved classification accuracy. PSO is utilized for hyperparameter tuning achieving a high accuracy of 95.24%. The GINSER model achieved a classification accuracy of 99.16%. The GINSER improved overall accuracy by 3.90%, 6.71%, 4.13%, and 0.70% better than TSANet, TCEVis, Ising-traffic, and AID, respectively. The proposed GINSER model offers a novel solution to urban transportation challenges by integrating deep learning and GIS technologies. Its ability to detect accident-prone zones classify congestion levels and recommend optimal routes ensures safer and more efficient mobility.},
  archive      = {J_IJCIS},
  author       = {Anitha Selvasofia, S. D. and SivaSankari, B. and Dinesh, R. and Muthukumaran, N.},
  doi          = {10.1007/s44196-025-00805-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {GINSER: Geographic information system based optimal route recommendation via optimized faster R-CNN},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: MSegNet: A multi-view coupled cross-modal attention model for enhanced MRI brain tumor segmentation. <em>IJCIS</em>, <em>18</em>(1), 1-2. (<a href='https://doi.org/10.1007/s44196-025-00807-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Wang, Yu and Xu, Juan and Guan, Yucheng and Ahmad, Faizan and Mahmood, Tariq and Rehman, Amjad},
  doi          = {10.1007/s44196-025-00807-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: MSegNet: A multi-view coupled cross-modal attention model for enhanced MRI brain tumor segmentation},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent decision support system for selecting optimal AI-powered assistive technology for individuals with disabilities. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00770-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel extension of conventional fuzzy sets in this paper: called trimorphic fuzzy sets. As per our research, trimorphic fuzzy sets which exhibit greater capability than intuitionistic fuzzy sets, picture fuzzy sets and bipolar fuzzy sets, present a viable approach to address ambiguity and uncertainty in decision-making scenarios. We present a complete characterization of trimorphic fuzzy sets, discuss their properties, and consider applications to real-world decision-making scenarios. We also present a case study to further highlight the practical applications of trimorphic fuzzy sets. We look into a few aggregation strategies for trimorphic fuzzy data in this work. We create the MCDM method using trimorphic fuzzy aggregation operators to help people with disabilities choose AI-Powered Assistive Technologies. We have also presented the extended TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) method with trimorphic fuzzy numbers. A numerical example for selection of AI-Powered Assistive Technologies using TOPSIS method is also provided.},
  archive      = {J_IJCIS},
  author       = {Minhaj and Muneeza and Khan, Asghar and Khishe, Mohammad and Gumaei, Abdu H. and Alzanin, Samah M. and Alkhamees, Bader Fahad and Ashraf, Shahzaib},
  doi          = {10.1007/s44196-025-00770-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An intelligent decision support system for selecting optimal AI-powered assistive technology for individuals with disabilities},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TrioConvTomatoNet-BiLSTM: An efficient framework for the classification of tomato leaf diseases in real time complex background images. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00788-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tomatoes are the most valuable vegetable worldwide that suffer from leaf diseases, which affect long-term tomato protection. So, to protect the tomato plants from the leaf diseases, it is essential to perform appropriate control measures through early and accurate categorization of leaf diseases. Recently, automated deep learning-based methods, including convolutional neural networks (CNNs), guaranteed accurate and timely classification of tomato leaf diseases. However, CNNs primarily capture local context features within a limited receptive field, making them effective for uniform background images. To handle complex background images, utilizing local and global context features is essential for accurate classification. To do so, it is essential to hybrid CNN architecture with other deep learning modules. This work suggests the TrioConvTomatoNet-BiLSTM framework, a hybridization of CNN architecture named TrioConvTomatoNet with a sequence module named bidirectional long short-term memory (BiLSTM). The proposed framework integrated both local and global context features for the precise classification of images with complex backgrounds. As a result, the proposed framework achieves remarkable accuracy of 99.65%, 98.83%, and 99.20% in classifying tomato leaf disease images with non-uniform, synthetic, and real-time complex backgrounds against the TrioConvTomatoNet and TrioConvTomatoNet-LSTM frameworks. Despite the fact that it requires a lesser number of training parameters and attained maximum accuracy over other existing hybrid approaches, expresses its superiority, robustness, and practical applicability. These features highlight the potential of the proposed framework in the emerging field of smart agriculture by enabling smartphone-based classification of tomato leaf diseases with real-life scenarios.},
  archive      = {J_IJCIS},
  author       = {Ledbin Vini, S. and Rathika, P.},
  doi          = {10.1007/s44196-025-00788-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {TrioConvTomatoNet-BiLSTM: An efficient framework for the classification of tomato leaf diseases in real time complex background images},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of renewable energies based on circular bipolar complex intuitionistic fuzzy linguistic information with frank power aggregation operators and MABAC model. <em>IJCIS</em>, <em>18</em>(1), 1-40. (<a href='https://doi.org/10.1007/s44196-025-00800-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy sets and bipolar fuzzy sets are two different ideas, used for the assessment of opinions because the intuitionistic fuzzy sets contain the membership function and non-membership function, but the bipolar fuzzy set describes opinions under two oppositional directions with the positive membership function and negative membership function. This paper develops the circular bipolar complex intuitionistic fuzzy linguistic (Cir-BCIFL) set theory, which is an extension of the numerous existing models, such as fuzzy sets, intuitionistic fuzzy sets, bipolar fuzzy sets, linguistic sets, complex fuzzy sets, and circular intuitionistic fuzzy sets to cope with vague and complex information. In a decision-making scenario, Cir-BCIFL set theory is considered a massive prominent and efficient tool than other existing techniques. Therefore, for the construction of the power aggregation operators, the operational laws based on algebraic and Frank norms for the Cir-BCIFL set are proposed. In this paper, we also derive the theory of Cir-BCIFL Frank power averaging operator, Cir-BCIFL Frank power weighted averaging operator, Cir-BCIFL Frank power geometric operator, and Cir-BCIFL Frank power weighted geometric operator with their basic properties, such as idempotency, monotonicity, and boundedness. Then a multi-attribute border approximation area comparison (MABAC) approach is proposed based on the developed theory. Renewable energy is the form of energy, which is formed or produced from natural and genuine resources that are continuously inexhaustible or replenished. This application goals to assess renewable energy in the European Union to evaluate the most prominent types for their usage in the best and worst conditions. Thus, to deliberate the rationality and efficiency of the designed model, we explain and discuss how to solve numerical problems related to renewable energy for choosing the best way of industrialization with the help of a multi-attribute decision-making model. Next, we indicate how the contribution of the parameters in our designed technique affects the decision-making results. Finally, to exhibit the worth of the initiated theory, the obtained results are compared with the existing techniques.},
  archive      = {J_IJCIS},
  author       = {Ali, Zeeshan and Yang, Miin-Shen},
  doi          = {10.1007/s44196-025-00800-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-40},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Analysis of renewable energies based on circular bipolar complex intuitionistic fuzzy linguistic information with frank power aggregation operators and MABAC model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DEANE: Context-aware dual-craft graph contrastive learning for enhanced extractive question answering. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00801-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extractive Question Answering (EQA) involves extracting accurate answer spans from a background passage in response to a given question. In recent years, there has been significant interest in leveraging Pre-trained Language Models (PLMs) and Graph Convolutional Networks (GCNs) to address EQA tasks. PLMs usually function as context encoders, while GCNs are employed to capture latent semantic relationships between answer spans and the passage/question. This combined approach has shown promise, yielding notable outcomes in EQA performance. However, current graph-based methods encounter a challenge where the graph structure is predefined without sufficient justification. This graph ambiguity can potentially lead to error propagation within the subsequent graph encoder. To alleviate this issue, this paper introduces Dual-craft basEd grAph coNtrastive lEarning (DEANE) for EQA, where the graph structure and node features are context-aware and data-driven. Initially, the passage and question are represented as a connected graph. Subsequently, the adaptive augmentation strategy is introduced to generate two distinct views of the original graph via reparameterization networks, where important graph edges and node features are prioritized. Finally, a multi-view contrastive loss is leveraged to learn latent representations from augmented graphs. Empirically, our method outperforms existing graph-based approaches on six well-established EQA benchmarks. Ablation studies further demonstrate the effectiveness of the proposed approach in mitigating structural ambiguity, enhancing encoder flexibility, and improving model performance through multi-view data integration.},
  archive      = {J_IJCIS},
  author       = {Ye, Dongfen and Zhou, Jianqiang and Huang, Gang},
  doi          = {10.1007/s44196-025-00801-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {DEANE: Context-aware dual-craft graph contrastive learning for enhanced extractive question answering},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced deep learning-based optimization model for the coverage optimization in wireless sensor networks. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00803-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key component of wireless sensor networks (WSN) is optimal coverage. For WSN to have network lifetime and optimal resource utilization, maximum coverage must be guaranteed. The unequal distribution of sensor nodes in densely populated regions contributes to the build-up of network coverage. This research suggests a revolutionary intelligent deep learning-based optimization approach for WSN coverage optimization to tackle this problem. Here, the optimal network coverage of WSN is performed by the novel enhanced deep Q-network (EDQN) algorithm, where the parameters of DQN are tuned by nature inspired optimization algorithm called hippopotamus optimization (HO) with the intention of attaining the fitness function. In order to maximize coverage, the node position is changed in the developed methodology to represent the spatial properties of the network. Along with lowering latency, the increased coverage also increases throughput and network longevity. The outcome of several network coverage optimization trials is computed, and the EDQN-HO’s impact on network coverage optimization is also determined by adjusting the parameters. The network coverage optimization studies’ simulated findings demonstrate that the suggested EDQN-HO may be effectively utilized in a variety of settings. The proposed EDQN-HO for the WSN coverage model returns superior outcomes with 18.31%, 78.95%, 10.65%, 87.5%, 83.33%, and 38.20% than the existing methods in terms of coverage rate, energy consumption, computing time, positioning error, network lifetime, and average moving distance respectively.},
  archive      = {J_IJCIS},
  author       = {Kumar, S. Praveen and Nagendranath, M. V. S. S. and Alsamri, Jamal and Ebad, Shouki A.},
  doi          = {10.1007/s44196-025-00803-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced deep learning-based optimization model for the coverage optimization in wireless sensor networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedMEM: Adaptive personalized federated learning framework for heterogeneous mobile edge environments. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00814-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of the Internet of Things (IoT) and communication technologies, edge devices have become more diverse. This diversity has increased the computational load on these systems and led to differences between devices. In mobile edge computing, variations in communication and computing resources can prevent some devices from updating models quickly. This delay affects overall performance. In addition, in federated learning, data that is not independently and identically distributed (non-IID) makes it hard for clients to maintain personalized models.To address these issues, this paper introduces a personalized federated learning framework. This framework enhances the resource allocation optimization algorithm by dynamically adjusting the depth of model inference and the bandwidth allocation strategy, which assists devices with limited computational capabilities in completing inference tasks promptly. Furthermore, it divide the client models into global and personalized layers. Only the global layers are combined, which helps manage the diversity in data distributions. Simulation results show that the proposed FedMEM method is superior to other state-of-the-art methods, and can drastically reduce system latency.},
  archive      = {J_IJCIS},
  author       = {Ximing, Chen and Xilong, He and Du, Cheng and Tiejun, Wu and Qingyu, Tian and Rongrong, Chen and Jing, Qiu},
  doi          = {10.1007/s44196-025-00814-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {FedMEM: Adaptive personalized federated learning framework for heterogeneous mobile edge environments},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic dataset generation method for object detection. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-025-00817-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the high construction cost of datasets for object detection, particularly in industrial application scenarios where sufficient sample images cannot be obtained from the Internet due to the specialized nature and diversity of objects and their working environments, this paper proposes a method to automatically generate synthetic datasets and train object detection models on them. First, 3D models of the target devices are created and rendered to ensure that the synthetic images exhibit realistic texture and detail. Next, a simulation environment is constructed and the 3D models are integrated into this environment using global domain randomization techniques. Finally, computer graphics methods are applied to automatically annotate target objects in the synthetic images. This approach effectively reduces the cost of data acquisition while maintaining the detection accuracy of the models. Several mainstream object detection models, including Faster R-CNN, SSD, and YOLO, are trained on synthetic datasets of anti-vibration dampers. Experimental results on real-world images demonstrate that models trained on synthetic data achieve relatively high accuracy. Furthermore, fine-tuning these models with a very small number of real images significantly enhances their performance. In addition, the models exhibit robustness against interference and occlusion.},
  archive      = {J_IJCIS},
  author       = {Zhou, Ningning and Li, Tong},
  doi          = {10.1007/s44196-025-00817-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Synthetic dataset generation method for object detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Author correction: Analysis of machine learning algorithms for real-time gallbladder stone identification from ultrasound images in clinical decision support systems. <em>IJCIS</em>, <em>18</em>(1), 1-2. (<a href='https://doi.org/10.1007/s44196-025-00826-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Chen, Hong and Zafar, Imran and Ayaz, Muhammad Mazhar and Kanwal, Rimsha and Kanwal, Faheem and Dauelbait, Musaab and Bourhia, Mohammed and Jardan, Yousef A. Bin},
  doi          = {10.1007/s44196-025-00826-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Author correction: Analysis of machine learning algorithms for real-time gallbladder stone identification from ultrasound images in clinical decision support systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-dataset analysis of language models for generalised multi-label review note distribution in animated productions. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00785-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the production of an animated film, supervisors and directors hold daily meetings to evaluate in-progress material. Over the course of the several years it takes to complete a film, thousands of text notes outlining required fixes are generated. These notes are manually allocated to various departments for resolution. However, as with any manual process, a significant number of notes are either delayed, miss-assigned or overlooked entirely, which can negatively impact the final quality of the film. This paper investigates the performance of various methods for automating the distribution of review notes across relevant departments using datasets from multiple films produced by an animation studio in Madrid, Spain. Since each note can belong to multiple departments, the task is posed as a multi-label classification problem. The analysis and comparison of the results obtained with datasets from three different films, focusing on generalisation, provides critical insights for any Animation Studio evaluating the use of these methods in their process. The methods leverage Large Language Models (LLMs), including encoder-only models such as BERT and decoder-only models like Llama 2. Fine-tuning with QLoRA and in-context learning techniques were applied and evaluated across all datasets, and a cross-dataset analysis is presented. The fine-tuned encoder-only model achieved an F1-score of 0.98 for notes directed to the Animation department. Training was carried out locally on an RTX-3090 GPU, completing it in less than 30 min.},
  archive      = {J_IJCIS},
  author       = {Garcés, Diego and Santos, Matilde and Fernández-Llorca, David},
  doi          = {10.1007/s44196-025-00785-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Cross-dataset analysis of language models for generalised multi-label review note distribution in animated productions},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid meta-heuristic algorithm for optimum micro-robotic position control with PID controller. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00799-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper aims to propose a novel hybrid algorithm, where the Arithmetic Optimization Algorithm (AOA) and Rat Swarm Optimization (RSO) are employed for the proportional-integral-derivative (PID) controller to control the position of a micro-robotics system. In the algorithm proposed, we combine the exploratory mechanisms of AOA with RSO's exploitative behaviors. The proposed algorithm is employed for identifying the PID controller optimal parameters considering six different objective functions. Using CEC 2017 benchmark functions, the proposed hybrid is evaluated, and these functions’ performance is compared with the existing multiple algorithms. The statistical results are compared with the AOA, Jellyfish Search Optimization, and Harries Hawk Optimization algorithm for identifying the optimal PID controller settings considering multiple fitness functions. We consider performance indicators like PID controller parameters, rise time, settling time, and fitness values. The fetched simulation results revealed that, among all investigated fitness functions, the developed controller based on HAOARSO is the most effective algorithm for delivering global optimal solutions with less settling time and rise time, enabling the implementation on such optimization issues. Finally, the validation via MATLAB/Simulink simulations underscores the efficacy of the proposed algorithm.},
  archive      = {J_IJCIS},
  author       = {Baihan, Abdullah and Ghith, Ehab and Garg, Harish and Mirjalili, Seyedali and Izci, Davut and Rashdan, Mostafa and Salman, Mohammad and Saleem, Kashif},
  doi          = {10.1007/s44196-025-00799-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A hybrid meta-heuristic algorithm for optimum micro-robotic position control with PID controller},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social network analysis: A novel paradigm for improving community detection. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00812-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social network analysis has become increasingly important across a wide range of fields, offering valuable insights into complex systems of interconnected entities. One of the fundamental challenges in this field is the community detection problem, which involves identifying groups within networks. Multiple algorithms have been proposed, exploring new approaches to finding solutions for cohesive partitions of the graph. One of the most considered philosophies when defining this type of technique is the use of the graph’s adjacency matrix as input and the consideration of modularity as the function to be optimized. We propose an enhancement to this approach to community detection by incorporating high-order relationships between nodes, allowing for a more comprehensive capture of network structure. By modifying the algorithm’s input, our method improves community detection accuracy. Moreover, our proposed approach is universal, applicable to any algorithm that utilizes a matrix as input. Its value is further validated through a comprehensive set of results, comparing the original problem with the enhanced method we present. We also present a tourism case study.},
  archive      = {J_IJCIS},
  author       = {Hernández, Rodrigo and Gutiérrez, Inmaculada and Castro, Javier},
  doi          = {10.1007/s44196-025-00812-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Social network analysis: A novel paradigm for improving community detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new double weighted fuzzy hypergeometric naive bayes network and its application for user’s assessment in virtual reality simulators. <em>IJCIS</em>, <em>18</em>(1), 1-17. (<a href='https://doi.org/10.1007/s44196-025-00816-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessment methods have been used for identify the quality of procedures performed by human beings. In virtual reality simulators, user’s interaction data can be collected and utilized by Single User Assessment Systems (SUAS) to assess the user’s performance. In particular, some procedures can be considered well performed when the same objective is achieved a number of times with success within a limited universe of attempts. In this case, the data can be modeled by a Hypergeometric distribution. This paper presents the proposal of a new Double Weighted Fuzzy Hypergeometric Naive Bayes (DW-FHyperNB) Network as basis for a SUAS, which can be used in virtual reality simulators. The results showed that this new SUAS was able to achieve better results when compared to other SUAS based on different Naive Bayes Networks. This comparison was performed using SUAS based on Fuzzy Hypergeometric Naive Bayes Network, Classical Hypergeometric Naive Bayes Network, Double Weighted Classical Hypergeometric Naive Bayes Network, Multinomial Naive Bayes Network, Bayes Net, Support Vector Machine, Multilayer Perceptron Neural Network, Radial Basis Network with Gaussian Functions, C4.5 Decision Tree, Decision Table-Naive Bayes, Multinomial Logistic Regression, Simple Cart, and Random Forest was performed. The results obtained showed that the DW-FHyperNB Network produced the best performance, according to the Overall Accuracy Index, Kappa and Tau Coefficients, and diagnostic tests. The new DW-FHyperNB Network can also be utilized for data and image classification, pattern recognition, as well as machine learning applications.},
  archive      = {J_IJCIS},
  author       = {Ferreira, Jodavid and Machado, Liliane S. and de Moraes, Ronei Marcos},
  doi          = {10.1007/s44196-025-00816-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A new double weighted fuzzy hypergeometric naive bayes network and its application for user’s assessment in virtual reality simulators},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A federated weighted learning algorithm against poisoning attacks. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00819-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of Federated Learning (FL) has enabled privacy-preserving distributed machine learning, yet its vulnerability to poisoning attacks remains a critical challenge. Existing defense methods often rely on static aggregation rules or centralized verification mechanisms, which lack adaptability to dynamic adversarial behaviors and incur high computational costs. To address these limitations, this paper proposes the Federated Weighted Learning Algorithm (FWLA), a novel framework designed to mitigate poisoning attacks through client-specific weight adaptation and asynchronous collaboration. The core of FWLA lies in two components: (1) a residual testing mechanism that dynamically identifies malicious clients by analyzing deviations between local and global model updates, and (2) an asynchronous training protocol that allows clients to independently upload parameters, thereby avoiding synchronization bottlenecks. Extensive experiments on three benchmark datasets (CICIDS2017, UNSW-NB15, NSL-KDD) demonstrate FWLA’s superiority over state-of-the-art methods. Specifically, FWLA achieves 98.9% accuracy and reduces the false acceptance rate to 2.9% on CICIDS2017. The robustness analysis further reveals that FWLA maintains 83% accuracy even when 20% of clients are malicious, outperforming FedAvg and FedSGD by 12%. These improvements stem from FWLA’s ability to suppress poisoned updates through iterative weight adjustments, validated by ablation studies showing a 3.3% accuracy drop when removing residual testing. Nonetheless, FWLA has its limitations in that when the number of clients is large, it may lead to increased resource consumption, so future work will concentrate on developing strategies to reduce these resource costs.},
  archive      = {J_IJCIS},
  author       = {Ning, Yafei and Zhang, Zirui and Li, Hu and Xia, Yuhan and Li, Ming},
  doi          = {10.1007/s44196-025-00819-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A federated weighted learning algorithm against poisoning attacks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Enhanced YOLOv8 for efficient parcel identification in disordered logistics environments. <em>IJCIS</em>, <em>18</em>(1), 1-2. (<a href='https://doi.org/10.1007/s44196-025-00831-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Yu, Han and Fengshou, Zhang and Gaoshuai, Zhuang and Yuanhao, Qu and Aohui, He and Qingyang, Duan},
  doi          = {10.1007/s44196-025-00831-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: Enhanced YOLOv8 for efficient parcel identification in disordered logistics environments},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent monitoring and treatment system of heavy metal contaminated soil based on artificial bee colony algorithm and edge computing nanotechnology. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-025-00834-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The CGABC algorithm improves the convergence speed of the algorithm by crossing the solution generated by the neighborhood search of bees with the current global optimal solution. By selecting reasonable cross-operation coefficients to balance the algorithm's global optimization ability and local search ability, and adding random interference terms to increase population diversity. By optimizing the test function, it was verified that the performance of the CGABC algorithm is superior to the ABC algorithm and GABC algorithm. In the context of environmental remediation, particularly in the treatment of heavy metal-contaminated soil, optimizing treatment methods through advanced computational algorithms has become increasingly critical. This paper introduces an intelligent monitoring and treatment system based on the Artificial Bee Colony (ABC) algorithm, incorporating edge computing and nanotechnology for the remediation of heavy metal-contaminated soils. To improve the efficiency and effectiveness of the system, we propose two enhanced algorithms: the Cooperative Global Artificial Bee Colony (CGABC) and Chaotic Tabu Search Artificial Bee Colony (CTABC) algorithms. Magnetic core iron trioxide was prepared by co-precipitation method, with an average particle size of 10–15 nm. Magnetic mesoporous nanoparticles Fe3O4 and SiO2 with uniform particle size and good dispersion were prepared using the Stober method. The specific surface area before calcination was 305.8 m2/g, and the pore size was 2.5 nm. The average particle size after calcination was around 200 nm. EDTA ferric oxide and silica were obtained by modification with N triacetate sodium salt. Fourier transform infrared spectroscopy showed successful EDTA modification with a specific surface area.},
  archive      = {J_IJCIS},
  author       = {Hu, Ke and Li, Dongdong and Cui, Xiaolei and Hu, Donghua and Chen, Junliang and Zhuan, Shaopeng and Chang, Hao and Zhang, Yaping and An, Tingting and Zhang, Juqin},
  doi          = {10.1007/s44196-025-00834-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Intelligent monitoring and treatment system of heavy metal contaminated soil based on artificial bee colony algorithm and edge computing nanotechnology},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neutrosophic gompertz distribution: Applications in analyzing complex environmental datasets. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00836-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems are characterized by uncertainty, indeterminacy, vagueness, and ambiguity. In situations where the random variable has ambiguous values, classical probability distributions may not be effective. Instead, neutrosophic probability distributions often yield better results. The Gompertz distribution, widely applied across various fields, is extended in this research to introduce the neutrosophic Gompertz distribution (NGoD) for modeling ambiguous data. Key neutrosophic properties such as moments, Shannon entropy, and reliability measures of NGoD are derived. Neutrosophic parameters are estimated using maximum likelihood estimation, and a simulation study is conducted to examine parameter behavior and compare the indeterminacy between parameters. Finally, the NGoD is applied to two real-world ambiguous data sets, demonstrating the effectiveness and suitability of the neutrosophic Gompertz distribution in uncertain contexts. The analysis shows that the neutrosophic Gompertz model is appropriate, reasonable, and useful for such applications.},
  archive      = {J_IJCIS},
  author       = {Saleem, Muhammad and Bashir, Shakila and Tayyab, Ammara and Aslam, Muhammad and Rasul, Mujahid},
  doi          = {10.1007/s44196-025-00836-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Neutrosophic gompertz distribution: Applications in analyzing complex environmental datasets},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enterprise tax assessment and risk avoidance based on deep learning. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00837-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Business tax assessments ensure financial solidity and regulatory adherence. Inaccurate or late tax returns can harm an organization’s reputation and economic health. Conventional tax risk appraisal techniques usually fail to estimate taxable input risks and future fiscal burdens correctly and hence are left with ineffective mitigation of risks. The proposed method forecasts the possibilities of taxable inputs and their depreciation, which results in risks over different financial quarters. The cumulative taxable input risks are updated based on the previous inputs and their claimable part to improve the risk prediction. In this prediction process, deep learning is employed; this learning model is designed with two conditional layers. The first conditional layer is responsible for identifying the taxable inputs, and the second is responsible for determining the risks due to external input changes. These two factors are combined using the previous risk factor impact to verify their existence. Based on this existing factor, the number of assessments is increased or benchmarked for further audit. The topic model accurately predicts taxable input risk by financial quarters, continuously refining risk estimates based on the incorporation of prior data. Continuous learning and benchmarking enable the model to adapt to changing tax conditions. By incorporating deep learning into tax evaluation, businesses can enhance financial stability, streamline risk management, and facilitate improved compliance. The approach simplifies business complexity and allows for more precise tax planning.},
  archive      = {J_IJCIS},
  author       = {Lan, Yali},
  doi          = {10.1007/s44196-025-00837-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enterprise tax assessment and risk avoidance based on deep learning},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A global attention mechanism-based EfficientNet model for road pavement-type identification. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00842-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate pavement-type recognition remains a critical challenge for intelligent transportation systems. However, the general CNN-based methods, such as ResNet and VGG, exhibit significant limitations when addressing the high degree of similarity between surface modifications and dissimilar pavements caused by changes in illumination or partial shading. To address the challenges posed by complex texture variations and surface modifications across road pavements, in this study, an enhanced method for pavement-type identification is proposed. First, an application-oriented dataset encompassing seven pavement types is constructed based on existing open-source road surface classification datasets. Secondly, the EfficientNet-Global Attention Mechanism (GAM) model is developed through the integration of a GAM module into the EfficientNet architecture. Within this model, the GAM module undergoes a process where it synergistically refines channel–spatial features, utilizing 3D permutation and multilayer perceptron operations. This enables the effective isolation of discriminative patterns, such as crack density, from complex backgrounds. Then, to mitigate inter-class confusion, a label smoothing strategy is implemented, while cosine learning rate decay is employed to ensure stable convergence during training. The experimental results demonstrate that the proposed model achieves high-precision recognition of various pavement types, with an accuracy rate of 98.11%, while simultaneously maintaining computational efficiency.},
  archive      = {J_IJCIS},
  author       = {Ni, Zhe-Yuan and Wang, Jun-Cheng},
  doi          = {10.1007/s44196-025-00842-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A global attention mechanism-based EfficientNet model for road pavement-type identification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Spark-based label diffusion and label selection community detection algorithm for metagenome sequence clustering. <em>IJCIS</em>, <em>18</em>(1), 1-3. (<a href='https://doi.org/10.1007/s44196-025-00850-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Wu, Zhengjiang and Wu, Xuyang and Luo, Junwei},
  doi          = {10.1007/s44196-025-00850-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: Spark-based label diffusion and label selection community detection algorithm for metagenome sequence clustering},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing automotive networks from DoS and fuzzy attacks with optimized LSTM models. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00782-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligently connected automobiles have come a long way thanks to the deep integration of cutting-edge networked gadgets and advancements in automotive technology. The increasing connectivity of vehicles has introduced significant cybersecurity concerns, particularly in controller area network (CAN) bus systems, which are crucial for vehicle communication. For this, the research presents a novel hybrid model combining and integrating a long short-term memory (LSTM) neural network and bacterial foraging optimization (BFO) technique to address challenges like identifying fuzzy and denial of service (DoS) attacks on the CAN bus system. The model’s efficacy is demonstrated by evaluating various cyber-attacks from the Car-Hacking dataset. An adaptive feature selection method using BFO to identify optimal CAN bus characteristics for accurate attack detection. The LSTM-based temporal pattern recognition system detects anomalous message sequences and real-time countermeasures for mitigating DoS and fuzzy attacks. Reducing attack detection time to 0.0838 s, an enhancement over LSTM-AE, suggests improving detection speed. With a higher precision of 94.6% and F1-scores of 95.8%, LSTM-BFO outperforms other models based on accuracy, precision, and F1-score under the current experimental setup.},
  archive      = {J_IJCIS},
  author       = {Dennyson, W. Beniel and Jothikumar, C.},
  doi          = {10.1007/s44196-025-00782-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Securing automotive networks from DoS and fuzzy attacks with optimized LSTM models},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy encryption search scheme and data verification mechanism based on blockchain. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00804-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of blockchain technology, the security of blockchain data verification has received increasing attention. A fuzzy encryption search scheme and data verification mechanism are proposed in the study. First, privacy protection of the raw data is achieved through a hierarchical Mini Batch K-Means clustering algorithm and locally sensitive hash functions. Second, the study proposes a blockchain data verification mechanism that employs a fuzzy encryption search scheme, in conjunction with cloud storage and a fuzzy encryption algorithm. This mechanism is designed to ensure data integrity and confidentiality. When the number of attributes was 30, the initialization time cost of the proposed fuzzy encryption search scheme was 98 ms, which was reduced by about 51.6% compared to the blockchain-assisted sorting method. The encryption time cost of the proposed search method was 61 ms, which was reduced by about 35.6% compared to the multi-permission data access method. When the number of parallel transactions reached 1000, the transaction duration for smart contract Upload was 23.68 s, while the transaction duration for Search was 24.36 s. The proposed fuzzy encryption search scheme and data verification mechanism not only protect data privacy and ensure data integrity and confidentiality, but also have high search efficiency and low time overhead, providing better security for blockchain data.},
  archive      = {J_IJCIS},
  author       = {Li, Kuan},
  doi          = {10.1007/s44196-025-00804-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fuzzy encryption search scheme and data verification mechanism based on blockchain},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-strategy improved horned lizard optimization algorithm and its application in engineering optimization. <em>IJCIS</em>, <em>18</em>(1), 1-31. (<a href='https://doi.org/10.1007/s44196-025-00824-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address NP-hard optimization challenges prevalent in engineering applications, meta-heuristic algorithms are highly regarded for their ability to provide high-quality solutions. In this study, a multi-strategy improved horned lizard optimization algorithm (MSHLOA) is proposed to overcome the limitations of the standard HLOA in terms of premature convergence and slow optimization search. The algorithm is innovated through four synergistic strategies: (1) logistic chaotic population initialization to enhance initial solution diversity; (2) dynamic lens imaging-based adversarial learning to enhance global search capability; (3) sub-linear probability decay selection-based crisscross strategy to effectively break through dimensional local optima; and (4) golden sine factor-guided local exploitation to balance the trade-off between exploration and exploitation. Experimental validation on 15 benchmark functions and the CEC2021 test set demonstrates the superior performance of MSHLOA, with an overall effectiveness improvement of 53.35% compared to standard HLOA. Statistical analyses including the Wilcoxon rank sum test (p < 0.05), Friedman’s test, and solution distribution visualization validate the robustness of the algorithm against local optimal stagnation. In the engineering optimization example, the average cost of the pressure vessel problem was reduced by 55.6%, while the optimal value with the lowest standard deviation verified its stability in terms of solution accuracy, convergence speed, and stability. These advances establish the computational efficiency and reliability of MSHLOA for engineering problems, providing a general example of an augmented meta-heuristic algorithm that offers a new, more efficient solution to engineering structural optimization problems.},
  archive      = {J_IJCIS},
  author       = {Li, Yancang and Zhang, Jinfan and Jin, Zidong and Qiao, Weitao},
  doi          = {10.1007/s44196-025-00824-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A multi-strategy improved horned lizard optimization algorithm and its application in engineering optimization},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On generalized overlap and grouping indices in n-dimensional contexts. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-025-00796-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overlap and grouping indices are functions measuring, respectively, the fuzzy intersection and fuzzy union of two fuzzy sets. They have been applied successfully in several fields, such as in interpolative fuzzy systems, fuzzy rule-based classification systems and comparison of fuzzy inference rules. Overlap and grouping indices can be built employing overlap and grouping functions, respectively, which are possibly non-associative aggregation functions with features that provide good results when applied to practical bivariate problems. Many studies have generalized the concepts of overlap and grouping functions to be applied in n-dimensional problems. However, the concepts of overlap/grouping indices have not been generalized in similar pattern. Since the associative property may not hold, their application in n-dimensional domains, for comparing more than two fuzzy sets at a time, is not immediate, which limit their application in such contexts. The objective of this paper is to introduce the concepts of n-dimensional and general overlap/grouping indices, with special attention to the development of their construction methods based on generalized overlap/grouping functions. As an application example, we introduce the concept of n-dimensional Jaccard index, with a construction method based on n-dimensional overlap/grouping indices, providing an n-dimensional fuzzy set similarity score.},
  archive      = {J_IJCIS},
  author       = {Asmus, Tiago and Dimuro, Graçaliz and Lucca, Giancarlo and Marco-Detchart, Cedric and Santos, Helida and Camargo, Heloisa and Bustince, Humberto},
  doi          = {10.1007/s44196-025-00796-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {On generalized overlap and grouping indices in n-dimensional contexts},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved TODIM method for probabilistic linguistic MAGDM based on new distance measure. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00806-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic linguistic term sets (PLTSs), which assign different weights to various linguistic terms, offer an efficient framework for expressing preferences. Meanwhile, the TODIM method, grounded in prospect theory, is adept at incorporating the cognitive behaviors of decision-makers into the decision-making process. In this paper, we extend the TODIM method to solve multi-attribute group decision making (MAGDM) problems with PLTSs. At first, we extend the Frank operators to PLTSs and propose the probabilistic linguistic Frank weighted averaging (PLFWA) operator based on adjusted rules of PLTSs. Further, some desirable properties of them are studied. Meanwhile, we present an innovative distance measure, deeply anchored in linguistic scale functions, designed to overcome the shortcomings of current distance metrics. What’s more, the combined weights for attributes can be obtained by the criteria importance though intercriteria correlation (CRITIC) method and the best-worst method (BWM) and the steps of the extended TODIM method for PLTSs are proposed. Finally, a numerical example for the purchase selection of electric vehicles is given, and some sensitivity and comparative analysis are used to illustrate the effectiveness and rationality of this new method.},
  archive      = {J_IJCIS},
  author       = {Li, Ke and Xu, Lei and Liu, Yi and Wang, Hongjuan and Rong, Yuan},
  doi          = {10.1007/s44196-025-00806-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improved TODIM method for probabilistic linguistic MAGDM based on new distance measure},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Defects detection in screen-printed circuits based on an enhanced YOLOv8n algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00815-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defect detection is a crucial task in screen-printed circuit (SPC) production, where image processing method based on deep learning is often used. This field frequently encounters challenges, such as minute surface defects, a large number of model parameters, and high computational complexity. To address these challenges, a self-made SPC defect data set and an enhanced CAAB-YOLOv8n detection algorithm were developed. A CAD module was integrated into the backbone network to improve the model’s ability to detect bar-shaped features. In addition, the ASF feature fusion and RMT modules were combined to construct the ASF-CR neck structure, which enhances the model’s capability to detect small, localized defects. To expedite inference speed, the DBB-Head reparameterization module was incorporated. Experimental results show that the enhanced algorithm achieves 88.4 $$\%$$ accuracy, a mAP@50 of 90.2 $$\%$$ , and a parameter count of just 33.27 million, with a detection speed of 35.2 frames per second. The real-time requirements for SPC defect detection are met by these findings. This work lays a solid theoretical foundation for subsequent defect traceability and the optimization of printing process parameters.},
  archive      = {J_IJCIS},
  author       = {Zhang, Xinyu and Wang, Jia and Jiang, Dan and Li, Yang and Wang, Xuewei and Zhang, Han},
  doi          = {10.1007/s44196-025-00815-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Defects detection in screen-printed circuits based on an enhanced YOLOv8n algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced global optimization using a novel hybrid sine cosine-gazelle algorithm with brownian motion and lévy flight mechanisms. <em>IJCIS</em>, <em>18</em>(1), 1-55. (<a href='https://doi.org/10.1007/s44196-025-00823-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms are crucial for solving intricate optimization problems in diverse fields. The Sine Cosine Algorithm (SCA), known for its efficiency and simplicity in global search, sometimes struggles with premature convergence and inadequate exploitation. To address these challenges, this study introduces a novel hybrid SCA-Gazelle Optimisation Algorithm (HSCAGOA) by integrating the Gazelle Optimisation Algorithm’s (GOA) exploitation strategy. Inspired by gazelle behaviour, GOA enhances local search capabilities, improving the balance between the exploration and exploitation phases. Additionally, HSCAGOA incorporates Brownian motion and Lévy flight mechanisms to further enhance exploration capabilities. This research rigorously evaluates HSCAGOA through extensive computational experiments on 33 benchmark test problems and six engineering design challenges. Comparisons with classical SCA and various state-of-the-art optimisation algorithms show that HSCAGOA consistently achieves faster convergence and higher solution quality across diverse optimisation landscapes. To validate these results, ranking analysis is conducted using the Wilcoxon rank-sum test and the Wilcoxon signed-rank test, confirming the efficacy of HSCAGOA. Furthermore, employing the Combined Compromise Solution (CoCoSo) method for multi-criteria decision-making enables systematic ranking and comparison of HSCAGOA’s performance against other algorithms. Additionally, a comparative analysis was conducted against renowned CEC competition winners, including LSHADEcnEpSin, LSHADESPACMA, and CMA-ES. HSCAGOA is evaluated through extensive computational experiments involving CEC 2017 benchmark test functions. Moreover, sensitivity analysis is performed to assess the robustness of HSCAGOA under varying configurations, including different population sizes and maximum iteration counts on CEC 2022 benchmark test functions. The findings highlight the algorithm’s adaptability and reliability in addressing complex optimization challenges. In summary, this study introduces HSCAGOA as a robust optimisation framework that mitigates the limitations of traditional SCA. It provides an effective solution for addressing complex real-world optimisation problems across different domains.},
  archive      = {J_IJCIS},
  author       = {Singh, Gyan and Biswas, Saptadeep and Ezugwu, Absalom El-Shamir and Simic, Vladimir and Bera, Uttam Kumar and Saleem, Kashif and Abualigah, Laith},
  doi          = {10.1007/s44196-025-00823-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-55},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced global optimization using a novel hybrid sine cosine-gazelle algorithm with brownian motion and lévy flight mechanisms},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Min3GISG: A synergistic feature selection framework for industrial control system security with the integrating genetic algorithm and filter methods. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00827-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial control systems (ICS) are crucial for automating and optimizing industrial operations but are increasingly vulnerable to cyberattacks due to their interconnected nature. High-dimensional ICS datasets pose challenges for effective anomaly detection and classification. This study aims to enhance ICS security by improving attack detection through an optimized feature selection framework that balances dimensionality reduction and classification accuracy. The study utilizes the HAI dataset, comprising 54,000 time series records with 225 features representing normal and anomalous ICS behaviors. A hybrid feature selection approach integrating wrapper and filter methods was employed. Initially, a Genetic Algorithm (GA) identified 118 relevant features. Further refinement was conducted using filter-based methods—Symmetrical Uncertainty (SU), Information Gain (IG), and Gain Ratio (GR)—leading to a final subset of 104 optimal features. These features were used to train classification models (Naive Bayes (NB), Random Forest (RF), and Support Vector Machine (SVM)) with a 70:30 train-test split and tenfold cross-validation. The proposed feature selection method significantly improved classification accuracy, achieving 98.86% (NB), 99.91% (RF), and 97.97% (SVM). Compared to the full dataset (225 features), which yielded 97.51%, 99.93%, and 96.17%, respectively, our optimized feature subset maintained or enhanced classification performance while reducing computational complexity. This research demonstrates the effectiveness of a hybrid feature selection approach in improving ICS anomaly detection. By reducing feature dimensionality without compromising accuracy, the proposed method enhances ICS security, offering a scalable and efficient solution for real-time attack detection.},
  archive      = {J_IJCIS},
  author       = {Potharaju, Saiprasad and Tambe, Swapnali N. and Rao, G. Madhukar and Kantipudi, M. V. V. Prasad and Bamane, Kalyan Devappa and Bendre, Mininath},
  doi          = {10.1007/s44196-025-00827-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Min3GISG: A synergistic feature selection framework for industrial control system security with the integrating genetic algorithm and filter methods},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A coevolutionary algorithm based on constraints decomposition for constrained multi-objective optimization problems. <em>IJCIS</em>, <em>18</em>(1), 1-34. (<a href='https://doi.org/10.1007/s44196-025-00830-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) are challenging for evolutionary algorithms (EAs). Due to the interaction of multiple constraints, the constrained Pareto fronts (CPFs) exhibit various complex characteristics, e.g., degeneracy, discontinuity or irregularity. Most algorithms achieve poor convergence and diversity performance on these problems. Therefore, we proposed a coevolutionary framework based on constraints decomposition to solve complex CMOPs. Specifically, this framework decomposes the CMOP into multiple help subproblems with a single constraint, thereby decoupling the complex constraints. Then, multiple subpopulations optimize these subproblems to assist in solving the original problem. In addition, a two-stage strategy is used to fully utilize the auxiliary populations to search for feasible solutions. In addition, an evolutionary state detection strategy based on historical information is proposed, which is used to determine whether the evolution moves to the next stage. The framework can take the advantage of the low complexity of single-constraint problems to help algorithm search the complete feasible regions. Experiments on benchmark problems show that the proposed algorithm is competitive with eight other most representative constrained evolutionary algorithms in terms of convergence and diversity performance.},
  archive      = {J_IJCIS},
  author       = {Li, Guangpeng and Li, Li and Cai, Guoyong},
  doi          = {10.1007/s44196-025-00830-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A coevolutionary algorithm based on constraints decomposition for constrained multi-objective optimization problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on civil aviation airport site selection considering group consensus level under large-scale uncertain information. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00840-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the decision-making challenges posed by large-scale information and complex data sources in civil aviation airport site selection, this paper proposes a novel method that integrates group consensus within a framework of substantial uncertainty. The method comprises five key processes: (1) Evaluation process: Based on the constructed multicriteria evaluation system for airport site selection, the q-Rung Orthopair Fuzzy (q-ROF) information is employed to represent evaluations from large-scale decision makers, which effectively characterizes the uncertainty of information and broadens the evaluative scope. (2) Clustering process: A clustering procedure is designed for large-scale q-ROF evaluation data and weight information of criteria, identifying and removing outliers. (3) Consensus reaching process: Considering the characteristics of q-ROF evaluations and multiplicative preference relations, two adaptive consensus reaching algorithms are developed to enhance group consensus levels, thereby improving the rationality of decision-making results. (4) Weight determination process: Criteria and subcriteria weights are calculated using multiplicative preference weighting approach and a deviation maximization model, respectively, derived from aggregated group evaluations. (5) Ranking process: The q-ROF Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method is applied, in conjunction with the induced q-ROF information integration paradigm, to comprehensively rank the alternative sites. Finally, the feasibility and effectiveness of the proposed method are demonstrated through a case study of civil aviation branch airport planning in a specific city.},
  archive      = {J_IJCIS},
  author       = {Wang, Rui and Zeng, Jing-Han and Huang, Jing-Yang and Kang, Rui and Yuan, Jiang and Zhong, Qing-Wei},
  doi          = {10.1007/s44196-025-00840-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Research on civil aviation airport site selection considering group consensus level under large-scale uncertain information},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective audio perturbations for targeting specific phrases in speech recognition systems. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00844-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel approach for creating audio adversarial examples that specifically target speech recognition systems. The proposed method involves adding optimized noise to a particular region of an audio sample that corresponds to a specified word or phrase. By doing so, the generated adversarial example is designed to deceive the targeted model into interpreting it as a modified sentence, where the specified phrase has been altered. This method offers advantages compared to existing techniques, including reduced distortion since noise is only added to the targeted area, and the ability for the attacker to selectively modify or add specific words as desired. The experimental evaluation utilized the Mozilla Common Voice dataset. The results demonstrate that the adversarial examples generated using the proposed method, which only transform the specified word or phrase by adding noise to that specific region, can successfully fool the speech recognition system into misclassifying them as the intended target sentence.},
  archive      = {J_IJCIS},
  author       = {Ko, Kyoungmin and Kim, SungHwan and Kwon, Hyun},
  doi          = {10.1007/s44196-025-00844-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Selective audio perturbations for targeting specific phrases in speech recognition systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incomplete dynamic fuzzy linguistic reasoning approach based on concept lattice. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00845-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, much fuzzy data is described by evaluative linguistic expressions, which typically exhibit dynamic and changing characteristics. To tackle the challenges of dynamic fuzzy knowledge acquisition and reasoning in uncertain environments, this paper proposes an incomplete dynamic fuzzy linguistic reasoning approach based on concept lattices. First, the dynamic fuzzy linguistic concept lattice is constructed based on dynamic fuzzy linguistic formal context, which can represent linguistic information more effectively in dynamic fuzzy environments. Second, to compensate for information loss, an incomplete dynamic fuzzy linguistic formal context completion algorithm involving two-pass completions is proposed. In addition, dynamic fuzzy linguistic rules are extracted using the finer relation of dynamic fuzzy linguistic concept lattices, which are utilized to construct a dynamic fuzzy linguistic rule base. On this basis, antecedent similarity degree of dynamic fuzzy linguistic rules is introduced, thereby an incomplete dynamic fuzzy linguistic reasoning approach is proposed for obtaining decision-making results. Finally, a practical example is used to verify the effectiveness and rationality of the proposed approach.},
  archive      = {J_IJCIS},
  author       = {Zhang, Chuyi and Sun, Deshan and Jia, Nan and Pang, Kuo and Zou, Li and Pedrycz, Witold},
  doi          = {10.1007/s44196-025-00845-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Incomplete dynamic fuzzy linguistic reasoning approach based on concept lattice},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual adapter tuning of Vision–Language models using large language models. <em>IJCIS</em>, <em>18</em>(1), 1-36. (<a href='https://doi.org/10.1007/s44196-025-00853-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision–language models (VLMs) pre-trained on large-scale image–text pairs have shown impressive results in zero-shot vision tasks. Knowledge transferability of these models can be further improved with the help of a limited number of samples. Feature adapter tuning is a prominent approach employed for efficient transfer learning (ETL). However, most of the previous ETL models focus on tuning either prior-independent or prior-dependent feature adapters. We propose a novel ETL approach that leverages both adapter styles simultaneously. Additionally, most existing ETL models rely on using textual prompts constructed by completing general pre-defined templates. This approach neglects the descriptive knowledge that can assist VLM by presenting an informative prompt. Instead of pre-defined templates for prompt construction, we use a pre-trained LLM to generate attribute-specific prompts for each visual category. Furthermore, we guide the VLM with context-aware discriminative information generated by the pre-trained LLM to emphasize features that distinguish the most probable candidate classes. The proposed ETL model is evaluated on 11 datasets and sets a new state of the art. Our code and all collected prompts are publicly available at https://github.com/mrzarei5/DATViL .},
  archive      = {J_IJCIS},
  author       = {Zarei, Mohammad Reza and Akkasi, Abbas and Komeili, Majid},
  doi          = {10.1007/s44196-025-00853-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Dual adapter tuning of Vision–Language models using large language models},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-population optimization framework based on plant evolutionary strategy and its application to engineering design problems. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00779-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization problems are widespread across various fields, including industry, agriculture, and healthcare. Metaheuristic algorithms (MAs) are commonly employed to solve these problems due to their flexibility and robustness. However, despite their success, MAs inspired by plant evolutionary strategies remain underexplored. This paper introduces a novel multi-population optimization framework based on the plant evolutionary strategy (PES_MPOF), which leverages plant evolutionary principles to improve optimization performance by maintaining population diversity and accelerating convergence in complex tasks. PES_MPOF integrates multiple subpopulations, each evolving according to different plant evolutionary models. These subpopulations mimic natural distribution and reproduction strategies, fostering solution diversity through both cooperation and competition. Additionally, PES_MPOF adapts population parameters based on the evolutionary performance of subpopulations, further enhancing its robustness and efficiency. The PES_MPOF algorithm was tested on the IEEE CEC 2020 benchmark suite and several classic engineering design problems. It outperforms other state-of-the-art optimization algorithms, demonstrating significant improvements in global optimization, solution accuracy, and convergence speed. PES_MPOF effectively addresses the challenges of premature convergence and loss of diversity, making it a robust and efficient optimization tool. Its innovative multi-population framework, inspired by plant evolutionary strategies, enhances both exploration and exploitation. Experimental results validate its effectiveness across a broad range of optimization problems, including those with constraints. The part of algorithm’s code will be made available upon the paper’s acceptance: https://github.com/ChengHongwei430/PES_MPOF .},
  archive      = {J_IJCIS},
  author       = {Cheng, Hongwei and Li, Jun and Zhang, Xiaoming and Li, Tingjuan and Zhang, Panpan},
  doi          = {10.1007/s44196-025-00779-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multi-population optimization framework based on plant evolutionary strategy and its application to engineering design problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving oil pipeline surveillance with a novel 3D drone simulation using dynamically constrained accumulative membership fuzzy logic algorithm (DCAMFL) for crack detection. <em>IJCIS</em>, <em>18</em>(1), 1-36. (<a href='https://doi.org/10.1007/s44196-025-00818-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cracks in oil pipelines pose significant risks to the environment, public safety, and the overall integrity of the infrastructure. In this paper, we propose a novel approach for crack detection in oil pipes using a combination of 3D drone simulation, convolutional neural network (CNN) feature extraction, and the dynamically constrained accumulative membership fuzzy logic algorithm (DCAMFL). The algorithm leverages the strengths of CNNs in extracting discriminative features from images and the DCAMFL’s ability to handle uncertainties and overlapping linguistic variables. We evaluated the proposed algorithm on a comprehensive dataset containing images of cracked oil pipes, achieving remarkable results. The precision, recall, and F1-score for crack detection were found to be 96.5%, 97.3%, and 95.6%, respectively. These high-performance metrics demonstrate the algorithm’s accuracy and reliability in identifying and classifying cracks. Our findings highlight the effectiveness of integrating advanced simulation techniques, deep learning, and fuzzy logic for crack detection in oil pipelines. The proposed algorithm holds promise for enhancing pipeline surveillance, improving safety measures, and extending the lifespan of oil infrastructure. Future work involves expanding the dataset, fine-tuning the CNN architecture, and validating the algorithm on large-scale pipelines to further enhance its performance and applicability.},
  archive      = {J_IJCIS},
  author       = {Muhi, Omar Saber and Farhan, Hameed Mutlag and Kurnaz, Sefer},
  doi          = {10.1007/s44196-025-00818-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improving oil pipeline surveillance with a novel 3D drone simulation using dynamically constrained accumulative membership fuzzy logic algorithm (DCAMFL) for crack detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive analytics in maternal health: A machine learning approach for classification of preeclampsia. <em>IJCIS</em>, <em>18</em>(1), 1-31. (<a href='https://doi.org/10.1007/s44196-025-00825-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The condition known as preeclampsia is a hypertensive disorder that occurs during pregnancy and has serious implications for both the mother and the fetus. Proper management of the condition depends on early detection of preeclampsia to make a correct prognosis. In this study, we classify pre-eclampsia using three datasets: two of which are the public datasets acquired from Mendeley and Kaggle, respectively, while the third is a real-world clinical dataset obtained from a local hospital. Recursive feature elimination, principal component analysis, correlation-based feature selection, and particle swarm optimization were used to select significant features from the predictor variables of the public datasets. To improve the classification performance, several models were created, with an emphasis on ensemble learning methods. Specifically, we propose three models: the alternative classification models include the Soft Decision Fusion Model, which applies soft-voting; the Stacking-Based Classifier, which is an ensemble stacking; and the Hybrid Soft Stacking Model. These models were assessed in detail concerning their quantitative indicators for the AUC-ROC criterion. The performance of our proposed models in the public datasets was an AUC-ROC of more than 95% and in the clinical dataset an even higher 96%. These ensemble methods accurately show that they have effective results in improving the precision and reliability of pre-eclampsia forecasts. With the help of real and public clinical data, the present work presents an effective and ecological approach that can help healthcare professionals make appropriate and timely decisions about the management of pre-eclampsia. In particular, the results of the Hybrid Soft Stacking Model look quite convincing in terms of predictive value, so the model could be considered a useful tool in the clinical context.},
  archive      = {J_IJCIS},
  author       = {Amin, Pakiza and Gulzar Ahmad, Saima and Khan, Hikmat Ullah and Munir, Ehsan Ullah and Ramzan, Naeem},
  doi          = {10.1007/s44196-025-00825-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Predictive analytics in maternal health: A machine learning approach for classification of preeclampsia},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved hypernymy detection algorithm based on heterogeneous graph neural network. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00828-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept mapping is a knowledge representation method used to represent and understand concepts, entities, and the relationships between them, which are referred to as hyponymy–hypernymy semantic relations. These relations are primarily used to describe the hierarchical and categorical relationships between different concepts or entities. The detection of hyponymy–hypernymy semantic relations is an important task in the field of natural language processing, crucial to many downstream tasks such as information extraction, automatic reasoning, and personalized recommendations. These tasks often require understanding the semantic relations between concepts or entities in text for more accurate analysis and reasoning. Currently, algorithms for identifying and detecting hyponymy–hypernymy semantic relations face two main challenges: first, candidate hyponymy–hypernymy relation tuples do not exist in the same contextual sentence, failing to meet the co-occurrence requirement; second, distributed algorithms have issues with lexical memory. To address these issues, this paper proposes an improved algorithm for detecting hyponymy–hypernymy relations based on heterogeneous graph neural networks, aiming to detect hyponymy–hypernymy relations in various candidate word sets and then construct a hierarchical system. To meet the co-occurrence requirement of candidate word pairs, an open-source large model is utilized to generate contextual sentences for the candidate pairs. Sub-word features are adopted to capture the intrinsic semantic connections between nested phrases, thus alleviating the issue of reversed predictions for nested phrases. The representation of relation nodes is modified by encoding relation definitions through a pre-trained model, enabling the model to understand the semantic relations between concept nodes. To address the problem of overfitting in traditional graph attention networks, the calculation order of adjacency node aggregation is changed in the heterogeneous graph to capture dynamic attention features. In addition, a pipeline for hierarchical system construction is designed and implemented, combining the divide-and-conquer approach with loop detection algorithms. Compared to baseline metrics, the proposed method achieves a 4.14% improvement in accuracy and a 0.62% increase in F1 score on the EVALution dataset; a 4.89% increase in accuracy and a 0.71% improvement in F1 score on the Bansal dataset; and a 1.05% increase in accuracy, a 2.21% increase in recall, and a 1.79% improvement in F1 score on a self-annotated Chinese dictionary dataset.},
  archive      = {J_IJCIS},
  author       = {Ren, Li and Huang, Jing and Jia, Hai-Tao and Sun, Shu-Bao and Wang, Kai-Shi and Wu, Yi-Le},
  doi          = {10.1007/s44196-025-00828-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improved hypernymy detection algorithm based on heterogeneous graph neural network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sensor infused quantum CNN for diabetes disease prediction and diet recommendation. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00833-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes detection requires evidence-based recommendations that enable people to manage their health. A rising diabetes rate can lead to significant health risks and financial hardships. An early diagnosis and efficient treatment are essential to reduce the effects of diabetes. Therefore, a novel Sensor-infused QUantum CNN for diabetes Identification and Diet recommendation (SQUID) technique has been proposed in this paper, which identifies diabetes in the early stage using an IoT system and provides diet recommendations for reducing diabetes. The proposed SQUID system collects data from remote patients using IoT sensors and uses the Namib Beetle Optimization (NBO) technique to select the features. The prediction phase uses the Quantum CNN technique for classifying the input into diabetes and non-diabetes. After prediction, the suggestion phase will provide the diet recommendation using the fuzzy rule for the person affected with diabetes through the mobile application. The efficacy of the proposed SQUID framework has been assessed using specific parameters such as Accuracy (AC), Precision (PN), F1 score (F1_S), Recall (RL) and Diagnostic Odds Ratio (DOR). The SQUID framework achieves a higher AC of 98.69%, whereas HCBDA, IWBSOA, e-diagnosis and GlucoBreath achieve the AC of 92%, 94%, 96.5% and 97.35% in the diabetes dataset. In the diabetes prediction dataset, the proposed SQUID model achieves a higher accuracy of 98.87%, whereas existing techniques such as HCBDA, IWBSOA, e-diagnosis and GlucoBreath achieve the AC of 91.35%, 93.56%, 97.21% and 96.43% in diabetes prediction dataset respectively.},
  archive      = {J_IJCIS},
  author       = {Kotwal, Jameer and Futane, Pravin and Chavan, Gurunath and Chaudhari, Archana and Jose, Jithina and Khan, Vajid},
  doi          = {10.1007/s44196-025-00833-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Sensor infused quantum CNN for diabetes disease prediction and diet recommendation},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of fuzzy decision support in deep learning model of english translation pattern classification. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00839-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {English translation requires an intense knowledge of words, lexical arrangement, and sentence formation. The translation pattern follows either of the above to provide an understandable output. This article assimilates deep learning and fuzzy decision systems to ensure a highly understandable classification of English translations. Integrated translation pattern classification (ITPC) relies on deep learning to classify patterns based on words, lexicons, and sentences. The network is trained for the highest understandable classification output from the translated sentences. The fuzzy decision process is used to validate and extract new possibilities of the translated patterns. The identified patterns (new) increase the chance of translation efficiency of any complex sentence/ words. This process is a single turn of the learning process until the target pattern with the highest efficiency is observed. Based on the number of turns, the training iterations are varied to confine the complexity of pattern classification.},
  archive      = {J_IJCIS},
  author       = {Liu, Jinlian},
  doi          = {10.1007/s44196-025-00839-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Application of fuzzy decision support in deep learning model of english translation pattern classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal medical image fusion in NSST domain in coupled neural systems. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00841-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image fusion through multiple modalities functions as an essential tool for improved diagnosis because it harmonizes varied imaging results together. The research introduces an enhanced image fusion solution which unites Nonsubsampled Shearlet Transform (NSST) with Coupled Neural P (CNP) Systems to maximize the fusion results between MRI and PET brain images. The proposed system performs image decomposition starting from low and high frequency regions before it applies CNP systems for low-frequency fusion and WF-SML for high-frequency fusion. The proposed method proves superior in merging MRI and PET brain image pairs through experimental testing of 48 pairs when evaluated against seven mainstream fusion methods including CNN-based and neuro-fuzzy models. The proposed methodology grants improvements of 19.2% on Structural Similarity Index (SSIM) as well as 17.8% additional entropy while delivering improved standard deviation values to provide the best possible contrast and texture preservation and information maintenance. Medical image fusion techniques using our method generate detailed observations about Alzheimer’s disease along with brain tumors and neurodegenerative conditions which help medical professionals make better choices. Enhanced medical capabilities in imaging result from this modern fusion approach which improves both perceptible quality and clinical interpretation of combined images.},
  archive      = {J_IJCIS},
  author       = {Satyanarayana, Vella and Mohanaiah, P.},
  doi          = {10.1007/s44196-025-00841-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multimodal medical image fusion in NSST domain in coupled neural systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel human action recognition model by grad-CAM visualization with multi-level feature extraction using global average pooling with sequence modeling by bidirectional gated recurrent units. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00848-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition is essential in many real-world scenarios, such as video surveillance, human–computer interaction, and behavior analysis. Despite the progress in deep learning, issues such as occlusion, distraction from the background, and motion pattern variability still exist, thus restricting the generalization ability of current models. Most methods are based only on spatial or temporal features and cannot efficiently capture both in one framework, causing lower accuracy in realistic situations. In response to these shortcomings, a multilevel feature extraction approach was proposed by integrating spatial and temporal features to improve the action recognition precision. The method captures RGB frames, optical flow, spatial saliency maps, and temporal saliency maps to enable an overall inspection of video streams. Efficient feature extraction was achieved by applying a pre-trained Inception V3 model and then bidirectional gated recurrent units (Bi-GRUs) to include sequential modeling. An attention mechanism was also included to boost the classification process by focusing on key temporal segments. UCF101 and HMDB51 benchmark datasets evaluated the efficiency of the strategy. The model’s accuracy was 98.13% on UCF101 and 81.45% on HMDB51, which validated the superior discrimination ability of the model in processing heterogeneous human actions. These results confirm that the provided framework is an efficient and discriminative action recognition approach, thus suitable for applications requiring extensive motion analysis and real-time deployment.},
  archive      = {J_IJCIS},
  author       = {Manoharan, Jayamohan and Sivagnanam, Yuvaraj},
  doi          = {10.1007/s44196-025-00848-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel human action recognition model by grad-CAM visualization with multi-level feature extraction using global average pooling with sequence modeling by bidirectional gated recurrent units},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized recommendation algorithm for cultural and creative products based on fuzzy decision support system. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00857-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cultural and creative products are extensive, difficult to mass produce, and undersupplied. They can demonstrate their distinctive qualities through multifunctional design while raising cultural and economic value. Three circumstances often emerge when cultural and creative customers purchase stationery: purchasing inclination, purchasing behavior, and reflection. Limited mass manufacturing, undersupply, and the need to balance cultural and commercial value are common cultural and creative product issues. Hence, this study proposes a fuzzy context-aware neural recommendation algorithm (F-CANRA) to analyze consumers’ purchase behaviors regarding cultural and creative products (CCPs). A graph neural network (GNN) is established by studying users’ cultural and creative product-buying behavior. In this environment, a fuzzy decision support system (FDSS) could assist in making product recommendations for artistic and innovative actions (e.g., artwork, music, crafts, etc.) by taking into account a variety of criteria, including users’ preferences, current trends, cultural importance, and the fuzziness of these factors (e.g., a user’s approximate preference for “modern yet traditional” designs). This article proposes a decision-making framework utilizing a fuzzy decision support system (FDSS) integrated with a fuzzy analytic hierarchy process (FAHP). This framework aims to prioritize design elements, develop cultural and creative design components, and identify and analyze the key criteria influencing user needs. This research shows that the strategy may assist industrial designers in creating better color schemes for creative and cultural products by incorporating group users’ visual preferences into purchasing intention via multiuser decision consistency. The simulation outcome demonstrates that the suggested model increases the purchase intention prediction ratio of 97.8%, customer emotional satisfaction ratio of 98.5%, product development ratio of 96.2%, recommendation accuracy ratio of 95.2%, and product design costs of 7.3% compared to other existing models. As these outcomes show, the approach can help companies and industrial designers create CCPs that are culturally important and financially feasible. The F-CANRA platform provides a strong answer to the challenges of tailored product suggestions and well-informed design choices by connecting sophisticated algorithms with the cultural industry's complex requirements.},
  archive      = {J_IJCIS},
  author       = {Shi, Lin and Yang, Xiaoqing},
  doi          = {10.1007/s44196-025-00857-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Personalized recommendation algorithm for cultural and creative products based on fuzzy decision support system},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing plant disease detection: Incorporating advanced CNN architectures for better accuracy and interpretability. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-025-00835-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) have proven effective in automated plant disease diagnosis, significantly contributing to crop health monitoring. However, their limited interpretability hinders practical deployment in real-world agricultural settings. To address this, we explore advanced CNN architectures, namely ResNet-50 and EfficientNet, augmented with attention mechanisms. These models enhance accuracy by optimizing depth, width, and resolution, while attention layers improve transparency by focusing on disease-relevant regions. Experiments using the PlantVillage dataset show that basic CNNs achieve 46.69% accuracy, while ResNet-50 and EfficientNet attain 63.79% and 98.27%, respectively. On a 39-class extended dataset, our proposed EfficientNet-B0 with attention (EfficientNetB0-Attn), integrating an attention module at layer 262, achieves 99.39% accuracy. This approach significantly enhances interpretability without compromising performance. The attention module generates weights via backpropagation, allowing the model to emphasize disease-relevant image regions, thereby enhancing both accuracy and interpretability.},
  archive      = {J_IJCIS},
  author       = {González-Briones, Alfonso and Florez, Sebastián López and Chamoso, Pablo and Castillo-Ossa, Luis F. and Corchado, Emilio S.},
  doi          = {10.1007/s44196-025-00835-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing plant disease detection: Incorporating advanced CNN architectures for better accuracy and interpretability},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computational brain imaging framework for neurological mapping and disorder classification using multimodal image processing. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00852-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex neurological illnesses necessitate modern facilities’ computational methods for precise mapping and categorization of brain activities. For the diagnosis and tracking of conditions including epilepsy, Parkinson’s disease, and Alzheimer’s, precise brain mapping is essential. When it comes to diagnostic accuracy and scalability, traditional methods frequently encounter problems, including data heterogeneity, low resolution, and computational inefficiencies. Dealing with large-scale imaging datasets, enhancing the reliability of disease categorization in varied patient groups, and overcoming the limitations of cross-modality data fusion are the primary challenges. The multimodal neuro-cognitive imaging computational technique (MN-CICT) has been suggested in this research to overcome the above challenges. MN-CICT thoroughly extracts and analyses structural and functional brain data by integrating multiple imaging modalities, such as MRI, fMRI, PET, and CT. Improved resolution and interpretability of neurological mappings are achieved by the use of adaptive feature extraction, multimodal data fusion, and advanced machine learning techniques by MN-CICT. Because of its focus on computing efficiency, the framework additionally seems well suited for use in real-time scenarios. Neurodegenerative disease research, therapy planning, and clinical diagnostics are among the many areas that can benefit greatly from the framework. In comparison to current methods, the simulation results show a considerable decrease in processing time and an improvement in classification accuracy. This exemplifies its promise to enhance diagnostic results and simplify neuroimaging operations. The MN-CICT is a revolutionary method to brain imaging, which paves the way for the development of novel applications in the fields of brain–computer interfaces, customized medicine, and automated diagnostics.},
  archive      = {J_IJCIS},
  author       = {Karthikeyan, S. and Muthu Kumar, B. and Kiran, M. L. and Srivatsan, K.},
  doi          = {10.1007/s44196-025-00852-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Computational brain imaging framework for neurological mapping and disorder classification using multimodal image processing},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusion of visible and infrared images using a reinforcement learning system based on fuzzy logic and convolution optimized with wild horse algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00856-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To create a fusion image with more information, complementary data from similar images taken by multiple types of sensors are combined into a single image through the process of infrared and visible image fusion. Existing fusion approaches based on machine learning still struggle with how to better preserve the detail information in the source images. To improve and supplement the fusion image information, a hybrid reinforcement learning system based on fuzzy logic and convolutional network and filtering designed to fuse visible and infrared images is used in this work. This hybrid reinforcement learning system was optimized using algorithms including wild horse optimization (WHO), genetic algorithm (GA), and particle swarm optimization (PSO) to improve specific fusion metrics such as image correlation, similarity coefficient, image entropy, and signal-to-noise ratio. The system aims to preserve the detail information in the final image by adding thermal information from the infrared image to the visible image, which is achieved by performing a series of fusion operations on the input images, including image detail enhancement with the help of a convolutional network and meaningful image fusion with fuzzy logic semantic model and filtering operations to increase clarity. As part of the validation process, the advantages of the proposed algorithm were compared with other classical algorithms using the TNO dataset. Successfully, the proposed method has been able to increase the SSIM parameters to 1.8594 and PSNR to 61.42. Based on the experimental results, our proposed method outperforms previous fusion methods in terms of subjective and objective evaluations.},
  archive      = {J_IJCIS},
  author       = {Zarimeidani, Mahvash and Amirabadi, Amir and Amiri, Nasrin and Ahanian, Iman and Es’haghi, Siavash},
  doi          = {10.1007/s44196-025-00856-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fusion of visible and infrared images using a reinforcement learning system based on fuzzy logic and convolution optimized with wild horse algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid deep learning-ViT model and a meta-heuristic feature selection algorithm for efficient remote sensing image classification. <em>IJCIS</em>, <em>18</em>(1), 1-37. (<a href='https://doi.org/10.1007/s44196-025-00838-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent deep learning techniques driven by large datasets demonstrate the significant impact of feature learning in remote sensing for land use and cover classification, particularly exemplified by CNNs. While the pre-trained models showed good classification performance, they struggled to classify remote-sensing images with high precision accurately. In this study, we introduced XNANet, a self-attention-based CNN network for image classification. Bayesian optimization has been used to initialize the hyperparameters of the proposed model to improve training on the radiographic images. We suggested a novel network-level approach via the fusion of deep structure utilizing tiny-32 ViT and XNANet. For the first time, the tiny-32 vision transformer architecture has been utilized for RS images and combined with XNANet through network-level fusion. Following the fusion process, the model focused on RS image datasets and obtained deep features from the self-attention layer. The features that have been extracted are subject to selection, utilizing a novel meta-heuristic feature selection algorithm, RF-DE. The selected features are categorized using three popular classifiers. The proposed architecture’s experimental process was executed on the AID, RSSCN7, and SIRI-WHU datasets, resulting in accuracies of 98.9%, 99.3%, and 99.7%, respectively. Similarly, RF-DE was evaluated against six popular feature selection algorithms, yielding accuracies of 98.9%, 99.3%, and 99.7%, respectively. An in-depth statistical analysis was conducted to evaluate the suggested ensemble and RF-DE and demonstrate that the fusion model attained enhanced accuracy with RF-DE. Furthermore, recent techniques and proposed methods are compared, demonstrating enhanced precision, recall, and accuracy.},
  archive      = {J_IJCIS},
  author       = {Ahmed, Bilal and Naqvi, Syed Rameez and Akram, Tallha and Peng, Lu and Almarshad, Fahdah},
  doi          = {10.1007/s44196-025-00838-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A hybrid deep learning-ViT model and a meta-heuristic feature selection algorithm for efficient remote sensing image classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review on intelligent prediction of inorganic building materials performance. <em>IJCIS</em>, <em>18</em>(1), 1-44. (<a href='https://doi.org/10.1007/s44196-025-00843-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction industry is crucial for economic and social development. Inorganic materials, which rely on natural minerals and are affected by uncertainties, hold a large share in the construction market. As building materials are from process—intensive industries, complex and continuous processing magnifies deviations, directly affecting product quality. Computational intelligent methods are effective for accurately predicting product quality. This paper focuses on inorganic building materials and systematically reviews computational intelligent techniques in this field. It comprehensively explores 234 related studies in 6 key areas (concrete, ceramics, glass, clay bricks, cement, and steel), compiles prediction models, evaluates them, analyzes model configurations and properties to gain insights into the field and identify optimal approaches. It points out model limitations, such as high computational costs, data-hungry, and suggests future research directions like practicality and promoting green initiatives through material circulation.},
  archive      = {J_IJCIS},
  author       = {Li, Mengru and Zhang, Zhenya and Zeng, Xianyi and He, Zhenglei},
  doi          = {10.1007/s44196-025-00843-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-44},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A systematic review on intelligent prediction of inorganic building materials performance},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization scheduling of multiple heterogeneous energy sources. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-025-00822-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large-scale emergence of photovoltaic and wind power generation has led to significant changes in the energy structure, thereby creating new challenges in the optimization and control of diverse and heterogeneous energy sources. Therefore, numerous researchers have conducted extensive studies aimed at improving the utilization rate of these diverse energy sources and reducing waste. This article reviews the research background, objectives, current status, and prospects of optimizing energy. It introduces the challenges and opportunities that energy systems face with the development of renewable energy and energy storage technologies. The discussion revolves around the methods of multi-source heterogeneous energy optimization scheduling to achieve intelligent scheduling and efficient operation of energy systems. The study summarizes the mainstream mathematical modeling and optimization algorithms, intelligent optimization techniques, and real-time data processing technologies. It compares the significant roles of different scheduling methods in improving the efficiency of heterogeneous energy utilization and reducing energy waste, as well as their practical application effects and limitations. By summarizing the role of multi-source heterogeneous energy optimization scheduling in energy system optimization and the current research status, this article aims to provide reference and guidance for future research and practical implementation.},
  archive      = {J_IJCIS},
  author       = {Zhao, Ying and Yu, Zhiwen and Wang, Xiaobin and Tang, Jianlin and Lin, Xiaoming and Zhang, Fan and Qian, Bin},
  doi          = {10.1007/s44196-025-00822-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimization scheduling of multiple heterogeneous energy sources},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entrepreneurial skill augmented neural network (ESANN): A deep learning approach for enhancing entrepreneurial competencies in teachers. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00851-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern education requires teachers to develop entrepreneurial competencies because traditional training practices fail to provide individualized training methods. The developments in deep learning provide educational institutions with new data-based methods to develop professional development training programs. Entrepreneurial Skill Augmented Neural Network (ESANN) presents itself as a deep learning framework that serves to individualize educator training while upgrading their acquisition of entrepreneurial skills. The model leverages Convolutional Neural Networks (CNNs), Bidirectional Long Short-Term Memory (Bi-LSTM) networks, and a Transformer-based recommendation engine to deliver adaptive, real-time feedback and optimize training pathways based on individual learning patterns. A model training process used data from 300 teachers, including their activity records, questionnaires, and evaluation feedback, to achieve valid model outcomes. Educators received assessment through an established entrepreneurial competency framework at the commencement and completion of ESANN-based instruction. The quantitative evaluation included measuring skill score improvement between participants in the ESANN group and those in traditional training through accuracy metrics evaluated within ten-fold cross-validation methods. Members of the training group that received ESANN training outperformed traditional training participants by 24% in their entrepreneurial competency scores. The developed model delivered 92.5% predictive accuracy, surpassing other baseline approaches regarding performance efficiency and accuracy. ESANN serves as a deep learning framework for educational development, which provides individualized and flexible learning solutions for teacher training on a large scale. These findings highlight artificial intelligence's (AI) transformative potential in fostering entrepreneurial education through real-time, data-informed feedback.},
  archive      = {J_IJCIS},
  author       = {Li, Jian},
  doi          = {10.1007/s44196-025-00851-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Entrepreneurial skill augmented neural network (ESANN): A deep learning approach for enhancing entrepreneurial competencies in teachers},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sustainable production inventory model for power-pattern demand with carbon emissions and shelf life considerations. <em>IJCIS</em>, <em>18</em>(1), 1-32. (<a href='https://doi.org/10.1007/s44196-025-00861-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing environmental concerns, especially those related to carbon emissions from production and supply chain activities, have highlighted the need for sustainable practices. Implementing policies that incentivize low-carbon operations is crucial. To foster sustainable development, implementing penalties for high-emission commercial activities is crucial. This study investigates a sustainable production-inventory system for a product with a power-pattern demand, considering limited shelf life and gradual deterioration. The analysis integrates carbon emissions from stockholding, transportation, and deterioration, along with the impact of shortages on total costs. Two distinct scenarios are examined: Case I (without deterioration) and Case II (with deterioration). Each case is further divided into two models: one allowing shortages and the other prohibiting them. The primary objective is to determine an optimal production-inventory policy that maximizes profit per unit time while accounting for carbon emission taxes related to transportation, storage, and deterioration. Numerical results demonstrate that the total cost in Case I (without deterioration) is significantly lower than in Case II (with deterioration), with reductions of $$24.89\%$$ and $$22.02\%$$ , respectively. These findings underscore the financial implications of deterioration and shortages on sustainable inventory management. The proposed model offers valuable insights for decision-makers seeking to optimize production cycles, manage carbon footprints, and develop sustainable supply chain policies.},
  archive      = {J_IJCIS},
  author       = {Suvetha, R. and Rangarajan, K. and Dey, Bikash Koli and Alrasheedi, Adel Fahad and Ivkovic, Nikola and Jana, Chiranjibe},
  doi          = {10.1007/s44196-025-00861-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A sustainable production inventory model for power-pattern demand with carbon emissions and shelf life considerations},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving aerobics posture evaluation by transfer learning: Humanized computational application of BERT-PTA domain adaptive methods. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00867-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the influence of datasets, traditional pose evaluation methods have insufficient generalization ability, high computational resource requirements, and low efficiency. To address this issue, this article applied transfer learning into the field of aerobics posture evaluation and achieved automation and objectivity of posture evaluation through BERT-PTA (Bidirectional Encoder Representations from Transformers-Prototype-based Transfer Assistants) domain adaptive methods. BERT and PTA methods were chosen because BERT’s bidirectional language understanding and transfer learning capabilities can effectively adapt to the language instructions in the field of aerobics, and PTA’s posture tracking and humanized computing features provide an accurate and user-friendly solution specifically for the assessment of aerobics poses. First, a BERT-PTA model was established based on the collection of aerobics posture data. Second, the BERT-PTA model was used to extract features from the preprocessed posture data. Next, a convolutional neural network was used to construct a key point localization model for aerobics poses, and transfer learning was used to train and fine-tune the model. Finally, experimental verification was conducted on using transfer learning to improve aerobics posture evaluation. The results showed that the precision of using transfer learning to improve aerobics posture evaluation was 4.88% and 8.86% higher than that of the other two methods, respectively. The recall rate of using transfer learning to improve aerobics posture evaluation was 3.45% and 7.14% higher than that of the other two methods, respectively. The evaluation efficiency of using transfer learning to improve aerobics posture evaluation was 6.52–7.69% higher than that of the other two methods, respectively. In short, using transfer learning to improve aerobics can provide more scientific guidance for aerobics sports.},
  archive      = {J_IJCIS},
  author       = {Zhou, Wenting and Guo, Biao and Cao, Feng},
  doi          = {10.1007/s44196-025-00867-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improving aerobics posture evaluation by transfer learning: Humanized computational application of BERT-PTA domain adaptive methods},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovative dombi aggregation operators in linguistic intuitionistic fuzzy environments for optimizing telecommunication networks. <em>IJCIS</em>, <em>18</em>(1), 1-29. (<a href='https://doi.org/10.1007/s44196-025-00868-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network optimization is accomplished by integrating AI-powered technologies that are industry leading throughout the network lifecycle to optimize network performance in accordance with strategic objectives and maximize return on investment. These technologies utilize live and predictive network data to advance the network to its full potential, proactively resolving performance issues prior to the impact on subscribers. By employing predictive forecasting and active monitoring, these systems also assess future interconnection requirements and determine the optimal time and location to increase capacity to achieve the highest possible return, months in advance. This yields a network that is consistently operational and provides exceptional performance, customized to the strategic business objectives, and prepared to satisfy the growing performance requirements of future 5G use cases. Linguistic intuitionistic fuzzy sets (LIFSs) offer an adequate base to represent and manage unpredictability linked to intuitionistic assessments and linguistic structures. Aggregation operators (AOs) play a critical role in enhancing the decision-making (DM) procedure by adeptly managing preferences and uncertainties in multiple attribute decision-making (MADM) problems. This leads to decisions that are both more accurate and reliable. Dynamic AOs, which adjust to time-varying data, further improve flexibility and precision in DM. This research builds upon these concepts to develop novel AOs, including the LIF dynamic Dombi weighted averaging operator (LIFDyDWA), and the LIF dynamic Dombi weighted geometric operator (LIFDyDWG), and illustrates their key structural properties. An algorithm is also proposed to address the challenges of handling imprecise data in DM using the LIF dynamic Dombi aggregation approaches. These strategies are successfully applied to present a solution to an MADM problem concerning the selection of an optimal strategy to enhance the efficiency of telecommunication network systems to demonstrate their effectiveness and superiority. A comparative analysis is provided to validate the efficacy and advantages of the suggested methods over existing approaches.},
  archive      = {J_IJCIS},
  author       = {Alghazzawi, Dilshad and Hayat, Misbah and Alhamzi, Ghaliah and Baidar, Abdul Wakil},
  doi          = {10.1007/s44196-025-00868-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Innovative dombi aggregation operators in linguistic intuitionistic fuzzy environments for optimizing telecommunication networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-adjusted deep reinforcement learning for portfolio optimization: A multi-reward approach. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00875-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimization is a widely studied topic in quantitative finance. Recent advances in portfolio optimization have shown promising capabilities of deep reinforcement learning algorithms to dynamically allocate funds across various potential assets to meet the objectives of prospective investors. The reward function plays a crucial role in providing feedback to the agent and shaping its behavior to attain the desired goals. However, choosing an optimal reward function poses a significant challenge for risk-averse investors aiming to maximize returns while minimizing risk or pursuing multiple investment objectives. In this study, we attempt to develop a risk-adjusted deep reinforcement learning (RA-DRL) approach leveraging three DRL agents trained using distinct reward functions, namely, log returns, differential Sharpe ratio, and maximum drawdown to develop a unified policy that incorporates the essence of these individual agents. The actions generated by these agents are then fused by employing a convolutional neural network to provide a single risk-adjusted action. Instead of relying solely on a singular reward function, our approach integrates three different functions aiming at diverse objectives. The proposed approach is tested on daily data of four real-world stock market instances: Sensex, Dow, TWSE, and IBEX. The experimental results demonstrate the superiority of our proposed approach based on several risk and return performance metrics when compared with base DRL agents and benchmark methods.},
  archive      = {J_IJCIS},
  author       = {Choudhary, Himanshu and Orra, Arishi and Sahoo, Kartik and Thakur, Manoj},
  doi          = {10.1007/s44196-025-00875-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Risk-adjusted deep reinforcement learning for portfolio optimization: A multi-reward approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-to-one matching decision for elderly care service considering subjective and objective picture fuzzy preferences. <em>IJCIS</em>, <em>18</em>(1), 1-32. (<a href='https://doi.org/10.1007/s44196-025-00858-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an innovative many-to-one two-sided matching decision method for complex decision problems in the matching of supply and demand of elderly care services is proposed. Faced with the challenges of diversified demand and uneven supply of elderly care services in the context of an aging population, existing matching methods have significant shortcomings in subjective preference expression, objective evaluation integration, and consideration of time factors. Therefore, a many-to-one matching model in picture fuzzy environment to achieve the best matching scheme between the elderly and pension institutions is constructed in this study. By using the minimum variance method and cumulative prospect theory, subjective preference satisfaction and objective matching results for the elderly and pension institutions are obtained, respectively. Combined with regret theory, the two are compared to obtain adjusted satisfaction, and an innovative time satisfaction index based on expected check-in time is proposed to construct a three-objective optimization model that includes virtual subjects. The research in this paper expresses the subjective evaluation of two-sided subjects in the form of picture fuzzy preference relation, which enriches the research of picture fuzzy theory. At the same time, the quality of pension service matching is further improved considering time satisfaction and objective matching results in the pension service model.},
  archive      = {J_IJCIS},
  author       = {Yue, Qi and Huang, He and Hu, Bin and Tao, Yuan and Liu, Liezhang},
  doi          = {10.1007/s44196-025-00858-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Many-to-one matching decision for elderly care service considering subjective and objective picture fuzzy preferences},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep embedded auto-encoder for end-to-end unsupervised image anomaly detection. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00860-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image anomaly detection plays a critical role in industrial quality control, medical diagnostics, and security surveillance, yet existing unsupervised methods often suffer from limited detection accuracy and poor adaptability. To overcome these limitations, we propose UAD-ADC, a novel framework that automatically identifies anomalies in images without requiring labeled training data. Our approach integrates deep representation learning with adaptive clustering to effectively separate normal patterns from anomalies by learning robust feature representations and dynamically refining decision boundaries. A key innovation is our intelligent sample selection mechanism, which enhances model stability by prioritizing high-confidence normal samples during training, along with an iterative optimization strategy that progressively improves anomaly discrimination. Extensive experiments on benchmark datasets demonstrate that UAD-ADC significantly outperforms state-of-the-art unsupervised methods, with particular effectiveness under varying anomaly ratios. These advancements pave the way for more reliable and scalable unsupervised anomaly detection in practical scenarios.},
  archive      = {J_IJCIS},
  author       = {Huang, Xuan and Tang, Hailin},
  doi          = {10.1007/s44196-025-00860-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Deep embedded auto-encoder for end-to-end unsupervised image anomaly detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-UAV trajectory optimization under dynamic threats: An enhanced GWO algorithm integrating a priori and real-time data. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00863-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though the widespread use of multi-UAV systems offers significant tactical and operational advantages, achieving efficient and secure collaborative planning remains a critical challenge in dynamic threat environments. Traditional methods struggle to balance path optimization with threat avoidance, particularly in fluctuating environments where UAVs must adapt to changing threats. To address this, an enhanced Grey Wolf Optimization (GWO) algorithm is proposed for multi-UAV collaborative planning in dynamic threat zones. Our research integrates a priori knowledge of threat zone locations, speeds, and directions with real-time data on the UAVs position relative to the threat zones to effectively manage dynamic threat zones, allowing UAVs to dynamically decide whether to navigate around or through these zones, thus significantly reducing trajectory costs. To further improve search efficiency and solution quality, strategies such as greedy initialization and K-means clustering are incorporated, enhancing the algorithms multi-objective optimization capabilities. Experimental results demonstrate that the dynamic threat zone crossing strategy significantly reduces trajectory costs compared to the traditional bypass strategy. Furthermore, the enhanced GWO algorithm outperforms both the traditional GWO and MP-GWO algorithms in terms of trajectory cost and convergence accuracy. Our approach provides novel insights and methodologies for the advancement of multi-UAV collaborative trajectory planning, while extending the applicability of the GWO algorithm in complex environments},
  archive      = {J_IJCIS},
  author       = {Zhou, Zihan and Guo, Yanhong and Wang, Yitao and Lyu, Jingfan and Gong, Haoran and Ye, Xin and Li, Yachao},
  doi          = {10.1007/s44196-025-00863-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multi-UAV trajectory optimization under dynamic threats: An enhanced GWO algorithm integrating a priori and real-time data},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SIP flooding attack detection technology of multi-agent system covert network based on BiGRU algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00864-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hidden network environment of multi-agent systems is complex and intricate. The data characteristics generated by SIP flood attacks may overlap and confuse with normal traffic characteristics, and the network traffic characteristics will dynamically change over time, thereby affecting the accuracy of SIP flood attack detection. Therefore, an SIP flood detection technique based on BiGRU algorithm is proposed for covert networks in multi-agent systems. This technology is divided into two levels of detection. The primary detection collects and analyzes the hidden network data of multi-agent systems, and determines whether the traffic is abnormal by calculating the Renyi entropy value; abnormal traffic enters the second-level attack detection stage, extracting abnormal traffic from multi-agent covert networks and using the BiGRU model to learn features bidirectionally to determine whether it is an SIP flooding attack. If it is, the result of the SIP flooding attack on the multi-agent covert network is output. The experimental results show that this technology can accurately determine abnormal traffic and accurately detect the time, attacker IP, and attack frequency of SIP flooding attacks in the hidden network of multi-agent systems. The application effect is good.},
  archive      = {J_IJCIS},
  author       = {Wu, Tong and Liu, Hengyu and Li, Tong and Fan, Wei and Hu, Dawei and Bai, Jianshi},
  doi          = {10.1007/s44196-025-00864-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {SIP flooding attack detection technology of multi-agent system covert network based on BiGRU algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced wheat stripe rust segmentation approach using vision transformer model. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00873-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worldwide, the wheat industry encounters major obstacles caused by stripe rust disease, triggered by the fungus Puccinia striiformis. This disease results in considerable losses of wheat crops and has significant economic repercussions. Accurate detection of crop diseases is vital for sustainable agriculture and food security. By effectively identifying and managing crop diseases, yield losses can be prevented and global food production can be ensured. This not only protects farmers’ livelihoods but also contributes to human health and well-being by safeguarding the food supply. Wheat plays a crucial role in Pakistan’s agriculture, covering 37% of the cultivated land and contributing 70% to total production. Stripe rust, a serious fungal disease, heavily affects wheat yield, causing a global loss of 5.5 million tons annually. Current models exhibit shortcomings in accurately detecting wheat stripe rust, necessitating improvements for more precise identification and diagnosis of the disease. Fortunately, recent advances in deep learning have led to significant improvements in object-detection accuracy, thus offering hope for better disease management. The purpose of this study is to introduce a method to minimize losses by accurately and promptly detecting stripe rust disease, thereby avoiding the need for manual inspection. To achieve this goal, we propose a vision transformer and a hybrid model to identify wheat stripe rust by analyzing multi-spectral and high-resolution image data. Additionally, we utilize two models, ViT-Base/16 and a transformer, which prove to be highly effective in accurately detecting diseases using the same datasets as the vision transformer model. The proposed method provides optimal results with a vision transformer and a hybrid approach with 98% accuracy and 97.9%, respectively. ViT-Base/16 and transformer models achieve an accuracy of 98% and 95%, almost. Using an improved vision transformer, we achieved precise detection of wheat stripe rust compared to previous methods. This has various benefits, such as safeguarding yields, reducing costs, supporting sustainable agriculture, facilitating crop monitoring, and improving disease management.},
  archive      = {J_IJCIS},
  author       = {Usman, Nosheen and Ahmad, Tauqir and Iqbal, Faiza and Altaf, Ayesha and Samee, Nagwan Abdel and Alohali, Manal Abdullah and Ashraf, Imran},
  doi          = {10.1007/s44196-025-00873-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An enhanced wheat stripe rust segmentation approach using vision transformer model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On fuzzy implication functions based on admissible orders on the set of discrete fuzzy numbers. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-025-00874-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on the construction of logical connectives using total (admissible) orders is a prolific area of study. Using such orders, a new method for constructing implication functions is defined on the set of discrete fuzzy numbers with support of a closed interval of a given finite chain and whose membership values belong to a finite set of fixed values. This method is based on the use of discrete implication functions defined on a finite chain. Furthermore, a bijective correspondence between the set of implication functions on the aforementioned subset of discrete fuzzy numbers and the set of discrete implication functions defined on the discrete chain is shown. Basic properties of these implication functions are thoroughly investigated, concluding that they are preserved under the proposed construction method. This result highlights the robustness and generality of the method, providing a systematic way to extend discrete implication functions to more complex structures while preserving their underlying properties.},
  archive      = {J_IJCIS},
  author       = {González-Hidalgo, Manuel and Massanet, Sebastia and Mir, Arnau and Riera, Juan Vicente and De Miguel, Laura},
  doi          = {10.1007/s44196-025-00874-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {On fuzzy implication functions based on admissible orders on the set of discrete fuzzy numbers},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming early breast cancer detection: A deep learning approach using convolutional neural networks and advanced classification techniques. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00876-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is a major global health problem, with the WHO estimating approximately 2.3 million new cases every year. In this study, we present a new approach to improve the early detection of breast cancer using deep learning methods and visual inspection of histopathological images. In a world where access to a doctor with specialised knowledge is limited, this study attempts to address the important limitations of current diagnostic strategies that facilitate the efficient detection of diseases. In the proposed method, we use transfer learning with a combination of classifiers, such as SVM, decision trees, and K-nearest neighbours, while implementing two different feature extraction approaches, PCA for dimensionality reduction and no PCA. The approach includes a full evaluation system using metrics such as recall, accuracy, precision, and ROC curves to evaluate the performance of the models. This yields major performance gains for almost all classifiers. The experimental results showed that the SVM classifier with PCA feature extraction obtained the best accuracy of 99.5% with 99.2% precision and 99.6% recall, indicating a significant improvement over the current approach. Even without PCA implementation, the Decision Tree classifier also performed well, scoring 99.4% accuracy. In particular, the application of PCA improved the accuracy of the Boosted Tree from 82.9% to 91.01%. The execution times of classifiers varied significantly; for example, SVM, which is the fastest one as of now, with an execution time without PCA of 38.24 s. This study suggests a potential clinical tool that combines advanced deep learning methods and subsequent classification in real healthcare systems to improve breast cancer detection capabilities. This shows that the high accuracy of this framework, coupled with its computational efficiency, makes it an invaluable tool for real-life clinical applications, which could minimise misdiagnosis and lead to better patient outcomes through earlier detection of respiratory viruses worldwide, especially in remote areas with limited health-care resources.},
  archive      = {J_IJCIS},
  author       = {Singh, Arun Kumar and Mazumdar, Bireshwar Dass and Raja, Rohit and Singh, Kamred Udham and Kumar, Ankit and Shah, Mohd Asif},
  doi          = {10.1007/s44196-025-00876-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Transforming early breast cancer detection: A deep learning approach using convolutional neural networks and advanced classification techniques},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A holistic strategy of modified superpixel segmentation and randomized adam hyperparameter tuning with deep learning approaches for the classification of breast cancer from BreakHis images: In the quest for precision. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-025-00877-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is a prevalent cancer type in women worldwide, and therefore it is necessary to do early detection that is accurate for effective treatment. However, traditional ways of diagnosing through mammogram or histopathological examination may take more time and also require an interpretation from an expert. In the past few years, deep learning techniques especially Convolutional Neural Networks (CNNs) have changed medical imaging by making possible automated diagnosis which is fast. In this study, an integrated breast cancer detection approach using BreakHis images is proposed focusing on balanced accuracy rate analysis to solve imbalanced datasets problem. The methodology starts with pre-processing these images by means of Adaptive Fuzzy Filter which removes the artifacts while improving the image quality. The next step involves superpixel segmentation through SLIC-K-Means-BIRCH followed by feature extraction using SIFT with Bag of Features (BoF). The extracted features are analyzed with machine learning models such as Gaussian Mixture Model (GMM), Decision Tree (DT), Softmax Discriminant Classifier (SDC), SVM using RBF kernel and Naive Bayes Classifier (NBC) as well as deep learning models ResNet-50, VGG16, VGG19 and EfficientNet-B0. Data augmentation techniques such as image rotation and brightness adjustments were applied to enrich our dataset. R-Adam hyperparameter tuning technique was utilized to optimize these deep learning models. Results show that the modified SLIC-K-Means-BIRCH segmentation, when combined with the SIFT with BoF and EfficientNet-B0 optimized with R-Adam, yields a classification accuracy of 99.11% on augmented images. In addition, balanced classification rate analysis confirmed that this method could classify breast cancer from an imbalanced dataset effectively.},
  archive      = {J_IJCIS},
  author       = {Manivannan, Gowri Shankar and Shanmugam, Karthikeyan and Rajaguru, Harikumar and Talawar, Satish V. and Siddaiah, Rajanna},
  doi          = {10.1007/s44196-025-00877-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A holistic strategy of modified superpixel segmentation and randomized adam hyperparameter tuning with deep learning approaches for the classification of breast cancer from BreakHis images: In the quest for precision},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedMDKGE: Multi-granularity dynamic knowledge graph embedding in federated learning. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00878-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As knowledge is time-sensitive, some researchers have started to focus on dynamic knowledge graphs to provide time-dimensioned knowledge content thus reflecting richer information. But they have not yet combined temporal information at different granularities. Also, in the case of multiple knowledge graphs distributed across different clients, it is of interest to ensure that the knowledge graph embedding representations are learned without exposing data and collaboratively. Therefore, in this paper, we propose a framework for multi-granularity dynamic knowledge graph embedding in federated learning (FedMDKGE), which allows multiple parties to interact securely with temporal information at different granularities. In the client, we present a multi-granularity dynamic knowledge graph embedding model that improves the capability of dynamic knowledge graph embedding representation by focusing on multi-granularity temporal facts from the perspective of knowledge utilization. On the server, we design a multi-granularity aggregation rule to accommodate multi-party information aggregation at different granularities. Finally, we conduct extensive experiments to demonstrate the superior performance of our model. The results on these real datasets show that FedMDKGE considering multi-granularity temporal information performs better than all comparative baselines and interconnect information for multi-party dynamic knowledge graph embedding without exposing data.},
  archive      = {J_IJCIS},
  author       = {Huang, Wei and Chen, Junling and Wang, Dexian and Zhang, Pengfei and Liu, Jia and Li, Tianrui},
  doi          = {10.1007/s44196-025-00878-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {FedMDKGE: Multi-granularity dynamic knowledge graph embedding in federated learning},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and development of gorilla optimized deep resilient architecture for prediction of agro-climatic changes to increase the Crop–Yield production. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00880-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting climatic changes is considered one of the most important economic parameters as it remains a catalyst for the agricultural system of any country. Climatic data and services are crucial for agriculturalists to withstand the rising frequency of strong meteorological conditions, which negatively impact crop yields. Weather forecasts play a key role in managing resources for agricultural operations, enabling farmers to plan and protect their crops from natural disasters. In addition, global warming has fueled climatic unpredictability, creating challenges like hurricanes that damage the foundational roots of agricultural production. In recent times, Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) techniques have been predominantly adopted for daily forecasting climatic conditions, including rainfall, maximum temperature, and humidity. However, the existing models for climatic prediction require improvements in computational complexity and performance. This research article proposes the ensemble Residual Long Short-Term Memory (R-LSTM) along with Artificial Gorilla Troops Optimized Deep Learning Networks (AGTO-DLN) as a solution for climatic condition prediction to boost crop–yield production. Performance metrics for the proposed model examining precision, F1 score, accuracy, specificity, and recall operate through evaluation using 5,04,647 climatic parameters with various advanced learning techniques. The proposed method achieved 97.2% accuracy and 96.9% precision together with 96.5% recall and 96.6% specificity and 97.5% F1 score. The research proves that the proposed model demonstrates high potential for climate forecast in agricultural production environments consequently boosting crop yields to enhance farmer incomes.},
  archive      = {J_IJCIS},
  author       = {Devarashetti, Deepa and Aravinth, S. S.},
  doi          = {10.1007/s44196-025-00880-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Design and development of gorilla optimized deep resilient architecture for prediction of agro-climatic changes to increase the Crop–Yield production},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity heterogeneous ensemble model for point and interval forecasting of carbon prices. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00881-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent complexities of carbon price fluctuations and the variability of influencing factors make the accurate prediction of carbon emission prices a significant challenge. This study introduces a novel multi-granularity heterogeneous ensemble model for point and interval forecasting. First, three feature selection methods are used to identify key factors affecting carbon price and to construct multiple granular spaces. Second, the distinct features identified through feature selection methods are input into six point forecasting models. Third, the Grey Wolf Optimization (GWO) algorithm is applied to calculate the optimal weights for each individual model. Finally, the interval predictions of carbon prices are obtained by integrating the point predictions with the kernel density estimation (KDE) model. The research results indicate that the proposed model outperforms comparative models in both predictive accuracy and statistical validation, showcasing outstanding predictive performance.},
  archive      = {J_IJCIS},
  author       = {Sha, Di and Zeng, Xianyi and Tran, Kim-Phuc and Xia, Lin and Wang, Ruolin},
  doi          = {10.1007/s44196-025-00881-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A multi-granularity heterogeneous ensemble model for point and interval forecasting of carbon prices},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The two-stage alzheimer’s disease automatic diagnosis algorithm based on ST-MBV3 model. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00883-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD), commonly referred to as senile dementia, is a progressive and degenerative brain disorder that significantly impacts cognitive function and memory. As the population ages, the need for early and accurate diagnostic tools has become increasingly critical to mitigate the impact of the disease. Recent developments in medical imaging technologies, particularly magnetic resonance imaging (MRI), alongside the application of artificial intelligence (AI), have provided new avenues for improving the early detection and diagnosis of AD. This study focuses on leveraging these advancements to enhance the accuracy of AD diagnosis through a novel two-stage algorithm. The proposed model combines an improved 3D DenseNet segmentation model with an enhanced ST-MBV3 classification model. The first stage of the proposed algorithm involves processing the collected images. The resulting brain MRI images are then segmented using an enhanced 3D DenseNet model, thereby constructing a comprehensive dataset for AD classification. In the second stage, the segmented images are then classified using the ST-MBV3 model, a deep learning architecture designed for high-accuracy classification. Experimental results demonstrate impressive classification accuracies, including 98.6% for distinguishing between AD and normal control (NC), 95.97% for mild cognitive impairment (MCI) versus NC, 94.57% for AD versus MCI, and 93.12% for AD/MCI/NC classification. The proposed approach offers promising results for automated and accurate AD diagnosis. This method could play a crucial role in advancing diagnostic procedures and improving patient outcomes.},
  archive      = {J_IJCIS},
  author       = {Li, Guiping and Jin, Zhenhao and Deng, Minghui and Gong, Junjie and Zheng, Piaoyi},
  doi          = {10.1007/s44196-025-00883-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {The two-stage alzheimer’s disease automatic diagnosis algorithm based on ST-MBV3 model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using a novel neutrosophic set-based method to evaluate the design risk of aerospace manufacturing projects in a neutrosophic environment. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00886-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During product design and manufacturing stages, unexpected challenges often occur, leading to product development or production failures. These failures can adversely affect the manufacturer's production efficiency, profitability, and reputation. Therefore, the industry often uses the failure mode and effects analysis (FMEA) approach to assess risk and identify possible risk factors. Moreover, with the rapid advancement of science and technology, shortened product life cycle, and the need for diversified product functions, factors such as time constraints, increased product manufacturing complexity, and difficulties in handling cross-domain information have made risk assessment in the design and manufacturing stages increasingly complex and challenging. These complexities can be considered a complicated multi-criteria decision-making (MCDM) problem. Due to the nature of the data, qualitative and quantitative data may coexist. On the other hand, decision-makers often lack a comprehensive understanding of cross-field expertise and information, leading to incomplete and inaccurate fuzzy information judgments. This, in turn, hinders their ability to provide accurate assessments of decision-making parameters in risk assessment issues. To address these challenges, this study integrates the FMEA method, the analytic hierarchy process (AHP) method, and the neutrosophic set (NS). It then applies these methodologies to numerical examples from an aerospace electronics manufacturing project for analysis and calculation. Compared with other research methods, the experiment results revealed that the novel NS-based risk analysis method yields more reliable and accurate rankings in failure mode risk in practical applications.},
  archive      = {J_IJCIS},
  author       = {Chung, Hsiang-Yu and Chang, Kuei-Hu},
  doi          = {10.1007/s44196-025-00886-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Using a novel neutrosophic set-based method to evaluate the design risk of aerospace manufacturing projects in a neutrosophic environment},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-objective cheetah optimizer: A novel paradigm for solving complex engineering problems. <em>IJCIS</em>, <em>18</em>(1), 1-63. (<a href='https://doi.org/10.1007/s44196-025-00859-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex many-objective optimization problems (MaOPs) generate multiple challenges for obtaining convergence alongside diversity within extensive multi-dimensional solution areas. Optimization approaches currently face limitations when trying to balance exploration and exploitation especially when resources become limited. MaOCO represents the Many-Objective Cheetah Optimization Algorithm which draws its concepts from the hunting behavior of cheetahs. MaOCO includes adaptive search functions that use attack and sit-and-wait approaches to optimize exploration and exploitation capabilities. MaOCO produces hypervolume (HV) results that exceed NSGA-III and MaOMVO by 50% while also delivering inverse generational distance (IGD) results which reach 40% better than both competing methods. The algorithm demonstrates superior efficiency in solving complex MaOPs, because it requires lower computational costs by 15%. MaOCO successfully traverses Pareto-optimal fronts according to theoretical evaluations, and its modular structure allows for both scale-up and hybridization features. The implemented applications of this approach include optimizing energy systems along with designing structures for engineering projects. Future researchers plan to integrate MaOCO with additional metaheuristic techniques to improve its performance when dealing with dynamic and irregular Pareto front problems.},
  archive      = {J_IJCIS},
  author       = {Patel, Pinank and Adalja, Divya and Mashru, Nikunj and Jangir, Pradeep and Arpita and Jangid, Reena and Gulothungan, G. and Hourani, Ahmad O. and Alshammari, Kaznah},
  doi          = {10.1007/s44196-025-00859-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-63},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Many-objective cheetah optimizer: A novel paradigm for solving complex engineering problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acoustic fault diagnosis method for rotating machinery based on collaborative perception information aggregation guidance network. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00862-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-contact and directional nature of acoustic fault diagnosis offers a distinct advantage for fault detection in complex environments, ensuring the safe and stable operation of rotating machinery. However, challenges such as complex working conditions and data imbalance significantly hinder the effectiveness of acoustic-based diagnostic systems. To address these issues, this paper proposes a Collaborative Perception Information Aggregation Guidance Network (CPAGN). In the proposed method, a Stem layer is utilized at the front end to extract nonlinear acoustic features. Subsequently, the collaborative perception layer integrates local frequency information extraction, multi-receptive field temporal information fusion, and redundancy reduction, thereby capturing the time-frequency variations of acoustic signals under complex operating conditions and enhancing condition awareness. Finally, inter-layer feature correlation computation is employed to generate global channel guidance, facilitating the effective interaction and fusion of global information. The CPAGN successfully extracts critical acoustic features and identifies essential fault information, demonstrating remarkable robustness and generalizability in handling data imbalance. To validate the effectiveness of CPAGN, comparative experiments were conducted on two datasets, comparing it with several existing deep learning methods. The results indicate that CPAGN excels at capturing fault information from acoustic signals, achieving superior diagnostic performance in complex working conditions and imbalanced data scenarios.},
  archive      = {J_IJCIS},
  author       = {Li, Chaofan and Zhang, Fan and Wang, Qichen and Han, Yufei and Li, Tianrui and Teng, Fei and Yi, Cai and Wu, Yongmeng},
  doi          = {10.1007/s44196-025-00862-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Acoustic fault diagnosis method for rotating machinery based on collaborative perception information aggregation guidance network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gas consumption accounting and prediction for medium and thick steel slabs: A method combining batch integrity and heat absorption ratio. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-025-00869-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heating process of steel slabs is a critical stage in the production of medium and thick plates, significantly impacting production costs and energy efficiency. Existing research faces two major scientific challenges in gas consumption accounting and prediction for medium-thick steel slabs: (1) due to the dynamic movement of slabs, high-temperature environments, and structural constraints, it is difficult to directly measure slab temperatures and accurately quantify heat loss during the reheating process; and (2) traditional methods lack systematic consideration of batch integrity and the heat absorption ratio during the heating process, leading to low accuracy in energy consumption accounting and prediction. This paper proposes an innovative gas consumption accounting and prediction method based on batch integrity and heat absorption ratio, integrating metallurgical mechanisms and industrial big data. In the accounting phase, a 2D heat conduction finite difference method is used to calculate the heat absorption of slabs, and the batch energy consumption is allocated proportionally based on heat absorption ratios. In the prediction phase, XGBoost models are employed to predict batch gas consumption, with results distributed to individual slabs using the heat absorption ratio.},
  archive      = {J_IJCIS},
  author       = {Guo, Qiang and Liang, Xinyu and Wang, Kai and Song, Yong},
  doi          = {10.1007/s44196-025-00869-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Gas consumption accounting and prediction for medium and thick steel slabs: A method combining batch integrity and heat absorption ratio},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized DenseNet architectures for precise classification of edible and poisonous mushrooms. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00871-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subtle differences between edible and toxic mushroom species make classification difficult. Traditional methods often result in errors which led to misclassifications and conventional machine learning models often struggle in feature extraction due to subtle differences in mushroom species. Deep learning models, such as DenseNet architectures, offer potential solutions, but due to model complexity, deep architecture and large number of parameters these models suffer from overfitting and computational costs. These can be handled by optimizing the model. This study’s primary goal is to enhance the precision and reliability of mushroom classification through deep learning by enhancing the DenseNet-121 structure. This is done through the implementation of more sophisticated model regularization techniques and automating the hyperparameter optimization process. The study intends to show how model architectural changes and optimization approaches can offer solutions to issues like overfitting and significant resource expenditure on computation and ultimately improve mushroom classification systems for efficiency and efficacy. The study analyzes the basic DenseNet-121 model as well as a modified DenseNet-121 with frozen upper layers which preserve important lower level features. Automated hyperparameter tuning is done with KerasTuner, while dropout and weight decay regularization methods are used to control overfitting. Evaluation metrics include accuracy, precision, recall, F1-score, confusion matrices, and other graphical methods. The enhanced DenseNet-121 model surpasses the standard DenseNet-121 in mushroom classification. While DenseNet-121 obtained an overall accuracy of 0.90 along with a macro average precision, recall, and F1-score of 0.90 $$-$$ 0.91, Modified DenseNet-121 achieved 0.97 for all those metrics. The improvements increased the precision and recall for all the classes which means the model has less trustability and more accuracy in classification. The study demonstrates the effectiveness of architectural modifications and regularization strategies in improving model performance. Despite problems such as possible over-reliance on pre-trained features and computational complexity, the modified DenseNet-121 is useful for accurate mushroom classification. Future study could look into improving freezing procedures and lowering computational demands to extend applicability.},
  archive      = {J_IJCIS},
  author       = {Singh, Jay Prakash and Ghosh, Debolina and Singh, Jagannath and Bhattacharjee, Anurag and Gourisaria, Mahendra Kumar},
  doi          = {10.1007/s44196-025-00871-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimized DenseNet architectures for precise classification of edible and poisonous mushrooms},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling fuzzy moral hazard in credit default swap pricing: A reduced-form approach. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-025-00872-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In existing literature, moral hazard is often modeled as a constant. However, moral hazard can be “fuzzy” rather than “precisely defined.” As moral hazard is dynamic and variable, exhibiting both constancy and differentiation, its representation through fuzzy intervals—rather than fixed constants—has emerged as a meaningful research direction. This paper integrates fuzzy set theory into credit default analysis, combining moral hazard, fuzzy risk, and credit risk in a cross-disciplinary study to explore their intrinsic interdependencies. First, a novel default intensity model incorporating market state variables and moral hazard state variables is proposed. By accounting for the fuzzy risks inherent in trading environments, the moral hazard indicators are transformed into fuzzy intervals, thereby establishing interval-based moral hazard metrics to characterize default intensity. Subsequently, to address the phenomenon of default clustering caused by default dependence in markets, a circular default intensity model involving two reference assets is constructed. Within this framework, the cross-influence mechanisms of moral hazard and fuzzy risk are further investigated. Furthermore, the proposed model, which integrates moral hazard and fuzzy risk, is applied to derivative pricing. A new pricing formula for default management costs is derived. Finally, through comparative analysis and simulation experiments, the study concludes that: (1) Under the parameter settings representing economic stagnation, the triangular fuzzy interval of survival probability narrows progressively as the credibility parameter $$\gamma$$ increases, eventually converging to a real number. (2) The cost of credit default management is significantly influenced by the number of reference assets. In trading environments where moral hazard, fuzzy risk, and credit risk intertwine, effective mitigation of their impacts on default risk requires strategic information utilization and reduction in the number of reference assets. This approach not only lowers credit management costs but also fosters the healthy development of financial markets.},
  archive      = {J_IJCIS},
  author       = {Wu, Liang and Hua, Hongtao},
  doi          = {10.1007/s44196-025-00872-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Modeling fuzzy moral hazard in credit default swap pricing: A reduced-form approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven predictive modeling for lung cancer detection and management using synthetic data augmentation and random forest classifier. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00879-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) transforms multiple businesses, including medical research, where AI-driven developments bring significant advantages. The application of machine learning algorithms enables medical researchers to examine large amounts of data accurately, which leads to the development of precise and effective treatment approaches. Lung cancer leads the list of critical healthcare issues because it remains the world’s most lethal form of cancer thus demanding innovative diagnostic tools for faster and accurate identification. The proposed study introduces an innovative method called CTGAN-RF which uses conditional tabular generative adversarial networks (CTGAN) and random forest (RF) classifier to detect lung cancer through synthetic data generation. The proposed model demonstrated superior performance by achieving a 0.9893 score of accuracy and 0.99 value for precision, F1 score, and recall. Extensive experimental evaluation for this method included testing nine classification algorithms. The implementation of different classifiers employed data balancing methods including SMOTE and borderline-SMOTE along with SMOTE ENN and unbalanced data configurations. Comparative analysis showed that CTGAN-RF consistently performed significantly better than traditional classifiers in dealing with class imbalance and improving prediction accuracy. After testing with fivefold cross-validation, the reliability of the model was further validated. In comparison to cutting-edge approaches for lung cancer diagnosis, the proposed methodology outperformed in terms of classification metrics. This in-depth evaluation of synthetic data augmentation with machine learning in lung cancer detection has helped in the development of personalized treatment strategies in the fight against such a life-threatening disease.},
  archive      = {J_IJCIS},
  author       = {Innab, Nisreen and Aldrees, Asma and AlHammadi, Dina Abdulaziz and Hakeem, Abeer and Umer, Muhammad and Alsubai, Shtwai and Trelova, Silvia and Ashraf, Imran},
  doi          = {10.1007/s44196-025-00879-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {AI-driven predictive modeling for lung cancer detection and management using synthetic data augmentation and random forest classifier},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid DRL-enhanced ACO-WWO for efficient resource allocation and load-balancing in cloud computing. <em>IJCIS</em>, <em>18</em>(1), 1-40. (<a href='https://doi.org/10.1007/s44196-025-00882-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing complexity of cloud computing necessitates astute workload allocation and adaptive resource management to enhance performance while minimizing expenses and energy consumption. Conventional optimization methods, including Improved Ant Colony Optimization (IACO) and Water Wave Optimization (IWWO), face challenges in real-time adaptability, exhibit slow convergence, and are inadequate for managing rapidly varying workloads. Although IACO enhances local search efficiency and IWWO specializes in global exploration, neither adequately resolves the complexities of dynamic cloud environments. To address this gap, we propose a Hybrid DRL-IACO-IWWO model, a novel hybrid model that combines DRL with advanced iterations of IACO and IWWO. The model presents an adaptive dual-phase optimization strategy, wherein IACO conducts initial task scheduling, and IWWO enhances global optimization, informed by real-time DRL feedback. Furthermore, DRL dynamically adjusts its heuristic parameters to improve operational cost and energy efficiency, ensuring real-time adaptability. To expedite convergence, our model utilizes a wavelet transformation-based perturbation in WWO, thereby preventing premature convergence and promoting a more balanced equilibrium between exploration and exploitation. An energy-efficient scheduling mechanism is integrated to reduce energy consumption and improve cloud sustainability. The proposed model was evaluated using the workflow dataset, considering constraints, such as task deadlines, resource availability, and cost efficiency. The results indicate that our methodology outperforms leading hybrid techniques, such as ACO-GA, ACO-SMO, and WWO-GA. The proposed model achieved a scheduling duration of 1.25 s, compared to 1.75 s for ACO-GA and 1.68 s for WWO-GA, while reducing operational expenses to $23.80, lowering energy consumption to 15.6 kWh, and achieving a resource utilization score of 0.92. These findings underscore the transformative capacity of our Enhanced ACO-WWO with DRL, offering a highly efficient, cost-effective, and adaptive solution for next-generation cloud resource management.},
  archive      = {J_IJCIS},
  author       = {Lilhore, Umesh Kumar and Simaiya, Sarita and Rao, K. B. V. Brahma and Rao, V. V. R. Maheswara and Sharma, Yogesh Kumar and Alroobaea, Roobaea and Alsufyani, Hamed and Alsafyani, Majed and Khan, M. D. Monish},
  doi          = {10.1007/s44196-025-00882-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-40},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hybrid DRL-enhanced ACO-WWO for efficient resource allocation and load-balancing in cloud computing},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving search accuracy in large-scale biased multiobjective optimization through local search. <em>IJCIS</em>, <em>18</em>(1), 1-38. (<a href='https://doi.org/10.1007/s44196-025-00884-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biased multiobjective optimization problems pose a challenge for evolutionary algorithms in obtaining high-accuracy solutions, and as the number of decision variables increases, this challenge becomes increasingly difficult to overcome. To address this issue, we propose a three-particle-based local search method (TPS) for multiobjective evolutionary algorithms (MOEAs). The main concept is to use three particles to maintain three equidistant values of a decision variable and gradually approach the local optimal value by adaptively adjusting their differences. Specifically, the TPS maintains a population with three particles and uses five proposed population state-transition operations to gradually move these three particles to a better state. A local optimal value can be obtained when these three particles become indistinguishable. The TPS is then embedded into an MOEA to form a new algorithm, called MOEA/TPS. To enable the TPS to search along the convergence and diversity directions, the two aggregation functions of the target problem are alternately used. Compared with twelve competitive MOEAs on various biased test problems with 30 to 2000 decision variables, our proposed algorithm demonstrates significant advantages in obtaining high-accuracy solutions.},
  archive      = {J_IJCIS},
  author       = {Yin, Feng and Cao, Bin},
  doi          = {10.1007/s44196-025-00884-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improving search accuracy in large-scale biased multiobjective optimization through local search},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMFOSOM: A novel multi-objective Moth–Flame optimization algorithm based on self-organizing mapping. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00891-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An optimization technique seeks to identify the best solution for a given problem. When the problem involves a single objective function, the optimal solution yields the best value for that objective. However, in cases with multiple objectives, selecting the best solution becomes more complex, as these objective functions often conflict with one another. For such multi-objective optimization problems, relying on analytical or exact methods is often not feasible. This paper proposes a modified MFO called multi-objective moth–flame optimization based on self-organizing mapping (MMFOSOM) to solve multi-objective optimization problems. For attaining high-quality initial moths, dual opposition-based learning mechanism is employed to generate two distinct populations, referred to as the exploration moth (EM) and the auxiliary moth (AM). In order to enhance the search capabilities of the algorithm, each population is assigned a SOM network, the adaptive neighborhood structure of which contributes to forming modal clusters in the mapping, organizing similar solutions together. In order to select the excellent individual as the training data for SOM, a novel environmental selection mechanism is introduced. To validate the effectiveness of the algorithm, experiments will be conducted on a set of multi-objective optimization test functions. The experimental results indicate that the proposed algorithm can effectively address multi-objective optimization problems.},
  archive      = {J_IJCIS},
  author       = {Li, Zhifu and Zheng, Ziyang and Ni, Chengkai and Li, Mingzong},
  doi          = {10.1007/s44196-025-00891-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MMFOSOM: A novel multi-objective Moth–Flame optimization algorithm based on self-organizing mapping},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Publisher correction: Cross-dataset analysis of language models for generalised multi-label review note distribution in animated productions. <em>IJCIS</em>, <em>18</em>(1), 1-2. (<a href='https://doi.org/10.1007/s44196-025-00854-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Garcés, Diego and Santos, Matilde and Fernández-Llorca, David},
  doi          = {10.1007/s44196-025-00854-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Publisher correction: Cross-dataset analysis of language models for generalised multi-label review note distribution in animated productions},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy logic-based computational framework for precision triage in androgenetic alopecia: A simulated biomarker-driven approach. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00887-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Androgenetic alopecia (AGA) is a common cause of hair loss affecting both men and women. Although its precise etiology remains uncertain, genetic and hormonal factors are recognized as major contributors. This study introduces a computational intelligence framework employing fuzzy logic and multi-criteria decision-making (MCDM) to simulate a robust triage system for AGA management. Using a simulated dataset of 100 AGA patients, we applied the fuzzy-weighted zero-inconsistency (FWZIC) method to assign weights to 11 bioactive criteria associated with AGA. These weights informed a novel triage procedure for alopecia patients (TPAP), which stratified patients into seven severity levels (level 1: minor; level 7: severe). This study presents a computationally intelligent triage model tailored for AGA, emphasizing the applicability of fuzzy MCDM techniques in medical decision support. The TPAP framework can assist in resource allocation and treatment planning, paving the way for personalized and timely interventions in hair loss management.},
  archive      = {J_IJCIS},
  author       = {Al-Samarraay, Mohammed S. and Magableh, Aws A. and Mahmood, Rana I. and Joudar, Shahad Sabbar and Zahid, Idrees A. and Al-Obaidi, Jameel R. and Al-Saffar, Ali Z. and Albahri, A. S. and Albahri, O. S. and Alamoodi, A. H. and Abdullah, Mohd Faizal Nizam Lee},
  doi          = {10.1007/s44196-025-00887-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A fuzzy logic-based computational framework for precision triage in androgenetic alopecia: A simulated biomarker-driven approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intrusion detection and mitigation method for the industrial internet of things using bidirectional convolutional long short-term memory and deep recurrent convolutional Q-networks. <em>IJCIS</em>, <em>18</em>(1), 1-38. (<a href='https://doi.org/10.1007/s44196-025-00890-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical system (CPS) security has become more important in the age of Industry 4.0 because of the quick integration of automation and the Internet of Things. The goal of this project is to create a strong intrusion detection and control system that can recognize and lessen security risks in CPS settings. The suggested approach makes use of deep learning (DL) and reinforcement learning (RL) techniques. To guarantee data consistency, pre-processing procedures such as mean-based imputation and min–max scaling come after data collection. ADASYN data augmentation is used to address class imbalance, while entropy analysis and statistical techniques are used to extract key features. The intrusion detection phase uses a combination of deep convolutional neural networks (DCNN) and bidirectional long short-term memory (BI-LSTM) networks to capture both spatial and temporal relationships in the data, while a hybrid feature selection technique improves the model’s performance. A deep Q-network (DQN) handles attack mitigation and uses reinforcement learning to adjust to new threats. Detecting attack patterns with high sensitivity (0.984), specificity (0.983), and accuracy (0.991626) for dataset 1, the accuracy of dataset 2 is 0.985 for 70% of training and 0.988 for 80% of training, and the Proposed-DBID-Net architecture enhances CPS security in Industry 4.0. The evaluation phase emphasizes how crucial feature selection is to maximize the model’s accuracy. In conclusion, this study offers a thorough and flexible method for protecting CPS in Industry 4.0, guaranteeing accuracy and scalability across changing cyber threats.},
  archive      = {J_IJCIS},
  author       = {Yan, Zhang and Shukla, Piyush Kumar and Shukla, Prashant Kumar and Thakur, Kanika and Sinha, Anurag and Khalid, Saifullah},
  doi          = {10.1007/s44196-025-00890-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Intrusion detection and mitigation method for the industrial internet of things using bidirectional convolutional long short-term memory and deep recurrent convolutional Q-networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential evolution-based transient search optimizer for image multi-thresholding problem. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00821-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant number of image processing and evaluation processes are presented and applied, due to their practical significance, in a variety of disciplines in the literature related to image processing and computer vision. One pre-processing approach that is frequently used to improve the information in a class of images is thresholding. By grouping correlated pixels according to the selected thresholds, the thresholding approach improves the image. For the benchmark image suite in this study, an entropy-based threshold is put into place. This study aims to investigate the thresholding performance of well-recognized fitness function called Kapur’s entropy, for a selected threshold. To facilitate the automatic identification of the optimum threshold (Th) on the benchmark images for a specified threshold value $$(Th=3, 5, 7)$$ , there is a need for an optimization algorithm that determines the optimum threshold values for the given image under study. This research proposed a self-adaptive hybrid differential evolution (DE) based transient search optimizer (TSO) called DETSO. DETSO uses the search equations of DE algorithm to improve the exploration capability of original TSO. Additionally, self-adaptivity has been included by modifying scaling factor and crossover rate using exponential decreasing and logarithmic decreasing mutation operator, respectively. The CEC 2019 numerical test problems have been used to confirm the working efficiency of DETSO. The experimental investigation confirms that utilizing a benchmark image test suite with varying dimensions, the DETSO helps to get superior results in achieving better threshold values in terms of performance metrics, such as PSNR, SSIM, FSIM, MSE, etc., compared to the other competitive heuristic algorithms.},
  archive      = {J_IJCIS},
  author       = {Mittal, Nitin and Singh, Supreet and Kumar, Lalit and Kaur, Gurpreet and Mittal, Vikas and Santhosh, A. Johnson},
  doi          = {10.1007/s44196-025-00821-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Differential evolution-based transient search optimizer for image multi-thresholding problem},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid optimizer based on coati optimization algorithm and differential evolution for global optimization and constrained engineering problems. <em>IJCIS</em>, <em>18</em>(1), 1-70. (<a href='https://doi.org/10.1007/s44196-025-00855-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel hybrid metaheuristic, the Hybrid Coati Optimization Algorithm with Differential Evolution (HCOADE), developed to address complex global optimization tasks and constrained engineering design problems. HCOADE integrates the exploration-driven behaviour of the Coati Optimization Algorithm (COA)-inspired by the social foraging and predation strategies of coatis-with the powerful mutation and crossover mechanisms of Differential Evolution (DE), thereby achieving a balanced and adaptive search process. The hybridization enhances global exploration and local exploitation, enabling the algorithm to efficiently navigate diverse and challenging optimization landscapes. To rigorously evaluate its performance, HCOADE is tested on benchmark suites from CEC 2014, 2017, 2020, and 2022, which encompass unimodal, multimodal, hybrid, and composition functions. It is also applied to real-world constrained engineering problems, such as pressure vessel design, cantilever beam optimization, and reinforced concrete beam design. Comparative experiments against state-of-the-art algorithms—including COA, DE, RSA, PSO, SSA, BBO, QIO, DMOA, and others—demonstrate that HCOADE consistently delivers superior solution quality, faster convergence, and higher robustness. Quantitative results show that HCOADE achieved the 1st place average rank across all four benchmark suites. It obtained top performance on 80% of the functions in CEC 2014, 66.7% in CEC 2017, 70% in CEC 2020, and 66.7% in CEC 2022. Furthermore, HCOADE outperformed or matched CEC competition-winning algorithms such as LSHADE-cnEpSin, LSHADE-SPACMA, and CMA-ES on numerous challenging functions of CEC 2017. Statistical analyses, including Wilcoxon Rank Sum Tests and ranking evaluations, confirm the significance and reliability of HCOADE’s performance. Furthermore, convergence behaviour, measurement of exploration and exploitation, and sensitivity analysis highlight the algorithm’s adaptability and stability across varied problem domains. This study contributes a computationally efficient and generalizable hybrid optimization framework, offering a promising solution for theoretical benchmarks and real-world engineering applications.},
  archive      = {J_IJCIS},
  author       = {Biswas, Saptadeep and Maiti, Binanda and Singh, Gyan and Ezugwu, Absalom E. and Saleem, Kashif and Abualigah, Laith and Smerat, Aseel and Bera, Uttam Kumar},
  doi          = {10.1007/s44196-025-00855-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-70},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel hybrid optimizer based on coati optimization algorithm and differential evolution for global optimization and constrained engineering problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classifying and detecting live insects with computationally effective deep learning object detection models. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00885-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A crucial part of agriculture is detecting insects that increase yield productivity. Insects in agricultural land are both helpful and harmful. The harmful insects are detected and controlled as early as possible, but these control measures should not affect the beneficial insects that help crops to grow. The existing pest detection models are image-based models where the preciseness of the insect detection is based on their appearance in the respective image, which may lead to the misclassification of insect classes if the insects are not present in the image properly. By analyzing consecutive frames rather than a still image, the proposed approach detects live insect objects from the video rather than a still image, where the presence of insects is identified by analyzing consecutive frames. As a result, insects can be detected without relying on the appearance of a single still image, which helps mitigate insects' misclassification. A wide range of applications in computer vision has proven that deep learning approaches are highly effective and popular. This study employs a variety of three deep learning-based object detection networks coupled with multiple backbone networks to maximize their efficiency. Each model is initially pre-trained using the COCO dataset to improve its performance. Experimental results show that SSD_MobileNet_V2 outperformed other models on insect classification and detection tasks. Regarding insect classification tasks, the SSD_MobileNet_V2 achieved an accuracy and F1 score of 98.02% and 97.99%, respectively. On the insect detection task, the mAP is 98.8% at a detection time of about 0.18 s. Also, it is delivered with a smaller model size of 6.5 MB, making it suitable for handheld devices.},
  archive      = {J_IJCIS},
  author       = {Rajeswaran, Arumuga Arun and Katara, Karthik and Selvaraj, Yoganand and Sundarasamy, Ranjithkumar},
  doi          = {10.1007/s44196-025-00885-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Classifying and detecting live insects with computationally effective deep learning object detection models},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating shallow and deep features for precision evaluation of corn grain quality: A novel fusion approach. <em>IJCIS</em>, <em>18</em>(1), 1-12. (<a href='https://doi.org/10.1007/s44196-025-00889-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the precision evaluation of corn grain quality, focusing on categorizing seeds into four classes: broken, discolored, pure, and silk cut. We evaluated 13 pre-trained CNN models, including AlexNet, VGG19, and ResNet, with AlexNet emerging as the top performer, achieving 71% accuracy validated through statistical analysis using Duncan’s multiple range test. To further enhance accuracy, we propose a novel fusion approach that integrates shallow features—extracted via 2D Discrete Fourier Transform (2D-DFT) and Hilbert transform—from the images with deep features from AlexNet. The deep features are combined with these shallow features to create an enriched feature vector. This vector, consisting of 1000 deep features, 140 2D-DFT features, and 140 Hilbert transform features, is classified using a Support Vector Machine (SVM). The hybrid model achieved an accuracy of 86%. Manual grain quality assessment is subjective and time-consuming; our automated framework addresses this challenge by providing a more objective and efficient evaluation. The integration of diverse features not only improves classification accuracy but also underscores the potential of combining various information sources for robust grain quality assessment.},
  archive      = {J_IJCIS},
  author       = {Mishra, Kunal and Behera, Santi Kumari and Devi, A. Geetha and Sethy, Prabira Kumar and Nanthaamornphong, Aziz},
  doi          = {10.1007/s44196-025-00889-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Integrating shallow and deep features for precision evaluation of corn grain quality: A novel fusion approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel YOLO algorithm integrating attention mechanisms and fuzzy information for pavement crack detection. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00894-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pavement crack detection is widely spread over road maintenance, ensuring the longevity and safety of infrastructure. Traditional manual inspection methods are time-consuming, labor-intensive, and prone to errors. In response, automated crack detection systems based on deep learning have emerged, offering more efficient and accurate solutions. However, existing models often face challenges such as large model sizes, slow inference speeds, and limited applicability in real-time applications. In this paper, we propose a novel light-weight Crack Regional Segmentation method based on YOLOv11, which introduces attention mechanisms to address challenges in pavement images, such as varying crack sizes, occlusion, and irregular surface textures. By embedding a region-based attention mechanism into the YOLOv11 network, the method enhances the model’s ability to focus on crack features. Specifically, the model network layers are progressively pruned to reduce the number of parameters and floating-point operations, thereby further improving operational efficiency and refining detection in the target regions. Furthermore, to tackle issues with blurred or indistinct crack boundaries, we present a fuzzy information-guided YOLOv11-based model, FIG-YOLO. This model integrates fuzzy logic and fuzzy membership functions to handle uncertainty in crack detection. The fuzzy membership functions are used to quantify the degree of crack features, allowing the model to better distinguish between crack and non-crack regions, especially in cases where crack boundaries are unclear. This approach significantly improves the accuracy of crack detection and segmentation. Extensive experiments demonstrate that our approach effectively addresses challenges such as complex backgrounds and blurred crack edges in pavement images. This research not only provides a novel solution for the automated detection of pavement cracks but also offers insights into the development of intelligent road maintenance systems. With the expansion of large-scale datasets and the advancement of deep learning models, pavement crack detection algorithms are expected to further enhance their accuracy and efficiency, offering significant support for road infrastructure management.},
  archive      = {J_IJCIS},
  author       = {Li, Qingqing and Wu, Tianshu and Xu, Tingfa and Lei, Jianmei and Liu, Jiu},
  doi          = {10.1007/s44196-025-00894-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel YOLO algorithm integrating attention mechanisms and fuzzy information for pavement crack detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting detection accuracy: An enhanced YOLOv8 for small target detection in remote sensing. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00895-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in remote sensing images has broad applications in military reconnaissance, urban planning, and disaster management. However, detecting small targets and extracting multi-scale features in complex scenes remain challenging. This paper presents YOLOv8s-Improved, enhancing small-target detection via PPHGNetV2, Progressive Feature Pyramid Network (AFPN-P2), and Diverse Branch Block (DBB) modules. Experiments on the DIOR and VisDrone2019 datasets show that YOLOv8s-Improved achieves mAP scores of 0.824 and 45.3%, respectively, representing improvements of 1.5 and 6.4 percentage points over the baseline YOLOv8s model (0.809 and 38.9%). The improved model demonstrates strong performance in multi-category object detection, particularly in complex scenes. The results suggest that the proposed method addresses the challenges of small target detection in remote sensing and exhibits generalization capabilities across different datasets.},
  archive      = {J_IJCIS},
  author       = {Chen, Boyuan and Ma, Zheng and Li, Xiang},
  doi          = {10.1007/s44196-025-00895-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Boosting detection accuracy: An enhanced YOLOv8 for small target detection in remote sensing},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive BlockVax distribution: Enhancing healthcare supply chain resilience with blockchain and LSTM. <em>IJCIS</em>, <em>18</em>(1), 1-26. (<a href='https://doi.org/10.1007/s44196-025-00897-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pandemic outbreak has revealed significant flaws in the complex and highly fragmented Healthcare Supply Chain’s (HSC’s). However, two major issues persist in the HSCs, leading to inefficiencies: transparency in vaccine distribution and accuracy in demand forecasting. The recent pandemic has highlighted and intensified existing vulnerabilities in HSC’s, leading to the effective utilization of digital technologies to manage them. This research proposes a novel framework that merges Blockchain (BC) and Machine Learning (ML) to bolster the HSCs amidst pandemics, by developing a framework named the Predictive BlockVax Distribution Network (PBDN) model. The proposed PBDN model utilizes BC for securing transactions and Long Short-Term Memory (LSTM), for precise demand prediction. Leveraging Hyperledger Besu, which represents an Ethereum client that is accessible for public use, the PBDN framework ensures BC’s privacy, scalability, and efficient network operations, while LSTM’s advanced forecasting outperforms traditional models and Deep Learning (DL) techniques. This integration showcases a significant leap in managing vaccine distribution and enhancing system resilience, fairness, and transparency. The proposed PBDN model illustrates the potential of BC and ML together to tackle pandemic-induced Supply Chains (SC’s) disruptions, providing a decentralized solution that supports autonomous, informed decision-making without third-party dependency. This approach not only addresses immediate challenges but also sets a precedent for future crisis response, emphasizing the need for robust, Transparent Supply Chain’s (TSC’s).},
  archive      = {J_IJCIS},
  author       = {Nair, Raji Ramakrishnan and Rattan, Punam and Kumar, Mukesh and Bhardwaj, Vivek},
  doi          = {10.1007/s44196-025-00897-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Predictive BlockVax distribution: Enhancing healthcare supply chain resilience with blockchain and LSTM},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Construction scheduling optimization of prefabricated buildings under resource constraints based on an improved whale optimization algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00898-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prefabricated construction offers significant advantages in efficiency, resource savings, and environmental sustainability, yet its scheduling remains challenging due to complex resource constraints and task interdependencies. This study proposes a dual-objective optimization model to minimize project duration and resource fluctuation in prefabricated construction projects. To solve this model effectively, an Improved Whale Optimization Algorithm (IWOA) is developed, addressing the limitations of the standard WOA such as premature convergence and poor local search ability. The proposed IWOA incorporates Tent chaotic mapping for population diversification, a nonlinear convergence factor to balance exploration and exploitation, and a hybrid search mechanism that integrates crossover operations and multiple neighborhood strategies. A real-world case study demonstrates the algorithm’s superiority over conventional approaches in both solution accuracy and stability. The results show that the optimized schedule significantly improves resource allocation efficiency and reduces construction time, offering a promising approach for intelligent scheduling in resource-constrained prefabricated building projects.},
  archive      = {J_IJCIS},
  author       = {Su, Rui and Aviles, Joey S.},
  doi          = {10.1007/s44196-025-00898-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Construction scheduling optimization of prefabricated buildings under resource constraints based on an improved whale optimization algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing and rewarding credit card spending habits in india: A machine learning approach. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00899-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid adoption of digital payments in India, credit card companies are focusing on customer loyalty and planning rewards to incentivize spending, especially during peak periods like festivals. However, there is a gap in developing a tailored system that optimizes sales and reward structures for these companies. The proposed work addresses this gap by leveraging machine learning techniques to analyze and assess credit card spending patterns and propose design targeted reward programs. Besides this, this study focuses on categories as luxury, travel, groceries, EMIs payments, and others and employs ML methods, using K-Means clustering to segment users based on card types (Silver, Gold, Platinum, and Signature). Feature engineering is another key in improving the model’s understanding and providing insights, particularly in calculating reward points based on various attributes and spending behavior. The usage of original and synthetic datasets ensured scalability and adaptability across different financial domains as well. The results highlight the potential and need of ML to optimize reward allocation and provide real-time predictions, enabling financial institutions to tailor their offerings for increased customer engagement and retention. By aligning rewards with high-margin spending categories and leveraging adaptive frameworks, this study offers strategies to enhance credit card reward programs. The proposed ML model achieved an R2 value of 0.99, demonstrating superior accuracy in optimizing reward point distribution.},
  archive      = {J_IJCIS},
  author       = {Agrawal, Renuka and Khanna, Aryan and Hamdare, Safa},
  doi          = {10.1007/s44196-025-00899-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Analyzing and rewarding credit card spending habits in india: A machine learning approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect sentiment triplet extraction with syntax-semantics graph convolutional network. <em>IJCIS</em>, <em>18</em>(1), 1-17. (<a href='https://doi.org/10.1007/s44196-025-00900-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the traditional task of aspect sentiment triplet extraction, existing approaches typically focus on either syntactic or semantic features independently, failing to leverage the complementary integration of these two types of information. Although graph convolutional network-based approaches have demonstrated impressive performance in triplet extraction tasks, they often ignore distance features and semantic information when capturing sentence information. As a result, the integration of syntactic and semantic information remains suboptimal, negatively impacting sentiment analysis performance. To address this limitation, we propose a novel Syntax-Semantics Graph Convolutional Network for aspect sentiment triplet extraction. Our method first extracts syntactic structural information using the probability matrix of dependency trees, from which a mask matrix is constructed based on the varying distances between words. Next, semantic information is captured via a self-attention mechanism and an aspect-attention mechanism, utilizing an attention score matrix. Finally, an interaction module is introduced to effectively integrate syntactic and semantic features. Extensive experiments on several benchmark datasets demonstrate that our approach significantly outperforms existing baselines, achieving an average F1-score improvement of at least 1.083%.},
  archive      = {J_IJCIS},
  author       = {Zhang, Jingyun and Xu, Shuwei and Gao, Xin and Tang, Zhiwei},
  doi          = {10.1007/s44196-025-00900-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Aspect sentiment triplet extraction with syntax-semantics graph convolutional network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Drought detection in satellite imagery: A layered ensemble machine learning approach. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00903-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drought has been a major calamity due to climate change in recent years. Predicting drought has grabbed the attention of meteorologists and climate scientists, who study and look for modern techniques. The early detection of drought leads to better management of resources and timely decisions to avoid damage. Machine learning techniques have proven their potential in classification and prediction problems. This study proposes a layered ensemble machine learning approach to detect drought from satellite imagery. The satellite imagery is collected using Google Earth Pro for the region ’Tharparkar’ in Pakistan’s Sindh province. Tharparkar is one of the most drought-stricken regions in Pakistan. The proposed approach combines conventional machine learning algorithms (Support Vector Machine (SVM), Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), Naive Bayes (NB), and k-Nearest Neighbor (k-NN)) with ensemble methods (Bagging and Voting) in a layered fashion for detecting drought from satellite imagery. The novelty of the study lies in its layered ensemble architecture that integrates multiple conventional classifiers with ensemble techniques for improved drought detection accuracy using satellite imagery. The validation of the model is computed using the stratified split method. The developed classification model is evaluated using well-established indexes, including accuracy, precision, recall, F measure, and Area Under Curve (AUC). Among the classical models, the Decision Tree classifier performed best with an accuracy of 82.17%, a precision of 82.53%, a recall of 82. 28%, and an F1 score of 82.35%. Within the Bagging models, Bagged Decision Tree achieved the highest performance, attaining an accuracy of 84.78%, a precision of 85.14%, a recall of 84.87%, and an F1 score of 84.91%. The final-layer Voting ensemble outperformed all previous models, yielding the highest F1 score of 84.80%. Based on experimental results, the proposed model has strong potential for practical deployment in real-world environmental monitoring systems.},
  archive      = {J_IJCIS},
  author       = {Raza, Muhammad Owais and Mahoto, Naeem Ahmed and Al Reshan, Mana Saleh and Alqazzaz, Ali and Rajab, Adel and Shaikh, Asadullah},
  doi          = {10.1007/s44196-025-00903-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Drought detection in satellite imagery: A layered ensemble machine learning approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy decision systems for sustainable public transport: A literature review. <em>IJCIS</em>, <em>18</em>(1), 1-29. (<a href='https://doi.org/10.1007/s44196-025-00904-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of sustainable transport has been proposed and implemented in cities around the world to facilitate transition to sustainability. Reducing carbon emissions and increasing accessibility in an economically feasible way has been the core objective of sustainable transport initiatives in cities. The complexity of the transport systems requires a decision framework that would take this complexity as well as uncertainty into account while proposing solutions for sustainable transport issues. Current worldwide developments, such as the COVID-19 outbreak and international tensions, economic crises, and climate change, have heightened uncertainty regarding decisions that affect sustainable transportation challenges. Classical decision methods are no longer sufficient to tackle sustainable transport issues in this economically, socially, and environmentally uncertain environment. This is evidenced by the rapid proliferation of the studies using some sort of fuzzy decision systems on developing solutions for sustainable transport problems. Fuzzy decision systems provide new frameworks of decision-making that would appropriately take the uncertainty into account for the sustainable transport decisions and problems. This study provides an overview of existing research on studies that utilize fuzzy decision systems for sustainable public transport, excluding logistics transport from its scope. Additionally, a thematic analysis is conducted on the types of fuzzy decision methods and sustainable transport topics, aiming to summarize the existing literature and guide future research in this field.},
  archive      = {J_IJCIS},
  author       = {Kilic, Mehmet and Demirel, Tufan},
  doi          = {10.1007/s44196-025-00904-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fuzzy decision systems for sustainable public transport: A literature review},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on container storage optimization in yards based on a hyper-heuristic algorithm with a Q-learning mechanism. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00905-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of a low-carbon economy, scientific methods to reduce carbon emissions have become an important issue for many ports. Carbon emissions in port areas mainly arise from vessels and handling equipment. Therefore, an effective resource assignment and equipment arrangement system could not only reduce carbon emissions, but also improve the port’s operational efficiency. This study considers factors such as the arrival order of container trailers, the cargo weight, and the number of container rehandling operations. The objective is to minimize the carbon emissions and the number of container rehandling operations in ports, for which a mixed-integer linear programming model is built. Both heuristic algorithms and hyper-heuristic algorithms are employed to optimize the container storage plan, and their applicability in storage optimization is compared. The results indicate that hyper-heuristic algorithms outperform heuristic algorithms in terms of solution quality and stability, effectively satisfying the storage requirements of the yard while minimizing the carbon emissions and the number of container rehandling operations. The results provide theoretical support for port enterprises in improving their operational efficiency and achieving their goals regarding low carbon emissions.},
  archive      = {J_IJCIS},
  author       = {Chen, Lifen and Lin, Jiajun and Xu, Shihao},
  doi          = {10.1007/s44196-025-00905-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A study on container storage optimization in yards based on a hyper-heuristic algorithm with a Q-learning mechanism},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in industry, knowledge computing and decision-making. <em>IJCIS</em>, <em>18</em>(1), 1-3. (<a href='https://doi.org/10.1007/s44196-025-00910-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Montero, Javier and Rodríguez, J. Tinguaro and Flores-Vidal, Pablo},
  doi          = {10.1007/s44196-025-00910-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Artificial intelligence in industry, knowledge computing and decision-making},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Face anti-spoofing detection based on novel encoder convolutional neural network and texture’s grayscale structural information. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00757-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise in popularity of face anti-spoofing is attributed to its crucial role in safeguarding face recognition systems. Perpetrators use either a photo or a video to execute a face-spoofing attack on the authentication system of an authorized user, aiming to gain access to the user’s resources. Traditional face anti-spoofing detection techniques often rely on grey texture elements while disregarding RGB color intensity features in face images, which lead to a loss of certain facial information. On the other hand, RGB-based methods could introduce noise or superfluous elements that reduce the effectiveness of spoofing detection. Furthermore, in real-world situations, color disparities may be introduced by lighting, camera settings, and other elements. Therefore, a face anti-spoofing detection approach based on a novel Encoder Convolutional Neural Network (ECNN) architecture, Local Binary Pattern (LBP) and Local Ternary Pattern (LTP) descriptors is proposed. The proposed ECNN can more effectively extract the RGB color brightness features. It encodes the brightness intensity change of the RGB color transition, which can recognize intricate spoofing attempts. The texture descriptors of LBP and LTP are utilized to extract the texture's grayscale structural information to overcome different environmental situations. This work combined the human face's intensity RGB color and grey texture categorization parameters to increase the detection accuracy of face spoofing and produce positive experimental outcomes. We contrast our proposed method with alternative algorithms and verify its performance using three publicly available datasets, showcasing its superiority.},
  archive      = {J_IJCIS},
  author       = {Radad, Marwa and Enab, Amira E. and Elagooz, Salah S. and El-Fishawy, Nawal A. and El-Rashidy, Mohamed A.},
  doi          = {10.1007/s44196-025-00757-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Face anti-spoofing detection based on novel encoder convolutional neural network and texture’s grayscale structural information},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MM-HGNN: Multimodal representation learning heterogeneous graph neural network. <em>IJCIS</em>, <em>18</em>(1), 1-26. (<a href='https://doi.org/10.1007/s44196-025-00820-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal learning heterogeneous graphs are very challenging because of the diverse structures and data modalities. The existing graph neural networks cannot efficiently capture both the multimodality of the data and the inherent heterogeneity of such graphs. In this paper, we propose Multimodal Representation Learning Heterogeneous Graph Neural network (MM-HGNN) to tackle these challenges. MM-HGNN introduces a novel Modality Transferability Function to quantify the heterogeneity between different modalities, which allows the model to dynamically adjust the attention scores and give precedence to unique information that is non-redundant. Additionally, it integrates modality-level attention that distributes attention in an adaptive way over different modalities according to their relevance, enhancing feature representations for tasks such as node classification. To further improve representation learning, a splicing mechanism is proposed to integrate outputs from multiple network layers, combining high-level features for more expressive node embeddings. We validate the effectiveness of MM-HGNN through extensive experiments on the IMDB and Amazon datasets. Our model outperforms several state-of-the-art methods under the Macro-F1, Micro-F1, and AUC metrics by a large margin, which well demonstrates its strong capability in dealing with the challenging multimodal and heterogeneous data. Comprehensive ablation studies further emphasize the contributions of each key component in improving the overall performance.},
  archive      = {J_IJCIS},
  author       = {Bachiri, Khalil and Yahyaouy, Ali and Malek, Maria and Rogovschi, Nicoleta},
  doi          = {10.1007/s44196-025-00820-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MM-HGNN: Multimodal representation learning heterogeneous graph neural network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An anomaly detection method for industrial system cybersecurity based on GGL-WAVE-CNN. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00832-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalies in industrial system cybersecurity is critical for enabling automated decision-making. Current approaches often struggle to handle complex, unknown topological time series data, thereby necessitating improved anomaly detection accuracy. This paper introduces a novel two-level anomaly detection framework that combines the generalized graph Laplacian (GGL), wavelet decomposition (WAVE), and an enhanced convolutional neural network (CNN). In the first level, the proposed method employs the GGL to efficiently identify abnormal windows in industrial time series data. In the second level, a precise anomaly detection technique is developed to analyze the abnormal windows identified by GGL, leveraging wavelet decomposition for feature extraction and a refined CNN for classification. The effectiveness of the proposed GGL-WAVE-CNN approach is validated using a real-world dataset capturing SCADA system network traffic from a facility in China. Experimental results demonstrate a true positive rate (TPR) of 97.54%, highlighting the robustness and accuracy of the proposed method in addressing complex industrial cybersecurity challenges.},
  archive      = {J_IJCIS},
  author       = {Zou, Bing and Zhang, Ke jun and Yu, Xin Ying and Jin, Yu han and Wang, Jun and Liu, Ling yu},
  doi          = {10.1007/s44196-025-00832-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An anomaly detection method for industrial system cybersecurity based on GGL-WAVE-CNN},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid domain perception combined with multi-expert decoding to improve image forgery localization. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-025-00892-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancements in multimedia software and hardware technology, image forgery localization has become an important challenge in digital forensics. To improve the efficiency and stability of image forgery detection, we propose a mixed-domain perception and multi-expert decoding recognition model. First, we design an alignment strategy that utilizes both RGB and frequency domain information of images. This strategy adapts to the multi-dimensional distribution characteristics of the original data, enhancing the discrimination of tampered regions. Next, we employ a hybrid expert modeling approach to improve the model’s robustness in the representation space through feature selection and recombination. Additionally, we introduce a region-weighted contrastive learning method to better localize and focus on tampered regions. Experiments on four datasets (CASIA, NIST, COVERAGE, and IMD) show that our proposed model achieves an improvement in AUC ranging from 0.15 to 1.9% compared to the existing advanced methods. These results indicate that our approach contributes to more accurate image forgery localization, offering potential benefits for digital forensics and multimedia security applications.},
  archive      = {J_IJCIS},
  author       = {Gong, Xuchao and Duan, Hongjie and Zhang, Peiying and Wang, Jian and Liu, Kai and Li, Zhaohui},
  doi          = {10.1007/s44196-025-00892-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hybrid domain perception combined with multi-expert decoding to improve image forgery localization},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy optimization and efficiency improvement model for enterprise production process based on deep learning under the background of carbon peak and carbon neutrality. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00901-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving carbon peak and carbon neutrality requires industries to enhance energy efficiency and optimize resource utilization. Traditional energy management methods rely on rule-based or static optimization approaches, which struggle to adapt to dynamic production environments and fluctuating energy demands. These limitations lead to inefficient energy use, increased operational costs, and challenges in meeting sustainability goals. This research introduces Deep Learning-based Green Optimization for Enterprise Production (DeepGreen-Opt), a deep learning-driven framework designed to analyze energy consumption patterns, predict demand, and optimize resource allocation in real time. The DeepGreen-Opt framework integrates Long Short-Term Memory (LSTM) for accurate energy consumption forecasting and Adaptive Hybrid Particle Swarm Optimization (AHPSO) for dynamic energy optimization. A fuzzy logic-based decision system is incorporated to enhance adaptability under uncertain conditions, enabling real-time adjustments to fluctuating energy demands. The DeepGreen-Opt framework was specifically validated across multiple industrial sectors, including automotive manufacturing, steel production facilities, and chemical processing plants, where intelligent energy management demonstrates significant operational improvements. By implementing DeepGreen-Opt, enterprises can achieve cost-effective production while aligning with sustainability objectives. The framework ensures energy-efficient operations, reducing resource waste and improving production efficiency. Experimental validation on industrial datasets demonstrates a 15% increase in energy efficiency and a 12% improvement in overall production performance compared to existing approaches. This research highlights the potential of DeepGreen-Opt in industrial energy management, providing a foundation for future advancements in intelligent and sustainable production processes.},
  archive      = {J_IJCIS},
  author       = {Bai, Hui and Chen, Yiyi and Bai, Hua and Liu, Meiling and Fan, Yu},
  doi          = {10.1007/s44196-025-00901-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Energy optimization and efficiency improvement model for enterprise production process based on deep learning under the background of carbon peak and carbon neutrality},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SUMMARIA — A XAI support methodology by generating composite linguistic summaries of qualitative data. <em>IJCIS</em>, <em>18</em>(1), 1-39. (<a href='https://doi.org/10.1007/s44196-025-00908-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main stream of Linguistic Data Summarization involves modeling numerical attributes using linguistic variables, which makes it difficult addressing real-world problems with qualitative or mixed data. Literature highlights challenges such as the limited expressiveness of summaries from classical protoforms, the need to explore relationships between them to find more useful patterns and refining language to improve their interpretability and usefulness. The latter is increasingly significant as the demand for explainability grows with the rise of black-box AI applications. This paper proposes SUMMARIA, a XAI support methodology by generating composite (enriched) linguistic summaries of qualitative data. A framework is formalized integrating Linguistic Data Summarization with the concept of rhetorical relation and defining the structure and quality metrics of a composite linguistic summary. Three abstract forms of composite linguistic summaries representing Evidence, Contrast and Emphasis relations are specified, inspired by Rhetorical Structure Theory. Also, a method based on Association Rules Mining, implements SUMMARIA in problem-solving via five algorithms. An empirical study tested SUMMARIA’s application on two judicial datasets and a substantially different behavior was found for four different scenarios, which reveals its sensitivity to the nature and distribution of the primary data. A human-expert validation was performed showing that the linguistic summaries are understandable and the relation type implicit in them is recognizable by the users.},
  archive      = {J_IJCIS},
  author       = {Rodríguez-Rodríguez, Carlos Rafael and Zulueta-Veliz, Yeleny and Gainza-Reyes, Dainys},
  doi          = {10.1007/s44196-025-00908-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-39},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {SUMMARIA — A XAI support methodology by generating composite linguistic summaries of qualitative data},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Audio–Visual synchronization and lip movement analysis for real-time deepfake detection. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00911-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancements in Artificial Intelligence (AI) and deep learning techniques have led to the creation of highly realistic synthetic media known as deepfakes. These manipulated images, videos, and audio pose significant ethical, security, and privacy concerns. To address this issue, we propose a novel Audio–Visual Synchronisation and Fusion Framework (AVSFF) for real-time detection of deepfakes. This approach focuses on fine-grained lip movement analysis by detecting subtle inconsistencies between lip movements and corresponding audio. By integrating visual and audio features using multimodal fusion techniques, AVSFF aims to distinguish between authentic and manipulated media. The proposed framework is evaluated on diverse datasets, including FakeAVCeleb, AV-Deepfake1M, TVIL, and LAV-DF, demonstrating promising results with accuracies of 0.9973, 0.9760, 0.9890, and 0.9786, respectively. This study contributes to the field by providing a robust real-time solution for detecting deepfakes in audio–visual synthetic data, ensuring enhanced detection accuracy and effective generalization across various deepfake manipulations and demographic data.},
  archive      = {J_IJCIS},
  author       = {Javed, Muhammad and Zhang, Zhaohui and Dahri, Fida Hussain and Laghari, Asif Ali and Krajčík, Martin and Almadhor, Ahmad},
  doi          = {10.1007/s44196-025-00911-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Audio–Visual synchronization and lip movement analysis for real-time deepfake detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilience analysis of airport systems based on improved bayesian networks. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00914-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern airports, as pivotal nodes in global transportation networks, face increasing resilience challenges from compound threats such as extreme weather events and cyberattacks. However, current assessment methods primarily rely on subjective evaluations and lack probabilistic reasoning to account for the dynamic interdependencies among resilience factors. To address this gap, this study presents a hybrid Bayesian network–best worst method (BN–BWM) framework aimed at improving the accuracy and practicality of airport system resilience assessments. While Bayesian networks are effective for modeling complex probabilistic dependencies, expert-based probability assignments often introduce subjectivity. To mitigate this, we apply the best worst method (BWM) to conduct systematic pairwise comparison. Building on this, we leverage the BWM’s systematic pairwise comparisons, conducted with 10 aviation experts, to generate conditional probability tables for the Bayesian network. The results indicate that large airports demonstrate higher resilience levels (84–85%), whereas medium-sized airports exhibit moderate resilience (79%). Sensitivity analysis identifies key factors influencing resilience, including emergency repair systems and personnel capabilities, thereby offering actionable insights into improving airport operations. This study presents a robust, data-driven framework that enhances the objectivity and accuracy of resilience evaluations, providing theoretical support for sustainable airport management and operational safety.},
  archive      = {J_IJCIS},
  author       = {Guo, Jiuxia and Tong, Xin and Yang, Yungui and Yuan, Jiang and Xu, Siying},
  doi          = {10.1007/s44196-025-00914-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Resilience analysis of airport systems based on improved bayesian networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Attention pyramid convolutional neural network optimized with big data for teaching aerobics. <em>IJCIS</em>, <em>18</em>(1), 1. (<a href='https://doi.org/10.1007/s44196-025-00917-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Chen, Chunmei},
  doi          = {10.1007/s44196-025-00917-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Retraction note: Attention pyramid convolutional neural network optimized with big data for teaching aerobics},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyberbullying-related automated hate speech detection on social media platforms using stack ensemble classification method. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00919-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate speech (HS) has grown because of increasing social media platform usage, which includes Twitter, YouTube, and Facebook. The frequent attempts to implement automated detection systems remain unsuccessful at separating hate speech from objectionable language, because user-generated content tends toward informal, brief, and diverse expressions. The determination of hate speech within texts proves exceptionally hard, since precise context detection is needed to distinguish abusive language from neutral statements. Precision in hate speech identification and filtering stands essential, because these online content forms have negative impacts on both minority and majority groups while heightening their conflicts. The research presents a stacked ensemble classification system that classifies tweets into three groups: hate speech, abusive language, or neutral. The framework uses term frequency–inverse document frequency (TF–IDF) extracted from tweet texts for which support vector machine (SVM), together with Random Forest, XGBoost, and Logistic Regression, base machine learning models function as classifiers. The final model outcome results from linking several base learning models into an ensemble configuration. The Kaggle Hate Speech data set served as training material for the system, because it contained 24,784 tweets along with eight attributes. The model performance received improvement through exclusion of manually derived features. The proposed ensemble model demonstrated superior performance with 96% accuracy, while each single classifier had lower accuracy rates (SVM: 93%, Random Forest: 94%, and XGBoost: 88%). The research outcomes show stacking represents an effective method to enhance systems for detecting hate speech operating on social media platforms.},
  archive      = {J_IJCIS},
  author       = {Mubeen, Muhammad and Muskan, Aliza and Akram, Arslan and Rashid, Javed and Alshalali, Tagrid Abdullah N. and Sarwar, Nadeem},
  doi          = {10.1007/s44196-025-00919-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Cyberbullying-related automated hate speech detection on social media platforms using stack ensemble classification method},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced multistep prediction of multivariate market indices using weighted optical reservoir computing. <em>IJCIS</em>, <em>18</em>(1), 1-17. (<a href='https://doi.org/10.1007/s44196-025-00906-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and experimentally demonstrate an innovative weighted optical reservoir computing system for market index prediction. By integrating fundamental market data with macroeconomic indicators and technical metrics, we capture the broader dynamics of the stock market. Our system shows significantly higher performance than the state-of-the-art methods such as linear regression, decision trees, and neural network architectures including long short-term memory. It effectively captures the market’s high volatility and nonlinear behaviors under limited data conditions, demonstrating strong potential for real-time, parallel, multi-dimensional data processing, and prediction.},
  archive      = {J_IJCIS},
  author       = {Wang, Fang and Bu, Ting and Huang, Yuping},
  doi          = {10.1007/s44196-025-00906-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced multistep prediction of multivariate market indices using weighted optical reservoir computing},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The application of deep learning in dance movement design. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00907-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed deep learning for designing dance movements by estimating dance poses. In this study, we proposed Fusion-based Global Dance Pose Patterns with ResNet-152 an approach that resolves class imbalance existing in dance pose datasets with the help of high-resolution global feature fusion during pose estimation. A fusion layer has been added for discerning patterns on both the local and global levels, resulting in a considerable improvement in classifier performance thereby yielding a referred reliability for discriminative power to dance pose classification applications. Refinement in feature extraction and using deep new models such as ResNet-152 for pose recognition have helped to capitalize on model overfitting and worse generalization problems. This approach indeed goes a long way in making dance pose classification more accurate and efficient with possible real-time applications, in addition to a better understanding of the dance movements themselves. Experimental results indicate promising performances, with high accuracies (0.9870), precisions (0.9851), sensitivities (0.9873), F-measures (0.9861), and Kappa (0.9841) constituting proof of the model competency. The workflow comprises a stage for data collection, pre-processing is then applied using Gaussian filtering and histogram equalization to improve image features, the class imbalance is countered using SMOTE, feature extraction on HR-Net, and global and local feature fusion leads to robust pose estimations. ResNet-152 acts as a classifier with an SGD optimizer for better model parameter optimization. This system highly accurately predicts dance poses and efficiently approaches pose estimation in various dance application fields.},
  archive      = {J_IJCIS},
  author       = {Ju, Xiang},
  doi          = {10.1007/s44196-025-00907-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {The application of deep learning in dance movement design},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image classification of imbalanced wood microscope by integrating multi-source features. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-025-00912-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to factors such as human activities and environmental pollution, the global forest area is continuously diminishing. Consequently, rapid and accurate identification of wood species becomes extremely crucial. With the recent advancements in deep learning, wood classification based on digital images is currently relatively popular method. Nevertheless, there still exist some challenges, such as the difficulty in integrating plant phenological and texture features and the inability to automatically select features of inter-class images. This paper presents a multi-source feature fusion classification, which combines traditional local feature description with automatic feature extraction by deep learning. The proposed method reduces misclassification and addresses the imbalance problem in wood data. Besides, the method is validated on the microscopic cross-sectional images of 75 broad-leaved wood species, with an accuracy of 94.0%, indicating its potential for application in the classification of imbalanced wood data. The comparison experiments with other existing models on the wood dataset demonstrate the effectiveness of the proposed method.},
  archive      = {J_IJCIS},
  author       = {Tian, Zhikang and Zhang, Na and Wang, Jiwei and Sha, Liwei and Liu, Hongping and Zou, Li},
  doi          = {10.1007/s44196-025-00912-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Image classification of imbalanced wood microscope by integrating multi-source features},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning framework for oil shale pyrolysis state recognition using bionic electronic nose. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00913-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time monitoring of the pyrolysis state of oil shale is crucial for precisely controlling heating temperature and duration, which can significantly reduce extraction costs. However, due to the complexity of in-situ environments, this task is highly challenging and remains one of the key technological barriers in in-situ mining. To address this issue, this paper proposes an end-to-end recognition technology solution for in-situ pyrolysis state of oil shale using electronic nose. The proposed solution integrates Graph Convolutional Network (GCN) and Long Short-Term Memory (LSTM) to capture the spatial correlations among different sensors in the electronic nose and the temporal characteristics of the data, respectively. It is designed to identify both the pyrolysis state classification and the oil shale maturity regression tasks. Our model achieves 93.87% accuracy on the task of classifying the pyrolysis stage of oil shale; the $$R^2$$ on the regression task reaches 0.93. To evaluate its effectiveness, we compare its performance with state-of-the-art (SOTA) methods in this field. Experimental results demonstrate the superiority of our proposed framework, highlighting its effectiveness and advantages over existing methods.},
  archive      = {J_IJCIS},
  author       = {Yuan, Yuping and Weng, Xiaohui and Qiao, Yuheng and Shi, Xiaohu and Chang, Zhiyong},
  doi          = {10.1007/s44196-025-00913-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Deep learning framework for oil shale pyrolysis state recognition using bionic electronic nose},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy-based novel cross-layer RPL objective function for energy-aware routing in IoT. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00916-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption remains a critical challenge for low-power, resource-constrained Internet of Things (IoT) devices operating over Low-Power and Lossy Networks (LLNs). Addressing this issue requires the development of energy-efficient Objective Functions (OFs) within the RPL (Routing Protocol for Low-Power and Lossy Networks) routing protocol. Traditional OFs primarily used routing layer metrics for parent selection. Therefore, our analysis demonstrates that transmission dynamics at the MAC layer significantly impact overall energy consumption. To tackle this, we introduce a cross-layer energy-efficient objective function (CL-RPL-OF) that incorporates a novel metric, energy per packet (EPP), which quantifies the energy consumed during the transmission and reception of a single data packet. This metric integrates strobe per packet rate (SPPR) and strobe packet success rate, both of which are influenced by radio duty cycling (RDC) mechanisms at the media access control (MAC) layer. The proposed CL-RPL-OF considers node-to-node communication variations arising from relative phase shifts by combining EEP with expected transmission count (ETX) and SPPR using fuzzy logic to select the best path to optimize energy consumption across both routing and MAC layers. Simulation using Cooja and real-world experimentation using the FIT IoT-LAB testbed demonstrate that CL-RPL-OF significantly improves energy efficiency, increases packet delivery ratio, and reduces strobe overhead compared to existing objective functions.},
  archive      = {J_IJCIS},
  author       = {Poornima, M. R. and Vimala, H. S. and Shreyas, J.},
  doi          = {10.1007/s44196-025-00916-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fuzzy-based novel cross-layer RPL objective function for energy-aware routing in IoT},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating the impact of labeling inaccuracies on 3D human body reconstruction from monocular videos. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00921-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of labeling inaccuracies in 3D human pose and shape reconstruction from monocular videos. Existing methods often rely on noisy pseudo ground truth, which introduces performance degradation such as jittering and drifting. To overcome these limitations, we propose a confidence-aware framework grounded in biomechanics. Our method adopts the SKEL model to provide anatomically constrained pose representations, reducing dependency on imprecise annotations. We further introduce a conditional normalizing flow to model per-parameter uncertainty conditioned on visual and motion features. Additionally, a novel evaluation metric, confidence-weighted procrustes aligned MPJPE, is proposed to incorporate confidence scores into performance assessment. Extensive experiments show that our approach outperforms existing methods on multiple datasets in both accuracy and motion smoothness. It demonstrates strong robustness against noisy annotations, and confidence estimates align closely with actual prediction errors. Ablation studies validate the contributions of both biomechanical modeling and confidence learning. Overall, our framework provides a unified and robust solution for 3D human reconstruction in real-world settings.},
  archive      = {J_IJCIS},
  author       = {Hou, Yupeng and Zeng, Guangping},
  doi          = {10.1007/s44196-025-00921-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Mitigating the impact of labeling inaccuracies on 3D human body reconstruction from monocular videos},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision-making framework for multi-objective transportation problem using fully triangular intuitionistic fuzzy sets. <em>IJCIS</em>, <em>18</em>(1), 1-29. (<a href='https://doi.org/10.1007/s44196-025-00915-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a fully triangular intuitionistic fuzzy number model for the multi-objective transportation problem that successfully manages ambiguity and hesitation in decision making. To provide a reliable transportation plan in the case of unpredictability, the suggested methodology uses a multi-objective optimization framework that strikes a balance between cost, time and reliability. A significant component of this study is the weight assignment and multiple decision levels, which enables decision makers to rank goals and customize solutions according to specific transportation needs. This technique makes decision making easier while also provides flexibility in dealing with difficult real-world situations. Furthermore, we compare our proposed model with other approaches that are currently in use, such as the intuitionistic fuzzy approach and the goal programming approach. According to the outcomes, our model provides a more effective and realistic transportation strategy by offering a more balanced trade-off between cost, time and reliability. A numerical example is provided to illustrate the efficacy of the method, showing how combining centre, expected, and ranking values ​​increases solution accuracy and decision reliability while providing a systematic way of comparing and defuzzifying fuzzy numbers.},
  archive      = {J_IJCIS},
  author       = {Joshi, Vishwas Deep and Agarwal, Priya and Alsaud, Huda and Čepová, Lenka and Swarna, B.},
  doi          = {10.1007/s44196-025-00915-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A decision-making framework for multi-objective transportation problem using fully triangular intuitionistic fuzzy sets},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image denoising using quantum deep convolutional generative adversarial network for medical images. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00920-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant role is played by medical images in diagnosing diseases and planning the course of treatment. Noise can potentially degrade the quality of images which can lead to misdiagnosis. One of the oldest challenges in computer vision for restoring images that have been corrupted is image denoising. Generative adversarial networks (GANs) are among the most extensively used deep learning methods for various computer vision tasks. Utilizing an innovative quantum adversarial denoising architecture, denoised image samples are produced from a noisy distribution. In this paper, the authors employ an architecture of quantum deep convolutional generative adversarial networks (QDCGAN) for denoising medical images. The architecture of the DCGAN (deep convolutional generative adversarial networks) is augmented with a quantum computing layer to enhance the performance through quantum-generated inputs. The research is performed on the BraTS dataset via the TensorFlow Quantum platform. The study demonstrates that QDCGAN outperforms traditional methods. The proposed method achieves a better PSNR (peak signal-to-noise ratio) and SSIM (structural similarity index measure) value. The study underscores its effectiveness in improving the diagnostic quality of medical images with an 3.4% enhancement in SSIM and 7.35% in PSNR over existing methods, thereby offering tangible benefits for healthcare practitioners and patients alike.},
  archive      = {J_IJCIS},
  author       = {Nandal, Priyanka and Pahal, Sudesh and Upadhyay, Govind Murari},
  doi          = {10.1007/s44196-025-00920-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Image denoising using quantum deep convolutional generative adversarial network for medical images},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative study of hybrid deep learning models for kannada sign language recognition. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00922-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language recognition (SLR) systems continue to face significant challenges in accurately interpreting dynamic gestures, particularly for underrepresented languages like Kannada sign language (KSL). This study presents a novel hybrid deep learning architecture that synergistically combines convolutional neural networks (CNNs), hand keypoints (HKPs), long short-term memory (LSTM) networks, and transformers to achieve robust spatial-temporal-contextual learning for KSL recognition. Developed on a newly curated dataset of 1080 medical-domain KSL gestures, our model addresses critical gaps in dataset diversity and model generalizability. The proposed framework demonstrates superior performance with 97.6% training accuracy, 96.75% validation accuracy, and 81% testing accuracy on unseen data—outperforming conventional CNN-LSTM (46%) and HKP-LSTM (71%) baselines. By hierarchically integrating CNN-extracted spatial features, HKP-derived structural priors, LSTM-processed temporal dynamics, and Transformer-modeled long-range dependencies, this work establishes a new benchmark for KSL recognition while providing a scalable solution for real-world healthcare and assistive technology applications.},
  archive      = {J_IJCIS},
  author       = {Hugar, Gurusiddappa and Kagalkar, Ramesh M. and Das, Abhijit},
  doi          = {10.1007/s44196-025-00922-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Comparative study of hybrid deep learning models for kannada sign language recognition},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Construction of industrial economic management decision model based on three parameter interval grey numbers. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00927-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As China’s industrial strength continues to develop, a growing number of challenges have emerged in the field of industrial management. This study proposes an industrial economic management decision model based on three parameter interval grey numbers to address the issues of high information uncertainty and complexity in industrial economic management decisions. This model characterizes the uncertainty of decision information by introducing three parameter interval grey numbers, and innovatively adopts grey relational clustering decision-making method, combined with genetic algorithm to dynamically optimize key parameters. The results demonstrated that the model exhibited excellent performance on multiple datasets, with an accuracy stable between 95 and 96%. In the application of industrial economic management datasets, the model increased the average profit margin of enterprises by 5.3% and reduced unit costs by an average of 13.3%, which was significantly better than other comparative models. In addition, through comparative experiments with other decision models, this model has shown superiority in improving profit margins, increasing sales, reducing unit costs, and reducing prediction errors. Therefore, the proposed industrial management decision model can effectively handle uncertainty factors, enhance the scientific and effective nature of industrial economic management decisions, and provide more accurate and reliable solutions for industrial enterprises.},
  archive      = {J_IJCIS},
  author       = {Lin, Pao-Ching and Wu, Tzu-Jung and Huang, Jui-Chan},
  doi          = {10.1007/s44196-025-00927-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Construction of industrial economic management decision model based on three parameter interval grey numbers},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial network structure characteristics of tourism supply in china: A social network analysis method. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00929-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the spatial network structure of tourism supply is a prerequisite for achieving high-quality development in the tourism industry. Research on the evolutionary characteristics of tourism supply spatial network structures remains unclear. In this study, integrated the modified gravity model and social network analysis (SNA) to investigate the spatial network structure characteristics of tourism supply in China at the provincial level from the years 2004–2019. The results indicate that while the provincial tourism supply spatial network maintained a relatively loose structure, its accessibility and balance showed progressive enhancement. Significant regional disparities emerged in the spatial network characteristics among eastern, central, and western regions. Furthermore, the tourism supply network exhibits a dual-polarized core-periphery structure. Different role subgroups were divided into four levels: core leader, important leader, general partner, and marginal partner. This research advances theoretical and methodological frameworks in tourism supply studies. The findings can inform policy formulation for enhancing regional tourism collaboration and optimizing network relationships.},
  archive      = {J_IJCIS},
  author       = {Yu, Hongyan and Zhou, Wenming},
  doi          = {10.1007/s44196-025-00929-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Spatial network structure characteristics of tourism supply in china: A social network analysis method},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive feature-driven PCOS predictor: A reinforcement learning-based binary equilibrium optimization approach. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00931-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Poly-cystic ovary syndrome (PCOS) is a prevalent condition that impinges women in their prime reproductive years. Its primary trait is the elevated levels of androgen, a male hormone in female body and leads to several symptoms, including ovarian cysts, irregular menstruation cycles, infertility, obesity, and excessive hair development. Since PCOS exact cause is unknown and its symptoms are uncertain, a timely and accurate diagnosis is essential. In these situations, a (ML) Machine Learning-based PCOS prediction model aids in the diagnostic procedure, addresses time constraints and potential inaccuracies. A plethora of feature selection techniques have been built to discover the best optimal features for the classification of medical dataset. However, finding an efficient solution is still difficult due to noise and redundant information which may degrade the model performance. In this article, a hybrid filter-wrapper approach is proposed to identify the optimal attributes. An ensemble filter method is built, the union of top k attributes from individual filters is considered for further process. Then, Reinforcement Learning-based Binary Equilibrium Optimizer is used to find the reduced optimal features. Here, RL uses SARSA (State–Action–Reward–State–Action) to increase the population diversity in the search space, to avoid the problem of local optima, finally balances the exploration capability during the search. Then, identified optimal features are given as input to BMFK (Bonferroni Mean Fuzzy KNN) classifier and achieved 96.32% of accuracy. Further, several machine learning classifiers have been employed for the prompt diagnosis of PCOS. Finally, Random Forest has produced the highest accuracy of 95.62% than other models.},
  archive      = {J_IJCIS},
  author       = {Reka, S. and Praba, T. Suriya and Manchala, Krishna Kumar and Venkateswarlu, Anna},
  doi          = {10.1007/s44196-025-00931-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Comprehensive feature-driven PCOS predictor: A reinforcement learning-based binary equilibrium optimization approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction and optimization of civil aviation flight delays based on machine learning algorithms. <em>IJCIS</em>, <em>18</em>(1), 1-26. (<a href='https://doi.org/10.1007/s44196-025-00932-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The civil aviation industry continues to face the significant problem of flight delays, which impacts operational efficiency and passenger satisfaction. This research aims to develop an innovative model that accurately predicts civil aviation flight delays and provides insights related to performance enhancement. The proposed Flight Delay Prediction Network with Spatio-Temporal Learning (FlightNet-ST) is a hybrid deep learning architecture that combines Long Short-Term Memory (LSTM) networks, Graph Convolutional Networks (GCNs), and 3D Convolutional Neural Networks (3D-CNNs) to achieve this goal. The model is trained using datasets of domestic flights that include geographical, operational, and temporal data, such as geographical separation, origin–destination pairs, airline rules, scheduled departure times, and dates. The approach involves running time series data through LSTM to capture temporal dependencies, applying 3D Convolutional Neural Networks (3D-CNNs) to analyze aircraft route grids dynamically, and utilizing Graph Convolutional Networks (GCNs) to discover topological patterns from spatial airport connectivity. Delay prediction is powered by a unified representation that fuses these disparate elements. Based on the experimental data, FlightNet-ST achieves a 14.47% reduction in Mean Absolute Error (MAE). Additionally, an attention mechanism enhances interpretability by highlighting key aspects that influence delays, such as departure time blocks and airport-specific trends. Finally, FlightNet-ST helps with civil aviation flight delay prediction and management with its data-driven, interpretable, and robust solution. This methodology facilitates real-time operational decision-making and provides tactics to mitigate delays.},
  archive      = {J_IJCIS},
  author       = {Zhong, Qingwei and Yu, Yingxue and Huang, Yiru and Zhang, Tianhang},
  doi          = {10.1007/s44196-025-00932-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Prediction and optimization of civil aviation flight delays based on machine learning algorithms},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coal price forecasting using CEEMDAN decomposition and IFOA-optimized LSTM model. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00923-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel hybrid forecasting model for coking coal prices, integrating complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) and long short-term memory (LSTM) neural networks, enhanced by an improved fruit fly optimization algorithm (IFOA). The approach begins with CEEMDAN decomposing the coking coal price sequence into intrinsic mode functions (IMFs) and a residual component, effectively mitigating non-stationarity and nonlinearity. High- and low-frequency IMFs are differentiated using a single-sample T-test, with high-frequency components consolidated to minimize noise interference. Subsequently, the IFOA algorithm optimizes LSTM hyperparameters, boosting both generalization and prediction precision. Empirical validation, leveraging the Platts price index for four major imported coking coal varieties, demonstrates that the CEEMDAN-IFOA-LSTM model significantly outperforms a broad range of benchmarks, including ANN, IFOA-LSSVR, CEEMDAN-LSTM, LSTM, BiLSTM, TCN, IFOA-LSTM, CEEMDAN-FOA-LSTM, CEEMDAN-PSO-LSTM, and CEEMDAN-GA-LSTM, achieving reduced root mean square error (RMSE) and mean absolute percentage error (MAPE). The study concludes that this model adeptly addresses the challenges of nonlinear coupling and hyperparameter optimization, offering a reliable tool for coking coal price forecasting. Future research will aim to refine the model further to adapt to diverse market conditions and enhance forecasting accuracy.},
  archive      = {J_IJCIS},
  author       = {Liu, Zhuang and Li, Xiaotuan},
  doi          = {10.1007/s44196-025-00923-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Coal price forecasting using CEEMDAN decomposition and IFOA-optimized LSTM model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling flight operation hazards’ interrelation via TEM model and network analysis. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00935-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent severe aviation accidents have underscored the intricate challenges within the aviation system, necessitating a more comprehensive understanding of hazards’ interrelation in flight operation. This study integrates the Threat and Error Management (TEM) framework with complex network theory to construct a Flight Operation Hazard Network (FOHN) based on 260 aviation occurrence reports. The FOHN, comprising 120 nodes (hazards) and 208 edges (causal links), exhibits unique structural characteristics: a low clustering coefficient (0.03), long average path length (4.20), and an exponential degree distribution (R2 = 0.994), confirming the absence of small-world and scale-free properties. These features reflect aviation’s defense-in-depth strategy, where sparse connectivity aims to isolate hazards. Analysis of the FOHN’s response to simulated hazard mitigation reveals its relative stability against non-targeted hazard removal but significant disruption when critical high-betweenness hazards are targeted for mitigation. The study identifies crew navigation errors as key risk mediators, bridging technical failures and organizational deficiencies. By proposing actionable enhancements grounded in these network findings—including resilience-augmented training, flight data-driven risk prioritization, and regulatory updates—this work provides a network-centric framework to address “black swan” risks in modern aviation systems.},
  archive      = {J_IJCIS},
  author       = {He, Peng and Zhang, Zhaoning and Sun, Ruishan},
  doi          = {10.1007/s44196-025-00935-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Unveiling flight operation hazards’ interrelation via TEM model and network analysis},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved crime prediction using hybrid neural architecture search together with hyperparameter tuning. <em>IJCIS</em>, <em>18</em>(1), 1-38. (<a href='https://doi.org/10.1007/s44196-025-00888-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different parts of the world have recorded an escalating number of criminal incidents, burdened the judicial system, and adversely impacted national security and economic development. Accurate prediction of crimes is crucial for law enforcement agencies to prevent proactively criminal activity and allocate resources effectively. Existing methods often address architecture design and hyperparameter tuning as separate processes. We present a combination of neural architecture search and hyperparameter tuning for improved crime prediction. The study method achieved automation of architecture discovery and fine-tuning of hyperparameters by utilizing Neural Architecture Search (NAS) to explore a wide range of neural network architectures for crime prediction and optimizing the hyperparameters of the discovered architecture for peak performance in binary crime prediction, respectively. The study used three datasets: criminal cases dataset (self-collected dataset), Vancouver crime data, and Austin crime data. The criminal cases dataset is extracted from a confidential database from certain countries, focusing on sensitive parts of those countries. The Vancouver crime and Austin crime datasets were sourced from the Kaggle website. The study considered the robust rank aggregation (RRA) feature selection method to rank and select the best features to predict crime behavior in some countries. The chosen features using robust rank aggregation included current position, age range, month, prisoner condition, and identified/unidentified (ide/unide). The hyperparameter tuning model of Architecture Search (NAS +) produced superior results across all datasets with an accuracy of 89.29% (AUC-ROC = 94.82% and recall = 64.54%) in the criminal cases dataset, 60.37% (AUC-ROC = 50.00% and recall = 100.00%) in the Vancouver dataset, and 86.68% (AUC_ROC = 65.40% and recall = 100.00%) in the findings which demonstrated that the proposed approach consistently outperforms conventional methods, making it an effective solution for the prediction of real-world crimes.},
  archive      = {J_IJCIS},
  author       = {Alshahrani, Rami Ayied and Khanzada, Tariq Jamil Saifullah},
  doi          = {10.1007/s44196-025-00888-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improved crime prediction using hybrid neural architecture search together with hyperparameter tuning},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved gaining sharing knowledge-based algorithm for solving resource allocation problems. <em>IJCIS</em>, <em>18</em>(1), 1-63. (<a href='https://doi.org/10.1007/s44196-025-00909-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript presents a procedure to deal with the complicated unbounded knapsack optimization problem with a combination of Total Value greedy heuristic (TV) and Integer Gaining Sharing metaheuristic (IGSK) algorithms in the framework of a divide-and-conquer strategy to lessen the search space and point the searching endeavor to an intensive, further hopeful area. IGSK is an integer version of lately evolved Gaining Sharing knowledge-based optimization algorithm (GSK), dependent upon the properties of GSK, IGSK is used to deal with the problem having integer decision variables. The GSK algorithm imitates the operation of gaining and sharing knowledge throughout the individual living cycle. It is established upon twain pivotal phases, apprentice gaining and sharing step and elder gaining and sharing step. Moreover, to enhance the execution of IGSK and prohibit the solutions from entrapping toward the inside of local optima, IGSK with dynamic elitism scheme is presented. It reduces the elite population size progressively with a linear decreasing, non-linear slow decreasing, non-linear rapid decreasing and non-linear exponential decreasing functions, (LDE, NLDSE, NLDRE, NLDEE), respectively. The proposed hybridizing of an Integer Gaining-Sharing Knowledge-based with Population Size Reduction metaheuristic and Total Value greedy heuristic (PR-IGSK - TV) algorithm with fixed and dynamic elitism schemes implemented in collection of unbounded knapsack problems with different dimensions and correlation categories, which demonstrate that PR-IGSK - TV hybrid algorithm with fixed and dynamic elitism scheme proved a capability to deal with unbounded knapsack problem concerning convergence, goodness and robustness.},
  archive      = {J_IJCIS},
  author       = {Kamal, Ayman and Roshdy, Heba Said and Hassan, Naglaa Ragaa Said and Mohamed, Ali Wagdy},
  doi          = {10.1007/s44196-025-00909-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-63},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An improved gaining sharing knowledge-based algorithm for solving resource allocation problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A residual-corrected hybrid ARIMA–CNN–LSTM framework for high-accuracy tobacco sales forecasting in regulated markets. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00930-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a common consumer product threatening public health, tobacco not only hinders the development of national public health, but also plays a significant impact on the national economy. The ARIMA model is reliable in learning linear or regular relationships, while the deep learn, such as convolutional neural network (CNN) and long short-term memory network (LSTM), is superior when capturing and learning nonlinear relationships. Combining time-series forecasting models with deep learning technologies, the hybrid architecture could integrate advantages and optimize forecasting effect. In this paper, leveraging 2023 daily sales data from a Southern Chinese tobacco company, this study proposes a new hybrid deep learning framework that integrates ARIMA, CNN, and LSTM models to address these inherent limitations and enhance prediction accuracy. This architecture decomposes forecasting tasks into linear trend analysis and nonlinear residual learning. The ARIMA component learns the linear relationship, and the CNN–LSTM component plays the role in the residual-driven correction. They enable synergistic capture of temporal dependencies and localized anomalies and enhancing the fitting effect. This hybrid model's optimization primarily relies on the residual-driven correction mechanism in the CNN–LSTM component, which significantly enhanced the model interpretability ( $${R}^{2}$$ : 0.95, enhance 10.5% compare with ARIMA model, enhance 13.1% compare with CNN-LSTM model). This research not only advances hybrid deep learning methods, but also provides a scalable solution for precise predictions in dynamic markets. This excellent forecasting results could also be practiced in inventory optimization and policy impact studies.},
  archive      = {J_IJCIS},
  author       = {Huang, Shiyu and Zhou, Lili},
  doi          = {10.1007/s44196-025-00930-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A residual-corrected hybrid ARIMA–CNN–LSTM framework for high-accuracy tobacco sales forecasting in regulated markets},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DEDSWIN-net: Dual encoder dilated convolution and swin transformer network for the classification of liver CT images. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00937-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic liver disease (CLD) segmentation and classification present significant challenges due to inaccurate diagnosis and misleading clinical treatment processes. In contemporary times, artificial intelligence (AI) and deep learning (DL) models are considered important tools for driving quantitative biomarkers for efficient stratification and computer-aided diagnosis support. However, prevailing DL models necessitate further enhancements as they rely on flawed assumptions that tumors exhibit non-complex physical structures and uniform image boundaries. To resolve this concern, this paper suggests a novel dual encoder deep learning structure named DEDSWIN-Net to mitigate this problem. The proposed framework consists of four components: a dilated convolution-based encoder, a transformer-based encoder, a multi-scale multiple feature fusion decoder (MSMFD), and a DL training model. The dilated convolution layers can retrieve fine spatial features, whereas Swin models are designed to obtain global information. Both these features are integrated by the MSMFD component that enhances segmentation. Finally, the deep learning training model is constructed using feed-forward principles for better classification of CLD. Comprehensive evaluation is conducted utilizing the LiTS2017-CT Image dataset comprising 100 hepatic disorders, and its performance is evaluated using ten powerful metrics: Jaccard Index (Jcc), dice similarity coefficient (DICE), precision (P), accuracy (Acc), specificity (Spec), recall (R), F1 score (FS), average symmetric surface distance (ASSD), Hausdorff distance (HD), and Intersection over Union (IoU). Furthermore, existing state-of-the-art DL frameworks are considered for comprehensive examination. Results demonstrate that the suggested methodology reveals supreme performance in terms of segmentation and classification with DICE: 0.984, JC: 0.92, IoU: 0.02, precision: 0.95, recall: 0.940, ASSD: 0.64, and HD: 0.32. Moreover, the exploratory outcomes prove the effectiveness of the suggested methodology in obtaining relevant characteristics, fuelling a better computer-aided diagnosis system for CLD.},
  archive      = {J_IJCIS},
  author       = {Allenki, Jyoshna and Soni, Hemant Kumar},
  doi          = {10.1007/s44196-025-00937-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {DEDSWIN-net: Dual encoder dilated convolution and swin transformer network for the classification of liver CT images},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Systematic approach for malware detection in IoT devices: Enhancing security and performance. <em>IJCIS</em>, <em>18</em>(1), 1-17. (<a href='https://doi.org/10.1007/s44196-025-00939-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of Internet of Things (IoT) devices has introduced significant security challenges, particularly concerning the detection and mitigation of malware threats. This study presents a systematic approach to malware detection that aims to improve both the security and performance of IoT systems. Using the IoT23 dataset, which contains a wide range of network traffic patterns from various IoT devices and malware families, the research explores and evaluates multiple machine learning techniques. These include ensemble methods such as Bagging, Stacking, Voting, AdaBoost, and H2O AutoML, as well as advanced models such as sparse neural networks with pruning and feature selection and regularized classifiers L1. The primary objective is to develop lightweight yet highly accurate models suitable for deployment on resource-constrained IoT devices. A comprehensive comparison of these techniques demonstrates the importance of achieving a balance between detection accuracy and computational efficiency. Among the models evaluated, the SNIPE approach shows the best performance, achieving an accuracy of 91.9% while maintaining minimal computational overhead. This makes it particularly well suited for real-world IoT environments, where performance and energy efficiency are critical. The findings of this study provide valuable insights for the development of robust, scalable, and resource-aware malware detection systems, laying a strong foundation for future research and practical cybersecurity solutions in the rapidly evolving IoT landscape.},
  archive      = {J_IJCIS},
  author       = {Pai, Vasudeva and Karthik Pai, B. H. and Sudhiksha, G. S. and Kamath, Vandya and Varsha, K. and Manjunatha, S.},
  doi          = {10.1007/s44196-025-00939-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Systematic approach for malware detection in IoT devices: Enhancing security and performance},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis of hot rolling equipment under uncertain conditions based on cloud rough model, game theory, and improved GRA-TOPSIS. <em>IJCIS</em>, <em>18</em>(1), 1-32. (<a href='https://doi.org/10.1007/s44196-025-00945-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hot-rolled strip steel is a critical process in steel production, where equipment stability directly impacts product quality. Traditional evaluation methods struggle to balance uncertainties between influencing factors and expert judgments. This study proposes a novel fault evaluation framework: first, a cloud rough model is adopted to handle multi-source uncertainties in expert evaluations; second, game theory is used to optimize the combined weights of subjective and objective criteria; finally, an improved Grey Relational Analysis-Technique for Order Preference by Similarity to Ideal Solution (GRA-TOPSIS) method constructs a dual-scale measurement model by fusing grey relational degree and Euclidean distance, effectively reducing the influence of geometric sequence similarity and distance on fault prioritization and enhancing the robustness of ranking results under complex working conditions. A case study on hot rolling loopers demonstrates a diagnostic accuracy of 90%. Comparative analyses with seven typical multicriteria decision-making methods indicate the proposed method's feasibility and effectiveness in practical applications, offering a novel reference for equipment status evaluation.},
  archive      = {J_IJCIS},
  author       = {Hu, Bo and Zhang, Yongjun and Jing, Fengwei},
  doi          = {10.1007/s44196-025-00945-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fault diagnosis of hot rolling equipment under uncertain conditions based on cloud rough model, game theory, and improved GRA-TOPSIS},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPOT-CRIME: Suspicious person and object tracking system for real-time crime monitoring. <em>IJCIS</em>, <em>18</em>(1), 1-21. (<a href='https://doi.org/10.1007/s44196-025-00893-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research work proposes a novel SPOT-CRIME model for detecting and tracking suspicious objects and people from video footage to assist the crime scene analysis. The SPOT-CRIME model has three different monitoring phases for detecting and tracking suspicious object and person. The deep learning-based YOLO network is used in the Primary Monitoring Phase to identify potentially suspicious activities based on individual pose and motion estimates. A suspicious activity database is used for further analysis to detect the activities accurately. Secondary Monitoring Phase uses stochastic gradient Grad-CAM to identify objects related to individuals in the scene using suspicious object detection. Correlations between suspicious objects and activities detected in the first phase enable the detection of these objects. The Tertiary Monitoring Phase combines the outputs of the previous phases for tracking people and objects. In Track RCNN, individuals and suspicious objects are tracked robustly and associated with multiple frames. Detection accuracy of 98.54% was achieved by the proposed SPOT-CRIME model on benchmark datasets. Moreover, the performance of the SPOT-CRIME model progresses the overall accuracy range by 6.63, 1.05, 8.66 and 3.15% better than Seven-layered CNN, Enhanced CNN, Lightweight multiclass-CNN and CNN-BiLSTM respectively.},
  archive      = {J_IJCIS},
  author       = {Jaffrin, Lijetha C. and Rani, D. Esther and Sobia, M. Carmel and Radhakrishnan, P. and Ahilan, A. and Senthil, D Siva},
  doi          = {10.1007/s44196-025-00893-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {SPOT-CRIME: Suspicious person and object tracking system for real-time crime monitoring},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic state cluster-based particle swarm optimization algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-37. (<a href='https://doi.org/10.1007/s44196-025-00902-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fitness landscape (FL) is an effective tool for describing and analyzing the real-time dynamics of the search process, offering valuable insights into the population’s varying states. In particle swarm optimization for complex optimization challenges, parameter selection significantly influences performance across various population states. However, current methods for constructing fitness landscapes demonstrate insufficient theoretical analysis of state parameters and involve high construction time costs. To address these limitations, this paper introduces a dynamic state cluster-based particle swarm optimization (DSCPSO) algorithm, which employs population phenotypic entropy based on clustering technique. (1) The algorithm provides theoretical splitting points by mathematically analyzing the population into four states: convergence, exploitation, escape, and exploration, enabling more effective parameter adaptive mechanisms. (2) DSCPSO incorporates sinusoidal chaos mapping to dynamically adjust inertia weights, allowing particles to better align with the population’s evolutionary state. (3) During the convergence state, an intelligent particle migration strategy (IPMS) enhances search efficiency within the solution space, preventing unnecessary computational resource consumption. Eventually, comparative analysis with 10 advanced existing algorithms on the CEC2017 and CEC2022 benchmark suites demonstrates that DSCPSO achieves competitive performance across over 70% of the functions, validating the algorithm’s effectiveness and superiority. In addition, the Wilcoxon-test of the algorithm verifies the validity of the algorithm, and also applies the algorithm to a high-dimensional feature selection problem, which demonstrates the ability of the proposed algorithm to solve real-world problems.},
  archive      = {J_IJCIS},
  author       = {Diao, Zhenya and Yu, Fei and Wu, Hongrun and Xia, Xuewen},
  doi          = {10.1007/s44196-025-00902-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A dynamic state cluster-based particle swarm optimization algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study of multi-distributed resource equalization allocation for virtual power plants based on genetic-heuristic algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00941-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-resource balanced allocation method using a genetic-heuristic fusion algorithm is proposed to address the imbalance in distributed power generation resource allocation and the over-generation problem in virtual power plants. By establishing models of wind, solar, storage, and controllable load characteristics, an optimization model is constructed with objectives of resource allocation balance and minimization of call costs, subject to constraints such as power balance. Combining the global search capability of a genetic algorithm and the local optimization capability of an ant colony algorithm, the genetic algorithm stage adopts real-number encoding and a dynamic crossover-mutation strategy, while the ant colony algorithm stage optimizes the pheromone update mechanism to avoid premature convergence. The experimental results show that this method achieves 100% accurate allocation of resources without any over-generation occurrences and reduces the resource allocation deviation rate by 32–67% compared to alternative methods. The algorithm demonstrates fast convergence, yielding solutions in less than 0.6 s across 14 repeated experiments, with an average convergence time reduction of 42% compared to traditional algorithms. Under a comprehensive fluctuation scenario with 30% renewable energy fluctuation rate and 15% load forecasting error, the system stability index remains at 0.865, demonstrating the algorithm’s efficiency and robustness under complex conditions and providing an effective approach for optimizing virtual power plant resource allocation.},
  archive      = {J_IJCIS},
  author       = {Li, Haifeng and Jin, Tao and Xu, Xian and Shi, Lin},
  doi          = {10.1007/s44196-025-00941-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A study of multi-distributed resource equalization allocation for virtual power plants based on genetic-heuristic algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning based acceptance criteria for metaheuristic algorithms. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00924-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes novel reinforcement learning-based acceptance criteria for metaheuristic algorithms. We develop Q-learning and Deep Q-learning-based acceptance criteria and integrate them into simulated annealing (SA) and artificial bee colony (ABC) algorithms. Also, we design two versions of these novel acceptance criteria: the online version and the offline version of Q-learning and deep Q-learning based acceptance criteria. The online version starts to train itself and to make decisions to accept or reject the candidate solution with the start of the metaheuristic. The offline version uses a trained and well-tuned Q-learning and deep Q-learning based acceptance criteria to make accept/reject decisions. Our experimental study compares our proposed acceptance criteria with existing ones, such as fuzzy rule-based acceptance (FRBA) and simulated annealing-like acceptance (SALA) criteria. The experiment reveals that metaheuristics with deep Q-learning-based offline acceptance criteria outperform metaheuristics with existing acceptance criteria and other variants in this study.},
  archive      = {J_IJCIS},
  author       = {Arık, Oğuzhan Ahmet and Toğa, Gülhan and Atalay, Berrin},
  doi          = {10.1007/s44196-025-00924-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Reinforcement learning based acceptance criteria for metaheuristic algorithms},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAGDM for evaluating the role of computer science in education with PLq-ROF heronian mean operators and maximizing deviation-MOORA methodology. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-025-00925-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer science (CS) has changed educational processes in a wide range of academic fields and is now considered to be an essential part of modern education. This manuscript presents a novel methodology in which CS can be used to solve judgment concerns in education. The conventional education system frequently finds it difficult to deal with the ambiguities and linguistic expressions that are an integral component of human judgment and choice-making processes. By combining probabilistic uncertainty with linguistic concepts, a probabilistic linguistic q-rung orthopair fuzzy set (PLq-ROFS) presents an efficient mathematical methodology for describing inaccurate and unclear facts to handle these concerns. For aggregating the assessment data, we first propose the PLq-ROF Heronian mean operators. The maximizing deviation methodology is a helpful tool when dealing with situations where the knowledge about the attribute weights is either partially or fully unknown. To find attribute weights, this study presents the PLq-ROF-maximizing deviation methodology. We also propose the multi-objective optimization by ratio analysis (MOORA) methodology with PLq-ROFNs to evaluate the options and identify an optimal choice. Furthermore, a case study related to the judgment process on CS applications in education is provided from the PLq-ROFS perspective to illustrate the effectiveness and use of the developed technique. The numerical results show that $${\mathbb {A}}_{4}$$ (namely: skill development) is the best CS application in education.},
  archive      = {J_IJCIS},
  author       = {Shafiq, Aqsa and Rasheed, Muhammad Waheed and Habeeb, Marwah Shaker and Tasneem, Rabia and Shabbir, Nimra and Alameri, Abdu},
  doi          = {10.1007/s44196-025-00925-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MAGDM for evaluating the role of computer science in education with PLq-ROF heronian mean operators and maximizing deviation-MOORA methodology},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy neural network approach for nanomaterials analysis in nanoelectronics under fuzzy credibility information. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00938-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanomaterials are a key component of nanoelectronics and selecting the most suitable nanomaterial for nanoelectronics remains a significant challenge for companies. The classical decision making process is often difficult and uncertain when identifying the ideal nanomaterial. To address this, we develop a novel decision making model based on a fuzzy credibility neural network with Hamacher aggregation operators. We apply the proposed model to select the most suitable nanomaterial for nanoelectronics. For this purpose, we collect information matrices from three experts regarding various nanomaterials. To analyze these matrices, we use entropy to calculate the weights of each criterion. After determining the weights, we apply fuzzy credibility Hamacher weighted aggregation operators to combine the input signals and their corresponding weights in order to compute the hidden layer information for the nanomaterials. To ensure accurate and reliable results, we apply the fuzzy credibility Hamacher weighted aggregation operator once again to the hidden layer information, aggregating it with the appropriate weights to generate the output layer information. Next, we use a score function based on fuzzy credibility numbers to calculate the score values of the output information. After this, we apply three activation functions to compute the final output of the proposed model. Based on the results, graphene is identified as the best nanomaterial for nanoelectronics. Furthermore, we perform a sensitivity analysis of the proposed model by varying the Hamacher parameter. To confirm the effectiveness and accuracy of the proposed approach, we finally validate the results using three well-known MCDM methods.},
  archive      = {J_IJCIS},
  author       = {Ullah, Ihsan and Abdullah, Saleem and Nawaz, Marya and Ahmadzai, Hameed Gul},
  doi          = {10.1007/s44196-025-00938-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A fuzzy neural network approach for nanomaterials analysis in nanoelectronics under fuzzy credibility information},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive covariance and quaternion-focused hybrid error-state EKF/UKF for visual-inertial odometry. <em>IJCIS</em>, <em>18</em>(1), 1-32. (<a href='https://doi.org/10.1007/s44196-025-00942-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an innovative hybrid Visual-Inertial Odometry (VIO) method for Unmanned Aerial Vehicles (UAVs) that is resilient to environmental challenges and capable of dynamically assessing sensor reliability. Built upon a loosely coupled sensor fusion architecture, the system utilizes a novel hybrid Quaternion-focused Error-State EKF/UKF (Qf-ES-EKF/UKF) architecture to process inertial measurement unit (IMU) data. This architecture first propagates the entire state using an Error-State Extended Kalman Filter (ESKF) and then applies a targeted Scaled Unscented Kalman Filter (SUKF) step to refine only the orientation. This sequential process blends the accuracy of SUKF in quaternion estimation with the overall computational efficiency of ESKF. The reliability of visual measurements is assessed via a dynamic sensor confidence score based on metrics, such as image entropy, intensity variation, motion blur, and inference quality, adapting the measurement noise covariance to ensure stable pose estimation even under challenging conditions. Comprehensive experimental analyses on the EuRoC MAV dataset demonstrate key advantages: an average improvement of 49% in position accuracy in challenging scenarios, an average of 57% in rotation accuracy over ESKF-based methods, and SUKF-comparable accuracy achieved with approximately 48% lower computational cost than a full SUKF implementation. These findings demonstrate that the presented approach strikes an effective balance between computational efficiency and estimation accuracy, and significantly enhances UAV pose estimation performance in complex environments with varying sensor reliability.},
  archive      = {J_IJCIS},
  author       = {Asil, Ufuk and Nasibov, Efendi},
  doi          = {10.1007/s44196-025-00942-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Adaptive covariance and quaternion-focused hybrid error-state EKF/UKF for visual-inertial odometry},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust InceptionV3 with novel EYENET weights for di-EYENET ocular surface imaging dataset: Integrating chain foraging and cyclone aging techniques. <em>IJCIS</em>, <em>18</em>(1), 1-26. (<a href='https://doi.org/10.1007/s44196-025-00943-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting diabetic types from ocular surface eye images is a challenging task due to subtle variations in features and the potential overlap in presentations among different diabetic types. While AI-based algorithms have shown promise in distinguishing these nuances, gaps remain in the accuracy and adaptability of existing models, especially in the context of medical imaging for diabetes classification. This study addresses these gaps by proposing a novel integration of AI and medical imaging through the Manta-ray Foraging Optimization (MRFO) algorithm, which leverages cyclone aging (CA) and chain foraging (CF) strategies. We couple MRFO with hierarchical feature learning to optimize the InceptionV3 model, achieving optimal hyperparameter configuration and enhancing both accuracy and computational efficiency. The novelty of this work lies in the introduction of a newly curated dataset, Di-EYENET, which is specifically designed for diabetic eye studies and contains multiclass categories (Type-1, Type-2, and non-diabetic). Di-EYENET fills a significant gap in diabetic ocular research by offering a reliable, validated resource for training models on eye image datasets with distinct characteristics. Our results demonstrate that the InceptionV3 model, fine-tuned with the newly developed EYENET weights, outperforms both traditional ImageNet weights and other pretrained models, showing a 2% accuracy improvement. This research highlights the potential of nature-inspired optimization algorithms and tailored datasets to enhance AI model robustness and adaptability in the context of medical disease diagnosis, particularly in the field of diabetic eye disease.},
  archive      = {J_IJCIS},
  author       = {Khan, Muhammad Ahmad and Khan, Saif Ur Rehman and Rehman, Hafeez Ur and Aladhadh, Suliman and Lin, Ding},
  doi          = {10.1007/s44196-025-00943-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Robust InceptionV3 with novel EYENET weights for di-EYENET ocular surface imaging dataset: Integrating chain foraging and cyclone aging techniques},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced bio-inspired GWO–DE technique for efficient feature selection in the EEG-RSVP paradigm. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-025-00944-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent noise and high dimensionality of EEG signal make it more difficult to accomplish fast and accurate classification, which is particularly challenging in rapid serial visual presentations (RSVP) target recognition tasks based on EEG. Conventional feature selection approaches have difficulty in reducing dimensions and keeping a good classification performance at the same time. To resolve these issues, we present a bio-inspired hybrid optimization framework where Differential Evolution (DE) is integrated with Grey Wolf Optimization (GWO) to improve the efficiency of feature selections. Our method utilizes the focal loss for combating data imbalance in EEG datasets, the Fisher score for enhancing the discrimination capability of the classes, and the average pairwise Pearson correlation for the reduction of redundant information between features in RSVP datasets. In such a sense, GWO functions as an exploration tool of the feature space, while DE further refines good candidates through a local exploitation. CFSFs are tested with a variety of classifiers ranging from traditional classifiers to deep learning, such as support vector machine (SVM), light gradient boosting machine (LightGBM), convolutional neural network (CNN), long short-term memory (LSTM), etc. Compared with those traditional optimization and classification pipelines, our hybrid GWO–DE method converges faster displacement, more efficient dimension reduction, higher detection accuracy, and classification accuracy, and F1 score result showed us 98.79% and 97.7%, respectively. This efficient method is applicable to real-time EEG applications, including cognitive monitoring, neuro-feedback, and biometric identification.},
  archive      = {J_IJCIS},
  author       = {Abinayaa, S. and Sridhar, S. S.},
  doi          = {10.1007/s44196-025-00944-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An enhanced bio-inspired GWO–DE technique for efficient feature selection in the EEG-RSVP paradigm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for diagnosis of osteoporosis integrating clinical decision support with generative adversarial networks. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00846-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporosis is a bone illness that minimizes bone strength and increases fracture risk. Machine learning methods have been applied to diagnose osteoporosis. However, the accuracy of osteoporosis disease prediction has not improved, nor has the time taken been reduced. To improve the accuracy of osteoporosis disease prediction efficiently, the Rosenthal canonical correlative explainable deep convolutional generative adversarial network (RCCEDCGAN) is proposed. It consists of four main processes: data acquisition, preprocessing, feature selection, and classification. Data samples are collected during data acquisition. Preprocessing includes using multivariate linear regression to fill in missing values and a Q statistical proximal test to identify outliers. Feature selection is carried out using Rosenthal canonical variants analysis for identifying and selecting pertinent features with less time. Finally, explainable deep convolutional generative adversarial network (EDCGAN) is employed for classifying and predicting osteoporosis. The clinical decision support system utilizes EDCGANs for osteoporosis risk prediction analysis based on the Rand indexive decision stump model to assist healthcare professionals in diagnosis and treatment planning. The quantitatively analyzed results show that the RCCEDCGAN method improved by 5% in disease prediction accuracy, precision, recall, F1 score, and 9% specificity compared to the RR model and modified GP classifier. RCCEDCGAN method showed a p-value of less than 0.05 and a confidence interval of 95% for developing osteoporosis. In addition, the RCCEDCGAN method reduced prediction time by 8% compared to the RR model and modified GP classifier techniques. Hence, the RCCEDCGAN is an effective approach for early diagnosis and risk reduction of osteoporosis, aiding in prevention and management strategies.},
  archive      = {J_IJCIS},
  author       = {Raja, M. and Reddy, Avulapalli Jayaram},
  doi          = {10.1007/s44196-025-00846-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel approach for diagnosis of osteoporosis integrating clinical decision support with generative adversarial networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of spectral clustering algorithm in cognitive diagnosis model: Approach for student’s psychological growth. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-025-00849-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of intelligent education, the diagnostic performance of the traditional cognitive diagnostic model has been unable to meet the needs of today’s education. This study uses the Gaussian mixture model (GMM) to model and optimize model parameters through maximum probability estimation. The spectral clustering (SC) algorithm iterative optimization was combined with a similarity matrix and Laplacian matrix to construct an improved spectral clustering cognitive diagnosis model. The proposed SC algorithm’s clustering accuracy was 0.95, ARI was 0.86, and FMI was 0.85, and its clustering performance was better than that of other comparison algorithms. The cognitive diagnosis model based on the SC algorithm showed 4.01 SC, and the psychological status score was 3.97. The clustering performance of the model proposed in this study showed a favorable outcome. Moreover, the cognitive diagnosis model based on SC can meet the cognitive diagnosis needs of most students and help improve their cognitive ability. The enhanced cognitive diagnostic model combining SC and the GMM proposed has significant advantages in clustering performance and educational application effects, providing technical support for promoting students’ psychological growth.},
  archive      = {J_IJCIS},
  author       = {Chang, Xiao},
  doi          = {10.1007/s44196-025-00849-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Development of spectral clustering algorithm in cognitive diagnosis model: Approach for student’s psychological growth},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AQST-ClustNet: Hybrid aquila quantum sooty tern optimization for user profile clustering in social network. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00866-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User profile clustering is the process of grouping users on social media sites based on common characteristics identified in their profile data, such as demographics, interests, and interactions. Profile clustering allows users to engage in targeted marketing, skill-matching, and collaborative networking by grouping them based on similar attributes, interests, or professional criteria. However, one key drawback of user profile clustering is its sensitivity to noisy and missing data, high-dimensional feature spaces, poor semantic understanding, and complexity limitations. To overcome these issues, a novel Hybrid Aquila Quantum Sooty tern optimization for clustering (AQST-ClustNet) approach based on user profiles (UP) has been proposed in this paper. The user profile data is preprocessed using NLP techniques involving data stemming, handling of missing data or values, removal of stop words, and data extraction for eliminating inappropriate data. A Hybrid Aquila Quantum Sooty Tern Optimization (HAQSTO) algorithm is employed for clustering the user profile into healthcare professionals, marketing professionals, software developers, and educators. The efficiency of the developed method is assessed employing various metrics, including Calinski–Harabasz score (CHS), Silhouette score (SHS), and Davies–Bouldin score (DBS). The proposed model achieves less runtime of 45 s, whereas the existing techniques, such as MCEMS, DBSTexC, and TSMIUSC-Miner, achieve runtimes of 70 s, 79 s, and 60 s. Using the effective dual-stage feature extraction and clustering approach, the complexity of clustering and a high-dimensional feature space is effectively reduced.},
  archive      = {J_IJCIS},
  author       = {Babu, K. Dinesh and Sujihelen, L. and Singh, C. Senthil},
  doi          = {10.1007/s44196-025-00866-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {AQST-ClustNet: Hybrid aquila quantum sooty tern optimization for user profile clustering in social network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an IoT-based MANET for healthcare monitoring system using data loss aware routing protocol. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00896-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare needs a major shift to more measurable and affordable solutions. The answer to these challenges is to focus on restructuring the healthcare system to prevent illness, not illness, and on disease prevention and early detection. The Internet of Things (IoT) communicates with mobile ad hoc networks (MANETs) in a smart environment, making it more attractive and cost-effective for consumers. Recently, MANET-IoT systems have been used in many areas of live applications. In addition, most routing protocols are for MANET, but they are not compatible with MANET-IoT. However, one of the key apparatuses of the MANET-IoT system is the loss of records due to unreliable routing. In this article, we suggest an optimal cluster founded data loss aware routing protocol, MANET-IoT, for healthcare monitoring systems (OCDL-HM). First, we introduce efficient cluster formation using the butterfly-induced sunflower optimization (BSFO) algorithm, which enhances the energy efficiency of routing. Then, the cluster head (CH) of every cluster is computed through a cuckoo search based deep probability neural network (CS-DPNN) with different design metrics. The CH node is acting as an intermediate node between cluster members and the next neighbouring CH node. After that, the next neighbouring CH node is selected by a hybrid recurrent dynamic neural network (RDNN), which provides data lossless routing between nodes. Finally, the simulation results of proposed and existing routing protocols analyzed with different simulation scenarios in terms of energy consumption, packet loss ratio, network lifetime, number of active nodes, packet delivery ratio, throughput, and latency.},
  archive      = {J_IJCIS},
  author       = {Balasubramanian, K. and Senthilkumar, S. and Kopperundevi, N. and Sivakumar, S.},
  doi          = {10.1007/s44196-025-00896-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Development of an IoT-based MANET for healthcare monitoring system using data loss aware routing protocol},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new multi-granular 2-tuple WASPAS-H approach for evaluating water resources for olive tree irrigation under group decision-making. <em>IJCIS</em>, <em>18</em>(1), 1-32. (<a href='https://doi.org/10.1007/s44196-025-00918-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiple criteria decision aid (MCDA) problems, evaluating and selecting alternatives across numerous criteria often presents a significant challenge. An excessive number of criteria can induce cognitive overload in decision-makers, diminishing the reliability and validity of the outcomes. To address this complexity, organizing criteria into a hierarchical tree structure has been recommended, allowing the main problem to be decomposed into more manageable sub-problems. However, existing ranking approaches rarely offer efficient tools to handle hierarchical criteria structures. This study proposes the development of hierarchical decision support systems aimed at improving the quality of decision-making. Specifically, an extension of the well-established weighted aggregated sum product assessment (WASPAS) method, termed 2-Tuple WASPAS-H, is introduced. This new method generates partial pre-orders at each sub-level and an overall pre-order at the highest level, enabling a step-by-step analysis and interpretation of the problem. A major strength of 2-Tuple WASPAS-H lies in its capacity to produce detailed rankings at each node of the hierarchy, while also accommodating imprecise and ambiguous evaluations through a symbolic treatment of multi-granular linguistic assessments provided by groups of experts. To evaluate the relative importance of criteria across different levels, the 2-Tuple BWM is utilized. The proposed approach is validated through a real case study: the evaluation of water resources for olive tree irrigation. The analysis employs a four-level hierarchy of criteria, incorporating environmental, productive, pomological, physico-chemical, social, technological, and financial dimensions. Ultimately, a sensitivity analysis is undertaken to evaluate the stability and performance of the developed methodology.},
  archive      = {J_IJCIS},
  author       = {Daoud-BenAmor, Wiem and Frikha, Hela Moalla},
  doi          = {10.1007/s44196-025-00918-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A new multi-granular 2-tuple WASPAS-H approach for evaluating water resources for olive tree irrigation under group decision-making},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid DL with battle royal optimisation algorithm for accurate tree counting using satellite images. <em>IJCIS</em>, <em>18</em>(1), 1-46. (<a href='https://doi.org/10.1007/s44196-025-00928-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree enumeration is a fundamental task in environmental monitoring, sustainable forestry management, and urban planning, yet manual methods remain prohibitively time-consuming and labor-intensive. This study presents an innovative approach, named BRO (Briefly Optimized Recognition with Deep Learning (DL) for accurate and efficient tree enumeration utilizing high-resolution satellite imagery and advanced machine learning techniques, specifically leveraging DL and transfer learning for robust tree detection and counting in complex environments. Experimental results demonstrate the significant effectiveness of the BRO approach compared to baseline methods, achieving a high accuracy of 97.8%. Furthermore, BRO shows substantial improvements in counting precision, resulting in a 5% reduction in Root Mean Squared Error (RMSE) and a 7% decrease in Mean Absolute Error (MAE) over existing techniques. Beyond performance metrics, execution time benchmarks highlight BRO’s computational efficiency, processing large datasets significantly faster than conventional optimization methods, which is crucial for large-scale applications. This research provides a robust and efficient system critical for various real-world applications, including large-scale deforestation monitoring, afforestation project planning and evaluation, and detailed urban forest inventories, thereby facilitating informed decision-making for environmental conservation and resource management.},
  archive      = {J_IJCIS},
  author       = {Bansal, Himanshu and Sinha, Anurag and Agarwal, Garvit and Mishra, Shantanu Kumar and Gupta, Shelly and Chaudhary, Parul and Ashokrao, Patil Rahul and Kushwaha, Ajay and Bagaria, Mukesh Kumar and Reza, Md.Sazid and Agrawal, Anupam and Bhad, Sandeep and Khalid, Saifullah and Lasisi, Ayodele and Aseere, Ali M.},
  doi          = {10.1007/s44196-025-00928-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-46},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A hybrid DL with battle royal optimisation algorithm for accurate tree counting using satellite images},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computer-aided application in medicine and biomedicine. <em>IJCIS</em>, <em>18</em>(1), 1-39. (<a href='https://doi.org/10.1007/s44196-025-00936-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided applications in medicine and biomedicine drive the advancement of diagnostics, treatment, and research by leveraging data processing, analysis, and innovation. Computer technologies are used in medicine in imaging, diagnosis, storing and processing information, and staff management. The review will organize these progressions by significant features, which are medical imaging, diagnostic systems, data management, and their impact on daily clinical work. It explores diverse computer applications in medicine, including simulations, modeling, data visualization, and advanced data processing. Pattern classification techniques, decision support systems, and the integration of supercomputers—particularly in drug development—are discussed, alongside natural user interfaces and the application of Computer Methods and Programs in Biomedicine, with attention to human–computer interface integration. Modern computer-based imaging modalities like CT and MRI are also examined in detail, as are clinical applications of CAD for improving medical procedures. Lastly, the review projects future trends in cost-effective, high-quality telemedicine, remote consultations, integrated health records, computer-based learning, and disease management. Overall, this comprehensive discussion highlights the multifaceted impact of computing on the continued evolution of healthcare.},
  archive      = {J_IJCIS},
  author       = {Liao, Qi-Ming and Hussain, Wahab and Liao, Zhong-Xia and Hussain, Sarfraz and Jiang, Zhi-Liang and Zhu, Yong-Hao and Luo, Huang-Yin and Ji, Xin-Ying and Wen, Hong-Wei and Wu, Dong-Dong},
  doi          = {10.1007/s44196-025-00936-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-39},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Computer-aided application in medicine and biomedicine},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating handwritten answers using DeepSeek: A comparative analysis of deep learning-based assessment. <em>IJCIS</em>, <em>18</em>(1), 1-16. (<a href='https://doi.org/10.1007/s44196-025-00946-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence is revolutionizing the education sector by making learning more accessible, efficient, and customized. Recent advancements in artificial intelligence have sparked significant interest in automating the evaluation of handwritten answers. Traditional handwritten evaluation techniques are influenced by the evaluator's mental and physical state, environmental factors, human bias, emotional swings, and logistical challenges like storage and retrieval. Although sequence-to-sequence neural networks and other existing AI evaluation methods have demonstrated promise, they are constrained by their reliance on high-performance hardware, such as GPUs, lengthy training periods, and challenges in managing a variety of scenarios. The state-of-the-art technique known as Bidirectional Encoders Representation from Transformer (BERT) has overcome the drawbacks of previous NLP techniques like Bag of Words, TF-IDF, and Word2Vec. But BERT depends on surface-level keyword similarity, if the keywords are different then the accuracy is not perfect. This study presents a technique that combines optical character recognition (OCR) technology with DeepSeek-R1 1.5B model to create a robust, efficient, and accurate grading system. To overcome the above-mentioned challenges, we proposed an evaluation technique that uses the Google Cloud Vision API to extract and convert handwritten responses into machine-readable text, thereby providing a pre-processed input for further evaluation in this study. The main aim of this study is to develop a scalable, automated, and effective system for grading handwritten responses by combining DeepSeek for response evaluation with the Google Cloud Vision API for text extraction. To check the performance of the proposed DeepSeek evaluation method, we compare its results with cosine similarity metrics. After testing on multiple assignments, DeepSeek’s independent evaluation method gave the best results: lowest MAE—0.0580, lowest RMSE—0.147, and strongest correlation—0.895. The finding of this technique has shown that the proposed technique is reliable and accurate.},
  archive      = {J_IJCIS},
  author       = {Bansal, Sanskar and Gupta, Vinay and Gupta, Eshita and Garg, Peeyush},
  doi          = {10.1007/s44196-025-00946-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Evaluating handwritten answers using DeepSeek: A comparative analysis of deep learning-based assessment},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using cuckoo search algorithm to predict corporate financial risks and alleviate economic uncertainty. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00950-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting financial risk accurately is crucial for maintaining economic sustainability and investor trust in an era of increasing economic volatility and business instability. There are several problems with traditional financial risk assessment models, including their inflexibility when confronted with high-dimensional, non-linear data and their inability to dynamically adjust to changing financial situations. Advanced forecasting models must be combined with robust optimization methods to address these challenges effectively. Conventional methods, such as logistic regression, decision trees, and linear discriminant analysis, often struggle to accurately detect early financial risks because they are deterministic and unsuited for exploring global optimal solutions. Problems like this contribute to macroeconomic uncertainty by delaying the identification of potential defaults. This research presents a new hybrid framework, the Financial Risk Prediction Framework utilizing Cuckoo Search Optimization (FRPF-CSO), to enhance prediction accuracy and optimize feature selection in high-dimensional financial datasets. This framework combines a Backpropagation Neural Network (BPNN) with the Cuckoo Search Algorithm (CSA) to build an adaptive learning system. CSA is used to tune the network weights and feature parameters worldwide to improve the neural model’s convergence speed and predictive ability. The system’s dynamic learning capabilities identify patterns connected to company failures and financial decline. Various real-world corporate finance datasets have been used for experimental validation. The experimental results demonstrate that the proposed FRPF-CSO model achieves a high early warning lead time of 2.1 quarters, a prediction accuracy of 95.72%, a convergence rate of 9.87 s, a risk detection ratio of 97.63%, and a computational efficiency ratio of 98.2% compared to other existing methods.},
  archive      = {J_IJCIS},
  author       = {Cai, Muqiao},
  doi          = {10.1007/s44196-025-00950-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Using cuckoo search algorithm to predict corporate financial risks and alleviate economic uncertainty},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using convolutional neural networks for material surface quality inspection and classification. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00951-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern industries, undetected material surface defects lead to increased scrap rates and costly rework, primarily due to the limitations of manual inspection done in a slow and inconsistent process with poor small-defect identification. This lack of high-speed inspection solutions for multistage quality control creates critical gaps in production efficiency and product reliability. Hence, the research introduces a Hybridized Convolutional Neural Network for Surface Quality Control model that integrates U-Net with a ResNet34 backbone for precise defect localization and EfficientNet-B4 for defect classification, enhanced by stroboscopic illuminant preprocessing to optimize defect visibility. The research is validated on the Metal Surface Defect Dataset containing 147,824 high-resolution images capturing eight critical industrial defect types. The research results provide 98.2% classification accuracy, 96.5% defect localization precision, minimizes false alarms, and 98.2% recall for incoming material inspection, preventing defective inputs for industrial quality inspection. By integrating these innovations, the research helps manufacturers with a unified, scalable quality inspection platform that reduces human inspection workload by 12% while operating at production line speeds of 20.6 frames/sec and achieves 83.2 fps. The research model delivers a production-ready quality inspection system, which leads to maintaining a significant leap forward in automated surface quality assurance for Industry 4.0 applications.},
  archive      = {J_IJCIS},
  author       = {Ke, HanLin},
  doi          = {10.1007/s44196-025-00951-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Using convolutional neural networks for material surface quality inspection and classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based expression generation technology for virtual characters in film and television art. <em>IJCIS</em>, <em>18</em>(1), 1-28. (<a href='https://doi.org/10.1007/s44196-025-00952-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression generation played an essential role in virtual avatars, television, film art, and human–computer interaction. The existing synthesis model faces difficulties due to poor generalization, unnatural distortion, identity inconsistency, and weak lip synchronization with audio. In addition, conventional approaches fail to balance expression fidelity, real-time synthesis, and identity preservation. The research difficulties are addressed by introducing the Machine Learning-based Expression Generation Model to improve the expression generation accuracy. The ML-EGM model uses spatial and temporal features to generate expression by integrating generative adversarial networks, transformer encoding, and lip synchronization. A generator synthesizes expressive face outputs in the generative framework, while the discriminator is trained to distinguish actual and created expressions. This adversarial process teaches the generator to mimic actual facial emotions. During this process, transformer encoding is applied to manage the temporal consistency using the self-attention mechanism to minimize the error and improve the similarity rate. Further, the expressions are integrated with the speech synthesis process to enhance the overall frame expression generation efficiency. The system uses the MEAD dataset to evaluate the system efficiency, in which the model attains 99.1% expression generation accuracy, which is a 5.7% improvement compared to the MFA methods. The ML-EGM model proposal sets a new standard in achieving realism in expression generation, consistency of emotion realism, and speed of synthesis; its possible use cases include virtual aides, AI avatars, deepfake image detection, robotics systems that convey expression, and emotion-sensitive human–computer systems.},
  archive      = {J_IJCIS},
  author       = {Zhang, Yi and Qian, Junting},
  doi          = {10.1007/s44196-025-00952-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Machine learning-based expression generation technology for virtual characters in film and television art},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Objective and intelligent acquisition of two types of decision data based on online comment information and its application in emergency decision-making. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00953-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the urgent, dynamic, and uncertain nature of emergencies, the rapid response to emergencies and their control is challenging, with the intelligent, real-time acquisition of decision data being a key issue. However, most previous studies relied on simulations, experts, assumptions, questionnaires, and borrowed literature, which are impractical. Therefore, this study developed two methods for the intelligent and objective acquisition of quantitative decision data based on machine learning and online review data and applied the methods to solve practical emergency problems. First, a reasonable decision index system was constructed using latent Dirichlet allocation thematic-cluster analysis of the focus word frequency from online public opinions. Python programming was then used to capture the big data of social media comments on emergencies in real time to obtain multisource comment data, which were preprocessed and visualized. Second, based on the optimized SnowNLP, emotional tendencies and statistical analyses were performed on the processed comment data, resulting in two quantitative decision matrices, which were represented as single-valued neutrosophic numbers (SVNNs) and probabilistic linguistic terms (PLTs). Next, the bidirectional projection method was extended to an environment of SVNNs and PLTs, and the alternatives were sorted and selected. Finally, a sudden natural disaster event was used as a numerical case to verify the proposed method. Through a comparative analysis, the experimental results show the practicability and feasibility of the proposed decision-making method, demonstrating the superiority and intelligence of our research. Our study can conduct real-time monitoring of emergencies and intelligently and objectively obtain quantified decision-making data, thereby providing auxiliary decision-making support for relevant emergency management departments, ensuring the positive development of public opinion, social stability, and the safety of people's lives and property.},
  archive      = {J_IJCIS},
  author       = {Tan, Ruipu and Yang, Lehua and Li, Jing},
  doi          = {10.1007/s44196-025-00953-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Objective and intelligent acquisition of two types of decision data based on online comment information and its application in emergency decision-making},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving diabetes and heart disease prediction via federated learning and WCO. <em>IJCIS</em>, <em>18</em>(1), 1-26. (<a href='https://doi.org/10.1007/s44196-025-00956-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes, afflicting 537 million worldwide, is a prevalent and lethal non-communicable ailment. Its onset, influenced by factors like obesity and family history, manifests symptoms such as frequent urination. Long-term complications encompass heart, kidney, and nerve ailments. Early prediction mitigates risks. All these encompassing strategies are designed to improve prediction precision and facilitate proactive diabetes control. This research employed SMOTE methods to tackle imbalanced classes, utilizing various classification algorithms such as Random Forest, XGBoost, Multilayer Perceptron, Gradient Boost, and AdaBoost. Following extensive training and evaluation, the AdaBoost classifier delivered superior outcomes, achieving a 94.02% accuracy rate, an F1 score of 93.32%, and an AUC of 0.95. In the healthcare industry, accurately forecasting diabetes mellitus is crucial; however, privacy laws hinder the transfer of medical information from the Internet of Medical Things (IoMT), causing delays in diagnosis. This study introduces the Federated Learning with Weighted Conglomeration Optimization (FLWCO) model as a solution to these challenges. In Centralized Learning, AdaBoost with WCO achieves an accuracy of 95.32% when tested on a Kaggle dataset consisting of 96,146 instances. During the second stage, FLWCO achieves a superior 97.27% accuracy rate compared to other federated learning techniques. The method not only guarantees privacy conformity but also decreases communication expenses. FLWCO demonstrates superiority over existing federated learning algorithms in real-world heart illness prediction. Furthermore, the proposed model can be employed to estimate the likelihood of heart disease in individuals with diabetes. This highlights the potential of federated learning, especially FLWCO, in leveraging distributed data while preserving privacy, facilitating accurate diabetes mellitus diagnosis, and addressing challenges in sharing medical information securely and efficiently.},
  archive      = {J_IJCIS},
  author       = {Dash, Sachikanta and Padhy, Sasmita and Suman, Preetam and Mal, Sandip and Malviya, Lokesh and Suman, Amrit and Kishore, Jaydeep},
  doi          = {10.1007/s44196-025-00956-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Privacy-preserving diabetes and heart disease prediction via federated learning and WCO},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating label encoding and preprocessing techniques for breast cancer prediction using machine learning algorithms. <em>IJCIS</em>, <em>18</em>(1), 1-35. (<a href='https://doi.org/10.1007/s44196-025-00957-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast Cancer (BC) is a major health concern in the world, accounting for a disproportionately high number of new cases each year among females. Its frequency as a health issue has increased significantly in recent years. Early detection of BC is the most straightforward method of coping with the diagnosis. In 2020, approximately 2.3 million women worldwide were diagnosed with breast cancer, resulting in around 685,000 deaths. Therefore, early detection of BC is crucial for effective treatment and improved survival rates. The results and assessments of many Machines Learning (ML) models for detecting BC survivability are presented in this manuscript using the BC dataset. Although the dataset is relatively small, it provides valuable insights. The data was evaluated with many ML techniques and different predictive models were built with the valuable results. Several ML techniques were applied to build predictive models, including Gaussian Naïve Bayes (GNB), k-Nearest Neighbors (k-NN), Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), and Support Vector Machine (SVM). Data scaling and encoding techniques, including StandardScaler and MinMaxScaler, are employed to enhance the accuracy of these machine learning models. Additionally, preprocessing steps, such as Numerical Variable Correlation, Categorical Variables Analysis, Continuous Variables Analysis, Bivariate Analysis, Balancing Classes (oversampling function) are applied to enhance the model’s performance. The results show that out of all the ML techniques tested, the k-NN method gives the most accurate predictions, which is close to 94.00%.},
  archive      = {J_IJCIS},
  author       = {Kumar, Mukesh and Bhardwaj, Vivek},
  doi          = {10.1007/s44196-025-00957-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-35},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Evaluating label encoding and preprocessing techniques for breast cancer prediction using machine learning algorithms},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of combat resource allocation based on restricted tournament selection social genetic algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00958-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the challenge of combat resource allocation problem (CRAP), especially under resource constraints, the dilemma between the efficiency of combat resource utilization and the efficiency of problem-solving. We propose a novel genetic algorithm that integrates a restricted tournament selection strategy with sociological principles, named the restricted tournament selection social genetic algorithm (RTS2GA). Initially, we develop a comprehensive model for the allocation of combat resources that takes into account multiple constraints. Then, building upon the traditional Genetic Algorithm, we introduce a novel selection strategy known as restricted tournament selection to enhance the diversity of the algorithm’s population. In addition, we innovatively incorporate the concept of ‘group effect’ from sociology, adding a socialization operator to the algorithm to accelerate convergence and improve the quality of optimal solutions. Comprehensive evaluation confirms RTS2GA’s trade-off profile: though incurring added computational costs, it achieves competitive convergence speed (marginally behind PSO/MPSO; comparable to GA/DE/GA-APSO) while establishing definitive superiority in global optimization across all five benchmarks.},
  archive      = {J_IJCIS},
  author       = {Yuan, Shandong and Ren, Yun and Zhou, Han and Cheng, Yongjing and Yan, Kai},
  doi          = {10.1007/s44196-025-00958-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimization of combat resource allocation based on restricted tournament selection social genetic algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ontology-based approach for heart disease prediction leveraging decision trees in healthcare. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00960-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An ontology-driven system for the diagnosis of heart disease combines data-driven methods with semantic reasoning. The dataset consists of major healthcare attributes like patient information, clinical findings, and diagnostic indicators. This information is processed in a methodical way into a clinical ontology, which facilitates structured, semantically enhanced representation of medical entities and their relationships. The system uses a hybrid strategy based on decision trees and Graph Neural Networks (GNNs) to enhance predictive performance. Decision trees offer interpretability through the identification of key decision paths, whereas GNNs utilize connected clinical ontology for richer relational analysis. Semantic Web Rule Language (SWRL) rules also enrich reasoning by deducing new knowledge from implicit relationships and patterns. The rules combine risk factors such as hypertension, cholesterol, and lifestyle to predict heart disease with high accuracy. The integration of rule-based reasoning and machine learning provides a complete and context-sensitive system. Performance is measured using accuracy, precision, recall, F1-score, and Area Under the Receiver Operating Characteristic Curve (AUC-ROC) to provide solid diagnostic evaluation. The hybrid model of decision trees, GNNs, and ontology-based reasoning with boosting via Semantic Web Rule Language (SWRL) rules shows great predictive accuracy and decision support improvements. The clinical ontology provides interpretability, flexibility, and scalability for future data sets and changing medical knowledge. This work emphasizes the opportunity of combining ontology engineering, machine learning, and semantic reasoning in enhancing heart disease prediction and diagnosis. The system assists healthcare workers in making well-informed decisions, improving diagnosis accuracy, and maximizing patient management.},
  archive      = {J_IJCIS},
  author       = {Priyadharshini, U. and Vijayan, R.},
  doi          = {10.1007/s44196-025-00960-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An ontology-based approach for heart disease prediction leveraging decision trees in healthcare},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractal fuzzy-based multi-criteria assessment of sustainability in rare earth use for hydrogen storage. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00962-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of rare earth elements in hydrogen storage processes offers significant advantages in terms of increasing technological efficiency and ensuring system security. However, this process also creates some serious problems in terms of environmental and economic sustainability. It is necessary to determine the most critical indicators affecting the sustainable use of these elements. Studies on this subject in the literature are quite limited, and this may lead to wrong investment decisions. The main purpose of this study is to determine the most important indicators to increase the sustainable use of rare earth elements in hydrogen storage processes. An original decision-making model in which Siamese network, logarithmic percentage-change driven objective weighting (LOPCOW), fractal fuzzy numbers, and weighted influence super matrix with precedence (WISP) approaches are integrated in the study. This study provides an original contribution to the literature by identifying the most critical indicators affecting the sustainable use of rare earths in hydrogen storage processes by presenting an innovative model. Fractal structures such as Koch Snowflake, Cantor Dust, and Sierpinski Triangle can model complex uncertainties more successfully. Fractal structures are particularly effective in modeling linguistic fuzziness because their recursive nature closely mirrors the layered and imprecise way humans often express subjective judgments. Unlike linear fuzzy sets, fractals can capture the patterns of ambiguity found in expert evaluations. Hydrogen storage capacity and government supports are determined as the most vital criteria affecting sustainability in rare earth use.},
  archive      = {J_IJCIS},
  author       = {Kou, Gang and Yüksel, Serhat and Eti, Serkan and Dinçer, Hasan and Acar, Merve},
  doi          = {10.1007/s44196-025-00962-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fractal fuzzy-based multi-criteria assessment of sustainability in rare earth use for hydrogen storage},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DenseNet model with attention mechanisms for robust date fruit image classification. <em>IJCIS</em>, <em>18</em>(1), 1-33. (<a href='https://doi.org/10.1007/s44196-025-00809-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dates in Saudi Arabia hold immense cultural, economic, and nutritional importance, being a staple food and a symbol of heritage. Saudi Arabia produces approximately 1.5 million metric tons of dates annually, accounting for nearly 17% of global date production, underscoring its pivotal role in the global market. Precise and automated classification of fruits is a crucial aspect of modern agriculture, yet it remains a challenging endeavor due to the diverse appearances of fruits. The classification of date fruit varieties presents additional complexities, given variations in size, shape, and texture, making it a critical focus for technological advancements. Dates are highly nutritious, providing approximately 277 cal per 100 g and serving as an excellent source of dietary fiber, natural sugars, and energy. Their substantial nutritional value makes them indispensable in addressing food security challenges and promoting global health benefits. In this paper, we introduce a novel DenseNet-based model augmented with attention mechanisms and optimized using the Nadam algorithm. Unlike traditional DenseNet variants, the model integrates attention mechanisms to enhance focus on pertinent image features, thereby improving classification accuracy under challenging conditions. To evaluate its efficacy, the model was benchmarked against several state-of-the-art deep learning architectures, including DenseNet with Adam optimization, EfficientNet, GoogleNet, HRNet, MobileNet, and VGG, optimized with both Adam and Nadam algorithms. The proposed model achieved outstanding performance metrics, including 98.05% accuracy, 98.00% precision, 97.04% recall, and a 98.32% F1-score.},
  archive      = {J_IJCIS},
  author       = {Hassan, Esraa and Ghazalah, Sarah Abu and El-Rashidy, Nora and El-Hafeez, Tarek Abd and Shams, Mahmoud Y.},
  doi          = {10.1007/s44196-025-00809-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {DenseNet model with attention mechanisms for robust date fruit image classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement-learning-based V2G scheduling: Peak load mitigation and financial benefits. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00959-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops a centralized reinforcement learning framework, employing Q-learning, for efficient vehicle-to-grid (V2G) scheduling of large electric vehicle (EV) fleets. To address scalability challenges and inherent uncertainties in user behavior, the framework utilizes an aggregated state representation. This state captures the time-of-day, the distribution of the fleet’s state of charge (SOC) across discrete bins, and an estimated user adherence factor. The central agent learns a control policy based on this aggregated state to dynamically issue charging, discharging, or idle commands to EVs grouped within specific SOC bins. The primary objectives are to enhance power grid stability by minimizing the peak-to-average ratio (PAR) and to improve the economic viability of V2G participation for EV owners. Simulations conducted under a 40% EV penetration level (relative to a 300,000 vehicle base fleet) demonstrate the proposed method’s effectiveness: it reduced the grid PAR to 1.0683, compared to 1.0729 for a baseline uncontrolled charging scenario. Critically, the proposed method transformed the economic outcome, achieving positive average daily earnings of $1.17 per EV, in stark contrast to an average daily loss of $6.75 per EV under the baseline. These results validate the potential of the proposed intelligent, centralized control strategy using aggregated information to effectively manage large-scale V2G systems, enhance grid stability, and provide economic benefits under practical behavioral assumptions.},
  archive      = {J_IJCIS},
  author       = {Xiao, Yong and Tang, Jianlin and Lin, Xiaoming and Feng, Xiangyong and Qian, Bin and Zhang, Fan},
  doi          = {10.1007/s44196-025-00959-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Reinforcement-learning-based V2G scheduling: Peak load mitigation and financial benefits},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biogeography-based optimization of machine learning models for accurate penetration rate prediction using rock texture coefficient. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00973-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting drill penetration rate (PR) in rock environments remains a significant challenge due to the complex interplay between rock texture, drilling fluid properties, and operational parameters. Traditional empirical models often lack generalizability and are based on inconsistent datasets, limiting their reliability. To address these limitations, this study develops a comprehensive experimental dataset using rock samples collected from various mines in Iran, tested under controlled laboratory conditions with different drilling fluids, bit loads, and rotational speeds. Texture coefficient (TC), electrical conductivity (EC), load on bit (LOB), and bit rotational velocity (BRV) were selected as input features. Four machine learning models—support vector regression (SVR), stochastic gradient descent (SGD), K-nearest neighbors (KNN), and decision tree (DT)—were trained to predict PR. A biogeography-based optimization (BBO) algorithm was employed to fine-tune hyperparameters and enhance model accuracy. Additionally, a novel hybrid error index (HEI) was introduced to comprehensively evaluate model performance. Among all models, the DT achieved the best accuracy with an HEI of 0.3753, followed by KNN, SVR, and SGD. These findings demonstrate the potential of the DT model, combined with optimized learning and a robust dataset, to reliably predict penetration rate in rock-based engineering projects.},
  archive      = {J_IJCIS},
  author       = {Esmaeilzadeh, Akbar and Mikaeil, Reza and Khosravimanesh, Shahrokh and Shaffiee Haghshenas, Sina and Simic, Vladimir and Pamucar, Dragan},
  doi          = {10.1007/s44196-025-00973-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Biogeography-based optimization of machine learning models for accurate penetration rate prediction using rock texture coefficient},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning enabled score-based generative adversarial networks (GANs). <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00933-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity of Generative Adversarial Networks (GANs) to provide high-quality data has led to their significant attention. On the other hand, hyperparameter adjustment is a common part of GAN training, which may increase computing costs and result in less-than-ideal performance on certain tasks. Meta-Learning Enabled Score-Based GANs (MLS-GAN) is a new framework we provide in this study that combines meta-learning with score-based generative models. Our method employs meta-learning to enhance the training of score-based models via the collection of priors customized to individual tasks and tactics for dynamic adaptability. This improves the generative process’s generalizability and robustness, and it also allows for more efficient learning with fewer data and hyperparameter modifications. By conducting comprehensive tests on image synthesis and data creation tasks, we demonstrate that our Meta-SB-GANs are successful. The results reveal higher-quality samples, quicker convergence, and better transferability to other domains. Integrating meta-learning with generative models can achieve state-of-the-art performance with decreased computing resources, as shown by our findings.},
  archive      = {J_IJCIS},
  author       = {Navaneethakrishnan, P. and Peter, Smitha Elsa and Simon, Sishaj P. and Ahamed, M. Irshad},
  doi          = {10.1007/s44196-025-00933-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Meta-learning enabled score-based generative adversarial networks (GANs)},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart diagnosis of cholangiocarcinoma from microscopic images using a modified visual geometry group network with adaptive augmentation. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00965-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral Microscopic Images (HSMI) offer a more comprehensive spectral range, making them particularly useful in medical diagnostics, including early detection of cancerous tissues. Cholangiocarcinoma, a highly lethal bile duct cancer, traditionally requires a histopathological analysis of tissue samples under a microscope. However, this method is prone to subjectivity and error, often leading to delays in diagnosis, contributing to patient mortality. This study focuses on the automated diagnosis of cholangiocarcinoma using deep learning techniques on microscopic hyperspectral data. Leveraging the spectral richness of HSMI, we developed a framework utilizing a modified Visual Geometry Group (VGG) architecture to process this hyperspectral data, aiming to detect cholangiocarcinoma at its early stages. With the growing role of artificial intelligence in pathology, this approach minimizes human error and enhances diagnostic accuracy. The dataset used in this study includes 880 cholangiocarcinoma tissue samples from 174 individuals, comprising 689 partial cancer regions, 49 full cancer regions, and 142 healthy scenes, all meticulously labeled by expert pathologists. Our ensemble learning technique integrates image preprocessing, spectral feature extraction, and classification, significantly improving diagnostic accuracy. The proposed system demonstrates a substantial improvement in the early detection of cholangiocarcinoma and offers a valuable tool for smart microscopy-based diagnosis, potentially facilitating the diagnostic burden in clinical settings.},
  archive      = {J_IJCIS},
  author       = {Mujahid, Muhammad and Kanwal, Khadija and Abubakar, Muhammad and Al-Otaibi, Shaha and Elyassih, Alex and Rehman, Amjad},
  doi          = {10.1007/s44196-025-00965-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Smart diagnosis of cholangiocarcinoma from microscopic images using a modified visual geometry group network with adaptive augmentation},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced facial emotion recognition and age estimation using modified residual network and support vector machine. <em>IJCIS</em>, <em>18</em>(1), 1-32. (<a href='https://doi.org/10.1007/s44196-025-00966-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial emotion recognition and age estimation are critical for human–computer interaction, yet existing methods struggle with variable image quality, diverse expressions, and aging patterns. To address these challenges, this study proposes a novel hybrid model combining optimized image enhancement with deep feature extraction and machine learning classification. The methodology integrates three key phases: (1) image enhancement using white balancing and adaptive gamma correction to improve edge intensity (82.235 vs. 62.89 in original images) and texture clarity (gradient: 8.248 vs. 6.183); (2) feature extraction via a modified ResNet-18 trained from scratch with monochromatic inputs; and (3) SVM classification of concatenated features from original and enhanced images. Evaluated on the UTKFace dataset (1,000 images) and savory/unsavory expression datasets (600 images), the model achieves 98.75–100% accuracy, outperforming AlexNet (94.17%) and ResNet-KNN alternatives. Key findings demonstrate: (a) 5.4% higher age estimation accuracy (96.41% vs. 87.41%) with enhanced gradient metrics, (b) 3.75% improvement in emotion recognition through edge preservation, and (c) interpretable Grad-CAM visualizations validating feature relevance. The proposed system reduces misclassification errors by 60% for subtle expressions (e.g., fear vs. surprise) compared to state-of-the-art models. Practical applications in healthcare show 40% faster patient check-in processing and robust performance under low-light conditions. This work establishes that integrating physics-based enhancement with deep residual networks significantly improves reliability for real-world deployment. Future research will optimize computational efficiency for edge devices and expand multi-modal biometric integration.},
  archive      = {J_IJCIS},
  author       = {El-Hag, Noha A. and El-Shafai, Walid and El-Samie, Fathi E. Abd and Soliman, Naglaa F.},
  doi          = {10.1007/s44196-025-00966-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced facial emotion recognition and age estimation using modified residual network and support vector machine},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SqueezeNet-based deep learning framework for accurate tomato (Solanum lycopersicum) leaf disease diagnosis and classification. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-00978-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture is crucial for food security but is severely threatened by crop disease and climate variability and causes severe yield loss. As the population grows worldwide, quick and accurate disease detection is critical. Deep learning, in particular through transfer learning, offers promising solutions, but most are computationally costly and unsuitable for real-time use in low-resource settings. There is limited research on lightweight models like SqueezeNet with optimized training parameters. This suggests the need for an efficient, high-accuracy, and deployable model to facilitate timely detection of tomato leaf diseases under real-world agricultural settings. This study presents a deep learning model based on the SqueezeNet framework for the detection and classification of tomato leaf diseases. Various combinations of optimizers (SGDM, ADAM, RMSProp) and learning rates (0.0004, 0.004) were employed during both training and testing phases, resulting in six configurations per case. The SqueezeNet model achieved 99.91% and 99.86% accuracy for TMC class classification during testing and training, with ADAM learning at 0.0004. ADAM at 0.0004 had ideal recall (100%) for the TH class during testing, and SGDM had 99.65% recall for the TYLCV class at the same learning rate, proving the model’s usefulness. The proposed framework is robust, with F1-Scores of 99.42% in ADAM testing at 0.0004 and 99.38% in SGDM training at 0.0004 for the TYLCV class. The model’s low misclassification rate (0–0.21%) boosts confidence. The ability to demonstrate classification performance and the minimal computational requirements of the proposed SqueezeNet-based system enhance the latter’s feasibility for use in real-time agricultural environments that are resource-constrained. Its scalability and resilience make it an excellent choice for utilization in advanced disease monitoring systems for tomato leaf diseases, facilitating quick, accurate diagnosis at the field level to facilitate enhanced precision agriculture practices.},
  archive      = {J_IJCIS},
  author       = {Jagdev, Siddhant and Sundararaman, Bharathwaaj and Khatri, Narendra and Gaur, Pramod and Mewada, Hiren},
  doi          = {10.1007/s44196-025-00978-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {SqueezeNet-based deep learning framework for accurate tomato (Solanum lycopersicum) leaf disease diagnosis and classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision-making method for lung diseases recognition using generalized complex fermatean fuzzy distance and entropy measures. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00926-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex Fermatean fuzzy sets (CFFSs) represent an advanced development of fuzzy sets by integrating aspects of complex fuzzy sets and Fermatean fuzzy sets. Such integration facilitates enhanced modeling and depiction of uncertain information within complex environments, surpassing the capabilities of complex intuitionistic and Pythagorean fuzzy sets. Despite these advantages, an urgent challenge is how to accurately evaluate the dissimilarity between CFFSs. Therefore, in this paper, we propose two generalized complex Fermatean fuzzy distance measures for CFFSs as well as their weighted counterparts. Furthermore, we demonstrate some key properties of the proposed distance measures, which illustrate their feasibility and effectiveness. Under certain circumstances, the proposed distance measures can be transformed into a hybrid complex Fermatean Hamming–Hausdorff and Euclidean–Hausdorff distance measures. Building on the proposed distance measures, we present a new entropy measure for CFFS. Finally, we propose a new decision-making method based on the proposed distance and entropy measures and apply the proposed method to lung disease recognition. The experiments demonstrate that the proposed distance measures effectively capture the dissimilarities between diseases represented as CFFSs, with the method achieving accurate classification results.},
  archive      = {J_IJCIS},
  author       = {Liu, Zhe and Senapati, Tapan and Santina, Dania and Jamil, Muhammad Kamran and Mlaiki, Nabil},
  doi          = {10.1007/s44196-025-00926-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A decision-making method for lung diseases recognition using generalized complex fermatean fuzzy distance and entropy measures},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early detection of retinopathy of prematurity using voting classifier-based ensemble deep learning models. <em>IJCIS</em>, <em>18</em>(1), 1-23. (<a href='https://doi.org/10.1007/s44196-025-00847-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinopathy of Prematurity (ROP) is the major cause of blindness in preterm infants, making early detection and precise classification essential for effective intervention. This research analyzes the effectiveness of four transfer learning models (InceptionV3, DenseNet201, MobileNet, and Xception), along with several voting-based ensemble approaches, such as Soft Voting, Hard Voting, Weighted Average Voting, and Mix Voting for identifying ROP in binary and multi-class conditions. A novel dataset obtained from Aravind Eye Hospital, Chennai, was utilized for this classification task. Among the individual models, Xception performed better, with F1 score of 96.95% and an accuracy of 97.28%. InceptionV3 achieved a recall of 98.76%, while DenseNet201 excelled in specificity (96.59%). To improve prediction performance, base models were combined using ensemble techniques. Soft Voting aggregates predicted probabilities, Weighted Average Voting considers model-wise performance contributions, and Mix Voting resolves tie cases scenarios in Hard Voting. These ensemble approaches significantly improved performance in both binary and multi-class classification. Specifically, Soft Voting and Mix Voting achieved an accuracy of 98.37%, an F1 score of 98.14%, and a specificity of 99.02% in binary classification. Soft Voting and Mix Voting also performed well in multi-class classification. In general, the findings suggest that ensemble techniques that include voting procedures can greatly improve the accuracy and reliability of ROP classification, thereby facilitating improved clinical decision-making.},
  archive      = {J_IJCIS},
  author       = {Krishna, S. Suresh and Reka, S. Sofana},
  doi          = {10.1007/s44196-025-00847-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Early detection of retinopathy of prematurity using voting classifier-based ensemble deep learning models},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing IoT network security by anomaly detection and intrusion prevention using gannet optimization-based adaptive deep capsule network. <em>IJCIS</em>, <em>18</em>(1), 1-51. (<a href='https://doi.org/10.1007/s44196-025-00940-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grouping of various interconnected devices along distinct applications leads the Internet of Things (IoT) to more vulnerability to security threats that affect the security of the data. Thus, Intrusion Detection Systems (IDS) are needed for IoT to mitigate cyber threats. A proven performance is offered by the deep learning models in detecting network traffic, minimizing the effects of cyberattacks, and providing enhanced security to IoT devices. Thus, this paper aims the implementation of anomaly identification and network intrusion prevention in IoT systems. Three main steps are involved in the developed framework. The first step is to get the necessary data from the publicly accessible data source. Once the necessary data is collected, the best and most appropriate weighted features are obtained from the input data. The optimal weighted features are obtained with the aid of a newly introduced Improved Gannet Optimization Algorithm (IGOA), which is responsible for optimizing the weight necessary to fuse the features to form the weighted fused features to assist in the upcoming intrusion detection procedure. To find the anomaly in the network, the weighted fused features are given as input to run via the Adaptive Deep Capsule Network (ADCapsNet). The generated IGOA is used to tune the hyper-parameter in the ADCapsNet framework to increase the detection performance. Then, the necessary actions are taken to prevent these intrusions from the network. In the end, the implemented model is evaluated by contrasting it with various traditional anomaly detection models.},
  archive      = {J_IJCIS},
  author       = {Hu, WeiWei and Alzubi, Jafar A. and Shreyas, J. and Al-Razgan, Muna and Ali, Yasser A. and Karthikayan, A.},
  doi          = {10.1007/s44196-025-00940-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-51},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing IoT network security by anomaly detection and intrusion prevention using gannet optimization-based adaptive deep capsule network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel model utilizing deep neural networks for opinion mining. <em>IJCIS</em>, <em>18</em>(1), 1-20. (<a href='https://doi.org/10.1007/s44196-025-00949-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes an aspect extraction model based on deep learning for opinion mining, an important task for sentiment analysis. Aspect extraction is concerned with determining specific product or service features that are praised or critiqued in opinionated texts. In our method, each word within a sentence is labeled as aspect-based or non-aspect-based by employing a seven-layer convolutional neural network. Performance is improved by creating linguistic patterns (LP) and combining them with the neural network. The designed model vastly surpasses current approaches by combining both linguistic heuristics and deep learning into an ensemble classification method. Experiments on four datasets that serve as gold standards, MP3, DVD, Canon, and Nikon showed significant improvements in accuracy, reaching 89.91%, 88.74%, 89.44%, and 83.99% with linguistic patterns, as opposed to 86.21%, 85.14%, 86.71%, and 79.91% in its absence. The results validate that our hybrid method is effective in boosting aspect-level sentiment analysis.},
  archive      = {J_IJCIS},
  author       = {Singh, Jagendra and Gangadharan, Syam Machinathu Parambil and Singh, Prabhishek and Diwakar, Manoj and Mall, Shachi and Bijalwan, Anchit and Kumar, Sandeep},
  doi          = {10.1007/s44196-025-00949-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel model utilizing deep neural networks for opinion mining},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Photovoltaic panels fault detection with convolutional neural network and bitterling fish optimization (BFO) algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00984-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust framework for detecting faults in PV panels using Convolutional Neural Networks (CNNs) for feature extraction and Bitterling Fish Optimization (BFO) algorithm for feature selection. The system integrates five pre-trained CNN architectures—GoogleNet, SqueezeNet, ResNet-50, VGGNet-16, and AlexNet—with BFO to optimize feature selection and improve classification performance. The VGGNet-16 + BFO combination achieved the highest accuracy of 98.75%, with excellent sensitivity of 98.72%, specificity of 98.78%, precision of 98.76%, and F1 score of 98.74%, demonstrating highly balanced and reliable performance. The present research shows that the BFO algorithm plays a crucial role in selecting the most significant features and improving classification accuracy compared to conventional techniques. The measures like accuracy, sensitivity, specificity, precision, and F1 score validate the success of the model in correctly predicting faulty PV panels. From the overall performance perspective, BFO performs better than alternative optimization methods such as Gray Wolf Optimization (GWO) and Ant Colony Optimization (ACO). The success of this approach with various CNN models highlights the effectiveness of BFO for accurate PV panel defect identification. The combination of BFO and CNN provides high accuracy and balanced performance in PV panel defect detection, making it a viable solution for improving the efficiency and reliability of solar systems.},
  archive      = {J_IJCIS},
  author       = {Sabati, Asghar and Bayindir, Ramazan and Rahebi, Javad},
  doi          = {10.1007/s44196-025-00984-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Photovoltaic panels fault detection with convolutional neural network and bitterling fish optimization (BFO) algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent recommendation of information resources in university libraries based on fuzzy logic and deep learning. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00993-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {University libraries contain vast information, yet students often struggle to locate relevant resources efficiently to support their academic learning needs. Traditional search and recommendation systems suffer from low personalization and limited handling of vague or uncertain user preferences, reducing their effectiveness in complex educational environments. To address these limitations, this research proposes the Fuzzy Deep Learning-Based Intelligent Library Resource Recommendation Framework (FDLILRRF), which integrates fuzzy logic and deep learning techniques to enhance the accuracy and relevance of information retrieval in university libraries. The research focuses on developing smart systems to retrieve information and recommend educational resources tailored to individual needs. The core problem identified is the inadequacy of keyword-based search engines to deliver personalized and context-aware resource suggestions within large digital library systems. The FDLILRRF framework uses fuzzy logic to handle unclear user input and deep learning to learn from interactions and content, ensuring personalized recommendations. This hybrid approach enables the generation of more accurate and context-sensitive recommendations. Potential applications of this framework include university digital libraries, online learning platforms, and research support systems, offering significant benefits in academic resource discovery and user satisfaction. Experimental evaluation using a student interaction dataset demonstrated that FDLILRRF improved recommendation accuracy by 14.6% over traditional collaborative filtering methods. Enhanced performance in precision and recall metrics further confirms the framework’s effectiveness for real-world educational applications. This research provides an intelligent, adaptive solution to optimize information access in academic library systems.},
  archive      = {J_IJCIS},
  author       = {Yang, Yanfang},
  doi          = {10.1007/s44196-025-00993-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Intelligent recommendation of information resources in university libraries based on fuzzy logic and deep learning},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of a PSO-optimized pythagorean hesitant fuzzy ANFIS model for drought prediction in istanbul. <em>IJCIS</em>, <em>18</em>(1), 1-29. (<a href='https://doi.org/10.1007/s44196-025-00998-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drought is a significant natural disaster that has serious impacts on agriculture, water resource management, and ecosystem health. Therefore, the early prediction of drought is of great importance for implementing timely and effective mitigation measures. In this study, for short-term meteorological drought prediction, an Adaptive Neuro-Pythagorean Hesitant Fuzzy Inference System optimized by Particle Swarm Optimization (ANPHFIS-PSO) method is proposed. The proposed model aims to provide high accuracy in Standardized Precipitation Index (SPI)-1 predictions by effectively handling the nonlinear relationships and uncertainties present in meteorological data. The performance of the model was compared with that of the Multilayer Perceptron Artificial Neural Network (MLP-ANN), Adaptive Neuro-Fuzzy Inference System (ANFIS) optimized via Grid Search (ANFIS-GS), ANFIS optimized by Particle Swarm Optimization (ANFIS-PSO), Long Short-Term Memory network (LSTM) and ANPHFIS optimized by Grid Search (ANPHFIS-GS). For model evaluation, Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Coefficient of Determination (R2) Kling Gupta Efficiency (KGE) and Bias Factor (BF) were used as performance metrics. The obtained results demonstrate that the ANPHFIS-PSO model yields the lowest MSE, RMSE, and MAE values, along with the highest R2 and competitive KGE and BF scores. These findings confirm that the ANPHFIS-PSO model achieves superior predictive performance compared to the other methods.},
  archive      = {J_IJCIS},
  author       = {Saadcı, Yunus Emre and Seker, Sukran},
  doi          = {10.1007/s44196-025-00998-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Development of a PSO-optimized pythagorean hesitant fuzzy ANFIS model for drought prediction in istanbul},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lemur optimized efficient spreading factor allocation of LoRa networks for IoT deployments. <em>IJCIS</em>, <em>18</em>(1), 1-15. (<a href='https://doi.org/10.1007/s44196-025-00947-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LoRa communication has become a cornerstone for Internet of Things (IoT) applications due to its long-range, low-power capabilities which are ideal for remote and rural deployments such as agricultural monitoring. LoRa faces significant challenges, such as network congestion, high latency, and inefficient resource allocation that hinder its scalability and real-time data transmission capabilities. To overcome these issues, a novel enhanced LORA model using lemuR optimization for AllocatIng of SprEading factor (LORA-RAISE) approach has been proposed to enhance communication speed in LoRa. The Lemur Optimization Algorithm (LOA) is employed to optimize spreading factor allocation which improves communication performance, reduces latency, and conserves energy using parameters, such as frequency band, device power, and bandwidth to ensure robust communication. The data are processed through an Ethernet-based system, providing visual insights that facilitate informed decision-making in agriculture. The efficacy of the LORA-RAISE framework is assessed using metrics, such as delay, packet delivery ratio (PDR), throughput, and Energy Consumption (EC). The LORA-RAISE method improves communication performance and decreases latency using the LOA technique. The LORA-RAISE method achieves a throughput of 8.1%, 10.5%, and 4.6% than existing systems, such as the ADR-OWA, LORA-RSSI, and LR-RL, respectively.},
  archive      = {J_IJCIS},
  author       = {SathiaParkavi, J. and Vennila, C.},
  doi          = {10.1007/s44196-025-00947-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Lemur optimized efficient spreading factor allocation of LoRa networks for IoT deployments},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The application of deep learning in user purchase behaviour analysis and marketing decision support. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00954-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User purchase behaviour (UPB) analysis is essential in enhancing marketing strategies on e-commerce platforms. The user purchasing pattern is determined from the product analysis to procurement evaluation, directly influencing business growth. User behaviour is challenging to predict because user requirements frequently change in a dynamic environment. Traditional methods utilize various learning strategies to understand consumer purchasing patterns. However, the existing techniques fail to learn the purchasing patterns from high-dimensionality and overfitting data. The research difficulties are addressed using Deep Generative Adversarial Networks (DGAN), which use the generator and discriminator to observe the purchase pattern. The DGAN model uses the nearest neighbouring integrated data formulation procedure to eliminate the missing data. Then, the normalization and standardization procedure that format and simplify the computation procedure. Finally, consumer profiles are generated to predict and differentiate the false data, improving the overall UPB efficiency with a minimum error rate. The system uses the E-commerce Customer Behaviour Dataset to evaluate system efficiency, and DGAN attains 98.23% accuracy. Thus, the introduced system achieves robustness and scalability and improves user purchase behaviour patterns.},
  archive      = {J_IJCIS},
  author       = {Wang, Zhi},
  doi          = {10.1007/s44196-025-00954-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {The application of deep learning in user purchase behaviour analysis and marketing decision support},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing emotion detection from EEG signals by extracting spatiotemporal features using ConvLSTM networks. <em>IJCIS</em>, <em>18</em>(1), 1-18. (<a href='https://doi.org/10.1007/s44196-025-00964-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion detection is a key factor in good interactions between people in daily routines. Human-Computer Interaction (HCI)-based intelligent systems are required to distinguish the emotional states of subjects. Electroencephalography (EEG) is a more reliable and cost-effective method for measuring brain activity. It makes it possible to comprehend human emotional and cognitive processes. However, emotions are dynamic and include complex relationships among different brain regions throughout time. Different Deep Learning (DL)-based automated HCI systems are able to detect emotions from EEG signals, but the challenge is that little research has been conducted on spatiotemporal feature-based detection. Most of the research has either used Convolutional Neural Networks (CNNs), a spatial model, or Long Short-Term Memory (LSTM), a temporal model, which is unable to detect spatiotemporal information at the same time. This research has introduced a spatiotemporal DL model that integrates CNN and LSTM models to obtain spatiotemporal features from EEG signals. Features are extracted in two ways, i.e., automatic and manual feature extraction. CNN is treated as an automated feature extractor, while manual features are extracted using spatial-temporal and connective feature extractors. An LSTM model is trained on the extracted features, which further extracts temporal features from the EEG data. The proposed methods are evaluated on two benchmark datasets, SJTU Emotion EEG Dataset (SEED) and Database for Emotion Analysis using Physiological Signals (DEAP). The experimental results show enhanced performance compared to recent literature in terms of accuracy, achieving 97.98% and 75.85% in the SEED and DEAP datasets, respectively.},
  archive      = {J_IJCIS},
  author       = {Alluhaidan, Ala Saleh and Bouchelligua, Wided and Rahman, Atta Ur and Ayadi, Manel and Ksibi, Amel and Saqia, Bibi},
  doi          = {10.1007/s44196-025-00964-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing emotion detection from EEG signals by extracting spatiotemporal features using ConvLSTM networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances in mountain gazelle optimizer: A comprehensive study on its classification and applications. <em>IJCIS</em>, <em>18</em>(1), 1-49. (<a href='https://doi.org/10.1007/s44196-025-00968-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Mountain Gazelle Optimizer (MGO) is a newly emerging nature-inspired metaheuristic algorithm based on mountain gazelles' regionally and adaptively directed behavior. It is intended to solve complex optimization problems with an effective balance of exploration and exploitation. The MGO has several benefits: it is scalable, adaptable, parameter-free, capable of multi-objective optimization , and offers real-world application opportunities. The drawbacks of MGO include susceptibility to premature convergence, high computational complexity, and limited scalability to solve higher dimensional problems. The focus of the work is to investigate the development of MGO in the optimization field thoroughly. This review addresses the capabilities and limitations and express its growing relevance across applications. The investigation will refer to 89 studies published on MGO, categorized into four headings: adapted, variants, hybrid, and enhanced, contributing 37, 3, 33, and 27%, respectively, of all studies. This review is to supply researchers and practitioners with a comprehensive overview of potential optimization strategies. The review will compile and synthesize relevant studies to portray potential development opportunities for MGO and practical applications.},
  archive      = {J_IJCIS},
  author       = {Anka, Ferzat and Gharehchopogh, Farhad Soleimanian and Tejani, Ghanshyam G. and Mousavirad, Seyed Jalaleddin},
  doi          = {10.1007/s44196-025-00968-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-49},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Advances in mountain gazelle optimizer: A comprehensive study on its classification and applications},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The two-archive multi-objective grey wolf optimization algorithm for truss structures. <em>IJCIS</em>, <em>18</em>(1), 1-61. (<a href='https://doi.org/10.1007/s44196-025-00972-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is difficult to find optimal solutions to multi-objective optimization problems, because they involve balancing conflicting objectives under complicated constraints. Metaheuristics are widely applied for solving problems, since they are easy to apply and may produce promising near-optimum solutions. However, achieving an optimal balance between exploration and exploitation still remains a key challenge, especially in high-dimensional and constrained design spaces. This research work presents MOGWO2Arc, a new multi-objective optimizer utilizing a dual-archive strategy to promote solution diversity and convergence. Eight benchmark truss structure optimization problems were used to test the suggested algorithm with the objectives of minimizing weight and compliance subject to safe stress levels. Other constraints, such as dimensional constraints, standard safety codes, and unique cross-sectional domains, were also considered. The hypervolume, generational distance, inverted generational distance, and spacing were used as the key parameters to compare performance with eight state-of-the-art optimization algorithms. Based on the outcome of the Friedman rank test, MOGWO2Arc outperformed the competing approaches, especially when utilized to solve large-scale structural optimization problems, producing higher-quality solutions at significantly lower computational costs. MOGWO2Arc also provides a powerful and efficient way to solve complex multi-objective structure optimization problems by promoting exploration and diversifying Pareto-optimal solutions across decision and objective spaces.},
  archive      = {J_IJCIS},
  author       = {Tejani, Ghanshyam G. and Sharma, Sunil Kumar and Mousavirad, Seyed Jalaleddin and Radwan, Abdelrahman},
  doi          = {10.1007/s44196-025-00972-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-61},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {The two-archive multi-objective grey wolf optimization algorithm for truss structures},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust Transformer–Residual hybrid framework with soft thresholding for high-performance image emotion classification. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00974-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of social media has led to a surge in emotional image messages, necessitating advancements in image-affective computing. This field aims to recognize emotional information within images, with emotion classification being a pivotal area of research. However, due to the inherent uncertainty and ambiguity in emotion interpretation, conventional approaches relying on Convolutional Neural Networks (CNNs) often exhibit limited effectiveness. To address these challenges, this study introduces the EmoViTResNet architecture, a novel hybrid framework that synergistically integrates Vision Transformer (ViT) networks with Residual Networks (ResNet). The proposed model enhances deep feature representation by combining global attention mechanisms from ViT with local feature extraction and soft thresholding from ResNet, thereby improving emotion classification performance. Two classification networks, Res-ViT and the more advanced EmoViTResNet, were developed and evaluated across four distinct classification tasks, encompassing both multi-class and binary emotion classification on the FI and EmotionROI datasets. The EmoViTResNet model achieved outstanding accuracy scores of 94.58%, and 92.73%, respectively. These results demonstrate the model’s robustness, improved generalization, and the effectiveness of combining ViT with residual learning for image emotion classification in visual media.},
  archive      = {J_IJCIS},
  author       = {Al-Shamasneh, Ala’a R. and Karim, Faten Khalid and Wang, Yu},
  doi          = {10.1007/s44196-025-00974-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A robust Transformer–Residual hybrid framework with soft thresholding for high-performance image emotion classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Map reduce framework-assisted feature analysis and adaptive multiplicative bi-RNN using big data analytics for decision-making. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00977-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent days, the usage of big data in different applications has improved rapidly, and also, it faces more complications due to enormous data. Generally, big data offers decision-making support to the decision-makers with high accuracy. The growth of communication and data contents is improved effectively according to the speed, velocity, size, and values for providing better knowledge to tackle upcoming complicated tasks and problems. On the other side, multi-criteria-aided decision-making technique is considered to tackle multiple problems presented in big data analysis. To achieve optimal outcomes, an automated model of big data analytics for improving the decision-making is proposed by utilizing the advanced methods. Initially, the big data is gathered from benchmark available sources. Consequently, the essential features are extracted based on the Map Reduce approach, where the features are analyzed by Spatial Incremental Principal Component Analysis (SI-PCA). Especially, in big data analytics, the Bidirectional Recurrent Neural Network (BiRNN) model facilitates increasing the overfitting issues that affects data quality. This issue is rectified by implementing the Adaptive Multiplicative BiRNN (AM-BiRNN) to enable accurate predictions to strengthen the decision-making performance. In the end, the resultant features are given as input to the AM-BiRNN. For further enhancement, the hyperparameters are optimally tuned by Improved Random Function-based Sculptor Optimization Algorithm (IRF-SOA). Finally, the validation of the model is done to achieve the high effective results. When compared with other state-of-the-art techniques, the impressive outcomes proved that the recommended system can provide a better decision-making outcome. Here, the experimental findings of the developed model show 93.15% of accuracy, and 87.09% of sensitivity, respectively.},
  archive      = {J_IJCIS},
  author       = {Verma, Neha and Bhutani, Priyanka and Lalit, Ruchika and Venugopal, Sumanth},
  doi          = {10.1007/s44196-025-00977-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Map reduce framework-assisted feature analysis and adaptive multiplicative bi-RNN using big data analytics for decision-making},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel enhancement of the parrot optimizer: Integrating hierarchical and mimicry behaviors for improved Performance—Case study on business intelligence portfolio optimization. <em>IJCIS</em>, <em>18</em>(1), 1-31. (<a href='https://doi.org/10.1007/s44196-025-00980-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an enhanced version of the Parrot Optimizer (PO), termed the Enhanced Parrot Optimizer (EPO), which integrates hierarchical leadership, mimicry-based behavior, and a weighted behavior selection mechanism to improve convergence behavior and robustness in complex optimization landscapes. The proposed EPO is evaluated through comprehensive benchmark tests, including unimodal, multimodal, and non-convex functions, specifically Sphere, Rosenbrock, and Ackley, as well as a real-world business intelligence (BI) portfolio optimization problem. Experimental results show that EPO consistently outperforms the original PO and other established metaheuristic algorithms, including Harris Hawks Optimization (HHO), Whale Optimization Algorithm (WOA), and Remora Optimization Algorithm (ROA). On the Sphere Function, EPO achieved a mean fitness of 47,200 with a low standard deviation of 1600, outperforming HHO, which obtained a mean of 47,000 with a standard deviation of 2500. In the more challenging Rosenbrock Function, EPO reached the best fitness of 8.42E + 07 and a mean of 1.01E + 08, surpassing the other algorithms in both precision and consistency. For the multimodal Ackley Function, EPO reported the lowest mean fitness of 19.60, with a deviation of 0.19, indicating high robustness and stability. Statistical analysis using the Wilcoxon signed-rank test confirmed the superiority of EPO, with p-values below 10⁻⁸ in most comparisons. Despite the algorithmic enhancements, EPO preserved the computational efficiency, with only a 10 to 12 percent increase in runtime compared to the original PO. Moreover, EPO was used to optimize a real-world BI portfolio case study and scored the Maximum portfolio utility, 92.6, and the extreme individual fitness, 94.21, and had the minimum Maximum average running time of 1.24 s. These results show two things: first, EPO is useful not only in raising average performance but also in raising the quality and reliability of solutions in both synthetic and pragmatic optimization applications.},
  archive      = {J_IJCIS},
  author       = {Deif, Mohanad A. and Elhoseny, Mohamed and Alomoush, Waleed and Hafez, Mohamed A. and Khishe, Mohammad},
  doi          = {10.1007/s44196-025-00980-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel enhancement of the parrot optimizer: Integrating hierarchical and mimicry behaviors for improved Performance—Case study on business intelligence portfolio optimization},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scalable brain tumor diagnosis from large-scale MRI datasets using CNN-ViT and expert-attention fusions. <em>IJCIS</em>, <em>18</em>(1), 1-25. (<a href='https://doi.org/10.1007/s44196-025-00981-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and timely diagnosis of brain tumors is crucial for effective treatment planning, yet the rapid growth of medical imaging data presents significant challenges for manual interpretation. This paper introduces a novel, scalable hybrid deep learning framework designed for robust brain tumor classification from large-scale MRI datasets. Our architecture distinctively combines a Convolutional Neural Network (CNN) for fine-grained local feature extraction with a Vision Transformer (ViT) for modeling global contextual dependencies. To specifically address the challenge of tumor heterogeneity, we introduce a Mixture-of-Experts (MoE) layer that dynamically routes features to specialized subnetworks. Feature representation is further refined by a Multi-Head Latent Attention (MHLA) mechanism, which focuses on the most salient diagnostic information. A key aspect of our methodology is an iterative data-centric refinement strategy to enhance label reliability and reduce intra-class variability in large, potentially noisy datasets. Evaluated on a comprehensive four-class benchmark dataset (glioma, meningioma, pituitary, and no tumor), our model achieves state-of-the-art performance with 98.9% accuracy. This work contributes a scalable, accurate, and more interpretable AI pipeline that directly addresses the complexities of real-world medical big data, demonstrating a clear novelty in its synergistic integration of advanced neural components for a challenging clinical problem.},
  archive      = {J_IJCIS},
  author       = {Yadav, Ram Kumar and Kumar, Manoj and Nandi, Avishek},
  doi          = {10.1007/s44196-025-00981-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A scalable brain tumor diagnosis from large-scale MRI datasets using CNN-ViT and expert-attention fusions},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PharmaNet deep: Real-time pharmaceutical defect detection using defect-guided feature fusion and uncertainty-driven inspection. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-00986-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oral dosage forms are the most widely employed method of drug delivery in therapeutic treatments. However, the presence of visual defects in blister packages can adversely affect the drug's bioavailability and therapeutic efficacy, potentially compromising treatment outcomes. Consequently, detecting tablet defects post-blister packaging in real-time represents a critical challenge in the pharmaceutical industry. Additionally, factors such as blister reflections and limited dataset size hinder the deep learning model's ability to identify defects accurately. To address these challenges, the PharmaNet deep model is developed utilizing a convolutional neural network (CNN) architecture, incorporating defect-guided dynamic feature fusion (DGDFF) in which the fusion process is dynamically guided by potential defect regions, allowing the model to focus on relevant features (defect areas) more efficiently, adaptive deep chain (ADC) which includes occlusion pattern generator (OPG) and residual recursive feature reconstructor (R2FR). The OPG creates multiple views of potential defect regions by systematically dividing features into blocks and creating layered occlusions. At the same time, the R2FR uses gates with ELU activation and residual connections to reconstruct detailed features from these occluded sequences, ultimately enhancing the model's ability to detect subtle defects. The model culminates in an uncertainty-aware detection head that enhances defect prediction reliability by incorporating uncertainty estimates alongside traditional class probabilities and bounding box predictions. This provides a more informed and interpretable decision-making process for pharmaceutical quality control in real-time. Empirical evaluation on the proposed model demonstrates state-of-the-art performance with 99.4% mAP on the PharmaBlister dataset and 97.2% mAP on MVTech AD, with minimal predictive uncertainty, validating its efficacy in pharmaceutical quality control applications.},
  archive      = {J_IJCIS},
  author       = {Vijayakumar, Ajantha and Koilraj, Joseph Abraham Sundar and Rajappa, Muthaiah},
  doi          = {10.1007/s44196-025-00986-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {PharmaNet deep: Real-time pharmaceutical defect detection using defect-guided feature fusion and uncertainty-driven inspection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved deep convolutional neural network for digital art image classification and identification. <em>IJCIS</em>, <em>18</em>(1), 1-17. (<a href='https://doi.org/10.1007/s44196-025-00996-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an enhanced deep convolutional neural network (DCNN) is proposed to address the challenges of accuracy and diversity in digital art image classification. This method significantly improves the feature extraction capability and model generalization performance by introducing an attention mechanism, residual connection and transfer learning. The key improvements include optimized network architecture, use of LeakyReLU activation function and fine-tuning of pre-trained models. Experimental results show that the improved DCNN performs significantly better than traditional DCNN on multiple datasets, especially when processing digital art images with complex styles and abstract forms the classification accuracy and generalization ability are significantly improved. In addition, the model also shows superiority in indicators such as specificity and Cohen's Kappa coefficient, which further verifies the effectiveness of the combination strategy. This enhanced DCNN not only has broad application prospects in the field of digital art but also provides a valuable reference for other image classification tasks.},
  archive      = {J_IJCIS},
  author       = {Zhang, Huidong},
  doi          = {10.1007/s44196-025-00996-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improved deep convolutional neural network for digital art image classification and identification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assimilation of matrix operations with picture fuzzy hypersoft structures for complex decision scenarios. <em>IJCIS</em>, <em>18</em>(1), 1-26. (<a href='https://doi.org/10.1007/s44196-025-00997-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrices are a unifying concept that permeates diverse fields of study and provides a common framework for expressing and solving problems in all fields, including decision-making. In most decision-making scenarios, addressing uncertainty is paramount as real-world scenarios often involve incomplete information, ambiguous data, and unpredictable factors. The aptness of a picture fuzzy hypersoft set as a parameterization tool becomes evident when dealing with the complexities and challenges associated with managing imprecise data. In this article, we have initially developed the notions of the picture fuzzy hypersoft matrices ( $$ {\textbf{P}^{\mathbb{F}\mathbb{H}}}_{\mathbb{S}\mathbb{M}}$$ ) and their basic operations based on the enhanced framework of the picture fuzzy hypersoft set. We then proposed the ideas of fundamental operational principles for picture fuzzy hypersoft numbers based on the structure of picture fuzzy hypersoft matrices. Furthermore, the concepts for picture fuzzy hypersoft geometric aggregation operators have been presented. The application of picture fuzzy hypersoft geometric aggregation operators to energy policy design signifies a bridge between theoretical advancements and practical decision-making. The inclusion of a decision-making approach, explanatory example, and comparative analysis enhances the understanding of how the developed theory can be effectively used and demonstrates its potential contributions to the field of informed decision-making using human intuitionistic data.},
  archive      = {J_IJCIS},
  author       = {Harl, Muhammad Imran and Saeed, Muhammad and Saeed, Muhammad Haris and Habib, Muhammad Salman and Ullah, Mehran},
  doi          = {10.1007/s44196-025-00997-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Assimilation of matrix operations with picture fuzzy hypersoft structures for complex decision scenarios},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on prediction model and optimization of enterprise material procurement management based on global linkage. <em>IJCIS</em>, <em>18</em>(1), 1-22. (<a href='https://doi.org/10.1007/s44196-025-01010-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Against the backdrop of increasing uncertainty in the global supply chain and simultaneous rise in procurement costs and delivery risks for enterprises, the traditional material procurement model is facing severe challenges due to information silos between departments, deviation in demand forecasting, and dynamic changes in supplier relationships; especially in the semiconductor manufacturing industry, high capital investment, long lead times, and high demand volatility can lead to significant capacity losses due to procurement decision-making errors. Therefore, this article constructs an enterprise material procurement management optimization framework based on a global linkage mechanism, aiming to use intelligent means to connect procurement, production, and warehousing data, and achieve multiple goals of cost reduction, quality assurance, and stable supply. The framework includes three technological innovations: ① integrating a Bayesian convolutional neural network and multi-head attention mechanism, using device image features and sensor timing data to predict material remaining life, and reducing the root mean square error of semiconductor key consumables demand prediction to 2.12 × 10⁶ (23.7% lower than LSTM), p < 0.01); ② designing a multi-objective optimization engine that combines the NSGA-II algorithm with a supplier maturity evaluation system that includes six indicators such as timely delivery rate and defect feedback rate to achieve Pareto equilibrium of procurement cost, quality defect rate, and delivery delay rate; the experiment shows that the total procurement cost is reduced by 17.4%, and the supplier complaint rate is reduced to 3.2%; ③ proposing a Global Linkage Rule Set (GLR), which coordinates the data flow of production, warehousing, and procurement through dynamic weights. In the empirical study of semiconductor manufacturing enterprises, it reduces emergency procurement frequency by 42% and increases inventory turnover by 29%. This study provides a reusable methodological framework and validated technical cases for the intelligent transformation of supply chains in capital-intensive industries such as semiconductor manufacturing.},
  archive      = {J_IJCIS},
  author       = {Kang, Meng},
  doi          = {10.1007/s44196-025-01010-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Research on prediction model and optimization of enterprise material procurement management based on global linkage},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and analysis of small-scale hydrogen valleys success factors: A stratified network-based hybrid fuzzy approach. <em>IJCIS</em>, <em>18</em>(1), 1-30. (<a href='https://doi.org/10.1007/s44196-025-01012-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydrogen energy, one of the renewable energy sources, plays a crucial role in combating climate change, since its usage aims to reduce carbon emissions and enhance energy security. As the global energy trend moves toward cleaner alternatives, countries start to adapt their energy strategies. In this transition, hydrogen is one of the energy sources with the potential to increase long-term energy security. Developing countries face challenges, such as high energy import dependency, rising industrial demand, and the need for infrastructure modernization, making hydrogen valleys one of the viable solutions, since they integrate hydrogen production, storage, distribution, and utilization at one facility. However, establishing small-scale hydrogen valleys requires a comprehensive decision-making strategy consisting of technical, financial, environmental, social, and political factors while addressing uncertainties in the system. To systematically manage the process, this study proposes a Z-number-based fuzzy cognitive mapping approach, which models the interdependencies among success factors, supported by Z-number Decision-Making Trial and Evaluation Laboratory for structured prioritization with a multi-expert perspective. The results indicate that Financial Factors emerged as the most critical category, with Government Incentives, Infrastructure Investment Cost, and Land Acquisition Cost ranking as the top three sub-success factors. Availability of Skilled Workforce and Regional Energy Supply followed in importance, which demonstrates the importance of social and technical dimensions in the hydrogen valley development. These findings demonstrate the critical role of policy support, infrastructure readiness, and workforce availability in the design process. Sensitivity analyses are also conducted to present robustness of the given decisions for the analysis of the results. Based on the results and analyses, possible implications based on the policy and practical dimensions are also discussed. By integrating fuzzy logic and Z-numbers, the study aims to minimize loss of information, enhances the analytical background for decision-making, and provides a strategic roadmap for hydrogen valley development.},
  archive      = {J_IJCIS},
  author       = {Karasan, Ali and Akdeniz, Ozge},
  doi          = {10.1007/s44196-025-01012-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Design and analysis of small-scale hydrogen valleys success factors: A stratified network-based hybrid fuzzy approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent decision support system for liver disease diagnosis with MLP network optimized by genetic algorithm. <em>IJCIS</em>, <em>18</em>(1), 1-29. (<a href='https://doi.org/10.1007/s44196-025-01013-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver failure is a common and life-threatening disease, and its early and accurate diagnosis plays a decisive role in improving the treatment process and the quality of life of patients. The complexity of the diagnostic process and the high costs of traditional methods highlight the necessity of utilizing intelligent and efficient systems. In this research, an innovative approach based on a multilayer perceptron (MLP) optimized by a genetic algorithm is presented. First, using principal component analysis (PCA), the data dimensions were reduced, and then the MLP network was trained with weights and biases adjusted by the genetic algorithm (GA). The performance of the proposed system was evaluated on two validated datasets, ILPD and BUPA, in the MATLAB environment and compared with reference methods. The results showed that this system achieved accuracies of 99.55% on the ILPD dataset and 97.85% on the BUPA dataset, demonstrating a significant superiority over previous approaches. This remarkable improvement is due to the optimal tuning of network parameters and can pave the way for the development of a new generation of medical decision support systems with high accuracy and stability.},
  archive      = {J_IJCIS},
  author       = {Farahi, Rasoul and Derakhshanfard, Nahideh and Ghaffari, Ali},
  doi          = {10.1007/s44196-025-01013-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Intelligent decision support system for liver disease diagnosis with MLP network optimized by genetic algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent feature concatenation process-based effective query expansion for patent retrieval approach using optimal bi-clustering and enhanced social engineering optimizer. <em>IJCIS</em>, <em>18</em>(1), 1-24. (<a href='https://doi.org/10.1007/s44196-025-00963-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The major objective of patent retrieval is to identify relevant documents from a large database. Patent retrieval requests often take the form of patent claims, as in prior art searches, and these searches typically require a long time to complete. However, the significant discrepancy between the query and the relevant documents leads to poor retrieval efficiency. Past studies have attempted to resolve these mismatch issues by applying query expansion approaches, which are usually successful in various retrieval tasks. One of the primary challenges in patent retrieval is vocabulary mismatch, which complicates the retrieval process. Nevertheless, it has been found that query expansion methods produce poor results in patent searches. To overcome this challenge, this research proposes an effective patent retrieval approach utilizing query expansion. Here, query expansion is applied to retrieve patents from the provided data. The necessary textual data are collected from multiple sources. The acquired data are then passed through a text pre-processing phase. The pre-processed data are further input to the feature extraction stage, where “Bidirectional Encoder Representations from Transformers (BERT)” and “Generative Pretrained Transformer-3 (GPT-3)” models are used to extract features. Moreover, the features obtained from BERT and GPT-3 are concatenated and fed into an Optimal Bi-Clustering (OBi-C) algorithm for patent retrieval, with parameters tuned using the Enhanced Social Engineering Optimizer (ESEO) to improve performance. Finally, experimental analysis is conducted on the developed patent retrieval system to validate its effectiveness.},
  archive      = {J_IJCIS},
  author       = {Raj, G. David and Mukherjee, Saswati and Robin, C. R. Rene and Jasmine, R. L.},
  doi          = {10.1007/s44196-025-00963-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An intelligent feature concatenation process-based effective query expansion for patent retrieval approach using optimal bi-clustering and enhanced social engineering optimizer},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced frilled lizard optimizer for global optimization and engineering design problems. <em>IJCIS</em>, <em>18</em>(1), 1-61. (<a href='https://doi.org/10.1007/s44196-025-00969-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Enhanced Frilled Lizard Optimizer (EFLO), an improved metaheuristic algorithm based on the recently proposed Frilled Lizard Optimizer. EFLO addresses key limitations, such as premature convergence and limited local exploitation, by incorporating four main enhancements: an adaptive step size sensitive to population diversity, a top-K prey selection mechanism guiding exploration, a dual-vantage tree-climbing strategy for effective exploitation, and a targeted Gaussian local search focused exclusively on optimal solutions. Extensive benchmarking on twelve single-objective IEEE CEC 2022 functions with dimensions (D = 10) and higher dimensional settings (D = 20) demonstrates EFLO’s superior performance. EFLO achieves the lowest mean errors on eleven functions and consistently ranks first overall, significantly outperforming the original FLO and twenty-one recent and state-of-the-art optimizers. Statistical analyses, including the Wilcoxon signed-rank test, confirm EFLO’s significant superiority when compared to benchmark optimizers and recent state-of-the-art algorithms. Practical applicability is further validated on five engineering design problems, where EFLO consistently yields optimal or near-optimal solutions with significantly reduced variability. Notably, EFLO achieves a 9.9% mass reduction in robot gripper design, a 1.0% improvement in spring weight optimization, and achieves solutions very close to theoretical or global optima in cantilever beam, three-bar truss, and welded beam problems. These results highlight EFLO’s robustness and effectiveness in addressing complex, high-dimensional, and engineering design optimization tasks. The source code of EFLO is publicly available at: https://www.mathworks.com/matlabcentral/fileexchange/181623-enhanced-frilled-lizard-optimizer-eflo .},
  archive      = {J_IJCIS},
  author       = {Rodan, Ali},
  doi          = {10.1007/s44196-025-00969-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-61},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced frilled lizard optimizer for global optimization and engineering design problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Small object detection by synchronous attention swin transformer with channel granularity adaptive mechanism. <em>IJCIS</em>, <em>18</em>(1), 1-19. (<a href='https://doi.org/10.1007/s44196-025-00982-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The essence of small object detection is to establish a mapping from the image pixels to the location and classification of targets. It is well known that a few valid pixels and complex backgrounds are the greatest challenges. This is because the intricate mapping cannot be formulated in a small object pixel space while facing a huge disturbance produced by background pixel spaces. To address these issues, this paper proposes a novel small object detection network named synchronous attention granularity Swin Transformer (SAG-ST). A synchronous attention ST block is proposed to elegantly integrate information from deep and shallow features. And the granularity adaptive ST block employs a channel granularity adaptive mechanism to mitigate background interference by adaptively applying self-attention with varying granularities for different channels. Finally, this paper creates a small object detection dataset based on unmanned aerial vehicles with different flight altitudes. The experiments are carried out on the created dataset and VisDrone dataset, and the experimental results show that our SAG-ST algorithm achieves the best detection accuracy.},
  archive      = {J_IJCIS},
  author       = {Wang, Keping and Suo, Bingqian and Qian, Wei and Zhang, Gaopeng and Wang, Tian and Yang, Yi},
  doi          = {10.1007/s44196-025-00982-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Small object detection by synchronous attention swin transformer with channel granularity adaptive mechanism},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-stream convolutional networks for scalable and precise water body mapping from multispectral earth observation imagery. <em>IJCIS</em>, <em>18</em>(1), 1-26. (<a href='https://doi.org/10.1007/s44196-025-00985-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable segmentation of surface water is crucial for monitoring hydrological dynamics, mitigating disaster impacts, and supporting climate-resilient infrastructure development. However, traditional approaches based on spectral indices—such as the Normalized Difference Water Index (NDWI)—often suffer from poor generalization in the presence of spectral ambiguity, seasonal variations, and urban or vegetated interference. Existing deep learning architectures (DeepLabv3+, SegNet) show a trade-off between accuracy and speed, without specific adaptation to the challenges of the domain. This observation justifies the design of a hybrid architecture combining these models to achieve high semantic accuracy, environmental robustness, and computational efficiency. We propose a hybrid deep learning (DL) architecture that integrates two encoder-decoder segmentation frameworks: DeepLabv3+ with residual networks (ResNet18 and ResNet50) and SegNet with Visual Geometry Group (VGG16 and VGG19) backbones. The proposed model seamlessly combines two well-established encoding–decoding architectures, DeepLabv3+ (with ResNet) and SegNet (with VGG), by fusing their segmentation outputs at a decision level to combine the high semantic accuracy of SegNet with the computational efficiency of DeepLabv3+. This hybrid integration thus simultaneously leverages the complementary strengths of both networks to improve the overall quality of water surface segmentation while optimizing training time. This formulation briefly explains that the integration is not limited to a simple choice between models but also involves decision-level fusion or synergistic combination of results, which justifies the term hybrid or dual-stream architecture. These models are optimized for both semantic accuracy and computational efficiency, and trained using multispectral Sentinel-2 satellite imagery sourced from a publicly available Kaggle dataset featuring diverse terrain and spectral complexity. All models were implemented in MATLAB and evaluated using multiple performance metrics: overall accuracy (OA), Intersection over Union (IoU), F1 score, precision, recall, producer accuracy (PA), and user accuracy (UA). Among all configurations, SegNet with VGG16 achieved the best results, delivering An OA of 91%, IoU of 79%, and F1 score of 75%, while effectively minimizing false positives. In contrast, DeepLabv3+ with ResNet18 demonstrated exceptional computational efficiency, completing training in only 95 min with a respectable OA of 78%. These results underscore a clear trade-off between segmentation quality and training speed. Compared to baseline DL architectures and conventional NDWI-based methods, the proposed hybrid framework achieved significant gains in segmentation performance: precision improved by 2.64–22.66%, recall by 1.03–29.87%, and F1 score by 1.33–37.33%, with a 25.31–32.91% increase in IoU and up to 80% reduction in training time. Furthermore, the models proved robust under real-world environmental complexities such as cloud occlusion, seasonal transitions, and mixed urban-land–water boundaries. This research presents a scalable and high-accuracy solution for water body extraction, supporting a range of applications including flood risk assessment, environmental monitoring, and water resource planning. Future work will explore the integration of artificial neural networks (ANNs) for enhanced classification, multimodal data fusion with synthetic aperture radar (SAR) for all-weather operation, and real-time deployment using cloud-based platforms for global water surveillance.},
  archive      = {J_IJCIS},
  author       = {Benali, Abdelali and Kharbouch, Hayet and Krachai, Mohamed Della and Singh, Juginder Pal and Bouddou, Riyadh and Yesma, Bendaha and Belabbes, Abdallah and Husein, Abdalrahman and Salau, Ayodeji Olalekan and Rubanenko, Oleksandr},
  doi          = {10.1007/s44196-025-00985-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Dual-stream convolutional networks for scalable and precise water body mapping from multispectral earth observation imagery},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing network connectivity via fuzzy hub domination. <em>IJCIS</em>, <em>18</em>(1), 1-27. (<a href='https://doi.org/10.1007/s44196-025-00991-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies hub domination and total hub domination in both standard and fuzzy graphs. We determine exact values for principal graph families (paths, cycles, complete graphs, complete bipartite graphs, and wheels) and develop structural bounds that relate hub parameters to classical invariants. On the fuzzy side, we formalize hub domination with vertex and edge memberships, compute the fuzzy hub domination number for standard fuzzy graph classes, and derive degree- and structure-based bounds. We connect these results to applications in telecommunication and transportation networks, where minimizing hub cost aligns with the fuzzy hub domination objective. The findings clarify the mathematical structure of hub domination, situate it among core graph-theoretic measures, and provide implementable bounds and algorithms for design under uncertainty. These contributions offer tools for cost-aware hub placement and resilient connectivity in complex networks modeled by fuzzy graphs.},
  archive      = {J_IJCIS},
  author       = {Ahmed, Haifa and Zeren, Yusuf and Tobaili, Saad and Alameri, Abdu and Alsharafi, Mohammed},
  doi          = {10.1007/s44196-025-00991-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimizing network connectivity via fuzzy hub domination},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive data compression technique using the horse herd optimization algorithm for smart grid data. <em>IJCIS</em>, <em>18</em>(1), 1-31. (<a href='https://doi.org/10.1007/s44196-025-00999-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of smart grid systems has resulted in an exponential increase in data volume. This has led to significant challenges for efficient storage and transmission, thereby necessitating the development of advanced data compression techniques. Traditional techniques often struggle to maintain a balance between compression efficiency and data integrity, particularly when dealing with diverse and large datasets. To address this issue, this paper presents an adaptive data compression algorithm based on discrete wavelet transform (DWT) and Horse Herd Optimization (HHO). The proposed technique significantly improves storage by dynamically optimizing key performance metrics, such as signal-to-noise ratio (SNR), mean square error (MSE), and compression ratio (CR). By employing a robust optimization algorithm, it effectively addresses the computational challenges of processing large-scale and real-time data. This adaptability ensures the algorithm is well-suited for dynamic smart grid environments, providing a scalable and reliable solution to modern data management demands. This technique uses HHO to find the optimal thresholding for smart grid data compression. In general, DWT-based data compression is carried out using a universal threshold for ignoring particular wavelet coefficients. But, the performance of data compression varies for different threshold values. Hence, selecting an optimal threshold is a challenging task for data compression. Therefore, to solve this issue, an effective optimization algorithm is needed. In this work, a Multi-Objective Horse Herd Optimization (MO-HHO) algorithm is proposed to find the optimal threshold. The suggested MO-HHO algorithm accurately determines the global optimum threshold. Hence, it maintains a good compromise between SNR, MSE and CR. The effectiveness of the proposed algorithm is examined using three different data sets. Various datasets from the IEEE Power quality wave data, Household Electric Power Consumption data and Real-time dataset from an experimental set-up were used to test the proposed algorithm. The outcome demonstrates that the suggested MO-HHO algorithm performs better than the other conventional methods.},
  archive      = {J_IJCIS},
  author       = {Selvakumar, Karthika and Ponpandi, Rathika},
  doi          = {10.1007/s44196-025-00999-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An adaptive data compression technique using the horse herd optimization algorithm for smart grid data},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ERP insights and truncated SVD in conjunction with dual-tree complex wavelet transform and multi-view hypergraph neural networks for cognitive distortion analysis. <em>IJCIS</em>, <em>18</em>(1), 1-31. (<a href='https://doi.org/10.1007/s44196-025-01005-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal EEG data analysis requires sophisticated methods for accurate prediction in the critical area of cognitive depression study in neuroscience. With the help of Multi-View Hypergraph Neural Networks (MV-HGNN) and Dual-Tree Complex Wavelet Transform (DT-CWT), a novel framework for enhancing cognitive distortion analysis is provided today. The initial stage of the procedure, DT-CWT, captures EEG signals and extracts the crucial frequency characteristics (gamma, delta, theta, beta, and alpha). Truncated singular value decomposition, or SVD, thereby reduces noise although preserving significant features. To identify task-related cognitive responses, Event-Related Potential (ERP) is used. The data is arranged into a multi-view framework following processing, which records multiple perspectives such as task-specific responses, frequency patterns, and temporal trends. To enable MV-HGNN to recognize complex cognitive patterns, a hypergraph is then constructed to mimic the complex relationships between various viewpoints. The final category predicts cognitive distortion. According on experimental data, the proposed method outperforms traditional deep learning models and delivers improved accuracy. This work shows that integrating multi-resolution feature extraction, dimensionality reduction, and hypergraph learning is effective for EEG-based cognitive distortion analysis.},
  archive      = {J_IJCIS},
  author       = {Banupriya, N. and Subramani, Neelakandan and Prakash, M. and Velmurugan, S.},
  doi          = {10.1007/s44196-025-01005-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {ERP insights and truncated SVD in conjunction with dual-tree complex wavelet transform and multi-view hypergraph neural networks for cognitive distortion analysis},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
