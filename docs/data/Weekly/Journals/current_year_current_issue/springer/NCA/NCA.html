<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca">NCA - 37</h2>
<ul>
<li><details>
<summary>
(2025). Optimized ensemble machine learning cancer classification system for clinical decision-making. <em>NCA</em>, <em>37</em>(29), 24483-24498. (<a href='https://doi.org/10.1007/s00521-025-11599-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical and healthcare informatics research is accelerating at an unprecedented rate due to the growth and accumulation of large volumes of biological and clinical data. There are new opportunities to use big data to uncover new insights and develop creative approaches to improve the quality of cancer treatment. The microarray gene expression profile is used to efficiently and accurately classify cancer cells for clinical decision-making. In this study, a cancer classification system using an optimized ensemble machine learning approach which is based on artificial bee colony (ABC) optimization and an ensemble of machine learning classifiers is proposed as a result of this effort to distinguish between acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML) utilizing microarray gene expression patterns. The relevant cancer features are optimally selected using the ABC technique to improve the performance of the proposed ensemble learning-based classification system. Moreover, the gene expression dataset is balanced using an upsampling technique and an equal number of ALL and AML records have been used for experimentation. The proposed methodology’s accuracy and other performance metrics are looked at, and the suggested model is contrasted to several base machine learning algorithms based on performance criteria to show how useful it is. Furthermore, to demonstrate the importance of the suggested strategy, receiver operating characteristics (ROC) analysis has been performed, and it is seen that the area under the ROC curve of the proposed approach is higher compared to the existing approaches.},
  archive      = {J_NCA},
  author       = {Amma, N. G. Bhuvaneswari and Amma, N. G. Nageswari},
  doi          = {10.1007/s00521-025-11599-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24483-24498},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimized ensemble machine learning cancer classification system for clinical decision-making},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breast cancer classification by converging tumour region probability density and texture feature-based clustering. <em>NCA</em>, <em>37</em>(29), 24461-24481. (<a href='https://doi.org/10.1007/s00521-025-11596-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel technique for the segmentation and classification of regions in breast tumour images by integrating a convergence-based density model, coupled with texture feature-based clustering. The segmentation process starts with an active contour that estimates probability densities for foreground, background, and tumour regions. A key advantage of the proposed method is its independence from an annotated training set. Thus, it reduces sensitivity to dataset variability by using intensity-driven convergence. To address overlapping structures in mammographic images, an edge-path contour-splitting methodology is employed for accurate boundary separation. Finally, a probabilistic neural network (PNN) is used to classify the tumour regions based on texture features. Both qualitative and quantitative results are presented to demonstrate the effectiveness of the proposed method. The proposed method achieves an accuracy of 92%, with a sensitivity of 95.4% and specificity of 94.2%. Performance evaluation with ROC analysis confirms the robustness and diagnostic reliability of the proposed approach in identifying breast tumours.},
  archive      = {J_NCA},
  author       = {Kumari, Bersha and Nandal, Amita and Dhaka, Arvind and Alhudhaif, Adi and Polat, Kemal},
  doi          = {10.1007/s00521-025-11596-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24461-24481},
  shortjournal = {Neural Comput. Appl.},
  title        = {Breast cancer classification by converging tumour region probability density and texture feature-based clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HR-YOLOv8: An innovative model to detect mitosis and identify cancer regions in histopathological images. <em>NCA</em>, <em>37</em>(29), 24441-24460. (<a href='https://doi.org/10.1007/s00521-025-11594-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pathologists use histopathology images to identify breast cancer. Under these circumstances, the identification of mitosis in tissues becomes a potent prognostic marker for breast cancer. Mitosis serves as a vital marker for pinpointing areas of tumor aggressiveness and assessing the probability of disease recurrence. The HR-YOLOv8 model is presented in this paper as a highly accurate way to identify regions of breast cancer and detect mitosis. There are two phases to the study. Through the integration of the HRNet blocks into the YOLOv8 backbone, mitosis is identified in the first stage. The MST algorithm locates the breast cancer region in the second stage. The MST algorithm is employed to merge separate nodes, enabling the identification of cancer regions. HR-YOLOv8 is evaluated on MIDOG21, TUPAC16, and MiDeSeC that datasets are specifically focused on breast cancer, using metrics such as accuracy and F1-score for mitosis detection and AUC, sensitivity, and specificity for breast cancer regions. The results obtained from the study show that the proposed model can identify mitosis and recognize breast cancer regions with high precision.},
  archive      = {J_NCA},
  author       = {Nemati, Nooshin and Samet, Refik},
  doi          = {10.1007/s00521-025-11594-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24441-24460},
  shortjournal = {Neural Comput. Appl.},
  title        = {HR-YOLOv8: An innovative model to detect mitosis and identify cancer regions in histopathological images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for efficient topic modeling. <em>NCA</em>, <em>37</em>(29), 24421-24439. (<a href='https://doi.org/10.1007/s00521-025-11593-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of large language models (LLMs) in research is becoming increasingly prevalent, as they offer advanced capabilities in processing and generating human-like text. However, this advancement comes with a significant trade-off in terms of time and computational costs. In this paper, we demonstrate that analyzing large text datasets with the use of LLMs can be performed efficiently in terms of both time and energy. For this purpose, we utilize the Llama pre-trained model. In more detail, we study the topic modeling task where the goal is to discover and identify topics in large text corpora. The basis of our approach is a hierarchical divisive clustering technique that clusters the data based on their semantic similarity, after employing a Sentence-BERT encoder, pre-trained on a variety of data across different tasks. Then, using an LLM, we identify topics for representative samples from each cluster. Additionally, we introduce a new evaluation method that leverages the capabilities of LLMs to assess the alignment between discovered topics and ground truth labels, providing a robust validation metric. Our findings indicate that it is possible to effectively reduce the computational cost of the topic modeling process compared to the direct application of LLMs and BERTopic, while simultaneously enhancing inference time and overall efficiency, thereby surpassing the current state-of-the-art capabilities of BERTopic.},
  archive      = {J_NCA},
  author       = {Theocharopoulos, Panagiotis C. and Anagnostou, Panagiotis and Georgakopoulos, Spiros V. and Tasoulis, Sotiris K. and Plagianakos, Vassilis P.},
  doi          = {10.1007/s00521-025-11593-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24421-24439},
  shortjournal = {Neural Comput. Appl.},
  title        = {Large language models for efficient topic modeling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplex network-based representation of vision transformers for visual explainability. <em>NCA</em>, <em>37</em>(29), 24385-24420. (<a href='https://doi.org/10.1007/s00521-025-11591-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enormous growth of artificial intelligence (AI), and deep learning (DL) in particular, has led to the widespread use of these systems in a variety of contexts. One DL model capable of addressing complex computer vision tasks is the vision transformer (ViT). Despite its huge success, the reasoning behind the inferences it makes is often unclear, which poses significant challenges in critical scenarios. In this paper, we propose a new approach called MUltiplex Transformer EXplainer (MUTEX), which aims to explain the inferences made by ViTs. MUTEX combines multiplex network-based representations of attention matrices and mask perturbation approaches to provide insight into the inference process of ViTs. By mapping the attention layers of a ViT into a multiplex network, MUTEX is able to analyze the relationships between different parts of the input image and identify the image patches that most influence the inference process. We tested MUTEX on a subset of ImageNet and on BloodMNIST and compared its performance with that of existing visual explainability approaches. In addition, to assess the robustness and adaptability of MUTEX, we conducted a qualitative analysis, along with a hyperparameter and ablation study, which allowed us to further appreciate its potential in visual explainability of ViT.},
  archive      = {J_NCA},
  author       = {Marchetti, Michele and Traini, Davide and Ursino, Domenico and Virgili, Luca},
  doi          = {10.1007/s00521-025-11591-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24385-24420},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiplex network-based representation of vision transformers for visual explainability},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced arrhythmia detection using spiking neural networks: An in-depth analysis of ECG data from the MIMIC-IV clinical database. <em>NCA</em>, <em>37</em>(29), 24365-24384. (<a href='https://doi.org/10.1007/s00521-025-11585-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of electrocardiogram (ECG) signals is essential for detecting arrhythmias such as bradycardia, ventricular tachycardia, and atrial fibrillation. This study utilizes MIMIC-IV-ECG dataset, containing over 800,000 recordings, to assess the effectiveness of spiking neural networks (SNNs) in arrhythmia finding. Various deep learning architectures including hybrid, leaky integrate-and-fire networks, spiking convolutional neural networks (SCNNs), convolutional spiking neural networks, S-RNN, and LSTM-SNN, are trained using key ECG features, with performance enhanced through data augmentation and feature engineering. Our findings identified the innovative SCNN demonstrate outstanding arrhythmia classification ability at a highly to notable 97% accuracy; while hybrid models like norse-hybrid and dense-spike show their own capabilities by incorporating traditional deep learning architectures with the concept of spiking neurons and offer additional performance improvements. These findings highlight the potential of neuromorphic computing for ECG analysis, with future work focusing on real-time processing and clinical scalability.},
  archive      = {J_NCA},
  author       = {Verma, Gunjan and Gocher, Honey and Verma, Sweety},
  doi          = {10.1007/s00521-025-11585-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24365-24384},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced arrhythmia detection using spiking neural networks: An in-depth analysis of ECG data from the MIMIC-IV clinical database},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid algorithm: Long short-term memory-genetic algorithm for optimizing uncertain revenue of wind farms in electricity markets. <em>NCA</em>, <em>37</em>(29), 24345-24364. (<a href='https://doi.org/10.1007/s00521-025-11582-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust hybrid optimization algorithm that combines artificial intelligence with genetic algorithms (GA) to maximize revenue for electricity generation plants, addressing the challenges posed by wind generation uncertainty in liberalized power markets. The novel method leverages the prediction capabilities of the long short-term memory algorithm, a deep learning methodology, to forecast superior genetic traits. These enhanced individuals are then incorporated into the population, accelerating the evolutionary process of the GA and improving its ability to achieve local optimality. The effectiveness of the proposed algorithm is demonstrated through experimental validation of the revenue optimization problem, aiming to increase wind energy utilization by reducing compensation risks related to electricity production fluctuations in the market. The performance of the algorithm in recommending wind power bidding capacity is evaluated using the IEEE 30-bus and 118-bus power system model. Comparative analysis shows that auctioned wind power consumption increased by 12% compared to the traditional GA and by more than 20% compared to the mixed integer linear programming (MILP) method, with a corresponding revenue increase of 7% compared to the MILP scenario. Furthermore, comparison with previous advanced GA research on the optimal power flow problem indicates not only a reduction in the number of generations but also significant savings in computation time; the effectiveness of the approach is confirmed by a more than 22% reduction in the NFFE index (the number of fitness function evaluations).},
  archive      = {J_NCA},
  author       = {Dinh, Ngoc Sang and Dinh, Le Song Binh and Truong, Viet Anh},
  doi          = {10.1007/s00521-025-11582-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24345-24364},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel hybrid algorithm: Long short-term memory-genetic algorithm for optimizing uncertain revenue of wind farms in electricity markets},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adapting artificial rabbit optimization for solving classification problem: Benchmark dataset analysis. <em>NCA</em>, <em>37</em>(29), 24325-24344. (<a href='https://doi.org/10.1007/s00521-025-11572-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, bio-inspired metaheuristic algorithms have been widespread in various application areas due to their straightforward implementation and ability to handle and solve complex problems. Despite the widespread adoption of metaheuristic algorithms, there is a lack of adaptation of the artificial rabbit optimization (ARO) algorithm to solve classification tasks. Specifically, the ARO algorithm has primarily been used for hyperparameter tuning machine learning algorithms or to select the best feature subset within a wrapper feature selection without cooperating in the classification process. This paper has introduced a new direct adaptation of the ARO algorithm for classification tasks. This adaptation was constructed by directly using the ARO algorithm to find the optimal centroids that could solve the classification task. Therefore, the ARO algorithm was shifted directly to the classification task by identifying the optimal centroid for each class label and minimizing the number of misclassified instances in the training data. The proposed direct adaptation of the ARO algorithm for classification tasks was tested and evaluated using eleven benchmark datasets from various domains. We conducted in-depth investigations of the other seven bio-inspired optimization algorithms alongside the ARO algorithm. The accomplished results demonstrated the robustness and effectiveness of the ARO algorithm for solving the classification problem compared to other bio-inspired optimization algorithms. Consequently, by extending ARO to focus on optimal centroid identification, our approach has enhanced the performance of classification tasks, thereby improving the effectiveness of decision-making models.},
  archive      = {J_NCA},
  author       = {Almseidin, Mohammad},
  doi          = {10.1007/s00521-025-11572-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24325-24344},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adapting artificial rabbit optimization for solving classification problem: Benchmark dataset analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient task offloading based on modified elk herd optimizer for minimizing response times in fog-enabled IoT. <em>NCA</em>, <em>37</em>(29), 24303-24323. (<a href='https://doi.org/10.1007/s00521-025-11569-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, fog computing has emerged as a prominent research because of the widespread adoption and continuous advancements in Internet of Things (IoT) technologies. Fog nodes (FNs) offer storage and computational capabilities to resource-constrained IoT devices, enabling them to support IoT applications with high computing needs. Moreover, closeness FNs to IoT devices ensure they meet the latency demands of IoT applications. However, increasing the need to offload the tasks, combined with limited IoT resources, requires to development an efficient task offloading. To address this challenge, a task offloading approach utilizing the modified elk herd optimizer (MEHO) is proposed to assign tasks to FNs. MEHO is designed as an optimization approach aimed at minimizing response time. Comprehensive simulations show that MEHO outperforms other methods under various numbers of FNs, service rate, and rate of arrival data. MEHO achieves a reduction in average response time for maximum tasks by 12%, 16%, 18%, 19%, 26%, and 41% compared to modified sparrow search algorithm, sparrow search algorithm, artificial bee colony optimization, ant colony optimization, particle swarm optimization, and round robin, respectively.},
  archive      = {J_NCA},
  author       = {Alfawaz, Oruba and Khedr, Ahmed M. and Mostafa, Reham R.},
  doi          = {10.1007/s00521-025-11569-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24303-24323},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient task offloading based on modified elk herd optimizer for minimizing response times in fog-enabled IoT},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft computing techniques for predicting thermal conductivity of bentonite–fly ash/-sand composite materials. <em>NCA</em>, <em>37</em>(29), 24281-24301. (<a href='https://doi.org/10.1007/s00521-025-11568-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bentonite–sand/fly ash-based thermal backfill materials are used as a heat transfer medium between the heat sources (e.g., underground power cable) and near-field. The characterization of materials in the laboratory, as a thermal backfill material, often requires extensive field as well as laboratory work, which is quite expensive and time-consuming. Therefore, this paper aims to develop a soft computing (SC) technique to predict the thermal conductivity due to its ability to handle complex, nonlinear and uncertain relationships in soil behavior. To achieve this goal, four SC algorithms, namely artificial neural network (ANN), ANN–PSO (particle swarm optimization), adaptive neural network-based fuzzy inference system (ANFIS) and extreme gradient boosting (XGB), were utilized based on the experimental database considering compaction state and physical properties of backfill as input variables. The performance of different SC techniques was evaluated based on scatter plots, statistical indices, Taylor’s diagrams and rank analysis. The results exhibited that XGB predicts more accurately than ANFIS, ANN and ANN–PSO. Finally, the influence and significance of the input parameters on XGB model performance are highlighted using Shapley additive explanation (SHAP) analysis. The findings demonstrated that the water content, dry density and particle size content had the most significant impact on the thermal conductivity of bentonite–sand/fly ash-based backfill material.},
  archive      = {J_NCA},
  author       = {Bharti, Vishakha and Sah, Pawan Kishor and Kumar, Shiv Shankar and Das, Bhabani Shankar},
  doi          = {10.1007/s00521-025-11568-w},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24281-24301},
  shortjournal = {Neural Comput. Appl.},
  title        = {Soft computing techniques for predicting thermal conductivity of bentonite–fly ash/-sand composite materials},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing monocular depth estimation with an advanced encoder-decoder architecture. <em>NCA</em>, <em>37</em>(29), 24265-24280. (<a href='https://doi.org/10.1007/s00521-025-11566-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant technological advancements have been made in autonomous navigation, impacting various fields such as robotics, autonomous vehicles, and unmanned aerial vehicles. These systems typically use the distances of surrounding objects as input. Monocular depth estimation, which involves estimating depths from a single RGB image, plays a crucial role in this context. In this study, we proposed an encoder-decoder model for monocular depth estimation. Additionally, we introduced a weighted loss function designed to minimize depth image reconstruction errors and penalize distortions in the scene domain of the depth map. The proposed model was evaluated using the NYU Depth V2 dataset, and the results surpassed those of state-of-the-art models on the same dataset. Specifically, our model achieved a validation accuracy of 0.9823, an average relative error (rel) of 0.04713 and a root mean square error (RMSE) of 0.2372, representing significant reductions of 60% and 49%, respectively, compared to contemporary techniques, even with a small training dataset.},
  archive      = {J_NCA},
  author       = {El-Alfy, Yasser and Baroudi, Uthman and Luqman, Hamzah},
  doi          = {10.1007/s00521-025-11566-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24265-24280},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing monocular depth estimation with an advanced encoder-decoder architecture},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ViT-DtC: Vision transformer-based design-to-code framework for code generation from generated UI designs and hand-drawn sketches. <em>NCA</em>, <em>37</em>(29), 24243-24264. (<a href='https://doi.org/10.1007/s00521-025-11565-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code generation in software development from various types of user interface (UI) design images can significantly reduce the manual effort required, accelerate development timelines, and facilitate collaboration between designers and developers. Previous studies have restricted the utilized types of UI designs to either generated UI designs or hand-drawn sketches separately, lacking the automatic detection capability for the design type. Moreover, studies frequently necessitated complex datasets with bounding box annotations and sophisticated computer vision preprocessing steps, especially within the context of hand-drawn sketches. In this paper, we introduce the novel comprehensive Vision Transformer-based Design-to-Code (ViT-DtC) framework, which tackles image classification and code generation from both generated UI designs and hand-drawn sketches by harnessing the capabilities of Vision Transformers. The proposed ViT-DtC undergoes fine-tuning to classify UI designs into specific categories, including web, iOS, Android, and hand-drawn sketches. Subsequently, the design is directed to the appropriate code generator to generate domain-specific language (DSL) tokens for UI elements based on the identified design type. The experimental results exhibited an exceptional proficiency in accurately classifying all designs. Employing a greedy search strategy, the proposed ViT-DtC framework achieved an average accuracy of 97.28% in generating UI elements on the modified web dataset (without capturing their state or color information). In iOS and Android designs, an average accuracy of 82.4% and 81.1% was achieved, respectively. Remarkably, when extended to handle hand-drawn sketches, an average accuracy of 84.8% was maintained.},
  archive      = {J_NCA},
  author       = {Ahmed, Areeg and Azab, Shahira and Moussa, Sherin M. and Abdelhamid, Yasser},
  doi          = {10.1007/s00521-025-11565-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24243-24264},
  shortjournal = {Neural Comput. Appl.},
  title        = {ViT-DtC: Vision transformer-based design-to-code framework for code generation from generated UI designs and hand-drawn sketches},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EWOSCA: An enhanced walrus optimizer-based secure clustering approach for IoT-based WSNs under adversarial contexts. <em>NCA</em>, <em>37</em>(29), 24209-24242. (<a href='https://doi.org/10.1007/s00521-025-11564-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an integral constituent of the Internet of Things (IoT), wireless sensor networks (WSNs) are revolutionizing different aspects of everyday life through intelligent and cost-effective applications. The dual challenges of security and efficiency are the major concerns facing any WSN deployment. Clustering is widely recognized as one of the most effective strategies for enhancing the WSN lifespan. While cluster heads (CHs) serve a pivotal role by managing data aggregation and communication, if CHs are compromised, the integrity of the collected data is lost, posing a significant risk to the network’s reliability and effectiveness. This work proposes an enhanced walrus optimizer-based secure clustering approach (EWOSCA) for IoT-based WSNs under adversarial contexts. An enhanced walrus optimizer (EWO) is developed to address the key shortcomings of the original WO. It incorporates an adaptive inertia weight strategy to better balance exploration and exploitation, a transverse crossover mechanism to tackle premature stagnation by enhancing diversity and generating high-quality solutions, and a colony predation strategy (CPS) to tackle the limited adaptability by dynamically refining the search process using the best-performing solutions. The EWOSCA approach adapts EWO and prioritizes the selection of secure, reliable, and energy-efficient CHs. Furthermore, an Adaptive weighted average function, AwE(), is devised and utilized while designing the fitness function for adapting the algorithm in response to varying network conditions over time. Simulation results reveal that EWOSCA can effectively handle varying rates of malicious or compromised nodes and surpasses recent schemes in terms of effective clustering, energy efficiency, reliability, and overall WSN lifetime.},
  archive      = {J_NCA},
  author       = {Khedr, Ahmed M. and V., Pravija Raj P. and Mostafa, Reham R.},
  doi          = {10.1007/s00521-025-11564-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24209-24242},
  shortjournal = {Neural Comput. Appl.},
  title        = {EWOSCA: An enhanced walrus optimizer-based secure clustering approach for IoT-based WSNs under adversarial contexts},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal MRI data augmentation and attention-based modeling for interpretable brain tumor classification. <em>NCA</em>, <em>37</em>(29), 24191-24207. (<a href='https://doi.org/10.1007/s00521-025-11561-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of brain tumors from MRI images is crucial for guiding treatment planning and improving clinical outcomes. However, current methods face limitations in generalization due to small datasets and lack of interpretability, both critical in medical applications. To address these challenges, we propose a multi-class brain tumor classification system, exploring three distinct models based on VGG19 architecture. These include an attention-module-based model, a deeper convolutional network, and a linear-boosted model. Each model is trained on a large, aggregated dataset with six types of image augmentations to improve generalization. Among the three models, the attention-based model achieves the highest classification performance by focusing on relevant tumor regions. Local interpretable model-agnostic explanations are used to visualize the decision-making process, enhancing model transparency. Our results demonstrate that the attention-based model outperforms baseline and state-of-the-art methods, making it a robust and interpretable solution for brain tumor diagnosis.},
  archive      = {J_NCA},
  author       = {Alanazi, Mubarak A.},
  doi          = {10.1007/s00521-025-11561-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24191-24207},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-modal MRI data augmentation and attention-based modeling for interpretable brain tumor classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing YOLOv9 for automated detection of stroke lesions in brain CT images. <em>NCA</em>, <em>37</em>(29), 24169-24189. (<a href='https://doi.org/10.1007/s00521-025-11560-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prompt detection and accurate localization of stroke-induced cerebral damage in Computed Tomography (CT) scans are essential for optimal treatment and patient prognosis. Traditional techniques significantly depend on the proficiency of radiologists, which can be labor-intensive and susceptible to inaccuracies. This study presents a novel methodology utilizing the YOLOv9 deep learning architecture, termed StrokeYOLO, for the automated detection of stroke lesions in brain CT images. Although YOLOv9 is primarily employed for general object detection, we have modified it to specifically focus on the nuanced characteristics of stroke lesions. Through the modification of anchor boxes, the refinement of feature extraction, and the fine-tuning of the model, we have improved its capacity to accurately identify smaller stroke regions. The proposed model was trained and assessed on a dataset of annotated brain CT scans, exhibiting outstanding efficacy in identifying ischemic and hemorrhagic stroke regions. The detection accuracy was further corroborated against expert annotations, attaining results that were comparable to or superior to traditional methods. Furthermore, we utilized explainable AI methodologies to enhance transparency in the model's decision-making process, thereby promoting trust and clinical implementation. This study emphasizes the capabilities of YOLOv9 as a real-time, automated instrument for facilitating stroke diagnosis while tackling the challenges and prospects of utilizing object detection models in medical imaging. StrokeYOLO attained an accuracy of 98.7%, precision of 99.92%, recall of 99.1%, and F1-measure of 99.51% on the evaluation dataset, surpassing current methodologies. The findings underscore the capability of YOLOv9 as a real-time, automated instrument for facilitating stroke diagnosis while tackling the challenges and prospects of utilizing object detection models in medical imaging.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and Shaban, Warda M.},
  doi          = {10.1007/s00521-025-11560-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24169-24189},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing YOLOv9 for automated detection of stroke lesions in brain CT images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing heart health: An AI-driven analysis of dietary habits, unveiling impacts on human health and attitudes. <em>NCA</em>, <em>37</em>(29), 24149-24167. (<a href='https://doi.org/10.1007/s00521-025-11559-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel deep learning-based approach for analyzing the relationship between eating habits and heart health. The method leverages wearable technology, smartphone applications, and food diaries to gather comprehensive dietary data. This data is then processed by recurrent neural networks (RNNs) and convolutional neural networks (CNNs) to extract significant dietary patterns and features relevant to cardiovascular health. By integrating dietary information with other health-related data, a comprehensive model is constructed to analyze the intricate interactions between lifestyle, nutrition, and cardiovascular outcomes. This approach facilitates the generation of personalized dietary recommendations and enables a more precise and objective evaluation of eating habits. To validate the effectiveness of the proposed methodology, an LSTM model is implemented and achieves a precision of 0.982, indicating a high percentage of true positive predictions. Additionally, the model demonstrates an accuracy of 98.9%, highlighting its ability to classify nearly all instances accurately. These exceptional results suggest the suitability of the modified LSTM model for further investigation and potential real-world implementation.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and ZainEldin, Hanaa and Gamel, Samah A.},
  doi          = {10.1007/s00521-025-11559-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24149-24167},
  shortjournal = {Neural Comput. Appl.},
  title        = {Revolutionizing heart health: An AI-driven analysis of dietary habits, unveiling impacts on human health and attitudes},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting design suitability of box-shaped sustainable timber structural members using machine learning and hyperparameter optimization. <em>NCA</em>, <em>37</em>(29), 24123-24148. (<a href='https://doi.org/10.1007/s00521-025-11556-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The improvement of timber structures is essential for sustainable construction, focusing on enhancing ductility and energy dissipation. While machine learning offers a promising approach to accelerate and simplify the design process for such structures, its application in this field remains underexplored. This study develops digital models of box-shape timber members to assess their suitability for design (TS 647 Building Code for Timber Structures, Türk Standardlari Enstitüsü, Ankara, 1979), considering cross-section, span, loading, screws and material properties. A dataset of 2000 design cases was generated, incorporating variations in these factors based on design calculations in accordance with the relevant standards. After data preprocessing, machine learning (ML) classification algorithms, including Decision Tree (DT), Gaussian Naïve Bayes (GNB), K-Nearest Neighbour (KNN), Linear Discriminant Analysis Classification (LDA), Logistic Regression (LR), Support Vector Machine (SVM) and Voting Ensemble Classification (VEC), were employed to predict design suitability (Fx), where Fx indicates whether the generated design meets structural criteria. The study found that Fx positively correlated with cross-section, span and moment of inertia, while it had a strong negative correlation with moment, stress, shear and deflection. Accuracy scores ranged from 91.7% to 98.6%, with LR performing the best (98.6%), while GNB had the lowest score (91.7%). These results were supported by model performance metrics, namely precision, recall, F1, AUC and MCC scores. Additionally, hyperparameter optimization was applied to improve the performance metrics of the models, resulting in more accurate and reliable predictions. It improved DT, KNN and SVM, while LR, LDA and GNB showed no significant changes. These findings highlight the effectiveness of machine learning in predicting the suitability of timber structure designs, providing a more efficient approach to structural assessment.},
  archive      = {J_NCA},
  author       = {Cosut, Muhammed and Bekdas, Gebrail and Nigdeli, Sinan Melih and Isikdag, Umit},
  doi          = {10.1007/s00521-025-11556-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24123-24148},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting design suitability of box-shaped sustainable timber structural members using machine learning and hyperparameter optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PINNs for solving unsteady maxwell’s equations: Convergence issues and comparative assessment with compact schemes. <em>NCA</em>, <em>37</em>(29), 24103-24122. (<a href='https://doi.org/10.1007/s00521-025-11554-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINNs) have recently gained prominence as a mesh-free, physics-integrated framework for solving partial differential equations. In this work, we evaluate the capabilities of PINNs in solving unsteady Maxwell’s equations, benchmarking their performance against two established numerical schemes: the finite-difference time-domain method and a compact Padé scheme. The investigation spans three canonical test cases, involving one-dimensional free-space wave propagation and two-dimensional Gaussian pulse evolution in both periodic and dielectric media. The convergence enhancement strategies including random Fourier feature embeddings, spatio-temporal periodicity enforcement, and temporal causality constraints are assessed systematically through ablation study. The results suggest that architectural design choices must be closely aligned with the governing physics to ensure stable and accurate convergence. Using Neural Tangent Kernel analysis, the intrinsic “uneven learning” behavior of PINNs is uncovered. It was observed that PINNs can fail to prioritize regions with high error, instead converging more rapidly where the loss is already small, contrary to effective optimization principles. Overall, this study demonstrates that PINNs, with appropriate architecture, can match or surpass numerical solvers in accuracy and flexibility. However, challenges remain in addressing spatial inhomogeneity of convergence rate (uneven learning), adapting training to localized high-gradient features, and computational cost.},
  archive      = {J_NCA},
  author       = {Shaviner, Gal G. and Chandravamsi, Hemanth and Pisnoy, Shimon and Chen, Ziv and Frankel, Steven H.},
  doi          = {10.1007/s00521-025-11554-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24103-24122},
  shortjournal = {Neural Comput. Appl.},
  title        = {PINNs for solving unsteady maxwell’s equations: Convergence issues and comparative assessment with compact schemes},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-based diagnostic model for autism spectrum disorder using blood biomarkers. <em>NCA</em>, <em>37</em>(29), 24075-24102. (<a href='https://doi.org/10.1007/s00521-025-11553-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autistic spectrum disorder (ASD) is a neurological condition characterized by difficulties in social interaction, communication, and repetitive behaviors. Despite its largely hereditary nature, early detection is crucial, and a potential strategy for more efficient and quicker diagnosis is to employ artificial intelligence (AI). In this paper, a new system is introduced that is called automatic screening autism (ASA) system. ASA comprises three primary stages: data preparation (DP), feature selection (FS), and patient detection (PD). In the first stage, the used dataset is preprocessed through several steps: handling missing values and rejecting outliers. Then, these preprocessed features are fed to the FS stage to select the most important features using improved genetic algorithm (IGA). IGA composed of two stages; (i) pre-selection stage (PS2) using information gain (IG) and (ii) conclusive selection stage (CS2) using genetic algorithm (GA). Subsequently, these attributes are input into the proposed classification model using optimized deep neural network (ODNN). Actually, ODNN is based on optimized weights of traditional DNN using various optimization algorithms, and the final decision is derived from the best performance. ASA has been evaluated against contemporary methodologies. Results from experimental studies demonstrate that the proposed ASA outperforms its competitors regarding accuracy, precision, sensitivity, and F-measure, achieving values of approximately 99.10, 98.90, 98.70, and 98.80% in that order.},
  archive      = {J_NCA},
  author       = {Shaban, Warda M.},
  doi          = {10.1007/s00521-025-11553-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24075-24102},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial intelligence-based diagnostic model for autism spectrum disorder using blood biomarkers},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance analysis of PEM fuel cells via puma optimizer with the aid of practical verifications. <em>NCA</em>, <em>37</em>(29), 24051-24074. (<a href='https://doi.org/10.1007/s00521-025-11552-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript presents a novel application of the recently developed Puma Optimizer (PO) for identifying the unknown parameters in Mann’s model, which is widely used for characterizing the behavior of Polymer Electrolyte Membrane Fuel Cells (PEMFCs). The proposed PO-based methodology is rigorously evaluated using three test cases. One test case involves experimental I–V measurements under various operating conditions from a commercial PEMFC stack, the Horizon H-100 (100 W), which was assembled and tested in the laboratory. The other two cases are established benchmark PEMFC systems, the Ballard Mark V 5 kW and BCS 500 W units. Comprehensive statistical analyses over multiple independent runs are performed to confirm the consistency and reliability of the PO-based approach. To evaluate the optimizer’s accuracy and robustness, comparisons are made with three other metaheuristic algorithms: two recently developed methods, the Propagation Search Algorithm (PSA) and the Walrus Optimization Algorithm (WOA), and a widely recognized one, the Slime Mold Optimizer (SMO). The comparisons show that the PO optimizer consistently achieved the lowest total square error (TSE) across all test cases, outperforming the other algorithms. Specifically, it develops the lowest values of 0.835811 for the Ballard Mark V 5 kW, 0.011281 for the BCS 0.5 kW, 0.711452 at 30 °C, 0.886144 at 35 °C, and 2.057015 at 40 °C for the Horizon H-100 fuel cell. These findings confirm that the PO is a reliable and effective tool for parameter estimation in PEMFC modeling under both simulated and real-world experimental conditions.},
  archive      = {J_NCA},
  author       = {Ashraf, Hossam and Abdellatif, Sameh O. and Elkholy, Mahmoud M. and El-Fergany, Attia A.},
  doi          = {10.1007/s00521-025-11552-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24051-24074},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance analysis of PEM fuel cells via puma optimizer with the aid of practical verifications},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving DNNs for time-series classification using state and gradient abstraction-based preprocessing. <em>NCA</em>, <em>37</em>(29), 24025-24049. (<a href='https://doi.org/10.1007/s00521-025-11550-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series classification is important in various domains and tasks, and has attracted meaningful research over the past decades. Recent years have brought meaningful advancements in using deep neural networks (DNNs) architectures to classify time-series. However, challenges due to measurement errors, missing values, and irregular sampling are still a concern. To minimize their impact on the classification performance, various standardization methods are commonly applied to the raw continuous data as a preprocessing stage to the DNN. Instead, we suggest employing temporal abstraction, wherein the raw time-series is converted into a symbolic representation of time points. The transformed data can then be utilized as input for the DNNs. Specifically, we explore the impact of combining temporal abstraction with convolution-based sequence models and recurrent neural networks. To assess the effectiveness of these methods, we conducted evaluations on a total of 128 univariate and 13 multivariate time-series datasets. Through our framework, which incorporates the temporal abstraction process, we significantly enhanced the performance of various state-of-the-art DNNs used for time-series classification tasks. Our evaluation shows that our methods are significantly superior in classification prediction across all seven evaluation metrics for univariate time-series datasets, outperforming in terms of AUC-ROC for multivariate time-series datasets, compared to predictions using standardized raw data.},
  archive      = {J_NCA},
  author       = {Itzhak, Nevo and Tal, Shahar and Cohen, Hadas and Daniel, Osher and Kopylov, Roze and Moskovitch, Robert},
  doi          = {10.1007/s00521-025-11550-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {24025-24049},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving DNNs for time-series classification using state and gradient abstraction-based preprocessing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing cervical cancer detection: A new optimized explainable artificial intelligence model. <em>NCA</em>, <em>37</em>(29), 23979-24023. (<a href='https://doi.org/10.1007/s00521-025-11548-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a classification model for analyzing cervical cancer images, addressing one of the most prevalent cancers among women worldwide. Early detection is crucial for improving recovery rates and reducing mortality. The integration of artificial intelligence (AI) in medical diagnostics has shown promise in cervical cancer screening by enabling faster results, reducing dependency on specialists, and minimizing biases. While AI-based solutions exist, ongoing research aims to enhance accuracy and efficiency. Advancements in deep learning (DL) have facilitated the development of automated frameworks for medical image analysis, including cervical cancer detection. This research proposes a five-phase model: (1) pre-processing the dataset, (2) extracting features using pre-trained models, (3) optimizing feature selection with the Copula Entropy-based Golden Jackal Optimization (CE-based GJO) algorithm, (4) optimizing hyperparameters using the Sea Horse Optimizer (SHO), and (5) employing explainable AI (XAI) to identify key cytomorphological features in classification. The proposed model is trained on the SipakMed dataset, the largest publicly available cervical cancer dataset on Kaggle. Experimental results demonstrate the proposed model’s superior performance, achieving high precision (0.9985), specificity (0.9996), F-measure (0.9985), and accuracy (0.9985). It outperforms leading benchmark studies, highlighting its potential for precise cervical cancer diagnosis. Additionally, the model offers a secure, cost-effective, and efficient AI-driven solution for early detection and screening.},
  archive      = {J_NCA},
  author       = {Abdel-Salam, Mahmoud and Askr, Heba and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-025-11548-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23979-24023},
  shortjournal = {Neural Comput. Appl.},
  title        = {Revolutionizing cervical cancer detection: A new optimized explainable artificial intelligence model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating and benchmarking nutritional supplement providers using a multi-criteria decision-making modeling approach. <em>NCA</em>, <em>37</em>(29), 23941-23978. (<a href='https://doi.org/10.1007/s00521-025-11547-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To determine the adequacy and balance of nutritional supplements for children, a high level of assessment and ranking of available Nutritional Supplement Providers (NSPs) is needed. Inherently, the evaluation of nutritional supplements is complex because it involves (1) different criteria, (2) trade-offs in preferences, and (3) the development of models that require data to be handled in a standardized manner. This study aims to develop a robust decision-making framework for assessing and benchmarking NSPs for children, thereby supporting informed choices in pediatric dietary supplementation. The methodology is developed in three phases. Phase 1: Identifying and collecting the dataset. Phase 2: Develop a decision matrix that includes 28 nutritional criteria, following eight NSPs as alternatives. Phase 3: Integration of mathematical process of 2-Tuple Linguistic q-Rung Picture Fuzzy Level-Based Weight Assessment (2TLq-RPF-LBWA), which offers a rigorous evaluation of the nutritional information for the children’s dietary supplements referred to in this study as Nutritional Information for Kids' Dietary Supplements (NIKDSs), and the Additively Ratio Assessment (ARAS) method helps in benchmarking the NSPs. The results from the 2TLq-RPF-LBWA indicated that the most highly weighted nutrients were 'vitamin D' (0.0545), 'iron' (0.0521), 'vitamin B12' (0.0500), and 'vitamin B9' (folic acid) (0.0480), which were the most highly weighted nutrients, whereas 'chromium' had the lowest weight (0.0245). ARAS benchmarking analysis indicated that "Centrum Kids Chewable Multivitamins" had a rating of 0.7626, ranking it in the top position. The "KINDER Multivitamin Syrup" was second, with a rating of 0.2893; "Maddovit Junior" was third, with a rating of 0.2599; and "OLIGOVIT Syrup" was rated lowest, with a rating of 0.0575. To verify the rigor of the results, three sensitivity analysis scenarios were developed, confirming that the methodology was robust and improved decision-making related to the development of safer, effective vitamin and mineral supplements for children. Overall, this study provides valuable benchmarking information to help parents, professionals, and manufacturers select suitable nutritional supplements for children.},
  archive      = {J_NCA},
  author       = {Habeeb, Mustafa Abdulfattah and Khaleel, Yahya Layth and Albahri, A. S. and Albahri, O. S. and Alamoodi, A. H. and Sharaf, Iman Mohamad},
  doi          = {10.1007/s00521-025-11547-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23941-23978},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluating and benchmarking nutritional supplement providers using a multi-criteria decision-making modeling approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A benchmark study of optimizers for short-term solar PV power forecasting using neural networks under real-world constraints. <em>NCA</em>, <em>37</em>(29), 23909-23939. (<a href='https://doi.org/10.1007/s00521-025-11546-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term photovoltaic (PV) power forecasts are critical for efficient grid balancing, yet training optimizers, often overlooked compared to neural network architectures, significantly influence prediction accuracy and convergence speed. Prior research primarily focuses on adjusting network architectures, typically employing a single optimizer (commonly Adam), thus leaving optimizer selection underexplored, especially under noisy and incomplete real-world PV data. This study systematically benchmarks four optimizers—Adam, Adaptive Gradient (Adagrad), Rectified Adam (RAdam), and Lookahead—across three deep-learning architectures (Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN)-LSTM, and LSTM-Autoencoder) using data from two distinct PV sites. Unlike prior works, we assess optimizer effectiveness across a wide range of conditions, including varying training data lengths, sampling intervals, and missing data patterns (both random and block-wise). Using two real-world PV datasets representing semi-arid and desert climates, we analyze forecasting accuracy, convergence time, and robustness. Our empirical results demonstrate that RAdam consistently outperforms Adam by achieving up to 36% lower forecasting error under noisy and incomplete data conditions, while Lookahead offers up to 40% faster convergence in deep hybrid models. These gains translate into tighter reserve-margin planning and smoother inverter set-points, advancing state-of-the-art PV forecast pipelines. The paper concludes with optimizer-architecture recommendations for practitioners facing latency or compute constraints.},
  archive      = {J_NCA},
  author       = {Dhingra, Saloni and Gruosso, Giambattista and Storti Gajani, Giancarlo},
  doi          = {10.1007/s00521-025-11546-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23909-23939},
  shortjournal = {Neural Comput. Appl.},
  title        = {A benchmark study of optimizers for short-term solar PV power forecasting using neural networks under real-world constraints},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing aviation safety and efficiency: Applying artificial intelligence (AI) to address navigational challenges. <em>NCA</em>, <em>37</em>(29), 23883-23907. (<a href='https://doi.org/10.1007/s00521-025-11544-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision Navigation and Timing systems, integral to air traffic management, primarily rely on the Global Navigation Satellite System (GNSS) for accurate data transmission. However, GNSS signals, particularly those used in Automatic Dependent Surveillance-Broadcast (ADS-B) systems, are susceptible to interference, leading to potential safety risks in aviation. This study presents a novel AI-driven Flight Trajectory Prediction Framework, leveraging machine learning and deep learning techniques to detect and mitigate GNSS signal interference. By training models on ADS-B data, this framework identifies potential interference and evaluates its impact on air traffic. The implementation of this AI-based system enhances the reliability and security of air navigation, significantly reducing human error and elevating overall safety standards in aviation. Experimental results demonstrate the framework’s efficacy in improving navigational accuracy and operational efficiency within modern air traffic control systems.},
  archive      = {J_NCA},
  author       = {Hamza, Alyaa A. and Yosef, Rehan Ahmed and Rahouma, Kamel Hussien},
  doi          = {10.1007/s00521-025-11544-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23883-23907},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing aviation safety and efficiency: Applying artificial intelligence (AI) to address navigational challenges},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing false alarms by identifying depression-mimicking expressions. <em>NCA</em>, <em>37</em>(29), 23863-23882. (<a href='https://doi.org/10.1007/s00521-025-11543-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, people have been using social media platforms to express their feelings and share their mental health struggles openly and anonymously. This surge has motivated many researchers to take advantage of social media as a valuable resource of data to detect severe depression. However, existing approaches have significant limitations as they rely on datasets with a wide disparity between depressive and non-depressive instances, ignoring depression-mimicking expressions (such as stress, anxiety, sadness, sarcasm, and complaints) that are frequently misclassified as severe depression due to their linguistic overlap. This, in turn, leads to false alarms about inaccurate cases of depression, undermining our confidence in the detection system. We present the first study that aims to detect severe depression while simultaneously differentiating it from other depression-mimicking expressions. We curated and annotated a new dataset and refined existing ones to capture these depression-mimicking expressions. We implement and compare the performance of state-of-the-art large language models (LLMs), with RoBERTa emerging as a top-performing model, achieving an AUC of 98.37% on the validation set and 98.53% on the separate test set. Notably, fine-tuning of the models led to an impressive average AUC increase in around 40% over their original baseline versions, significantly enhancing the models’ ability to distinguish severe depression from depression-mimicking expressions. The fine-tuned RoBERTa model generalized well to an external dataset, increasing AUC from 0.65 to 0.97 and significantly reducing false alarms. The significant improvement highlights the effectiveness of fine-tuning LLMs on carefully curated data, reducing false alarms, and boosting the model’s reliability and applicability in practical settings.},
  archive      = {J_NCA},
  author       = {Ghouch, Baraa Abou and Khreich, Wael},
  doi          = {10.1007/s00521-025-11543-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23863-23882},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reducing false alarms by identifying depression-mimicking expressions},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nutriconv: Multitask learning framework for digital dietary tracking trained on EFSA’s pancake dataset. <em>NCA</em>, <em>37</em>(29), 23833-23862. (<a href='https://doi.org/10.1007/s00521-025-11542-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing prevalence of nutrition-related health conditions calls for advanced tools to support reliable and efficient dietary monitoring. This paper presents NutriConv, a lightweight multitask convolutional neural network designed to simultaneously perform food classification and weight estimation from single-item food images. Trained on the institutionally validated PANCAKE dataset from the European Food Safety Authority, NutriConv combines classification and regression objectives within a unified architecture, optimized via a hybrid loss function. While its classification accuracy remains lower than that of specialized single-task models, NutriConv achieves competitive regression performance and offers a practical balance between both tasks. Its compact design enables deployment on resource-constrained platforms such as smartglasses and mobile health devices, expanding its usability in real-world dietary tracking scenarios. Extensive experiments confirm its robustness, including external validation on the Nutrition5K dataset, underscoring the model’s generalizability. This work highlights the potential of multitask learning for integrated, scalable, and accessible AI-based nutrition assessment.},
  archive      = {J_NCA},
  author       = {Junquera, Enol and Rico, Noelia and Díaz, Irene and González, Sonia and Remeseiro, Beatriz},
  doi          = {10.1007/s00521-025-11542-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23833-23862},
  shortjournal = {Neural Comput. Appl.},
  title        = {Nutriconv: Multitask learning framework for digital dietary tracking trained on EFSA’s pancake dataset},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced fault detection and diagnosis in wind turbine systems using canonical variate analysis and reconstruction-based contribution method. <em>NCA</em>, <em>37</em>(29), 23811-23832. (<a href='https://doi.org/10.1007/s00521-025-11541-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection and diagnosis (FDD) is critical for ensuring the performance, safety, and reliability of industrial systems, especially in the expanding wind energy sector. As wind turbine installations continue to increase globally, maintaining operational reliability has become increasingly important due to their complex and nonlinear nature. Traditional FDD methods often underperform in such systems due to challenges in handling high-dimensional, nonlinear data. This paper proposes a robust methodology for fault detection and diagnosis in wind turbines. The proposed approach employs canonical variate analysis (CVA) for fault detection by analyzing multivariate data, and reconstruction-based contribution (RBC) for fault isolation by quantifying the contribution of individual variables. The methodology was validated using benchmark data from a real wind turbine system. The results demonstrate high effectiveness in detecting and diagnosing faults, highlighting the approach’s capability to manage complex, nonlinear systems. Simulation results show that the proposed methodology outperforms traditional techniques such as PCA, PLS, EMPRM, and TPCR achieving higher fault detection rates and improved sensitivity, with detection accuracy exceeding $$95\%$$ across multiple fault scenarios. These findings confirm the successful achievement of the research objectives and represent a significant advancement in enhancing the safety, reliability, and operational performance of wind turbine systems under dynamic conditions.},
  archive      = {J_NCA},
  author       = {Elshenawy, Lamiaa M. and Gafar, Ahmed A. and Awad, Hamdi A.},
  doi          = {10.1007/s00521-025-11541-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23811-23832},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced fault detection and diagnosis in wind turbine systems using canonical variate analysis and reconstruction-based contribution method},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal object detection: An architecture using feature-level fusion and deep learning. <em>NCA</em>, <em>37</em>(29), 23799-23810. (<a href='https://doi.org/10.1007/s00521-025-11521-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is one of the most fundamental problems to tackle in the computer vision research area. Recent advances in multimodal data streams and deep learning architectures have prompted a fast growth in the field of multimodal learning, which brings several advantages over single-modality approaches for object detection, such as improved accuracy, robustness to noise and ambiguity, handling of complex scenarios and adaptability to diverse data. Some of the biggest challenges when implementing a multimodal learning approach are the selection of the fusion strategy, design of processing architecture, modality alignment/synchronization and interpretability of such high-dimensional representations. To address this challenge, we propose a feature-level fusion architecture for object detection based on extracting YOLO features from images, spectral and rhythm features from sound using Mel-frequency cepstral coefficients, and general descriptors from radar modalities that, after timestamp and homography transformation matrix alignment, are combined with an attention mechanism into a single classification network. Preliminary experiments indicate that the proposed architecture can constitute itself as a base pipeline for several different multimodal object detection tasks in real-world applications.},
  archive      = {J_NCA},
  author       = {Silva, Rui and Coelho, Eduardo and Pimenta, Nuno and Durães, Dalila and Alves, Victor and Bandeira, Lourenço and Machado, José and Novais, Paulo and Melo-Pinto, Pedro},
  doi          = {10.1007/s00521-025-11521-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23799-23810},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal object detection: An architecture using feature-level fusion and deep learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive concept-phrase pre-training for generating clinically accurate and interpretable chest X-ray reports. <em>NCA</em>, <em>37</em>(29), 23789-23797. (<a href='https://doi.org/10.1007/s00521-024-10640-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated radiology report generation is an emerging field for improving patient care and alleviating radiologist workload. However, existing methods face a range of challenges such as limited data availability, clinical metric performance, and interpretability. To address these issues, we propose a contrastive concept-phrase pre-training (C2P2) method, which utilizes a phrase-concept grounding task for contrastive learning. C2P2 learns the correspondence between phrases in a report and image concepts by using a phrase classification task to train a multi-label classifier for X-rays and extracting visual concepts of phrases using class activation maps. We then fine-tune a pre-trained BERT model to translate the extracted phrases into reports. Our proposed method outperforms or matches the previous state of the art in clinical efficacy metrics on both internal and external datasets. Moreover, C2P2 leverages more vision language data for pre-training and provides visual explanations of generated phrases.},
  archive      = {J_NCA},
  author       = {Tubaishat, Abdallah and Zia, Tehseen and Windridge, David and Nawaz, Muhammad and Razzaq, Saad},
  doi          = {10.1007/s00521-024-10640-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23789-23797},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contrastive concept-phrase pre-training for generating clinically accurate and interpretable chest X-ray reports},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparing machine learning algorithms for imputation of missing time series in meteorological data. <em>NCA</em>, <em>37</em>(29), 23773-23787. (<a href='https://doi.org/10.1007/s00521-024-10601-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores advanced feedforward neural networks specifically multi-layer perceptron (MLP), long short-term memory (LSTM), and convolutional neural networks (CNNs) as time-series imputation techniques to address the challenge of missing data in analytical contexts. The study evaluates their performance by introducing artificial data gaps of varying durations 3 days, 1 week, and 1 month. The results reveal that all three algorithms (MLP, LSTM, and CNN) exhibit the ability to estimate incomplete data, yet with differing accuracies. LSTM and CNN outperform in filling short-term gaps (3 days and 1 week) with R2 values of 77% and 70% for LSTM, and 58.4% and 69.7% for CNN. MLP also demonstrates effectiveness, achieving accuracies of 74.9% for a 3-day gap and 67.7% for a 1-week gap. Notably, CNN proves the most accurate for monthly data gaps, attaining an R2 value of 70.1%. The findings suggest that the selection of imputation techniques should consider the specific time gap, with CNN highlighted as particularly effective for monthly gaps. In conclusion, this study provides valuable insights for researchers and practitioners engaged in imputing missing data in time-series analysis.},
  archive      = {J_NCA},
  author       = {Boujoudar, Mohamed and El Ydrissi, Massaab and Abraim, Mounir and Bouarfa, Ibtissam and El Alani, Omaima and Ghennioui, Hicham and Bennouna, El Ghali},
  doi          = {10.1007/s00521-024-10601-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23773-23787},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparing machine learning algorithms for imputation of missing time series in meteorological data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of a model for the study and measurement of consciousness in artificial cognitive systems based on the integrated information theory. <em>NCA</em>, <em>37</em>(29), 23739-23771. (<a href='https://doi.org/10.1007/s00521-024-10584-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study and measurement of consciousness in artificial cognitive systems have been subjects of great interest in the fields of artificial intelligence and neuroscience. This article introduces an innovative model based on the integrated information theory (IIT) aimed at addressing this fundamental issue. The IIT, proposed by Giulio Tononi, offers a robust theoretical approach to comprehend consciousness in terms of information and its integration. Our model focuses on identifying and quantifying key aspects of consciousness in artificial systems, including information complexity and the structure of artificial neural connections. We have developed a conceptual framework to assess the “integrity” of information within a system, enabling us to measure consciousness in terms of its capacity to integrate information coherently, setting it apart from other approaches. Through experiments and simulations conducted with a video game using the Go No Go task, we demonstrate how our model can be applied to artificial cognitive systems, allowing for the evaluation of their level of consciousness in different contexts. This approach carries significant implications for the advancement of more advanced and ethical artificial intelligence systems, as it provides a methodology for evaluating and comparing their level of consciousness. Ultimately, our work contributes to the progress in understanding and measuring consciousness in artificial systems, paving the way for future developments in artificial intelligence and computational neuroscience.},
  archive      = {J_NCA},
  author       = {Guerrero, Luz Enith and Arango-López, Jeferson and Castillo, Luis Fernando and Moreira, Fernando},
  doi          = {10.1007/s00521-024-10584-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23739-23771},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of a model for the study and measurement of consciousness in artificial cognitive systems based on the integrated information theory},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid deep learning and machine learning approach for detecting spatial and temporal forgeries in videos. <em>NCA</em>, <em>37</em>(29), 23723-23737. (<a href='https://doi.org/10.1007/s00521-024-10558-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video forgery detection has become increasingly critical due to the rise of sophisticated video manipulation techniques. Traditional methods often struggle to keep up with the ever-evolving sophistication of forgery techniques, necessitating innovative and advanced solutions. In response to this challenge, we propose a hybrid approach that combines deep learning and machine learning techniques. This approach leverages the power of DenseNet121 for excellent spatial feature extraction, utilizes a spatiotemporal autoencoder to capture spatiotemporal dependencies, and employs a gradient boosting machine (GBM) to effectively classify the video clips based on the extracted features. This provides a robust and comprehensive solution for detecting spatial and temporal forgeries in videos. By combining these components, this approach offers a more robust and comprehensive solution for detecting spatial and temporal forgeries in videos. To evaluate our approach, we are using a diverse dataset of videos (VTD and VIFFD) with different forgery scenarios and conducting extensive experiments. The results demonstrate the effectiveness and accuracy of our hybrid approach in detecting spatial and temporal forgeries, surpassing the performance of individual classifiers and traditional methods.},
  archive      = {J_NCA},
  author       = {Singh, Upasana and Rathor, Sandeep and Kumar, Manoj},
  doi          = {10.1007/s00521-024-10558-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23723-23737},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid deep learning and machine learning approach for detecting spatial and temporal forgeries in videos},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integration of causal inference in the DQN sampling process for classical control problems. <em>NCA</em>, <em>37</em>(29), 23709-23721. (<a href='https://doi.org/10.1007/s00521-024-10540-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, causal inference is integrated into deep reinforcement learning to enhance sampling in classical control environments. The problem we’re working on is "classical control," where an agent makes decisions to keep systems balanced. With the help of artificial intelligence and causal inference, we have developed a method that adjusts a deep Q-network’s experience memory by adjusting the priority of transitions. According to the agent’s actions, these priorities are based on the magnitude of causal differences. We have applied our methodology to a reference environment in reinforcement learning. In comparison with a deep Q-network based on conventional random sampling, the results indicate significant improvements in performance and learning efficiency. Our study shows that causal inference can be integrated into the sampling process so that experience transitions can be selected more intelligently, resulting in more effective learning for classical control problems. The study contributes to the convergence between artificial intelligence and causal inference, offering new perspectives for the application of reinforcement learning techniques in real-world applications where precise control is essential.},
  archive      = {J_NCA},
  author       = {Velez Bedoya, Jairo Ivan and Gonzalez Bedia, Manuel and Castillo Ossa, Luis Fernando and Arango Lopez, Jeferson and Moreira, Fernando},
  doi          = {10.1007/s00521-024-10540-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23709-23721},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integration of causal inference in the DQN sampling process for classical control problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Empowering global ethereum price prediction with EtherVoyant: A state-of-the-art time series forecasting model. <em>NCA</em>, <em>37</em>(29), 23707-23708. (<a href='https://doi.org/10.1007/s00521-025-11146-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Islam, Umar and Shah, Babar and Al-Atawi, Abdullah A. and Arnone, Gioia and Abonazel, Mohamed R. and Ali, Ijaz and Moreira, Fernando},
  doi          = {10.1007/s00521-025-11146-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23707-23708},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Empowering global ethereum price prediction with EtherVoyant: A state-of-the-art time series forecasting model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering global ethereum price prediction with EtherVoyant: A state-of-the-art time series forecasting model. <em>NCA</em>, <em>37</em>(29), 23683-23706. (<a href='https://doi.org/10.1007/s00521-024-10169-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ethereum has emerged as a major platform for decentralized apps and smart contracts with the heightened interest in cryptocurrencies in recent years. Investors and market participants in the cryptocurrency space will find it increasingly important to use reliable price prediction models as Ethereum's popularity grows. To better estimate Ethereum prices around the world, we propose "EtherVoyant," a novel hybrid forecasting model that combines the advantages of ARIMA and SARIMA methods. To improve its forecasting abilities, EtherVoyant uses Ethereum price history to train ARIMA and SARIMA components independently before fusing their predictions. With the help of feature engineering and data preparation, we further improve the model so that it can deal with real-world difficulties like missing values and seasonality in the data. We also investigate hyperparameter optimization for the model's best possible performance. We compare EtherVoyant's forecasts against those of the more conventional ARIMA and SARIMA models to determine its efficacy. By providing more precise and trustworthy price forecasts, our trial results suggest that EtherVoyant is superior to the individual models. The importance of this study resides in the fact that it will lead to the creation of a sophisticated time series forecasting model that will be useful to cryptocurrency investors, traders, and decision-makers. We hope that by making EtherVoyant available on a worldwide scale, we will help advance the field of cryptocurrency analytics and encourage wider adoption of blockchain-based assets.},
  archive      = {J_NCA},
  author       = {Islam, Umar and Shah, Babar and Al-Atawi, Abdullah A. and Arnone, Gioia and Abonazel, Mohamed R. and Ali, Ijaz and Moreira, Fernando},
  doi          = {10.1007/s00521-024-10169-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23683-23706},
  shortjournal = {Neural Comput. Appl.},
  title        = {Empowering global ethereum price prediction with EtherVoyant: A state-of-the-art time series forecasting model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering privacy and resilience: A decentralized federated learning approach to cyberbullying detection. <em>NCA</em>, <em>37</em>(29), 23667-23682. (<a href='https://doi.org/10.1007/s00521-024-10148-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a rapidly changing digital world, the rise of cyberbullying has become a pressing issue that calls for creative and flexible solutions to detect and prevent it. To address this urgent need, we introduce a novel method: decentralized federated learning for cyberbullying detection using a ring topology network. Traditional federated learning (FL) paradigms have traditionally relied on centralized servers to manage important operations. However, this centralized model faces complex challenges related to privacy vulnerabilities, fairness disparities, and scalability constraints. Our solution brings about a significant change, embracing decentralization as the foundation of a strong and privacy-focused cyberbullying detection framework. This research represents a significant shift away from centralization, as it relies on distributed clients in a ring topology network to collectively carry out crucial FL tasks. Through the redistribution of these responsibilities and the establishment of direct communication channels between neighboring nodes, our approach successfully avoids the challenges related to central server instability and bias. The ring topology architecture creates a decentralized ecosystem, carefully crafted to prioritize the confidentiality of user data while enhancing the resilience and efficiency of the FL process. Our model architecture for cyberbullying detection is carefully crafted, utilizing the powerful capabilities of GRU, LSTM, BERT, and Word2Vec embedding, along with emotional features. This architectural innovation perfectly aligns with the ring topology FL approach, enabling localized updates, efficient aggregation, and flexible adaptability. It is worth mentioning that the BERT model consistently outperforms its competitors, delivering exceptional results.},
  archive      = {J_NCA},
  author       = {Khan, Umair and Khan, Salabat and Mussiraliyeva, Shynar and Samee, Nagwan Abdel and Alabdulhafith, Maali and Shah, Khalid},
  doi          = {10.1007/s00521-024-10148-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {23667-23682},
  shortjournal = {Neural Comput. Appl.},
  title        = {Empowering privacy and resilience: A decentralized federated learning approach to cyberbullying detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
