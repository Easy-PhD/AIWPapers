<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca">NCA - 48</h2>
<ul>
<li><details>
<summary>
(2025). Discriminating psychological stress levels: Multi-level attentive LSTM approach. <em>NCA</em>, <em>37</em>(30), 25579-25599. (<a href='https://doi.org/10.1007/s00521-025-11608-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this challenging era, psychological stress has become a pervasive issue affecting human well-being. Timely identification of stress, especially through physiological signals such as Electrocardiograms (ECG), is essential for early intervention and effective stress management, as these signals offer objective, real-time insights into autonomic nervous system responses that are closely linked to stress levels. While existing research largely focuses on binary classification (e.g., stressed vs. non-stressed) or multi-level classification restricted to specific domains such as workplace environments or academic settings, there remains a gap in developing a generalized model applicable across diverse real-world conditions. This study introduces a novel Multi-Level Attentive LSTM Network (MALN) for classifying real-world ECG signals into three stress levels: normal, low, and mid. The approach leverages the robustness of deep learning in analyzing complex biomedical time-series data. ECG signals from drivers (a high-stress occupational domain) and graduate students (an academic stress domain) are transformed into time-dependent HRV and spectral sequences to preserve meaningful temporal and frequency-based characteristics. Two attention-guided Bi-directional LSTM modules are designed to extract relevant patterns from these sequences. Their outputs are concatenated and passed through a fully connected layer to distinguish the features into three stress levels. Experimental evaluations conducted on a public drivers’ ECG dataset and a custom-built student ECG dataset show that the proposed model effectively generalizes across distinct domains and outperforms state-of-the-art methods in multi-level stress classification. This work is available at https://github.com/Ramyashri14-0593/Stress-Level-Classification .},
  archive      = {J_NCA},
  author       = {Ramteke, Ramyashri B. and Gajbhiye, Gaurav O. and Thool, Vijaya R.},
  doi          = {10.1007/s00521-025-11608-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25579-25599},
  shortjournal = {Neural Comput. Appl.},
  title        = {Discriminating psychological stress levels: Multi-level attentive LSTM approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling epidemic dynamics: Harnessing the synergy of social media data and mobility patterns during COVID-19. <em>NCA</em>, <em>37</em>(30), 25555-25578. (<a href='https://doi.org/10.1007/s00521-025-11606-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convergence of social media data and mobility patterns presents a unique opportunity to delve deeper into societal behavior and its implications on epidemic dynamics. Social media platforms have become veritable repositories of real-time, user-generated data, reflecting public sentiments, discussions, and perceptions regarding health concerns, including infectious diseases. Concurrently, mobility patterns, derived from transportation usage, geolocation services, and movement data, offer insights into population movements and travel behaviors critical for understanding disease spread. This paper proposes an approach exploiting social media data and mobility patterns to perform epidemic predictions, whose experimental evaluation has been carried out on COVID-19 pandemic data. Leveraging these diverse data sources, we aim to uncover synergies and correlations between online discussions and travel behaviors that can contribute to more accurate and proactive epidemic forecasts. Our central focus lies in discerning the alignment between peaks in social media discussions and corresponding fluctuations in mobility patterns. By identifying and analyzing these alignments, our aim is to clarify their potential as predictive indicators for upcoming epidemic trends. Results obtained from real-world datasets about the city of Chicago (USA) demonstrate the efficacy of the proposed method in predicting the spread of the epidemic accurately. The explainability analysis reveals a significant correlation between tweet content and actual COVID-19 data, affirming Twitter’s credibility as a dependable indicator of epidemic spread. This underscores the growing importance of social media user-generated data as a valuable resource for monitoring and comprehending epidemic outbreaks.},
  archive      = {J_NCA},
  author       = {Cesario, Eugenio and Comito, Carmela},
  doi          = {10.1007/s00521-025-11606-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25555-25578},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unveiling epidemic dynamics: Harnessing the synergy of social media data and mobility patterns during COVID-19},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Brain tumor diagnosis using hybrid quantum-classical neural networks. <em>NCA</em>, <em>37</em>(30), 25535-25554. (<a href='https://doi.org/10.1007/s00521-025-11601-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor classification has become a critical entry point in enhancing the diagnosis and the subsequent management in medical imaging. In an attempt to design an efficient classifier for brain tumors, this study introduces the hybrid quantum-classical neural networks (H-QNNs). The model comprises standard convolutional layers for the extraction of relevant features from input images with a quantum neural network based on ZZFeatureMap with RealAmplitudes Ansatz for enhanced feature identification. MRI images of four tumor classes were assessed in the study, which include glioma, meningioma, pituitary tumor, and no tumor. The proposed framework led to a classification accuracy of 95.58% with precision, recall, and F1-score at 95.58%, significantly surpassing legacy methods. Data imbalance was resolved using data augmentation and weighted cross-entropy loss, while methods such as weight decay were used to increase model resilience. Findings indicate the future application of QML in improving the efficiency of computer-aided image analysis for medical diagnosis and accuracy of classification. Specific strategies mentioned for future work include extending the method to larger datasets and improving quantum components to support additional tasks.},
  archive      = {J_NCA},
  author       = {Ranga, Deepak and Prajapat, Sunil and Kumar, Kranti and Kumar, Pankaj},
  doi          = {10.1007/s00521-025-11601-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25535-25554},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain tumor diagnosis using hybrid quantum-classical neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized deep CNN with rotation-driven features for malaria parasite detection. <em>NCA</em>, <em>37</em>(30), 25515-25534. (<a href='https://doi.org/10.1007/s00521-025-11598-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual microscopic analysis of blood smears for malaria detection is labor-intensive, time-consuming, and prone to human error. To address these limitations, this study proposes a self-supervised learning approach using RotNet, a rotation-based model, to differentiate between healthy and malaria-infected cells. RotNet learns image representations by predicting the rotation angle of input images, eliminating the need for manually labeled data. This method uses synthetic rotation labels to train the model, significantly reducing dependency on human annotations. The core contribution of this work lies in using embeddings and weights from a rotation-based pretext task on unlabeled images to improve classification accuracy in a downstream convolutional neural network (CNN) task. Key highlights include: (1) an efficient and accurate deep learning solution for malaria detection, (2) a novel rotation-based self-supervised strategy, and (3) a practical approach to tackle the scarcity of labeled medical data. The proposed method was tested on the National Institutes of Health (NIH) malaria dataset, achieving a remarkable AUC of 99.8%, surpassing previously reported results. Moreover, similar accuracy was attained using only 10% of the labeled data compared to fully supervised training, highlighting the effectiveness of self-supervised pretraining. Overall, RotNet demonstrates high potential as a robust, scalable, and efficient tool for automated malaria diagnosis.},
  archive      = {J_NCA},
  author       = {Kumar, Sudhakar and Singh, Sunil K. and Mengi, Gopal and Singh, Animesh and Dubey, Arun Kumar and Gupta, Brij B. and Alhalabi, Wadee and Arya, Varsha and Nedjah, Nadia},
  doi          = {10.1007/s00521-025-11598-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25515-25534},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimized deep CNN with rotation-driven features for malaria parasite detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EfficientOvaNet: Efficient deep learning model for multiclass classification of benign ovarian cyst using ultrasound images. <em>NCA</em>, <em>37</em>(30), 25495-25514. (<a href='https://doi.org/10.1007/s00521-025-11589-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ovarian cysts are common conditions in women, potentially leading to infertility, malignancy, or torsion if not identified and treated early. Artificial intelligence (AI) has proven effective in medical imaging; however, most research focuses on distinguishing between benign and malignant cysts. it is equally important to classify specific cyst types to aid in ovarian cancer prevention. This study aims to develop an efficient model to classify seven benign cyst types—Polycystic Ovary Syndrome (PCOS), Serous, Carcinoma, Dermoid, Hemorrhagic, Complex, and Simple cysts using ultrasound images. A novel deep transfer learning model, EfficientOvaNet, was proposed and trained on ultrasound images of ovarian cysts. Diverse data augmentation techniques were applied to address class imbalance issues. The model’s performance was benchmarked against established deep learning architectures, including VGG16, VGG19, ResNet50, DenseNet201, and InceptionV3, using metrics such as accuracy, precision, recall, and F1-score. EfficientOvaNet achieved superior performance across all evaluated metrics, outperforming state-of-the-art models in accurately identifying all seven types of ovarian cysts. The model demonstrated high reliability and robustness, addressing class imbalance effectively and ensuring accurate predictions. EfficientOvaNet offers a promising solution for accurate classification of ovarian cysts, contributing to early diagnosis, improved treatment strategies, and ovarian cancer prevention. This study highlights the model’s potential for real-world applications in medical imaging and its capability to overcome significant challenges such as data imbalance.},
  archive      = {J_NCA},
  author       = {Parekh, Aarti and Desai, Madhavi},
  doi          = {10.1007/s00521-025-11589-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25495-25514},
  shortjournal = {Neural Comput. Appl.},
  title        = {EfficientOvaNet: Efficient deep learning model for multiclass classification of benign ovarian cyst using ultrasound images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Encoding analysis in inhibition response classification using sinc-EEGNet and partial directed coherence. <em>NCA</em>, <em>37</em>(30), 25473-25493. (<a href='https://doi.org/10.1007/s00521-025-11588-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, numerous model networks have been developed and studied to classify the electroencephalogram (EEG) signals and achieve impressive classification accuracy. Despite the advancements in classification accuracy, there is a notable lack of research into understanding how these models interpret and represent the intricate features of EEG signals. Thus, understanding the neural dynamics underlying cognitive control is essential for advancing EEG-based classification models. This study investigates the interpretability of the Sinc-EEGNet model by integrating feature visualization of the spatial filters and Sinc-kernels, as well as partial directed coherence (PDC) analysis, with a specific focus on the destination channels activated during inhibitory processes. The Sinc-EEGNet model was applied to EEG data of twenty healthy subjects doing the Stroop task, a well-known test of cognitive control, to evaluate its ability to inhibit response. The methodology involves training the Sinc-EEGNet model on preprocessed EEG signals with Sinc-based filters and applying feature visualization techniques to understand the model’s output. PDC analysis is then employed to validate the spatial filter activation and identify the neural connections during inhibitory processes. Results demonstrate that the model achieves a classification accuracy of 97%, with clear distinctions in neural activations between subjects. Integrating feature visualization with PDC enhances model interpretability, providing insights into the neural dynamics of inhibitory control and confirming the effectiveness of Sinc-EEGNet in EEG-based classification tasks.},
  archive      = {J_NCA},
  author       = {Sahar, Noor Syazwana and Safri, Norlaili Mat and Izzuddin, Tarmizi and Zakaria, Nor Aini and Kadir, Nurul Ashikin Abdul},
  doi          = {10.1007/s00521-025-11588-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25473-25493},
  shortjournal = {Neural Comput. Appl.},
  title        = {Encoding analysis in inhibition response classification using sinc-EEGNet and partial directed coherence},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Financial asset price prediction with graph neural network-based temporal deep learning models. <em>NCA</em>, <em>37</em>(30), 25445-25471. (<a href='https://doi.org/10.1007/s00521-025-11586-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Changes in the prices of multiple financial assets over time can be characterized by their complex nature and interdependence. More traditional forecasting approaches may overlook the interdependencies among these assets, since they may not fully consider the spatial-temporal dependencies between them. Graph neural networks (GNNs) have emerged as powerful tools for modeling complex relational dependencies in areas such as social network analysis and traffic forecasting. However, their application in asset price prediction remains relatively unexplored. Here, we investigate GNNs’ effectiveness in forecasting multiple financial asset prices jointly, specifically in the foreign exchange (Forex) and cryptocurrency markets. We employ three spatio-temporal GNN frameworks-MTGNN, StemGNN, and FourierGNN-which are all recognized for their state-of-the-art performance in forecasting multivariate time series. These models transform time-series data into graphs and capture both spatial and temporal dependencies. They significantly outperform the baseline methods, including LSTM, ARIMA, and VAR, in predicting financial asset prices in the highly volatile cryptocurrency market. While the performance gap is less obvious in the relatively stable Forex market, GNN-based models still demonstrate a general advantage over LSTM, although they are outperformed by ARIMA. Through a series of experiments and backtesting strategies, we assess the predictive power and profitability of these models in portfolio construction. Our code and datasets are publicly available at https://github.com/seferlab/temporal gnn .},
  archive      = {J_NCA},
  author       = {Uygun, Yasin and Sefer, Emre},
  doi          = {10.1007/s00521-025-11586-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25445-25471},
  shortjournal = {Neural Comput. Appl.},
  title        = {Financial asset price prediction with graph neural network-based temporal deep learning models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel metaheuristic algorithm inspired by tree pruning for solving benchmark optimization and engineering design problems. <em>NCA</em>, <em>37</em>(30), 25415-25443. (<a href='https://doi.org/10.1007/s00521-025-11584-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the large number of metaheuristic algorithms developed for solving optimization problems, nature-inspired algorithms still face challenges such as premature convergence, getting trapped in local optima, and failing to maintain a proper balance between exploration and exploitation. This study aims to develop a robust optimization algorithm that addresses these limitations by maintaining an effective balance between global exploration and local exploitation, thereby improving convergence toward optimal solutions. In this paper, the tree pruning optimization (TPO) algorithm is proposed, inspired by arborists' tree pruning methods. TPO begins by removing dead or diseased branches and then selects the best leader by eliminating competing leaders. The removal of weaker and suckering branches represents the exploration phase, while selecting a dominant leader and removing other competing branches represents the exploitation phase. These two phases are controlled using a random variable. Elitism and a crossover operator are employed to select the best branches for the next iteration. To evaluate the proposed TPO algorithm, benchmark suites from CEC2019 (10 functions) and CEC2022 (12 functions) were used, comparing TPO against nine well-known and competitive optimization algorithms. TPO outperformed all compared algorithms individually in at least 7 out of 10 functions in CEC2019 and 8 out of 12 functions in CEC2022. It achieved strong average ranking scores of 1.8 and 1.4, respectively. Statistical analyses confirmed the superior performance of TPO in most cases, supported by p values (p < 0.05) and boxplot visualizations. Furthermore, TPO demonstrated its effectiveness on real-world engineering problems. It achieved the best results and ranked first in solving the speed reducer design, tension/compression spring design, and welded beam design problems, outperforming all competitors in terms of minimizing cost and satisfying constraints.},
  archive      = {J_NCA},
  author       = {Mohammed, Hardi M.},
  doi          = {10.1007/s00521-025-11584-w},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25415-25443},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel metaheuristic algorithm inspired by tree pruning for solving benchmark optimization and engineering design problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MindfulLIME: A stable solution for explanations of machine learning models with enhanced localization precision—a medical image case study. <em>NCA</em>, <em>37</em>(30), 25387-25413. (<a href='https://doi.org/10.1007/s00521-025-11583-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring transparency in machine learning decisions is critically important, especially in sensitive sectors such as healthcare, finance, and justice. Despite this, some popular explainable algorithms, such as Local Interpretable Model-agnostic Explanations (LIME), often produce unstable explanations due to the random generation of perturbed samples. Random perturbation introduces small changes or noise to modified instances of the original data, leading to inconsistent explanations. Even slight variations in the generated samples significantly affect the explanations provided by such models, undermining trust and hindering the adoption of interpretable models. To address this challenge, we propose MindfulLIME, a novel algorithm that intelligently generates purposive samples using a graph-based pruning algorithm and uncertainty sampling. MindfulLIME substantially improves the consistency of visual explanations compared to random sampling approaches. Our experimental evaluation, conducted on a widely recognized chest X-ray dataset, confirms MindfulLIME’s stability with a 100% success rate in delivering reliable explanations under identical conditions. Additionally, MindfulLIME improves the localization precision of visual explanations by reducing the distance between the generated explanations and the actual local annotations compared to LIME. We also performed comprehensive experiments considering various segmentation algorithms and sample numbers, focusing on stability, quality, and efficiency. The results demonstrate the outstanding performance of MindfulLIME across different segmentation settings, generating fewer high-quality samples within a reasonable processing time. By addressing the stability limitations of LIME in the context of image data, MindfulLIME notably contributes to enhancing the trustworthiness and interpretability of machine learning models applied to specific medical images, which is a critical application.},
  archive      = {J_NCA},
  author       = {Rahimiaghdam, Shakiba and Alemdar, Hande},
  doi          = {10.1007/s00521-025-11583-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25387-25413},
  shortjournal = {Neural Comput. Appl.},
  title        = {MindfulLIME: A stable solution for explanations of machine learning models with enhanced localization precision—a medical image case study},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing algorithmic trading with wavelet-based deep reinforcement learning: A multi-indicator approach. <em>NCA</em>, <em>37</em>(30), 25339-25385. (<a href='https://doi.org/10.1007/s00521-025-11581-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research investigates wavelet-enhanced deep reinforcement learning (DRL) for trading S&P 500 futures, assessing four wavelet families (Daubechies, Symlets, Coiflets, and Biorthogonal) in conjunction with three DRL algorithms (PPO, A2C, and DQN). We employ level-2 decomposition utilizing conservative soft thresholding on market microstructure indicators (DIX, GEX, VIX), enhancing signal-to-noise ratios by 25–41 dB. The coif4+DQN combination yields the most robust outcomes (Sharpe ratio: 0.96; total return: 112.5%), while A2C+db1 and PPO+db4 attain Sharpe ratios of 0.803 and 0.801, respectively. In comparison with XGBoost, random forest, and Logistic regression, wavelet-DRL attains a 35–70% superior Sharpe ratio and reduces maximum drawdowns (0.28–0.34 vs. 0.39–0.42). Feature-set analysis reveals that DIX, GEX, and VIX combined surpass single-indicator configurations by 18.7% in Sharpe ratio. Statistical analyses validate the robustness, revealing that 82.1% of maximum drawdown (MDD) and 67.9% of Sharpe ratio comparisons are significant at the 5% level. Our findings support a gradual implementation strategy—transitioning from A2C+db1 to DQN+coif4—to enhance institutional algorithmic trading efficacy.},
  archive      = {J_NCA},
  author       = {Casares, Antonio José Martínez},
  doi          = {10.1007/s00521-025-11581-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25339-25385},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing algorithmic trading with wavelet-based deep reinforcement learning: A multi-indicator approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative study of neural ordinary differential equations and neural operators for modeling temporal dynamics. <em>NCA</em>, <em>37</em>(30), 25319-25338. (<a href='https://doi.org/10.1007/s00521-025-11580-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing the dynamics of relational systems is a key challenge in the natural sciences, with applications ranging from simulating molecular interactions to analyzing particle mechanics. Machine learning approaches have made significant progress in this area by using graph neural networks to learn and visualize spatial interactions effectively. Neural ordinary differential equations (Neural ODEs) and neural operators (NO) represent two distinct paradigms. However, a clear comparative understanding of when to prefer one over the other is still lacking. To address this gap, we present the first systematic comparison between two representative architectures: EGNO (Equivariant Graph Neural Operator) and SEGNO (Second-order Equivariant Graph Neural Ordinary Differential Equation). Through a series of experiments, we investigate their strengths and limitations in various simulation scenarios in the multi-step trajectory prediction tasks. Specifically, we employ rollout strategies and different input/output configurations, including multiple and irregularly sampled time steps. Our findings highlight a key trade-off between precision and stability that is central to model selection. SEGNO demonstrates superior robustness and stability over long prediction horizons, making it well-suited for tasks requiring reliable long-term forecasting. Conversely, EGNO offers higher precision during early stages of the trajectory and better leverages diverse training configurations, thanks to its discretization-invariant design. In summary, Neural Operators (EGNO) are preferable when short-term accuracy and data efficiency are critical, while Neural ODEs (SEGNO) are advantageous for scenarios demanding stable long-term predictions. This work not only clarifies the practical advantages of each approach but also lays the groundwork for informed model selection and future hybrid strategies in dynamical system modeling.},
  archive      = {J_NCA},
  author       = {Celia, Matteo and Monaco, Simone and Apiletti, Daniele},
  doi          = {10.1007/s00521-025-11580-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25319-25338},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comparative study of neural ordinary differential equations and neural operators for modeling temporal dynamics},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bioinspired optimization on controlled anthropomorphic manipulator robots. <em>NCA</em>, <em>37</em>(30), 25283-25317. (<a href='https://doi.org/10.1007/s00521-025-11579-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bioinspired optimization algorithms, derived from biological processes such as bacterial foraging and swarm behavior, have shown increasing potential in addressing high-dimensional, nonlinear, and time-varying problems in engineering. Their integration into robotic control architectures enables the development of adaptive, model-flexible schemes that are robust to uncertainty and real-time constraints. Anthropomorphic manipulator robots, widely used in manufacturing and medical applications, require high-performance motion control under structural uncertainty, dynamic perturbations, and limited sensing. This paper proposes a unified and robust control scheme that integrates three key components: (i) a bacterial foraging optimization algorithm for offline initialization of controller weights, (ii) B-spline artificial neural networks for online adjustment of adaptive control gains, and (iii) a robust motion control law based on integral reconstruction theory, which eliminates the need for velocity measurement or full dynamic models and avoids high-gain compensation. This architecture overcomes several limitations of classical model-based, PID, or adaptive-only approaches by combining learning, compensation, and optimization within a scalable framework. The proposed method is validated through multiple simulation studies involving anthropomorphic manipulators with documented physical parameters and subjected to varying disturbances. Comparative analysis demonstrates superior tracking precision, reduced control effort, and faster convergence dynamics. These results confirm the practical viability of the proposed framework for motion control in dynamically uncertain robotic platforms.},
  archive      = {J_NCA},
  author       = {Galvan-Perez, Daniel and Beltran-Carbajal, Francisco and Yañez-Badillo, Hugo and Rivas-Cambero, Ivan and Gabbar, Hossam A. and Tapia-Olvera, Ruben},
  doi          = {10.1007/s00521-025-11579-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25283-25317},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bioinspired optimization on controlled anthropomorphic manipulator robots},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EV charging duration prediction using advanced ensemble learning techniques and feature importance analysis. <em>NCA</em>, <em>37</em>(30), 25257-25281. (<a href='https://doi.org/10.1007/s00521-025-11576-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sudden growth in electric vehicle (EV) usage has highlighted the need for advanced and efficient charging infrastructure. This research applies sophisticated ensemble learning models to actual charging session data and proposes a data-based approach to estimating the EV charging duration. The dataset comprises features like battery specs, charging session parameters, arrival and departure times, energy consumed, and temporal variables derived from departure time (hour, day of the week, month). Further extensive preprocessing was undertaken to treat the outliers, especially those from heavy-duty EVs, and to derive more helpful features such as the State of Charge (SOC) differential and charging ratio. The goal of this paper was to predict the charging duration, measured in minutes, using ensembles of algorithm frameworks: XGBoost, LightGBM, CatBoost, and Random Forest. Feature importance analysis was undertaken to evaluate the contribution of each variable to the prediction. In its best run, with an R2 of 0.90, an RMSE of 5.49, and a MAPE of 11.05%, XGBoost achieved the best performance, beating all the other models. This demonstrates the capability of ensemble methods in learning and simulating the EV charging behavior and thereby benefiting the management of charging stations. The study also provides some valuable insights into consumption patterns and possible congestion timings that can aid in better infrastructure planning and user experience.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and Salem, Mohamed and Hamza, Alyaa A.},
  doi          = {10.1007/s00521-025-11576-w},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25257-25281},
  shortjournal = {Neural Comput. Appl.},
  title        = {EV charging duration prediction using advanced ensemble learning techniques and feature importance analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for house pricing: Evaluating categorical encoders and price correction indexes on real transaction data. <em>NCA</em>, <em>37</em>(30), 25229-25256. (<a href='https://doi.org/10.1007/s00521-025-11575-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real estate market is highly influenced by heterogeneous and subjective factors, making property pricing a challenging problem for predictive modeling. This study aims to evaluate the performance of machine learning (ML) models in predicting residential property sales values, focusing on the effect of categorical variable encoding and real estate price correction indexes. A dataset of 306 properties sold in Juiz de Fora, Brazil, was collected from real estate companies and brokers, including physical and locational attributes. Two algorithms were compared—Extreme Gradient Boosting (XGBoost) and Artificial Neural Networks (ANN), using tenfold cross-validation —combined with four encoders (Label, One Hot, Target, and James–Stein) and four Brazilian price correction indexes (IPCA, IGP-M, INCC, and FipeZAP). The R2 varied from 0.44 to 0.72, with the best results being achieved by the XGBoost model, the Target encoder, and the configuration without price correction (using month and year of sale as input, not any correction index). This result indicates that the ML algorithm can better overcome the temporality issue than generic/national inflation indexes. Feature importance analysis revealed that the number of bathrooms, property area, and number of rooms were the most influential variables. The study highlights that real transaction data combined with appropriate categorical encoding can significantly improve predictive accuracy, while public price indexes may not necessarily enhance performance due to regional and methodological differences. These findings contribute to data-driven property valuation, offering methodological insights for both researchers and practitioners.},
  archive      = {J_NCA},
  author       = {Pita, Romário Parreira and Carvalho, Aldo Ribeiro de and Castro, Júlia Assumpção de and Paixão, Rafael Christian Fonseca de and Cury, Alexandre Abrahão and Mendes, Julia Castro},
  doi          = {10.1007/s00521-025-11575-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25229-25256},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning for house pricing: Evaluating categorical encoders and price correction indexes on real transaction data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved transformer-based approach for industrial micro-object defect detection. <em>NCA</em>, <em>37</em>(30), 25201-25228. (<a href='https://doi.org/10.1007/s00521-025-11573-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-precision manufacturing, detecting small and complex defects is crucial for ensuring product quality and production efficiency. Industrial micro-defect detection is especially important in the mass production of micro-parts. Traditional methods struggle with accuracy and speed due to the small size, complexity, and high density of the targets. To address these challenges, this paper proposes a transformer-based method using glass beads as a case study, named Glass Bead Detection with Transformers (GLB-DETR). First, a partially convolutional feature extraction network is designed to improve detection accuracy for small targets while reducing model complexity. Next, an optimized hybrid encoder module is introduced to enhance cross-scale feature fusion and real-time detection efficiency. Finally, an improved shape intersection-over-union loss function is applied to improve localization accuracy for small targets. Experimental results show that GLB-DETR outperforms the Real-Time Detection Transformer and You Only Look Once models in both accuracy and real-time performance. Specifically, the mean Average Precision has improved by at least 3.06%, the number of model parameters has been reduced by at least 18.1%, and the detection speed has increased by at least 1.06%. The method also demonstrates strong generalization ability on public datasets, further validating its effectiveness and superiority.},
  archive      = {J_NCA},
  author       = {Gao, Shan and Wang, YuMeng and Ma, ZongFang},
  doi          = {10.1007/s00521-025-11573-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25201-25228},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved transformer-based approach for industrial micro-object defect detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmentation of microscopic images of dermatophytes in clinical samples using ResNet and attention-based modifications of U-net. <em>NCA</em>, <em>37</em>(30), 25183-25199. (<a href='https://doi.org/10.1007/s00521-025-11571-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct microscopic images of dermatophytes face the challenge of distracting artifacts such as cell debris from skin preparations, air bubbles, cellulose fibers, and also blurred images arising from out-of-focus areas, all of which make the diagnosis at the clinics cumbersome. Automated detection will be the preferred choice under such situations. Work in the area of semantic segmentation of dermatophytes has not yet been attempted, while a few attempts have been reported on the object detection and classification aspects. Our work focusses on the modification of the popular and efficient U-Net architecture with the introduction of residual, squeeze and excitation (SE), and attention-gating modules. A hybrid of weighted binary cross-entropy and dice loss functions was also used to obviate the imbalanced pixel class distribution. The dataset included images captured with 10 $$\times$$ and 40 $$\times$$ objective lenses. Significant increase has been progressively noticed in dice score with an appreciable improvement of about 8% and 13% in 10 $$\times$$ and 40 $$\times$$ magnifications, respectively. Qualitative performance evaluation conducted using heatmaps and predicted images permitted visual verification of the progress made. All the metrics evaluated gave satisfactory values which indicated better performance of the proposed model over the compared architectures.},
  archive      = {J_NCA},
  author       = {Rajitha, K. V. and Krishnamoorthy, Anusha and Prakash, P. Y. and Govindan, Sreejith and Rao, Raghavendra and Prasad, Keerthana},
  doi          = {10.1007/s00521-025-11571-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25183-25199},
  shortjournal = {Neural Comput. Appl.},
  title        = {Segmentation of microscopic images of dermatophytes in clinical samples using ResNet and attention-based modifications of U-net},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TD-CLNet: A time-distributed CNN-LSTM network for fault detection in belt conveyor idlers. <em>NCA</em>, <em>37</em>(30), 25151-25181. (<a href='https://doi.org/10.1007/s00521-025-11570-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection in belt conveyor idlers is crucial for minimising downtime and reducing maintenance costs in industrial operations. Traditional methods, like vibration or temperature-based monitoring, face limitations, including challenging sensor installation and restricted data accessibility. Moreover, these approaches often emphasise spatial features, neglecting the temporal dynamics essential for understanding idler performance over time. This study introduces TD-CLNet, a hybrid fault detection framework that leverages acoustic signals captured via contactless microphones processed through a Time-Distributed CNN-LSTM architecture. The model combines the spatial feature extraction capabilities of Convolutional Neural Networks (CNNs) with the temporal sequence modelling strengths of Long Short-Term Memory (LSTM) networks. A key innovation is the use of the Time-Distributed layer, which enables consistent feature extraction across individual log-Mel spectrogram frames while preserving their temporal relationships. This ensures a robust and coordinated learning process, efficiently addressing the challenges of detecting complementary and relevant features. The performance of TD-CLNet is compared to a frame-based feature extraction approach, which treats each log-Mel spectrogram frame as an independent sample, as well as traditional machine learning methods. Results demonstrate that TD-CLNet achieves a test accuracy of 92% on real-world idler data using K-fold cross-validation, significantly outperforming competing methods. This research provides a scalable and effective solution for fault detection in belt conveyor idlers, advancing predictive maintenance strategies, improving operational efficiency, and minimising unplanned downtime in industrial environments.},
  archive      = {J_NCA},
  author       = {Alharbi, Fahad and Luo, Suhuai and Yang, Guang},
  doi          = {10.1007/s00521-025-11570-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25151-25181},
  shortjournal = {Neural Comput. Appl.},
  title        = {TD-CLNet: A time-distributed CNN-LSTM network for fault detection in belt conveyor idlers},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale residual attention model for retinal image feature segmentation: Toward chemical exposure detection. <em>NCA</em>, <em>37</em>(30), 25123-25149. (<a href='https://doi.org/10.1007/s00521-025-11567-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel methodology for detecting chemical-induced retinal damage through fundus imaging by leveraging the correlation between retinal abnormalities and chemical exposures. Fundus imaging, a noninvasive and cost-efficient diagnostic modality, is extensively used for detecting ophthalmic and systemic conditions. Pathological manifestations commonly include vascular abnormalities in blood vessels, optic disk deformities, and lesions such as hemorrhages and exudates. Accurate identification and segmentation of these features are crucial for clinically evaluating ocular anomalies. Many pathological conditions share similar manifestations associated with chemical exposure, common to well-known retinal diseases. This paper introduces a multi-scale residual attention U-Net model for retinal feature segmentation and comprehensively maps retinal abnormalities to chemical exposure. To capture broader contextual information, dilated convolutions with layer-specific dilation rates are incorporated into parallel paths within each layer of the U-Net architecture. Furthermore, the convolutional block attention module (CBAM) is integrated into each path to dynamically emphasize spatial and channel-wise features. We also introduce a weighted auxiliary loss function that utilizes output from each decoder block, forcing the model to learn features at a lower-level feature space and enhancing overall system performance. The proposed method is evaluated on three publicly available datasets: DRIVE and STARE for blood vessel segmentation and IDRiD for segmenting exudates, optic disks, and hemorrhages. Performance metrics, including specificity, sensitivity, accuracy, and AUC score, are employed to assess the model. The proposed method can be adapted for automated retinal screening systems for early detection of chemical exposure for public health surveillance and occupational health monitoring.},
  archive      = {J_NCA},
  author       = {Aouti, Rajesh and Redkar, Sangram and Dwivedi, Prabha},
  doi          = {10.1007/s00521-025-11567-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25123-25149},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale residual attention model for retinal image feature segmentation: Toward chemical exposure detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving pediatric trauma care: An automated system for wrist trauma detection using GELAN. <em>NCA</em>, <em>37</em>(30), 25095-25121. (<a href='https://doi.org/10.1007/s00521-025-11539-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trauma is a major cause of disability among children, requiring swift and accurate diagnosis for effective treatment. This paper introduces an automated method that uses deep learning to detect and categorize fractures in children using X-ray images. The system makes use of the GRAZPEDWRI-DX dataset, which consists of 20,327 annotated X-ray images of pediatric wrist fractures. Our architecture, which is built upon the generalized efficient layer aggregation network (GELAN), effectively tackles the issues of class imbalance and image resolution. As a result, it achieves state-of-the-art performance in both trauma and severity detection. Our proposed framework surpassed the most advanced techniques, showcasing exceptional precision and effectiveness, achieving a mean average precision (mAP50) score of 74.1%, 95%, and 85.5% for Task A (trauma detection), Task B (fracture detection), and Task C (fracture severity detection), respectively. The results of our study highlight the capacity of deep learning to improve the diagnosis of pediatric trauma, decrease the burden on radiologists, and boost patient outcomes.},
  archive      = {J_NCA},
  author       = {Basak, Promit and Mushtak, Adam and Ouda, Mohamed and Nobi, Sadia Farhana and Hasan, Anwarul and Chowdhury, Muhammad E. H.},
  doi          = {10.1007/s00521-025-11539-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25095-25121},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving pediatric trauma care: An automated system for wrist trauma detection using GELAN},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDNER: Integrating MRC with diffusion models for enhanced named entity recognition. <em>NCA</em>, <em>37</em>(30), 25077-25094. (<a href='https://doi.org/10.1007/s00521-025-11533-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have recently achieved impressive results in generative tasks, extending their capabilities from continuous data to discrete text. However, these models still face challenges when it comes to accurately capturing discrete entity information, especially in tasks like named entity recognition (NER). To address this, we propose MDNER, a novel NER model that integrates diffusion models with a Machine Reading Comprehension (MRC) framework. Unlike DIFFUSIONNER, which relies solely on diffusion processes without semantic priors, MDNER introduces MRC-guided denoising to explicitly align label semantics and contextual representations during boundary refinement. During training, MDNER concatenates the input text with predefined queries and processes them through BERT to obtain enhanced contextual representations. It then gradually adds noise to the golden entity boundaries and trains the model to recover these boundaries through a denoising process. In inference, the process starts by sampling noisy entity boundaries from a Gaussian distribution and inputs them with the text into MDNER. MDNER iteratively refines these noisy boundaries using the learned denoising process. By reformulating the NER task as a denoising diffusion process on entity boundaries, MDNER leverages the shared denoising objectives of diffusion models and pre-trained language model (PLM) to generate entity spans from noise. Experiments demonstrate that MDNER achieves state-of-the-art results across flat and nested NER datasets, with improvements of +0.18% and +0.78% in F1 scores on CoNLL2003 and OntoNotes5.0, respectively. For nested NER datasets such as ACE2005, it achieves gains of +1.66% in F1 scores. These results highlight MDNER’s superior performance in complex entity recognition scenarios.},
  archive      = {J_NCA},
  author       = {Wang, Mengying and Lv, Wenxiu and Zhang, YuKun and Yan, Danfeng},
  doi          = {10.1007/s00521-025-11533-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25077-25094},
  shortjournal = {Neural Comput. Appl.},
  title        = {MDNER: Integrating MRC with diffusion models for enhanced named entity recognition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph isomorphism attention network combined with pre-trained language models: A novel approach for crystal material property prediction. <em>NCA</em>, <em>37</em>(30), 25061-25076. (<a href='https://doi.org/10.1007/s00521-025-11532-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting crystal material properties is a central task in AI-for-science, yet existing graph neural network methods face three limitations: (1) conventional neighbor-based graph construction causes node features to be dominated by neighbors, losing atomic uniqueness, (2) such atomic graphs only capture short-range dependencies via immediate neighbors while neglecting long-range interactions through multi-hop connections, and (3) insufficient utilization of chemical formulae, often relying on simplistic one-hot encoding without material-specific knowledge. To address these, we propose the graph isomorphism attention network (GIAT), which balances self-node and neighbor information to preserve atomic characteristics while capturing short-range dependencies. Additionally, we integrate a GraphTransformer to model long-range atomic interactions, forming a complementary framework with GIAT. Furthermore, we employ matBERT, a material science-specific language model, to encode chemical formulae, leveraging domain knowledge from both individual materials and their analogs. Experiments show that our model achieves state-of-the-art performance by synergistically combining short-range (GIAT), long-range (GraphTransformer), and chemical formula embeddings (matBERT).},
  archive      = {J_NCA},
  author       = {Kang, Jiahao and Yang, Liang and Zeng, Jingjie and Sun, Zhi and Lin, Hongfei and Li, Junpeng},
  doi          = {10.1007/s00521-025-11532-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25061-25076},
  shortjournal = {Neural Comput. Appl.},
  title        = {Graph isomorphism attention network combined with pre-trained language models: A novel approach for crystal material property prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Swarm-based metaheuristic and reptile search algorithm for downstream operation-dependent fragmentation size prediction. <em>NCA</em>, <em>37</em>(30), 25033-25059. (<a href='https://doi.org/10.1007/s00521-025-11321-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The improvement in blast fragmentation material size aids downstream operation efficiency by supplying a high percentage of 80% passing size of rocks (D80) material. In this study, blast fragmentation percentage prediction models were developed using five soft computing approaches, i.e., multilayer perceptron (MLP), multivariate adaptive regression spline (MARS), support vector regression SVR), decision tree (DT), and random forest (RF), combined with reptile search algorithm. Blast characteristics were obtained from 407 production blasts at the Anguran lead and zinc mine in Mahenshan, Iran. The particle size distribution resulting from blasting was determined using a digital image processing approach in the current paper. The novelty of this research lies in the integration of the reptile search algorithm (RSA) with machine-learning models for enhanced rock fragmentation prediction. In this study, the RSA was used to optimize RF model and accurate prediction of rock fragmentation due to mine blasting. The proposed models’ prediction accuracy was compared using nine performance indices such as root mean square error (RMSE), correlation coefficient (R), coefficient of determination (R2), mean absolute percentage error (MAPE), weighted mean absolute percentage error (WMAPE), Variance Accounted For (VAF), Nash–Sutcliffe efficiency (NS), Willmott’s index of agreement (WI) and bias index (Bias). Based on the obtained results, the RF-RSA model outperformed other developed models with the lowest error and highest accuracy. Hence, the results indicated that the RF-RSA model outperforms other models in predicting blast fragmentation, achieving the lowest R2 of 0.9734 and RMSE of 0.8386 in the training phase, and 0.9715 and 0.7464 in the testing phase. Furthermore, the model attained the lowest MAPE values of 2.3067 (training) and 2.0959 (testing), demonstrating its robustness and predictive accuracy. These findings highlight the effectiveness of the proposed AI-based approach in optimizing blast fragmentation prediction, contributing to improved operational efficiency in mining.},
  archive      = {J_NCA},
  author       = {Chen, Lihua and Taiwo, Blessing Olamide and Hosseini, Shahab and Kahraman, Esma and Fissha, Yewuhalashet and Sazid, Mohammed and Famobuwa, Oluwaseun Victor and Faluyi, Joshua Oluwaseyi and Akinlabi, Adams Abiodun and Ikeda, Hajime and Kawamura, Youhei},
  doi          = {10.1007/s00521-025-11321-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {25033-25059},
  shortjournal = {Neural Comput. Appl.},
  title        = {Swarm-based metaheuristic and reptile search algorithm for downstream operation-dependent fragmentation size prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing forensic dentistry: A comprehensive review of machine learning and deep learning applications in dental image analysis. <em>NCA</em>, <em>37</em>(30), 24997-25032. (<a href='https://doi.org/10.1007/s00521-025-11612-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of forensic dentistry has witnessed a marked rise in the utilization of artificial intelligence (AI), particularly in the domains of age estimation, gender classification, and human identification through dental image analysis. Although there are more publications in this field now than there used to be, there has not been a full review of how good the methods are and how things have changed over time. The aim of this systematic review is to assess the state of the literature on AI-based forensic dental image analysis using two complementary methods: (1) Publication dynamics and keyword trends are examined using bibliometric analysis, and (2) study goals, AI techniques, and experimental protocols are evaluated using systematic content review. A well-planned search was done in the Web of Science for the years between 2020 and 2024. The review followed PRISMA 2020 guidelines. Sixty-four articles met the criteria and were analyzed both quantitatively and qualitatively. The highest publication count was observed in 2022, with a stabilization trend noted in 2023 and 2024. Most of the studies focused on age estimation, with gender classification and identification coming a close second. CNNs were the dominant model architecture. While the field is maturing, there are still key challenges, such as the heterogeneity of datasets, the lack of external validation, and the limited attention given to forensic admissibility. The addressing of these issues will be vital for the translation of AI innovations into robust forensic tools.},
  archive      = {J_NCA},
  author       = {Karcioglu, Abdullah Ammar and Yilmaz, Rabia Meryem and Yaganoglu, Mete and Almohammad, Mahmoud and Laloglu, Abubekir},
  doi          = {10.1007/s00521-025-11612-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24997-25032},
  shortjournal = {Neural Comput. Appl.},
  title        = {Advancing forensic dentistry: A comprehensive review of machine learning and deep learning applications in dental image analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital footprints and personality prediction: Integrating methodological innovations and ethical considerations in social media analysis. <em>NCA</em>, <em>37</em>(30), 24953-24996. (<a href='https://doi.org/10.1007/s00521-025-11607-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the emerging area of personality prediction using social media, emphasizing the simultaneous emphasis on improving research methods and addressing ethical concerns. The widespread use of digital technology, especially social media, presents an interesting opportunity to automatically detect personality traits from digital footprints. The study conducts an extensive analysis of existing literature to extract important findings regarding contemporary methods for predicting personality through automation. It thoroughly reviews different personality models, computational datasets, and sources of social media data. The primary contribution of this research is its thorough examination of the complex correlation between online social behaviors and personality traits, highlighting the potential of using social media behaviors as dependable indicators of personality. This investigation demonstrates the power of digital footprints to provide profound insights into human psychology, leading to substantial impacts on the disciplines of psychology, marketing, and social media design. Furthermore, the study thoroughly examines the ethical issues associated with forecasting personality traits, highlighting the imperative of employing ethical research methodologies, transparency, and preserving privacy when utilizing social media data. The main objective of this study is to integrate empirical evidence, theoretical frameworks, and ethical considerations to establish the framework for future research that is both scientifically rigorous and ethically responsible. Our findings provide illumination on the challenges and opportunities in personality prediction research.},
  archive      = {J_NCA},
  author       = {Maharani, Warih and Gani, Prati Hutari},
  doi          = {10.1007/s00521-025-11607-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24953-24996},
  shortjournal = {Neural Comput. Appl.},
  title        = {Digital footprints and personality prediction: Integrating methodological innovations and ethical considerations in social media analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pre-communication mechanism for evolutionary multitasking optimization. <em>NCA</em>, <em>37</em>(30), 24919-24951. (<a href='https://doi.org/10.1007/s00521-025-11534-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking optimization (EMTO) aims to make use of evolutionary algorithms to solve multiple optimization tasks simultaneously through exploiting the relevant information between different tasks. However, the existing EMTO algorithms (EMTOAs) usually begin the optimization process from scratch without considering the prior information between different tasks, which would restrict the solving performance. This paper proposes a pre-communication mechanism (PCM) for EMTO, which takes the distribution information of the initial population corresponding to each task as the prior information, and uses the correlation of the prior information to provide refined solutions for each task in the each generation of the early evolution. Firstly, after generating initial individual solutions, PCM constructs a Gaussian distribution model on the individual solutions of each task as the prior information. Next, in the each generation of the early evolution, PCM takes each task as the target task in turn and learns the similarity information between the target task and other tasks by constructing a Gaussian mixture model. Mixture coefficients represent the learned similarity information between the target task and other tasks. Finally, the individual solutions sampled from the obtained Gaussian mixture model of each task compete with original individual solutions of each generation of early evolution to obtain refined individual solutions. The experimental results show that PCM can help the existing EMTOAs to solve multitasking optimization problems more effectively and efficiently.},
  archive      = {J_NCA},
  author       = {Yang, Cuicui and Li, Xiang and Ji, Junzhong and Zhang, Xiaoyu},
  doi          = {10.1007/s00521-025-11534-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24919-24951},
  shortjournal = {Neural Comput. Appl.},
  title        = {A pre-communication mechanism for evolutionary multitasking optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can large language models beat wall street? evaluating GPT-4’s impact on financial decision-making with MarketSenseAI. <em>NCA</em>, <em>37</em>(30), 24893-24918. (<a href='https://doi.org/10.1007/s00521-024-10613-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces MarketSenseAI, an innovative framework leveraging GPT-4’s advanced reasoning for selecting stocks in financial markets. By integrating Chain of Thought and In-Context Learning, MarketSenseAI analyzes diverse data sources, including market trends, news, fundamentals, and macroeconomic factors, to emulate expert investment decision-making. The development, implementation, and validation of the framework are elaborately discussed, underscoring its capability to generate actionable and interpretable investment signals. A notable feature of this work is employing GPT-4 both as a predictive mechanism and signal evaluator, revealing the significant impact of the AI-generated explanations on signal accuracy, reliability, and acceptance. Through empirical testing on the competitive S&P 100 stocks over a 15-month period, MarketSenseAI demonstrated exceptional performance, delivering excess alpha of 10–30% and achieving a cumulative return of up to 72% over the period, while maintaining a risk profile comparable to the broader market. Our findings highlight the transformative potential of Large Language Models in financial decision-making, marking a significant leap in integrating generative AI into financial analytics and investment strategies.},
  archive      = {J_NCA},
  author       = {Fatouros, George and Metaxas, Kostas and Soldatos, John and Kyriazis, Dimosthenis},
  doi          = {10.1007/s00521-024-10613-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24893-24918},
  shortjournal = {Neural Comput. Appl.},
  title        = {Can large language models beat wall street? evaluating GPT-4’s impact on financial decision-making with MarketSenseAI},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chinese fine-grained financial sentiment analysis with large language models. <em>NCA</em>, <em>37</em>(30), 24883-24892. (<a href='https://doi.org/10.1007/s00521-024-10603-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity-level fine-grained sentiment analysis in the financial domain is a crucial subtask of sentiment analysis and currently faces numerous challenges. The primary challenge stems from the need for more high-quality and large-scale annotated corpora designed explicitly for financial text sentiment analysis, which, in turn, limits the availability of data necessary for developing effective text processing techniques. Recent advancements in large language models (LLMs) have yielded remarkable performance in natural language processing tasks, primarily centered around language pattern matching. In this paper, we propose a novel and extensive Chinese fine-grained financial sentiment analysis dataset, FinChina SA, for enterprise early warning. We thoroughly evaluate and experiment with well-known existing open-source LLMs using our dataset. We firmly believe that our dataset will serve as a valuable resource to advance the exploration of real-world financial sentiment analysis tasks, which should be the focus of future research.},
  archive      = {J_NCA},
  author       = {Lan, Yinyu and Wu, Yanru and Xu, Wang and Feng, Weiqiang and Zhang, Youhao},
  doi          = {10.1007/s00521-024-10603-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24883-24892},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chinese fine-grained financial sentiment analysis with large language models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model XAI approach for illicit activity investigation in bitcoin. <em>NCA</em>, <em>37</em>(30), 24869-24881. (<a href='https://doi.org/10.1007/s00521-024-10510-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) present an opportunity for interpreting and investigating financial cybercrime activity. Analysts are tasked with learning and understanding the ever-shifting domain of financial crime, coupled with the latest tools being produced to assist them in their investigative tasks. We present an LLM XAI approach for identifying and explaining illicit activity in Bitcoin. We show that LLMs can produce intuitive and highly useful contextual narratives when prompted with Bitcoin transaction data. Extracting embeddings of the narratives allow for the calculation of similarity metrics capable of identifying other illicit transactions. We develop a pipeline of collating similar transactions, creating contextual narratives explaining their similarity, and produce a summary report all for the goal of aiding the investigative analyst.},
  archive      = {J_NCA},
  author       = {Nicholls, Jack and Kuppa, Aditya and Le-Khac, Nhien-An},
  doi          = {10.1007/s00521-024-10510-w},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24869-24881},
  shortjournal = {Neural Comput. Appl.},
  title        = {Large language model XAI approach for illicit activity investigation in bitcoin},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models in finance (FinLLMs). <em>NCA</em>, <em>37</em>(30), 24853-24867. (<a href='https://doi.org/10.1007/s00521-024-10495-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated remarkable capabilities and have attracted significant attention across diverse domains, including financial services. Despite the extensive research into general-domain LLMs and their immense potential in finance, financial LLMs (FinLLMs) research remains limited. This survey provides a comprehensive overview of FinLLMs, including their history, techniques, downstream tasks associated with datasets, evaluations, and opportunities and challenges. Firstly, we present a chronological overview of general-domain language models (LMs) through to current FinLLMs, including the GPT-series, selected open-source LLMs, and financial LMs. Secondly, we compare five techniques used across eight financial LMs, including training methods, training data, and fine-tuning methods. Thirdly, we summarize the performance evaluations of six benchmark tasks and datasets and provide eight advanced financial NLP tasks and datasets for developing more sophisticated FinLLMs. Finally, we discuss the opportunities and the challenges facing FinLLMs, such as hallucination, privacy, and efficiency. To support AI research in finance, we compile a collection of accessible datasets and benchmarks on GitHub. ( https://github.com/adlnlp/FinLLMs )},
  archive      = {J_NCA},
  author       = {Lee, Jean and Stevens, Nicholas and Han, Soyeon Caren},
  doi          = {10.1007/s00521-024-10495-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24853-24867},
  shortjournal = {Neural Comput. Appl.},
  title        = {Large language models in finance (FinLLMs)},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient all-pairs approach for multi-objective dynamic shortest path problems. <em>NCA</em>, <em>37</em>(30), 24823-24851. (<a href='https://doi.org/10.1007/s00521-025-11437-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Shortest Path problem is fundamental for determining optimal routes in various applications. The Dynamic Shortest Path problem extends this concept to evolving graph structures. However, existing algorithms often fail to address decision-making complexities involving multiple objectives. In our previous work, we introduced the Multi-Objective Dynamic Shortest Path problem to address this gap. This paper presents the All-pairs Multi-objective Dynamic Shortest Path algorithm, offering a novel approach that combines a labeling-correcting method with the Optimistic Linear Support algorithm. This hybrid methodology enhances efficiency by minimizing redundant calculations during graph updates. Extensive testing demonstrates that our algorithm is over 3.22 times faster than baseline algorithms in producing Pareto solutions. This work advances techniques for multi-objective dynamic shortest paths and tackles challenges in evolving graph structures, paving the way for future research in this dynamic field.},
  archive      = {J_NCA},
  author       = {da Silva, Juarez Machado and Ramos, Gabriel de Oliveira and Barbosa, Jorge Luis Victória},
  doi          = {10.1007/s00521-025-11437-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24823-24851},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient all-pairs approach for multi-objective dynamic shortest path problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling uncertainty with parametric surrogate-assisted optimization for dynamic multi-objective problems. <em>NCA</em>, <em>37</em>(30), 24793-24822. (<a href='https://doi.org/10.1007/s00521-025-11359-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of dynamic multi-objective optimization problems, a shift of Pareto fronts is a consequence of changing environmental parameters. Current state-of-the-art methods define this dynamic nature as unknown time-dependent variables influencing the objective space of the problem. However, when dealing with real-world processes, these time-dependent variables are not always unknown. Processes are characterized by an intricate relationship between a series of decision variables, observed parameters, but also unknown parameters. Observed parameters can be seen as causal responses to underlying unknown environmental variables. This implies that they are at least partially determined by the state of other variables and reveal information about the state of the process that is not known when solely considering the decision variables. This paper discusses the types of uncertainty present in dynamic processes and how these uncertainties can be quantified and handled in surrogate modeling. A novel approach, PSAMOO, is proposed to integrate environmental parameters into parametric surrogate models to achieve more efficient Pareto front tracking in dynamic optimization. An extensive evaluation on dynamic problems shows how epistemic and aleatoric uncertainty can effectively be quantified and accounted for resulting in an improved dynamic Pareto front tracking and approximation.},
  archive      = {J_NCA},
  author       = {Temmerman, Arne De and Ryck, Matthias De and Verbeke, Mathias},
  doi          = {10.1007/s00521-025-11359-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24793-24822},
  shortjournal = {Neural Comput. Appl.},
  title        = {Handling uncertainty with parametric surrogate-assisted optimization for dynamic multi-objective problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective reinforcement learning framework for beneficent artificial intelligence. <em>NCA</em>, <em>37</em>(30), 24773-24791. (<a href='https://doi.org/10.1007/s00521-025-11311-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence (AI) systems are more widely deployed and utilized, they have greater potential to inflict harm or provide benefits to individuals. Designers must consider these concepts when building AI systems, but it is difficult to capture these notions in a mathematical framework. An ethical framework put forth by London and Heidari (Minds Mach, 2024. https://doi.org/10.1007/s11023-024-09696-8 ) provides structure and formal definitions of benefits and harms in relation to an individual’s life plans. This leaves an open question of how these concepts impact the decision-making of an AI system. We leverage their work to provide a direct translation of these theoretical ethical concepts to a standard multi-objective reinforcement learning (MORL) decision model. Using this model, we show that multi-objective rewards are necessary to capture benefits and harms in accordance with their definitions. We demonstrate how to capture these concepts in a MORL system and provide scenarios to highlight the utility of this work.},
  archive      = {J_NCA},
  author       = {Nickelson, Anna and Perkins, Russell and London, Alex John and Robinette, Paul and Tumer, Kagan},
  doi          = {10.1007/s00521-025-11311-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24773-24791},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective reinforcement learning framework for beneficent artificial intelligence},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utility-inspired generalizations of TOPSIS. <em>NCA</em>, <em>37</em>(30), 24743-24772. (<a href='https://doi.org/10.1007/s00521-025-11238-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {TOPSIS, a popular method for ranking alternatives, is based on aggregated distances to ideal and anti-ideal points. As such, it was considered to be essentially different from widely popular and acknowledged ’utility-based methods’, which build rankings from weight-averaged utility values. Nonetheless, TOPSIS has recently been shown to be a natural generalization of these ’utility-based methods’ on the grounds that the distances it uses can be decomposed into so-called weight-scaled means (WM) and weight-scaled standard deviations (WSD) of utilities. However, the influence that these two components exert on the final ranking cannot be in any way implemented in the standard TOPSIS. This is why, building on our previous results, in this paper we put forward modifications that make TOPSIS aggregations responsive to WM and WSD, achieving some amount of well interpretable control over how the rankings are influenced by WM and WSD. The modifications constitute a natural generalization of the standard TOPSIS method because, thanks to them, the generalized TOPSIS may turn into the original TOPSIS or, otherwise, following the decision-maker’s preferences, may trade off WM for WSD or WSD for WM. In the latter case, TOPSIS gradually reduces to a regular ’utility-based method’. All in all, we believe that the proposed generalizations constitute an interesting practical tool for influencing the ranking by controlled application of a new form of decision-maker’s preferences.},
  archive      = {J_NCA},
  author       = {Szczęch, Izabela and Susmaga, Robert},
  doi          = {10.1007/s00521-025-11238-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24743-24772},
  shortjournal = {Neural Comput. Appl.},
  title        = {Utility-inspired generalizations of TOPSIS},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep multi-objective reinforcement learning for utility-based infrastructural maintenance optimization. <em>NCA</em>, <em>37</em>(30), 24719-24742. (<a href='https://doi.org/10.1007/s00521-024-10954-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce multi-objective deep centralized multi-agent actor-critic (MO-DCMAC), a multi-objective reinforcement learning method for infrastructural maintenance optimization, an area traditionally dominated by single-objective reinforcement learning (RL) approaches. Previous single-objective RL methods combine multiple objectives, such as probability of collapse and cost, into a singular reward signal through reward-shaping. In contrast, MO-DCMAC can optimize a policy for multiple objectives directly, even when the utility function is nonlinear. We evaluated MO-DCMAC using two utility functions, which use probability of collapse and cost as input. The first utility function is the threshold utility, in which MO-DCMAC should minimize cost so that the probability of collapse is never above the threshold. The second is based on the failure mode, effects, and criticality analysis methodology used by asset managers to assess maintenance plans. We evaluated MO-DCMAC, with both utility functions, in multiple maintenance environments, including ones based on a case study of the historical quay walls of Amsterdam. The performance of MO-DCMAC was compared against multiple rule-based policies based on heuristics currently used for constructing maintenance plans. Our results demonstrate that MO-DCMAC outperforms traditional rule-based policies across various environments and utility functions.},
  archive      = {J_NCA},
  author       = {van Remmerden, Jesse and Kenter, Maurice and Roijers, Diederik M. and Andriotis, Charalampos and Zhang, Yingqian and Bukhsh, Zaharah},
  doi          = {10.1007/s00521-024-10954-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24719-24742},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep multi-objective reinforcement learning for utility-based infrastructural maintenance optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-weight ranking for multi-criteria decision making. <em>NCA</em>, <em>37</em>(30), 24705-24717. (<a href='https://doi.org/10.1007/s00521-024-10626-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A basic problem in multi-criteria decision-making (MCDM) is to find a ranking for alternatives which are not directly comparable with each other. A number of different methods exists. In this paper, a new ranking method is proposed by turning a statistical function into an MCDM ranking function. In particular, cone distribution functions from multivariate statistics are used as ranking functions and their features are investigated. Our findings demonstrate that this procedure can be considered as an upgrade of the weighted sum ranking insofar as it absorbs a whole collection of weighted sums at once instead of fixing a particular one in advance. The new ranking–in contrast to a pure weighted sum ranking–is also able to detect “non-convex” parts of the Pareto frontier. The rank reversal phenomenon is studied, and it is explained why it might even be useful for analyzing the ranking procedure. The ranking is extended to sets providing unary indicators for set preferences which establishes the link between set optimization methods and set-based multi-objective optimization. This also provides a new tool for evaluating the outcomes of evolutionary algorithms for multi-criteria optimization. The proposed method has implications for preferences learning and categorization of multi-dimensional data points, both with respect to an underlying non-complete order relation.},
  archive      = {J_NCA},
  author       = {Hamel, Andreas H. and Kostner, Daniel},
  doi          = {10.1007/s00521-024-10626-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24705-24717},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-weight ranking for multi-criteria decision making},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising multi-value alignment: A multi-objective evolutionary strategy for normative multi-agent systems. <em>NCA</em>, <em>37</em>(30), 24685-24703. (<a href='https://doi.org/10.1007/s00521-024-10625-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Value alignment in normative multi-agent systems (NorMAS) is used to promote a certain value and to ensure consistent behaviour of agents in autonomous intelligent systems with human values. Although various techniques were proposed in the literature for addressing the value alignment challenges in NorMAS, aligning multiple values remains an area requiring further investigation, especially in heterogeneous systems where agents may have different, potentially conflicting, coherent or unrelated norms and values. In such systems, it is crucial to simultaneously compromise and optimise values while synthesising an optimally aligned set of norms. Moreover, to deal with the conflicting or unrelated values and norms, we need to consider the norms and values as independent distinct sets. This research proposes a novel framework, Norms Optimisation and Values Alignment (NOVA), which enables multi-value alignment in heterogeneous NorMAS using parametric norms, multi-objective evolutionary algorithms (MOEAs) and decentralised reasoning. NOVA models the values and norms as independent distinct sets, then formalises the problem as a multi-objective optimisation problem (MOP), and optimises these two sets simultaneously while aligning them. To understand various aspects of this complex problem, several evolutionary algorithms were used to find a set of optimised norm parameters considering two tax scenarios with two and five values. The results show the impact of the selected evolutionary algorithm on the solution, and the importance of understanding the relation between values and norms when prioritising them using different reasoning strategies.},
  archive      = {J_NCA},
  author       = {Riad, Maha and de Carvalho, Vinicius Renan and Golpayegani, Fatemeh},
  doi          = {10.1007/s00521-024-10625-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24685-24703},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimising multi-value alignment: A multi-objective evolutionary strategy for normative multi-agent systems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalization in multi-objective machine learning. <em>NCA</em>, <em>37</em>(30), 24669-24683. (<a href='https://doi.org/10.1007/s00521-024-10616-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning tasks often require considering not just one but multiple objectives. For example, besides the prediction quality, this could be the efficiency, robustness or fairness of the learned models, or any of their combinations. Multi-objective learning offers a natural framework for handling such problems without having to commit to early trade-offs. Surprisingly, statistical learning theory so far offers almost no insight into the generalization properties of multi-objective learning. In this work, we make first steps to fill this gap: We establish foundational generalization bounds for the multi-objective setting as well as generalization and excess bounds for learning with scalarizations. We also provide the first theoretical analysis of the relation between the Pareto-optimal sets of the true objectives and the Pareto-optimal sets of their empirical approximations from training data. In particular, we show a surprising asymmetry: All Pareto-optimal solutions can be approximated by empirically Pareto-optimal ones, but not vice versa.},
  archive      = {J_NCA},
  author       = {Súkeník, Peter and Lampert, Christoph},
  doi          = {10.1007/s00521-024-10616-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24669-24683},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generalization in multi-objective machine learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fade: Fairness-aware deep ensemble for quantifying uncertainty. <em>NCA</em>, <em>37</em>(30), 24655-24667. (<a href='https://doi.org/10.1007/s00521-024-10523-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper brings together two important aspects of trustworthy ML that go beyond mere accuracy that is calibration and fairness. A model is well calibrated if predictions that have a confidence of 0.6 are true 60% of the time. For fairness, we require calibration-by-groups and no underestimation, i.e., that predictions are consistent with respect to the actual distribution, across sensitive feature values. The deep ensemble method provides uncertainty estimates, as a form of transparency, by retraining the same neural network architecture with different weight initializations to produce a distribution of predictions. This method provides a compelling approach to approximating Bayesian predictive distributions, resulting in well-calibrated predictions. Through a series of experiments, we demonstrate that deep ensemble models are often well calibrated in terms of posterior probabilities but less so when a sensitive attribute is involved, resulting in biased predictions. This should not come as a surprise because the distributions of weights in the deep ensemble are usually optimized to maximize generalization accuracy without explicit consideration of fairness. To address this issue, we propose Fairness-Aware Deep Ensemble (FADE), a multi-objective optimization strategy to optimize the deep ensemble model on accuracy and fairness. We empirically evaluate our framework on two synthetic and twelve real-world datasets. We find that FADE can obtain fairer models while still attaining adequate overall generalization accuracy and calibrated probability estimates.},
  archive      = {J_NCA},
  author       = {Blanzeisky, William and Cunningham, Pádraig},
  doi          = {10.1007/s00521-024-10523-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24655-24667},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fade: Fairness-aware deep ensemble for quantifying uncertainty},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear scalarization in stochastic multi-objective MDPs. <em>NCA</em>, <em>37</em>(30), 24641-24653. (<a href='https://doi.org/10.1007/s00521-024-10504-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many sequential decision problems of interest are best described in relation to multiple, possibly conflicting objectives. In recent years, there has been a growing interest in the application of reinforcement learning techniques to solve this type of problem. However, most existing multi-objective reinforcement learning (MORL) algorithms only apply in cases where the utility over the different criteria is linear. Unfortunately, in many real-world use cases, users’ preferences cannot be represented accurately by linear scalarization. Nonlinear scalarizations provide the required expressivity, but pose a number of issues when tackled by reinforcement learning, with so far little study and no definite solution. In particular, current methods struggle to deal with the most general MORL setting, where the environment is stochastic and the scalarization of the expected returns associated with each objective is nonlinear. In this paper, we present a model-free, value-based algorithm aimed at this type of problem: we prove that it converges to the optimal deterministic policy, confirm this result with experimental evidence, and discuss its limitations.},
  archive      = {J_NCA},
  author       = {Vincent, Marc},
  doi          = {10.1007/s00521-024-10504-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24641-24653},
  shortjournal = {Neural Comput. Appl.},
  title        = {Nonlinear scalarization in stochastic multi-objective MDPs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-based adaptive control and analysis for nonlinear systems with state-dependent constraint. <em>NCA</em>, <em>37</em>(30), 24625-24640. (<a href='https://doi.org/10.1007/s00521-025-11052-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the adaptive control issue for nonlinear systems with state-dependent constraint is investigated. The state-dependent constraint is not only related to time but also related to the historical state information of the system. It is a new type of complex constraint. Moreover, the input quantization and unknown system dynamics are also considered here, which are solved by using radial basis function neural networks. Then, an adaptive controller is proposed by using the backstepping method and the barrier Lyapunov function approach such that all signals in the resulted system are bounded, all system states satisfy their corresponding state-dependent constraint condition and the system output tracks the desired tracking signal. Finally, a simulation example is employed to further show the effectiveness of the proposed approach.},
  archive      = {J_NCA},
  author       = {Li, Guangshi},
  doi          = {10.1007/s00521-025-11052-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24625-24640},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning-based adaptive control and analysis for nonlinear systems with state-dependent constraint},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-based adaptive fuzzy control for electro-hydraulic servo system. <em>NCA</em>, <em>37</em>(30), 24607-24624. (<a href='https://doi.org/10.1007/s00521-024-10741-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel adaptive fuzzy controller based on deep reinforcement learning (DRL) is introduced for electro-hydraulic servo systems. The controller combines the strengths of fuzzy proportional–integral (PI) control and deep Q-learning network (DQLN) to achieve real-time adaptation and improve the control performance. The purpose of this paper is to address the challenges of controlling electro-hydraulic servo systems by developing an adaptive controller that can dynamically adjust its control parameters based on the system’s state. The traditional fuzzy PI controller is enhanced with DRL techniques to enable automatic adaptation and compensation for changing online conditions. The proposed adaptive controller utilizes a DQLN to dynamically adjust the scaling factors of the input/output membership functions. By using the DQLN algorithm, the controller learns from a variety of system data to determine the optimal control parameters. The update equation of the weights for the Q-network is derived using the Lyapunov stability (LS) theorem, which overcomes the limitations of gradient descent (GD) methods such as instability and local minima trapping. To evaluate the effectiveness of the proposed controller, it is practically implemented to regulate an electro-hydraulic servo system. The controller’s performance is compared against other existing controllers, and its enhancements are demonstrated through experimental evaluation.},
  archive      = {J_NCA},
  author       = {Khater, A. Aziz and Fekry, Mohamed and El-Bardini, Mohammad and El-Nagar, Ahmad M.},
  doi          = {10.1007/s00521-024-10741-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24607-24624},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep reinforcement learning-based adaptive fuzzy control for electro-hydraulic servo system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced intelligent water drops with genetic algorithm for multi-objective mixed time window vehicle routing. <em>NCA</em>, <em>37</em>(30), 24591-24605. (<a href='https://doi.org/10.1007/s00521-024-10702-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of addressing the multi-objective vehicle routing problem, a hybrid time window multi-objective vehicle model was established using integer programming and the intelligent water drop algorithm. To overcome the limitation of the intelligent water drop algorithm potentially converging to local optimal solutions, enhancements were proposed through genetic algorithms, particularly by introducing genetic crossover and single-point recombination operators. Subsequently, the intelligent water drop algorithm was refined, and its effectiveness was evaluated through a real-world case study. Comparative analyses were conducted among three algorithms: IWD, GA, and SA. The results demonstrate that the improved algorithm effectively alleviates the common issue of traditional algorithms converging to local optimal solutions. Therefore, an enhanced solution is provided for the discrete hybrid time window problem, achieving superior optimization outcomes.},
  archive      = {J_NCA},
  author       = {Guo, Zhibao and Karimi, Hamid Reza and Jiang, Baoping and Wu, Zhengtian and Cheng, Yukun},
  doi          = {10.1007/s00521-024-10702-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24591-24605},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced intelligent water drops with genetic algorithm for multi-objective mixed time window vehicle routing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe adaptive control for multi-agent systems under uncertain dynamic environments: A robust barrier-certified learning approach. <em>NCA</em>, <em>37</em>(30), 24575-24590. (<a href='https://doi.org/10.1007/s00521-024-10639-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a decentralized safe learning-based adaptive control is developed for multi-agent systems (MAS) operating in uncertain environments. Ensuring the safety of MAS in uncertain environments becomes a challenging task, particularly when the dynamics of the individual agent are unknown and their accurate state information is unavailable to the local agent. Due to the fact that the safe set of the local agent depends on the other agents’ states, the uncertainty of these external systems leads to an uncertain safety set. As a consequence, the safe control design of the local agent system in a multi-agent setting under environmental uncertainties becomes intractable. To address this challenge and ensure the safety of the local agent, a neural network (NN)-based adaptive observer is designed to estimate the state of the unknown external agents in the multi-agent environment. Based on the state estimation of external agents, an adaptive interplay control barrier function (AI-CBF) is formulated. The AI-CBF is designed by considering both the local agent’s state and the estimated states of external agents. Notably, the limitation of forward invariance for the approximated safe set without guaranteeing the same for the actual safe set is acknowledged in AI-CBF design. The AI-CBF incorporates the bounds on state estimation errors of external agents to guarantee the strict safety requirements of the local agent. Based on the safety constraint enforced by the AI-CBF, a control framework is formulated using a quadratic programming (QP) method that integrates the safety and stability of the system. In addition, a stability analysis based on Lyapunov theory is performed to demonstrate the convergence of the neural network-based adaptive observer as well as the closed-loop stability of the overall system. Eventually, experimental validation and comparison study confirm the effectiveness of the developed approach that can ensure multi-agent system safety under challenging conditions in a decentralized manner.},
  archive      = {J_NCA},
  author       = {Dey, Shawon and Xu, Hao},
  doi          = {10.1007/s00521-024-10639-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24575-24590},
  shortjournal = {Neural Comput. Appl.},
  title        = {Safe adaptive control for multi-agent systems under uncertain dynamic environments: A robust barrier-certified learning approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online multi-agent deep reinforcement learning platform for distributed real-time dynamic control of power systems. <em>NCA</em>, <em>37</em>(30), 24561-24574. (<a href='https://doi.org/10.1007/s00521-024-10488-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-agent deep reinforcement learning (MADRL) has made significant strides in power system decision-making and control. However, there is a scarcity of high-fidelity, real-time platforms for testing various DRL control algorithms in detailed power systems. Motivated by EtherCAT communication and DRL features, this study presents a MADRL online testing platform for distributed real-time dynamic control of power systems. The platform utilizes the Opal-RT real-time simulator for real-time simulation of dynamic power system environments and uses multiple AI workstations for the implementation of MADRL control algorithms. The proposed platform facilitates real-time interaction among AI workstations and the Opal-RT real-time simulator by leveraging the EtherCAT communication protocol to transmit system information and control signals. It enables the online and real-time training of distributed MADRL algorithms for power system dynamic control. The effectiveness and advantages of the proposed platform have been validated through detailed case studies of testing distributed MADRL algorithms for classical power system control problems.},
  archive      = {J_NCA},
  author       = {Zhen, Fan and Zhenghong, Tu and Wenxin, Liu},
  doi          = {10.1007/s00521-024-10488-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24561-24574},
  shortjournal = {Neural Comput. Appl.},
  title        = {Online multi-agent deep reinforcement learning platform for distributed real-time dynamic control of power systems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel bi-state deep reinforcement learning approach for SFC placements and deployments. <em>NCA</em>, <em>37</em>(30), 24541-24560. (<a href='https://doi.org/10.1007/s00521-024-10486-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The SFC (service function chain) consists of virtual network function chains (VNFs) that generate provisioned network services on demand. To properly structure a network service, SFC traverses a series of VNFs in a predefined order. Thus, the VNF placement problem has become surrounded by other constraints that enshrine the order of VNFs according to their chain type. This restriction requires a method of extracting the best and shortest traffic from a chain of VNFs while considering duplication of the same kind of VNF. In this context, we propose to study and solve the problem of VNF placement and chaining in order to reduce the resources cost and minimize the end-to-end delay (chain of VNFs) while respecting the resources constraints (CPU, memory, and storage) in a multi-instance VNF environment taking into account the bandwidth (traffic congestion). To address these problems, we propose an ILP modeling and a novel model of classification named parallel bistate module deep reinforcement learning (PBDRL) algorithm. This algorithm is based on two modules: The first is MDP (Markov decision process) which is used to capture service chain state transition, and the second is LSTM (long short-term memory) which enables to detection of the long-term history of the service chain and its transitions. Our proposal aims to extract the characteristics of the VNF environment through MDP and LSTM simultaneously taking into account the dynamicity and history of the NFV environment. Simulation results show that our approach achieved $$47\%$$ more reward than VNF deep approach and $$52\%$$ than first-fit algorithm.},
  archive      = {J_NCA},
  author       = {Khemili, Wided and Saidi, Mohand Yazid and Hajlaoui, Jalel Eddine and Omri, Mohamed Nazih and Chen, Ken},
  doi          = {10.1007/s00521-024-10486-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24541-24560},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parallel bi-state deep reinforcement learning approach for SFC placements and deployments},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADP-based nonlinear optimal output regulation with nonlinear exosystem. <em>NCA</em>, <em>37</em>(30), 24531-24539. (<a href='https://doi.org/10.1007/s00521-023-09253-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the optimal output regulation problem for nonlinear systems with a nonlinear exosystem. Adaptive dynamic programming and internal model principle are integrated to deal with this problem. The control scheme process is designed in the following two steps. In the first step, a nonlinear internal model is constructed to obtain the feedforward controller, which allows for the conversion of the output regulation problem into a stabilization problem. Compared with feedforward design approach, the common assumption that the exosystem is linear and neutral stable has been eliminated successfully. In the second step, the control cost is taken into account and the optimal feedback controller is learned through adaptive dynamic programming. After that, we demonstrate that the closed-loop system is uniformly ultimately bounded by the Lyapunov stability theory. As a distinctive feature, the proposed control framework can tolerate the nonlinear exosystem. Finally, the effectiveness of the control scheme is shown by a simulation example.},
  archive      = {J_NCA},
  author       = {Jiang, Haoan and Jin, Peng and Ma, Qian and Zhou, Guopeng and Miao, Guoying},
  doi          = {10.1007/s00521-023-09253-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24531-24539},
  shortjournal = {Neural Comput. Appl.},
  title        = {ADP-based nonlinear optimal output regulation with nonlinear exosystem},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered synchronization adaptive learning control of nonlinear multi-agent systems with resilience to communication link faults. <em>NCA</em>, <em>37</em>(30), 24517-24530. (<a href='https://doi.org/10.1007/s00521-023-09215-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to propose an event-triggered synchronization adaptive learning scheme for uncertain nonlinear multi-agent systems with communication link faults. In reality, the link faults are ubiquitous and responsible for modeling delays and disturbances in communications and also capturing time-varying communication weights between any two nodes in the network. To address this challenge, based on Lyapunov analysis, adaptive learning neural networks are employed to settle unknown link faults and system uncertainties. To reduce the consumption of communication resources, an event-triggered control strategy is introduced on the input side of the controller, whose triggering events are relative thresholds that can be spontaneously modified with the system states. In addition, a set of smooth functions are inserted in the Lyapunov function that assure the asymptotic stability of the system even with corrupted link faults. Meanwhile, it is rigorously verified that the synchronous tracking errors converge to a user-defined interval. Finally, the effectiveness of the proposed control protocol is demonstrated by a numerical simulation.},
  archive      = {J_NCA},
  author       = {Zheng, Zhiyang and Chen, Ci and Xie, Kan and Li, Zhenni and Xie, Shengli},
  doi          = {10.1007/s00521-023-09215-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24517-24530},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered synchronization adaptive learning control of nonlinear multi-agent systems with resilience to communication link faults},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive road shoulder traffic control with reinforcement learning approach. <em>NCA</em>, <em>37</em>(30), 24499-24515. (<a href='https://doi.org/10.1007/s00521-023-09134-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce traffic congestion on the highway, variable speed limits, flow control, and traffic light are used in the current traffic control system. Other strategies for easing traffic congestion include controlling the number of vehicles entering the highway by setting up traffic lights on the ramp and extending the number of lanes by opening the shoulder. Although opening the road shoulder to digest the traffic congestion seems to be very efficient, the current system only opens the road shoulder at a fixed schedule. In this research, we proposed a Reinforcement Learning Approach for Adaptive Road Shoulder Traffic Control (ARSTC) to dynamically change the opening and closing time of the road shoulder. The proposed ARSTC technique is able to adjust to different traffic situations and make a suitable decision that is different from the traditional static scheduling approach for opening the road shoulder. The proposed technique is simulated in the Simulation of Urban Mobility. The results showed that ARSTC can reduce traffic congestion time by adaptively controlling the hard shoulders’ opening time and the traffic flow. Our proposed technique (ARSTC) is able to provide safer and more efficient driving conditions while using the hard shoulder to ease traffic congestion.},
  archive      = {J_NCA},
  author       = {Ho, Yao-Hua and Cheng, Tung-Chun},
  doi          = {10.1007/s00521-023-09134-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {24499-24515},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive road shoulder traffic control with reinforcement learning approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
