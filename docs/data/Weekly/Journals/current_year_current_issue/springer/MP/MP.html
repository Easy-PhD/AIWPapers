<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MP</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mp">MP - 31</h2>
<ul>
<li><details>
<summary>
(2025). Correction: Regular packing of rooted hyperforests with root constraints in hypergraphs. <em>MP</em>, <em>213</em>(1), 1279. (<a href='https://doi.org/10.1007/s10107-025-02203-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Hoppenot, Pierre and Martin, Mathis and Szigeti, Zoltán},
  doi          = {10.1007/s10107-025-02203-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1279},
  shortjournal = {Math. Program.},
  title        = {Correction: Regular packing of rooted hyperforests with root constraints in hypergraphs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean robust optimization. <em>MP</em>, <em>213</em>(1), 1235-1277. (<a href='https://doi.org/10.1007/s10107-024-02170-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization is a tractable and expressive technique for decision-making under uncertainty, but it can lead to overly conservative decisions when pessimistic assumptions are made on the uncertain parameters. Wasserstein distributionally robust optimization can reduce conservatism by being data-driven, but it often leads to very large problems with prohibitive solution times. We introduce mean robust optimization, a general framework that combines the best of both worlds by providing a trade-off between computational effort and conservatism. We propose uncertainty sets constructed based on clustered data rather than on observed data points directly thereby significantly reducing problem size. By varying the number of clusters, our method bridges between robust and Wasserstein distributionally robust optimization. We show finite-sample performance guarantees and explicitly control the potential additional pessimism introduced by any clustering procedure. In addition, we prove conditions for which, when the uncertainty enters linearly in the constraints, clustering does not affect the optimal solution. We illustrate the efficiency and performance preservation of our method on several numerical examples, obtaining multiple orders of magnitude speedups in solution time with little-to-no effect on the solution quality.},
  archive      = {J_MP},
  author       = {Wang, Irina and Becker, Cole and Van Parys, Bart and Stellato, Bartolomeo},
  doi          = {10.1007/s10107-024-02170-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1235-1277},
  shortjournal = {Math. Program.},
  title        = {Mean robust optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regular packing of rooted hyperforests with root constraints in hypergraphs. <em>MP</em>, <em>213</em>(1), 1211-1233. (<a href='https://doi.org/10.1007/s10107-024-02167-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seminal papers of Edmonds (Combinatorial algorithms, Academic Press, New York, 1973), Nash-Williams (J Lond Math Soc 36:445–450, 1961) and Tutte (J Lond Math Soc 36:221–230, 1961) have laid the foundations of the theories of packing arborescences and packing trees. The directed version has been extensively investigated, resulting in a great number of generalizations. In contrast, the undirected version has been marginally considered. The aim of this paper is to further develop the theories of packing trees and forests. Our main result on graphs characterizes the existence of a packing of k forests, $$F_1, \ldots , F_k$$ , in a graph G such that each vertex of G belongs to exactly h of the forests, the number of connected components of each $$F_i$$ is between $$\ell (i)$$ and $$\ell '(i)$$ and the total number of connected components in the packing is between $$\alpha $$ and $$\beta $$ . Finally, we extend this result to hypergraphs and dypergraphs, the latter giving a generalization of a theorem of Bérczi and Frank (Math Oper Res 43(3):726–753, 2018). As a matter of fact, this research was motivated by the paper of Bérczi and Frank (Math Oper Res 43(3):726–753, 2018).},
  archive      = {J_MP},
  author       = {Hoppenot, Pierre and Martin, Mathis and Szigeti, Zoltán},
  doi          = {10.1007/s10107-024-02167-z},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1211-1233},
  shortjournal = {Math. Program.},
  title        = {Regular packing of rooted hyperforests with root constraints in hypergraphs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On rank-monotone graph operations and minimal obstruction graphs for the Lovász–Schrijver SDP hierarchy. <em>MP</em>, <em>213</em>(1), 1169-1209. (<a href='https://doi.org/10.1007/s10107-024-02166-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the lift-and-project rank of the stable set polytopes of graphs with respect to the Lovász–Schrijver SDP operator $${{\,\textrm{LS}\,}}_+$$ , with a particular focus on finding and characterizing the smallest graphs with a given $${{\,\textrm{LS}\,}}_+$$ -rank (the needed number of iterations of the $${{\,\textrm{LS}\,}}_+$$ operator on the fractional stable set polytope to compute the stable set polytope). We introduce a generalized vertex-stretching operation that appears to be promising in generating $${{\,\textrm{LS}\,}}_+$$ -minimal graphs and study its properties. We also provide several new $${{\,\textrm{LS}\,}}_+$$ -minimal graphs, most notably the first known instances of 12-vertex graphs with $${{\,\textrm{LS}\,}}_+$$ -rank 4, which provides the first advance in this direction since Escalante, Montelar, and Nasini’s discovery of a 9-vertex graph with $${{\,\textrm{LS}\,}}_+$$ -rank 3 in 2006.},
  archive      = {J_MP},
  author       = {Au, Yu Hin and Tunçel, Levent},
  doi          = {10.1007/s10107-024-02166-0},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1169-1209},
  shortjournal = {Math. Program.},
  title        = {On rank-monotone graph operations and minimal obstruction graphs for the Lovász–Schrijver SDP hierarchy},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying low rank approximations of third order symmetric tensors. <em>MP</em>, <em>213</em>(1), 1119-1168. (<a href='https://doi.org/10.1007/s10107-024-02165-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a method to certify the approximation quality of a low rank tensor to a given third order symmetric tensor. Under mild assumptions, best low rank approximation is attained if a control parameter is zero or quantified quasi-optimal low rank approximation is obtained if the control parameter is positive. This is based on a primal-dual method for computing a low rank approximation for a given tensor. The certification is derived from the global optimality of the primal and dual problems, and is characterized by easily checkable relations between the primal and the dual solutions together with another rank condition. The theory is verified theoretically for orthogonally decomposable tensors as well as numerically through examples in the general case.},
  archive      = {J_MP},
  author       = {Hu, Shenglong and Sun, Defeng and Toh, Kim-Chuan},
  doi          = {10.1007/s10107-024-02165-1},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1119-1168},
  shortjournal = {Math. Program.},
  title        = {Quantifying low rank approximations of third order symmetric tensors},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acceleration by stepsize hedging: Silver stepsize schedule for smooth convex optimization. <em>MP</em>, <em>213</em>(1), 1105-1118. (<a href='https://doi.org/10.1007/s10107-024-02164-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a concise, self-contained proof that the Silver Stepsize Schedule proposed in our companion paper directly applies to smooth (non-strongly) convex optimization. Specifically, we show that with these stepsizes, gradient descent computes an $$\varepsilon $$ -minimizer in $$O(\varepsilon ^{-\log _{\rho } 2}) = O(\varepsilon ^{-0.7864})$$ iterations, where $$\rho = 1+\sqrt{2}$$ is the silver ratio. This is intermediate between the textbook unaccelerated rate $$O(\varepsilon ^{-1})$$ and the accelerated rate $$O(\varepsilon ^{-1/2})$$ due to Nesterov in 1983. The Silver Stepsize Schedule is a simple explicit fractal: the i-th stepsize is $$1 + \rho ^{\nu (i)-1}$$ where $$\nu (i)$$ is the 2-adic valuation of i. The design and analysis are conceptually identical to the strongly convex setting in our companion paper, but simplify remarkably in this specific setting.},
  archive      = {J_MP},
  author       = {Altschuler, Jason M. and Parrilo, Pablo A.},
  doi          = {10.1007/s10107-024-02164-2},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1105-1118},
  shortjournal = {Math. Program.},
  title        = {Acceleration by stepsize hedging: Silver stepsize schedule for smooth convex optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A first-order augmented lagrangian method for constrained minimax optimization. <em>MP</em>, <em>213</em>(1), 1063-1104. (<a href='https://doi.org/10.1007/s10107-024-02163-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a class of constrained minimax problems. In particular, we propose a first-order augmented Lagrangian method for solving them, whose subproblems turn out to be a much simpler structured minimax problem and are suitably solved by a first-order method developed in this paper. Under some suitable assumptions, an operation complexity of $$\mathcal{O}(\varepsilon ^{-4}\log \varepsilon ^{-1})$$ , measured by its fundamental operations, is established for the first-order augmented Lagrangian method for finding an $$\varepsilon $$ -KKT solution of the constrained minimax problems.},
  archive      = {J_MP},
  author       = {Lu, Zhaosong and Mei, Sanyou},
  doi          = {10.1007/s10107-024-02163-3},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1063-1104},
  shortjournal = {Math. Program.},
  title        = {A first-order augmented lagrangian method for constrained minimax optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended formulations for binary optimal control problems. <em>MP</em>, <em>213</em>(1), 1039-1062. (<a href='https://doi.org/10.1007/s10107-024-02162-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extended formulations are an important tool in polyhedral combinatorics. Many combinatorial optimization problems require an exponential number of inequalities when modeled as a linear program in the natural space of variables. However, by adding artificial variables, one can often find a small linear formulation, i.e., one containing a polynomial number of variables and constraints, such that the projection to the original space of variables yields a perfect linear formulation. Motivated by binary optimal control problems with switching constraints, we show that a similar approach can be useful also for optimization problems in function space, in order to model the closed convex hull of feasible controls in a compact way. More specifically, we present small extended formulations for switches with bounded variation and for dwell-time constraints. For general linear switching point constraints, we devise an extended model linearizing the problem, but show that a small extended formulation that is compatible with discretization cannot exist unless P = NP.},
  archive      = {J_MP},
  author       = {Buchheim, Christoph},
  doi          = {10.1007/s10107-024-02162-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1039-1062},
  shortjournal = {Math. Program.},
  title        = {Extended formulations for binary optimal control problems},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved global guarantees for the nonconvex Burer–Monteiro factorization via rank overparameterization. <em>MP</em>, <em>213</em>(1), 1009-1038. (<a href='https://doi.org/10.1007/s10107-024-02160-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider minimizing a twice-differentiable, L-smooth, and $$\mu $$ -strongly convex objective $$\phi $$ over an $$n\times n$$ positive semidefinite matrix $$M\succeq 0$$ , under the assumption that the minimizer $$M^{\star }$$ has low rank $$r^{\star }\ll n$$ . Following the Burer–Monteiro approach, we instead minimize the nonconvex objective $$f(X)=\phi (XX^{T})$$ over a factor matrix X of size $$n\times r$$ . This substantially reduces the number of variables from $$O(n^{2})$$ to as few as O(n) and also enforces positive semidefiniteness for free, but at the cost of giving up the convexity of the original problem. In this paper, we prove that if the search rank $$r\ge r^{\star }$$ is overparameterized by a constant factor with respect to the true rank $$r^{\star }$$ , namely as in $$r>\frac{1}{4}(L/\mu -1)^{2}r^{\star }$$ , then despite nonconvexity, local optimization is guaranteed to globally converge from any initial point to the global optimum. This significantly improves upon a previous rank overparameterization threshold of $$r\ge n$$ , which we show is sharp in the absence of smoothness and strong convexity, but would increase the number of variables back up to $$O(n^{2})$$ . Conversely, without rank overparameterization, we prove that such a global guarantee is possible if and only if $$\phi $$ is almost perfectly conditioned, with a condition number of $$L/\mu <3$$ . Therefore, we conclude that a small amount of overparameterization can lead to large improvements in theoretical guarantees for the nonconvex Burer–Monteiro factorization.},
  archive      = {J_MP},
  author       = {Zhang, Richard Y.},
  doi          = {10.1007/s10107-024-02160-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1009-1038},
  shortjournal = {Math. Program.},
  title        = {Improved global guarantees for the nonconvex Burer–Monteiro factorization via rank overparameterization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact and approximation algorithms for routing a convoy through a graph. <em>MP</em>, <em>213</em>(1), 985-1008. (<a href='https://doi.org/10.1007/s10107-024-02159-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study routing problems of a convoy in a graph, generalizing the shortest path problem (SPP), the travelling salesperson problem (TSP), and the Chinese postman problem (CPP) which are all well-studied in the classical (non-convoy) setting. We assume that each edge in the graph has a length and a speed at which it can be traversed and that our convoy has a given length. While the convoy moves through the graph, parts of it can be located on different edges. For safety requirements, at all time the whole convoy needs to travel at the same speed which is dictated by the slowest edge on which currently a part of the convoy is located. For Convoy-SPP, we give a strongly polynomial time exact algorithm. For Convoy-TSP, we provide an $$O(\log n)$$ -approximation algorithm and an O(1)-approximation algorithm for trees. Both results carry over to Convoy-CPP which—maybe surprisingly—we prove to be $$\textsf{NP}$$ -hard in the convoy setting. This contrasts the non-convoy setting in which the problem is polynomial time solvable.},
  archive      = {J_MP},
  author       = {van Ee, Martijn and Oosterwijk, Tim and Sitters, René and Wiese, Andreas},
  doi          = {10.1007/s10107-024-02159-z},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {985-1008},
  shortjournal = {Math. Program.},
  title        = {Exact and approximation algorithms for routing a convoy through a graph},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algebraic combinatorial optimization on the degree of determinants of noncommutative symbolic matrices. <em>MP</em>, <em>213</em>(1), 941-984. (<a href='https://doi.org/10.1007/s10107-024-02158-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the computation of the degrees of minors of a noncommutative symbolic matrix of form $$ A[c] :=\sum _{k=1}^m A_k t^{c_k} x_k, $$ where $$A_k$$ are matrices over a field $$\mathbb {K}$$ , $$x_k$$ are noncommutative variables, $$c_k$$ are integer weights, and t is a commuting variable specifying the degree. This problem extends noncommutative Edmonds’ problem (Ivanyos et al. in Comput Complex 26:717–763, 2017), and can formulate various combinatorial optimization problems. Extending the study by Hirai 2018, and Hirai, Ikeda 2022, we provide novel duality theorems and polyhedral characterization for the maximum degrees of minors of A[c] of all sizes, and develop a strongly polynomial-time algorithm for computing them. This algorithm is viewed as a unified algebraization of the classical Hungarian method for bipartite matching and the weight-splitting algorithm for linear matroid intersection. As applications, we provide polynomial-time algorithms for weighted fractional linear matroid matching and for membership of rank-2 Brascamp–Lieb polytopes.},
  archive      = {J_MP},
  author       = {Hirai, Hiroshi and Iwamasa, Yuni and Oki, Taihei and Soma, Tasuku},
  doi          = {10.1007/s10107-024-02158-0},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {941-984},
  shortjournal = {Math. Program.},
  title        = {Algebraic combinatorial optimization on the degree of determinants of noncommutative symbolic matrices},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A projection-free method for solving convex bilevel optimization problems. <em>MP</em>, <em>213</em>(1), 907-940. (<a href='https://doi.org/10.1007/s10107-024-02157-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When faced with multiple minima of an inner-level convex optimization problem, the convex bilevel optimization problem selects an optimal solution which also minimizes an auxiliary outer-level convex objective of interest. Bilevel optimization requires a different approach compared to single-level optimization problems since the set of minimizers for the inner-level objective is not given explicitly. In this paper, we propose a new projection-free conditional gradient method for convex bilevel optimization which requires only a linear optimization oracle over the base domain. We establish $$O(t^{-1/2})$$ convergence rate guarantees for our method in terms of both inner- and outer-level objectives, and demonstrate how additional assumptions such as quadratic growth and strong convexity result in accelerated rates of up to $$O(t^{-1})$$ and $$O(t^{-2/3})$$ for inner- and outer-levels respectively. Lastly, we conduct a numerical study to demonstrate the performance of our method.},
  archive      = {J_MP},
  author       = {Giang-Tran, Khanh-Hung and Ho-Nguyen, Nam and Lee, Dabeen},
  doi          = {10.1007/s10107-024-02157-1},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {907-940},
  shortjournal = {Math. Program.},
  title        = {A projection-free method for solving convex bilevel optimization problems},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Riemannian trust-region methods for strict saddle functions with complexity guarantees. <em>MP</em>, <em>213</em>(1), 863-905. (<a href='https://doi.org/10.1007/s10107-024-02156-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of minimizing a nonconvex function is in part explained by the presence of saddle points. This slows down optimization algorithms and impacts worst-case complexity guarantees. However, many nonconvex problems of interest possess a favorable structure for optimization, in the sense that saddle points can be escaped efficiently by appropriate algorithms. This strict saddle property has been extensively used in data science to derive good properties for first-order algorithms, such as convergence to second-order critical points. However, the analysis and the design of second-order algorithms in the strict saddle setting have received significantly less attention. In this paper, we consider second-order trust-region methods for a class of strict saddle functions defined on Riemannian manifolds. These functions exhibit (geodesic) strong convexity around minimizers and negative curvature at saddle points. We first show that the standard trust-region method with exact subproblem minimization finds an approximate local minimizer in a number of iterations that depends logarithmically on the accuracy parameter, which significantly improves known results for general nonconvex optimization. We then propose a new inexact variant of the algorithm that explicitly leverages the strict saddle property to compute the most appropriate step at every iteration. Our bounds for the inexact variant also improve over the general nonconvex case, and illustrate the benefit of using strict saddle properties within optimization algorithms.},
  archive      = {J_MP},
  author       = {Goyens, Florentin and Royer, Clément W.},
  doi          = {10.1007/s10107-024-02156-2},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {863-905},
  shortjournal = {Math. Program.},
  title        = {Riemannian trust-region methods for strict saddle functions with complexity guarantees},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From coordinate subspaces over finite fields to ideal multipartite uniform clutters. <em>MP</em>, <em>213</em>(1), 823-861. (<a href='https://doi.org/10.1007/s10107-024-02155-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Take a prime power q, an integer $$n\ge 2$$ , and a coordinate subspace $$S\subseteq GF(q)^n$$ over the Galois field GF(q). One can associate with S an n-partite n-uniform clutter $$\mathcal {C}$$ , where every part has size q and there is a bijection between the vectors in S and the members of $$\mathcal {C}$$ . In this paper, we determine when the clutter $$\mathcal {C}$$ is ideal, a property developed in connection to Packing and Covering problems in the areas of Integer Programming and Combinatorial Optimization. Interestingly, the characterization differs depending on whether q is 2, 4, a higher power of 2, or otherwise. Each characterization uses crucially that idealness is a minor-closed property: first the list of excluded minors is identified, and only then is the global structure determined. A key insight is that idealness of $$\mathcal {C}$$ depends solely on the underlying matroid of S. Our theorems also extend from idealness to the stronger max-flow min-cut property. As a consequence, we prove the Replication and $$\tau =2$$ Conjectures for this class of clutters.},
  archive      = {J_MP},
  author       = {Abdi, Ahmad and Lee, Dabeen},
  doi          = {10.1007/s10107-024-02155-3},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {823-861},
  shortjournal = {Math. Program.},
  title        = {From coordinate subspaces over finite fields to ideal multipartite uniform clutters},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated-gradient-based generalized Levenberg–Marquardt method with oracle complexity bound and local quadratic convergence. <em>MP</em>, <em>213</em>(1), 771-822. (<a href='https://doi.org/10.1007/s10107-024-02154-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing the sum of a convex function and a composite function appears in various fields. The generalized Levenberg–Marquardt (LM) method, also known as the prox-linear method, has been developed for such optimization problems. The method iteratively solves strongly convex subproblems with a damping term. This study proposes a new generalized LM method for solving the problem with a smooth composite function. The method enjoys three theoretical guarantees: iteration complexity bound, oracle complexity bound, and local convergence under a Hölderian growth condition. The local convergence results include local quadratic convergence under the quadratic growth condition; this is the first to extend the classical result for least-squares problems to a general smooth composite function. In addition, this is the first LM method with both an oracle complexity bound and local quadratic convergence under standard assumptions. These results are achieved by carefully controlling the damping parameter and solving the subproblems by the accelerated proximal gradient method equipped with a particular termination condition. Experimental results show that the proposed method performs well in practice for several instances, including classification with a neural network and nonnegative matrix factorization.},
  archive      = {J_MP},
  author       = {Marumo, Naoki and Okuno, Takayuki and Takeda, Akiko},
  doi          = {10.1007/s10107-024-02154-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {771-822},
  shortjournal = {Math. Program.},
  title        = {Accelerated-gradient-based generalized Levenberg–Marquardt method with oracle complexity bound and local quadratic convergence},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural spectrahedra and semidefinite lifts: Global convex optimization of degree-two polynomial activation neural networks in polynomial-time. <em>MP</em>, <em>213</em>(1), 737-769. (<a href='https://doi.org/10.1007/s10107-024-02153-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training of two-layer neural networks with nonlinear activation functions is an important non-convex optimization problem with numerous applications and promising performance in layerwise deep learning. In this paper, we develop exact convex optimization formulations for two-layer neural networks with second degree polynomial activations based on dual relaxations and semidefinite programming. Remarkably, we show that our semidefinite relaxations are always tight. Therefore, the computational complexity for global optimization is polynomial in the input dimension and sample size for all input data. The developed convex formulations are proven to achieve the same globally optimal solution set as their non-convex counterparts. Specifically, globally optimal two-layer neural networks with degree-two polynomial activations can be found by solving a semidefinite program (SDP) and decomposing the solution using a procedure we call Neural Decomposition. Moreover, the choice of regularizers plays a crucial role in the computational tractability of neural network training. We show that the standard weight decay regularization formulation is NP-hard, whereas other simple convex penalties render the problem tractable in polynomial time via convex programming. The techniques go beyond the fully connected architecture to encompass various neural network structures including those with vector outputs and convolutional architectures. We provide extensive numerical simulations showing that the standard backpropagation approach often fails to achieve the global optimum of the training loss. The proposed approach is significantly faster to obtain better test accuracy compared to the standard backpropagation procedure.},
  archive      = {J_MP},
  author       = {Bartan, Burak and Pilanci, Mert},
  doi          = {10.1007/s10107-024-02153-5},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {737-769},
  shortjournal = {Math. Program.},
  title        = {Neural spectrahedra and semidefinite lifts: Global convex optimization of degree-two polynomial activation neural networks in polynomial-time},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The mixed integer trust region problem. <em>MP</em>, <em>213</em>(1), 699-736. (<a href='https://doi.org/10.1007/s10107-024-02152-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the problem of minimizing a general quadratic function over the mixed integer points in an ellipsoid. This problem is strongly NP-hard, NP-hard to approximate within a constant factor, and optimal solutions can be irrational. In our main result we show that an arbitrarily good solution can be found in polynomial time, if we fix the number of integer variables. This algorithm provides a natural extension to the mixed integer setting, of the polynomial solvability of the trust region problem proven by Ye, Karmarkar, Vavasis, and Zippel. As a result, our findings pave the way for designing efficient trust region methods for mixed integer nonlinear optimization problems. The techniques that we introduce are of independent interest and can be used in other mixed integer nonlinear optimization problems. As an example, we consider the problem of minimizing a general quadratic function over the mixed integer points in a polyhedron. For this problem, we show that a solution satisfying weak bounds with respect to optimality can be computed in polynomial time, provided that the number of integer variables is fixed. It is well known that finding a solution satisfying stronger bounds cannot be done in polynomial time, unless P = NP.},
  archive      = {J_MP},
  author       = {Del Pia, Alberto},
  doi          = {10.1007/s10107-024-02152-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {699-736},
  shortjournal = {Math. Program.},
  title        = {The mixed integer trust region problem},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear distributionally robust optimization. <em>MP</em>, <em>213</em>(1), 639-698. (<a href='https://doi.org/10.1007/s10107-024-02151-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on a class of distributionally robust optimization (DRO) problems where, unlike the growing body of the literature, the objective function is potentially nonlinear in the distribution. Existing methods to optimize nonlinear functions in probability space use the Frechet derivatives, which present both theoretical and computational challenges. Motivated by this, we propose an alternative notion for the derivative and corresponding smoothness based on Gateaux (G)-derivative for generic risk measures. These concepts are explained via three running risk measure examples of variance, entropic risk, and risk on finite support sets. We then propose a G-derivative based Frank–Wolfe (FW) algorithm for generic nonlinear optimization problems in probability spaces and establish its convergence under the proposed notion of smoothness in a completely norm-independent manner. We use the set-up of the FW algorithm to devise a methodology to compute a saddle point of the nonlinear DRO problem. Finally, we validate our theoretical results on two cases of the entropic and variance risk measures in the context of portfolio selection problems. In particular, we analyze their regularity conditions and “sufficient statistic”, compute the respective FW-oracle in various settings, and confirm the theoretical outcomes through numerical validation.},
  archive      = {J_MP},
  author       = {Sheriff, Mohammed Rayyan and Mohajerin Esfahani, Peyman},
  doi          = {10.1007/s10107-024-02151-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {639-698},
  shortjournal = {Math. Program.},
  title        = {Nonlinear distributionally robust optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALSO-x#: Better convex approximations for distributionally robust chance constrained programs. <em>MP</em>, <em>213</em>(1), 575-638. (<a href='https://doi.org/10.1007/s10107-024-02150-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies distributionally robust chance constrained programs (DRCCPs), where the uncertain constraints must be satisfied with at least a probability of a prespecified threshold for all probability distributions from the Wasserstein ambiguity set. As DRCCPs are often nonconvex and some DRCCPs may not have mixed-integer reformulations, researchers have been developing various convex inner approximations. Recently, ALSO-X has been proven to outperform the conditional value-at-risk (CVaR) approximation of a regular chance constrained program when the deterministic set is convex. In this work, we relax this assumption by introducing a new ALSO-X# method to solve DRCCPs. Namely, in the bilevel structures of ALSO-X and CVaR approximation, we observe that the lower-level ALSO-X is a special case of the lower-level CVaR approximation, and the upper-level CVaR approximation is more restricted than the one in ALSO-X. This observation motivates us to propose ALSO-X#, which has a bilevel structure—in the lower-level problem, we adopt the more general CVaR approximation, and for the upper-level one, we choose the less restricted ALSO-X. We show that ALSO-X# is always better than CVaR approximation and can outperform ALSO-X under regular chance constrained programs and type $$\infty $$ -Wasserstein ambiguity set. We also provide new sufficient conditions under which ALSO-X# outputs an optimal solution to a DRCCP. We apply ALSO-X# to a wireless communication problem and numerically demonstrate that the solution quality can be even better than the exact method.},
  archive      = {J_MP},
  author       = {Jiang, Nan and Xie, Weijun},
  doi          = {10.1007/s10107-024-02150-8},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {575-638},
  shortjournal = {Math. Program.},
  title        = {ALSO-x#: Better convex approximations for distributionally robust chance constrained programs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of trigonometric polynomials with crystallographic symmetry and spectral bounds for set avoiding graphs. <em>MP</em>, <em>213</em>(1), 517-573. (<a href='https://doi.org/10.1007/s10107-024-02149-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a new approach to the optimization of trigonometric polynomials with crystallographic symmetry. This approach widens the bridge between trigonometric and polynomial optimization. The trigonometric polynomials considered are supported on weight lattices associated to crystallographic root systems and are assumed invariant under the associated reflection group. On one hand the invariance allows us to rewrite the objective function in terms of generalized Chebyshev polynomials of the generalized cosines; On the other hand the generalized cosines parameterize a compact basic semi algebraic set, this latter being given by an explicit polynomial matrix inequality. The initial problem thus boils down to a polynomial optimization problem that is straightforwardly written in terms of generalized Chebyshev polynomials. The minimum is to be computed by a converging sequence of lower bounds as given by a hierarchy of relaxations based on the Hol–Scherer Positivstellensatz and indexed by the weighted degree associated to the root system. This new method for trigonometric optimization was motivated by its application to estimate the spectral bound on the chromatic number of set avoiding graphs. We examine cases of the literature where the avoided set affords crystallographic symmetry. In some cases we obtain new analytic proofs for sharp bounds on the chromatic number while in others we compute new lower bounds numerically.},
  archive      = {J_MP},
  author       = {Hubert, Evelyne and Metzlaff, Tobias and Moustrou, Philippe and Riener, Cordian},
  doi          = {10.1007/s10107-024-02149-1},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {517-573},
  shortjournal = {Math. Program.},
  title        = {Optimization of trigonometric polynomials with crystallographic symmetry and spectral bounds for set avoiding graphs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dyadic linear programming and extensions. <em>MP</em>, <em>213</em>(1), 473-516. (<a href='https://doi.org/10.1007/s10107-024-02146-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rational number is dyadic if it has a finite binary representation $$p/2^k$$ , where p is an integer and k is a nonnegative integer. Dyadic rationals are important for numerical computations because they have an exact representation in floating-point arithmetic on a computer. A vector is dyadic if all its entries are dyadic rationals. We study the problem of finding a dyadic optimal solution to a linear program, if one exists. We show how to solve dyadic linear programs in polynomial time. We give bounds on the size of the support of a solution as well as on the size of the denominators. We identify properties that make the solution of dyadic linear programs possible: closure under addition and negation, and density, and we extend the algorithmic framework beyond the dyadic case.},
  archive      = {J_MP},
  author       = {Abdi, Ahmad and Cornuéjols, Gérard and Guenin, Bertrand and Tunçel, Levent},
  doi          = {10.1007/s10107-024-02146-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {473-516},
  shortjournal = {Math. Program.},
  title        = {Dyadic linear programming and extensions},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive proximal algorithms for convex optimization under local lipschitz continuity of the gradient. <em>MP</em>, <em>213</em>(1), 433-471. (<a href='https://doi.org/10.1007/s10107-024-02143-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backtracking linesearch is the de facto approach for minimizing continuously differentiable functions with locally Lipschitz gradient. In recent years, it has been shown that in the convex setting it is possible to avoid linesearch altogether, and to allow the stepsize to adapt based on a local smoothness estimate without any backtracks or evaluations of the function value. In this work we propose an adaptive proximal gradient method, adaPGM, that uses novel estimates of the local smoothness modulus which leads to less conservative stepsize updates and that can additionally cope with nonsmooth terms. This idea is extended to the primal-dual setting where an adaptive three-term primal-dual algorithm, adaPDM, is proposed which can be viewed as an extension of the PDHG method. Moreover, in this setting the “essentially” fully adaptive variant $$\textsf {adaPDM}^{\textsf {+}}$$ is proposed that avoids evaluating the linear operator norm by invoking a backtracking procedure, that, remarkably, does not require extra gradient evaluations. Numerical simulations demonstrate the effectiveness of the proposed algorithms compared to the state of the art.},
  archive      = {J_MP},
  author       = {Latafat, Puya and Themelis, Andreas and Stella, Lorenzo and Patrinos, Panagiotis},
  doi          = {10.1007/s10107-024-02143-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {433-471},
  shortjournal = {Math. Program.},
  title        = {Adaptive proximal algorithms for convex optimization under local lipschitz continuity of the gradient},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coderivative-based semi-newton method in nonsmooth difference programming. <em>MP</em>, <em>213</em>(1), 385-432. (<a href='https://doi.org/10.1007/s10107-024-02142-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the study of a new class of nonsmooth optimization problems, where the objective is represented as a difference of two generally nonconvex functions. We propose and develop a novel Newton-type algorithm to solving such problems, which is based on the coderivative generated second-order subdifferential (generalized Hessian) and employs advanced tools of variational analysis. Well-posedness properties of the proposed algorithm are derived under fairly general requirements, while constructive convergence rates are established by using additional assumptions including the Kurdyka–Łojasiewicz condition. We provide applications of the main algorithm to solving a general class of nonsmooth nonconvex problems of structured optimization that encompasses, in particular, optimization problems with explicit constraints. Finally, applications and numerical experiments are given for solving practical problems that arise in biochemical models, supervised learning, constrained quadratic programming, etc., where advantages of our algorithms are demonstrated in comparison with some known techniques and results.},
  archive      = {J_MP},
  author       = {Aragón-Artacho, Francisco J. and Mordukhovich, Boris S. and Pérez-Aros, Pedro},
  doi          = {10.1007/s10107-024-02142-8},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {385-432},
  shortjournal = {Math. Program.},
  title        = {Coderivative-based semi-newton method in nonsmooth difference programming},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast convergence of trust-regions for non-isolated minima via analysis of CG on indefinite matrices. <em>MP</em>, <em>213</em>(1), 343-384. (<a href='https://doi.org/10.1007/s10107-024-02140-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust-region methods (TR) can converge quadratically to minima where the Hessian is positive definite. However, if the minima are not isolated, then the Hessian there cannot be positive definite. The weaker Polyak–Łojasiewicz (PŁ) condition is compatible with non-isolated minima, and it is enough for many algorithms to preserve good local behavior. Yet, TR with an exact subproblem solver lacks even basic features such as a capture theorem under PŁ. In practice, a popular inexact subproblem solver is the truncated conjugate gradient method (tCG). Empirically, TR-tCG exhibits superlinear convergence under PŁ. We confirm this theoretically. The main mathematical obstacle is that, under PŁ, at points arbitrarily close to minima, the Hessian has vanishingly small, possibly negative eigenvalues. Thus, tCG is applied to ill-conditioned, indefinite systems. Yet, the core theory underlying tCG is that of CG, which assumes a positive definite operator. Accordingly, we develop new tools to analyze the dynamics of CG in the presence of small eigenvalues of any sign, for the regime of interest to TR-tCG.},
  archive      = {J_MP},
  author       = {Rebjock, Quentin and Boumal, Nicolas},
  doi          = {10.1007/s10107-024-02140-w},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {343-384},
  shortjournal = {Math. Program.},
  title        = {Fast convergence of trust-regions for non-isolated minima via analysis of CG on indefinite matrices},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The computational complexity of finding stationary points in non-convex optimization. <em>MP</em>, <em>213</em>(1), 281-341. (<a href='https://doi.org/10.1007/s10107-024-02139-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding approximate stationary points, i.e., points where the gradient is approximately zero, of non-convex but smooth objective functions f over unrestricted d-dimensional domains is one of the most fundamental problems in classical non-convex optimization. Nevertheless, the computational and query complexity of this problem are still not well understood when the dimension d of the problem is independent of the approximation error. In this paper, we show the following computational and query complexity results:},
  archive      = {J_MP},
  author       = {Hollender, Alexandros and Zampetakis, Manolis},
  doi          = {10.1007/s10107-024-02139-3},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {281-341},
  shortjournal = {Math. Program.},
  title        = {The computational complexity of finding stationary points in non-convex optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated stochastic approximation with state-dependent noise. <em>MP</em>, <em>213</em>(1), 239-280. (<a href='https://doi.org/10.1007/s10107-024-02138-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of stochastic smooth convex optimization problems under rather general assumptions on the noise in the stochastic gradient observation. As opposed to the classical problem setting in which the variance of noise is assumed to be uniformly bounded, herein we assume that the variance of stochastic gradients is related to the “sub-optimality” of the approximate solutions delivered by the algorithm. Such problems naturally arise in a variety of applications, in particular, in the well-known generalized linear regression problem in statistics. However, to the best of our knowledge, none of the existing stochastic approximation algorithms for solving this class of problems attain optimality in terms of the dependence on accuracy, problem parameters, and mini-batch size. We discuss two non-Euclidean accelerated stochastic approximation routines—stochastic accelerated gradient descent (SAGD) and stochastic gradient extrapolation (SGE)—which carry a particular duality relationship. We show that both SAGD and SGE, under appropriate conditions, achieve the optimal convergence rate, attaining the optimal iteration and sample complexities simultaneously. However, corresponding assumptions for the SGE algorithm are more general; they allow, for instance, for efficient application of the SGE to statistical estimation problems under heavy tail noises and discontinuous score functions. We also discuss the application of the SGE to problems satisfying quadratic growth conditions, and show how it can be used to recover sparse solutions. Finally, we report on some simulation experiments to illustrate numerical performance of our proposed algorithms in high-dimensional settings.},
  archive      = {J_MP},
  author       = {Ilandarideva, Sasila and Juditsky, Anatoli and Lan, Guanghui and Li, Tianjiao},
  doi          = {10.1007/s10107-024-02138-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {239-280},
  shortjournal = {Math. Program.},
  title        = {Accelerated stochastic approximation with state-dependent noise},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complexity of chordal conversion for sparse semidefinite programs with small treewidth. <em>MP</em>, <em>213</em>(1), 201-237. (<a href='https://doi.org/10.1007/s10107-024-02137-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {If a sparse semidefinite program (SDP), specified over $$n\times n$$ matrices and subject to m linear constraints, has an aggregate sparsity graph G with small treewidth, then chordal conversion will sometimes allow an interior-point method to solve the SDP in just $$O(m+n)$$ time per-iteration, which is a significant speedup over the $$\varOmega (n^{3})$$ time per-iteration for a direct application of the interior-point method. Unfortunately, the speedup is not guaranteed by an O(1) treewidth in G that is independent of m and n, as a diagonal SDP would have treewidth zero but can still necessitate up to $$\varOmega (n^{3})$$ time per-iteration. Instead, we construct an extended aggregate sparsity graph $$\overline{G}\supseteq G$$ by forcing each constraint matrix $$A_{i}$$ to be its own clique in G. We prove that a small treewidth in $$\overline{G}$$ does indeed guarantee that chordal conversion will solve the SDP in $$O(m+n)$$ time per-iteration, to $$\epsilon $$ -accuracy in at most $$O(\sqrt{m+n}\log (1/\epsilon ))$$ iterations. This sufficient condition covers many successful applications of chordal conversion, including the MAX-k-CUT relaxation, the Lovász theta problem, sensor network localization, polynomial optimization, and the AC optimal power flow relaxation, thus allowing theory to match practical experience.},
  archive      = {J_MP},
  author       = {Zhang, Richard Y.},
  doi          = {10.1007/s10107-024-02137-5},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {201-237},
  shortjournal = {Math. Program.},
  title        = {Complexity of chordal conversion for sparse semidefinite programs with small treewidth},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast convergence to non-isolated minima: Four equivalent conditions for $${\textrm{C}^{2}}$$ functions. <em>MP</em>, <em>213</em>(1), 151-199. (<a href='https://doi.org/10.1007/s10107-024-02136-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization algorithms can see their local convergence rates deteriorate when the Hessian at the optimum is singular. These singularities are inescapable when the optima are non-isolated. Yet, under the right circumstances, several algorithms preserve their favorable rates even when optima form a continuum (e.g., due to over-parameterization). This has been explained under various structural assumptions, including the Polyak–Łojasiewicz condition, Quadratic Growth and the Error Bound. We show that, for cost functions which are twice continuously differentiable ( $$\textrm{C}^2$$ ), those three (local) properties are equivalent. Moreover, we show they are equivalent to the Morse–Bott property, that is, local minima form differentiable submanifolds, and the Hessian of the cost function is positive definite along its normal directions. We leverage this insight to improve local convergence guarantees for safe-guarded Newton-type methods under any (hence all) of the above assumptions. First, for adaptive cubic regularization, we secure quadratic convergence even with inexact subproblem solvers. Second, for trust-region methods, we argue capture can fail with an exact subproblem solver, then proceed to show linear convergence with an inexact one (Cauchy steps).},
  archive      = {J_MP},
  author       = {Rebjock, Quentin and Boumal, Nicolas},
  doi          = {10.1007/s10107-024-02136-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {151-199},
  shortjournal = {Math. Program.},
  title        = {Fast convergence to non-isolated minima: Four equivalent conditions for $${\textrm{C}^{2}}$$ functions},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convexification techniques for fractional programs. <em>MP</em>, <em>213</em>(1), 107-149. (<a href='https://doi.org/10.1007/s10107-024-02131-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a correspondence relating convex hulls of fractional functions with those of polynomial functions over the same domain. Using this result, we develop a number of new reformulations and relaxations for fractional programming problems. First, we relate $$0\mathord {-}1$$ problems involving a ratio of affine functions with the boolean quadric polytope, and use inequalities for the latter to develop tighter formulations for the former. Second, we derive a new formulation to optimize a ratio of quadratic functions over a polytope using copositive programming. Third, we show that univariate fractional functions can be convexified using moment hulls. Fourth, we develop a new hierarchy of relaxations that converges finitely to the simultaneous convex hull of a collection of ratios of affine functions of $$0\mathord {-}1$$ variables. Finally, we demonstrate theoretically and computationally that our techniques close a significant gap relative to state-of-the-art relaxations, require much less computational effort, and can solve larger problem instances.},
  archive      = {J_MP},
  author       = {He, Taotao and Liu, Siyue and Tawarmalani, Mohit},
  doi          = {10.1007/s10107-024-02131-x},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {107-149},
  shortjournal = {Math. Program.},
  title        = {Convexification techniques for fractional programs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing distortion riskmetrics with distributional uncertainty. <em>MP</em>, <em>213</em>(1), 51-106. (<a href='https://doi.org/10.1007/s10107-024-02128-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization of distortion riskmetrics with distributional uncertainty has wide applications in finance and operations research. Distortion riskmetrics include many commonly applied risk measures and deviation measures, which are not necessarily monotone or convex. One of our central findings is a unifying result that allows to convert an optimization of a non-convex distortion riskmetric with distributional uncertainty to a convex one induced from the concave envelope of the distortion function, leading to practical tractability. A sufficient condition to the unifying equivalence result is the novel notion of closedness under concentration, a variation of which is also shown to be necessary for the equivalence. Our results include many special cases that are well studied in the optimization literature, including but not limited to optimizing probabilities, Value-at-Risk, Expected Shortfall, Yaari’s dual utility, and differences between distortion risk measures, under various forms of distributional uncertainty. We illustrate our theoretical results via applications to portfolio optimization, optimization under moment constraints, and preference robust optimization.},
  archive      = {J_MP},
  author       = {Pesenti, Silvana M. and Wang, Qiuqi and Wang, Ruodu},
  doi          = {10.1007/s10107-024-02128-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {51-106},
  shortjournal = {Math. Program.},
  title        = {Optimizing distortion riskmetrics with distributional uncertainty},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear conjugate gradient methods: Worst-case convergence rates via computer-assisted analyses. <em>MP</em>, <em>213</em>(1), 1-49. (<a href='https://doi.org/10.1007/s10107-024-02127-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a computer-assisted approach to the analysis of the worst-case convergence of nonlinear conjugate gradient methods (NCGMs). Those methods are known for their generally good empirical performances for large-scale optimization, while having relatively incomplete analyses. Using our computer-assisted approach, we establish novel complexity bounds for the Polak-Ribière-Polyak (PRP) and the Fletcher-Reeves (FR) NCGMs for smooth strongly convex minimization. In particular, we construct mathematical proofs that establish the first non-asymptotic convergence bound for FR (which is historically the first developed NCGM), and a much improved non-asymptotic convergence bound for PRP. Additionally, we provide simple adversarial examples on which these methods do not perform better than gradient descent with exact line search, leaving very little room for improvements on the same class of problems.},
  archive      = {J_MP},
  author       = {Das Gupta, Shuvomoy and Freund, Robert M. and Sun, Xu Andy and Taylor, Adrien},
  doi          = {10.1007/s10107-024-02127-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1-49},
  shortjournal = {Math. Program.},
  title        = {Nonlinear conjugate gradient methods: Worst-case convergence rates via computer-assisted analyses},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
