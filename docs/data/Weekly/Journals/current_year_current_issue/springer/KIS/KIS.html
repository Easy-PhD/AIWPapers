<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>KIS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="kis">KIS - 29</h2>
<ul>
<li><details>
<summary>
(2025). SecPPAccess: Secured privacy protection access control on big data in cloud computing paradigm. <em>KIS</em>, <em>67</em>(9), 8195-8218. (<a href='https://doi.org/10.1007/s10115-025-02443-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of cloud computing, preserving the privacy of big data while also allowing for secure access control is a critical concern. With the increasing adoption of cloud technology, it is imperative to address the challenges associated with safeguarding sensitive data while enabling authorized access. This paper develops an efficient privacy-preserving security model that uses cryptographic techniques to protect sensitive data and ensure that only authorized individuals can access it. The research puts together a secure data authentication technique, named secured privacy protection access control (SecPPAccess), allowing secured communication in cloud computing. For the protection of privacy for sensitive data, the protected transferring of data is commenced among the elements, like a user, cloud server, registration authority, key generation center and data owner, by using many phases mainly the key generation phase, setup phase, server registration, user registration, data upload, data encryption, requester authentication, data access, and data download phase. Here, a method is designed newly for securing data privacy using various operations, like secret keys, hashing, encryption, etc. The study proves that the initiated SecPPAccess model achieves the highest rate of detection of 0.85, the lowest usage for memory of 0.505 MB, and less computation time of 51.50 s.},
  archive      = {J_KIS},
  author       = {Gupta, Lalit Mohan and Garg, Hitendra and Samad, Abdus and Singh, Atul Kumar},
  doi          = {10.1007/s10115-025-02443-0},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {8195-8218},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {SecPPAccess: Secured privacy protection access control on big data in cloud computing paradigm},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective and lightweight lossy compression of tensors: Techniques and applications. <em>KIS</em>, <em>67</em>(9), 8143-8193. (<a href='https://doi.org/10.1007/s10115-025-02471-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world data from various domains can be represented as tensors, and a significant portion of them is large scale. Thus, tensor compression is crucial for their storage and transmission. Recently, deep learning-based methods have emerged to enhance compression performance. However, they require considerable compression time to fulfill their performance. In this work, to achieve both speed and performance, we develop ELiCiT, an effective and lightweight lossy tensor compression method. When designing ELiCiT, we avoid deep auto-regressive neural networks and index reordering, which incur high computational costs of deep learning-based tensor compression. Specifically, instead of using the orders of indices as parameters, we introduce a feature-based model for indices, which enhances the model’s expressive capacity and simplifies the overall end-to-end training procedure. Moreover, to reduce the size of the parameters and computational cost for inference, we adopt end-to-end clustering-based quantization, as an alternative to deep auto-regressive architecture. As a result, ELiCiT becomes easy to optimize with enhanced expressiveness. We prove that it (partially) generalizes deep learning-based methods and also traditional ones. Using eight real-world tensors, we show that ELiCiT yields compact outputs that fit the input tensor accurately. Compared to the best competitor with similar fitness, it offers 1.51 $$-$$ 5.05 $$\times $$ smaller outputs. Moreover, compared to deep learning-based compression methods, ELiCiT is 11.8 $$-$$ 96.0 $$\times $$ faster with 5–48% better fitness for a similarly sized output. We also demonstrate that ELiCiT is extended to matrix completion, neural network compression , and tensor stream summarization, providing the best trade-offs between model size and application performance.},
  archive      = {J_KIS},
  author       = {Ko, Jihoon and Kwon, Taehyung and Jung, Jinhong and Shin, Kijung},
  doi          = {10.1007/s10115-025-02471-w},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {8143-8193},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Effective and lightweight lossy compression of tensors: Techniques and applications},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective feature selection and classification technique for palmprint biometric identification systems. <em>KIS</em>, <em>67</em>(9), 8115-8142. (<a href='https://doi.org/10.1007/s10115-025-02478-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palmprint recognition’s outstanding sanitary, non-invasive, and user-friendliness properties have sparked a lot of research attention. The majority of palmprint recognition techniques used today are deep learning approaches, which typically use palmprint images to learn discriminative features. In most cases, considerable labelled samples are needed to perform well enough for identification. Here, we propose employing a deep learning method for palmprint recognition to get around the problems. First, the original picture should be (a) converted to greyscale, (b) cropped and resized, and (c) contrast-enhanced using the contrast-limited adaptive histogram equalization method. Next, use the ConvNeXt approach to extract the most essential characteristics from contrast-enhanced palm pictures. After removing redundant collected attributes, the improved spotted hyena optimizer algorithm selects the most important features. Finally, the deep fuzzy neural network (DFNN) technique determines if the palmprint image matches. Use the sooty tern optimization algorithm for increased identification and categorization accuracy to increase categorization accuracy. The proposed approach effectively reduces the number of attributes and computation time while increasing the accuracy of the optimized DFNN—an approximation of the proposed methods using Tongji, IITD, and CASIA open palmprint datasets. The approach has better accuracy with 99.62%, 99.72%, and 99.67% on IITD, Tongji, and CASIA palmprint databases. Experiments show that our approach achieves a high identification rate while using a substantially fewer number of features.},
  archive      = {J_KIS},
  author       = {Nalamothu, Aravind and Rayachoti, Eswaraiah},
  doi          = {10.1007/s10115-025-02478-3},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {8115-8142},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An effective feature selection and classification technique for palmprint biometric identification systems},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VCGAE++: Variational collective graph autoEncoder for multi-behavior recommendation. <em>KIS</em>, <em>67</em>(9), 8085-8114. (<a href='https://doi.org/10.1007/s10115-025-02467-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational autoencoder (VAE) is known as a classic and effective method in modeling users’ homogeneous behaviors in recommender systems. In recent years, graph neural networks (GNNs) have achieved promising performance in learning users’ preferences by modeling complex relationships between users and items. However, most VAE- and GNN-based methods are for single-behavior recommendation, rather than the more prevalent counterpart in real-world applications, i.e., multi-behavior recommendation. This motivates us to leverage VAE and GNNs to address the more important and challenging problem of multi-behavior recommendation. Traditional multi-behavior recommendation models have not captured the complex transition relationships across different types of behaviors well, ignoring the varying semantic strength of different types of behaviors. In addition, most of them just construct separate behavior-specific subgraphs and learn separate collaborative filtering embeddings, overlooking the information of the global graph. Moreover, existing methods rarely explored how to deal with the sparse data under the target behavior (e.g., purchase). To tackle the above four challenges, we propose a novel multi-behavior recommendation framework named VCGAE++, which inherits the advantages of VCGAE (Variational Collective Graph AutoEncoder) to fully exploit the multi-behavior data and model the high-order relationships to improve the accuracy of the recommendations. Specifically, we design a multi-behavior contrastive learning framework to capture the complex transitions between diverse behaviors. In addition, we design a global graph information fusion network to capture the high-level relationships across different user-item interaction graphs. Extensive experiments on four real-world datasets clearly demonstrate the effectiveness of our VCGAE++ compared with the state-of-the-art methods.},
  archive      = {J_KIS},
  author       = {Zhuang, Yingxuan and Liu, Yang and Pan, Weike and Ming, Zhong},
  doi          = {10.1007/s10115-025-02467-6},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {8085-8114},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {VCGAE++: Variational collective graph autoEncoder for multi-behavior recommendation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task multi-modal graph neural network for recommender system. <em>KIS</em>, <em>67</em>(9), 8059-8084. (<a href='https://doi.org/10.1007/s10115-025-02456-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of online information, users may also face information overload. To handle this problem, recommender systems have become an effective strategy, which can analyze the characters of users and items to provide valuable information. One of the important types of information is the item’s side information. For example, in Amazon dataset, side information mainly includes visual side information (e.g., image and video), textual side information (e.g., title and description), and auxiliary side information (e.g., brand and category). To analyze various types of side information, some research designed multiple modalities for different types of side information, which can improve the performance of the recommender system. To analyze the deeper relationships between users and items, recent works also use a graph structure to represent the interactions. Existing works on multi-modal recommender systems using graph neural networks largely depend on the interaction records, while little effort focuses on the relationships between interactions and various types of side information. In this paper, we propose a novel multi-task learning model. First, we construct the interaction records to graphs for each modality to gather the representations, and then we analyze the representations of each modality and the specific side information based on the similarities. We design a multi-task multi-modal graph neural network framework built upon message passing with the attention mechanism of graph neural networks, which can generate the representations of users and items from interaction records, and then analyze the relationships between the representations from GNNs and item’s side information. We conduct experiments on three public datasets, Amazon, Modcloth and MovieLens. The results of our model outperform the state-of-the-art methods.},
  archive      = {J_KIS},
  author       = {Jiao, Shengzhe and Zhang, Yihong and Hara, Takahiro},
  doi          = {10.1007/s10115-025-02456-9},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {8059-8084},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Multi-task multi-modal graph neural network for recommender system},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view multi-label personalized classification via generalized exclusive sparse tensor factorization. <em>KIS</em>, <em>67</em>(9), 8023-8057. (<a href='https://doi.org/10.1007/s10115-025-02449-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification (MLC) assigns multiple relevant labels to each sample simultaneously, while multi-view MLC aims to apply MLC to handle heterogeneous data represented by multiple feature subsets. In recent years, a variety of methods have been proposed to handle these problems and have achieved great success in a wide range of applications. MLC saves global label correlation by building a single model shared by all samples but ignores sample-specific local structures, while personalized learning (PL) is able to preserve sample-specific information by learning local models but ignores the global structure. Integrating PL with MLC is a straightforward way to overcome the limitations, but it still faces three key challenges. (1) capture both local and global structures in a unified model; (2) efficiently preserve full-order interactions between labels, samples and features or multi-view features in heterogeneous data; (3) learn a concise and interpretable model where only a fraction of interactions are associated with multiple labels. In this paper, we propose a novel Multi-label Personalized Classification (MLPC) method and its multi-view extension to handle these challenges. For (1), it integrates local and global components to preserve sample-specific information and global structure shared across samples, respectively. For (2), a multilinear model is developed to capture full-order label-feature-sample interactions, and over-parameterization is avoided by tensor factorization. For (3), exclusive sparsity regularization penalizes factorization by promoting intra-group competition, thereby eliminating irrelevant and redundant interactions during Exclusive Sparse Tensor Factorization (ESTF). Moreover, theoretical analysis generalizes the proposed ESTF and reveals the equivalence between MLPC and a family of jointly regularized counterparts. We develop an alternating algorithm to solve the optimization problem, and demonstrate its effectiveness based on comprehensive experiments on both synthetic and real-world benchmark datasets.},
  archive      = {J_KIS},
  author       = {Fei, Luhuan and Lin, Weijia and Wang, Jiankun and Sun, Lu and Kudo, Mineichi and Kimura, Keigo},
  doi          = {10.1007/s10115-025-02449-8},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {8023-8057},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Multi-view multi-label personalized classification via generalized exclusive sparse tensor factorization},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond pairwise relationships: A transformer-based hypergraph learning approach for fraud detection. <em>KIS</em>, <em>67</em>(9), 7987-8022. (<a href='https://doi.org/10.1007/s10115-025-02476-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraud detection in online networks has become increasingly challenging as fraudsters adopt sophisticated camouflage tactics to evade detection, making it imperative to combat their deceptive strategies. Graph-based fraud detection has gained significant attention in recent years, reflecting its growing potential to mitigate sophisticated fraudulent activities. The main objective of graph-based fraud detection is to distinguish between fraudsters and normal entities within graphs. While real-world networks contain complex, high-order relationships, existing graph-based fraud detection methods focus solely on pairwise interactions, overlooking non-pairwise relationships and the broader dependencies among entities within fraud graphs. Thus, we highlight the importance of exploring non-pairwise relationships to build a more effective fraud detection model. In this paper, we propose TROPICAL, a novel TRansfOrmer-based hyPergraph LearnIng framework for detecting CAmouflaged maLicious actors in online social networks. To capture comprehensive high-order relations, we construct a hypergraph from the original input graph. However, constructing the hypergraph can be computationally intensive. TROPICAL addresses this challenge by carefully selecting moderate hyperparameters, creating a balance between computational efficiency and effectively capturing high-order relationships. TROPICAL learns node representations by processing multiple hyperedge groups and incorporates positional encodings into the aggregated information to enhance their distinctiveness. The aggregated sequential information is then passed through a transformer encoder, enabling the model to generate rich, high-order representations to detect camouflaged fraudsters. Extensive experiments on two real-world datasets demonstrate TROPICAL’s superior performance compared to the state-of-the-art fraud detection models. The source codes and the datasets of our work are available at https://github.com/VenusHaghighi/TROPICAL .},
  archive      = {J_KIS},
  author       = {Haghighi, Venus and Soltani, Behnaz and Shabani, Nasrin and Wu, Jia and Zhang, Yang and Yao, Lina and Yang, Jian and Sheng, Quan Z.},
  doi          = {10.1007/s10115-025-02476-5},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7987-8022},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Beyond pairwise relationships: A transformer-based hypergraph learning approach for fraud detection},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid long-range dependency-aware graph convolutional network for node classification. <em>KIS</em>, <em>67</em>(9), 7955-7986. (<a href='https://doi.org/10.1007/s10115-025-02473-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks, despite their effectiveness, face inherent limitations such as over-squashing within the message-passing mechanism. This impedes their ability to effectively capture long-range dependencies, thereby constraining their performance on graph mining tasks, such as node classification. Recent studies attempt to address this issue by developing two-step aggregation-based methods, whose key idea is to seek nodes with high similarity in topology or attribute feature space for information aggregation. Despite effectiveness, we observe that previous studies share two common deficiencies: single-type feature-based strategies of sifting nodes, and limited to preserving low-frequency information. These limitations result in the inadvertent inclusion of irrelevant nodes and the neglect of multi-frequency information within long-range dependencies. To this end, we propose a novel method, called hybrid long-range dependency-aware graph convolutional network (HLDGCN) to overcome the above deficiencies. Specifically, HLDGCN first employs a flexible node selection process that considers both topological and attribute features across diverse graph structures. Subsequently, the original graph is transformed into a long-range dependency-aware graph by incorporating additional edges that connect selected nodes. Contrary to prior approaches that focus solely on high-similarity nodes, HLDGCN incorporates both high- and low-similarity nodes, assigning positive and negative edge weights, respectively. This design ensures the preservation of diverse frequency information within the graph. Furthermore, HLDGCN employs a specialized graph convolution layer that utilizes a separated fusion strategy to aggregate information effectively on the transformed graph. Extensive experiments on various benchmark datasets, including homophily and heterophily graphs, demonstrate the superiority of HLDGCN on the node classification task.},
  archive      = {J_KIS},
  author       = {Chen, Jinsong and Wang, Meng and He, Kun},
  doi          = {10.1007/s10115-025-02473-8},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7955-7986},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Hybrid long-range dependency-aware graph convolutional network for node classification},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H2LFR: A hybrid two-layered feature ranking approach for enhanced data analysis. <em>KIS</em>, <em>67</em>(9), 7901-7953. (<a href='https://doi.org/10.1007/s10115-025-02463-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is a critical process in machine learning that involves identifying a subset of relevant features from a larger set. The primary objective of FS is to eliminate irrelevant and redundant features, thereby reducing storage requirements and computational costs, enhancing data interpretability, and improving model accuracy. FS methods can be classified as either supervised or unsupervised, depending on the availability of a target variable. Furthermore, FS techniques are broadly categorized into two subtypes: feature subset selection and feature ranking (FR). Typically, various feature subsets are identified through different FR techniques, each of which operates under specific assumptions regarding the regression function that relates input features to output. In this paper, we introduce a novel supervised hybrid two-layered feature ranking technique, referred to as H2LFR, which integrates a learning model, a metaheuristic algorithm, and weighted metrics. The first layer of this approach (H2LFR-L1) focuses on extracting encoded solutions alongside their performance metrics. Subsequently, the second layer (H2LFR-L2) is tasked with ranking the features. To evaluate the proposed method, we utilize twelve publicly available datasets and the results obtained from H2LFR are compared against 16 established FR methods. Our comparative analysis demonstrates that H2LFR consistently outperforms 12 of these methods in many cases, yielding notably robust results.},
  archive      = {J_KIS},
  author       = {Balaha, Hossam Magdy and Hassan, Asmaa El-Sayed and Balaha, Magdy Hassan},
  doi          = {10.1007/s10115-025-02463-w},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7901-7953},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {H2LFR: A hybrid two-layered feature ranking approach for enhanced data analysis},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implicit graph neural network for deep graph transformation. <em>KIS</em>, <em>67</em>(9), 7871-7900. (<a href='https://doi.org/10.1007/s10115-025-02468-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel graph neural network architecture for the general problem of attributed graph transformation, where both the input and output are attributed graphs, and the evolution of the output graphs, including the attributes of nodes and edges, is governed by complex interactions that capture the intricate dependencies within the transformation process. Research in this area has been limited due to two key challenges: (1) the complexity of jointly modeling four types of atomic interactions, i.e., node-to-edge, node-to-node, edge-to-node, and edge-to-edge; and (2) the challenge of modeling dependencies between nodes and edges that span distant parts of the graph and develop through multiple iterative steps in the transformation process. To overcome these challenges, we present a scalable equilibrium model, NEC $$^{\infty }$$ , which incorporates both node-to-edge and edge-to-node message passing. Furthermore, we develop an efficient optimization algorithm based on the implicit function theorem [1] and provide a well-posedness analysis of NEC $$^{\infty }$$ . Experiments were conducted on four synthetic random graph datasets, four real-world datasets, and two synthetic dynamical system datasets, employing multiple evaluation metrics for node and edge prediction. The results show that NEC $$^{\infty }$$ consistently outperforms all baseline models, achieving up to a tenfold decrease in MSE on BA random graphs, edge prediction accuracy ranging from 94% to nearly 100% on synthetic datasets, and exceptional results in tasks involving molecular reactions and high-order brain networks, highlighting its strength in modeling complex graph transformations.},
  archive      = {J_KIS},
  author       = {Zhang, Lei and Zhang, Qisheng and Chen, Zhiqian and Sun, Yanshen and Lu, Chang-Tien and Zhao, Liang},
  doi          = {10.1007/s10115-025-02468-5},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7871-7900},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Implicit graph neural network for deep graph transformation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple feature-anisotropic regularization for out-of-domain intent detection. <em>KIS</em>, <em>67</em>(9), 7847-7869. (<a href='https://doi.org/10.1007/s10115-025-02459-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-domain (OOD) intent detection is one of the research hotspots in task-based AI dialog. Aiming at the problems of entangling features and insufficient extraction of discriminative information, multiple feature-anisotropy regularization for OOD intent detection bidirectional encoder representations from transformer (MFAR-BERT) is proposed. The instance-level and class-level features of the intent are decoupled by a multi-head feature anisotropy disentangled strategy. To extract feature information of instance-level intent samples from different perspectives, multi-view KNN contrastive learning is designed. Correlation-matrix regularization is devised to adjust the direction of class-level sentence embeddings. Feature distributions are avoided from being confined in cone space. The experimental results show that the MFAR-BERT model achieves a minimum improvement of 0.67, 0.44, 0.49, and 1.85% on ACC_ALL, F1_ALL, F1_OOD, and F1_IND compared to DCL, SCL, ABD, HybridCL, and KNNBERT models on the publicly available datasets BANKING, OverStackflow, CLINC-SMALL, and CLINCX-FULL},
  archive      = {J_KIS},
  author       = {Wu, Di and Wang, Xiaoyu and Feng, Liming},
  doi          = {10.1007/s10115-025-02459-6},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7847-7869},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Multiple feature-anisotropic regularization for out-of-domain intent detection},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating rule-based and generative data augmentation techniques for legal document classification. <em>KIS</em>, <em>67</em>(9), 7825-7846. (<a href='https://doi.org/10.1007/s10115-025-02454-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated text classification is a fundamental research topic within the legal domain as it is the foundation for building many intelligent legal solutions. There is a scarcity of publicly available legal training data and these classification algorithms struggle to perform in low data scenarios. Text augmentation techniques have been proposed to enhance classifiers through artificially synthesised training data. In this paper we present and evaluate a combination of rule-based and advanced generative text augmentation methods designed to create additional training data for the task of classification of legal contracts. We introduce a repurposed CUAD contract dataset, modified for the task of document level classification, and compare a deep learning distilBERT model with an optimised support vector machine baseline for useful comparison of shallow and deep strategies. The deep learning model significantly outperformed the shallow model on the full training data (F1-score of 0.9738 compared to 0.599). We achieved promising improvements when evaluating the combined augmentation techniques on three reduced datasets. Augmentation caused the F1-score performance to increase by 66.6%, 17.5% and 2.6% for the 25%, 50% and 75% reduced datasets respectively, compared to the non-augmented baseline. We discuss the benefits augmentation can bring to low data regimes and the need to extend augmentation techniques to preserve key terms in specialised domains such as law.},
  archive      = {J_KIS},
  author       = {Duffy, William and O’Connell, Eoin and McCarroll, Niall and Sloan, Katie and Curran, Kevin and McNamee, Eugene and Clist, Angela and Brammer, Andrew},
  doi          = {10.1007/s10115-025-02454-x},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7825-7846},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Evaluating rule-based and generative data augmentation techniques for legal document classification},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Providing and evaluating a model for big data anonymization streams by using in-memory processing. <em>KIS</em>, <em>67</em>(9), 7791-7824. (<a href='https://doi.org/10.1007/s10115-025-02417-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting valuable information from vast sources of social networks while protecting confidentiality and preventing data disclosure is a significant challenge in big data environments. Traditional anonymization methods often fall short in handling the volume, variety, and velocity of big data, leading to high data loss and inefficiency. This article addresses these challenges by proposing a novel anonymization method based on K-means clustering within the Spark framework, leveraging its in-memory processing capabilities. Our model uses K-means clustering to determine optimal cluster heads, significantly reducing data loss and identity disclosure risks. By utilizing Spark's RDD abilities and the MLlib component, our method achieves faster processing times compared to traditional methods that rely on non-in-memory big data tools. Performance evaluation demonstrates that at k = 9, the cost factor is minimized to 0.20, indicating the efficiency and effectiveness of our approach. The proposed method not only enhances processing speed but also ensures minimal data loss, making it suitable for real-time anonymization of big data streams. This work provides a balanced solution that addresses the critical need for high-speed data anonymization while maintaining data privacy and utility.},
  archive      = {J_KIS},
  author       = {Shamsinejad, Elham and Banirostam, Hamid and BaniRostam, Touraj and Pedram, Mir Mohsen and Rahmani, Amir Masoud},
  doi          = {10.1007/s10115-025-02417-2},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7791-7824},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Providing and evaluating a model for big data anonymization streams by using in-memory processing},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TIDRec: A novel triple-graph interactive distillation method for paper recommendation. <em>KIS</em>, <em>67</em>(9), 7757-7789. (<a href='https://doi.org/10.1007/s10115-025-02457-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of academic graph networks, over-fitting has become a great challenge for graph-based paper recommendation. Existing methods mainly focus on knowledge distillation to solve above problem by compressing the volume of graph networks. However, incomplete distillation between two graphs would lead to the neglect of author’s diverse interests, resulting in biases for research interests. Therefore, we propose a new triple-graph interactive distillation recommendation (TIDRec) method for paper recommendation. Specifically, we construct a triple-graph interaction to complete the distillation knowledge between graphs to correct biased research interests of authors. First, a main model is built that integrates knowledge from both graphs (i.e., writing–citation relationship and author–author co-authorship graph) to initialize inner product vectors, capturing global research interests. Then, two auxiliary models with single graph knowledge are constructed to generate distinct inner product vectors, mining local research interests, respectively. Next, a triple-graph interactive distillation approach is designed to continuously correct the global research interests with distill vectors of each other. Finally, papers highly relevant to global research interests are recommended to authors. Extensive experiments prove that TIDRec surpasses state-of-the-art approaches, with an average performance improved by 8–25% for all four metrics.},
  archive      = {J_KIS},
  author       = {Xiao, Xia and Liu, Yan and Huang, Jiaying and Jin, Dawei and Shen, Zuwu and Zhang, Chengde},
  doi          = {10.1007/s10115-025-02457-8},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7757-7789},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {TIDRec: A novel triple-graph interactive distillation method for paper recommendation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversity-enhanced conversational recommendation via multi-agent reinforcement learning. <em>KIS</em>, <em>67</em>(9), 7727-7755. (<a href='https://doi.org/10.1007/s10115-025-02455-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-round conversational recommendation (MRCR) system assists users in finding the items they need with the fewest dialogue rounds by inquiring about desired features or making tailored recommendations. Numerous models employ single-agent Reinforcement Learning (RL) to accomplish MRCR and improve recommendation accuracy. However, they overlook the diversity of conversational recommendations and primarily focus on popular features or items. It impacts the fair visibility of the items and results in an unbalanced user experience. We propose a diversity-enhanced conversational recommendation model (DECREC), which is built on our proposed multi-agent RL framework. Compared to single-agent methods, this collaborative approach enables broader exploration of the action space, leading to more diverse decisions and recommendation results. Furthermore, we introduce a dynamic experience replay method that balances long-tail and head data. It ensures that each learning batch includes long-tail samples, keeping the model attentive to these less common but important data. Moreover, we incorporate feature entropy into the value estimation process, encouraging broader feature exploration and ultimately enhancing recommendation diversity. Extensive experiments on four public datasets demonstrate that DECREC reduces bias in MRCR and achieves optimal recommendation diversity and accuracy. Our code is available at https://github.com/wzhwzhwzh0921/DECREC .},
  archive      = {J_KIS},
  author       = {Wang, Zihan and Feng, Shi and Wang, Daling and Song, Kaisong and Wu, Gang and Zhang, Yifei and Zhao, Han and Yu, Ge},
  doi          = {10.1007/s10115-025-02455-w},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7727-7755},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Diversity-enhanced conversational recommendation via multi-agent reinforcement learning},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modal associated learning with spatial–temporal attention for hot topic detection. <em>KIS</em>, <em>67</em>(9), 7699-7726. (<a href='https://doi.org/10.1007/s10115-025-02444-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosion in the number of web videos, it has become a common practice to detect hot topics with web videos. However, each video clip contains multiple patterns, in which object actions might only appear in specific spatial areas or specific time periods, posing a huge challenge for web video hot topic detection. Fortunately, visual information during a specific time period and area will significantly enhance the rapid capture of key information, which is particularly important for detecting hot topics. Therefore, we propose a cross-modal associated learning method with spatial–temporal attention. It can automatically select discriminative time segments to detect hot topics by focusing on spatial regions with rich information. Firstly, after focusing on important keyframes related to the topic through temporal attention, spatial attention emphasizes the salient regions in the frame, thus incorporating discriminative features at the spatial level. Secondly, after integrating text structure knowledge into text semantic features, it can adaptively learn the weights of text features and visual features. Thirdly, adaptive learning of cross-modal fusion weights, achieving mutual guidance between text and visual information in attention dispersed association models to enhance feature learning. Finally, under the constraint of contrast loss, hot topics are detected with the similarity between features. Extensive experiments conducted on web videos from YouTube indicate that our method outperforms 8 leading state-of-the-art methods.},
  archive      = {J_KIS},
  author       = {Zhang, Chengde and Liu, Shiyu and Li, Xinyu and Xiao, Xia},
  doi          = {10.1007/s10115-025-02444-z},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7699-7726},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Cross-modal associated learning with spatial–temporal attention for hot topic detection},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chronological squirrel search algorithm enabled deep recurrent neural network for employability prediction. <em>KIS</em>, <em>67</em>(9), 7669-7698. (<a href='https://doi.org/10.1007/s10115-025-02437-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many scholars are still debating the idea of employability, and no agreement has been reached as of yet. A solid theoretical foundation is still not established with the empirical investigation. The ability of the graduate to find fulfilling employment emphasizes the satisfaction that the graduate finds in their job. Therefore, employability prediction models are crucial in assessing a student's ability to find employment. This study aims to create a hybrid optimization-enhanced deep learning model for predicting employability. For that, primarily, input data is given to the pre-processing phase, where quantile normalization is used. Then, feature fusion is done by using Renyi entropy with Generative Adversarial Network. The employability prediction is done by utilizing a Deep Recurrent Neural Network (Deep RNN) in which its weight is trained using the proposed Chronological Squirrel Search Algorithm (CSSA). Here, CSSA is constructed by the combination of the Chronological concept and Squirrel search algorithm to optimize the predicted result. Moreover, the predicted output is noted. Furthermore, the introduced Chronological Squirrel Search Algorithm_Deep Recurrent Neural Network (CSSA_Deep RNN) compared with different algorithms illustrates better performance concerning the evaluation metrics such as Root-Mean-Square Error and Mean Square Error with a minimal error value of 0.458 and 0.210, respectively.},
  archive      = {J_KIS},
  author       = {Kamakshamma, V. and Bharati, K. F.},
  doi          = {10.1007/s10115-025-02437-y},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7669-7698},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Chronological squirrel search algorithm enabled deep recurrent neural network for employability prediction},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SkSpO-L2TDBM: Optimized drug name recognition using a large language-based time-distributed deep learning model. <em>KIS</em>, <em>67</em>(9), 7641-7667. (<a href='https://doi.org/10.1007/s10115-025-02409-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Poor handwriting of doctors in medical prescriptions can cause misunderstanding, misreading, misinterpretation risks and cause medical errors. Despite being rare, identifying the correct drugs with the unclear prescription seriously affects patients and also requires a quite lot of time, attention, and effort for recognition. As a result, a drug name recognition system is implemented, but previously developed models are not significant in terms of accuracy, interpretability, and reliability. Therefore, the skill split optimization enabled large language-based time-distributed bidirectional long short-term memory (SkSpO-L2TDBM) model for drug name recognition is proposed in this research. The SkSpO-L2TDBM model exploits deep features concerning bidirectional encoder representations from transformers and bidirectional long short-term memory techniques that are employed to increase the model’s reliability and interpretability for effective recognition. Moreover, the SkSpO algorithm tunes the hyper-parameters of the proposed model based on the effect of skillful learning and sharing ability that makes easy recognition with maximum convergence speed. The major advantages of the proposed model are simplicity, robustness, and endue complex computation for accurate recognition. Compared to other existing techniques, the SkSpO-L2TDBM model achieved a minimal mean squared error rate of 4.46, and minimal root mean squared error rate of 2.11 using the hybrid dataset comprising the ‘Handwritten Medical Prescriptions Collection’ dataset, and a proprietary set of handwritten medical prescriptions collected from various doctors across the cities such as Nagpur, Pune in Maharashtra, India. Moreover, the proposed approach is robust in recognizing the biomedical entities in the text.},
  archive      = {J_KIS},
  author       = {Nair, Sruthi and Sahare, Parul and Peshwe, Paritosh},
  doi          = {10.1007/s10115-025-02409-2},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7641-7667},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {SkSpO-L2TDBM: Optimized drug name recognition using a large language-based time-distributed deep learning model},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive hierarchical knowledge distillation from GNNs to MLPs. <em>KIS</em>, <em>67</em>(9), 7619-7639. (<a href='https://doi.org/10.1007/s10115-025-02447-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation has attracted much attention in knowledge and information systems. The latest distillation methods use Kullback–Leibler divergence to distill complex models from simple models, yielding surprising results. However, due to the difference in the capacity of graph neural networks (GNNs) and MLPs models, distilling GNNs through fixed dimensions and layers of MLPs will inevitably cause information loss. In addition, the gap between the features produced by GNNs and the features produced by MLPs gradually becomes larger as the number of layers increases. To this end, we propose an adaptive hierarchical distillation framework that distills GNNs through MLPs with variable dimensions and layers to ensure the integrity of the distilled information. Specifically, we use a neural architecture search to adaptively find MLPs with appropriate dimensions and layers for each layer of GNNs. Then, the graph structure information is distilled from GNNs layer by layer, which makes the student neural network structure can better match with the teacher model, and the features are better aligned, so as to better learn the graph structure information. At last, the student model distilled to the complete information is used in the downstream learning task. Experimental results on various datasets show impressive improvements in node classification tasks compared with previous state-of-the-art methods.},
  archive      = {J_KIS},
  author       = {Zhang, Junfeng and Xie, Cheng and Yu, BeiBei and Yang, Rui},
  doi          = {10.1007/s10115-025-02447-w},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7619-7639},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Adaptive hierarchical knowledge distillation from GNNs to MLPs},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conflict-aware influence maximization on hostile-labeled social networks. <em>KIS</em>, <em>67</em>(9), 7597-7618. (<a href='https://doi.org/10.1007/s10115-025-02466-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) is a well-known problem in social network analysis, which aims to identify a strategic set of seeds to maximize the influence propagation. However, a significant downside has emerged: influence propagation can unintentionally activate previously isolated but mutually hostile nodes in cyberspace, increasing the likelihood of online conflicts. To mitigate this issue, we propose the Conflict-Aware Influence Maximization (CAIM) problem, which seeks to maximize influence while minimizing the activation of mutually hostile nodes on hostile-labeled social networks. We demonstrate that CAIM remains NP-hard and #P-hard, making it a complex non-submodular optimization problem. To overcome this challenge, we propose an efficient estimation method for the objective function and design a convergent algorithm with a data-driven approximation of $$z_\lambda ^+ / b^+$$ , where the parameter computations are intricately connected to the solution. Experiments on real-world networks demonstrate that our algorithms outperform multiple baselines in effectively preventing conflicts while maximizing influence.},
  archive      = {J_KIS},
  author       = {Rao, Guoyao and Li, Deying and Zhu, Yuqing},
  doi          = {10.1007/s10115-025-02466-7},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7597-7618},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Conflict-aware influence maximization on hostile-labeled social networks},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding user satisfaction: Explainable artificial intelligence-based user-centric analysis of mobile health applications adoption. <em>KIS</em>, <em>67</em>(9), 7563-7596. (<a href='https://doi.org/10.1007/s10115-025-02451-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile health applications (mHealth) have revolutionized healthcare sector by leveraging mobile technology to provide personalized services. As a rapidly growing industry, mHealth aligns with the World Health Organization’s goal of empowering patients to take control of their healthcare journey. In the realm of mHealth, ensuring user satisfaction always remains a key concern. Therefore, recognizing crucial factors that determine customer satisfaction levels can help mHealth applications improve their quality of service. Leveraging machine learning techniques for this task can prove to be highly beneficial. However, the existing machine learning methods in this domain are ‘black-box’ and possess several limitations, such as less accuracy, lack of explainability, and many more. To resolve these challenges, the current research introduces a novel approach based on deep transformers and explainable artificial intelligence (EAI). This approach aims to analyze user-generated content to determine mHealth ratings and the factors influencing user satisfaction. The proposed pipeline encompasses several steps, namely, data preprocessing and anonymization, feature extraction, feature selection, transformer architecture building, and evaluating performance using a dataset containing reviews of several different mHealth applications. The sensitivity analysis of the proposed approach is performed by utilizing several feature selection techniques and comparing the prediction performance with existing benchmark solutions available in the literature. From the comparative evaluation, it is observed that the proposed approach outperforms existing techniques by providing 98% accuracy and 99% F1-score, with a 3–5% relative improvement over benchmark solutions. In addition, the proposed method incorporates EAI to determine several crucial factors that affect user satisfaction or app rating scores. This information will be beneficial for the stakeholders in devising better platforms and strategies for enhancing user satisfaction and experience in the mHealth domain.},
  archive      = {J_KIS},
  author       = {Rai, Stuti and Bedi, Jatin and Anand, Ashima},
  doi          = {10.1007/s10115-025-02451-0},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7563-7596},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Decoding user satisfaction: Explainable artificial intelligence-based user-centric analysis of mobile health applications adoption},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature disentanglement, selection, and reaggregation method for multi-task learning. <em>KIS</em>, <em>67</em>(9), 7537-7562. (<a href='https://doi.org/10.1007/s10115-025-02460-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning utilizes the dependencies among tasks to make the tasks boost each other and achieve better results. However, there are not only dependencies but also conflicts among tasks. Task conflict is a critical issue that needs to be addressed to avoid mutual interference among tasks. Previous studies focus on weighting each task to intervene between two or more tasks to reach a compromise. The issue of dependency and conflict among tasks is more complex, where there may be both dependencies and conflicts between two tasks. Simply adjusting weights cannot effectively handle such complex relationships and achieve better results. This paper analyzes the reasons for the task conflicts and discovers that different requirements exist for features in different tasks. For a single task, the features required for other tasks may interfere with the decoder. A new method named feature disentanglement, selection, and reaggregation method is proposed based on the reason for task conflict, which is to disentangle encoder output to obtain high-level features and then select and aggregate high-level features according to the requirements of the task. Experiments show that our method achieves state-of-the-art results on the Multi-Domain Sentiment dataset and 20 Newsgroups dataset. The results prove that our method effectively alleviates conflicts among tasks.},
  archive      = {J_KIS},
  author       = {Liu, Renyuan and Zhang, Xuejie and Wang, Jin and Zhou, Xiaobing},
  doi          = {10.1007/s10115-025-02460-z},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7537-7562},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Feature disentanglement, selection, and reaggregation method for multi-task learning},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A priority-based blockchain transaction packaging algorithm in a cloud-edge-end collaboration computing environment. <em>KIS</em>, <em>67</em>(9), 7503-7536. (<a href='https://doi.org/10.1007/s10115-025-02432-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of mobile internet, intelligent IoT, and 5G communication technologies, many IoT devices connect to the Industrial Internet of Things, generating significant data. Blockchain is widely used in identity authentication and trust management due to its reliability. In blockchain technology, transaction packaging is a crucial component of the consensus mechanism and is critical to enhancing fairness and service quality in request processing. However, the flat structure of the blockchain, the necessity for multi-party consensus, and the profit-seeking nature of nodes lead to issues such as unfair transaction processing and prolonged response times in cloud-edge-end architectures, which are critical for empowering intelligent edge applications. To address these challenges, we have refined the blockchain consensus mechanism and introduced a novel packaging algorithm, ITFPA (Improved time-fee packaging algorithm), within the cloud-edge-end environment. This algorithm models the transaction packaging problem as a 0–1 knapsack problem and employs a branch-and-bound method to find the optimal solution. The proposed model considers both the transaction waiting time and transaction fee, using the weighted result of these factors as the priority for the transaction. We compared the proposed algorithm with the WaitTime and TxFee algorithms across four metrics: system fairness, transaction response time, and block priority. The experimental results demonstrate that the proposed algorithm enhances system fairness, reduces transaction response times, and improves service quality to a significant degree.},
  archive      = {J_KIS},
  author       = {Li, Chunlin and Zeng, Haibo and Jiang, Kun and Yang, Kaijun and Yang, Shaohua and Jia, Qingren},
  doi          = {10.1007/s10115-025-02432-3},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7503-7536},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A priority-based blockchain transaction packaging algorithm in a cloud-edge-end collaboration computing environment},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain feature transfer-based multi-domain fake news detection. <em>KIS</em>, <em>67</em>(9), 7473-7501. (<a href='https://doi.org/10.1007/s10115-025-02412-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news is spreading rapidly throughout social media, and is having serious negative consequences on both individuals and society. Currently, fake news detection methods often only predict news for a single domain, neglecting the domain information contained within the text. This may result in an inability to make effective predictions in domains where there is a low quantity or quality of data. With the aid of multi-task learning and transfer learning concepts, this paper presents a domain feature transfer-based multi-domain fake news detection (DFTD). First, we construct a multi-task feature extractor to obtain news text features in different domains. Then, we build an implicit domain gatherer to mine hidden domain information in the news. Next, the domain feature transferor is combined to obtain cross-domain text features. Finally, these features are inputted into the fake news detector for prediction. Our model maintains the extensive association information between domains while segmenting them. Additionally, it employs features from several source domains to aid in determining the authenticity of news in the target domain. Relevant experiments conducted on Weibo21 provide proof of the effectiveness of this model.},
  archive      = {J_KIS},
  author       = {Meng, Xuan and Zhao, Di and Meng, Jiana and Guo, Xu and Ma, Tengfei and Wang, Xiaopei},
  doi          = {10.1007/s10115-025-02412-7},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7473-7501},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Domain feature transfer-based multi-domain fake news detection},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). XLR-KGDD: Leveraging LLM and RAG for knowledge graph-based explainable disease diagnosis using multimodal clinical information. <em>KIS</em>, <em>67</em>(9), 7451-7471. (<a href='https://doi.org/10.1007/s10115-025-02465-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are making a big impact in Artificial Intelligence due to their ability to perform tasks as humans. However, using LLMs in many domain-specific tasks is a relatively unexplored area, specifically in disease diagnosis. This is due to challenges such as multiple modalities in patient clinical information and LLM's high memory and computational power requirements. This study proposes a framework, XLR-KGDD, that overcomes these challenges and performs an LLM-based disease diagnosis. Additionally, XLR-KGDD generates explanations to establish the trust of clinicians and support the diagnosis. These explanations are precise and unambiguous as they adhere to the standard medical guidelines and are presented in natural language. The proposed framework maps multimodal patient clinical information to a patient Knowledge Graph (KG) using the N2K mapper and CheXzero. Prompt Engineering is then applied to create an LLM-compatible input prompt from the patient KG. The framework employs a Parameter Efficient Fine-tuning technique to fine-tune LLM efficiently by optimizing numerical computations and memory requirements. The framework uses Retrieval Augmented Generation to provide standard medical guidelines as context to the LLM, addressing the issue of hallucinations in LLMs and generating coherent explanations. A system based on the XLR-KGDD framework was developed and tested on the multimodal MIMIC-Eye dataset. The LLaMA-3 LLM shows an AUC value of 0.88 and 0.91 in ROC and PR curves, respectively, in diagnosing patients with CHF disease. Furthermore, the system-generated explanations support the diagnosis with evidence from medical guidelines.},
  archive      = {J_KIS},
  author       = {Bedi, Punam and Thukral, Anjali and Dhiman, Shivani},
  doi          = {10.1007/s10115-025-02465-8},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7451-7471},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {XLR-KGDD: Leveraging LLM and RAG for knowledge graph-based explainable disease diagnosis using multimodal clinical information},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic token pruning for LLMs: Leveraging task-specific attention and adaptive thresholds. <em>KIS</em>, <em>67</em>(9), 7431-7450. (<a href='https://doi.org/10.1007/s10115-025-02450-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have achieved state-of-the-art performance across a wide range of natural language processing (NLP) tasks. With their high inference computational costs, deployment is extremely challenging, especially to resource-constrained environments. Dynamic pruning methods, because they are efficient, are likely to assign uniform policies to all tasks and even forget task-specific knowledge and make optimal behavior complicated. To counter this limitation, we propose task-specific dynamic token pruning (TS-DTP), a novel optimization framework that reaches maximum efficiency for LLMs at inference without compromising task-specific performance and, in certain cases, improving upon it. TS-DTP utilizes task-specific knowledge to regulate the token selection process by applying task-specific attention weights and adaptive threshold learning. This approach enables better token importance decision-making through the dynamically adjustable pruning policy according to the downstream task need. It enables very high-grained control, keeping the meaningful contextual information, therefore promoting better performance compared to regular pruning methods. Experimental findings on a variety of NLP tasks (question answering, machine translation, sentiment analysis) validate that TS-DTP achieves extremely large reductions in computational expense and memory demands and similar or marginal gains in accuracy. Our findings are at the forefront of efficient and deployable LLM development and highlight the importance of task adaptation for optimal performance in low-resource settings.},
  archive      = {J_KIS},
  author       = {Ahmadpanah, Seyed Hossein and Sobhanloo, Sanaz and Afsharfarnia, Pania},
  doi          = {10.1007/s10115-025-02450-1},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7431-7450},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Dynamic token pruning for LLMs: Leveraging task-specific attention and adaptive thresholds},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based advances in sarcasm detection: A study of contextual models and methodologies. <em>KIS</em>, <em>67</em>(9), 7399-7430. (<a href='https://doi.org/10.1007/s10115-025-02469-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm detection is a subset of sentiment analysis and poses significant challenges due to its inherent linguistic complexity and the contextual subtleties required for accurate interpretation. In this paper, we present a comprehensive survey of the current state of sarcasm detection, covering models from traditional machine learning to large language models. Our review examines primary datasets and corpora used for training and evaluation, evaluates the effectiveness of existing sentiment analysis techniques, and highlights predominant methodologies. Additionally, we discuss the challenges and limitations facing sarcasm detection, including issues related to linguistic complexity and contextual interpretation. We compared all datasets, and how they impact the model performance and generalizability, assess the ability of sentiment analysis techniques to capture sarcasm and irony, and explore the strengths and limitations of leading methodologies. By exploring current limitations, including cross-cultural variances and the adaptability of deep learning models, this survey underscores ongoing challenges and highlights future directions in AI-driven sarcasm detection research.},
  archive      = {J_KIS},
  author       = {Bodige, Ramakrishna and Akarapu, Rameshbabu and Poladi, Pramod Kumar},
  doi          = {10.1007/s10115-025-02469-4},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7399-7430},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Transformer-based advances in sarcasm detection: A study of contextual models and methodologies},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative analysis of predictive process monitoring: Object-centric versus classical event logs. <em>KIS</em>, <em>67</em>(9), 7355-7398. (<a href='https://doi.org/10.1007/s10115-025-02461-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive Process Monitoring (PPM) techniques are emerging as part of the more general research scenario of Process Mining (PM). They play a crucial role in the continuously evolving process of digital transformation by constantly supporting the organizational decision-making processes providing (accurate) predictions on the future behavior of processes. The state of the art of PPM application methodologies is mainly focused on Single ID Event Logs, commonly known as Traditional Event Logs or Classical Event Logs. As a matter of fact, the importance of Object-Centric Event Logs (OCEL) is being increasingly recognized as many emerging PPM approaches benefited of the usage of OCEL by obtaining a significative increase of the prediction accuracy. This survey aims to explore the current proposals in the context of OCEL-based PPM approaches. More in detail, we contribute to the state of the art by adding new classification features by differentiating between the approaches based on the input Event Log (Traditional or OCEL). We also analyzed the existing literature considering the prediction task addressed, the methodology used, the specific contribution area they addressed and the application domain.},
  archive      = {J_KIS},
  author       = {Fioretto, Simona and Masciari, Elio},
  doi          = {10.1007/s10115-025-02461-y},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7355-7398},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A comparative analysis of predictive process monitoring: Object-centric versus classical event logs},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chatbot development strategies: A review of current studies and applications. <em>KIS</em>, <em>67</em>(9), 7319-7354. (<a href='https://doi.org/10.1007/s10115-025-02462-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chatbots have become increasingly popular by transforming interactions across numerous fields. As the technology behind chatbots has rapidly developed, new methodologies have arisen, each contributing unique strengths and addressing different challenges. This paper systematically reviews the methods used in chatbot development from 2019 to 2024, comprehensively analyzing the studies. We categorize the techniques into three main groups: machine learning (ML)-based, deep learning (DL)-based, and large language model (LLM)-based methods. We present a broad and inclusive survey by exploring the foundational principles of chatbot technologies and their applications across diverse domains such as education, healthcare, and interviews. Our analysis reveals that while traditional ML-based methods remain widely used, DL models are gaining prominence for handling complex tasks, and LLM-based systems are advancing the field by offering more coherent, contextually aware responses. However, challenges remain, especially in ethical concerns like hallucination and privacy-preserving technologies, particularly with LLMs. The paper also identifies gaps in existing research, notably the need for improved privacy-preserving mechanisms and better strategies for mitigating hallucinations in chatbot responses. Future research directions are suggested to address these challenges, particularly in developing LLM-based chatbots, with a focus on enhancing privacy, accuracy, and ethical standards.},
  archive      = {J_KIS},
  author       = {Yigit, Gulsum and Bayraktar, Rabia},
  doi          = {10.1007/s10115-025-02462-x},
  journal      = {Knowledge and Information Systems},
  month        = {9},
  number       = {9},
  pages        = {7319-7354},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Chatbot development strategies: A review of current studies and applications},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
