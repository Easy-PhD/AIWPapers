<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOTA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jota">JOTA - 14</h2>
<ul>
<li><details>
<summary>
(2026). A positive semidefinite safe approximation of multivariate distributionally robust constraints determined by simple functions. <em>JOTA</em>, <em>208</em>(1), 1-27. (<a href='https://doi.org/10.1007/s10957-025-02791-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-level reformulations of (nonconvex) distributionally robust optimization (DRO) problems are often intractable, as they contain semi-infinite dual constraints. Based on such a semi-infinite reformulation, we present a safe approximation that allows for the computation of feasible solutions for DROs that depend on nonconvex multivariate simple functions. Moreover, the approximation allows to address ambiguity sets that can incorporate information on moments as well as confidence sets. The typical strong assumptions on the structure of the underlying constraints, such as convexity in the decisions or concavity in the uncertainty found in the literature were, at least in part, recently overcome in [16]. We start from the duality-based reformulation approach in [16] that can be applied for DRO constraints based on simple functions that are univariate in the uncertainty parameters. We significantly extend their approach to multivariate simple functions, which leads to a considerably wider applicability of the proposed reformulation approach. In order to achieve algorithmic tractability, the presented safe approximation is then realized by a discretized counterpart for the semi-infinite dual constraints. The approximation leads to a computationally tractable mixed-integer positive semidefinite problem for which state-of-the-art software implementations are readily available. The tractable safe approximation provides sufficient conditions for distributional robustness of the original problem, i.e., obtained solutions are provably robust.},
  archive      = {J_JOTA},
  author       = {Dienstbier, Jana and Liers, Frauke and Rolfes, Jan},
  doi          = {10.1007/s10957-025-02791-5},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-27},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A positive semidefinite safe approximation of multivariate distributionally robust constraints determined by simple functions},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the optimal control existence for multi-term multi-order fractional differential equations with impulsive conditions. <em>JOTA</em>, <em>208</em>(1), 1-24. (<a href='https://doi.org/10.1007/s10957-025-02830-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the existence of solutions to nonlinear impulsive fractional optimal control problems, where the state equations are linear with respect to their control variables and governed by multi-order systems of multi-term fractional differential ones. Initial and impulsive conditions are also given. The performance index is considered as an integral functional, whose integrand is continuous with respect to its variables. At first, we transform the state equations into the integral ones to prove the existence and uniqueness of solutions, assuming that the nonlinear functions in the equations are Lipschitz continuous in a bounded domain. Secondly, using the generalized Arzela-Ascoli theorem, we establish that sets of our admissible processes are compact ones in a piecewise continuous function space to show the optimal control existence.},
  archive      = {J_JOTA},
  author       = {Choe, HuiChol and Han, SuRim and Pak, SunAe and Kim, GwangHyok and Kim, GyongGuk and U, DanOh},
  doi          = {10.1007/s10957-025-02830-1},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-24},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {On the optimal control existence for multi-term multi-order fractional differential equations with impulsive conditions},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the existence and the stability of solutions in nonconvex vector optimization $$^\dagger $$. <em>JOTA</em>, <em>208</em>(1), 1-26. (<a href='https://doi.org/10.1007/s10957-025-02831-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is devoted to the existence of weak Pareto solutions and the weak sharp minima at infinity property for a general class of constrained nonconvex vector optimization problems with unbounded constraint set via asymptotic cones and generalized asymptotic functions. Then we show that these conditions are useful for studying the solution stability of nonconvex vector optimization problems with linear perturbation. We also provide some applications for a subclass of robustly quasiconvex vector optimization problems.},
  archive      = {J_JOTA},
  author       = {Nghi, Tran Van and Kien, Le Ngoc and Tuyen, Nguyen Van},
  doi          = {10.1007/s10957-025-02831-0},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-26},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {On the existence and the stability of solutions in nonconvex vector optimization $$^\dagger $$},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Derivative-free optimization on riemannian manifolds using simplex gradient approximations. <em>JOTA</em>, <em>208</em>(1), 1-22. (<a href='https://doi.org/10.1007/s10957-025-02832-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In optimization problems with complex or unknown gradients, using a derivative-free algorithm is an efficient approach. In this paper, we present a new derivative-free optimization method designed for problems in which the search space is a Riemannian manifold. The method utilizes a simplex gradient approximation and incorporates a line search strategy. We state the conditions under which the proposed algorithm is well-defined and establish its convergence to critical points on Riemannian manifolds from any starting point. Lastly, we demonstrate the practical implementation of this technique on two commonly used manifolds and compare its performance to some existing Riemannian derivative-free methods.},
  archive      = {J_JOTA},
  author       = {Najafi, Shahabeddin and Hajarian, Masoud},
  doi          = {10.1007/s10957-025-02832-z},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-22},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Derivative-free optimization on riemannian manifolds using simplex gradient approximations},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A three-term conjugate gradient-type method with sufficient descent property for vector optimization. <em>JOTA</em>, <em>208</em>(1), 1-42. (<a href='https://doi.org/10.1007/s10957-025-02815-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of vector optimization represents a critical domain within the broader spectrum of optimization problems. Extensive research efforts are currently dedicated to developing solution methods for vector optimization problems. A range of classical approaches, originally designed for scalar optimization, have been adapted to address issues in vector optimization. These include techniques such as the steepest descent method, Newton’s method, quasi-Newton method and conjugate gradient method, among others. However, limited attention has been given to the three-term conjugate gradient method in the context of vector optimization. In this paper, based on the modified self-scaling memoryless Broyden-Fletcher-Goldfarb-Shanno (BFGS) method proposed by Kou and Dai (J. Optim. Theory Appl., 165(1): 209-224, 2015), we propose a novel three-term conjugate gradient-type method specifically designed for vector optimization problems. This method ensures the sufficient descent property independent of any line search strategy. Furthermore, the improved Wolfe line search is extended to vector optimization. The global convergence of the proposed method under the improved Wolfe line search is analyzed, demonstrating that at least one accumulation point of the sequence generated by the proposed algorithm is a K-critical point of vector optimization problem. Numerical experiments conducted on a set of benchmark test problems highlight the effectiveness of the proposed method compared to some existing gradient-based approaches.},
  archive      = {J_JOTA},
  author       = {Chen, Yu and Chen, Helong and Zhu, Zhibin},
  doi          = {10.1007/s10957-025-02815-0},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-42},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A three-term conjugate gradient-type method with sufficient descent property for vector optimization},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preconditioned barzilai-borwein methods for multiobjective optimization problems. <em>JOTA</em>, <em>208</em>(1), 1-43. (<a href='https://doi.org/10.1007/s10957-025-02824-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preconditioning is a powerful strategy for addressing ill-conditioned problems in optimization. It involves utilizing a preconditioning matrix to reduce the condition number and speed up the convergence of first-order methods. However, in multiobjective optimization, capturing the curvature of all objective functions using a single preconditioning matrix is challenging. Consequently, second-order methods tailored for multiobjective optimization problems (MOPs) employ distinct matrices for each of the objectives in direction-finding subproblems, resulting in expensive per-step costs. To strike a balance between per-step costs and better curvature exploration, we develop a “preconditioning” $$+$$ “preconditioning” strategy to devise a preconditioned Barzilai-Borwein descent method for MOPs (PBBMO). Specifically, this method integrates a single scaling matrix to capture the local geometry of an implicit scalarization problem, leading to reduced per-step costs. We then incorporate the Barzilai-Borwein rule relative to the matrix metric to tune the gradients within the direction-finding subproblem. This can be interpreted as an additional diagonal preconditioner tailored to each objective for better curvature exploration. From a preconditioning perspective, we employ the BFGS update formula to approximate a trade-off of Hessian matrices. Subsequently, we develop a Barzilai-Borwein quasi-Newton method with Wolfe line search for MOPs. Under mild assumptions, we provide a convergence analysis for the Barzilai-Borwein quasi-Newton method. Finally, comparative numerical results validate the efficiency of the proposed method, even when applied to higher-dimensional and ill-conditioned problems.},
  archive      = {J_JOTA},
  author       = {Chen, Jian and Chen, Wang and Tang, Liping and Yang, Xinmin},
  doi          = {10.1007/s10957-025-02824-z},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-43},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Preconditioned barzilai-borwein methods for multiobjective optimization problems},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new infeasible projection method for stochastic variational inequality problem. <em>JOTA</em>, <em>208</em>(1), 1-28. (<a href='https://doi.org/10.1007/s10957-025-02825-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new infeasible stochastic approximation projection method based on the golden ratio for a nonmonotone stochastic variational inequality problem. In the traditional golden ratio methods, the constant $$\phi $$ is taken as $$\frac{1+\sqrt{5}}{2}$$ . However, the constant is relaxed to the interval $$(1,\infty )$$ in our method. A new self-adaptive step size which is admitted to be increasing is generated for dealing with the unknown Lipschitz constant of the mapping. The almost sure convergence and convergence rate of the proposed method are shown. Some numerical examples are given to illustrate the competitiveness of our algorithm compared to the related algorithms in the literature. Finally, we apply our method to solve a network bandwidth allocation problem.},
  archive      = {J_JOTA},
  author       = {Wang, Shenghua and Zhang, Yueyao and Cho, Yeol Je},
  doi          = {10.1007/s10957-025-02825-y},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-28},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A new infeasible projection method for stochastic variational inequality problem},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified derivative-free projection framework for convex-constrained nonlinear equations. <em>JOTA</em>, <em>208</em>(1), 1-26. (<a href='https://doi.org/10.1007/s10957-025-02826-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework and a unified convergence analysis for derivative-free projection methods to solve large-scale constrained nonlinear equations. The framework combines the inertial extrapolation technique with the concept of approximate projections, thereby encompassing and generalising the results of previous studies. Additionally, we introduce a new function-based line search based on the stabilised Barzilai and Borwein method, as introduced by Burdakov et al. The framework further explores the impact of six distinct, well-known line search schemes on its overall performance. Through numerical experiments, we highlight the theoretical findings.},
  archive      = {J_JOTA},
  author       = {Ibrahim, Abdulkarim Hassan and Alshahrani, Mohammed and Al-Homidan, Suliman},
  doi          = {10.1007/s10957-025-02826-x},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-26},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A unified derivative-free projection framework for convex-constrained nonlinear equations},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust n-agent heterogeneous investment-consumption game under $$\alpha $$ -maxmin mean-variance-utility criterion. <em>JOTA</em>, <em>208</em>(1), 1-38. (<a href='https://doi.org/10.1007/s10957-025-02834-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a robust heterogeneous n-agent stochastic differential game under a mean-variance-utility criterion, where agents compete based on relative performance in the presence of model uncertainty. Model uncertainty is represented by a set of equivalent probability measures, with Novikov’s condition imposed to guarantee their mutual equivalence. Ambiguity attitudes are characterized by the $$\alpha $$ -maxmin model. Agents invest and consume in a financial market exposed to both common and idiosyncratic risks, aiming to maximize relative terminal wealth with the mean-variance criterion and the expected utility of relative consumption under the $$\alpha $$ -maxmin model. We formulate a heterogeneous game that emphasizes outperforming a specific group of competitors. Agents focus on a weighted average of their peers’ wealth and consumption. This optimization problem is inherently time-inconsistent, and we derive the associated extended Hamilton-Jacobi-Bellman-Isaacs (HJBI) equations within a game-theoretic framework. The robust best response strategies are composed of a myopic component and another component that reacts to the actions of other agents. We obtain closed-form solutions for the robust Nash equilibrium investment-consumption strategies through a system of linear equations. This paper explores how levels of ambiguity, ambiguity aversion, risk aversion, and competition affect Nash equilibrium strategies, uncovering the herd effect that competition has on agents’ strategies.},
  archive      = {J_JOTA},
  author       = {Guan, Guohui and Liang, Zongxia},
  doi          = {10.1007/s10957-025-02834-x},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-38},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Robust n-agent heterogeneous investment-consumption game under $$\alpha $$ -maxmin mean-variance-utility criterion},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unique solvability of infinite dimensional differential sweeping systems. <em>JOTA</em>, <em>208</em>(1), 1-37. (<a href='https://doi.org/10.1007/s10957-025-02837-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the existence and uniqueness of solutions to a differential sweeping system. This system is an implicit coupled dynamical system consisting of a nonlinear differential equation and a history/state-dependent sweeping process. First, an existence result to a perturbed state-dependent sweeping process is proved based on Schauder’s fixed-point theorem. Next, the unique solvability of a history/state-dependent sweeping process is established by employing a fixed-point theorem for a history-dependent operator. Finally, using tools from nonsmooth analysis and Banach’s fixed-point theorem, we establish the existence and uniqueness of solutions to a differential sweeping system.},
  archive      = {J_JOTA},
  author       = {Du, Jinsheng and Migórski, Stanisław and Vilches, Emilio and Zeng, Shengda},
  doi          = {10.1007/s10957-025-02837-8},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-37},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Unique solvability of infinite dimensional differential sweeping systems},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Variational analysis of generalized ordinal nash games on banach spaces. <em>JOTA</em>, <em>208</em>(1), 1-25. (<a href='https://doi.org/10.1007/s10957-025-02838-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the generalized ordinal Nash games defined over Banach spaces by employing variational techniques. To reformulate these games in terms of quasi-variational inequality problems, we will first form a suitable principal operator and study some significant properties of this operator. Then, we deduce the sufficient conditions to obtain an equilibrium for the proposed game by solving an auxiliary quasi-variational inequality. Based on this quasi-variational reformulation, we derive the existence of equilibrium for generalized ordinal Nash games with mid-point continuous preference maps. We apply the derived results to ensure the presence of Pareto equilibrium for multi-objective games and dynamic electricity markets.},
  archive      = {J_JOTA},
  author       = {Valecha, Shivani and Sultana, Asrifa},
  doi          = {10.1007/s10957-025-02838-7},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-25},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Variational analysis of generalized ordinal nash games on banach spaces},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Estimating mean and variance of random coefficients in stochastic variational problems using second-order methods. <em>JOTA</em>, <em>208</em>(1), 1-48. (<a href='https://doi.org/10.1007/s10957-025-02805-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the need to identify both deterministic and stochastic coefficients in various stochastic partial differential equations, we have developed an abstract inversion framework. The inverse problem is studied in a stochastic optimization framework. Essential properties of solution maps are derived to prove the solvability of the optimization problems and to establish optimality conditions. A comprehensive regularization framework, including total-variation regularization, has been created to identify rapidly varying coefficients. By using the Bregman distance, we provide new convergence rates for stochastic inverse problems in the abstract formulation without the need for the so-called smallness condition. Assuming finite-dimensional noise, the inverse problem is parameterized and solved using the stochastic Galerkin framework. The numerical schemes utilize Hessian-based optimization methods, resulting in rapid convergence. The numerical results are promising, demonstrating the feasibility and effectiveness of the proposed framework.},
  archive      = {J_JOTA},
  author       = {Gong, Zi-Jia and Khan, Akhtar A. and Sama, Miguel and Starkloff, Hans-Jörg},
  doi          = {10.1007/s10957-025-02805-2},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-48},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Estimating mean and variance of random coefficients in stochastic variational problems using second-order methods},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Differential inclusions for measures and lyapunov stability. <em>JOTA</em>, <em>208</em>(1), 1-22. (<a href='https://doi.org/10.1007/s10957-025-02828-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on differential inclusions for measures, that are differential relations whose solutions are time-evolving measures. The definition of evolution equations for measures attracted a lot of attention recently. We start by recalling the main concepts developed in the latest literature and comparing them. In particular, we show how the definition of Measure Differential Inclusion is the most general allowing to model phenomena as diffusion from a Dirac delta. Then we pass to Lyapunov-type stability proposing two concepts of stability, based on the measure support and first moment, and show relationships between such definitions depending on the assumptions on the evolution equation used.},
  archive      = {J_JOTA},
  author       = {D’Apice, Ciro and Manzo, Rosanna and Piccoli, Benedetto},
  doi          = {10.1007/s10957-025-02828-9},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-22},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Differential inclusions for measures and lyapunov stability},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Majorization-minimization bregman proximal gradient algorithms for NMF with the Kullback–Leibler divergence. <em>JOTA</em>, <em>208</em>(1), 1-34. (<a href='https://doi.org/10.1007/s10957-025-02833-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) is a popular method in machine learning and signal processing to decompose a given nonnegative matrix into two nonnegative matrices. In this paper, we propose new algorithms, called majorization-minimization Bregman proximal gradient algorithm (MMBPG) and MMBPG with extrapolation (MMBPGe) to solve NMF. These iterative algorithms minimize the objective function and its potential function monotonically. Assuming the Kurdyka–Łojasiewicz property, we establish that a sequence generated by MMBPG(e) globally converges to a stationary point. We apply MMBPG and MMBPGe to the Kullback–Leibler (KL) divergence-based NMF. While most existing KL-based NMF methods update two blocks or each variable alternately, our algorithms update all variables simultaneously. MMBPG and MMBPGe for KL-based NMF are equipped with a separable Bregman distance that satisfies the smooth adaptable property and that makes its subproblem solvable in closed form. Using this fact, we guarantee that a sequence generated by MMBPG(e) globally converges to a Karush–Kuhn–Tucker (KKT) point of KL-based NMF. In numerical experiments, we compare proposed algorithms with existing algorithms on synthetic data and real-world data.},
  archive      = {J_JOTA},
  author       = {Takahashi, Shota and Tanaka, Mirai and Ikeda, Shiro},
  doi          = {10.1007/s10957-025-02833-y},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-34},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Majorization-minimization bregman proximal gradient algorithms for NMF with the Kullback–Leibler divergence},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
