<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>APIN</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="apin">APIN - 15</h2>
<ul>
<li><details>
<summary>
(2025). PretopoMD: Pretopology-based mixed data hierarchical clustering. <em>APIN</em>, <em>55</em>(15), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06770-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm’s robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.},
  archive      = {J_APIN},
  author       = {Levy, Loup-Noé and Guerard, Guillaume and Djebali, Sonia and Amor, Soufian Ben},
  doi          = {10.1007/s10489-025-06770-1},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {PretopoMD: Pretopology-based mixed data hierarchical clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-discriminator generative adversarial networks with dynamic penalty to over-sample imbalanced credit datasets. <em>APIN</em>, <em>55</em>(15), 1-30. (<a href='https://doi.org/10.1007/s10489-025-06836-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of credit risk data imbalance reduces the effectiveness of assessment models. Existing oversampling methods focus only on a partial sample of a few classes, resulting in a lack of diversity in the types of data generated. This paper proposes an innovative GAN variant called Magnify-GAN. The originality of Magnify-GAN lies in the fact that it is equipped with a primary discriminator and multiple secondary discriminators, each of which employs a different loss function. This multi-discriminator approach not only improves the learning results, but also enriches the feedback received during the training process. In addition, we integrate an innovative dynamic coefficient mechanism to enable the model to dynamically adapt to changes in data distribution. To further improve stability and address the common modal collapse problem in GAN, a gradient penalty method is embedded in the training protocol. This integrated strategy ensures that Magnify-GAN can effectively generate samples representing various minority classes within the real data. Compared to ten classical imbalanced sampling methods, Magnify-GAN demonstrates superior performance in precision, F1-score, and AUC values across six synthetic and four real-world imbalanced datasets. Ablation studies, visualized through heatmaps, reveal the complementary synergy between the core modules. Furthermore, a complexity analysis shows that Magnify-GAN offers significant performance gains with moderate increases in computational cost compared to state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Dong, Xiaogang and Wang, Lifei and Qin, Xiwen and Shi, Hongyu},
  doi          = {10.1007/s10489-025-06836-0},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-30},
  shortjournal = {Appl. Intell.},
  title        = {Multi-discriminator generative adversarial networks with dynamic penalty to over-sample imbalanced credit datasets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph convolutional network for time series classification using recurrence plots. <em>APIN</em>, <em>55</em>(15), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06841-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification (TSC) is a crucial task across various domains, and its performance heavily depends on the quality of input representations. Among various representations, the recurrence plot (RP) effectively captures topological recurrence, the unique property of time series data. However, conventional convolutional neural networks (CNNs) cannot fully exploit this property since they treat the RP as grid-like data. In this study, we propose RP-GCN, a novel approach that uses a graph convolutional network (GCN) to exploit topological recurrence inherent in the RP, thereby improving TSC performance. Our method transforms a multivariate time series into graphs where state matrices act as node feature matrices and RPs serve as adjacency matrices, enabling graph convolution to utilize recurrence relationships. We evaluated RP-GCN on 35 benchmark multivariate time series classification datasets and demonstrated superior accuracy and efficient inference time compared to existing methods.},
  archive      = {J_APIN},
  author       = {Kang, Hyewon and Lee, Taek-Ho and Lee, Junghye},
  doi          = {10.1007/s10489-025-06841-3},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A graph convolutional network for time series classification using recurrence plots},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preprocessing method for shield operational parameters adaptable to geological survey data characteristic for predicting disc cutter wear. <em>APIN</em>, <em>55</em>(15), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06846-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shield operational parameters are inherently noisy and, relative to concurrent geological exploration data, contain considerable redundancy, they must be pre-processed before the datasets input to artificial intelligence models. This paper presents a denoising and compression method for preprocessing shield operational parameters, integrating it with the stratal slicing method for predicting disc cutter wear. The operational parameter signals affecting cutter wear are first denoised using wavelet transform, Fourier transform, rolling average, and autoencoder techniques. The proposed Ring-based Summation Averaging (RSA) and Piecewise Aggregate Averaging (PAA) methods are then used to compress the denoised signals, resulting in compressed sequences composed of key points equal to the number of tunnel rings, effectively matching the geological parameters expanded by the stratal slicing method. Furthermore, the prepared data were tested using the long short-term memory (LSTM) + attention mechanism (AM) model to evaluate its application effectiveness in the Guangzhou Metro Line 18 railway. The results show that data compressed using PAA not only better tracks signal variations but also allows for flexible control of the output length of the compressed sequence. The combination of wavelet transforms denoising (WTD) with PAA exhibited the best wear prediction results, achieving R2 / MSE = 0.95 / 2.21 mm. By integrating WTD, PAA, stratal slicing method, and sequence models, a comprehensive and universal methodology is established that can predict disc cutter wear based on initial geological data and shield operational parameters.},
  archive      = {J_APIN},
  author       = {Mo, Deyun and Bai, Liping and Liao, Wenjiang and Tian, Xinyuan and Huang, Weiran},
  doi          = {10.1007/s10489-025-06846-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Preprocessing method for shield operational parameters adaptable to geological survey data characteristic for predicting disc cutter wear},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic gradient accelerated by negative momentum for training deep neural networks. <em>APIN</em>, <em>55</em>(15), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06900-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast and robust stochastic optimization algorithms for training deep neural networks (DNNs) are still a topic of heated discussion. As a simple but effective way, the momentum technique, which utilizes historical gradient information, shows significant promise in training DNNs both theoretically and empirically. Nonetheless, the accumulation of error gradients in stochastic settings leads to the failure of momentum techniques, e.g., Nesterov’s accelerated gradient (NAG), in accelerating stochastic optimization algorithms. To address this problem, a novel type of stochastic optimization algorithm based on negative momentum (NM) is developed and analyzed. In this work, we applied NM to vanilla stochastic gradient descent (SGD), leading to SGD-NM. Although a convex combination of previous and current historical information is adopted in SGD-NM, fewer hyperparameters are introduced than those of the existing NM techniques. Meanwhile, we establish a theoretical guarantee for the resulting SGD-NM and show that SGD-NM enjoys the same low computational cost as vanilla SGD. To further show the superiority of NM in stochastic optimization algorithms, we propose a variant of stochastically controlled stochastic gradient (SCSG) based on the negative momentum technique, termed SCSG-NM, which achieves faster convergence compared to SCSG. Finally, we conduct experiments on various DNN architectures and benchmark datasets. The comparison results with state-of-the-art stochastic optimization algorithms show the great potential of NM in accelerating stochastic optimization, including more robust to large learning rates and better generalization.},
  archive      = {J_APIN},
  author       = {Li, Xiaotian and Yang, Zhuang and Wang, Yang},
  doi          = {10.1007/s10489-025-06900-9},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Stochastic gradient accelerated by negative momentum for training deep neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). External information-augmented contrastive learning framework for fake news detection. <em>APIN</em>, <em>55</em>(15), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06807-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of fake news and information overload on social media has led to increased public confusion and poses a serious threat to social stability. Traditional fake news detection methods typically focus solely on the content of the news itself, making them vulnerable to manipulation by disinformation campaigns. This limitation highlights the need for a more comprehensive approach that incorporates external information to improve detection accuracy. In response to this challenge, we propose a novel framework for fake news detection, named External Information-Augmented Contrastive Learning (EACL). The EACL framework consists of three key modules: (1) the External Information Construction Module, which utilizes entity linking, embedding, and retrieval techniques to analyze news from both factual and public opinion perspectives, thus creating an analysis-friendly environment; (2) the Consistency Feature Extraction Module, which employs a distance-aware signed attention mechanism to model the consistency between news content and external information, while filtering out irrelevant data; and (3) the Comparative Learning Enhancement Module, which constructs positive and negative sample pairs to enhance the learning of semantic differences between fake and real news. Extensive qualitative and quantitative experiments conducted on two real-world datasets demonstrate that EACL achieves impressive accuracy rates of 85.2% and 82.9%, significantly outperforming existing baseline methods. The results further illustrate the effectiveness of integrating external information and contrastive learning in combating misinformation.},
  archive      = {J_APIN},
  author       = {Fang, Xiaochang and Zhang, Huaxiang and Wu, Hongchen and Liu, Li and Yu, Hongzhu and Li, Hongxuan and Jing, Zhaorong},
  doi          = {10.1007/s10489-025-06807-5},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {External information-augmented contrastive learning framework for fake news detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-stimulus generalized and corrected canonical correlation analysis for enhancing SSVEP detection. <em>APIN</em>, <em>55</em>(15), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06859-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial filter-based calibration-training algorithms play a crucial role in improving the information transfer rate (ITR) of steady-state visual evoked potential based brain-computer interfaces (SSVEP-BCIs). These algorithms optimize spatial filters by suppressing the non-SSVEP related components, thereby enhancing the signal-to-noise ratio (SNR) of electroencephalogram (EEG) signals. However, conventional methods neglect the temporally-varying and spatially-coupled characteristics of EEG signals, leading to inherent ITR bottlenecks in BCIs. To this end, we propose a novel SSVEP detection algorithm, termed as multi-stimulus Generalized and Corrected Canonical Correlation Analysis (msGC3A), which is extended and corrected from the generalized canonical correlation analysis algorithm. Specifically, we develop corrected sine-cosine reference templates that enhance the spatial filters’ generalization capability across multiple stimuli. Moreover, we formulate a weighted correlation coefficient that synergistically integrates both generalized and corrected multi-stimulus templates for further enhancement. Empirical experiments have been conducted on two publicly available benchmark SSVEP datasets, and we compared the ensemble version of our msGC3A algorithm with four state-of-the-art algorithms. The results have shown that our algorithm significantly improves SSVEP detection performance while requiring less calibration data. Furthermore, we also conducted ablation experiments to show the adaptive capacity of employing our algorithm for SSVEP-BCIs.},
  archive      = {J_APIN},
  author       = {Lv, Yanhao and Luo, Tian-jian},
  doi          = {10.1007/s10489-025-06859-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Multi-stimulus generalized and corrected canonical correlation analysis for enhancing SSVEP detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards understanding the optimization mechanisms in deep learning. <em>APIN</em>, <em>55</em>(15), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06875-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we adopt a probability distribution estimation perspective to explore the optimization mechanisms of supervised classification using deep neural networks. We demonstrate that, when employing the Fenchel-Young loss, despite the non-convex nature of the fitting error with respect to the model’s parameters, global optimal solutions can be approximated by simultaneously minimizing both the gradient norm and the structural error. The former can be controlled through gradient descent algorithms. For the latter, we prove that it can be managed by increasing the number of parameters and ensuring parameter independence, thereby providing theoretical insights into mechanisms such as overparameterization and random initialization. Ultimately, the paper validates the key conclusions of the proposed method through empirical results, illustrating its practical effectiveness.},
  archive      = {J_APIN},
  author       = {Qi, Binchuan and Gong, Wei and Li, Li},
  doi          = {10.1007/s10489-025-06875-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Towards understanding the optimization mechanisms in deep learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust low-rank representation with structured similarity learning for multi-label classification. <em>APIN</em>, <em>55</em>(15), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06879-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling high-dimensional, noisy data in multi-label classification is challenging, as feature abundance and noise obscure actual data-label relationships. Traditional approaches often model labels and features independently, limiting dependency modeling and noise reduction. To address this, we propose a unified framework combining low-rank representation using nuclear norm regularization with structured similarity learning. This simultaneously projects features and labels into low-rank spaces while preserving key inter-sample and inter-label relationships through structural constraints, further capturing fine-grained correlations via a learned similarity Matrix. Extensive experiments on five benchmark datasets show our model outperforms state-of-the-art methods, achieving a 16% reduction in Hamming Lossl and a 14% improvement in Micro-F1 on high-dimensional, noisy datasets like CAL500 and Corel16k7, with consistent gains in Macro-F1 and Example-F1. These results demonstrate the model’s strong capability for noisy, high-dimensional multi-label classification.},
  archive      = {J_APIN},
  author       = {Ntaye, Emmanuel and Zhou, Conghua and Liu, Zhifeng and Song, Heping and Issahaku, Fadilul-lah Yassaanah and Shen, Xiang-Jun},
  doi          = {10.1007/s10489-025-06879-3},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Robust low-rank representation with structured similarity learning for multi-label classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced inverted transformer: Advancing variate token encoding and blending for time series forecasting. <em>APIN</em>, <em>55</em>(15), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06886-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in channel-dependent Transformer-based forecasters highlight the efficacy of variate tokenization for time series forecasting. Despite this progress, challenges remain in handling complex time series. The vanilla Transformer, while effective in certain scenarios, faces limitations in addressing intricate cross-variate interactions and diverse temporal patterns. This paper presents the Enhanced Inverted Transformer (EiT for short), enhancing standard Transformer blocks for advanced modeling and blending of variate tokens. EiT incorporates three key innovations: First, a hybrid multi-patch attention mechanism that adaptively fuses global and local attention maps, capturing both stable and volatile correlations to mitigate overfitting and enrich inter-channel communication. Second, a multi-head feed-forward network with specialized heads for various temporal patterns, enhancing parameter efficiency and contributing to robust multivariate predictions. Third, paired channel normalization applied to each layer, preserving crucial channel-specific statistics and boosting forecasting performance. By integrating these innovations, EiT effectively overcomes limitations and unlocks the potential of variate tokens for accurate and robust multivariate time series forecasting. Extensive evaluations demonstrate that EiT achieves state-of-the-art (SOTA) performance, surpassing the previous method, the inverted Transformer, by an average of 4.4% in Mean Squared Error (MSE) and 3.4% in Mean Absolute Error (MAE) across five challenging long-term forecasting datasets.},
  archive      = {J_APIN},
  author       = {Li, Xin-Yi and Yang, Yu-Bin},
  doi          = {10.1007/s10489-025-06886-4},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced inverted transformer: Advancing variate token encoding and blending for time series forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rapid federated unlearning with tuning parameters based on fisher information matrix. <em>APIN</em>, <em>55</em>(15), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06593-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed machine learning approach widely applied in privacy-sensitive scenarios. With the emergence of the “right to be forgotten” and the pursuit of data accuracy, there is an increasing demand to quickly and accurately delete targeted information from models while ensuring model performance. Therefore, federated unlearning has been introduced. Although current federated unlearning methods achieve effective unlearning, they often involve lengthy processes and require servers to store extensive historical update information. We propose a novel rapid federated unlearning method named FedTune. This method leverages the Fisher information matrix computed on the client side to assess the correlation between model parameters and the target data, identifying key parameters for adjustment. Based on the importance of these parameters and the frequency of client participation, FedTune determines appropriate adjustment ratios to increase the classification loss on the target data, thereby reducing the model’s accuracy and achieving effective data unlearning. Finally, the server collaborates with the remaining clients for a few rounds of retraining to restore the overall classification performance rapidly. We evaluated the FedTune method on the MNIST, CIFAR-10, and PURCHASE datasets, considering both fixed and dynamic client selection scenarios in privacy-sensitive and contamination settings. Experimental results show that FedTune reduces the time consumed by the unlearning process and server storage costs of the unlearning algorithm while ensuring model classification accuracy and effective unlearning compared to other unlearning algorithms.},
  archive      = {J_APIN},
  author       = {Zhao, Fengda and Xu, Qianyi and Wang, Hao and Guo, Dingding},
  doi          = {10.1007/s10489-025-06593-0},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Rapid federated unlearning with tuning parameters based on fisher information matrix},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale group decision-making approach for quality function deployment based on dempster-shafer evidence theory and hierarchical clustering algorithm. <em>APIN</em>, <em>55</em>(15), 1-36. (<a href='https://doi.org/10.1007/s10489-025-06724-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality Function Deployment (QFD) is a classic customer requirements (CRs)-oriented quality management method. However, the increasing complexity and diversity of CRs in the modern society makes it impossible for the traditional QFD approach with a limited number of team members (TMs) to fully satisfy CRs. Therefore, in order to solve the QFD problem in complex environments, this paper proposes an improved QFD method based on Dempster–Shafer evidence theory (D-S theory) and hierarchical clustering algorithm in large-scale group environments. Firstly, utilizing the advantages of D-S theory in information processing and synthesis, the evaluation of quality characteristics (QCs) in the form of probabilistic linguistic term sets (PLTSs) is transformed into basic probability assignments (BPAs) to handle uncertainty more flexibly. Secondly, this paper designs a hierarchical clustering algorithm based on bounded confidence to divide TMs into subgroups, and fully considers the interaction willingness of TMs during the clustering process to ensure the efficiency and accuracy of decision-making. On this basis, the Stepwise Weight Assessment Ratio Analysis (SWARA) method based on distance degree is introduced to calculate the weight of CRs in a more objective way. Then, the Decision-making Trial and Evaluation Laboratory (DEMATEL) method based on D-S theory is used to deeply analyze the mutual influence relationship between QCs to reveal its internal logic. Besides, combined with the psychological expectations of TMs, the disappointment theory is used to prioritize QCs to ensure that products or services are more in line with customer expectations. Finally, this paper applies the proposed method to the development process of mobile health applications (mHealth apps) from the perspective of privacy security, verifying the practicability and superiority of the method. The effectiveness of the method in CRs transformation and product design optimization is further demonstrated through parametric and comparative analyses.},
  archive      = {J_APIN},
  author       = {Liu, Zhengmin and Feng, Xuan and Zhang, Jihao and Zhang, Bo and Wang, Wenxin and Liu, Peide},
  doi          = {10.1007/s10489-025-06724-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-36},
  shortjournal = {Appl. Intell.},
  title        = {A large-scale group decision-making approach for quality function deployment based on dempster-shafer evidence theory and hierarchical clustering algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way clustering ensemble based on shadowed sets with five approximation regions. <em>APIN</em>, <em>55</em>(15), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06726-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering ensemble is a powerful technique for aggregating multiple clustering results. In order to address the challenge in clustering analysis which was brought by the uncertainty information in the datasets, this work presents a novel three-way clustering ensemble method based on shadowed sets with five approximation regions (3WCE-S5). Firstly, a set of clustering members are generated by fuzzy c-means clustering (FCM). A new shadowed sets is approximated by five regions, named as shadowed sets with five approximation regions (S5). Then, all objects are initially partitioned into five regions according to their membership degrees, which are provided by FCM. Secondly, according to multi-granularity rough sets, objects are further assigned into six approximated regions, namely a core region and five fringe regions. There is a partial order relationship between these six different approximate regions. Finally, the above six regions are processed by the new shadowed sets again to generate the output of three-way clustering. Ten University of California Irvine (UCI) data sets are employed to test the performance of this approach and five comparative methods. Accuracy (ACC), adjusted rand index (ARI), normalized mutual information (NMI) and time cost are utilized to quantify the clustering results.},
  archive      = {J_APIN},
  author       = {Yi, Huangjian and Guo, Dongkai and Zhang, Qinran and He, Xiaowei and Ren, Ruisi},
  doi          = {10.1007/s10489-025-06726-5},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {Three-way clustering ensemble based on shadowed sets with five approximation regions},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic interaction-enhanced encoding network for math word problem solving. <em>APIN</em>, <em>55</em>(15), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06850-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving math word problems (MWPs) requires machines to understand not only the literal meaning of text but also the abstract logic and mathematical reasoning embedded within it. However, existing models often lack explicit reasoning capabilities for semantic information, particularly when dealing with complex math word problem texts. Additionally, these models tend to embed all kinds of information without fine-grained selection, which may introduce unexpected noise for mathematical expression generation. To address these challenges, we propose a Semantic Interaction-Enhanced Encoding Network (SIEN) for math expression generation is proposed in this paper. Firstly, SIEN constructs a semantic role interaction graph for each problem and employs a graph attention neural network to learn interaction and semantic information, offering a more structured and enriched view of the math word problem text. Secondly, SIEN introduces a multi-channel adapter module that simultaneously learns comprehensive contextual information from numeric information channel, hierarchical semantic information channel, and interaction information channel. Furthermore, SIEN introduces a dynamic weighting mechanism that adjusts the information weight from each channel to prioritize relevant information and reduce noise. Experimental results on three public benchmark datasets demonstrate that SIEN achieves significant performance improvement over other state-of-the-art baseline models.},
  archive      = {J_APIN},
  author       = {Xiao, Lingsheng and Chen, Yuzhong and Liu, Zhanghui and Zhong, Jiayuan and Dong, Yu},
  doi          = {10.1007/s10489-025-06850-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Semantic interaction-enhanced encoding network for math word problem solving},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KRMNet: Learning core representations for partial discharge pattern recognition via masked autoencoders and mixed position coding. <em>APIN</em>, <em>55</em>(15), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06899-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial discharge pattern recognition (PDPR) is a crucial cornerstone for condition monitoring and safe operation of electrical devices. It has become an important hotspot in the field of energy systems. However, it faces several challenges, including noise interference, signal complexity, and difficulty in data labeling. This study proposes an efficient multi-scale masked autoencoder (MAE) network (KRMNet) to effectively address these challenges. KRMNet learns common and important multi-scale features and long-range semantic dependencies of partial discharge signals. Furthermore, by using the MAE structure and the transformer as the backbone, the model extracts key distinguishing features from phase-resolved partial discharge (PRPD) signals with background noise, interference, and labeling issues in an efficient and self-supervised manner. In addition, the efficient multi-scale module uses an efficient multi-scale attention mechanism to aggregate key information from multiple feature dimensions. The integration of the efficient multi-scale attention mechanism and contrastive learning methods improves the model’s ability to distinguish key information and resist interference. Experiments on two challenging PRPD datasets show that our proposed KRMNet achieves detection accuracies of 88.5% and 90.2% on noisy (ECPD) and clean (PUPD) datasets, respectively. This finding suggests that the method faces challenges in effectively managing noise interferences and missing labels.},
  archive      = {J_APIN},
  author       = {Deng, Yi and Chen, Jiawen and Xie, Quan and Tan, Dapeng and Liu, Hai},
  doi          = {10.1007/s10489-025-06899-z},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {KRMNet: Learning core representations for partial discharge pattern recognition via masked autoencoders and mixed position coding},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
