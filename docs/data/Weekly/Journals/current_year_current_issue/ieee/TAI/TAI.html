<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tai">TAI - 14</h2>
<ul>
<li><details>
<summary>
(2025). Learning from N-tuple similarities and unlabeled data. <em>TAI</em>, <em>6</em>(9), 2542-2551. (<a href='https://doi.org/10.1109/TAI.2025.3552687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from pairwise similarity and unlabeled data (SU) is a recently emerging weakly-supervised learning method, which learns a classifier from similar data pairs (two instances belonging to the same class) and unlabeled data. However, this framework is insoluble for triplet similarities and unlabeled data. To address this limitation, this article develops a framework for learning from triplet similarities (three instances belonging to the same class) and unlabeled data points, denoted as TSU. This framework not only showcases the feasibility of constructing a TSU classifier but also serves as an inspiration to explore the broader challenge of addressing N-tuple similarities (N ≥ 2) and unlabeled data points. To tackle this more generalized problem, the present article develops an advancing weakly-supervision framework of learning from N-tuple similarities (N instances belong to the same class) and unlabeled data points, named NSU. This framework provides a solid foundation for handling diverse similarity scenarios. Based on these findings, we propose empirical risk minimization estimators for both TSU and NSU classification. The estimation error bounds are also established for the proposed methods. Finally, experiments are performed to verify the effectiveness of the proposed algorithm.},
  archive      = {J_TAI},
  author       = {Junpeng Li and Shuying Huang and Changchun Hua and Yana Yang},
  doi          = {10.1109/TAI.2025.3552687},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2542-2551},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Learning from N-tuple similarities and unlabeled data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of unknown-unknowns in human-in-loop human-in-plant safety critical systems. <em>TAI</em>, <em>6</em>(9), 2526-2541. (<a href='https://doi.org/10.1109/TAI.2025.3550913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Errors in artificial intelligence (AI)-enabled autonomous systems (AASs) where both the cause and effect are unknown to the human operator at the time they occur are referred to as “unknown-unknown” errors. This article introduces a methodology for preemptively identifying “unknown-unknown” errors in AAS that arise due to unpredictable human interactions and complex real-world usage scenarios, potentially leading to critical safety incidents through unsafe shifts in operational data distributions. We posit that AAS functioning in human-in-the-loop and human-in-the-plant modes must adhere to established physical laws, even when unknown-unknown errors occur. Our approach employs constructing physics-guided models from operational data, coupled with conformal inference for assessing structural breaks in the underlying model caused by violations of physical laws, thereby facilitating early detection of such errors before unsafe shifts in operational data distribution occur. Validation across diverse contexts—zero-day vulnerabilities in autonomous vehicles, hardware failures in artificial pancreas systems, and design deficiencies in aircraft in maneuvering characteristics augmentation systems (MCASs)—demonstrates our framework's efficacy in preempting unsafe data distribution shifts due to unknown-unknowns. This methodology not only advances unknown-unknown error detection in AAS but also sets a new benchmark for integrating physics-guided models and machine learning to ensure system safety.},
  archive      = {J_TAI},
  author       = {Aranyak Maity and Ayan Banerjee and Sandeep K. S. Gupta},
  doi          = {10.1109/TAI.2025.3550913},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2526-2541},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Detection of unknown-unknowns in human-in-loop human-in-plant safety critical systems},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensuring reliable learning in graph convolutional networks: Convergence analysis and training methodology. <em>TAI</em>, <em>6</em>(9), 2510-2525. (<a href='https://doi.org/10.1109/TAI.2025.3550458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in learning from graph-structured data have highlighted the importance of graph convolutional networks (GCNs). Despite some research efforts on the theoretical aspects of GCNs, a gap remains in understanding their training process, especially concerning convergence analysis. This study introduces a two-stage training methodology for GCNs, incorporating both pretraining and fine-tuning phases. A two-layer GCN model is used for the convergence analysis and case studies. The convergence analysis that employs a Lyapunov-like approach is performed on the proposed learning algorithm, providing conditions to ensure the convergence of the model learning. Additionally, an automated learning rate scheduler is proposed based on the convergence conditions to prevent divergence and eliminate the need for manual tuning of the initial learning rate. The efficacy of the proposed method is demonstrated through case studies on the node classification problem. The results reveal that the proposed method outperforms gradient descent-based optimizers by achieving consistent training accuracies within a variation of 0.1% across various initial learning rates, without requiring manual tuning.},
  archive      = {J_TAI},
  author       = {Xinge Zhao and Chien Chern Cheah},
  doi          = {10.1109/TAI.2025.3550458},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2510-2525},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Ensuring reliable learning in graph convolutional networks: Convergence analysis and training methodology},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unimodal distributions for ordinal regression. <em>TAI</em>, <em>6</em>(9), 2498-2509. (<a href='https://doi.org/10.1109/TAI.2025.3549740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world prediction tasks, the class labels contain information about the relative order between the labels that are not captured by commonly used loss functions such as multicategory cross-entropy. In ordinal regression, many works have incorporated ordinality into models and loss functions by promoting unimodality of the probability output. However, current approaches are based on heuristics, particularly nonparametric ones, which are still insufficiently explored in the literature. We analyze the set of unimodal distributions in the probability simplex, establishing fundamental properties and giving new perspectives to understand the ordinal regression problem. Two contributions are then proposed to incorporate the preference for unimodal distributions into the predictive model: 1) UnimodalNet, a new architecture that by construction ensures the output is a unimodal distribution, and 2) Wasserstein regularization, a new loss term that relies on the notion of projection in a set to promote unimodality. Experiments show that the new architecture achieves top performance, while the proposed new loss term is very competitive while maintaining high unimodality.},
  archive      = {J_TAI},
  author       = {Jaime S. Cardoso and Ricardo P. M. Cruz and Tomé Albuquerque},
  doi          = {10.1109/TAI.2025.3549740},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2498-2509},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Unimodal distributions for ordinal regression},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MalaNet: A small world inspired neural network for automated malaria diagnosis. <em>TAI</em>, <em>6</em>(9), 2486-2497. (<a href='https://doi.org/10.1109/TAI.2025.3549406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a novel neural network architecture called MalaNet is proposed for the detection and diagnosis of malaria, an infectious disease that poses a major global health challenge. The proposed neural network architecture is inspired by small-world network principles, which generally involve the introduction of new links. A small-world neural network is realized by establishing new connections, thereby reducing the average path length and increasing clustering coefficient. These characteristics are known to enhance interconnectivity and improve feature propagation within the network. In the context of malaria diagnosis, these characteristics of MalaNet can enhance detection accuracy and enable better generalization in scenarios with limited data availability. Broadly, two variants of MalaNet are proposed in this work. First, a small-world-inspired feed-forward neural network (FNN) is developed for symptom and categorical feature-based diagnosis, providing an accessible solution when blood smear images are unavailable. Subsequently, a small-world-inspired convolutional neural network (CNN) is developed for precise and automated diagnosis when blood smear images are available. Both variants of MalaNet are rigorously validated using the National Institute of Health Malaria dataset, a clinical dataset from Federal Polytechnic Ilaro Medical Centre, Nigeria, and the APTOS dataset. Comparative results against several state-of-the-art neural network models in the literature demonstrate MalaNet’s superior performance, generalization capability, and computational efficiency. The small-world neural network architecture proposed in this work enhances feature learning, diagnostic accuracy, and adaptability in limited-data and resource-constrained settings, motivating its application in disease diagnosis where timely and accurate results are critical.},
  archive      = {J_TAI},
  author       = {Shubham Dwivedi and Kartikeya Pandey and Kumar Shubham and Om Jee Pandey and Achyut Mani Tripathi and Tushar Sandhan and Rajesh M. Hegde},
  doi          = {10.1109/TAI.2025.3549406},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2486-2497},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {MalaNet: A small world inspired neural network for automated malaria diagnosis},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-uniform illumination attack for fooling convolutional neural networks. <em>TAI</em>, <em>6</em>(9), 2476-2485. (<a href='https://doi.org/10.1109/TAI.2025.3549396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have made remarkable strides; however, they remain susceptible to vulnerabilities, particularly to image perturbations that humans can easily recognize. This weakness, often termed as “attacks,” underscores the limited robustness of CNNs and the need for research into fortifying their resistance against such manipulations. This study introduces a novel nonuniform illumination (NUI) attack technique, where images are subtly altered using varying NUI masks. Extensive experiments are conducted on widely accepted datasets including CIFAR10, TinyImageNet, CalTech256, and NWPU-RESISC45 focusing on image classification with 12 different NUI masks. The resilience of VGG, ResNet, MobilenetV3-small, InceptionV3, and EfficientNet_b0 models against NUI attacks are evaluated. Our results show a substantial decline in the CNN models’ classification accuracy when subjected to NUI attacks, due to changes in the image pixel value distribution, indicating their vulnerability under NUI. To mitigate this, a defense strategy is proposed, including NUI-attacked images, generated through the new NUI transformation, into the training set. The results demonstrate a significant enhancement in CNN model performance when confronted with perturbed images affected by NUI attacks. This strategy seeks to bolster CNN models’ resilience against NUI attacks. A comparative study with other attack techniques shows the effectiveness of the NUI attack and defense technique.11The code is available at https://github.com/Akshayjain97/Non-Uniform_Illumination},
  archive      = {J_TAI},
  author       = {Akshay Jain and Shiv Ram Dubey and Satish Kumar Singh and KC Santosh and Bidyut Baran Chaudhuri},
  doi          = {10.1109/TAI.2025.3549396},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2476-2485},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Non-uniform illumination attack for fooling convolutional neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting postgraduate student engagement using artificial intelligence (AI). <em>TAI</em>, <em>6</em>(9), 2464-2475. (<a href='https://doi.org/10.1109/TAI.2025.3548016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing number of international students (IS) enrolled in Australian higher education institutions, combined with the widespread adoption of online and hybrid learning, has significant implications for understanding the factors that influence engagement among this diverse student group. Early identification of students with low engagement facilitates academic success, prevents poor outcomes, optimizes resource allocation, improves teaching strategies, increases motivation, and supports long-term success. This study's main aim is to examine the use of AI to predict student engagement. Development of a theoretically informed survey that aimed to elicit postgraduate students' engagement was developed and validated by expert judgment. In total, 200 copies of the survey were distributed, 121 responses were received, and 96 were considered for this study representing a response rate of 48%. This study promotes a multidimensional approach, utilizing AI and ML methodologies, to determine the influence of social and cultural contexts on student engagement. This approach enables educators and institutions to create effective strategies for enhancing the learning experience of postgraduate students. Multiple AI and ML techniques have been utilized including synthetic data generation methods such GaussianCopula, triplet-based variational autoencoder, generative adversarial networks, CopulaGAN, and conditional tabular generative adversarial network. These techniques are specifically employed to predict various dimensions of engagement, including personal, academic, intellectual, social, and professional engagement. The performance of AI/ML algorithms, including support vector machine, K-nearest neighbors, decision trees, gradient boosting machine, random forest, Naive Bayes, logistic regression, and extra trees, was assessed using several metrics including F1 score, sensitivity, specificity, confusion matrix, and accuracy. The models used in this study achieved up to 85% accuracy, offering a solid foundation for guidelines and support to enhance decision making processes in higher education. These findings provide valuable insights for both academics and policy makers, laying the groundwork for evidence-based strategies to improve student engagement.},
  archive      = {J_TAI},
  author       = {Niusha Shafiabady and Tebbin Koo and Fareed Ud Din and Kabir Sattarshetty and Margaret Yen and Mamoun Alazab and Ethar Alsharaydeh},
  doi          = {10.1109/TAI.2025.3548016},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2464-2475},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Predicting postgraduate student engagement using artificial intelligence (AI)},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep graph convolutional autoencoder with conditional normalizing flow for power distribution systems fault classification and location. <em>TAI</em>, <em>6</em>(9), 2448-2463. (<a href='https://doi.org/10.1109/TAI.2025.3547878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate fault classification and location are critical to ensure the reliability and resilience of large-scale power distribution systems (PDSs). The existing data-driven works in this area struggle to capture essential space-time correlations of PDS measurements and often rely on deterministic and shallow neural architectures. Furthermore, they encounter challenges such as over-smoothing and the inability to capture deep correlations. To overcome these limitations, a novel deep space-time generative graph convolutional autoencoder (SGGCA) is proposed. First, the PDS is modeled as a space-time graph where the nodes and edges show the bus measurements and line impedance values, respectively. The proposed SGGCA's encoder captures deep correlations of the space-time graph using a new graph convolution with early connections and identity transformations to mitigate the over-smoothing. Our encoder encompasses a new recurrent method to adjust graph convolution parameters without relying on node embeddings on the temporal dimension. Additionally, it incorporates generative modeling by capturing the probability distribution function of the latent representation through a conditional normalizing flow model. The extracted generative space-time features are enhanced by a multi-head attention mechanism to better capture task-relevant characteristics of the PDS measurements. The extracted features are fed to sparse decoders to classify and locate the faults in the PDS. The feature sparsity of decoders ensures a high generalization capacity and avoids overfitting. The proposed method is evaluated on the IEEE 69-bus and 123-bus systems. It achieves substantial improvements in fault classification accuracy by 3.33% and 6.26% and enhances fault location accuracy by 6.33% and 5.73% for the respective PDSs compared with state-of-the-art models.},
  archive      = {J_TAI},
  author       = {Mohsen Saffari and Mahdi Khodayar and Mohammad E. Khodayar and Seyed Saeed Fazlhashemi},
  doi          = {10.1109/TAI.2025.3547878},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2448-2463},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep graph convolutional autoencoder with conditional normalizing flow for power distribution systems fault classification and location},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive deep learning based short-term wind speed forecasting model for variable terrain conditions. <em>TAI</em>, <em>6</em>(9), 2437-2447. (<a href='https://doi.org/10.1109/TAI.2025.3547685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind flow can be highly unpredictable suffer substantial fluctuations in speed and direction due to the shape and height of hills, mountains, and valleys, making accurate wind speed (WS) forecasting essential in complex terrain. Hourly WS data at 50 meters above ground, from MERRA-2, NASA (2015–2021), collected from five Indian wind stations for plain and complex terrain. This article presents a novel and adaptive model for short-term WS forecasting. The article's key contributions are as follows. (a) the partial auto correlation function (PACF) is utilized to minimize the dimension of the set of intrinsic mode functions (IMF), hence reducing training time; (b) The sample entropy (SampEn) was used to calculate the complexity of the reduced set of IMFs. Since a particular deep learning (DL) model-feature-combination was selected based on complexity, the proposed method is adaptive; (c) a novel bidirectional feature-LSTM framework for complicated IMFs has been suggested, resulting in improved forecasting accuracy; (d) the proposed model shows 55.94% superior forecasting performance compared to the persistence, hybrid, ensemble empirical mode decomposition (EEMD), complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN), and variational mode decomposition (VMD)-based DL models. It has achieved the lowest prediction variance between simple and complex terrain at 0.70%, ensuring robust forecasting performance. Dimension reduction of IMF's and complexity-based model-feature selection helps reduce the training time by 68.77%, additionally forecasting quality is improved by 58.58% on average. These benefits highlight the model's adaptability, effectiveness, and resilience in addressing WS forecasting challenges on complex terrain.},
  archive      = {J_TAI},
  author       = {Sourav Malakar and Saptarsi Goswami and Bhaswati Ganguli and Amlan Chakrabarti},
  doi          = {10.1109/TAI.2025.3547685},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2437-2447},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {An adaptive deep learning based short-term wind speed forecasting model for variable terrain conditions},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale heliostat field optimization for solar power tower system using matrix-based differential evolution. <em>TAI</em>, <em>6</em>(9), 2422-2436. (<a href='https://doi.org/10.1109/TAI.2025.3545813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent optimization of a solar power tower heliostat field (SPTHF) is critical for harnessing solar energy in various scenarios. However, existing SPTHF optimization methods are typically based on specific geometric layout constraints and assume that each heliostat has the same size and height. As a result, these methods are not flexible or practical in many real-world SPTHF application scenarios. Therefore, this article proposes a novel flexible SPTHF (FSPTHF) model that is more practical and involves fewer assumptions. This model enables the use of different layouts and simultaneous optimization of the parameters of each heliostat. As an FSPTHF can involve hundreds or even thousands of heliostats, optimizing the parameters of all heliostats results in a challenging large-scale optimization problem. To efficiently solve this problem, this article proposes a matrix-based differential evolution algorithm, called HMDE, for large-scale heliostat design. The HMDE uses a matrix-based encoding and representation method to improve optimization accuracy and convergence speed, incorporating two novel designs. First, a dual elite-based mutation method is proposed to enhance the convergence speed of HMDE by learning from multiple elite individuals. Second, a multi-level crossover method is proposed to improve the optimization accuracy and convergence speed by integrating element-level and vector-level crossover based on matrix representation. Extensive experiments were conducted on 30 problem instances based on real-world data with three different layouts and problem dimensions up to 12 000, where state-of-the-art algorithms were used for comparison. The experimental results show that the proposed HMDE can effectively solve large-scale FSPTHF optimization problems.},
  archive      = {J_TAI},
  author       = {Dan-Ting Duan and Jian-Yu Li and Bing Sun and Xiao-Fang Liu and Qiang Yang and Qi-Jia Jiang and Zhi-Hui Zhan and Sam Kwong and Jun Zhang},
  doi          = {10.1109/TAI.2025.3545813},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2422-2436},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Large-scale heliostat field optimization for solar power tower system using matrix-based differential evolution},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeoDCL: Weak geometrical distortion-based contrastive learning for fine-grained fashion image retrieval. <em>TAI</em>, <em>6</em>(9), 2409-2421. (<a href='https://doi.org/10.1109/TAI.2025.3545791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses fine-grained fashion image retrieval (FIR), which aims at the detailed and precise retrieval of fashion items from extensive databases. Conventional fine-grained FIR methods design complex attention modules to enhance attribute-aware feature discrimination. However, they often ignore the multiview characteristics of real-world fashion data, leading to diminished model accuracy. Furthermore, our empirical analysis revealed that the straightforward application of standard contrastive learning methods to fine-grained FIR often yields suboptimal results. To alleviate this issue, we propose a novel weak geometrical distortion-based contrastive learning (GeoDCL) strategy. Specifically, GeoDCL incorporates both a novel positive pair design and a novel contrastive loss. GeoDCL can be seamlessly integrated into state-of-the-art (SOTA) fine-grained FIR methods during the training stage to enhance performance during inference. When GeoDCL is applied, the model structures of SOTA methods require no modifications. Additionally, GeoDCL is not utilized during inference, ensuring no increase in inference time. Experiments on the FashionAI, DeepFashion, and Zappos50K datasets verified GeoDCL's effectiveness in consistently improving SOTA models. In particular, GeoDCL drastically improved ASENet_V2 from 60.76% to 66.48% in mAP on the FashionAI dataset.},
  archive      = {J_TAI},
  author       = {Ling Xiao and Toshihiko Yamasaki},
  doi          = {10.1109/TAI.2025.3545791},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2409-2421},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {GeoDCL: Weak geometrical distortion-based contrastive learning for fine-grained fashion image retrieval},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enabling efficient and interpretable cybersecurity reasoning through hyperdimensional computing. <em>TAI</em>, <em>6</em>(9), 2395-2408. (<a href='https://doi.org/10.1109/TAI.2025.3545394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs play a crucial role in addressing the complexities of cybersecurity, as the increasing frequency and sophistication of cyber threats pose significant challenges to traditional defense technologies. In this article, we propose a novel reasoning model, called INCYSER, that is tailored for cybersecurity. By leveraging hyperdimensional computing (HDC) as a symbolic and transparent computational model, INCYSER offers efficient and interpretable reasoning capabilities, ensuring reliable and trustworthy outcomes. Our model combines embedding-based unsupervised learning and HDC-based graph representation learning to construct a general representation for cybersecurity knowledge graphs, enabling diverse tasks including reasoning and general graph operations. Experimental evaluations demonstrate the effectiveness and efficiency of INCYSER, surpassing state-of-the-art models in link prediction and triple classification tasks. Additionally, a comprehensive ablation study examines the impact of various hyperparameters, showcasing the versatility of INCYSER. This work contributes to advancing the field of cybersecurity by introducing an interpretable and representation-based reasoning model for cybersecurity knowledge graphs.},
  archive      = {J_TAI},
  author       = {Ali Zakeri and Hanning Chen and Narayan Srinivasa and Hugo Latapie and Mohsen Imani},
  doi          = {10.1109/TAI.2025.3545394},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2395-2408},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enabling efficient and interpretable cybersecurity reasoning through hyperdimensional computing},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancement of robot dynamics learning by integrating analytical models into deep neural networks: A data fusion perspective. <em>TAI</em>, <em>6</em>(9), 2384-2394. (<a href='https://doi.org/10.1109/TAI.2025.3544591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise modeling of dynamical systems can be crucial for engineering applications. Traditional analytical models often struggle when capturing real-world complexities due to challenges in system nonlinearity representation and model parameter determination. Data-driven models, such as deep neural networks (DNNs), offer better accuracy and generalization but require large quantities of high-quality data. The present article introduces a novel method called the synthesized-data neural network (SDNN), which integrates analytical models, which represent physics, with DNNs to enhance the dynamic model. The main steps of the present method are as follows. The first three degrees of freedom (DOF) of a Kinova Gen3 Lite manipulator are formulated using the Euler–Lagrange equations of motion. The experimental data are recorded from the manipulator. Simulated data from the analytical model are combined with experimental data to train the neural network. The model’s performance is evaluated using the mean squared error (MSE) in real-time experiments with the Kinova Gen3 Lite manipulator. Training datasets represent 14 trajectories, with the MSE calculated for four testing trajectories. The obtained results have led to the following conclusions. The SDNN model has shown improved performance in predicting joint torques when compared to the purely analytical model or the purely data-driven model. The SDNN, when trained with synthesized data from 14 trajectories (SDNN-14), achieved the lowest MSE of 2.14, outperforming the analytical model (MSE of 2.81) and the neural network trained solely on experimental data (MSE of 3.05).},
  archive      = {J_TAI},
  author       = {Erfaan Rezvanfar and Jing Wang and Clarence W. de Silva},
  doi          = {10.1109/TAI.2025.3544591},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2384-2394},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enhancement of robot dynamics learning by integrating analytical models into deep neural networks: A data fusion perspective},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on diagnostic microscopic imaging modalities, challenges, taxonomy, and future directions for cervical abnormality detection and grading. <em>TAI</em>, <em>6</em>(9), 2354-2383. (<a href='https://doi.org/10.1109/TAI.2025.3551669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is one of the most severe diseases, affecting the lives of many people in the modern world. Among the various types of cancer, cervical cancer is one of the most frequently occurring cancers in the female population. In most cases, doctors and practitioners can typically only identify cervical cancer in its latter stages. Planning cancer therapy and increasing patient survival rates become very difficult as the disease progresses. As a result, diagnosing cervical cancer in its initial stages has become imperative to arrange proper therapy and surgery. In this article, we present a survey of automatic computerized methods for diagnosing cervical abnormalities based on microscopic imaging modalities. The present survey was conducted by defining a novel taxonomy of the surveyed techniques based on the approaches they used. We also discuss the challenges and subchallenges associated with an automatic cervical cancer diagnosis based on microscopic imaging modalities. Additionally, surveys on various public and private datasets used by the research community for developing new methods are presented. In this article, the performances of published papers are compared. The article concludes by suggesting possible research directions in these fields.},
  archive      = {J_TAI},
  author       = {Anindita Mohanta and Sourav Dey Roy and Niharika Nath and Abhijit Datta and Mrinal Kanti Bhowmik},
  doi          = {10.1109/TAI.2025.3551669},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  number       = {9},
  pages        = {2354-2383},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A comprehensive survey on diagnostic microscopic imaging modalities, challenges, taxonomy, and future directions for cervical abnormality detection and grading},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
